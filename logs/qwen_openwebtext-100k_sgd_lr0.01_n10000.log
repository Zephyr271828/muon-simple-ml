2025-12-09 12:17:56.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 0.0001 Training loss: 12.033109664916992
2025-12-09 12:17:56.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 0.0002 Training loss: 12.050241470336914
2025-12-09 12:17:57.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 0.0003 Training loss: 12.053863525390625
2025-12-09 12:17:57.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.0004 Training loss: 12.056864738464355
2025-12-09 12:17:57.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.0005 Training loss: 12.02119255065918
2025-12-09 12:17:57.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.0006 Training loss: 12.006023406982422
2025-12-09 12:17:57.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.0007000000000000001 Training loss: 12.02318286895752
2025-12-09 12:17:57.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.0008 Training loss: 12.016715049743652
2025-12-09 12:17:57.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.0009 Training loss: 11.987963676452637
2025-12-09 12:17:57.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.001 Training loss: 12.000905990600586
2025-12-09 12:17:57.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.0011 Training loss: 11.97700023651123
2025-12-09 12:17:57.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.0012 Training loss: 11.997869491577148
2025-12-09 12:17:57.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.0013000000000000002 Training loss: 11.941247940063477
2025-12-09 12:17:57.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.0014000000000000002 Training loss: 11.959638595581055
2025-12-09 12:17:57.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.0015 Training loss: 11.910857200622559
2025-12-09 12:17:58.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.0016 Training loss: 11.893643379211426
2025-12-09 12:17:58.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.0017000000000000001 Training loss: 11.81752872467041
2025-12-09 12:17:58.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.0018 Training loss: 11.856987953186035
2025-12-09 12:17:58.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.0019 Training loss: 11.80951976776123
2025-12-09 12:17:58.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.002 Training loss: 11.759660720825195
2025-12-09 12:17:58.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.0021 Training loss: 11.698113441467285
2025-12-09 12:17:58.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.0022 Training loss: 11.55764389038086
2025-12-09 12:17:58.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0023 Training loss: 11.631705284118652
2025-12-09 12:17:58.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0024 Training loss: 11.47314167022705
2025-12-09 12:17:58.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.0025 Training loss: 11.417311668395996
2025-12-09 12:17:58.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0026000000000000003 Training loss: 11.32460880279541
2025-12-09 12:17:58.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0027 Training loss: 11.314221382141113
2025-12-09 12:17:58.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0028000000000000004 Training loss: 11.077343940734863
2025-12-09 12:17:59.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.0029 Training loss: 11.202746391296387
2025-12-09 12:17:59.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.003 Training loss: 10.966338157653809
2025-12-09 12:17:59.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.0031 Training loss: 11.053139686584473
2025-12-09 12:17:59.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.0032 Training loss: 10.966968536376953
2025-12-09 12:17:59.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.0033000000000000004 Training loss: 10.798657417297363
2025-12-09 12:17:59.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.0034000000000000002 Training loss: 10.64126205444336
2025-12-09 12:17:59.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.0034999999999999996 Training loss: 10.787705421447754
2025-12-09 12:17:59.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.0036 Training loss: 10.671910285949707
2025-12-09 12:17:59.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.0037 Training loss: 10.724297523498535
2025-12-09 12:17:59.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.0038 Training loss: 10.403419494628906
2025-12-09 12:17:59.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.0039000000000000003 Training loss: 10.769765853881836
2025-12-09 12:17:59.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.004 Training loss: 10.482829093933105
2025-12-09 12:17:59.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.0040999999999999995 Training loss: 10.355799674987793
2025-12-09 12:18:00.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.0042 Training loss: 10.168853759765625
2025-12-09 12:18:00.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.0043 Training loss: 10.219493865966797
2025-12-09 12:18:00.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.0044 Training loss: 10.446229934692383
2025-12-09 12:18:00.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.0045000000000000005 Training loss: 10.305816650390625
2025-12-09 12:18:00.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0046 Training loss: 10.167817115783691
2025-12-09 12:18:00.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.0047 Training loss: 10.198702812194824
2025-12-09 12:18:00.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0048 Training loss: 9.965880393981934
2025-12-09 12:18:00.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.0049 Training loss: 10.039380073547363
2025-12-09 12:18:00.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.005 Training loss: 10.026716232299805
2025-12-09 12:18:00.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0051 Training loss: 10.039234161376953
2025-12-09 12:18:00.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.005200000000000001 Training loss: 10.162800788879395
2025-12-09 12:18:01.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0053 Training loss: 10.007779121398926
2025-12-09 12:18:01.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0054 Training loss: 9.883824348449707
2025-12-09 12:18:01.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0055000000000000005 Training loss: 10.199663162231445
2025-12-09 12:18:01.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.005600000000000001 Training loss: 10.036397933959961
2025-12-09 12:18:01.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.005699999999999999 Training loss: 9.7857084274292
2025-12-09 12:18:01.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.0058 Training loss: 10.030525207519531
2025-12-09 12:18:01.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0059 Training loss: 9.651308059692383
2025-12-09 12:18:01.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.006 Training loss: 10.010781288146973
2025-12-09 12:18:01.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.0061 Training loss: 9.827994346618652
2025-12-09 12:18:01.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.0062 Training loss: 9.742321968078613
2025-12-09 12:18:01.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.0063 Training loss: 9.914456367492676
2025-12-09 12:18:01.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.0064 Training loss: 9.559660911560059
2025-12-09 12:18:01.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.006500000000000001 Training loss: 9.71556568145752
2025-12-09 12:18:02.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.006600000000000001 Training loss: 9.748998641967773
2025-12-09 12:18:02.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.0067 Training loss: 9.708845138549805
2025-12-09 12:18:02.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.0068000000000000005 Training loss: 9.725923538208008
2025-12-09 12:18:02.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.0069 Training loss: 9.74397087097168
2025-12-09 12:18:02.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.006999999999999999 Training loss: 9.453361511230469
2025-12-09 12:18:02.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.0070999999999999995 Training loss: 9.842940330505371
2025-12-09 12:18:02.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0072 Training loss: 9.834053993225098
2025-12-09 12:18:02.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.0073 Training loss: 9.571474075317383
2025-12-09 12:18:02.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.0074 Training loss: 9.693559646606445
2025-12-09 12:18:02.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0075 Training loss: 9.643701553344727
2025-12-09 12:18:02.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.0076 Training loss: 9.683027267456055
2025-12-09 12:18:02.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0077 Training loss: 9.678601264953613
2025-12-09 12:18:02.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0078000000000000005 Training loss: 9.705016136169434
2025-12-09 12:18:03.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.0079 Training loss: 9.659521102905273
2025-12-09 12:18:03.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.008 Training loss: 9.86998462677002
2025-12-09 12:18:03.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.008100000000000001 Training loss: 9.456888198852539
2025-12-09 12:18:03.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.008199999999999999 Training loss: 9.467070579528809
2025-12-09 12:18:03.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.0083 Training loss: 9.70854663848877
2025-12-09 12:18:03.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.0084 Training loss: 9.899545669555664
2025-12-09 12:18:03.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.0085 Training loss: 9.433671951293945
2025-12-09 12:18:03.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.0086 Training loss: 9.284196853637695
2025-12-09 12:18:03.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.0087 Training loss: 9.774889945983887
2025-12-09 12:18:03.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.0088 Training loss: 9.776246070861816
2025-12-09 12:18:03.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0089 Training loss: 9.508951187133789
2025-12-09 12:18:03.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.009000000000000001 Training loss: 9.027754783630371
2025-12-09 12:18:03.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0091 Training loss: 9.474617004394531
2025-12-09 12:18:04.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0092 Training loss: 9.548543930053711
2025-12-09 12:18:04.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.009300000000000001 Training loss: 9.027787208557129
2025-12-09 12:18:04.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.0094 Training loss: 9.458733558654785
2025-12-09 12:18:04.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.0095 Training loss: 9.693700790405273
2025-12-09 12:18:04.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0096 Training loss: 9.210953712463379
2025-12-09 12:18:04.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0097 Training loss: 9.491228103637695
2025-12-09 12:18:04.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.0098 Training loss: 9.562190055847168
2025-12-09 12:18:04.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.0099 Training loss: 9.410178184509277
2025-12-09 12:18:04.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.01 Training loss: 9.434613227844238
2025-12-09 12:18:04.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.009999999072578702 Training loss: 9.267559051513672
2025-12-09 12:18:04.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.009999996290315153 Training loss: 9.50208854675293
2025-12-09 12:18:04.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.009999991653210385 Training loss: 9.722994804382324
2025-12-09 12:18:04.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.009999985161266116 Training loss: 9.389378547668457
2025-12-09 12:18:04.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.009999976814484758 Training loss: 9.499696731567383
2025-12-09 12:18:05.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.009999966612869405 Training loss: 9.101239204406738
2025-12-09 12:18:05.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.009999954556423843 Training loss: 9.414799690246582
2025-12-09 12:18:05.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.009999940645152541 Training loss: 9.628926277160645
2025-12-09 12:18:05.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.009999924879060665 Training loss: 9.565876007080078
2025-12-09 12:18:05.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.00999990725815406 Training loss: 9.549372673034668
2025-12-09 12:18:05.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.009999887782439263 Training loss: 9.525192260742188
2025-12-09 12:18:05.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0099998664519235 Training loss: 9.40392780303955
2025-12-09 12:18:05.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.009999843266614685 Training loss: 9.474981307983398
2025-12-09 12:18:05.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.009999818226521415 Training loss: 9.33033561706543
2025-12-09 12:18:05.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.009999791331652984 Training loss: 9.692671775817871
2025-12-09 12:18:05.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.009999762582019366 Training loss: 9.535855293273926
2025-12-09 12:18:05.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.009999731977631227 Training loss: 9.668279647827148
2025-12-09 12:18:06.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.00999969951849992 Training loss: 9.796473503112793
2025-12-09 12:18:06.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.009999665204637487 Training loss: 9.442193984985352
2025-12-09 12:18:06.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.009999629036056657 Training loss: 8.961463928222656
2025-12-09 12:18:06.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.009999591012770847 Training loss: 9.559117317199707
2025-12-09 12:18:06.363 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.009999551134794164 Training loss: 9.873346328735352
2025-12-09 12:18:06.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.0099995094021414 Training loss: 9.492359161376953
2025-12-09 12:18:06.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.009999465814828036 Training loss: 9.494683265686035
2025-12-09 12:18:06.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.009999420372870242 Training loss: 9.56955337524414
2025-12-09 12:18:06.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.009999373076284877 Training loss: 9.114977836608887
2025-12-09 12:18:06.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.009999323925089485 Training loss: 9.514140129089355
2025-12-09 12:18:06.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.009999272919302301 Training loss: 9.68748950958252
2025-12-09 12:18:06.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.009999220058942245 Training loss: 9.860045433044434
2025-12-09 12:18:06.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.009999165344028926 Training loss: 9.325875282287598
2025-12-09 12:18:07.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.009999108774582644 Training loss: 9.525025367736816
2025-12-09 12:18:07.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.009999050350624381 Training loss: 9.280986785888672
2025-12-09 12:18:07.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.009998990072175813 Training loss: 9.543394088745117
2025-12-09 12:18:07.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.009998927939259302 Training loss: 9.462995529174805
2025-12-09 12:18:07.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.009998863951897896 Training loss: 9.592405319213867
2025-12-09 12:18:07.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.009998798110115333 Training loss: 9.603764533996582
2025-12-09 12:18:07.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.009998730413936037 Training loss: 9.515212059020996
2025-12-09 12:18:07.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.009998660863385123 Training loss: 8.974093437194824
2025-12-09 12:18:07.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.00999858945848839 Training loss: 10.206304550170898
2025-12-09 12:18:07.739 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.009998516199272327 Training loss: 9.46072006225586
2025-12-09 12:18:07.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.009998441085764113 Training loss: 9.519230842590332
2025-12-09 12:18:07.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.009998364117991612 Training loss: 9.57584285736084
2025-12-09 12:18:07.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.009998285295983376 Training loss: 9.491803169250488
2025-12-09 12:18:08.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.009998204619768645 Training loss: 9.62713623046875
2025-12-09 12:18:08.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.00999812208937735 Training loss: 9.698055267333984
2025-12-09 12:18:08.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.009998037704840102 Training loss: 9.6583890914917
2025-12-09 12:18:08.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.00999795146618821 Training loss: 9.699783325195312
2025-12-09 12:18:08.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.009997863373453663 Training loss: 9.563682556152344
2025-12-09 12:18:08.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.00999777342666914 Training loss: 9.655677795410156
2025-12-09 12:18:08.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.009997681625868013 Training loss: 9.394180297851562
2025-12-09 12:18:08.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.009997587971084335 Training loss: 9.585360527038574
2025-12-09 12:18:08.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.009997492462352845 Training loss: 9.609359741210938
2025-12-09 12:18:08.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.009997395099708982 Training loss: 9.643036842346191
2025-12-09 12:18:08.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.009997295883188855 Training loss: 9.433152198791504
2025-12-09 12:18:08.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.009997194812829277 Training loss: 9.476155281066895
2025-12-09 12:18:08.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.009997091888667738 Training loss: 9.558395385742188
2025-12-09 12:18:09.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.009996987110742421 Training loss: 9.607769012451172
2025-12-09 12:18:09.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.009996880479092198 Training loss: 9.730914115905762
2025-12-09 12:18:09.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.009996771993756622 Training loss: 9.704875946044922
2025-12-09 12:18:09.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.009996661654775939 Training loss: 9.51901912689209
2025-12-09 12:18:09.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.009996549462191081 Training loss: 9.876799583435059
2025-12-09 12:18:09.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.00999643541604367 Training loss: 9.375198364257812
2025-12-09 12:18:09.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.00999631951637601 Training loss: 9.409224510192871
2025-12-09 12:18:09.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.009996201763231098 Training loss: 9.461658477783203
2025-12-09 12:18:09.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.009996082156652618 Training loss: 9.514028549194336
2025-12-09 12:18:09.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.009995960696684939 Training loss: 9.197660446166992
2025-12-09 12:18:09.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.009995837383373118 Training loss: 9.412994384765625
2025-12-09 12:18:09.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.009995712216762901 Training loss: 9.524065017700195
2025-12-09 12:18:09.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.009995585196900723 Training loss: 9.533980369567871
2025-12-09 12:18:10.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.009995456323833701 Training loss: 9.06484317779541
2025-12-09 12:18:10.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.009995325597609645 Training loss: 9.58047866821289
2025-12-09 12:18:10.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.00999519301827705 Training loss: 9.31237506866455
2025-12-09 12:18:10.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.009995058585885095 Training loss: 9.603304862976074
2025-12-09 12:18:10.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.009994922300483657 Training loss: 9.630472183227539
2025-12-09 12:18:10.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.00999478416212329 Training loss: 9.3885498046875
2025-12-09 12:18:10.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.009994644170855237 Training loss: 9.297779083251953
2025-12-09 12:18:10.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.009994502326731434 Training loss: 9.268507957458496
2025-12-09 12:18:10.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.009994358629804499 Training loss: 9.48758602142334
2025-12-09 12:18:10.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.009994213080127738 Training loss: 9.5798978805542
2025-12-09 12:18:10.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.009994065677755147 Training loss: 9.598852157592773
2025-12-09 12:18:10.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.00999391642274141 Training loss: 9.582460403442383
2025-12-09 12:18:10.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.00999376531514189 Training loss: 9.438458442687988
2025-12-09 12:18:11.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.009993612355012647 Training loss: 8.815786361694336
2025-12-09 12:18:11.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.009993457542410423 Training loss: 9.420443534851074
2025-12-09 12:18:11.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.00999330087739265 Training loss: 9.286880493164062
2025-12-09 12:18:11.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.009993142360017445 Training loss: 9.601381301879883
2025-12-09 12:18:11.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.009992981990343614 Training loss: 9.284857749938965
2025-12-09 12:18:11.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.009992819768430647 Training loss: 9.62885856628418
2025-12-09 12:18:11.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.009992655694338725 Training loss: 9.304141998291016
2025-12-09 12:18:11.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.009992489768128714 Training loss: 9.406278610229492
2025-12-09 12:18:11.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.009992321989862165 Training loss: 9.45346450805664
2025-12-09 12:18:11.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.009992152359601322 Training loss: 9.298212051391602
2025-12-09 12:18:11.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.00999198087740911 Training loss: 9.412908554077148
2025-12-09 12:18:11.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.009991807543349147 Training loss: 9.379579544067383
2025-12-09 12:18:11.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.009991632357485729 Training loss: 9.539390563964844
2025-12-09 12:18:12.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.009991455319883848 Training loss: 9.252677917480469
2025-12-09 12:18:12.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.00999127643060918 Training loss: 9.448800086975098
2025-12-09 12:18:12.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.009991095689728087 Training loss: 9.381814956665039
2025-12-09 12:18:12.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.009990913097307614 Training loss: 9.205907821655273
2025-12-09 12:18:12.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.009990728653415505 Training loss: 9.052393913269043
2025-12-09 12:18:12.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.009990542358120174 Training loss: 9.475314140319824
2025-12-09 12:18:12.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.009990354211490735 Training loss: 8.756414413452148
2025-12-09 12:18:12.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.009990164213596987 Training loss: 9.479975700378418
2025-12-09 12:18:12.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.009989972364509407 Training loss: 9.220748901367188
2025-12-09 12:18:12.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.009989778664299172 Training loss: 9.278955459594727
2025-12-09 12:18:12.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.009989583113038134 Training loss: 9.211577415466309
2025-12-09 12:18:12.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.009989385710798838 Training loss: 9.261090278625488
2025-12-09 12:18:12.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.009989186457654514 Training loss: 8.761716842651367
2025-12-09 12:18:13.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.009988985353679076 Training loss: 9.09543228149414
2025-12-09 12:18:13.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.009988782398947132 Training loss: 9.091553688049316
2025-12-09 12:18:13.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.009988577593533967 Training loss: 9.212494850158691
2025-12-09 12:18:13.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.00998837093751556 Training loss: 9.21969985961914
2025-12-09 12:18:13.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.009988162430968575 Training loss: 9.148789405822754
2025-12-09 12:18:13.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.009987952073970359 Training loss: 9.091429710388184
2025-12-09 12:18:13.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.00998773986659895 Training loss: 9.044578552246094
2025-12-09 12:18:13.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.009987525808933069 Training loss: 9.170472145080566
2025-12-09 12:18:13.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.009987309901052122 Training loss: 9.719107627868652
2025-12-09 12:18:13.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.009987092143036209 Training loss: 9.28540325164795
2025-12-09 12:18:13.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.009986872534966109 Training loss: 9.151240348815918
2025-12-09 12:18:13.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.009986651076923288 Training loss: 9.032743453979492
2025-12-09 12:18:13.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.009986427768989904 Training loss: 9.188170433044434
2025-12-09 12:18:14.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.009986202611248794 Training loss: 9.265732765197754
2025-12-09 12:18:14.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.009985975603783484 Training loss: 8.897225379943848
2025-12-09 12:18:14.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.00998574674667819 Training loss: 8.90546703338623
2025-12-09 12:18:14.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.009985516040017807 Training loss: 8.918780326843262
2025-12-09 12:18:14.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.009985283483887922 Training loss: 8.863312721252441
2025-12-09 12:18:14.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.009985049078374806 Training loss: 9.171808242797852
2025-12-09 12:18:14.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.009984812823565416 Training loss: 8.994400024414062
2025-12-09 12:18:14.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.009984574719547395 Training loss: 9.079230308532715
2025-12-09 12:18:14.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.00998433476640907 Training loss: 8.941970825195312
2025-12-09 12:18:14.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.00998409296423946 Training loss: 8.829413414001465
2025-12-09 12:18:14.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.009983849313128264 Training loss: 8.903266906738281
2025-12-09 12:18:14.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.009983603813165869 Training loss: 8.827102661132812
2025-12-09 12:18:14.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.009983356464443347 Training loss: 9.022817611694336
2025-12-09 12:18:15.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.009983107267052456 Training loss: 8.90223217010498
2025-12-09 12:18:15.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.009982856221085643 Training loss: 8.967856407165527
2025-12-09 12:18:15.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.009982603326636037 Training loss: 8.95923900604248
2025-12-09 12:18:15.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.009982348583797453 Training loss: 8.808396339416504
2025-12-09 12:18:15.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.009982091992664392 Training loss: 9.500321388244629
2025-12-09 12:18:15.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.009981833553332044 Training loss: 9.103540420532227
2025-12-09 12:18:15.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.009981573265896281 Training loss: 8.889738082885742
2025-12-09 12:18:15.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.00998131113045366 Training loss: 8.94625186920166
2025-12-09 12:18:15.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.009981047147101425 Training loss: 9.007918357849121
2025-12-09 12:18:15.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.009980781315937506 Training loss: 8.29340934753418
2025-12-09 12:18:15.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.00998051363706052 Training loss: 9.084076881408691
2025-12-09 12:18:15.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.009980244110569764 Training loss: 8.738554000854492
2025-12-09 12:18:15.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.009979972736565226 Training loss: 8.828662872314453
2025-12-09 12:18:16.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.009979699515147577 Training loss: 8.616186141967773
2025-12-09 12:18:16.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.009979424446418172 Training loss: 8.071342468261719
2025-12-09 12:18:16.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.009979147530479055 Training loss: 8.821106910705566
2025-12-09 12:18:16.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.009978868767432954 Training loss: 9.061890602111816
2025-12-09 12:18:16.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.009978588157383277 Training loss: 8.885103225708008
2025-12-09 12:18:16.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.009978305700434125 Training loss: 9.286272048950195
2025-12-09 12:18:16.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.00997802139669028 Training loss: 8.763372421264648
2025-12-09 12:18:16.547 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.009977735246257209 Training loss: 8.7783784866333
2025-12-09 12:18:16.623 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.009977447249241066 Training loss: 8.682066917419434
2025-12-09 12:18:16.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.009977157405748687 Training loss: 8.709463119506836
2025-12-09 12:18:16.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.009976865715887595 Training loss: 9.243444442749023
2025-12-09 12:18:16.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.009976572179765998 Training loss: 8.724929809570312
2025-12-09 12:18:16.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.009976276797492793 Training loss: 8.790757179260254
2025-12-09 12:18:17.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.009975979569177552 Training loss: 8.698400497436523
2025-12-09 12:18:17.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.009975680494930538 Training loss: 8.815591812133789
2025-12-09 12:18:17.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.0099753795748627 Training loss: 9.010306358337402
2025-12-09 12:18:17.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.00997507680908567 Training loss: 8.408255577087402
2025-12-09 12:18:17.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.009974772197711762 Training loss: 8.8868989944458
2025-12-09 12:18:17.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.009974465740853979 Training loss: 8.90587329864502
2025-12-09 12:18:17.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.009974157438626008 Training loss: 7.948544502258301
2025-12-09 12:18:17.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.009973847291142217 Training loss: 8.601494789123535
2025-12-09 12:18:17.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.009973535298517662 Training loss: 8.519122123718262
2025-12-09 12:18:17.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.009973221460868084 Training loss: 8.607878684997559
2025-12-09 12:18:17.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.009972905778309905 Training loss: 8.693693161010742
2025-12-09 12:18:17.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.009972588250960234 Training loss: 9.282678604125977
2025-12-09 12:18:17.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.009972268878936864 Training loss: 8.81921672821045
2025-12-09 12:18:18.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.009971947662358269 Training loss: 7.706153869628906
2025-12-09 12:18:18.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.009971624601343614 Training loss: 8.58562183380127
2025-12-09 12:18:18.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.009971299696012743 Training loss: 8.776609420776367
2025-12-09 12:18:18.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.009970972946486186 Training loss: 8.954887390136719
2025-12-09 12:18:18.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.009970644352885156 Training loss: 8.480779647827148
2025-12-09 12:18:18.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.009970313915331553 Training loss: 8.75213623046875
2025-12-09 12:18:18.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.009969981633947956 Training loss: 8.575552940368652
2025-12-09 12:18:18.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.009969647508857631 Training loss: 8.483006477355957
2025-12-09 12:18:18.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.00996931154018453 Training loss: 8.663230895996094
2025-12-09 12:18:18.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.009968973728053289 Training loss: 8.482128143310547
2025-12-09 12:18:18.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.009968634072589218 Training loss: 9.361907958984375
2025-12-09 12:18:18.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.009968292573918324 Training loss: 8.449963569641113
2025-12-09 12:18:18.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.009967949232167294 Training loss: 8.602527618408203
2025-12-09 12:18:19.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.009967604047463493 Training loss: 8.340642929077148
2025-12-09 12:18:19.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.009967257019934974 Training loss: 8.50272274017334
2025-12-09 12:18:19.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.009966908149710475 Training loss: 8.308753967285156
2025-12-09 12:18:19.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.009966557436919416 Training loss: 8.779483795166016
2025-12-09 12:18:19.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.009966204881691898 Training loss: 8.706218719482422
2025-12-09 12:18:19.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.00996585048415871 Training loss: 8.469399452209473
2025-12-09 12:18:19.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.009965494244451324 Training loss: 8.846869468688965
2025-12-09 12:18:19.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.00996513616270189 Training loss: 8.558686256408691
2025-12-09 12:18:19.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.009964776239043245 Training loss: 8.433727264404297
2025-12-09 12:18:19.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.009964414473608912 Training loss: 8.734590530395508
2025-12-09 12:18:19.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.009964050866533094 Training loss: 8.475847244262695
2025-12-09 12:18:19.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.009963685417950676 Training loss: 8.281517028808594
2025-12-09 12:18:19.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.00996331812799723 Training loss: 8.486810684204102
2025-12-09 12:18:20.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.009962948996809008 Training loss: 8.55611801147461
2025-12-09 12:18:20.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.009962578024522948 Training loss: 8.469574928283691
2025-12-09 12:18:20.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.009962205211276665 Training loss: 8.27117919921875
2025-12-09 12:18:20.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.009961830557208463 Training loss: 8.802705764770508
2025-12-09 12:18:20.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.009961454062457329 Training loss: 8.646233558654785
2025-12-09 12:18:20.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.009961075727162927 Training loss: 8.45084285736084
2025-12-09 12:18:20.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.009960695551465611 Training loss: 8.454205513000488
2025-12-09 12:18:20.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.009960313535506412 Training loss: 8.150959014892578
2025-12-09 12:18:20.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.009959929679427047 Training loss: 8.60751724243164
2025-12-09 12:18:20.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.009959543983369913 Training loss: 7.8789448738098145
2025-12-09 12:18:20.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.009959156447478091 Training loss: 8.622891426086426
2025-12-09 12:18:20.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.009958767071895348 Training loss: 8.386128425598145
2025-12-09 12:18:20.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.009958375856766127 Training loss: 8.702574729919434
2025-12-09 12:18:21.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.009957982802235556 Training loss: 8.679229736328125
2025-12-09 12:18:21.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.009957587908449448 Training loss: 8.334508895874023
2025-12-09 12:18:21.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.009957191175554294 Training loss: 8.664057731628418
2025-12-09 12:18:21.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.009956792603697273 Training loss: 8.465394973754883
2025-12-09 12:18:21.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.009956392193026239 Training loss: 8.122749328613281
2025-12-09 12:18:21.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.009955989943689734 Training loss: 8.173124313354492
2025-12-09 12:18:21.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.009955585855836977 Training loss: 8.552000999450684
2025-12-09 12:18:21.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.009955179929617875 Training loss: 8.415356636047363
2025-12-09 12:18:21.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.009954772165183012 Training loss: 8.587668418884277
2025-12-09 12:18:21.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.009954362562683658 Training loss: 8.464500427246094
2025-12-09 12:18:21.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.00995395112227176 Training loss: 8.54471492767334
2025-12-09 12:18:21.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.00995353784409995 Training loss: 8.496785163879395
2025-12-09 12:18:21.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.009953122728321542 Training loss: 8.082563400268555
2025-12-09 12:18:22.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.00995270577509053 Training loss: 8.899504661560059
2025-12-09 12:18:22.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.009952286984561591 Training loss: 8.346611022949219
2025-12-09 12:18:22.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.009951866356890084 Training loss: 8.246329307556152
2025-12-09 12:18:22.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.009951443892232048 Training loss: 8.477096557617188
2025-12-09 12:18:22.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.009951019590744202 Training loss: 8.279233932495117
2025-12-09 12:18:22.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.009950593452583952 Training loss: 7.94000244140625
2025-12-09 12:18:22.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.00995016547790938 Training loss: 8.430434226989746
2025-12-09 12:18:22.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.009949735666879251 Training loss: 8.514267921447754
2025-12-09 12:18:22.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.009949304019653011 Training loss: 8.556478500366211
2025-12-09 12:18:22.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.00994887053639079 Training loss: 9.188305854797363
2025-12-09 12:18:22.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.009948435217253393 Training loss: 8.184436798095703
2025-12-09 12:18:22.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.009947998062402312 Training loss: 8.475860595703125
2025-12-09 12:18:22.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.009947559071999719 Training loss: 8.381136894226074
2025-12-09 12:18:23.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.009947118246208461 Training loss: 8.406375885009766
2025-12-09 12:18:23.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.009946675585192076 Training loss: 8.64594841003418
2025-12-09 12:18:23.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.009946231089114773 Training loss: 7.444934844970703
2025-12-09 12:18:23.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.009945784758141448 Training loss: 8.23687744140625
2025-12-09 12:18:23.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.009945336592437678 Training loss: 8.182853698730469
2025-12-09 12:18:23.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.009944886592169713 Training loss: 8.343463897705078
2025-12-09 12:18:23.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.009944434757504492 Training loss: 8.196660041809082
2025-12-09 12:18:23.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.009943981088609631 Training loss: 8.375994682312012
2025-12-09 12:18:23.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.009943525585653428 Training loss: 8.416716575622559
2025-12-09 12:18:23.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.009943068248804858 Training loss: 8.404899597167969
2025-12-09 12:18:23.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.009942609078233581 Training loss: 8.387758255004883
2025-12-09 12:18:23.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.009942148074109933 Training loss: 8.376049041748047
2025-12-09 12:18:23.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.009941685236604934 Training loss: 8.183777809143066
2025-12-09 12:18:23.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.009941220565890278 Training loss: 8.490521430969238
2025-12-09 12:18:24.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.00994075406213835 Training loss: 8.520001411437988
2025-12-09 12:18:24.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.009940285725522203 Training loss: 8.223978042602539
2025-12-09 12:18:24.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.009939815556215575 Training loss: 8.492168426513672
2025-12-09 12:18:24.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.009939343554392886 Training loss: 8.536721229553223
2025-12-09 12:18:24.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.009938869720229233 Training loss: 8.26021957397461
2025-12-09 12:18:24.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.009938394053900394 Training loss: 8.28504467010498
2025-12-09 12:18:24.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.009937916555582828 Training loss: 8.187788963317871
2025-12-09 12:18:24.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.009937437225453668 Training loss: 8.308798789978027
2025-12-09 12:18:24.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.009936956063690734 Training loss: 8.54697036743164
2025-12-09 12:18:24.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.009936473070472518 Training loss: 9.167689323425293
2025-12-09 12:18:24.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.009935988245978198 Training loss: 8.10490894317627
2025-12-09 12:18:24.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.009935501590387627 Training loss: 8.665728569030762
2025-12-09 12:18:24.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.009935013103881342 Training loss: 8.582534790039062
2025-12-09 12:18:25.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.009934522786640554 Training loss: 8.876405715942383
2025-12-09 12:18:25.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.009934030638847154 Training loss: 7.977227687835693
2025-12-09 12:18:25.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.009933536660683716 Training loss: 8.332927703857422
2025-12-09 12:18:25.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.009933040852333487 Training loss: 8.06020450592041
2025-12-09 12:18:25.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.009932543213980401 Training loss: 8.319673538208008
2025-12-09 12:18:25.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.009932043745809064 Training loss: 8.326967239379883
2025-12-09 12:18:25.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.009931542448004758 Training loss: 8.27148151397705
2025-12-09 12:18:25.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.009931039320753456 Training loss: 8.124750137329102
2025-12-09 12:18:25.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.0099305343642418 Training loss: 8.465529441833496
2025-12-09 12:18:25.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.009930027578657113 Training loss: 8.390970230102539
2025-12-09 12:18:25.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.009929518964187393 Training loss: 8.47886848449707
2025-12-09 12:18:25.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.009929008521021325 Training loss: 8.358597755432129
2025-12-09 12:18:25.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.009928496249348266 Training loss: 8.365065574645996
2025-12-09 12:18:26.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.00992798214935825 Training loss: 8.296602249145508
2025-12-09 12:18:26.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.009927466221241995 Training loss: 8.50226879119873
2025-12-09 12:18:26.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.009926948465190892 Training loss: 8.468674659729004
2025-12-09 12:18:26.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.009926428881397015 Training loss: 8.260053634643555
2025-12-09 12:18:26.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.00992590747005311 Training loss: 7.777721881866455
2025-12-09 12:18:26.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.009925384231352606 Training loss: 8.22221851348877
2025-12-09 12:18:26.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.009924859165489608 Training loss: 8.180424690246582
2025-12-09 12:18:26.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.009924332272658898 Training loss: 8.338675498962402
2025-12-09 12:18:26.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.009923803553055936 Training loss: 9.058414459228516
2025-12-09 12:18:26.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.009923273006876865 Training loss: 8.304154396057129
2025-12-09 12:18:26.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.009922740634318495 Training loss: 8.008533477783203
2025-12-09 12:18:26.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.009922206435578323 Training loss: 8.54913330078125
2025-12-09 12:18:26.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.009921670410854518 Training loss: 8.196712493896484
2025-12-09 12:18:27.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.009921132560345929 Training loss: 8.522690773010254
2025-12-09 12:18:27.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.009920592884252082 Training loss: 8.549213409423828
2025-12-09 12:18:27.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.009920051382773179 Training loss: 8.403721809387207
2025-12-09 12:18:27.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.009919508056110101 Training loss: 8.438544273376465
2025-12-09 12:18:27.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.009918962904464406 Training loss: 8.348958015441895
2025-12-09 12:18:27.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.009918415928038325 Training loss: 8.829483032226562
2025-12-09 12:18:27.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.009917867127034772 Training loss: 8.270638465881348
2025-12-09 12:18:27.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.009917316501657334 Training loss: 8.211703300476074
2025-12-09 12:18:27.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.009916764052110274 Training loss: 8.495074272155762
2025-12-09 12:18:27.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.009916209778598535 Training loss: 7.495213031768799
2025-12-09 12:18:27.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.009915653681327737 Training loss: 8.068768501281738
2025-12-09 12:18:27.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.009915095760504169 Training loss: 8.43764877319336
2025-12-09 12:18:27.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.009914536016334808 Training loss: 8.242621421813965
2025-12-09 12:18:28.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.009913974449027297 Training loss: 8.316285133361816
2025-12-09 12:18:28.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.009913411058789963 Training loss: 8.387666702270508
2025-12-09 12:18:28.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.009912845845831806 Training loss: 8.475130081176758
2025-12-09 12:18:28.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.009912278810362498 Training loss: 8.354496955871582
2025-12-09 12:18:28.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.009911709952592397 Training loss: 8.211387634277344
2025-12-09 12:18:28.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.009911139272732527 Training loss: 7.9806952476501465
2025-12-09 12:18:28.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.009910566770994594 Training loss: 8.275483131408691
2025-12-09 12:18:28.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.00990999244759098 Training loss: 8.252955436706543
2025-12-09 12:18:28.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.009909416302734736 Training loss: 7.676573276519775
2025-12-09 12:18:28.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.009908838336639598 Training loss: 8.593535423278809
2025-12-09 12:18:28.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.00990825854951997 Training loss: 8.350264549255371
2025-12-09 12:18:28.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.009907676941590938 Training loss: 8.427680969238281
2025-12-09 12:18:28.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.009907093513068259 Training loss: 8.227387428283691
2025-12-09 12:18:29.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.009906508264168366 Training loss: 8.333324432373047
2025-12-09 12:18:29.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.009905921195108367 Training loss: 8.487390518188477
2025-12-09 12:18:29.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.00990533230610605 Training loss: 8.172642707824707
2025-12-09 12:18:29.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.00990474159737987 Training loss: 7.924649715423584
2025-12-09 12:18:29.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.009904149069148962 Training loss: 8.528740882873535
2025-12-09 12:18:29.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.009903554721633139 Training loss: 8.079413414001465
2025-12-09 12:18:29.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.00990295855505288 Training loss: 8.128307342529297
2025-12-09 12:18:29.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.009902360569629348 Training loss: 8.631054878234863
2025-12-09 12:18:29.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.009901760765584376 Training loss: 8.278841018676758
2025-12-09 12:18:29.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.00990115914314047 Training loss: 7.998721599578857
2025-12-09 12:18:29.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.009900555702520816 Training loss: 8.519329071044922
2025-12-09 12:18:29.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.00989995044394927 Training loss: 8.33905029296875
2025-12-09 12:18:29.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.009899343367650365 Training loss: 8.118453025817871
2025-12-09 12:18:30.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.009898734473849305 Training loss: 8.552522659301758
2025-12-09 12:18:30.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.00989812376277197 Training loss: 8.391572952270508
2025-12-09 12:18:30.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.00989751123464492 Training loss: 8.6102876663208
2025-12-09 12:18:30.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.009896896889695377 Training loss: 8.121796607971191
2025-12-09 12:18:30.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.009896280728151248 Training loss: 8.363822937011719
2025-12-09 12:18:30.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.009895662750241108 Training loss: 8.689094543457031
2025-12-09 12:18:30.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.009895042956194209 Training loss: 8.274195671081543
2025-12-09 12:18:30.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.009894421346240473 Training loss: 8.098653793334961
2025-12-09 12:18:30.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.009893797920610495 Training loss: 8.437159538269043
2025-12-09 12:18:30.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.009893172679535553 Training loss: 8.453669548034668
2025-12-09 12:18:30.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.009892545623247586 Training loss: 8.4019775390625
2025-12-09 12:18:30.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.009891916751979217 Training loss: 8.01339054107666
2025-12-09 12:18:30.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.009891286065963734 Training loss: 8.118042945861816
2025-12-09 12:18:31.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0098906535654351 Training loss: 8.234270095825195
2025-12-09 12:18:31.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.00989001925062796 Training loss: 7.952238082885742
2025-12-09 12:18:31.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.009889383121777617 Training loss: 8.90357780456543
2025-12-09 12:18:31.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.00988874517912006 Training loss: 8.444622039794922
2025-12-09 12:18:31.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.009888105422891941 Training loss: 8.285539627075195
2025-12-09 12:18:31.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.009887463853330595 Training loss: 8.492364883422852
2025-12-09 12:18:31.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.009886820470674018 Training loss: 8.142444610595703
2025-12-09 12:18:31.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.00988617527516089 Training loss: 8.064000129699707
2025-12-09 12:18:31.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.009885528267030555 Training loss: 8.080425262451172
2025-12-09 12:18:31.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.009884879446523035 Training loss: 8.407453536987305
2025-12-09 12:18:31.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.00988422881387902 Training loss: 8.26144790649414
2025-12-09 12:18:31.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.009883576369339874 Training loss: 8.458321571350098
2025-12-09 12:18:31.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.009882922113147636 Training loss: 8.281438827514648
2025-12-09 12:18:32.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.009882266045545011 Training loss: 8.429040908813477
2025-12-09 12:18:32.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.009881608166775383 Training loss: 8.471421241760254
2025-12-09 12:18:32.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.009880948477082803 Training loss: 8.269275665283203
2025-12-09 12:18:32.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.009880286976711991 Training loss: 8.38789176940918
2025-12-09 12:18:32.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.00987962366590835 Training loss: 8.481114387512207
2025-12-09 12:18:32.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.009878958544917943 Training loss: 8.175619125366211
2025-12-09 12:18:32.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.00987829161398751 Training loss: 8.137457847595215
2025-12-09 12:18:32.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.00987762287336446 Training loss: 8.220794677734375
2025-12-09 12:18:32.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.009876952323296877 Training loss: 8.241880416870117
2025-12-09 12:18:32.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.009876279964033513 Training loss: 8.240532875061035
2025-12-09 12:18:32.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.00987560579582379 Training loss: 8.50969123840332
2025-12-09 12:18:32.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.009874929818917806 Training loss: 7.725229740142822
2025-12-09 12:18:32.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.009874252033566327 Training loss: 8.294733047485352
2025-12-09 12:18:33.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.009873572440020791 Training loss: 8.345890998840332
2025-12-09 12:18:33.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.0098728910385333 Training loss: 8.163468360900879
2025-12-09 12:18:33.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.009872207829356642 Training loss: 8.22435188293457
2025-12-09 12:18:33.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.009871522812744256 Training loss: 8.06135368347168
2025-12-09 12:18:33.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.009870835988950269 Training loss: 8.160719871520996
2025-12-09 12:18:33.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.009870147358229466 Training loss: 8.309088706970215
2025-12-09 12:18:33.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.009869456920837311 Training loss: 7.8228864669799805
2025-12-09 12:18:33.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.009868764677029934 Training loss: 8.837689399719238
2025-12-09 12:18:33.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.009868070627064135 Training loss: 8.703965187072754
2025-12-09 12:18:33.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.009867374771197384 Training loss: 8.300915718078613
2025-12-09 12:18:33.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.009866677109687822 Training loss: 8.5315580368042
2025-12-09 12:18:33.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.009865977642794259 Training loss: 8.26186752319336
2025-12-09 12:18:33.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.009865276370776178 Training loss: 8.432605743408203
2025-12-09 12:18:34.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.009864573293893723 Training loss: 9.294005393981934
2025-12-09 12:18:34.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.00986386841240772 Training loss: 8.221858978271484
2025-12-09 12:18:34.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.009863161726579655 Training loss: 8.237571716308594
2025-12-09 12:18:34.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.009862453236671684 Training loss: 8.344240188598633
2025-12-09 12:18:34.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.009861742942946639 Training loss: 8.179702758789062
2025-12-09 12:18:34.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.009861030845668013 Training loss: 8.470541954040527
2025-12-09 12:18:34.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.009860316945099973 Training loss: 8.08188533782959
2025-12-09 12:18:34.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.009859601241507353 Training loss: 8.068307876586914
2025-12-09 12:18:34.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.009858883735155657 Training loss: 8.418405532836914
2025-12-09 12:18:34.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.009858164426311058 Training loss: 8.679558753967285
2025-12-09 12:18:34.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.009857443315240397 Training loss: 8.042106628417969
2025-12-09 12:18:34.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.00985672040221118 Training loss: 8.220394134521484
2025-12-09 12:18:34.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.00985599568749159 Training loss: 8.186993598937988
2025-12-09 12:18:35.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.00985526917135047 Training loss: 8.285058975219727
2025-12-09 12:18:35.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.009854540854057337 Training loss: 8.394316673278809
2025-12-09 12:18:35.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.00985381073588237 Training loss: 8.070834159851074
2025-12-09 12:18:35.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.009853078817096423 Training loss: 8.288176536560059
2025-12-09 12:18:35.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.009852345097971017 Training loss: 8.037498474121094
2025-12-09 12:18:35.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.009851609578778332 Training loss: 7.906260967254639
2025-12-09 12:18:35.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.009850872259791229 Training loss: 8.394837379455566
2025-12-09 12:18:35.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.009850133141283225 Training loss: 8.337364196777344
2025-12-09 12:18:35.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.009849392223528514 Training loss: 8.164421081542969
2025-12-09 12:18:35.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.00984864950680195 Training loss: 8.266753196716309
2025-12-09 12:18:35.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.00984790499137906 Training loss: 8.257272720336914
2025-12-09 12:18:35.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.009847158677536034 Training loss: 8.518094062805176
2025-12-09 12:18:36.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.00984641056554973 Training loss: 8.352766036987305
2025-12-09 12:18:36.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.009845660655697678 Training loss: 8.401651382446289
2025-12-09 12:18:36.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.009844908948258067 Training loss: 8.003069877624512
2025-12-09 12:18:36.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.009844155443509759 Training loss: 8.965609550476074
2025-12-09 12:18:36.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.009843400141732279 Training loss: 8.33400821685791
2025-12-09 12:18:36.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.009842643043205822 Training loss: 8.254582405090332
2025-12-09 12:18:36.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.009841884148211246 Training loss: 8.23324203491211
2025-12-09 12:18:36.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.009841123457030079 Training loss: 8.217268943786621
2025-12-09 12:18:36.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.009840360969944511 Training loss: 8.14108943939209
2025-12-09 12:18:36.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.009839596687237401 Training loss: 8.557023048400879
2025-12-09 12:18:36.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.009838830609192278 Training loss: 8.386680603027344
2025-12-09 12:18:36.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.009838062736093327 Training loss: 8.238659858703613
2025-12-09 12:18:36.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.009837293068225408 Training loss: 8.368819236755371
2025-12-09 12:18:37.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.009836521605874044 Training loss: 8.326744079589844
2025-12-09 12:18:37.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.009835748349325421 Training loss: 8.3407564163208
2025-12-09 12:18:37.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.009834973298866394 Training loss: 8.457497596740723
2025-12-09 12:18:37.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.009834196454784484 Training loss: 8.394754409790039
2025-12-09 12:18:37.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.009833417817367874 Training loss: 7.566822052001953
2025-12-09 12:18:37.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.009832637386905412 Training loss: 8.433248519897461
2025-12-09 12:18:37.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.009831855163686617 Training loss: 7.15172815322876
2025-12-09 12:18:37.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.009831071148001667 Training loss: 8.376151084899902
2025-12-09 12:18:37.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.009830285340141407 Training loss: 8.566800117492676
2025-12-09 12:18:37.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.009829497740397349 Training loss: 8.301520347595215
2025-12-09 12:18:37.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.009828708349061663 Training loss: 8.444025039672852
2025-12-09 12:18:37.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.009827917166427195 Training loss: 8.027871131896973
2025-12-09 12:18:37.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.009827124192787444 Training loss: 8.352889060974121
2025-12-09 12:18:38.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.00982632942843658 Training loss: 8.227787017822266
2025-12-09 12:18:38.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.009825532873669433 Training loss: 8.274871826171875
2025-12-09 12:18:38.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.009824734528781505 Training loss: 8.248312950134277
2025-12-09 12:18:38.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.009823934394068952 Training loss: 8.823235511779785
2025-12-09 12:18:38.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.009823132469828601 Training loss: 8.03432846069336
2025-12-09 12:18:38.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.009822328756357942 Training loss: 8.334630966186523
2025-12-09 12:18:38.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.009821523253955123 Training loss: 8.304035186767578
2025-12-09 12:18:38.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.009820715962918964 Training loss: 7.948334693908691
2025-12-09 12:18:38.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.009819906883548942 Training loss: 8.19129753112793
2025-12-09 12:18:38.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.009819096016145203 Training loss: 8.107949256896973
2025-12-09 12:18:38.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.00981828336100855 Training loss: 8.386455535888672
2025-12-09 12:18:38.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.009817468918440455 Training loss: 8.668288230895996
2025-12-09 12:18:38.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.009816652688743049 Training loss: 8.295780181884766
2025-12-09 12:18:39.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.009815834672219127 Training loss: 8.389416694641113
2025-12-09 12:18:39.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.00981501486917215 Training loss: 8.17410945892334
2025-12-09 12:18:39.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.009814193279906236 Training loss: 8.177461624145508
2025-12-09 12:18:39.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.00981336990472617 Training loss: 7.991596221923828
2025-12-09 12:18:39.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.0098125447439374 Training loss: 7.9798760414123535
2025-12-09 12:18:39.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.009811717797846033 Training loss: 8.438453674316406
2025-12-09 12:18:39.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.00981088906675884 Training loss: 8.146933555603027
2025-12-09 12:18:39.547 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.009810058550983254 Training loss: 8.285935401916504
2025-12-09 12:18:39.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.009809226250827372 Training loss: 8.653616905212402
2025-12-09 12:18:39.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.009808392166599948 Training loss: 8.297067642211914
2025-12-09 12:18:39.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.009807556298610402 Training loss: 8.10252571105957
2025-12-09 12:18:39.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.009806718647168818 Training loss: 8.229031562805176
2025-12-09 12:18:39.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.009805879212585933 Training loss: 8.133898735046387
2025-12-09 12:18:40.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.009805037995173155 Training loss: 7.964211463928223
2025-12-09 12:18:40.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.009804194995242549 Training loss: 7.959569454193115
2025-12-09 12:18:40.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.009803350213106837 Training loss: 8.328849792480469
2025-12-09 12:18:40.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.00980250364907941 Training loss: 8.247663497924805
2025-12-09 12:18:40.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.009801655303474318 Training loss: 8.0667724609375
2025-12-09 12:18:40.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.009800805176606269 Training loss: 7.9983015060424805
2025-12-09 12:18:40.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.009799953268790632 Training loss: 8.010025978088379
2025-12-09 12:18:40.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.00979909958034344 Training loss: 7.636908531188965
2025-12-09 12:18:40.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.009798244111581382 Training loss: 8.5270414352417
2025-12-09 12:18:40.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.009797386862821814 Training loss: 8.442537307739258
2025-12-09 12:18:40.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.009796527834382745 Training loss: 8.368358612060547
2025-12-09 12:18:40.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.009795667026582846 Training loss: 8.38937759399414
2025-12-09 12:18:40.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.009794804439741454 Training loss: 8.393265724182129
2025-12-09 12:18:41.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.00979394007417856 Training loss: 7.858076095581055
2025-12-09 12:18:41.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.009793073930214816 Training loss: 8.201826095581055
2025-12-09 12:18:41.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.009792206008171534 Training loss: 8.147510528564453
2025-12-09 12:18:41.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.009791336308370686 Training loss: 7.9454779624938965
2025-12-09 12:18:41.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.009790464831134903 Training loss: 8.425211906433105
2025-12-09 12:18:41.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.009789591576787476 Training loss: 8.233338356018066
2025-12-09 12:18:41.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.009788716545652353 Training loss: 8.286417007446289
2025-12-09 12:18:41.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.009787839738054147 Training loss: 8.092540740966797
2025-12-09 12:18:41.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.009786961154318121 Training loss: 8.184700012207031
2025-12-09 12:18:41.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.009786080794770207 Training loss: 8.5410737991333
2025-12-09 12:18:41.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.009785198659736987 Training loss: 8.232721328735352
2025-12-09 12:18:41.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.009784314749545706 Training loss: 8.426377296447754
2025-12-09 12:18:41.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.00978342906452427 Training loss: 8.05370044708252
2025-12-09 12:18:42.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.009782541605001235 Training loss: 8.13687515258789
2025-12-09 12:18:42.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.009781652371305825 Training loss: 8.409302711486816
2025-12-09 12:18:42.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.009780761363767914 Training loss: 8.336414337158203
2025-12-09 12:18:42.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.009779868582718041 Training loss: 8.823573112487793
2025-12-09 12:18:42.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.009778974028487398 Training loss: 8.10010814666748
2025-12-09 12:18:42.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.009778077701407838 Training loss: 7.97252082824707
2025-12-09 12:18:42.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.009777179601811866 Training loss: 8.191556930541992
2025-12-09 12:18:42.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.009776279730032653 Training loss: 8.32783031463623
2025-12-09 12:18:42.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.009775378086404022 Training loss: 8.12126636505127
2025-12-09 12:18:42.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.009774474671260455 Training loss: 8.241543769836426
2025-12-09 12:18:42.786 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.00977356948493709 Training loss: 8.663741111755371
2025-12-09 12:18:42.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.00977266252776972 Training loss: 7.8577799797058105
2025-12-09 12:18:42.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.009771753800094802 Training loss: 8.127300262451172
2025-12-09 12:18:43.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.009770843302249442 Training loss: 8.292799949645996
2025-12-09 12:18:43.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.009769931034571407 Training loss: 8.254129409790039
2025-12-09 12:18:43.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.00976901699739912 Training loss: 8.11943531036377
2025-12-09 12:18:43.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.009768101191071661 Training loss: 8.13982105255127
2025-12-09 12:18:43.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.009767183615928763 Training loss: 8.541923522949219
2025-12-09 12:18:43.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.009766264272310822 Training loss: 8.211973190307617
2025-12-09 12:18:43.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.009765343160558878 Training loss: 8.9341459274292
2025-12-09 12:18:43.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.009764420281014641 Training loss: 8.356892585754395
2025-12-09 12:18:43.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.009763495634020467 Training loss: 8.051895141601562
2025-12-09 12:18:43.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.009762569219919371 Training loss: 7.963217258453369
2025-12-09 12:18:43.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.009761641039055026 Training loss: 8.315582275390625
2025-12-09 12:18:43.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.009760711091771755 Training loss: 8.260262489318848
2025-12-09 12:18:43.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.009759779378414542 Training loss: 7.881075382232666
2025-12-09 12:18:44.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.009758845899329021 Training loss: 7.928182125091553
2025-12-09 12:18:44.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.009757910654861483 Training loss: 8.650500297546387
2025-12-09 12:18:44.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.009756973645358876 Training loss: 8.015713691711426
2025-12-09 12:18:44.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.009756034871168799 Training loss: 8.021345138549805
2025-12-09 12:18:44.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.009755094332639512 Training loss: 8.18182373046875
2025-12-09 12:18:44.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.00975415203011992 Training loss: 8.252063751220703
2025-12-09 12:18:44.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.00975320796395959 Training loss: 7.924902439117432
2025-12-09 12:18:44.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.009752262134508742 Training loss: 8.464384078979492
2025-12-09 12:18:44.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.009751314542118247 Training loss: 8.433717727661133
2025-12-09 12:18:44.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.009750365187139632 Training loss: 7.898402690887451
2025-12-09 12:18:44.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.009749414069925078 Training loss: 8.23186206817627
2025-12-09 12:18:44.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.00974846119082742 Training loss: 8.041950225830078
2025-12-09 12:18:44.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.009747506550200145 Training loss: 8.33053970336914
2025-12-09 12:18:45.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.009746550148397396 Training loss: 8.051173210144043
2025-12-09 12:18:45.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.00974559198577397 Training loss: 8.465473175048828
2025-12-09 12:18:45.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.009744632062685311 Training loss: 8.160633087158203
2025-12-09 12:18:45.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.009743670379487522 Training loss: 8.17113208770752
2025-12-09 12:18:45.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.009742706936537358 Training loss: 8.015335083007812
2025-12-09 12:18:45.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.009741741734192224 Training loss: 8.054099082946777
2025-12-09 12:18:45.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.009740774772810181 Training loss: 8.415130615234375
2025-12-09 12:18:45.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.009739806052749942 Training loss: 8.412219047546387
2025-12-09 12:18:45.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.009738835574370872 Training loss: 7.976346969604492
2025-12-09 12:18:45.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.009737863338032985 Training loss: 8.53411865234375
2025-12-09 12:18:45.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.009736889344096951 Training loss: 8.103094100952148
2025-12-09 12:18:45.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.009735913592924092 Training loss: 8.103584289550781
2025-12-09 12:18:45.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.009734936084876382 Training loss: 7.957823276519775
2025-12-09 12:18:46.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.009733956820316443 Training loss: 8.545740127563477
2025-12-09 12:18:46.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.009732975799607553 Training loss: 8.213394165039062
2025-12-09 12:18:46.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.00973199302311364 Training loss: 8.341292381286621
2025-12-09 12:18:46.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.009731008491199285 Training loss: 8.064846992492676
2025-12-09 12:18:46.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.009730022204229714 Training loss: 8.214176177978516
2025-12-09 12:18:46.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.009729034162570812 Training loss: 8.004847526550293
2025-12-09 12:18:46.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.009728044366589108 Training loss: 8.3090181350708
2025-12-09 12:18:46.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.009727052816651788 Training loss: 8.021251678466797
2025-12-09 12:18:46.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.009726059513126686 Training loss: 7.600644111633301
2025-12-09 12:18:46.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.009725064456382283 Training loss: 8.492830276489258
2025-12-09 12:18:46.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.009724067646787717 Training loss: 7.921415328979492
2025-12-09 12:18:46.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.00972306908471277 Training loss: 8.409300804138184
2025-12-09 12:18:46.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.009722068770527881 Training loss: 8.161665916442871
2025-12-09 12:18:47.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.009721066704604134 Training loss: 8.113433837890625
2025-12-09 12:18:47.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.00972006288731326 Training loss: 8.632691383361816
2025-12-09 12:18:47.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.00971905731902765 Training loss: 8.521771430969238
2025-12-09 12:18:47.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.009718050000120333 Training loss: 8.386129379272461
2025-12-09 12:18:47.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.009717040930964996 Training loss: 8.448204040527344
2025-12-09 12:18:47.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.009716030111935968 Training loss: 8.25856876373291
2025-12-09 12:18:47.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.009715017543408233 Training loss: 8.26527214050293
2025-12-09 12:18:47.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.009714003225757424 Training loss: 8.216800689697266
2025-12-09 12:18:47.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.009712987159359818 Training loss: 8.414441108703613
2025-12-09 12:18:47.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.009711969344592347 Training loss: 8.156570434570312
2025-12-09 12:18:47.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.009710949781832585 Training loss: 8.107081413269043
2025-12-09 12:18:47.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.009709928471458759 Training loss: 8.034012794494629
2025-12-09 12:18:47.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.009708905413849743 Training loss: 7.915136337280273
2025-12-09 12:18:48.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.009707880609385058 Training loss: 8.243769645690918
2025-12-09 12:18:48.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.009706854058444877 Training loss: 8.536270141601562
2025-12-09 12:18:48.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.009705825761410014 Training loss: 8.395049095153809
2025-12-09 12:18:48.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.009704795718661938 Training loss: 8.174651145935059
2025-12-09 12:18:48.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.00970376393058276 Training loss: 8.478495597839355
2025-12-09 12:18:48.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.009702730397555245 Training loss: 8.32658863067627
2025-12-09 12:18:48.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.009701695119962798 Training loss: 8.641324043273926
2025-12-09 12:18:48.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.009700658098189475 Training loss: 8.417317390441895
2025-12-09 12:18:48.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.009699619332619978 Training loss: 8.069452285766602
2025-12-09 12:18:48.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.009698578823639658 Training loss: 8.273359298706055
2025-12-09 12:18:48.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.009697536571634508 Training loss: 8.591164588928223
2025-12-09 12:18:48.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.009696492576991175 Training loss: 8.433286666870117
2025-12-09 12:18:48.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.009695446840096945 Training loss: 8.230937957763672
2025-12-09 12:18:49.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.009694399361339753 Training loss: 8.215946197509766
2025-12-09 12:18:49.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.009693350141108182 Training loss: 8.047670364379883
2025-12-09 12:18:49.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.00969229917979146 Training loss: 8.08730411529541
2025-12-09 12:18:49.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.009691246477779459 Training loss: 7.9928717613220215
2025-12-09 12:18:49.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.0096901920354627 Training loss: 8.119400024414062
2025-12-09 12:18:49.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.009689135853232349 Training loss: 8.032145500183105
2025-12-09 12:18:49.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.009688077931480212 Training loss: 7.902033805847168
2025-12-09 12:18:49.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.009687018270598749 Training loss: 8.039005279541016
2025-12-09 12:18:49.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.009685956870981059 Training loss: 8.059621810913086
2025-12-09 12:18:49.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.009684893733020887 Training loss: 7.992299556732178
2025-12-09 12:18:49.794 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.009683828857112626 Training loss: 9.027633666992188
2025-12-09 12:18:49.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.009682762243651308 Training loss: 8.287603378295898
2025-12-09 12:18:49.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.009681693893032617 Training loss: 8.225998878479004
2025-12-09 12:18:50.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.009680623805652875 Training loss: 8.143762588500977
2025-12-09 12:18:50.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.009679551981909052 Training loss: 8.251227378845215
2025-12-09 12:18:50.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.00967847842219876 Training loss: 8.398039817810059
2025-12-09 12:18:50.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.009677403126920255 Training loss: 8.38248062133789
2025-12-09 12:18:50.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.00967632609647244 Training loss: 8.281961441040039
2025-12-09 12:18:50.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.009675247331254857 Training loss: 8.076805114746094
2025-12-09 12:18:50.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.009674166831667696 Training loss: 8.445862770080566
2025-12-09 12:18:50.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.009673084598111788 Training loss: 8.328433990478516
2025-12-09 12:18:50.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.009672000630988605 Training loss: 7.945059776306152
2025-12-09 12:18:50.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.009670914930700268 Training loss: 8.127059936523438
2025-12-09 12:18:50.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.009669827497649537 Training loss: 8.237884521484375
2025-12-09 12:18:50.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.009668738332239813 Training loss: 8.20384407043457
2025-12-09 12:18:50.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.009667647434875144 Training loss: 8.378986358642578
2025-12-09 12:18:51.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.00966655480596022 Training loss: 8.067622184753418
2025-12-09 12:18:51.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.009665460445900368 Training loss: 8.356551170349121
2025-12-09 12:18:51.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.009664364355101564 Training loss: 8.19151496887207
2025-12-09 12:18:51.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.009663266533970424 Training loss: 8.531879425048828
2025-12-09 12:18:51.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.009662166982914203 Training loss: 8.199342727661133
2025-12-09 12:18:51.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.0096610657023408 Training loss: 8.253971099853516
2025-12-09 12:18:51.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.009659962692658756 Training loss: 7.623075485229492
2025-12-09 12:18:51.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.009658857954277254 Training loss: 8.073691368103027
2025-12-09 12:18:51.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.009657751487606114 Training loss: 8.284178733825684
2025-12-09 12:18:51.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.009656643293055805 Training loss: 8.39189338684082
2025-12-09 12:18:51.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.009655533371037426 Training loss: 8.33584213256836
2025-12-09 12:18:51.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.009654421721962729 Training loss: 8.210790634155273
2025-12-09 12:18:51.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.009653308346244099 Training loss: 8.105138778686523
2025-12-09 12:18:52.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.009652193244294562 Training loss: 8.872456550598145
2025-12-09 12:18:52.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.009651076416527786 Training loss: 8.319326400756836
2025-12-09 12:18:52.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.00964995786335808 Training loss: 8.350479125976562
2025-12-09 12:18:52.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.009648837585200392 Training loss: 7.9673075675964355
2025-12-09 12:18:52.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.00964771558247031 Training loss: 7.576232433319092
2025-12-09 12:18:52.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.00964659185558406 Training loss: 8.454954147338867
2025-12-09 12:18:52.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.00964546640495851 Training loss: 8.22585678100586
2025-12-09 12:18:52.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.009644339231011169 Training loss: 8.131301879882812
2025-12-09 12:18:52.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.009643210334160178 Training loss: 8.37994384765625
2025-12-09 12:18:52.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.009642079714824328 Training loss: 8.081025123596191
2025-12-09 12:18:52.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.00964094737342304 Training loss: 8.34720516204834
