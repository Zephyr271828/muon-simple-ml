2025-12-09 12:04:55.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 9.20986557006836
2025-12-09 12:04:55.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 9.209885597229004
2025-12-09 12:04:55.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 9.210670471191406
2025-12-09 12:04:55.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 9.209357261657715
2025-12-09 12:04:55.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 9.209815979003906
2025-12-09 12:04:55.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 9.210168838500977
2025-12-09 12:04:56.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 9.209951400756836
2025-12-09 12:04:56.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 9.209392547607422
2025-12-09 12:04:56.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 9.208230018615723
2025-12-09 12:04:56.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 9.207984924316406
2025-12-09 12:04:56.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 9.208637237548828
2025-12-09 12:04:56.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 9.206437110900879
2025-12-09 12:04:56.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 9.206660270690918
2025-12-09 12:04:56.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 9.205323219299316
2025-12-09 12:04:56.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 9.204938888549805
2025-12-09 12:04:56.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 9.204834938049316
2025-12-09 12:04:56.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 9.204405784606934
2025-12-09 12:04:56.207 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 9.203251838684082
2025-12-09 12:04:56.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 9.202311515808105
2025-12-09 12:04:56.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 9.201807975769043
2025-12-09 12:04:56.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 9.19962215423584
2025-12-09 12:04:56.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 9.199010848999023
2025-12-09 12:04:56.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 9.198190689086914
2025-12-09 12:04:56.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 9.196310997009277
2025-12-09 12:04:56.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 9.195507049560547
2025-12-09 12:04:56.354 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 9.19357967376709
2025-12-09 12:04:56.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 9.191110610961914
2025-12-09 12:04:56.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 9.191511154174805
2025-12-09 12:04:56.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 9.188498497009277
2025-12-09 12:04:56.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 9.18739128112793
2025-12-09 12:04:56.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 9.187244415283203
2025-12-09 12:04:56.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 9.183589935302734
2025-12-09 12:04:56.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 9.183642387390137
2025-12-09 12:04:56.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 9.18204116821289
2025-12-09 12:04:56.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 9.1781644821167
2025-12-09 12:04:56.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 9.17562198638916
2025-12-09 12:04:56.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 9.172999382019043
2025-12-09 12:04:56.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 9.172351837158203
2025-12-09 12:04:56.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 9.170516967773438
2025-12-09 12:04:56.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 9.168116569519043
2025-12-09 12:04:56.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 9.167427062988281
2025-12-09 12:04:56.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 9.165847778320312
2025-12-09 12:04:56.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 9.162334442138672
2025-12-09 12:04:56.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 9.153227806091309
2025-12-09 12:04:56.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 9.157623291015625
2025-12-09 12:04:56.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 9.149405479431152
2025-12-09 12:04:56.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 9.150577545166016
2025-12-09 12:04:56.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 9.147282600402832
2025-12-09 12:04:56.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 9.142256736755371
2025-12-09 12:04:56.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 9.134761810302734
2025-12-09 12:04:56.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 9.1366605758667
2025-12-09 12:04:56.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 9.135385513305664
2025-12-09 12:04:56.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 9.128605842590332
2025-12-09 12:04:56.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 9.130030632019043
2025-12-09 12:04:56.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 9.121213912963867
2025-12-09 12:04:56.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 9.12011432647705
2025-12-09 12:04:56.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 9.110827445983887
2025-12-09 12:04:56.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 9.115679740905762
2025-12-09 12:04:56.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 9.102752685546875
2025-12-09 12:04:56.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 9.099503517150879
2025-12-09 12:04:56.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 9.095006942749023
2025-12-09 12:04:56.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 9.086748123168945
2025-12-09 12:04:57.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 9.080857276916504
2025-12-09 12:04:57.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 9.07855224609375
2025-12-09 12:04:57.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 9.07599925994873
2025-12-09 12:04:57.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 9.064007759094238
2025-12-09 12:04:57.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 9.056788444519043
2025-12-09 12:04:57.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 9.05146598815918
2025-12-09 12:04:57.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 9.035873413085938
2025-12-09 12:04:57.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 9.034204483032227
2025-12-09 12:04:57.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 9.022653579711914
2025-12-09 12:04:57.175 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 9.018049240112305
2025-12-09 12:04:57.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 9.02047348022461
2025-12-09 12:04:57.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 8.997529983520508
2025-12-09 12:04:57.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 9.003188133239746
2025-12-09 12:04:57.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 8.974532127380371
2025-12-09 12:04:57.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 8.97226333618164
2025-12-09 12:04:57.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 8.973663330078125
2025-12-09 12:04:57.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 8.95251750946045
2025-12-09 12:04:57.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 8.939626693725586
2025-12-09 12:04:57.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 8.923883438110352
2025-12-09 12:04:57.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 8.93244457244873
2025-12-09 12:04:57.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 8.917272567749023
2025-12-09 12:04:57.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 8.90630054473877
2025-12-09 12:04:57.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 8.885007858276367
2025-12-09 12:04:57.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 8.885083198547363
2025-12-09 12:04:57.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 8.8753662109375
2025-12-09 12:04:57.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 8.866058349609375
2025-12-09 12:04:57.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 8.844663619995117
2025-12-09 12:04:57.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 8.831707954406738
2025-12-09 12:04:57.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 8.804998397827148
2025-12-09 12:04:57.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 8.798495292663574
2025-12-09 12:04:57.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 8.78547477722168
2025-12-09 12:04:57.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 8.759178161621094
2025-12-09 12:04:57.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 8.768558502197266
2025-12-09 12:04:57.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 8.727803230285645
2025-12-09 12:04:57.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 8.693094253540039
2025-12-09 12:04:57.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 8.718737602233887
2025-12-09 12:04:57.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 8.667381286621094
2025-12-09 12:04:57.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 8.689367294311523
2025-12-09 12:04:57.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0009698463103929542 Training loss: 8.6524019241333
2025-12-09 12:04:57.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.000883022221559489 Training loss: 8.610235214233398
2025-12-09 12:04:57.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.00075 Training loss: 8.615728378295898
2025-12-09 12:04:57.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0005868240888334653 Training loss: 8.591569900512695
2025-12-09 12:04:57.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.00041317591116653486 Training loss: 8.581375122070312
2025-12-09 12:04:57.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0002500000000000001 Training loss: 8.561566352844238
2025-12-09 12:04:57.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.00011697777844051105 Training loss: 8.52019214630127
2025-12-09 12:04:57.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 3.0153689607045842e-05 Training loss: 8.536534309387207
2025-12-09 12:04:57.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0 Training loss: 8.47471809387207
