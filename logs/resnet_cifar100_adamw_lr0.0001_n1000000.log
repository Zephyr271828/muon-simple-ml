2025-12-09 12:06:57.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 4.854283809661865
2025-12-09 12:06:57.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 4.831978797912598
2025-12-09 12:06:57.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 4.912419319152832
2025-12-09 12:06:57.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 4.823228359222412
2025-12-09 12:06:57.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 4.990100860595703
2025-12-09 12:06:57.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 4.875051498413086
2025-12-09 12:06:57.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 4.937801361083984
2025-12-09 12:06:57.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 4.871363639831543
2025-12-09 12:06:57.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 4.812675476074219
2025-12-09 12:06:57.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 4.856395244598389
2025-12-09 12:06:57.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 4.853599548339844
2025-12-09 12:06:57.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 4.83686637878418
2025-12-09 12:06:57.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 4.812750339508057
2025-12-09 12:06:57.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 4.813241481781006
2025-12-09 12:06:57.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 4.678197860717773
2025-12-09 12:06:57.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 4.876860618591309
2025-12-09 12:06:57.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 4.928826808929443
2025-12-09 12:06:57.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 4.762227535247803
2025-12-09 12:06:57.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 4.854517936706543
2025-12-09 12:06:57.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 4.845731735229492
2025-12-09 12:06:57.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 4.890653133392334
2025-12-09 12:06:57.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 4.8168134689331055
2025-12-09 12:06:58.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 4.880712985992432
2025-12-09 12:06:58.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 4.927534103393555
2025-12-09 12:06:58.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 4.8227410316467285
2025-12-09 12:06:58.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 4.783098220825195
2025-12-09 12:06:58.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 4.806928634643555
2025-12-09 12:06:58.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 4.772195339202881
2025-12-09 12:06:58.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 4.8470659255981445
2025-12-09 12:06:58.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 4.765686511993408
2025-12-09 12:06:58.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 4.860014915466309
2025-12-09 12:06:58.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 4.730714321136475
2025-12-09 12:06:58.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 4.9148383140563965
2025-12-09 12:06:58.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 4.8553547859191895
2025-12-09 12:06:58.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 4.727014064788818
2025-12-09 12:06:58.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 4.723910331726074
2025-12-09 12:06:58.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 4.726020812988281
2025-12-09 12:06:58.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 4.777405738830566
2025-12-09 12:06:58.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 4.742199897766113
2025-12-09 12:06:58.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 4.7550458908081055
2025-12-09 12:06:58.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 4.630533218383789
2025-12-09 12:06:58.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 4.782924175262451
2025-12-09 12:06:58.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 4.612030982971191
2025-12-09 12:06:58.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 4.677438259124756
2025-12-09 12:06:58.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 4.740228176116943
2025-12-09 12:06:58.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 4.6700873374938965
2025-12-09 12:06:58.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 4.603530406951904
2025-12-09 12:06:58.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 4.743465900421143
2025-12-09 12:06:58.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 4.639352798461914
2025-12-09 12:06:58.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 4.618043422698975
2025-12-09 12:06:58.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 4.5150041580200195
2025-12-09 12:06:58.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 4.624542236328125
2025-12-09 12:06:58.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 4.580234527587891
2025-12-09 12:06:58.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 4.729524612426758
2025-12-09 12:06:58.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 4.5885396003723145
2025-12-09 12:06:58.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 4.616948127746582
2025-12-09 12:06:58.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 4.5866312980651855
2025-12-09 12:06:58.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 4.673373222351074
2025-12-09 12:06:58.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 4.635913848876953
2025-12-09 12:06:58.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 4.673069953918457
2025-12-09 12:06:58.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 4.536548137664795
2025-12-09 12:06:58.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 4.646340847015381
2025-12-09 12:06:58.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 4.501505374908447
2025-12-09 12:06:58.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 4.542118072509766
2025-12-09 12:06:58.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 4.6350297927856445
2025-12-09 12:06:58.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 4.62124490737915
2025-12-09 12:06:58.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 4.595634460449219
2025-12-09 12:06:58.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 4.492221832275391
2025-12-09 12:06:58.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 4.547300815582275
2025-12-09 12:06:58.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 4.410206317901611
2025-12-09 12:06:58.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 4.533703804016113
2025-12-09 12:06:58.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 4.44480562210083
2025-12-09 12:06:58.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 4.410390853881836
2025-12-09 12:06:58.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 4.534135341644287
2025-12-09 12:06:58.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 4.423419952392578
2025-12-09 12:06:58.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 4.519959449768066
2025-12-09 12:06:58.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 4.436923980712891
2025-12-09 12:06:58.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 4.469552516937256
2025-12-09 12:06:58.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 4.459731101989746
2025-12-09 12:06:58.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 4.340163230895996
2025-12-09 12:06:58.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 4.40826940536499
2025-12-09 12:06:58.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 4.270868301391602
2025-12-09 12:06:58.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 4.3908586502075195
2025-12-09 12:06:58.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 4.452849864959717
2025-12-09 12:06:58.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 4.4256110191345215
2025-12-09 12:06:58.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 4.452824592590332
2025-12-09 12:06:58.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 4.476365566253662
2025-12-09 12:06:58.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 4.443815231323242
2025-12-09 12:06:58.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 4.311321258544922
2025-12-09 12:06:58.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 4.3514790534973145
2025-12-09 12:06:58.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 4.534542083740234
2025-12-09 12:06:58.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 4.36632776260376
2025-12-09 12:06:58.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 4.442415714263916
2025-12-09 12:06:58.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 4.4687066078186035
2025-12-09 12:06:58.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 4.4546709060668945
2025-12-09 12:06:58.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 4.319267749786377
2025-12-09 12:06:58.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 4.408821105957031
2025-12-09 12:06:58.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 4.424880027770996
2025-12-09 12:06:58.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 4.384862422943115
2025-12-09 12:06:58.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 4.300318241119385
2025-12-09 12:06:58.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.999708626830618e-05 Training loss: 4.329293727874756
2025-12-09 12:06:58.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 9.998834541281798e-05 Training loss: 4.3628153800964355
2025-12-09 12:06:58.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 9.997377845227576e-05 Training loss: 4.249407768249512
2025-12-09 12:06:58.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 9.995338708444804e-05 Training loss: 4.1984734535217285
2025-12-09 12:06:58.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 9.992717368593385e-05 Training loss: 4.306155204772949
2025-12-09 12:06:58.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 9.989514131188559e-05 Training loss: 4.290853500366211
2025-12-09 12:06:58.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 9.985729369565299e-05 Training loss: 4.308109283447266
2025-12-09 12:06:58.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 9.9813635248348e-05 Training loss: 4.20418119430542
2025-12-09 12:06:58.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 9.97641710583307e-05 Training loss: 4.1398186683654785
2025-12-09 12:06:58.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 9.970890689061622e-05 Training loss: 4.166777610778809
2025-12-09 12:06:58.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 9.964784918620282e-05 Training loss: 4.174644947052002
2025-12-09 12:06:58.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 9.958100506132127e-05 Training loss: 4.178516864776611
2025-12-09 12:06:58.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 9.950838230660534e-05 Training loss: 4.236655235290527
2025-12-09 12:06:58.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 9.942998938618394e-05 Training loss: 4.278528690338135
2025-12-09 12:06:58.819 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 9.934583543669453e-05 Training loss: 4.132211685180664
2025-12-09 12:06:58.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 9.925593026621833e-05 Training loss: 4.113114356994629
2025-12-09 12:06:58.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 9.916028435313708e-05 Training loss: 4.19613790512085
2025-12-09 12:06:58.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 9.905890884491195e-05 Training loss: 4.395435333251953
2025-12-09 12:06:58.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 9.895181555678418e-05 Training loss: 4.3150529861450195
2025-12-09 12:06:58.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 9.883901697039808e-05 Training loss: 4.23065710067749
2025-12-09 12:06:58.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 9.872052623234632e-05 Training loss: 4.1830644607543945
2025-12-09 12:06:58.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 9.85963571526376e-05 Training loss: 4.29765510559082
2025-12-09 12:06:58.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 9.846652420308728e-05 Training loss: 4.216587066650391
2025-12-09 12:06:58.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 9.833104251563056e-05 Training loss: 4.136542320251465
2025-12-09 12:06:58.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 9.818992788055889e-05 Training loss: 4.1336669921875
2025-12-09 12:06:58.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 9.80431967446797e-05 Training loss: 4.301205635070801
2025-12-09 12:06:58.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 9.789086620939936e-05 Training loss: 4.1358113288879395
2025-12-09 12:06:58.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 9.773295402873026e-05 Training loss: 4.085188388824463
2025-12-09 12:06:58.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 9.756947860722143e-05 Training loss: 4.11769962310791
2025-12-09 12:06:58.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 9.740045899781352e-05 Training loss: 4.02972936630249
2025-12-09 12:06:58.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 9.722591489961827e-05 Training loss: 4.1487135887146
2025-12-09 12:06:58.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 9.70458666556225e-05 Training loss: 4.111783027648926
2025-12-09 12:06:58.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 9.686033525031719e-05 Training loss: 4.20424222946167
2025-12-09 12:06:58.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 9.66693423072518e-05 Training loss: 4.204248428344727
2025-12-09 12:06:58.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 9.647291008651398e-05 Training loss: 4.230284214019775
2025-12-09 12:06:59.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 9.627106148213522e-05 Training loss: 4.202953815460205
2025-12-09 12:06:59.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 9.606382001942255e-05 Training loss: 4.071052074432373
2025-12-09 12:06:59.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 9.585120985221671e-05 Training loss: 4.074645042419434
2025-12-09 12:06:59.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 9.563325576007701e-05 Training loss: 4.087821960449219
2025-12-09 12:06:59.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 9.540998314539328e-05 Training loss: 4.113432884216309
2025-12-09 12:06:59.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 9.518141803042527e-05 Training loss: 4.123684406280518
2025-12-09 12:06:59.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 9.494758705426978e-05 Training loss: 3.963097333908081
2025-12-09 12:06:59.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 9.470851746975582e-05 Training loss: 4.1621785163879395
2025-12-09 12:06:59.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 9.446423714026846e-05 Training loss: 4.037012100219727
2025-12-09 12:06:59.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 9.421477453650118e-05 Training loss: 3.975029468536377
2025-12-09 12:06:59.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 9.396015873313781e-05 Training loss: 4.211562633514404
2025-12-09 12:06:59.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 9.37004194054638e-05 Training loss: 3.9974281787872314
2025-12-09 12:06:59.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 9.343558682590756e-05 Training loss: 4.17371940612793
2025-12-09 12:06:59.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 9.316569186051234e-05 Training loss: 4.0117363929748535
2025-12-09 12:06:59.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 9.289076596533872e-05 Training loss: 4.102156162261963
2025-12-09 12:06:59.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 9.261084118279847e-05 Training loss: 4.0645647048950195
2025-12-09 12:06:59.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 9.232595013792002e-05 Training loss: 3.945413589477539
2025-12-09 12:06:59.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 9.203612603454604e-05 Training loss: 4.094845294952393
2025-12-09 12:06:59.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 9.174140265146356e-05 Training loss: 3.968907594680786
2025-12-09 12:06:59.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 9.144181433846707e-05 Training loss: 4.028271675109863
2025-12-09 12:06:59.175 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 9.113739601235507e-05 Training loss: 4.012262344360352
2025-12-09 12:06:59.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 9.082818315286055e-05 Training loss: 3.944751739501953
2025-12-09 12:06:59.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 9.051421179851588e-05 Training loss: 3.931450366973877
2025-12-09 12:06:59.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 9.01955185424525e-05 Training loss: 3.851182460784912
2025-12-09 12:06:59.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 8.987214052813604e-05 Training loss: 4.0422515869140625
2025-12-09 12:06:59.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 8.954411544503729e-05 Training loss: 3.963252067565918
2025-12-09 12:06:59.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 8.921148152423946e-05 Training loss: 3.9542598724365234
2025-12-09 12:06:59.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 8.887427753398248e-05 Training loss: 4.071305751800537
2025-12-09 12:06:59.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 8.853254277514446e-05 Training loss: 4.010483264923096
2025-12-09 12:06:59.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 8.818631707666135e-05 Training loss: 4.088729381561279
2025-12-09 12:06:59.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 8.783564079088477e-05 Training loss: 4.153090476989746
2025-12-09 12:06:59.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 8.748055478887904e-05 Training loss: 4.0196943283081055
2025-12-09 12:06:59.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 8.712110045565768e-05 Training loss: 3.919039011001587
2025-12-09 12:06:59.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 8.675731968536002e-05 Training loss: 3.8949778079986572
2025-12-09 12:06:59.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 8.638925487636848e-05 Training loss: 3.982841730117798
2025-12-09 12:06:59.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 8.6016948926367e-05 Training loss: 3.849442958831787
2025-12-09 12:06:59.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 8.564044522734147e-05 Training loss: 4.0160980224609375
2025-12-09 12:06:59.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 8.52597876605223e-05 Training loss: 3.834015369415283
2025-12-09 12:06:59.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 8.487502059127015e-05 Training loss: 3.97245454788208
2025-12-09 12:06:59.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 8.448618886390522e-05 Training loss: 3.8875842094421387
2025-12-09 12:06:59.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 8.40933377964806e-05 Training loss: 3.8656091690063477
2025-12-09 12:06:59.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 8.369651317550054e-05 Training loss: 3.9063503742218018
2025-12-09 12:06:59.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 8.329576125058406e-05 Training loss: 3.8623619079589844
2025-12-09 12:06:59.376 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 8.289112872907454e-05 Training loss: 4.019557476043701
2025-12-09 12:06:59.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 8.248266277059607e-05 Training loss: 4.024027347564697
2025-12-09 12:06:59.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 8.2070410981557e-05 Training loss: 3.846798896789551
2025-12-09 12:06:59.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 8.16544214096015e-05 Training loss: 3.9575424194335938
2025-12-09 12:06:59.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 8.123474253800957e-05 Training loss: 3.769230604171753
2025-12-09 12:06:59.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 8.081142328004637e-05 Training loss: 3.887059211730957
2025-12-09 12:06:59.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 8.038451297326145e-05 Training loss: 3.9429121017456055
2025-12-09 12:06:59.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 7.995406137373846e-05 Training loss: 3.939791202545166
2025-12-09 12:06:59.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 7.952011865029614e-05 Training loss: 3.8799846172332764
2025-12-09 12:06:59.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 7.908273537864113e-05 Training loss: 4.019714832305908
2025-12-09 12:06:59.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 7.86419625354735e-05 Training loss: 3.843060255050659
2025-12-09 12:06:59.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 7.819785149254532e-05 Training loss: 4.0061492919921875
2025-12-09 12:06:59.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 7.77504540106735e-05 Training loss: 3.7788784503936768
2025-12-09 12:06:59.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 7.729982223370691e-05 Training loss: 3.73054575920105
2025-12-09 12:06:59.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 7.68460086824492e-05 Training loss: 3.8469388484954834
2025-12-09 12:06:59.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 7.638906624853743e-05 Training loss: 3.7584152221679688
2025-12-09 12:06:59.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 7.592904818827775e-05 Training loss: 3.9083900451660156
2025-12-09 12:06:59.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 7.546600811643816e-05 Training loss: 3.9068562984466553
2025-12-09 12:06:59.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 7.500000000000001e-05 Training loss: 3.9516279697418213
2025-12-09 12:06:59.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 7.453107815186803e-05 Training loss: 3.8569607734680176
2025-12-09 12:06:59.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 7.405929722454026e-05 Training loss: 3.838956832885742
2025-12-09 12:06:59.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 7.358471220373832e-05 Training loss: 3.741452217102051
2025-12-09 12:06:59.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 7.310737840199885e-05 Training loss: 3.893106460571289
2025-12-09 12:06:59.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 7.262735145222696e-05 Training loss: 3.786752462387085
2025-12-09 12:06:59.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 7.214468730121208e-05 Training loss: 3.843427896499634
2025-12-09 12:06:59.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 7.165944220310767e-05 Training loss: 3.7135894298553467
2025-12-09 12:06:59.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 7.117167271287453e-05 Training loss: 3.890105962753296
2025-12-09 12:06:59.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 7.068143567968957e-05 Training loss: 3.986466884613037
2025-12-09 12:06:59.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 7.018878824032009e-05 Training loss: 3.6334409713745117
2025-12-09 12:06:59.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 6.969378781246436e-05 Training loss: 3.9476349353790283
2025-12-09 12:06:59.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 6.919649208805981e-05 Training loss: 3.7053730487823486
2025-12-09 12:06:59.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 6.869695902655897e-05 Training loss: 3.8539552688598633
2025-12-09 12:06:59.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 6.819524684817438e-05 Training loss: 3.9609148502349854
2025-12-09 12:06:59.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 6.769141402709305e-05 Training loss: 3.7822141647338867
2025-12-09 12:06:59.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 6.718551928466132e-05 Training loss: 3.9322547912597656
2025-12-09 12:06:59.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 6.667762158254104e-05 Training loss: 3.6904714107513428
2025-12-09 12:06:59.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 6.616778011583743e-05 Training loss: 3.812622308731079
2025-12-09 12:06:59.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 6.565605430620013e-05 Training loss: 3.7843427658081055
2025-12-09 12:06:59.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 6.514250379489753e-05 Training loss: 3.8327596187591553
2025-12-09 12:06:59.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 6.462718843586571e-05 Training loss: 3.924203634262085
2025-12-09 12:06:59.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 6.411016828873239e-05 Training loss: 3.723508358001709
2025-12-09 12:06:59.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 6.359150361181715e-05 Training loss: 3.7187492847442627
2025-12-09 12:06:59.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 6.307125485510828e-05 Training loss: 3.880784511566162
2025-12-09 12:06:59.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 6.254948265321744e-05 Training loss: 3.8366312980651855
2025-12-09 12:06:59.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 6.202624781831268e-05 Training loss: 3.8977701663970947
2025-12-09 12:06:59.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 6.150161133303089e-05 Training loss: 3.944199562072754
2025-12-09 12:06:59.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 6.0975634343370256e-05 Training loss: 3.8944973945617676
2025-12-09 12:06:59.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 6.044837815156377e-05 Training loss: 3.716460943222046
2025-12-09 12:06:59.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 5.99199042089345e-05 Training loss: 3.700043201446533
2025-12-09 12:06:59.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 5.939027410873351e-05 Training loss: 3.95253586769104
2025-12-09 12:06:59.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 5.885954957896115e-05 Training loss: 3.778898239135742
2025-12-09 12:06:59.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 5.832779247517273e-05 Training loss: 3.677168607711792
2025-12-09 12:06:59.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 5.779506477326933e-05 Training loss: 3.9953055381774902
2025-12-09 12:06:59.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 5.726142856227452e-05 Training loss: 3.6967644691467285
2025-12-09 12:06:59.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 5.672694603709794e-05 Training loss: 3.826378345489502
2025-12-09 12:06:59.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 5.619167949128652e-05 Training loss: 3.9094812870025635
2025-12-09 12:06:59.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 5.565569130976422e-05 Training loss: 3.7931602001190186
2025-12-09 12:06:59.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 5.5119043961561136e-05 Training loss: 3.652776002883911
2025-12-09 12:06:59.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 5.458179999253275e-05 Training loss: 3.7264468669891357
2025-12-09 12:06:59.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 5.4044022018070214e-05 Training loss: 3.7107253074645996
2025-12-09 12:06:59.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 5.3505772715802704e-05 Training loss: 3.7501723766326904
2025-12-09 12:06:59.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 5.296711481829226e-05 Training loss: 3.7656893730163574
2025-12-09 12:06:59.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 5.242811110572242e-05 Training loss: 3.895786762237549
2025-12-09 12:06:59.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 5.188882439858117e-05 Training loss: 3.6707522869110107
2025-12-09 12:06:59.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 5.134931755033936e-05 Training loss: 3.7746975421905518
2025-12-09 12:06:59.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 5.080965344012508e-05 Training loss: 3.551265001296997
2025-12-09 12:06:59.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 5.0269894965395225e-05 Training loss: 3.951277256011963
2025-12-09 12:06:59.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 4.973010503460479e-05 Training loss: 3.804276943206787
2025-12-09 12:06:59.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 4.919034655987493e-05 Training loss: 3.545405387878418
2025-12-09 12:06:59.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 4.865068244966066e-05 Training loss: 3.7713100910186768
2025-12-09 12:06:59.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 4.8111175601418844e-05 Training loss: 3.875871181488037
2025-12-09 12:06:59.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 4.7571888894277604e-05 Training loss: 3.611025094985962
2025-12-09 12:06:59.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 4.703288518170774e-05 Training loss: 3.762186050415039
2025-12-09 12:07:00.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 4.6494227284197294e-05 Training loss: 3.724543809890747
2025-12-09 12:07:00.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 4.59559779819298e-05 Training loss: 3.8853273391723633
2025-12-09 12:07:00.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 4.541820000746727e-05 Training loss: 3.7056593894958496
2025-12-09 12:07:00.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 4.4880956038438876e-05 Training loss: 3.8218002319335938
2025-12-09 12:07:00.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 4.434430869023579e-05 Training loss: 3.714262008666992
2025-12-09 12:07:00.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 4.38083205087135e-05 Training loss: 3.831036329269409
2025-12-09 12:07:00.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 4.3273053962902076e-05 Training loss: 3.831557512283325
2025-12-09 12:07:00.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 4.27385714377255e-05 Training loss: 3.6734840869903564
2025-12-09 12:07:00.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 4.220493522673067e-05 Training loss: 3.716331720352173
2025-12-09 12:07:00.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 4.1672207524827275e-05 Training loss: 3.7641499042510986
2025-12-09 12:07:00.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 4.114045042103887e-05 Training loss: 3.6201446056365967
2025-12-09 12:07:00.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 4.06097258912665e-05 Training loss: 3.820664882659912
2025-12-09 12:07:00.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 4.0080095791065505e-05 Training loss: 3.4889943599700928
2025-12-09 12:07:00.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 3.955162184843625e-05 Training loss: 3.685731887817383
2025-12-09 12:07:00.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 3.902436565662977e-05 Training loss: 3.8335418701171875
2025-12-09 12:07:00.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 3.849838866696913e-05 Training loss: 3.85538387298584
2025-12-09 12:07:00.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 3.7973752181687335e-05 Training loss: 3.580583095550537
2025-12-09 12:07:00.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 3.745051734678256e-05 Training loss: 3.660168409347534
2025-12-09 12:07:00.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 3.692874514489173e-05 Training loss: 3.7640810012817383
2025-12-09 12:07:00.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 3.640849638818286e-05 Training loss: 3.6196866035461426
2025-12-09 12:07:00.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 3.588983171126762e-05 Training loss: 3.8280365467071533
2025-12-09 12:07:00.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 3.53728115641343e-05 Training loss: 3.6899044513702393
2025-12-09 12:07:00.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 3.4857496205102474e-05 Training loss: 3.6950857639312744
2025-12-09 12:07:00.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 3.434394569379988e-05 Training loss: 3.75325608253479
2025-12-09 12:07:00.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 3.3832219884162585e-05 Training loss: 3.621522903442383
2025-12-09 12:07:00.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 3.332237841745898e-05 Training loss: 3.67728853225708
2025-12-09 12:07:00.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 3.281448071533867e-05 Training loss: 3.6723499298095703
2025-12-09 12:07:00.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 3.2308585972906966e-05 Training loss: 3.67236590385437
2025-12-09 12:07:00.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 3.180475315182563e-05 Training loss: 3.797400951385498
2025-12-09 12:07:00.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 3.130304097344103e-05 Training loss: 3.601317882537842
2025-12-09 12:07:00.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 3.080350791194019e-05 Training loss: 3.6594157218933105
2025-12-09 12:07:00.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 3.0306212187535653e-05 Training loss: 3.7491705417633057
2025-12-09 12:07:00.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 2.9811211759679924e-05 Training loss: 3.643538236618042
2025-12-09 12:07:00.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 2.9318564320310444e-05 Training loss: 3.5947935581207275
2025-12-09 12:07:00.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 2.882832728712551e-05 Training loss: 3.752751111984253
2025-12-09 12:07:00.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 2.8340557796892354e-05 Training loss: 3.8017578125
2025-12-09 12:07:00.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 2.7855312698787904e-05 Training loss: 3.7837672233581543
2025-12-09 12:07:00.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 2.737264854777306e-05 Training loss: 3.7636027336120605
2025-12-09 12:07:00.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 2.6892621598001156e-05 Training loss: 3.8730788230895996
2025-12-09 12:07:00.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 2.6415287796261706e-05 Training loss: 3.583857297897339
2025-12-09 12:07:00.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 2.5940702775459747e-05 Training loss: 3.5857157707214355
2025-12-09 12:07:00.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 2.5468921848131983e-05 Training loss: 3.8029580116271973
2025-12-09 12:07:00.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 2.500000000000001e-05 Training loss: 3.5407862663269043
2025-12-09 12:07:00.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 2.4533991883561868e-05 Training loss: 3.5353102684020996
2025-12-09 12:07:00.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 2.407095181172227e-05 Training loss: 3.8530774116516113
2025-12-09 12:07:00.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 2.3610933751462553e-05 Training loss: 3.6548237800598145
2025-12-09 12:07:00.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 2.315399131755081e-05 Training loss: 3.751981258392334
2025-12-09 12:07:00.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 2.2700177766293096e-05 Training loss: 3.517580032348633
2025-12-09 12:07:00.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 2.2249545989326514e-05 Training loss: 3.7504076957702637
2025-12-09 12:07:00.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 2.180214850745467e-05 Training loss: 3.6773765087127686
2025-12-09 12:07:00.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 2.1358037464526515e-05 Training loss: 3.6175343990325928
2025-12-09 12:07:00.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 2.091726462135888e-05 Training loss: 3.805619239807129
2025-12-09 12:07:00.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 2.0479881349703883e-05 Training loss: 3.744575262069702
2025-12-09 12:07:00.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 2.0045938626261546e-05 Training loss: 3.595315456390381
2025-12-09 12:07:00.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 1.9615487026738543e-05 Training loss: 3.4882025718688965
2025-12-09 12:07:00.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 1.9188576719953633e-05 Training loss: 3.4987003803253174
2025-12-09 12:07:00.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 1.8765257461990442e-05 Training loss: 3.597715139389038
2025-12-09 12:07:00.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 1.834557859039851e-05 Training loss: 3.599313497543335
2025-12-09 12:07:00.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 1.7929589018443016e-05 Training loss: 3.5529394149780273
2025-12-09 12:07:00.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 1.7517337229403946e-05 Training loss: 3.621839761734009
2025-12-09 12:07:00.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 1.710887127092548e-05 Training loss: 3.5443692207336426
2025-12-09 12:07:00.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 1.6704238749415957e-05 Training loss: 3.789057493209839
2025-12-09 12:07:00.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 1.6303486824499458e-05 Training loss: 3.503645658493042
2025-12-09 12:07:00.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 1.5906662203519412e-05 Training loss: 3.7386395931243896
2025-12-09 12:07:00.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 1.5513811136094787e-05 Training loss: 3.6860828399658203
2025-12-09 12:07:00.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 1.5124979408729861e-05 Training loss: 3.704669237136841
2025-12-09 12:07:00.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 1.4740212339477721e-05 Training loss: 3.589751720428467
2025-12-09 12:07:00.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 1.4359554772658552e-05 Training loss: 3.581062078475952
2025-12-09 12:07:00.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 1.3983051073632997e-05 Training loss: 3.784985065460205
2025-12-09 12:07:00.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 1.3610745123631535e-05 Training loss: 3.6087419986724854
2025-12-09 12:07:00.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 1.3242680314639993e-05 Training loss: 3.7666008472442627
2025-12-09 12:07:00.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 1.2878899544342327e-05 Training loss: 3.701892375946045
2025-12-09 12:07:00.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 1.2519445211120979e-05 Training loss: 3.724440574645996
2025-12-09 12:07:00.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 1.2164359209115234e-05 Training loss: 3.7106857299804688
2025-12-09 12:07:00.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 1.1813682923338653e-05 Training loss: 3.818887948989868
2025-12-09 12:07:00.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 1.1467457224855544e-05 Training loss: 3.6455531120300293
2025-12-09 12:07:00.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 1.1125722466017547e-05 Training loss: 3.3413949012756348
2025-12-09 12:07:00.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 1.0788518475760545e-05 Training loss: 3.5413219928741455
2025-12-09 12:07:00.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 1.0455884554962725e-05 Training loss: 3.826908588409424
2025-12-09 12:07:00.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 1.012785947186397e-05 Training loss: 3.778160810470581
2025-12-09 12:07:00.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 9.804481457547498e-06 Training loss: 3.5508689880371094
2025-12-09 12:07:00.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 9.485788201484126e-06 Training loss: 3.472651720046997
2025-12-09 12:07:00.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 9.171816847139448e-06 Training loss: 3.7172958850860596
2025-12-09 12:07:00.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 8.86260398764494e-06 Training loss: 3.7445878982543945
2025-12-09 12:07:00.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 8.558185661532941e-06 Training loss: 3.723233699798584
2025-12-09 12:07:00.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 8.25859734853645e-06 Training loss: 3.6651811599731445
2025-12-09 12:07:00.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 7.96387396545396e-06 Training loss: 3.835040807723999
2025-12-09 12:07:00.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 7.67404986207999e-06 Training loss: 3.6985628604888916
2025-12-09 12:07:00.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 7.389158817201542e-06 Training loss: 3.7781875133514404
2025-12-09 12:07:00.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 7.109234034661289e-06 Training loss: 3.700387477874756
2025-12-09 12:07:00.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 6.8343081394876715e-06 Training loss: 3.608898162841797
2025-12-09 12:07:00.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 6.564413174092443e-06 Training loss: 3.6532928943634033
2025-12-09 12:07:00.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 6.299580594536214e-06 Training loss: 3.519148111343384
2025-12-09 12:07:00.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 6.0398412668621895e-06 Training loss: 3.609532117843628
2025-12-09 12:07:00.819 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 5.785225463498828e-06 Training loss: 3.7017219066619873
2025-12-09 12:07:00.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 5.535762859731547e-06 Training loss: 3.503455877304077
2025-12-09 12:07:00.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 5.291482530244179e-06 Training loss: 3.591597318649292
2025-12-09 12:07:00.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 5.05241294573024e-06 Training loss: 3.5372865200042725
2025-12-09 12:07:00.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 4.818581969574742e-06 Training loss: 3.7487096786499023
2025-12-09 12:07:00.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 4.590016854606727e-06 Training loss: 3.4798102378845215
2025-12-09 12:07:00.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 4.366744239922998e-06 Training loss: 3.6034421920776367
2025-12-09 12:07:00.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 4.148790147783288e-06 Training loss: 3.650090456008911
2025-12-09 12:07:00.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 3.936179980577453e-06 Training loss: 3.7679970264434814
2025-12-09 12:07:00.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 3.728938517864794e-06 Training loss: 3.7263715267181396
2025-12-09 12:07:00.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 3.527089913486037e-06 Training loss: 3.6965670585632324
2025-12-09 12:07:00.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 3.3306576927482126e-06 Training loss: 3.5628654956817627
2025-12-09 12:07:00.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 3.1396647496828247e-06 Training loss: 3.606773614883423
2025-12-09 12:07:00.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 2.9541333443775243e-06 Training loss: 3.7330570220947266
2025-12-09 12:07:00.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 2.774085100381735e-06 Training loss: 3.786121368408203
2025-12-09 12:07:00.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 2.5995410021864787e-06 Training loss: 3.856532096862793
2025-12-09 12:07:00.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 2.430521392778573e-06 Training loss: 3.7683207988739014
2025-12-09 12:07:00.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 2.2670459712697377e-06 Training loss: 3.5283124446868896
2025-12-09 12:07:00.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 2.1091337906006482e-06 Training loss: 3.6132991313934326
2025-12-09 12:07:00.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 1.956803255320322e-06 Training loss: 3.53914737701416
2025-12-09 12:07:00.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 1.810072119441103e-06 Training loss: 3.818727493286133
2025-12-09 12:07:01.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 1.6689574843694433e-06 Training loss: 3.6142096519470215
2025-12-09 12:07:01.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 1.53347579691272e-06 Training loss: 3.715486764907837
2025-12-09 12:07:01.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 1.4036428473624019e-06 Training loss: 3.986616849899292
2025-12-09 12:07:01.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 1.2794737676536994e-06 Training loss: 3.6956632137298584
2025-12-09 12:07:01.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 1.1609830296019143e-06 Training loss: 3.6008927822113037
2025-12-09 12:07:01.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 1.0481844432158161e-06 Training loss: 3.5671794414520264
2025-12-09 12:07:01.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.410911550880475e-07 Training loss: 3.4820146560668945
2025-12-09 12:07:01.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 8.397156468629208e-07 Training loss: 3.711705207824707
2025-12-09 12:07:01.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 7.44069733781677e-07 Training loss: 3.4729866981506348
2025-12-09 12:07:01.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 6.54164563305465e-07 Training loss: 3.7292182445526123
2025-12-09 12:07:01.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 5.700106138160688e-07 Training loss: 3.628969430923462
2025-12-09 12:07:01.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 4.916176933946693e-07 Training loss: 3.5645384788513184
2025-12-09 12:07:01.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 4.189949386787462e-07 Training loss: 3.6276140213012695
2025-12-09 12:07:01.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 3.5215081379718074e-07 Training loss: 3.6357223987579346
2025-12-09 12:07:01.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 2.9109310938378877e-07 Training loss: 3.668879508972168
2025-12-09 12:07:01.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 2.3582894166930268e-07 Training loss: 3.580132484436035
2025-12-09 12:07:01.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 1.8636475165200174e-07 Training loss: 3.7303192615509033
2025-12-09 12:07:01.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 1.427063043470178e-07 Training loss: 3.610105276107788
2025-12-09 12:07:01.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 1.0485868811441757e-07 Training loss: 3.772099018096924
2025-12-09 12:07:01.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 7.282631406615447e-08 Training loss: 3.662510871887207
2025-12-09 12:07:01.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 4.661291555196345e-08 Training loss: 3.724213123321533
2025-12-09 12:07:01.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 2.6221547724253337e-08 Training loss: 3.5079431533813477
2025-12-09 12:07:01.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 1.1654587182013953e-08 Training loss: 3.7243452072143555
2025-12-09 12:07:01.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 2.9137316938265825e-09 Training loss: 3.624079465866089
2025-12-09 12:07:01.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0 Training loss: 3.345655918121338
