2025-12-09 12:06:40.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 0.0001 Training loss: 9.209999084472656
2025-12-09 12:06:40.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 0.0002 Training loss: 9.21146011352539
2025-12-09 12:06:40.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 0.0003 Training loss: 9.210366249084473
2025-12-09 12:06:40.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.0004 Training loss: 9.210699081420898
2025-12-09 12:06:40.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.0005 Training loss: 9.210087776184082
2025-12-09 12:06:40.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.0006 Training loss: 9.210454940795898
2025-12-09 12:06:40.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.0007000000000000001 Training loss: 9.21002197265625
2025-12-09 12:06:40.556 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.0008 Training loss: 9.209879875183105
2025-12-09 12:06:40.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.0009 Training loss: 9.210851669311523
2025-12-09 12:06:40.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.001 Training loss: 9.209966659545898
2025-12-09 12:06:40.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.0011 Training loss: 9.209686279296875
2025-12-09 12:06:40.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.0012 Training loss: 9.209589004516602
2025-12-09 12:06:40.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.0013000000000000002 Training loss: 9.209878921508789
2025-12-09 12:06:40.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.0014000000000000002 Training loss: 9.209556579589844
2025-12-09 12:06:40.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.0015 Training loss: 9.209092140197754
2025-12-09 12:06:40.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.0016 Training loss: 9.209318161010742
2025-12-09 12:06:40.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.0017000000000000001 Training loss: 9.209025382995605
2025-12-09 12:06:40.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.0018 Training loss: 9.208483695983887
2025-12-09 12:06:40.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.0019 Training loss: 9.2069673538208
2025-12-09 12:06:40.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.002 Training loss: 9.207907676696777
2025-12-09 12:06:40.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.0021 Training loss: 9.20862102508545
2025-12-09 12:06:40.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.0022 Training loss: 9.208059310913086
2025-12-09 12:06:40.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0023 Training loss: 9.206680297851562
2025-12-09 12:06:40.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0024 Training loss: 9.206539154052734
2025-12-09 12:06:40.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.0025 Training loss: 9.206056594848633
2025-12-09 12:06:40.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0026000000000000003 Training loss: 9.206703186035156
2025-12-09 12:06:40.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0027 Training loss: 9.206052780151367
2025-12-09 12:06:40.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0028000000000000004 Training loss: 9.205138206481934
2025-12-09 12:06:40.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.0029 Training loss: 9.204345703125
2025-12-09 12:06:40.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.003 Training loss: 9.203618049621582
2025-12-09 12:06:40.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.0031 Training loss: 9.204437255859375
2025-12-09 12:06:40.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.0032 Training loss: 9.203662872314453
2025-12-09 12:06:40.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.0033000000000000004 Training loss: 9.202448844909668
2025-12-09 12:06:40.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.0034000000000000002 Training loss: 9.201532363891602
2025-12-09 12:06:40.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.0034999999999999996 Training loss: 9.202292442321777
2025-12-09 12:06:40.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.0036 Training loss: 9.201266288757324
2025-12-09 12:06:41.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.0037 Training loss: 9.200623512268066
2025-12-09 12:06:41.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.0038 Training loss: 9.200783729553223
2025-12-09 12:06:41.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.0039000000000000003 Training loss: 9.19987678527832
2025-12-09 12:06:41.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.004 Training loss: 9.199650764465332
2025-12-09 12:06:41.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.0040999999999999995 Training loss: 9.198962211608887
2025-12-09 12:06:41.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.0042 Training loss: 9.19703483581543
2025-12-09 12:06:41.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.0043 Training loss: 9.198054313659668
2025-12-09 12:06:41.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.0044 Training loss: 9.197697639465332
2025-12-09 12:06:41.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.0045000000000000005 Training loss: 9.195648193359375
2025-12-09 12:06:41.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0046 Training loss: 9.194279670715332
2025-12-09 12:06:41.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.0047 Training loss: 9.194808006286621
2025-12-09 12:06:41.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0048 Training loss: 9.194293975830078
2025-12-09 12:06:41.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.0049 Training loss: 9.193161964416504
2025-12-09 12:06:41.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.005 Training loss: 9.192587852478027
2025-12-09 12:06:41.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0051 Training loss: 9.192758560180664
2025-12-09 12:06:41.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.005200000000000001 Training loss: 9.192192077636719
2025-12-09 12:06:41.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0053 Training loss: 9.191022872924805
2025-12-09 12:06:41.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0054 Training loss: 9.190803527832031
2025-12-09 12:06:41.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0055000000000000005 Training loss: 9.189075469970703
2025-12-09 12:06:41.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.005600000000000001 Training loss: 9.189713478088379
2025-12-09 12:06:41.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.005699999999999999 Training loss: 9.188621520996094
2025-12-09 12:06:41.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.0058 Training loss: 9.187103271484375
2025-12-09 12:06:41.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0059 Training loss: 9.185853004455566
2025-12-09 12:06:41.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.006 Training loss: 9.185774803161621
2025-12-09 12:06:41.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.0061 Training loss: 9.18369197845459
2025-12-09 12:06:41.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.0062 Training loss: 9.185553550720215
2025-12-09 12:06:41.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.0063 Training loss: 9.184773445129395
2025-12-09 12:06:41.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.0064 Training loss: 9.18313980102539
2025-12-09 12:06:41.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.006500000000000001 Training loss: 9.181711196899414
2025-12-09 12:06:41.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.006600000000000001 Training loss: 9.181602478027344
2025-12-09 12:06:41.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.0067 Training loss: 9.181554794311523
2025-12-09 12:06:41.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.0068000000000000005 Training loss: 9.17831039428711
2025-12-09 12:06:41.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.0069 Training loss: 9.178744316101074
2025-12-09 12:06:41.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.006999999999999999 Training loss: 9.177574157714844
2025-12-09 12:06:41.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.0070999999999999995 Training loss: 9.17864990234375
2025-12-09 12:06:41.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0072 Training loss: 9.175681114196777
2025-12-09 12:06:41.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.0073 Training loss: 9.177225112915039
2025-12-09 12:06:41.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.0074 Training loss: 9.175692558288574
2025-12-09 12:06:41.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0075 Training loss: 9.174171447753906
2025-12-09 12:06:41.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.0076 Training loss: 9.17521858215332
2025-12-09 12:06:41.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0077 Training loss: 9.171536445617676
2025-12-09 12:06:41.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0078000000000000005 Training loss: 9.170650482177734
2025-12-09 12:06:41.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.0079 Training loss: 9.169734954833984
2025-12-09 12:06:41.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.008 Training loss: 9.169398307800293
2025-12-09 12:06:41.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.008100000000000001 Training loss: 9.169102668762207
2025-12-09 12:06:41.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.008199999999999999 Training loss: 9.169157981872559
2025-12-09 12:06:41.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.0083 Training loss: 9.167255401611328
2025-12-09 12:06:41.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.0084 Training loss: 9.166399955749512
2025-12-09 12:06:41.734 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.0085 Training loss: 9.164761543273926
2025-12-09 12:06:41.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.0086 Training loss: 9.167752265930176
2025-12-09 12:06:41.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.0087 Training loss: 9.164509773254395
2025-12-09 12:06:41.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.0088 Training loss: 9.162942886352539
2025-12-09 12:06:41.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0089 Training loss: 9.162818908691406
2025-12-09 12:06:41.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.009000000000000001 Training loss: 9.165106773376465
2025-12-09 12:06:41.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0091 Training loss: 9.161785125732422
2025-12-09 12:06:41.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0092 Training loss: 9.163398742675781
2025-12-09 12:06:41.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.009300000000000001 Training loss: 9.160959243774414
2025-12-09 12:06:41.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.0094 Training loss: 9.161722183227539
2025-12-09 12:06:41.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.0095 Training loss: 9.157424926757812
2025-12-09 12:06:41.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0096 Training loss: 9.157280921936035
2025-12-09 12:06:41.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0097 Training loss: 9.154627799987793
2025-12-09 12:06:41.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.0098 Training loss: 9.157463073730469
2025-12-09 12:06:41.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.0099 Training loss: 9.154134750366211
2025-12-09 12:06:41.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.01 Training loss: 9.156082153320312
2025-12-09 12:06:41.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.009698463103929543 Training loss: 9.155733108520508
2025-12-09 12:06:41.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.00883022221559489 Training loss: 9.153365135192871
2025-12-09 12:06:42.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0075 Training loss: 9.152853965759277
2025-12-09 12:06:42.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.005868240888334653 Training loss: 9.154276847839355
2025-12-09 12:06:42.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0041317591116653484 Training loss: 9.153300285339355
2025-12-09 12:06:42.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0025000000000000014 Training loss: 9.152152061462402
2025-12-09 12:06:42.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0011697777844051104 Training loss: 9.152538299560547
2025-12-09 12:06:42.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.00030153689607045843 Training loss: 9.1519775390625
2025-12-09 12:06:42.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0 Training loss: 9.151529312133789
