2025-12-09 12:10:40.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 2.9999999999999997e-06 Training loss: 4.923524856567383
2025-12-09 12:10:40.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 5.999999999999999e-06 Training loss: 4.917691707611084
2025-12-09 12:10:40.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 8.999999999999999e-06 Training loss: 4.883355617523193
2025-12-09 12:10:41.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 1.1999999999999999e-05 Training loss: 4.857679843902588
2025-12-09 12:10:41.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 1.4999999999999999e-05 Training loss: 4.911452293395996
2025-12-09 12:10:41.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 1.7999999999999997e-05 Training loss: 4.790577411651611
2025-12-09 12:10:41.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 2.1e-05 Training loss: 4.81107234954834
2025-12-09 12:10:41.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 2.3999999999999997e-05 Training loss: 5.0420613288879395
2025-12-09 12:10:41.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 2.6999999999999996e-05 Training loss: 4.823736190795898
2025-12-09 12:10:41.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 2.9999999999999997e-05 Training loss: 4.7508745193481445
2025-12-09 12:10:41.064 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 3.2999999999999996e-05 Training loss: 4.774764060974121
2025-12-09 12:10:41.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 3.5999999999999994e-05 Training loss: 4.824504852294922
2025-12-09 12:10:41.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 3.9e-05 Training loss: 4.872519493103027
2025-12-09 12:10:41.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 4.2e-05 Training loss: 4.871403217315674
2025-12-09 12:10:41.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 4.4999999999999996e-05 Training loss: 4.855477333068848
2025-12-09 12:10:41.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 4.7999999999999994e-05 Training loss: 4.762186527252197
2025-12-09 12:10:41.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 5.1e-05 Training loss: 4.952995777130127
2025-12-09 12:10:41.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 5.399999999999999e-05 Training loss: 4.851293087005615
2025-12-09 12:10:41.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 5.6999999999999996e-05 Training loss: 4.763354778289795
2025-12-09 12:10:41.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 5.9999999999999995e-05 Training loss: 4.8883771896362305
2025-12-09 12:10:41.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 6.299999999999999e-05 Training loss: 4.834596633911133
2025-12-09 12:10:41.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 6.599999999999999e-05 Training loss: 4.870547771453857
2025-12-09 12:10:41.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 6.9e-05 Training loss: 4.844584941864014
2025-12-09 12:10:41.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 7.199999999999999e-05 Training loss: 4.758405685424805
2025-12-09 12:10:41.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 7.5e-05 Training loss: 4.775813579559326
2025-12-09 12:10:41.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 7.8e-05 Training loss: 4.818179130554199
2025-12-09 12:10:41.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 8.1e-05 Training loss: 4.897711277008057
2025-12-09 12:10:41.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 8.4e-05 Training loss: 4.882034778594971
2025-12-09 12:10:41.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 8.699999999999999e-05 Training loss: 4.85836124420166
2025-12-09 12:10:41.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 8.999999999999999e-05 Training loss: 4.828201770782471
2025-12-09 12:10:41.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 9.3e-05 Training loss: 4.7470784187316895
2025-12-09 12:10:41.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 9.599999999999999e-05 Training loss: 4.815918922424316
2025-12-09 12:10:41.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 9.9e-05 Training loss: 4.790370941162109
2025-12-09 12:10:41.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.000102 Training loss: 4.888246059417725
2025-12-09 12:10:41.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00010499999999999999 Training loss: 4.84777307510376
2025-12-09 12:10:41.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00010799999999999998 Training loss: 4.85235071182251
2025-12-09 12:10:41.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00011099999999999999 Training loss: 4.885766506195068
2025-12-09 12:10:41.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00011399999999999999 Training loss: 4.980050086975098
2025-12-09 12:10:41.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.000117 Training loss: 4.86566686630249
2025-12-09 12:10:41.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.00011999999999999999 Training loss: 4.730164051055908
2025-12-09 12:10:41.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00012299999999999998 Training loss: 4.853756904602051
2025-12-09 12:10:41.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00012599999999999997 Training loss: 4.852707386016846
2025-12-09 12:10:41.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.000129 Training loss: 4.8217267990112305
2025-12-09 12:10:41.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00013199999999999998 Training loss: 4.895575523376465
2025-12-09 12:10:41.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.000135 Training loss: 4.766790866851807
2025-12-09 12:10:41.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.000138 Training loss: 4.7584662437438965
2025-12-09 12:10:41.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00014099999999999998 Training loss: 4.738488674163818
2025-12-09 12:10:41.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00014399999999999998 Training loss: 4.805789947509766
2025-12-09 12:10:41.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.000147 Training loss: 4.748051643371582
2025-12-09 12:10:41.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.00015 Training loss: 4.765286922454834
2025-12-09 12:10:41.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00015299999999999998 Training loss: 4.817471027374268
2025-12-09 12:10:41.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.000156 Training loss: 4.886542797088623
2025-12-09 12:10:41.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.000159 Training loss: 4.85871696472168
2025-12-09 12:10:41.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.000162 Training loss: 4.670317649841309
2025-12-09 12:10:41.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.000165 Training loss: 4.754739761352539
2025-12-09 12:10:41.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.000168 Training loss: 4.794753551483154
2025-12-09 12:10:41.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00017099999999999998 Training loss: 4.906783580780029
2025-12-09 12:10:41.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00017399999999999997 Training loss: 4.767303943634033
2025-12-09 12:10:41.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00017699999999999997 Training loss: 4.711618900299072
2025-12-09 12:10:41.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.00017999999999999998 Training loss: 4.751558780670166
2025-12-09 12:10:41.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00018299999999999998 Training loss: 4.811636447906494
2025-12-09 12:10:41.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.000186 Training loss: 4.859556674957275
2025-12-09 12:10:41.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00018899999999999999 Training loss: 4.723453521728516
2025-12-09 12:10:41.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00019199999999999998 Training loss: 4.827639579772949
2025-12-09 12:10:41.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.000195 Training loss: 4.851753234863281
2025-12-09 12:10:41.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.000198 Training loss: 4.779086589813232
2025-12-09 12:10:41.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.000201 Training loss: 4.829927921295166
2025-12-09 12:10:41.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.000204 Training loss: 4.795703887939453
2025-12-09 12:10:41.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00020699999999999996 Training loss: 4.726868152618408
2025-12-09 12:10:41.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.00020999999999999998 Training loss: 4.7036237716674805
2025-12-09 12:10:41.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00021299999999999997 Training loss: 4.649196624755859
2025-12-09 12:10:41.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.00021599999999999996 Training loss: 4.625326156616211
2025-12-09 12:10:41.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00021899999999999998 Training loss: 4.670447826385498
2025-12-09 12:10:41.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00022199999999999998 Training loss: 4.804738521575928
2025-12-09 12:10:41.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.000225 Training loss: 4.772231101989746
2025-12-09 12:10:41.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00022799999999999999 Training loss: 4.610632419586182
2025-12-09 12:10:41.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.00023099999999999998 Training loss: 4.751290321350098
2025-12-09 12:10:41.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.000234 Training loss: 4.67846155166626
2025-12-09 12:10:41.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.000237 Training loss: 4.8711652755737305
2025-12-09 12:10:41.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.00023999999999999998 Training loss: 4.733456134796143
2025-12-09 12:10:41.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.000243 Training loss: 4.693757057189941
2025-12-09 12:10:41.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00024599999999999996 Training loss: 4.723306179046631
2025-12-09 12:10:41.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.000249 Training loss: 4.7204694747924805
2025-12-09 12:10:41.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00025199999999999995 Training loss: 4.695163249969482
2025-12-09 12:10:41.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00025499999999999996 Training loss: 4.82147741317749
2025-12-09 12:10:41.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.000258 Training loss: 4.670745849609375
2025-12-09 12:10:41.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.000261 Training loss: 4.7808451652526855
2025-12-09 12:10:41.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00026399999999999997 Training loss: 4.671902179718018
2025-12-09 12:10:41.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.000267 Training loss: 4.7642436027526855
2025-12-09 12:10:41.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.00027 Training loss: 4.626420021057129
2025-12-09 12:10:41.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00027299999999999997 Training loss: 4.681816101074219
2025-12-09 12:10:41.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.000276 Training loss: 4.702230453491211
2025-12-09 12:10:41.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.000279 Training loss: 4.631865501403809
2025-12-09 12:10:41.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00028199999999999997 Training loss: 4.755547523498535
2025-12-09 12:10:41.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.000285 Training loss: 4.656495094299316
2025-12-09 12:10:41.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00028799999999999995 Training loss: 4.749840259552002
2025-12-09 12:10:41.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.00029099999999999997 Training loss: 4.605946063995361
2025-12-09 12:10:41.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.000294 Training loss: 4.658005714416504
2025-12-09 12:10:41.831 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00029699999999999996 Training loss: 4.7712788581848145
2025-12-09 12:10:41.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0003 Training loss: 4.699216365814209
2025-12-09 12:10:41.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.00029999125880491846 Training loss: 4.65709924697876
2025-12-09 12:10:41.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.00029996503623845393 Training loss: 4.543164253234863
2025-12-09 12:10:41.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.00029992133535682725 Training loss: 4.676092147827148
2025-12-09 12:10:41.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.00029986016125334406 Training loss: 4.612221717834473
2025-12-09 12:10:41.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0002997815210578015 Training loss: 4.691955089569092
2025-12-09 12:10:41.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0002996854239356567 Training loss: 4.712009906768799
2025-12-09 12:10:41.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0002995718810869589 Training loss: 4.698428630828857
2025-12-09 12:10:41.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.00029944090574504395 Training loss: 4.656438827514648
2025-12-09 12:10:41.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0002992925131749921 Training loss: 4.595066070556641
2025-12-09 12:10:41.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.0002991267206718486 Training loss: 4.693675518035889
2025-12-09 12:10:41.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.00029894354755860845 Training loss: 4.60822868347168
2025-12-09 12:10:41.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.00029874301518396376 Training loss: 4.679912567138672
2025-12-09 12:10:41.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.000298525146919816 Training loss: 4.679566383361816
2025-12-09 12:10:41.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0002982899681585518 Training loss: 4.676482677459717
2025-12-09 12:10:41.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.00029803750631008356 Training loss: 4.647018909454346
2025-12-09 12:10:41.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.00029776779079865496 Training loss: 4.600032329559326
2025-12-09 12:10:41.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.00029748085305941123 Training loss: 4.511446952819824
2025-12-09 12:10:41.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.0002971767265347358 Training loss: 4.558138847351074
2025-12-09 12:10:42.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0002968554466703525 Training loss: 4.559233665466309
2025-12-09 12:10:42.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.0002965170509111942 Training loss: 4.747154235839844
2025-12-09 12:10:42.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.0002961615786970389 Training loss: 4.57178258895874
2025-12-09 12:10:42.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.00029578907145791274 Training loss: 4.743042469024658
2025-12-09 12:10:42.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.00029539957260926183 Training loss: 4.698686122894287
2025-12-09 12:10:42.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.0002949931275468917 Training loss: 4.597690105438232
2025-12-09 12:10:42.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0002945697836416767 Training loss: 4.625166416168213
2025-12-09 12:10:42.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.000294129590234039 Training loss: 4.707520961761475
2025-12-09 12:10:42.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.00029367259862819804 Training loss: 4.579916477203369
2025-12-09 12:10:42.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.00029319886208619073 Training loss: 4.645374298095703
2025-12-09 12:10:42.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.00029270843582166427 Training loss: 4.609116077423096
2025-12-09 12:10:42.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.00029220137699344055 Training loss: 4.698586940765381
2025-12-09 12:10:42.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.0002916777446988548 Training loss: 4.6325788497924805
2025-12-09 12:10:42.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.00029113759996686743 Training loss: 4.669450759887695
2025-12-09 12:10:42.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0002905810057509515 Training loss: 4.634336948394775
2025-12-09 12:10:42.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.00029000802692175537 Training loss: 4.66238260269165
2025-12-09 12:10:42.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.0002894187302595419 Training loss: 4.6053385734558105
2025-12-09 12:10:42.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0002888131844464056 Training loss: 4.650503158569336
2025-12-09 12:10:42.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0002881914600582676 Training loss: 4.568224906921387
2025-12-09 12:10:42.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.0002875536295566501 Training loss: 4.56351375579834
2025-12-09 12:10:42.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.000286899767280231 Training loss: 4.588467597961426
2025-12-09 12:10:42.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0002862299494361798 Training loss: 4.618247985839844
2025-12-09 12:10:42.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0002855442540912758 Training loss: 4.605144500732422
2025-12-09 12:10:42.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.00028484276116280926 Training loss: 4.669950485229492
2025-12-09 12:10:42.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0002841255524092674 Training loss: 4.644477367401123
2025-12-09 12:10:42.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.00028339271142080534 Training loss: 4.496387958526611
2025-12-09 12:10:42.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.00028264432360950353 Training loss: 4.571413993835449
2025-12-09 12:10:42.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.00028188047619941343 Training loss: 4.673977375030518
2025-12-09 12:10:42.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0002811012582163913 Training loss: 4.56592321395874
2025-12-09 12:10:42.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.00028030676047772265 Training loss: 4.540207386016846
2025-12-09 12:10:42.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.000279497075581537 Training loss: 4.625739097595215
2025-12-09 12:10:42.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0002786722978960161 Training loss: 4.549921989440918
2025-12-09 12:10:42.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0002778325235483954 Training loss: 4.581111907958984
2025-12-09 12:10:42.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.00027697785041376006 Training loss: 4.565978527069092
2025-12-09 12:10:42.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0002761083781036381 Training loss: 4.467986106872559
2025-12-09 12:10:42.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.00027522420795439065 Training loss: 4.567814350128174
2025-12-09 12:10:42.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.0002743254430154012 Training loss: 4.55072546005249
2025-12-09 12:10:42.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0002734121880370652 Training loss: 4.585017204284668
2025-12-09 12:10:42.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.0002724845494585816 Training loss: 4.527657508850098
2025-12-09 12:10:42.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0002715426353955476 Training loss: 4.517692565917969
2025-12-09 12:10:42.354 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.0002705865556273575 Training loss: 4.502403259277344
2025-12-09 12:10:42.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0002696164215844081 Training loss: 4.613414764404297
2025-12-09 12:10:42.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.00026863234633511183 Training loss: 4.544559001922607
2025-12-09 12:10:42.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.00026763444457271837 Training loss: 4.620053291320801
2025-12-09 12:10:42.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.0002666228326019474 Training loss: 4.521151542663574
2025-12-09 12:10:42.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.00026559762832543336 Training loss: 4.4811906814575195
2025-12-09 12:10:42.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.000264558951229984 Training loss: 4.556140422821045
2025-12-09 12:10:42.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.00026350692237265427 Training loss: 4.542926788330078
2025-12-09 12:10:42.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.0002624416643666371 Training loss: 4.50507926940918
2025-12-09 12:10:42.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.000261363301366973 Training loss: 4.481649875640869
2025-12-09 12:10:42.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.00026027195905608006 Training loss: 4.499714374542236
2025-12-09 12:10:42.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.0002591677646291054 Training loss: 4.508194923400879
2025-12-09 12:10:42.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.00025805084677910095 Training loss: 4.594491481781006
2025-12-09 12:10:42.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.0002569213356820244 Training loss: 4.588169097900391
2025-12-09 12:10:42.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0002557793629815669 Training loss: 4.567795276641846
2025-12-09 12:10:42.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.00025462506177381043 Training loss: 4.6202497482299805
2025-12-09 12:10:42.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.00025345856659171563 Training loss: 4.545119285583496
2025-12-09 12:10:42.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.00025228001338944175 Training loss: 4.515810966491699
2025-12-09 12:10:42.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0002510895395265016 Training loss: 4.463412284851074
2025-12-09 12:10:42.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.00024988728375175214 Training loss: 4.452515125274658
2025-12-09 12:10:42.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.00024867338618722357 Training loss: 4.579396724700928
2025-12-09 12:10:42.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.0002474479883117882 Training loss: 4.448605537414551
2025-12-09 12:10:42.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.00024621123294467096 Training loss: 4.436147212982178
2025-12-09 12:10:42.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.0002449632642288045 Training loss: 4.571305274963379
2025-12-09 12:10:42.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.00024370422761402867 Training loss: 4.533444881439209
2025-12-09 12:10:42.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.0002424342698401391 Training loss: 4.3738555908203125
2025-12-09 12:10:42.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.00024115353891978431 Training loss: 4.448312759399414
2025-12-09 12:10:42.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.00023986218412121537 Training loss: 4.508676528930664
2025-12-09 12:10:42.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.00023856035595088839 Training loss: 4.529903411865234
2025-12-09 12:10:42.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.00023724820613592337 Training loss: 4.503085613250732
2025-12-09 12:10:42.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.00023592588760642044 Training loss: 4.510905742645264
2025-12-09 12:10:42.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.00023459355447763596 Training loss: 4.561859130859375
2025-12-09 12:10:42.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.00023325136203202049 Training loss: 4.501755714416504
2025-12-09 12:10:42.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.00023189946670112069 Training loss: 4.531229019165039
2025-12-09 12:10:42.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.00023053802604734757 Training loss: 4.494935035705566
2025-12-09 12:10:42.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.00022916719874561226 Training loss: 4.470911979675293
2025-12-09 12:10:42.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.0002277871445648332 Training loss: 4.505495071411133
2025-12-09 12:10:42.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.00022639802434931444 Training loss: 4.528920650482178
2025-12-09 12:10:42.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.000225 Training loss: 4.508203506469727
2025-12-09 12:10:42.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.00022359323445560406 Training loss: 4.472737789154053
2025-12-09 12:10:42.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.00022217789167362073 Training loss: 4.481135845184326
2025-12-09 12:10:42.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.00022075413661121492 Training loss: 4.441999912261963
2025-12-09 12:10:42.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.00021932213520599653 Training loss: 4.468811511993408
2025-12-09 12:10:42.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.00021788205435668083 Training loss: 4.431142807006836
2025-12-09 12:10:42.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.00021643406190363624 Training loss: 4.442102909088135
2025-12-09 12:10:42.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.00021497832660932295 Training loss: 4.512395858764648
2025-12-09 12:10:42.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.00021351501813862356 Training loss: 4.4003520011901855
2025-12-09 12:10:42.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0002120443070390687 Training loss: 4.525990009307861
2025-12-09 12:10:42.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.00021056636472096025 Training loss: 4.477585315704346
2025-12-09 12:10:42.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.00020908136343739307 Training loss: 4.386143207550049
2025-12-09 12:10:42.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.00020758947626417943 Training loss: 4.458678722381592
2025-12-09 12:10:42.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0002060908770796769 Training loss: 4.482021808624268
2025-12-09 12:10:42.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.00020458574054452313 Training loss: 4.44083309173584
2025-12-09 12:10:42.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.00020307424208127912 Training loss: 4.411304950714111
2025-12-09 12:10:42.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.00020155655785398393 Training loss: 4.491649627685547
2025-12-09 12:10:42.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.0002000328647476231 Training loss: 4.469689846038818
2025-12-09 12:10:42.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.00019850334034751226 Training loss: 4.426296234130859
2025-12-09 12:10:42.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.00019696816291860038 Training loss: 4.507365703582764
2025-12-09 12:10:42.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0001954275113846926 Training loss: 4.44722843170166
2025-12-09 12:10:42.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.00019388156530759712 Training loss: 4.488461494445801
2025-12-09 12:10:42.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.00019233050486619713 Training loss: 4.451944828033447
2025-12-09 12:10:42.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0001907745108354514 Training loss: 4.515422344207764
2025-12-09 12:10:42.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.00018921376456532482 Training loss: 4.3406476974487305
2025-12-09 12:10:42.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.00018764844795965229 Training loss: 4.486544132232666
2025-12-09 12:10:42.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.00018607874345493805 Training loss: 4.43675422668457
2025-12-09 12:10:42.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.00018450483399909263 Training loss: 4.412952899932861
2025-12-09 12:10:42.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.00018292690303011076 Training loss: 4.4161376953125
2025-12-09 12:10:42.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.00018134513445469127 Training loss: 4.516952991485596
2025-12-09 12:10:42.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.00017975971262680347 Training loss: 4.378630638122559
2025-12-09 12:10:42.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.00017817082232620052 Training loss: 4.397191524505615
2025-12-09 12:10:42.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.00017657864873688343 Training loss: 4.473413467407227
2025-12-09 12:10:43.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.00017498337742551817 Training loss: 4.391659736633301
2025-12-09 12:10:43.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.00017338519431980796 Training loss: 4.412095069885254
2025-12-09 12:10:43.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.00017178428568682353 Training loss: 4.5068535804748535
2025-12-09 12:10:43.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0001701808381112938 Training loss: 4.461086273193359
2025-12-09 12:10:43.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.00016857503847385953 Training loss: 4.3985114097595215
2025-12-09 12:10:43.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.00016696707392929266 Training loss: 4.481683731079102
2025-12-09 12:10:43.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0001653571318846834 Training loss: 4.4583330154418945
2025-12-09 12:10:43.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.00016374539997759821 Training loss: 4.507311820983887
2025-12-09 12:10:43.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.00016213206605421063 Training loss: 4.361344814300537
2025-12-09 12:10:43.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.0001605173181474081 Training loss: 4.430853843688965
2025-12-09 12:10:43.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.00015890134445487676 Training loss: 4.4405198097229
2025-12-09 12:10:43.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.00015728433331716724 Training loss: 4.396716117858887
2025-12-09 12:10:43.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.0001556664731957435 Training loss: 4.4192585945129395
2025-12-09 12:10:43.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.00015404795265101806 Training loss: 4.4077277183532715
2025-12-09 12:10:43.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.00015242896032037522 Training loss: 4.424525737762451
2025-12-09 12:10:43.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.00015080968489618565 Training loss: 4.437948226928711
2025-12-09 12:10:43.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.00014919031510381435 Training loss: 4.3537516593933105
2025-12-09 12:10:43.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.00014757103967962475 Training loss: 4.395471096038818
2025-12-09 12:10:43.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.00014595204734898197 Training loss: 4.4128947257995605
2025-12-09 12:10:43.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0001443335268042565 Training loss: 4.4473795890808105
2025-12-09 12:10:43.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.0001427156666828328 Training loss: 4.428282260894775
2025-12-09 12:10:43.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.00014109865554512319 Training loss: 4.504930019378662
2025-12-09 12:10:43.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.00013948268185259188 Training loss: 4.410021781921387
2025-12-09 12:10:43.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.00013786793394578937 Training loss: 4.525735855102539
2025-12-09 12:10:43.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.0001362546000224018 Training loss: 4.423225402832031
2025-12-09 12:10:43.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.00013464286811531661 Training loss: 4.382453441619873
2025-12-09 12:10:43.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.00013303292607070737 Training loss: 4.326246738433838
2025-12-09 12:10:43.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.0001314249615261405 Training loss: 4.265264511108398
2025-12-09 12:10:43.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0001298191618887062 Training loss: 4.4400482177734375
2025-12-09 12:10:43.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.00012821571431317647 Training loss: 4.339352130889893
2025-12-09 12:10:43.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.00012661480568019201 Training loss: 4.296823978424072
2025-12-09 12:10:43.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0001250166225744818 Training loss: 4.436720848083496
2025-12-09 12:10:43.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0001234213512631166 Training loss: 4.37613582611084
2025-12-09 12:10:43.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00012182917767379948 Training loss: 4.504053115844727
2025-12-09 12:10:43.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.00012024028737319652 Training loss: 4.484712600708008
2025-12-09 12:10:43.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.00011865486554530873 Training loss: 4.370748996734619
2025-12-09 12:10:43.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.0001170730969698893 Training loss: 4.289870738983154
2025-12-09 12:10:43.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.00011549516600090737 Training loss: 4.439903259277344
2025-12-09 12:10:43.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.00011392125654506198 Training loss: 4.37606143951416
2025-12-09 12:10:43.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.00011235155204034767 Training loss: 4.392282962799072
2025-12-09 12:10:43.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.00011078623543467518 Training loss: 4.3624396324157715
2025-12-09 12:10:43.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.00010922548916454855 Training loss: 4.349993705749512
2025-12-09 12:10:43.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.00010766949513380284 Training loss: 4.3792924880981445
2025-12-09 12:10:43.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.00010611843469240288 Training loss: 4.284769535064697
2025-12-09 12:10:43.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.00010457248861530741 Training loss: 4.402535915374756
2025-12-09 12:10:43.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.00010303183708139964 Training loss: 4.425441265106201
2025-12-09 12:10:43.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.00010149665965248775 Training loss: 4.5248026847839355
2025-12-09 12:10:43.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 9.996713525237694e-05 Training loss: 4.31233024597168
2025-12-09 12:10:43.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 9.8443442146016e-05 Training loss: 4.292062759399414
2025-12-09 12:10:43.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 9.692575791872089e-05 Training loss: 4.376317024230957
2025-12-09 12:10:43.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 9.541425945547687e-05 Training loss: 4.434989929199219
2025-12-09 12:10:43.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 9.390912292032309e-05 Training loss: 4.319254398345947
2025-12-09 12:10:43.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 9.241052373582057e-05 Training loss: 4.362839221954346
2025-12-09 12:10:43.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 9.091863656260695e-05 Training loss: 4.306515216827393
2025-12-09 12:10:43.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 8.943363527903976e-05 Training loss: 4.4382643699646
2025-12-09 12:10:43.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 8.795569296093132e-05 Training loss: 4.368865966796875
2025-12-09 12:10:43.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 8.648498186137653e-05 Training loss: 4.490551471710205
2025-12-09 12:10:43.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 8.502167339067705e-05 Training loss: 4.319126605987549
2025-12-09 12:10:43.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 8.356593809636371e-05 Training loss: 4.418765544891357
2025-12-09 12:10:43.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 8.211794564331917e-05 Training loss: 4.236790180206299
2025-12-09 12:10:43.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 8.067786479400346e-05 Training loss: 4.3231658935546875
2025-12-09 12:10:43.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 7.924586338878511e-05 Training loss: 4.29986047744751
2025-12-09 12:10:43.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 7.782210832637923e-05 Training loss: 4.345158100128174
2025-12-09 12:10:43.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 7.640676554439594e-05 Training loss: 4.4509358406066895
2025-12-09 12:10:43.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 7.500000000000002e-05 Training loss: 4.381167411804199
2025-12-09 12:10:43.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 7.36019756506856e-05 Training loss: 4.4018120765686035
2025-12-09 12:10:43.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 7.22128554351668e-05 Training loss: 4.3513641357421875
2025-12-09 12:10:43.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 7.083280125438766e-05 Training loss: 4.339053153991699
2025-12-09 12:10:43.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 6.946197395265242e-05 Training loss: 4.286625862121582
2025-12-09 12:10:43.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 6.810053329887928e-05 Training loss: 4.3333916664123535
2025-12-09 12:10:43.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 6.674863796797953e-05 Training loss: 4.397094249725342
2025-12-09 12:10:43.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 6.540644552236401e-05 Training loss: 4.3857221603393555
2025-12-09 12:10:43.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 6.407411239357953e-05 Training loss: 4.352280616760254
2025-12-09 12:10:43.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 6.275179386407663e-05 Training loss: 4.3557844161987305
2025-12-09 12:10:43.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 6.143964404911164e-05 Training loss: 4.403833389282227
2025-12-09 12:10:43.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 6.013781587878463e-05 Training loss: 4.431765079498291
2025-12-09 12:10:43.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 5.8846461080215626e-05 Training loss: 4.383589744567871
2025-12-09 12:10:43.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 5.756573015986089e-05 Training loss: 4.48802375793457
2025-12-09 12:10:43.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 5.629577238597132e-05 Training loss: 4.369038105010986
2025-12-09 12:10:43.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 5.503673577119552e-05 Training loss: 4.340268135070801
2025-12-09 12:10:43.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 5.378876705532904e-05 Training loss: 4.591423511505127
2025-12-09 12:10:43.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 5.2552011688211835e-05 Training loss: 4.243477821350098
2025-12-09 12:10:43.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 5.1326613812776434e-05 Training loss: 4.407210826873779
2025-12-09 12:10:43.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 5.011271624824786e-05 Training loss: 4.2985382080078125
2025-12-09 12:10:43.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 4.891046047349837e-05 Training loss: 4.285995960235596
2025-12-09 12:10:43.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 4.7719986610558234e-05 Training loss: 4.451419353485107
2025-12-09 12:10:43.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 4.654143340828435e-05 Training loss: 4.285309791564941
2025-12-09 12:10:43.786 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 4.537493822618958e-05 Training loss: 4.35732889175415
2025-12-09 12:10:43.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 4.422063701843316e-05 Training loss: 4.292530536651611
2025-12-09 12:10:43.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 4.3078664317975646e-05 Training loss: 4.44524621963501
2025-12-09 12:10:43.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 4.194915322089898e-05 Training loss: 4.33014440536499
2025-12-09 12:10:43.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 4.08322353708946e-05 Training loss: 4.253078937530518
2025-12-09 12:10:43.831 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 3.972804094391998e-05 Training loss: 4.34231424331665
2025-12-09 12:10:43.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 3.863669863302697e-05 Training loss: 4.349165916442871
2025-12-09 12:10:43.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 3.755833563336293e-05 Training loss: 4.423608303070068
2025-12-09 12:10:43.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 3.64930776273457e-05 Training loss: 4.290409088134766
2025-12-09 12:10:43.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 3.5441048770015954e-05 Training loss: 4.424646854400635
2025-12-09 12:10:43.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 3.4402371674566626e-05 Training loss: 4.365022659301758
2025-12-09 12:10:43.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 3.3377167398052636e-05 Training loss: 4.268333911895752
2025-12-09 12:10:43.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 3.2365555427281634e-05 Training loss: 4.38218879699707
2025-12-09 12:10:43.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 3.136765366488817e-05 Training loss: 4.39894962310791
2025-12-09 12:10:43.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 3.038357841559191e-05 Training loss: 4.281968116760254
2025-12-09 12:10:43.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 2.941344437264249e-05 Training loss: 4.356578350067139
2025-12-09 12:10:43.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 2.8457364604452372e-05 Training loss: 4.382942199707031
2025-12-09 12:10:43.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 2.7515450541418338e-05 Training loss: 4.271102428436279
2025-12-09 12:10:43.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 2.658781196293482e-05 Training loss: 4.335931777954102
2025-12-09 12:10:43.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 2.5674556984598822e-05 Training loss: 4.503103256225586
2025-12-09 12:10:43.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 2.477579204560935e-05 Training loss: 4.476944446563721
2025-12-09 12:10:43.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 2.389162189636188e-05 Training loss: 4.375973701477051
2025-12-09 12:10:43.982 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 2.3022149586239968e-05 Training loss: 4.389944553375244
2025-12-09 12:10:43.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 2.216747645160462e-05 Training loss: 4.3619890213012695
2025-12-09 12:10:44.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 2.1327702103983863e-05 Training loss: 4.312648296356201
2025-12-09 12:10:44.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 2.0502924418463013e-05 Training loss: 4.409222602844238
2025-12-09 12:10:44.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 1.9693239522277327e-05 Training loss: 4.274643898010254
2025-12-09 12:10:44.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 1.889874178360864e-05 Training loss: 4.308535575866699
2025-12-09 12:10:44.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 1.8119523800586568e-05 Training loss: 4.27377986907959
2025-12-09 12:10:44.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 1.735567639049648e-05 Training loss: 4.496062278747559
2025-12-09 12:10:44.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 1.6607288579194638e-05 Training loss: 4.381468772888184
2025-12-09 12:10:44.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 1.5874447590732538e-05 Training loss: 4.358310699462891
2025-12-09 12:10:44.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 1.5157238837190716e-05 Training loss: 4.428773403167725
2025-12-09 12:10:44.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 1.4455745908724226e-05 Training loss: 4.382340908050537
2025-12-09 12:10:44.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 1.3770050563820179e-05 Training loss: 4.461502552032471
2025-12-09 12:10:44.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 1.3100232719768994e-05 Training loss: 4.375328063964844
2025-12-09 12:10:44.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 1.2446370443349863e-05 Training loss: 4.435407638549805
2025-12-09 12:10:44.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 1.180853994173236e-05 Training loss: 4.3436713218688965
2025-12-09 12:10:44.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 1.118681555359438e-05 Training loss: 4.387261390686035
2025-12-09 12:10:44.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 1.058126974045811e-05 Training loss: 4.276790142059326
2025-12-09 12:10:44.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 9.991973078244636e-06 Training loss: 4.340399265289307
2025-12-09 12:10:44.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 9.418994249048472e-06 Training loss: 4.474699974060059
2025-12-09 12:10:44.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 8.862400033132571e-06 Training loss: 4.345830917358398
2025-12-09 12:10:44.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 8.322255301145204e-06 Training loss: 4.362090110778809
2025-12-09 12:10:44.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 7.798623006559435e-06 Training loss: 4.269545078277588
2025-12-09 12:10:44.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 7.291564178335718e-06 Training loss: 4.4197540283203125
2025-12-09 12:10:44.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 6.801137913809213e-06 Training loss: 4.41564416885376
2025-12-09 12:10:44.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 6.3274013718019434e-06 Training loss: 4.319411754608154
2025-12-09 12:10:44.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 5.870409765960965e-06 Training loss: 4.409239292144775
2025-12-09 12:10:44.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 5.430216358323309e-06 Training loss: 4.253771781921387
2025-12-09 12:10:44.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 5.006872453108329e-06 Training loss: 4.309874057769775
2025-12-09 12:10:44.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 4.600427390738159e-06 Training loss: 4.3620829582214355
2025-12-09 12:10:44.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 4.210928542087206e-06 Training loss: 4.460825443267822
2025-12-09 12:10:44.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 3.838421302961098e-06 Training loss: 4.398655891418457
2025-12-09 12:10:44.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 3.482949088805742e-06 Training loss: 4.256054401397705
2025-12-09 12:10:44.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 3.1445533296474478e-06 Training loss: 4.2476725578308105
2025-12-09 12:10:44.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 2.823273465264142e-06 Training loss: 4.445261001586914
2025-12-09 12:10:44.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 2.519146940588762e-06 Training loss: 4.373728275299072
2025-12-09 12:10:44.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 2.232209201345031e-06 Training loss: 4.261410236358643
2025-12-09 12:10:44.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 1.9624936899163945e-06 Training loss: 4.422285079956055
2025-12-09 12:10:44.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 1.7100318414482061e-06 Training loss: 4.418106555938721
2025-12-09 12:10:44.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 1.4748530801840074e-06 Training loss: 4.244777202606201
2025-12-09 12:10:44.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 1.2569848160362384e-06 Training loss: 4.402139186859131
2025-12-09 12:10:44.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 1.056452441391542e-06 Training loss: 4.525832653045654
2025-12-09 12:10:44.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 8.732793281513661e-07 Training loss: 4.3658857345581055
2025-12-09 12:10:44.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 7.07486825007908e-07 Training loss: 4.384942054748535
2025-12-09 12:10:44.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 5.590942549560051e-07 Training loss: 4.42264461517334
2025-12-09 12:10:44.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 4.281189130410534e-07 Training loss: 4.332993030548096
2025-12-09 12:10:44.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 3.1457606434325266e-07 Training loss: 4.341168403625488
2025-12-09 12:10:44.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 2.184789421984634e-07 Training loss: 4.306196689605713
2025-12-09 12:10:44.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 1.3983874665589035e-07 Training loss: 4.295928001403809
2025-12-09 12:10:44.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 7.866464317276e-08 Training loss: 4.375732898712158
2025-12-09 12:10:44.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 3.4963761546041855e-08 Training loss: 4.468233585357666
2025-12-09 12:10:44.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 8.741195081479747e-09 Training loss: 4.486572265625
2025-12-09 12:10:44.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0 Training loss: 4.39247989654541
