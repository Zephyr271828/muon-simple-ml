2025-12-09 12:27:27.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.14067554473877
2025-12-09 12:27:27.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.140398025512695
2025-12-09 12:27:28.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.179524421691895
2025-12-09 12:27:28.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 12.186334609985352
2025-12-09 12:27:29.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 12.164158821105957
2025-12-09 12:27:29.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 12.16448974609375
2025-12-09 12:27:30.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 12.129446983337402
2025-12-09 12:27:30.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 12.108721733093262
2025-12-09 12:27:31.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 12.036223411560059
2025-12-09 12:27:31.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 11.99364185333252
2025-12-09 12:27:32.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 11.964790344238281
2025-12-09 12:27:32.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 11.938892364501953
2025-12-09 12:27:33.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 11.889070510864258
2025-12-09 12:27:33.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 11.96691608428955
2025-12-09 12:27:34.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 11.839859008789062
2025-12-09 12:27:34.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 11.725015640258789
2025-12-09 12:27:35.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 11.580595016479492
2025-12-09 12:27:35.748 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 11.650520324707031
2025-12-09 12:27:36.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 11.22351360321045
2025-12-09 12:27:36.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 11.375282287597656
2025-12-09 12:27:37.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 11.092700958251953
2025-12-09 12:27:37.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 10.894475936889648
2025-12-09 12:27:38.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 10.88779354095459
2025-12-09 12:27:38.739 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 10.611621856689453
2025-12-09 12:27:39.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 9.87359619140625
2025-12-09 12:27:39.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 9.784221649169922
2025-12-09 12:27:40.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 9.478909492492676
2025-12-09 12:27:40.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 9.556376457214355
2025-12-09 12:27:41.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 8.861369132995605
2025-12-09 12:27:41.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 8.728338241577148
2025-12-09 12:27:42.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 8.938600540161133
2025-12-09 12:27:42.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 9.0049409866333
2025-12-09 12:27:43.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 8.90845012664795
2025-12-09 12:27:43.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 8.475627899169922
2025-12-09 12:27:44.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 8.335697174072266
2025-12-09 12:27:44.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 8.26091194152832
2025-12-09 12:27:45.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 8.734188079833984
2025-12-09 12:27:45.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 8.239296913146973
2025-12-09 12:27:46.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 8.413012504577637
2025-12-09 12:27:46.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 8.197525024414062
2025-12-09 12:27:47.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 8.31199836730957
2025-12-09 12:27:47.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 8.672637939453125
2025-12-09 12:27:48.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 8.744454383850098
2025-12-09 12:27:48.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 8.268231391906738
2025-12-09 12:27:49.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 9.258037567138672
2025-12-09 12:27:49.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 8.422391891479492
2025-12-09 12:27:50.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 8.08371639251709
2025-12-09 12:27:50.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 8.391776084899902
2025-12-09 12:27:51.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 7.667593955993652
2025-12-09 12:27:51.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 7.876835346221924
2025-12-09 12:27:52.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 8.558792114257812
2025-12-09 12:27:52.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 7.716012954711914
2025-12-09 12:27:53.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 8.347959518432617
2025-12-09 12:27:53.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 8.283788681030273
2025-12-09 12:27:54.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 7.913489818572998
2025-12-09 12:27:54.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 7.991145133972168
2025-12-09 12:27:55.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 7.96306037902832
2025-12-09 12:27:55.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 8.168055534362793
2025-12-09 12:27:56.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 7.991270065307617
2025-12-09 12:27:56.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 8.036922454833984
2025-12-09 12:27:57.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 8.723335266113281
2025-12-09 12:27:57.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 8.037513732910156
2025-12-09 12:27:58.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 7.8837504386901855
2025-12-09 12:27:58.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 8.269265174865723
2025-12-09 12:27:59.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 7.938786029815674
2025-12-09 12:27:59.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 7.953577995300293
2025-12-09 12:28:00.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 8.003498077392578
2025-12-09 12:28:00.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 7.708179473876953
2025-12-09 12:28:01.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 8.026862144470215
2025-12-09 12:28:01.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 7.7747015953063965
2025-12-09 12:28:02.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 7.923528671264648
2025-12-09 12:28:02.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 7.9734392166137695
2025-12-09 12:28:03.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 7.937849521636963
2025-12-09 12:28:03.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 7.195821762084961
2025-12-09 12:28:04.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 8.39987564086914
2025-12-09 12:28:04.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 7.9482340812683105
2025-12-09 12:28:05.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 7.250980377197266
2025-12-09 12:28:05.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 7.631125450134277
2025-12-09 12:28:06.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 7.711906433105469
2025-12-09 12:28:06.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 7.716377258300781
2025-12-09 12:28:07.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 7.645511627197266
2025-12-09 12:28:07.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 7.552575588226318
2025-12-09 12:28:08.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 7.827210426330566
2025-12-09 12:28:08.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 7.556694507598877
2025-12-09 12:28:09.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 8.242199897766113
2025-12-09 12:28:09.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 7.036378383636475
2025-12-09 12:28:10.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 7.590716361999512
2025-12-09 12:28:10.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 7.666630268096924
2025-12-09 12:28:11.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 7.629794597625732
2025-12-09 12:28:11.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 8.830140113830566
2025-12-09 12:28:12.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 7.6169281005859375
2025-12-09 12:28:12.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 7.754877090454102
2025-12-09 12:28:13.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 7.624566078186035
2025-12-09 12:28:13.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 7.62432336807251
2025-12-09 12:28:14.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 7.7114458084106445
2025-12-09 12:28:14.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 7.64631462097168
2025-12-09 12:28:15.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 7.917754650115967
2025-12-09 12:28:15.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 7.559521675109863
2025-12-09 12:28:16.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 8.065061569213867
2025-12-09 12:28:16.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 7.517282485961914
2025-12-09 12:28:17.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0009999999029798809 Training loss: 7.556232452392578
2025-12-09 12:28:17.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.000999999611919561 Training loss: 7.627020835876465
2025-12-09 12:28:18.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0009999991268191536 Training loss: 7.47043514251709
2025-12-09 12:28:18.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0009999984476788465 Training loss: 7.548088073730469
2025-12-09 12:28:19.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0009999975744989036 Training loss: 7.390030860900879
2025-12-09 12:28:19.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0009999965072796635 Training loss: 7.478005886077881
2025-12-09 12:28:20.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0009999952460215409 Training loss: 7.597801685333252
2025-12-09 12:28:20.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0009999937907250245 Training loss: 7.254940986633301
2025-12-09 12:28:21.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0009999921413906799 Training loss: 7.825357913970947
2025-12-09 12:28:21.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.0009999902980191463 Training loss: 7.732493877410889
2025-12-09 12:28:22.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.00099998826061114 Training loss: 7.617632865905762
2025-12-09 12:28:22.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0009999860291674508 Training loss: 7.125296592712402
2025-12-09 12:28:23.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0009999836036889453 Training loss: 7.4407734870910645
2025-12-09 12:28:23.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0009999809841765644 Training loss: 7.3246331214904785
2025-12-09 12:28:24.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.000999978170631325 Training loss: 7.489873886108398
2025-12-09 12:28:24.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0009999751630543187 Training loss: 7.715115070343018
2025-12-09 12:28:25.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.000999971961446713 Training loss: 7.6754045486450195
2025-12-09 12:28:25.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.0009999685658097501 Training loss: 7.446727752685547
2025-12-09 12:28:26.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0009999649761447478 Training loss: 7.7982563972473145
2025-12-09 12:28:26.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.0009999611924530994 Training loss: 7.32445764541626
2025-12-09 12:28:27.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.000999957214736273 Training loss: 7.668529510498047
2025-12-09 12:28:27.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.0009999530429958125 Training loss: 7.672604560852051
2025-12-09 12:28:28.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.0009999486772333365 Training loss: 7.06951379776001
2025-12-09 12:28:28.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.00099994411745054 Training loss: 7.445232391357422
2025-12-09 12:28:29.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0009999393636491917 Training loss: 7.208754062652588
2025-12-09 12:28:29.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.000999934415831137 Training loss: 7.640268325805664
2025-12-09 12:28:30.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.000999929273998296 Training loss: 7.474569320678711
2025-12-09 12:28:30.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.0009999239381526638 Training loss: 7.736284255981445
2025-12-09 12:28:31.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0009999184082963117 Training loss: 7.777828216552734
2025-12-09 12:28:31.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.0009999126844313852 Training loss: 8.011225700378418
2025-12-09 12:28:32.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.000999906766560106 Training loss: 7.2317728996276855
2025-12-09 12:28:32.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.0009999006546847706 Training loss: 7.477654933929443
2025-12-09 12:28:33.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0009998943488077508 Training loss: 7.822485446929932
2025-12-09 12:28:33.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.0009998878489314938 Training loss: 7.409250736236572
2025-12-09 12:28:34.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.000999881155058522 Training loss: 7.449699401855469
2025-12-09 12:28:34.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0009998742671914335 Training loss: 7.671299934387207
2025-12-09 12:28:35.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.000999867185332901 Training loss: 7.381735324859619
2025-12-09 12:28:35.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.000999859909485673 Training loss: 7.457037448883057
2025-12-09 12:28:36.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.000999852439652573 Training loss: 7.881954669952393
2025-12-09 12:28:36.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0009998447758365 Training loss: 7.649499416351318
2025-12-09 12:28:37.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0009998369180404282 Training loss: 7.307946681976318
2025-12-09 12:28:37.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.000999828866267407 Training loss: 8.810543060302734
2025-12-09 12:28:38.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0009998206205205612 Training loss: 7.557161331176758
2025-12-09 12:28:38.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.0009998121808030905 Training loss: 7.596920490264893
2025-12-09 12:28:39.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0009998035471182707 Training loss: 7.636497974395752
2025-12-09 12:28:39.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.000999794719469452 Training loss: 7.388187885284424
2025-12-09 12:28:40.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0009997856978600603 Training loss: 7.472849369049072
2025-12-09 12:28:40.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0009997764822935967 Training loss: 7.220998287200928
2025-12-09 12:28:41.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.000999767072773638 Training loss: 7.582981586456299
2025-12-09 12:28:41.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0009997574693038351 Training loss: 7.398190975189209
2025-12-09 12:28:42.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0009997476718879154 Training loss: 7.187769889831543
2025-12-09 12:28:42.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.000999737680529681 Training loss: 6.903786659240723
2025-12-09 12:28:43.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0009997274952330093 Training loss: 7.190800189971924
2025-12-09 12:28:43.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.000999717116001853 Training loss: 7.221450328826904
2025-12-09 12:28:44.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.0009997065428402404 Training loss: 7.50406551361084
2025-12-09 12:28:44.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0009996957757522741 Training loss: 7.9144768714904785
2025-12-09 12:28:45.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.0009996848147421334 Training loss: 7.160081386566162
2025-12-09 12:28:45.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0009996736598140714 Training loss: 7.258602619171143
2025-12-09 12:28:46.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.0009996623109724174 Training loss: 7.341098785400391
2025-12-09 12:28:46.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0009996507682215755 Training loss: 7.218838214874268
2025-12-09 12:28:47.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.0009996390315660253 Training loss: 8.070505142211914
2025-12-09 12:28:47.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.0009996271010103215 Training loss: 7.538268566131592
2025-12-09 12:28:48.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.0009996149765590945 Training loss: 6.951854705810547
2025-12-09 12:28:48.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.000999602658217049 Training loss: 7.139333724975586
2025-12-09 12:28:49.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0009995901459889658 Training loss: 7.173926830291748
2025-12-09 12:28:49.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.0009995774398797008 Training loss: 7.308816432952881
2025-12-09 12:28:50.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.0009995645398941846 Training loss: 7.088650226593018
2025-12-09 12:28:50.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0009995514460374238 Training loss: 6.956919193267822
2025-12-09 12:28:51.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.0009995381583144996 Training loss: 7.161694526672363
2025-12-09 12:28:51.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.0009995246767305688 Training loss: 7.443966388702393
2025-12-09 12:28:52.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0009995110012908633 Training loss: 7.373257637023926
2025-12-09 12:28:52.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.0009994971320006906 Training loss: 7.4545979499816895
2025-12-09 12:28:53.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0009994830688654327 Training loss: 7.4229936599731445
2025-12-09 12:28:53.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.000999468811890547 Training loss: 7.741217136383057
2025-12-09 12:28:54.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.000999454361081567 Training loss: 7.132897853851318
2025-12-09 12:28:54.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.0009994397164441006 Training loss: 7.506896495819092
2025-12-09 12:28:55.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.000999424877983831 Training loss: 7.236813545227051
2025-12-09 12:28:55.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0009994098457065167 Training loss: 7.155708312988281
2025-12-09 12:28:56.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.0009993946196179913 Training loss: 6.988373279571533
2025-12-09 12:28:56.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.000999379199724164 Training loss: 7.648619651794434
2025-12-09 12:28:57.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0009993635860310187 Training loss: 7.628645896911621
2025-12-09 12:28:57.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.000999347778544615 Training loss: 7.352725505828857
2025-12-09 12:28:58.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.0009993317772710873 Training loss: 7.090492248535156
2025-12-09 12:28:58.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.0009993155822166457 Training loss: 7.391252517700195
2025-12-09 12:28:59.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.0009992991933875748 Training loss: 7.47422981262207
2025-12-09 12:28:59.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0009992826107902348 Training loss: 7.166608810424805
2025-12-09 12:29:00.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.0009992658344310614 Training loss: 7.0017547607421875
2025-12-09 12:29:00.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.000999248864316565 Training loss: 7.116812229156494
2025-12-09 12:29:01.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0009992317004533314 Training loss: 7.016713619232178
2025-12-09 12:29:01.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.0009992143428480215 Training loss: 7.351211071014404
2025-12-09 12:29:02.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0009991967915073715 Training loss: 6.971747398376465
2025-12-09 12:29:02.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0009991790464381925 Training loss: 7.1093339920043945
2025-12-09 12:29:03.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.0009991611076473714 Training loss: 7.533173084259033
2025-12-09 12:29:03.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.0009991429751418698 Training loss: 7.19352388381958
2025-12-09 12:29:04.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.0009991246489287244 Training loss: 7.666057109832764
2025-12-09 12:29:04.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0009991061290150474 Training loss: 7.242539882659912
2025-12-09 12:29:05.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0009990874154080258 Training loss: 7.051942348480225
2025-12-09 12:29:05.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.0009990685081149222 Training loss: 7.169742107391357
2025-12-09 12:29:06.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0009990494071430741 Training loss: 7.26534366607666
2025-12-09 12:29:06.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0009990301124998943 Training loss: 7.354729175567627
2025-12-09 12:29:07.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0009990106241928704 Training loss: 7.124908924102783
2025-12-09 12:29:07.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0009989909422295658 Training loss: 7.807430744171143
2025-12-09 12:29:08.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0009989710666176185 Training loss: 7.2137322425842285
2025-12-09 12:29:08.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0009989509973647418 Training loss: 7.184169292449951
2025-12-09 12:29:09.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0009989307344787242 Training loss: 7.09329080581665
2025-12-09 12:29:09.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0009989102779674292 Training loss: 7.2537713050842285
2025-12-09 12:29:10.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.000998889627838796 Training loss: 6.796212196350098
2025-12-09 12:29:10.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.000998868784100838 Training loss: 7.0967183113098145
2025-12-09 12:29:11.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.0009988477467616447 Training loss: 7.452305316925049
2025-12-09 12:29:11.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0009988265158293798 Training loss: 6.860918045043945
2025-12-09 12:29:12.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.000998805091312283 Training loss: 7.225393772125244
2025-12-09 12:29:12.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.0009987834732186687 Training loss: 6.8050150871276855
2025-12-09 12:29:13.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0009987616615569263 Training loss: 6.908858776092529
2025-12-09 12:29:13.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.0009987396563355204 Training loss: 6.952359676361084
2025-12-09 12:29:14.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.000998717457562991 Training loss: 7.243325710296631
2025-12-09 12:29:14.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.0009986950652479533 Training loss: 8.20921516418457
2025-12-09 12:29:15.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0009986724793990967 Training loss: 7.09166955947876
2025-12-09 12:29:15.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.0009986497000251866 Training loss: 6.658665180206299
2025-12-09 12:29:16.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.0009986267271350634 Training loss: 8.044320106506348
2025-12-09 12:29:16.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0009986035607376421 Training loss: 6.916461944580078
2025-12-09 12:29:17.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.0009985802008419132 Training loss: 7.458913803100586
2025-12-09 12:29:17.662 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0009985566474569425 Training loss: 7.221164703369141
2025-12-09 12:29:18.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0009985329005918703 Training loss: 7.558581352233887
2025-12-09 12:29:18.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0009985089602559125 Training loss: 7.230287075042725
2025-12-09 12:29:19.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0009984848264583597 Training loss: 6.883142948150635
2025-12-09 12:29:19.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.000998460499208578 Training loss: 7.100121021270752
2025-12-09 12:29:20.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.000998435978516008 Training loss: 7.375136852264404
2025-12-09 12:29:20.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.0009984112643901658 Training loss: 7.131154537200928
2025-12-09 12:29:21.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0009983863568406427 Training loss: 7.258862495422363
2025-12-09 12:29:21.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0009983612558771048 Training loss: 6.787600994110107
2025-12-09 12:29:22.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0009983359615092931 Training loss: 7.364080429077148
2025-12-09 12:29:22.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.000998310473747024 Training loss: 7.181532382965088
2025-12-09 12:29:23.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0009982847926001885 Training loss: 6.876790523529053
2025-12-09 12:29:23.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0009982589180787533 Training loss: 6.371721267700195
2025-12-09 12:29:24.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.0009982328501927599 Training loss: 6.665850639343262
2025-12-09 12:29:24.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0009982065889523242 Training loss: 7.822927951812744
2025-12-09 12:29:25.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.000998180134367638 Training loss: 7.986496925354004
2025-12-09 12:29:25.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0009981534864489678 Training loss: 7.642220497131348
2025-12-09 12:29:26.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.0009981266452066553 Training loss: 7.443521976470947
2025-12-09 12:29:26.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0009980996106511168 Training loss: 7.317160129547119
2025-12-09 12:29:27.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.000998072382792844 Training loss: 6.842181205749512
2025-12-09 12:29:27.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.0009980449616424037 Training loss: 7.031946659088135
2025-12-09 12:29:28.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.000998017347210437 Training loss: 6.721724510192871
2025-12-09 12:29:28.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.000997989539507661 Training loss: 7.118850231170654
2025-12-09 12:29:29.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.000997961538544867 Training loss: 7.265468597412109
2025-12-09 12:29:29.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0009979333443329217 Training loss: 7.4004597663879395
2025-12-09 12:29:30.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.000997904956882767 Training loss: 6.900006294250488
2025-12-09 12:29:30.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0009978763762054192 Training loss: 6.888700485229492
2025-12-09 12:29:31.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.00099784760231197 Training loss: 7.149425983428955
2025-12-09 12:29:31.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.000997818635213586 Training loss: 7.484669208526611
2025-12-09 12:29:32.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0009977894749215088 Training loss: 6.761784076690674
2025-12-09 12:29:32.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.000997760121447055 Training loss: 7.096036911010742
2025-12-09 12:29:33.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0009977305748016159 Training loss: 6.4451751708984375
2025-12-09 12:29:33.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.000997700834996658 Training loss: 7.209145545959473
2025-12-09 12:29:34.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.000997670902043723 Training loss: 6.725238800048828
2025-12-09 12:29:34.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.000997640775954427 Training loss: 7.003317356109619
2025-12-09 12:29:35.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.0009976104567404615 Training loss: 7.110528469085693
2025-12-09 12:29:35.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0009975799444135929 Training loss: 6.952028274536133
2025-12-09 12:29:36.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.0009975492389856621 Training loss: 8.581509590148926
2025-12-09 12:29:36.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.0009975183404685856 Training loss: 7.595184803009033
2025-12-09 12:29:37.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0009974872488743543 Training loss: 7.550781726837158
2025-12-09 12:29:37.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0009974559642150344 Training loss: 7.024559020996094
2025-12-09 12:29:38.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.000997424486502767 Training loss: 6.900722026824951
2025-12-09 12:29:38.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0009973928157497674 Training loss: 7.593240261077881
2025-12-09 12:29:39.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.000997360951968327 Training loss: 7.061790466308594
2025-12-09 12:29:39.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.0009973288951708112 Training loss: 7.362603664398193
2025-12-09 12:29:40.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0009972966453696609 Training loss: 7.2053375244140625
2025-12-09 12:29:40.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.0009972642025773912 Training loss: 7.190685749053955
2025-12-09 12:29:41.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.0009972315668065929 Training loss: 7.135724067687988
2025-12-09 12:29:41.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.000997198738069931 Training loss: 7.344037055969238
2025-12-09 12:29:42.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.000997165716380146 Training loss: 7.036994457244873
2025-12-09 12:29:42.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0009971325017500525 Training loss: 7.046334266662598
2025-12-09 12:29:43.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.0009970990941925411 Training loss: 8.143793106079102
2025-12-09 12:29:43.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.0009970654937205762 Training loss: 6.636556148529053
2025-12-09 12:29:44.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0009970317003471976 Training loss: 6.847761631011963
2025-12-09 12:29:44.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.0009969977140855198 Training loss: 7.113913536071777
2025-12-09 12:29:45.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0009969635349487322 Training loss: 7.539679527282715
2025-12-09 12:29:45.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.000996929162950099 Training loss: 6.949917316436768
2025-12-09 12:29:46.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0009968945981029596 Training loss: 7.418377876281738
2025-12-09 12:29:46.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0009968598404207275 Training loss: 6.70267915725708
2025-12-09 12:29:47.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0009968248899168918 Training loss: 6.950661659240723
2025-12-09 12:29:47.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.000996789746605016 Training loss: 7.199869155883789
2025-12-09 12:29:48.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0009967544104987386 Training loss: 7.161870956420898
2025-12-09 12:29:48.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0009967188816117727 Training loss: 6.851691246032715
2025-12-09 12:29:49.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0009966831599579067 Training loss: 7.337496280670166
2025-12-09 12:29:49.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.000996647245551003 Training loss: 7.317773818969727
2025-12-09 12:29:50.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0009966111384049996 Training loss: 7.407641410827637
2025-12-09 12:29:50.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0009965748385339088 Training loss: 6.748014450073242
2025-12-09 12:29:51.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0009965383459518181 Training loss: 6.7864274978637695
2025-12-09 12:29:51.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0009965016606728893 Training loss: 7.135992527008057
2025-12-09 12:29:52.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0009964647827113596 Training loss: 6.996058940887451
2025-12-09 12:29:52.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.0009964277120815403 Training loss: 7.195801734924316
2025-12-09 12:29:53.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.0009963904487978177 Training loss: 7.046675682067871
2025-12-09 12:29:53.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0009963529928746534 Training loss: 6.599987983703613
2025-12-09 12:29:54.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0009963153443265829 Training loss: 6.898212909698486
2025-12-09 12:29:54.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.0009962775031682168 Training loss: 6.933264255523682
2025-12-09 12:29:55.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.0009962394694142409 Training loss: 6.707132339477539
2025-12-09 12:29:55.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.0009962012430794153 Training loss: 6.569894790649414
2025-12-09 12:29:56.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.0009961628241785747 Training loss: 7.11209774017334
2025-12-09 12:29:56.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0009961242127266288 Training loss: 6.946425437927246
2025-12-09 12:29:57.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0009960854087385617 Training loss: 6.95219087600708
2025-12-09 12:29:57.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.000996046412229433 Training loss: 6.510288238525391
2025-12-09 12:29:58.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0009960072232143762 Training loss: 6.664017200469971
2025-12-09 12:29:58.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.0009959678417085997 Training loss: 6.757989883422852
2025-12-09 12:29:59.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0009959282677273868 Training loss: 6.657694339752197
2025-12-09 12:29:59.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0009958885012860954 Training loss: 6.906163692474365
2025-12-09 12:30:00.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.0009958485424001581 Training loss: 6.528417110443115
2025-12-09 12:30:00.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0009958083910850822 Training loss: 6.8421430587768555
2025-12-09 12:30:01.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0009957680473564494 Training loss: 7.475564956665039
2025-12-09 12:30:01.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.0009957275112299165 Training loss: 6.768740653991699
2025-12-09 12:30:02.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0009956867827212148 Training loss: 7.257426738739014
2025-12-09 12:30:02.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.00099564586184615 Training loss: 6.966517925262451
2025-12-09 12:30:03.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0009956047486206032 Training loss: 6.9245686531066895
2025-12-09 12:30:03.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0009955634430605291 Training loss: 6.722026348114014
2025-12-09 12:30:04.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.000995521945181958 Training loss: 7.196253776550293
2025-12-09 12:30:04.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0009954802550009943 Training loss: 7.021443843841553
2025-12-09 12:30:05.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.0009954383725338167 Training loss: 7.095102310180664
2025-12-09 12:30:05.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.0009953962977966794 Training loss: 7.0319294929504395
2025-12-09 12:30:06.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.000995354030805911 Training loss: 7.358645915985107
2025-12-09 12:30:06.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0009953115715779141 Training loss: 6.851968288421631
2025-12-09 12:30:07.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.0009952689201291663 Training loss: 7.061455249786377
2025-12-09 12:30:07.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.00099522607647622 Training loss: 7.186051845550537
2025-12-09 12:30:08.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.0009951830406357018 Training loss: 7.356024265289307
2025-12-09 12:30:08.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.0009951398126243135 Training loss: 6.768503665924072
2025-12-09 12:30:09.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.0009950963924588304 Training loss: 7.364488124847412
2025-12-09 12:30:09.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.0009950527801561033 Training loss: 7.093801021575928
2025-12-09 12:30:10.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0009950089757330574 Training loss: 6.662754535675049
2025-12-09 12:30:10.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0009949649792066922 Training loss: 7.1676435470581055
2025-12-09 12:30:11.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.000994920790594082 Training loss: 6.5767340660095215
2025-12-09 12:30:11.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.0009948764099123755 Training loss: 7.515737533569336
2025-12-09 12:30:12.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.000994831837178796 Training loss: 6.625072479248047
2025-12-09 12:30:12.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.000994787072410641 Training loss: 7.102452278137207
2025-12-09 12:30:13.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0009947421156252835 Training loss: 7.151952266693115
2025-12-09 12:30:13.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.0009946969668401698 Training loss: 6.603006839752197
2025-12-09 12:30:14.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.0009946516260728212 Training loss: 6.99099588394165
2025-12-09 12:30:14.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.000994606093340834 Training loss: 6.746578216552734
2025-12-09 12:30:15.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.0009945603686618784 Training loss: 6.7214813232421875
2025-12-09 12:30:15.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.000994514452053699 Training loss: 6.987531661987305
2025-12-09 12:30:16.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.0009944683435341155 Training loss: 6.492800235748291
2025-12-09 12:30:16.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.0009944220431210215 Training loss: 8.171964645385742
2025-12-09 12:30:17.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.0009943755508323854 Training loss: 7.931329727172852
2025-12-09 12:30:17.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.0009943288666862497 Training loss: 7.213238716125488
2025-12-09 12:30:18.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.000994281990700732 Training loss: 7.033683776855469
2025-12-09 12:30:18.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.0009942349228940237 Training loss: 6.804889678955078
2025-12-09 12:30:19.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.0009941876632843908 Training loss: 7.1171135902404785
2025-12-09 12:30:19.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.0009941402118901744 Training loss: 6.868425369262695
2025-12-09 12:30:20.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0009940925687297885 Training loss: 6.998752593994141
2025-12-09 12:30:20.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0009940447338217234 Training loss: 6.921266078948975
2025-12-09 12:30:21.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0009939967071845423 Training loss: 7.28949499130249
2025-12-09 12:30:21.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.0009939484888368837 Training loss: 7.020820617675781
2025-12-09 12:30:22.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.0009939000787974601 Training loss: 6.460931777954102
2025-12-09 12:30:22.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.0009938514770850585 Training loss: 7.26609992980957
2025-12-09 12:30:23.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.0009938026837185403 Training loss: 7.109954833984375
2025-12-09 12:30:23.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.0009937536987168413 Training loss: 6.8490400314331055
2025-12-09 12:30:24.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0009937045220989715 Training loss: 6.728225231170654
2025-12-09 12:30:24.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0009936551538840153 Training loss: 6.666924953460693
2025-12-09 12:30:25.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.000993605594091132 Training loss: 6.670321464538574
2025-12-09 12:30:25.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.000993555842739554 Training loss: 7.083446502685547
2025-12-09 12:30:26.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0009935058998485897 Training loss: 7.458151340484619
2025-12-09 12:30:26.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.0009934557654376205 Training loss: 6.6581315994262695
2025-12-09 12:30:27.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.0009934054395261025 Training loss: 7.463688373565674
2025-12-09 12:30:27.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.0009933549221335664 Training loss: 7.2968645095825195
2025-12-09 12:30:28.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.000993304213279617 Training loss: 6.579867839813232
2025-12-09 12:30:28.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0009932533129839334 Training loss: 7.345582008361816
2025-12-09 12:30:29.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.000993202221266269 Training loss: 6.873445510864258
2025-12-09 12:30:29.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.0009931509381464515 Training loss: 6.443754196166992
2025-12-09 12:30:30.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.0009930994636443828 Training loss: 7.0998969078063965
2025-12-09 12:30:30.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.0009930477977800392 Training loss: 6.905633449554443
2025-12-09 12:30:31.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.000992995940573471 Training loss: 7.1159467697143555
2025-12-09 12:30:31.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.0009929438920448037 Training loss: 6.9282989501953125
2025-12-09 12:30:32.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.0009928916522142356 Training loss: 6.792328834533691
2025-12-09 12:30:32.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.00099283922110204 Training loss: 6.844868183135986
2025-12-09 12:30:33.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.0009927865987285648 Training loss: 6.812244892120361
2025-12-09 12:30:33.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.0009927337851142314 Training loss: 6.951690673828125
2025-12-09 12:30:34.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.000992680780279536 Training loss: 7.115371227264404
2025-12-09 12:30:34.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.0009926275842450482 Training loss: 7.466757297515869
2025-12-09 12:30:35.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.0009925741970314129 Training loss: 6.703596591949463
2025-12-09 12:30:35.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.0009925206186593484 Training loss: 6.918215751647949
2025-12-09 12:30:36.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.0009924668491496473 Training loss: 7.294947147369385
2025-12-09 12:30:36.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.000992412888523177 Training loss: 6.72380256652832
2025-12-09 12:30:37.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.000992358736800878 Training loss: 6.79392147064209
2025-12-09 12:30:37.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.0009923043940037657 Training loss: 7.181946277618408
2025-12-09 12:30:38.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.0009922498601529295 Training loss: 6.146812438964844
2025-12-09 12:30:38.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.000992195135269533 Training loss: 6.9127326011657715
2025-12-09 12:30:39.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0009921402193748137 Training loss: 6.8237223625183105
2025-12-09 12:30:39.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.0009920851124900836 Training loss: 7.090335845947266
2025-12-09 12:30:40.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.0009920298146367287 Training loss: 6.620946884155273
2025-12-09 12:30:40.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.0009919743258362086 Training loss: 6.428158283233643
2025-12-09 12:30:41.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0009919186461100577 Training loss: 7.09984016418457
2025-12-09 12:30:41.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.000991862775479884 Training loss: 6.806264400482178
2025-12-09 12:30:42.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.00099180671396737 Training loss: 6.943147659301758
2025-12-09 12:30:42.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.0009917504615942721 Training loss: 8.241985321044922
2025-12-09 12:30:43.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.0009916940183824206 Training loss: 6.674646377563477
2025-12-09 12:30:43.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.0009916373843537201 Training loss: 7.899674892425537
2025-12-09 12:30:44.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.0009915805595301491 Training loss: 6.464366912841797
2025-12-09 12:30:44.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.0009915235439337602 Training loss: 7.0322184562683105
2025-12-09 12:30:45.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.0009914663375866803 Training loss: 6.550357818603516
2025-12-09 12:30:45.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.0009914089405111098 Training loss: 6.336618900299072
2025-12-09 12:30:46.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.0009913513527293235 Training loss: 6.9987640380859375
2025-12-09 12:30:46.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0009912935742636697 Training loss: 6.7622270584106445
2025-12-09 12:30:47.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.0009912356051365717 Training loss: 6.852166652679443
2025-12-09 12:30:47.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.0009911774453705258 Training loss: 7.029488563537598
2025-12-09 12:30:48.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.0009911190949881028 Training loss: 7.144678592681885
2025-12-09 12:30:48.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.0009910605540119474 Training loss: 6.633153915405273
2025-12-09 12:30:49.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.0009910018224647782 Training loss: 6.917763710021973
2025-12-09 12:30:49.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.0009909429003693876 Training loss: 7.356454372406006
2025-12-09 12:30:50.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.0009908837877486423 Training loss: 8.360695838928223
2025-12-09 12:30:50.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.0009908244846254825 Training loss: 6.387821674346924
2025-12-09 12:30:51.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.000990764991022923 Training loss: 6.939871311187744
2025-12-09 12:30:51.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.0009907053069640515 Training loss: 7.0105414390563965
2025-12-09 12:30:52.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.000990645432472031 Training loss: 6.732839584350586
2025-12-09 12:30:52.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.000990585367570097 Training loss: 6.822341442108154
2025-12-09 12:30:53.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.0009905251122815596 Training loss: 7.011477470397949
2025-12-09 12:30:53.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.000990464666629803 Training loss: 6.8578200340271
2025-12-09 12:30:54.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.0009904040306382847 Training loss: 6.6406450271606445
2025-12-09 12:30:54.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0009903432043305365 Training loss: 6.762495517730713
2025-12-09 12:30:55.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.0009902821877301638 Training loss: 7.012618064880371
2025-12-09 12:30:55.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.000990220980860846 Training loss: 6.517641067504883
2025-12-09 12:30:56.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.0009901595837463362 Training loss: 6.710022449493408
2025-12-09 12:30:56.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.0009900979964104616 Training loss: 6.661576271057129
2025-12-09 12:30:57.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.000990036218877123 Training loss: 6.884778022766113
2025-12-09 12:30:57.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.000989974251170295 Training loss: 6.483508110046387
2025-12-09 12:30:58.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.000989912093314026 Training loss: 7.29220724105835
2025-12-09 12:30:58.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.0009898497453324385 Training loss: 6.7238311767578125
2025-12-09 12:30:59.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.000989787207249728 Training loss: 6.513658046722412
2025-12-09 12:30:59.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.0009897244790901649 Training loss: 6.852881908416748
2025-12-09 12:31:00.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.0009896615608780924 Training loss: 6.776527404785156
2025-12-09 12:31:00.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.000989598452637928 Training loss: 6.615519046783447
2025-12-09 12:31:01.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.0009895351543941628 Training loss: 6.670053958892822
2025-12-09 12:31:01.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0009894716661713616 Training loss: 6.5788726806640625
2025-12-09 12:31:02.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0009894079879941627 Training loss: 6.878908634185791
2025-12-09 12:31:02.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.0009893441198872788 Training loss: 6.865251064300537
2025-12-09 12:31:03.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.0009892800618754953 Training loss: 6.506026268005371
2025-12-09 12:31:03.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.0009892158139836725 Training loss: 6.454689025878906
2025-12-09 12:31:04.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0009891513762367431 Training loss: 6.411715507507324
2025-12-09 12:31:04.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.0009890867486597146 Training loss: 6.383606910705566
2025-12-09 12:31:05.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.0009890219312776677 Training loss: 6.438450813293457
2025-12-09 12:31:05.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.0009889569241157564 Training loss: 6.779844760894775
2025-12-09 12:31:06.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.000988891727199209 Training loss: 7.086236953735352
2025-12-09 12:31:06.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.000988826340553327 Training loss: 6.719024181365967
2025-12-09 12:31:07.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.0009887607642034859 Training loss: 6.450837135314941
2025-12-09 12:31:07.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.0009886949981751346 Training loss: 6.8310465812683105
2025-12-09 12:31:08.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.0009886290424937951 Training loss: 6.580506324768066
2025-12-09 12:31:08.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0009885628971850642 Training loss: 6.900557994842529
2025-12-09 12:31:09.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.0009884965622746112 Training loss: 6.869917869567871
2025-12-09 12:31:09.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.0009884300377881795 Training loss: 6.910440444946289
2025-12-09 12:31:10.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.0009883633237515858 Training loss: 6.859005928039551
2025-12-09 12:31:10.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.0009882964201907208 Training loss: 6.657725811004639
2025-12-09 12:31:11.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0009882293271315482 Training loss: 7.0522871017456055
2025-12-09 12:31:11.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.0009881620446001056 Training loss: 6.787111759185791
2025-12-09 12:31:12.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.000988094572622504 Training loss: 7.129720687866211
2025-12-09 12:31:12.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.0009880269112249281 Training loss: 6.94036340713501
2025-12-09 12:31:13.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.000987959060433636 Training loss: 6.622816562652588
2025-12-09 12:31:13.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.0009878910202749589 Training loss: 6.617386817932129
2025-12-09 12:31:14.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.0009878227907753022 Training loss: 6.657501220703125
2025-12-09 12:31:14.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.0009877543719611444 Training loss: 7.433607578277588
2025-12-09 12:31:15.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.0009876857638590373 Training loss: 6.426724433898926
2025-12-09 12:31:15.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.0009876169664956068 Training loss: 6.529592990875244
2025-12-09 12:31:16.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.0009875479798975512 Training loss: 6.785369873046875
2025-12-09 12:31:16.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.0009874788040916433 Training loss: 6.69195032119751
2025-12-09 12:31:17.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.0009874094391047288 Training loss: 7.250894546508789
2025-12-09 12:31:17.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.0009873398849637267 Training loss: 6.7745041847229
2025-12-09 12:31:18.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.00098727014169563 Training loss: 6.897568702697754
2025-12-09 12:31:18.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.0009872002093275043 Training loss: 7.555509090423584
2025-12-09 12:31:19.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.000987130087886489 Training loss: 6.662852764129639
2025-12-09 12:31:19.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.000987059777399797 Training loss: 7.235528945922852
2025-12-09 12:31:20.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.0009869892778947148 Training loss: 6.8148512840271
2025-12-09 12:31:20.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.0009869185893986011 Training loss: 6.518265247344971
2025-12-09 12:31:21.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.0009868477119388895 Training loss: 6.527503490447998
2025-12-09 12:31:21.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.0009867766455430858 Training loss: 6.899430274963379
2025-12-09 12:31:22.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.0009867053902387693 Training loss: 6.828178882598877
2025-12-09 12:31:22.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.0009866339460535929 Training loss: 6.5082197189331055
2025-12-09 12:31:23.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.0009865623130152828 Training loss: 6.818679332733154
2025-12-09 12:31:23.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.0009864904911516383 Training loss: 6.541617393493652
2025-12-09 12:31:24.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.0009864184804905323 Training loss: 6.619039535522461
2025-12-09 12:31:24.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.0009863462810599105 Training loss: 6.725561141967773
2025-12-09 12:31:25.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.000986273892887792 Training loss: 6.634086608886719
2025-12-09 12:31:25.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.0009862013160022696 Training loss: 6.959362983703613
2025-12-09 12:31:26.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.0009861285504315085 Training loss: 6.886609077453613
2025-12-09 12:31:26.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.0009860555962037478 Training loss: 6.3783111572265625
2025-12-09 12:31:27.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.0009859824533472999 Training loss: 6.1480793952941895
2025-12-09 12:31:27.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.0009859091218905498 Training loss: 6.619452953338623
2025-12-09 12:31:28.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.000985835601861956 Training loss: 6.318126201629639
2025-12-09 12:31:28.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.0009857618932900504 Training loss: 6.3621416091918945
2025-12-09 12:31:29.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0009856879962034375 Training loss: 7.175297737121582
2025-12-09 12:31:29.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0009856139106307956 Training loss: 7.646679878234863
2025-12-09 12:31:30.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.0009855396366008756 Training loss: 6.427591323852539
2025-12-09 12:31:30.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.0009854651741425023 Training loss: 6.685802459716797
2025-12-09 12:31:31.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.0009853905232845728 Training loss: 6.242642402648926
2025-12-09 12:31:31.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0009853156840560575 Training loss: 6.7842254638671875
2025-12-09 12:31:32.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.0009852406564860004 Training loss: 6.877872467041016
2025-12-09 12:31:32.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.000985165440603518 Training loss: 6.446649074554443
2025-12-09 12:31:33.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.0009850900364378 Training loss: 7.012146472930908
2025-12-09 12:31:33.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.0009850144440181096 Training loss: 5.903919219970703
2025-12-09 12:31:34.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.0009849386633737824 Training loss: 6.5071306228637695
2025-12-09 12:31:34.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.0009848626945342278 Training loss: 7.304714202880859
2025-12-09 12:31:35.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.0009847865375289275 Training loss: 6.520315647125244
2025-12-09 12:31:35.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.0009847101923874367 Training loss: 6.617374897003174
2025-12-09 12:31:36.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.0009846336591393832 Training loss: 6.562270641326904
2025-12-09 12:31:36.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.0009845569378144686 Training loss: 6.700011730194092
2025-12-09 12:31:37.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.0009844800284424663 Training loss: 6.702442169189453
2025-12-09 12:31:37.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0009844029310532238 Training loss: 6.247476577758789
2025-12-09 12:31:38.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.0009843256456766609 Training loss: 6.610847473144531
2025-12-09 12:31:38.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.0009842481723427705 Training loss: 6.698853015899658
2025-12-09 12:31:39.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.0009841705110816186 Training loss: 7.043126583099365
2025-12-09 12:31:39.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.000984092661923344 Training loss: 6.7924580574035645
2025-12-09 12:31:40.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.0009840146248981585 Training loss: 6.713125228881836
2025-12-09 12:31:40.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.0009839364000363466 Training loss: 6.348961353302002
2025-12-09 12:31:41.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.000983857987368266 Training loss: 7.202809810638428
2025-12-09 12:31:41.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.0009837793869243467 Training loss: 6.733853340148926
2025-12-09 12:31:42.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.0009837005987350927 Training loss: 6.411972522735596
2025-12-09 12:31:42.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.0009836216228310797 Training loss: 6.760650634765625
2025-12-09 12:31:43.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.0009835424592429566 Training loss: 6.8694963455200195
2025-12-09 12:31:43.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.0009834631080014456 Training loss: 6.763239860534668
2025-12-09 12:31:44.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.0009833835691373412 Training loss: 7.1541008949279785
2025-12-09 12:31:44.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.000983303842681511 Training loss: 7.059584140777588
2025-12-09 12:31:45.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.000983223928664895 Training loss: 6.552546501159668
2025-12-09 12:31:45.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.0009831438271185064 Training loss: 6.684370517730713
2025-12-09 12:31:46.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.0009830635380734312 Training loss: 6.393507957458496
2025-12-09 12:31:46.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.000982983061560828 Training loss: 6.772611618041992
2025-12-09 12:31:47.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0009829023976119279 Training loss: 6.681931972503662
2025-12-09 12:31:47.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0009828215462580352 Training loss: 6.901120662689209
2025-12-09 12:31:48.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.0009827405075305267 Training loss: 6.742822647094727
2025-12-09 12:31:48.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.000982659281460852 Training loss: 7.6254658699035645
2025-12-09 12:31:49.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.0009825778680805331 Training loss: 6.778660297393799
2025-12-09 12:31:49.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.0009824962674211653 Training loss: 6.682653427124023
2025-12-09 12:31:50.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.0009824144795144158 Training loss: 6.646317005157471
2025-12-09 12:31:50.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.0009823325043920256 Training loss: 6.78264045715332
2025-12-09 12:31:51.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.0009822503420858068 Training loss: 6.891898155212402
2025-12-09 12:31:51.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.0009821679926276456 Training loss: 6.595344066619873
2025-12-09 12:31:52.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.0009820854560494998 Training loss: 6.249652862548828
2025-12-09 12:31:52.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.0009820027323834007 Training loss: 6.834436893463135
2025-12-09 12:31:53.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.0009819198216614513 Training loss: 6.81496524810791
2025-12-09 12:31:53.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.0009818367239158277 Training loss: 6.67080020904541
2025-12-09 12:31:54.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.0009817534391787788 Training loss: 7.0691609382629395
2025-12-09 12:31:54.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0009816699674826256 Training loss: 7.2230448722839355
2025-12-09 12:31:55.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.0009815863088597618 Training loss: 6.396691799163818
2025-12-09 12:31:55.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.0009815024633426537 Training loss: 6.780519962310791
2025-12-09 12:31:56.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.00098141843096384 Training loss: 6.601596832275391
2025-12-09 12:31:56.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.0009813342117559324 Training loss: 6.258370399475098
2025-12-09 12:31:57.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.0009812498057516143 Training loss: 6.391929626464844
2025-12-09 12:31:57.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.0009811652129836422 Training loss: 6.561426639556885
2025-12-09 12:31:58.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.0009810804334848449 Training loss: 6.521949768066406
2025-12-09 12:31:58.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.0009809954672881237 Training loss: 6.461749076843262
2025-12-09 12:31:59.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.0009809103144264523 Training loss: 6.490589618682861
2025-12-09 12:31:59.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.0009808249749328768 Training loss: 6.90691614151001
2025-12-09 12:32:00.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.000980739448840516 Training loss: 7.002237319946289
2025-12-09 12:32:00.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.0009806537361825606 Training loss: 6.601584434509277
2025-12-09 12:32:01.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.0009805678369922742 Training loss: 6.291700839996338
2025-12-09 12:32:01.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.0009804817513029928 Training loss: 6.802402019500732
2025-12-09 12:32:02.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.000980395479148124 Training loss: 6.512640953063965
2025-12-09 12:32:02.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.0009803090205611487 Training loss: 7.329019546508789
2025-12-09 12:32:03.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.0009802223755756199 Training loss: 6.422628879547119
2025-12-09 12:32:03.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0009801355442251626 Training loss: 6.484764575958252
2025-12-09 12:32:04.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.0009800485265434745 Training loss: 6.396625995635986
2025-12-09 12:32:04.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.0009799613225643252 Training loss: 6.379465103149414
2025-12-09 12:32:05.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.0009798739323215572 Training loss: 6.998785018920898
2025-12-09 12:32:05.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.0009797863558490849 Training loss: 6.919552803039551
2025-12-09 12:32:06.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.000979698593180895 Training loss: 6.305868148803711
2025-12-09 12:32:06.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.0009796106443510462 Training loss: 6.626132965087891
2025-12-09 12:32:07.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.00097952250939367 Training loss: 6.829841613769531
2025-12-09 12:32:07.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.0009794341883429699 Training loss: 6.513866901397705
2025-12-09 12:32:08.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.0009793456812332215 Training loss: 5.972682952880859
2025-12-09 12:32:08.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.0009792569880987725 Training loss: 6.951874732971191
2025-12-09 12:32:09.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.0009791681089740432 Training loss: 6.672443866729736
2025-12-09 12:32:09.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.0009790790438935256 Training loss: 6.920781135559082
2025-12-09 12:32:10.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.0009789897928917846 Training loss: 6.922534942626953
2025-12-09 12:32:10.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.000978900356003456 Training loss: 6.48922061920166
2025-12-09 12:32:11.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.0009788107332632495 Training loss: 6.795124053955078
2025-12-09 12:32:11.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.0009787209247059453 Training loss: 7.414031505584717
2025-12-09 12:32:12.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.0009786309303663962 Training loss: 6.80191707611084
2025-12-09 12:32:12.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.0009785407502795277 Training loss: 6.270362377166748
2025-12-09 12:32:13.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.0009784503844803367 Training loss: 6.536116600036621
2025-12-09 12:32:13.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.0009783598330038925 Training loss: 6.2461700439453125
2025-12-09 12:32:14.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.0009782690958853363 Training loss: 6.4849534034729
2025-12-09 12:32:14.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.0009781781731598813 Training loss: 5.841225624084473
2025-12-09 12:32:15.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.000978087064862813 Training loss: 6.802253246307373
2025-12-09 12:32:15.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.0009779957710294885 Training loss: 6.436590671539307
2025-12-09 12:32:16.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.0009779042916953375 Training loss: 6.9401373863220215
2025-12-09 12:32:16.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.0009778126268958612 Training loss: 7.1441545486450195
2025-12-09 12:32:17.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.000977720776666633 Training loss: 6.667670249938965
2025-12-09 12:32:17.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.000977628741043298 Training loss: 6.671813011169434
2025-12-09 12:32:18.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.0009775365200615734 Training loss: 7.083937168121338
2025-12-09 12:32:18.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.0009774441137572487 Training loss: 6.609910488128662
2025-12-09 12:32:19.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.0009773515221661846 Training loss: 6.270910263061523
2025-12-09 12:32:19.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.0009772587453243141 Training loss: 6.765732288360596
2025-12-09 12:32:20.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.0009771657832676427 Training loss: 6.320289611816406
2025-12-09 12:32:20.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.0009770726360322465 Training loss: 6.6426849365234375
2025-12-09 12:32:21.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.000976979303654274 Training loss: 6.279932022094727
2025-12-09 12:32:21.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.0009768857861699462 Training loss: 6.3799309730529785
2025-12-09 12:32:22.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.0009767920836155552 Training loss: 6.487252235412598
2025-12-09 12:32:22.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.0009766981960274653 Training loss: 6.641326427459717
2025-12-09 12:32:23.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.000976604123442112 Training loss: 6.644103527069092
2025-12-09 12:32:23.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.0009765098658960035 Training loss: 6.668962478637695
2025-12-09 12:32:24.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.0009764154234257191 Training loss: 6.6957621574401855
2025-12-09 12:32:24.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.00097632079606791 Training loss: 6.748109817504883
2025-12-09 12:32:25.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.0009762259838592994 Training loss: 6.707984924316406
2025-12-09 12:32:25.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.0009761309868366819 Training loss: 6.5715789794921875
2025-12-09 12:32:26.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0009760358050369243 Training loss: 6.949098110198975
2025-12-09 12:32:26.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.0009759404384969643 Training loss: 6.562690734863281
2025-12-09 12:32:27.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.0009758448872538121 Training loss: 6.450626850128174
2025-12-09 12:32:27.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.0009757491513445493 Training loss: 6.783605098724365
2025-12-09 12:32:28.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.0009756532308063293 Training loss: 6.56552267074585
2025-12-09 12:32:28.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.0009755571256763765 Training loss: 6.247155666351318
2025-12-09 12:32:29.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.0009754608359919879 Training loss: 6.4066619873046875
2025-12-09 12:32:29.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.0009753643617905312 Training loss: 6.568959712982178
2025-12-09 12:32:30.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.0009752677031094466 Training loss: 7.543308258056641
2025-12-09 12:32:30.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0009751708599862451 Training loss: 6.656515598297119
2025-12-09 12:32:31.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.0009750738324585098 Training loss: 6.708942890167236
2025-12-09 12:32:31.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.0009749766205638952 Training loss: 6.679547309875488
2025-12-09 12:32:32.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.0009748792243401273 Training loss: 6.670316696166992
2025-12-09 12:32:32.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.0009747816438250037 Training loss: 6.604778289794922
2025-12-09 12:32:33.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.0009746838790563935 Training loss: 6.434509754180908
2025-12-09 12:32:33.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.000974585930072237 Training loss: 6.598677635192871
2025-12-09 12:32:34.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.0009744877969105468 Training loss: 7.2063751220703125
2025-12-09 12:32:34.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.0009743894796094062 Training loss: 6.384339809417725
2025-12-09 12:32:35.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.0009742909782069701 Training loss: 6.421414375305176
2025-12-09 12:32:35.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.0009741922927414651 Training loss: 6.912100315093994
2025-12-09 12:32:36.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.0009740934232511893 Training loss: 6.47437047958374
2025-12-09 12:32:36.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.0009739943697745117 Training loss: 6.406041622161865
2025-12-09 12:32:37.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0009738951323498732 Training loss: 6.827827453613281
2025-12-09 12:32:37.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0009737957110157858 Training loss: 6.679788589477539
2025-12-09 12:32:38.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.0009736961058108331 Training loss: 6.343111515045166
2025-12-09 12:32:38.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.0009735963167736698 Training loss: 6.290972709655762
2025-12-09 12:32:39.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.0009734963439430222 Training loss: 6.360826015472412
2025-12-09 12:32:39.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.0009733961873576877 Training loss: 6.589438438415527
2025-12-09 12:32:40.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0009732958470565352 Training loss: 6.272322177886963
2025-12-09 12:32:40.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.0009731953230785049 Training loss: 6.1308441162109375
2025-12-09 12:32:41.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.0009730946154626079 Training loss: 7.114288806915283
2025-12-09 12:32:41.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.000972993724247927 Training loss: 6.529733657836914
2025-12-09 12:32:42.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.0009728926494736163 Training loss: 6.6697282791137695
2025-12-09 12:32:42.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.0009727913911789008 Training loss: 6.8188300132751465
2025-12-09 12:32:43.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.0009726899494030768 Training loss: 6.813645839691162
2025-12-09 12:32:43.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.0009725883241855118 Training loss: 6.390222549438477
2025-12-09 12:32:44.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.0009724865155656448 Training loss: 6.571231842041016
2025-12-09 12:32:44.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.0009723845235829856 Training loss: 5.862629413604736
2025-12-09 12:32:45.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.0009722823482771155 Training loss: 6.917950630187988
2025-12-09 12:32:45.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.0009721799896876864 Training loss: 6.549983501434326
2025-12-09 12:32:46.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.0009720774478544219 Training loss: 6.39562463760376
2025-12-09 12:32:46.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.0009719747228171163 Training loss: 6.268426895141602
2025-12-09 12:32:47.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.0009718718146156355 Training loss: 5.957973003387451
2025-12-09 12:32:47.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0009717687232899158 Training loss: 7.3899245262146
2025-12-09 12:32:48.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0009716654488799652 Training loss: 6.790140151977539
2025-12-09 12:32:48.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.0009715619914258623 Training loss: 6.582339286804199
2025-12-09 12:32:49.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.000971458350967757 Training loss: 7.538423538208008
2025-12-09 12:32:49.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.0009713545275458703 Training loss: 6.64178466796875
2025-12-09 12:32:50.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.0009712505212004937 Training loss: 6.320254802703857
2025-12-09 12:32:50.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.0009711463319719904 Training loss: 6.982608795166016
2025-12-09 12:32:51.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0009710419599007938 Training loss: 6.774720191955566
2025-12-09 12:32:51.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.0009709374050274089 Training loss: 6.806718349456787
2025-12-09 12:32:52.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.0009708326673924114 Training loss: 6.104226112365723
2025-12-09 12:32:52.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0009707277470364482 Training loss: 6.7243781089782715
2025-12-09 12:32:53.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.0009706226440002363 Training loss: 6.724992752075195
2025-12-09 12:32:53.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.0009705173583245644 Training loss: 6.659509658813477
2025-12-09 12:32:54.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.0009704118900502918 Training loss: 6.923118591308594
2025-12-09 12:32:54.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.0009703062392183488 Training loss: 6.468753337860107
2025-12-09 12:32:55.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.0009702004058697362 Training loss: 6.794678688049316
2025-12-09 12:32:55.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0009700943900455262 Training loss: 6.585771083831787
2025-12-09 12:32:56.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.0009699881917868609 Training loss: 6.67202091217041
2025-12-09 12:32:56.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.0009698818111349544 Training loss: 6.584964752197266
2025-12-09 12:32:57.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.0009697752481310904 Training loss: 7.179949760437012
2025-12-09 12:32:57.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.0009696685028166244 Training loss: 6.524428367614746
2025-12-09 12:32:58.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.000969561575232982 Training loss: 6.56055212020874
2025-12-09 12:32:58.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0009694544654216595 Training loss: 6.7458014488220215
2025-12-09 12:32:59.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.0009693471734242243 Training loss: 6.450080394744873
2025-12-09 12:32:59.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0009692396992823144 Training loss: 7.1581573486328125
2025-12-09 12:33:00.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.0009691320430376385 Training loss: 6.170236587524414
2025-12-09 12:33:00.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.0009690242047319755 Training loss: 6.537804126739502
2025-12-09 12:33:01.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.0009689161844071756 Training loss: 6.5557966232299805
2025-12-09 12:33:01.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.0009688079821051594 Training loss: 5.948268890380859
2025-12-09 12:33:02.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.0009686995978679181 Training loss: 6.152361869812012
2025-12-09 12:33:02.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.0009685910317375133 Training loss: 6.3395094871521
2025-12-09 12:33:03.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.0009684822837560776 Training loss: 6.56405782699585
2025-12-09 12:33:03.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.0009683733539658139 Training loss: 6.665807723999023
2025-12-09 12:33:04.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.0009682642424089958 Training loss: 6.481404781341553
2025-12-09 12:33:04.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.0009681549491279673 Training loss: 6.463074207305908
2025-12-09 12:33:05.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.000968045474165143 Training loss: 6.672821044921875
2025-12-09 12:33:05.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0009679358175630081 Training loss: 6.6477484703063965
2025-12-09 12:33:06.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.000967825979364118 Training loss: 6.511245250701904
2025-12-09 12:33:06.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.0009677159596110987 Training loss: 5.8166823387146
2025-12-09 12:33:07.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.000967605758346647 Training loss: 6.261077880859375
2025-12-09 12:33:07.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.0009674953756135297 Training loss: 6.3534417152404785
2025-12-09 12:33:08.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.0009673848114545843 Training loss: 6.174889087677002
2025-12-09 12:33:08.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.0009672740659127184 Training loss: 6.224475383758545
2025-12-09 12:33:09.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.0009671631390309102 Training loss: 6.202189922332764
2025-12-09 12:33:09.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.0009670520308522084 Training loss: 6.292776107788086
2025-12-09 12:33:10.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.0009669407414197318 Training loss: 5.976868152618408
2025-12-09 12:33:10.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.0009668292707766699 Training loss: 6.399212837219238
2025-12-09 12:33:11.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.0009667176189662818 Training loss: 6.287137508392334
2025-12-09 12:33:11.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.0009666057860318978 Training loss: 6.465997695922852
2025-12-09 12:33:12.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.000966493772016918 Training loss: 6.1680521965026855
2025-12-09 12:33:12.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.0009663815769648127 Training loss: 6.62347412109375
2025-12-09 12:33:13.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.000966269200919123 Training loss: 6.694565296173096
2025-12-09 12:33:13.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.0009661566439234593 Training loss: 6.616764068603516
2025-12-09 12:33:14.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.000966043906021503 Training loss: 7.155979633331299
2025-12-09 12:33:14.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.0009659309872570057 Training loss: 6.775797367095947
2025-12-09 12:33:15.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.0009658178876737886 Training loss: 6.279080867767334
2025-12-09 12:33:15.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.0009657046073157437 Training loss: 6.221019268035889
2025-12-09 12:33:16.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.0009655911462268327 Training loss: 6.7108330726623535
2025-12-09 12:33:16.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.000965477504451088 Training loss: 6.705137729644775
2025-12-09 12:33:17.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.0009653636820326113 Training loss: 6.622175693511963
2025-12-09 12:33:17.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.0009652496790155752 Training loss: 6.136782646179199
2025-12-09 12:33:18.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.0009651354954442218 Training loss: 6.403554916381836
2025-12-09 12:33:18.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.0009650211313628637 Training loss: 6.774044513702393
2025-12-09 12:33:19.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.0009649065868158832 Training loss: 5.8226518630981445
2025-12-09 12:33:19.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.0009647918618477329 Training loss: 6.73031759262085
2025-12-09 12:33:20.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.0009646769565029354 Training loss: 6.359675407409668
2025-12-09 12:33:20.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.0009645618708260831 Training loss: 6.9368743896484375
2025-12-09 12:33:21.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.0009644466048618386 Training loss: 6.607172966003418
2025-12-09 12:33:21.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.0009643311586549342 Training loss: 7.820219993591309
2025-12-09 12:33:22.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.0009642155322501725 Training loss: 6.275521755218506
2025-12-09 12:33:22.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.0009640997256924257 Training loss: 6.9309210777282715
2025-12-09 12:33:23.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.0009639837390266362 Training loss: 6.2943243980407715
2025-12-09 12:33:23.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.0009638675722978161 Training loss: 6.67971134185791
2025-12-09 12:33:24.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.0009637512255510475 Training loss: 6.384684085845947
2025-12-09 12:33:24.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.000963634698831482 Training loss: 6.483372211456299
2025-12-09 12:33:25.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.0009635179921843417 Training loss: 6.542228698730469
2025-12-09 12:33:25.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.0009634011056549182 Training loss: 6.231137752532959
2025-12-09 12:33:26.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.0009632840392885726 Training loss: 6.443962097167969
2025-12-09 12:33:26.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.0009631667931307364 Training loss: 6.1614603996276855
2025-12-09 12:33:27.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.0009630493672269101 Training loss: 6.3907856941223145
2025-12-09 12:33:27.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.0009629317616226649 Training loss: 6.649807453155518
2025-12-09 12:33:28.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.0009628139763636407 Training loss: 6.5288848876953125
2025-12-09 12:33:28.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.0009626960114955483 Training loss: 6.4839277267456055
2025-12-09 12:33:29.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.0009625778670641669 Training loss: 6.528022766113281
2025-12-09 12:33:29.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.0009624595431153467 Training loss: 6.700442790985107
2025-12-09 12:33:30.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 726 LR: 0.0009623410396950063 Training loss: 6.333070755004883
2025-12-09 12:33:30.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 727 LR: 0.000962222356849135 Training loss: 6.369980812072754
2025-12-09 12:33:31.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 728 LR: 0.000962103494623791 Training loss: 6.414927005767822
2025-12-09 12:33:31.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 729 LR: 0.0009619844530651026 Training loss: 6.136300563812256
2025-12-09 12:33:32.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 730 LR: 0.0009618652322192675 Training loss: 6.222356796264648
2025-12-09 12:33:32.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 731 LR: 0.0009617458321325529 Training loss: 6.462061405181885
2025-12-09 12:33:33.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 732 LR: 0.0009616262528512957 Training loss: 6.186143398284912
2025-12-09 12:33:33.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 733 LR: 0.0009615064944219022 Training loss: 6.421570777893066
2025-12-09 12:33:34.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 734 LR: 0.0009613865568908484 Training loss: 6.653454780578613
2025-12-09 12:33:34.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 735 LR: 0.0009612664403046797 Training loss: 6.4148268699646
