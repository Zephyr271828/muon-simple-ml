2025-12-09 11:51:23.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.010464668273926
2025-12-09 11:51:23.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.023785591125488
2025-12-09 11:51:23.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 11.970541000366211
2025-12-09 11:51:23.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 12.017266273498535
2025-12-09 11:51:23.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 11.973002433776855
2025-12-09 11:51:23.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 11.920866012573242
2025-12-09 11:51:23.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 11.868256568908691
2025-12-09 11:51:23.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 11.734930992126465
2025-12-09 11:51:23.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 11.676116943359375
2025-12-09 11:51:24.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 11.459640502929688
2025-12-09 11:51:24.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 11.305469512939453
2025-12-09 11:51:24.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 11.24527359008789
2025-12-09 11:51:24.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 11.181814193725586
2025-12-09 11:51:24.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 11.163555145263672
2025-12-09 11:51:24.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 11.043532371520996
2025-12-09 11:51:24.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 11.027451515197754
2025-12-09 11:51:24.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 11.001967430114746
2025-12-09 11:51:24.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 11.008116722106934
2025-12-09 11:51:24.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 10.796326637268066
2025-12-09 11:51:24.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 10.741238594055176
2025-12-09 11:51:24.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 10.579575538635254
2025-12-09 11:51:24.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 10.57547378540039
2025-12-09 11:51:25.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 10.497740745544434
2025-12-09 11:51:25.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 10.399245262145996
2025-12-09 11:51:25.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 10.226043701171875
2025-12-09 11:51:25.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 10.220553398132324
2025-12-09 11:51:25.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 9.965328216552734
2025-12-09 11:51:25.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 9.848882675170898
2025-12-09 11:51:25.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 9.82928466796875
2025-12-09 11:51:25.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 9.792016983032227
2025-12-09 11:51:25.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 9.49974250793457
2025-12-09 11:51:25.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 9.393646240234375
2025-12-09 11:51:25.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 9.045978546142578
2025-12-09 11:51:25.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 8.956381797790527
2025-12-09 11:51:25.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 8.807406425476074
2025-12-09 11:51:26.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 8.749655723571777
2025-12-09 11:51:26.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 8.715524673461914
2025-12-09 11:51:26.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 8.596365928649902
2025-12-09 11:51:26.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 8.525925636291504
2025-12-09 11:51:26.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 8.421818733215332
2025-12-09 11:51:26.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 8.231407165527344
2025-12-09 11:51:26.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 8.213775634765625
2025-12-09 11:51:26.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 8.354307174682617
2025-12-09 11:51:26.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 8.734152793884277
2025-12-09 11:51:26.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 7.555598735809326
2025-12-09 11:51:26.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 8.005509376525879
2025-12-09 11:51:26.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 7.980469703674316
2025-12-09 11:51:26.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 8.190622329711914
2025-12-09 11:51:27.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 7.806957244873047
2025-12-09 11:51:27.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 7.917644023895264
2025-12-09 11:51:27.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 8.693229675292969
2025-12-09 11:51:27.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 7.830593109130859
2025-12-09 11:51:27.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 7.834442615509033
2025-12-09 11:51:27.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 8.0945463180542
2025-12-09 11:51:27.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 7.865991115570068
2025-12-09 11:51:27.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 8.571595191955566
2025-12-09 11:51:27.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 7.99268102645874
2025-12-09 11:51:27.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 8.067710876464844
2025-12-09 11:51:27.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 7.628133773803711
2025-12-09 11:51:27.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 7.957350730895996
2025-12-09 11:51:28.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 8.108834266662598
2025-12-09 11:51:28.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 8.11984634399414
2025-12-09 11:51:28.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 7.91924524307251
2025-12-09 11:51:28.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 7.63769006729126
2025-12-09 11:51:28.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 8.03022575378418
2025-12-09 11:51:28.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 7.7929840087890625
2025-12-09 11:51:28.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 7.811437606811523
2025-12-09 11:51:28.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 7.806396007537842
2025-12-09 11:51:28.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 7.968926906585693
2025-12-09 11:51:28.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 8.021539688110352
2025-12-09 11:51:28.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 7.973887920379639
2025-12-09 11:51:28.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 7.991684436798096
2025-12-09 11:51:28.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 7.942219257354736
2025-12-09 11:51:29.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 7.865083694458008
2025-12-09 11:51:29.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 8.393563270568848
2025-12-09 11:51:29.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 7.920166969299316
2025-12-09 11:51:29.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 7.5799102783203125
2025-12-09 11:51:29.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 7.838821887969971
2025-12-09 11:51:29.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 7.850194931030273
2025-12-09 11:51:29.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 7.914801120758057
2025-12-09 11:51:29.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 7.545301914215088
2025-12-09 11:51:29.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 7.550682067871094
2025-12-09 11:51:29.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 7.802933692932129
2025-12-09 11:51:29.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 7.848031520843506
2025-12-09 11:51:29.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 7.954909324645996
2025-12-09 11:51:29.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 7.71421480178833
2025-12-09 11:51:30.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 7.793353080749512
2025-12-09 11:51:30.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 8.126863479614258
2025-12-09 11:51:30.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 7.8177971839904785
2025-12-09 11:51:30.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 7.487784385681152
2025-12-09 11:51:30.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 7.972564697265625
2025-12-09 11:51:30.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 7.604583740234375
2025-12-09 11:51:30.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 7.96268367767334
2025-12-09 11:51:30.677 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 7.701143264770508
2025-12-09 11:51:30.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 7.454950332641602
2025-12-09 11:51:30.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 7.635272979736328
2025-12-09 11:51:30.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 7.961788177490234
2025-12-09 11:51:30.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 7.711968421936035
2025-12-09 11:51:31.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 7.966843605041504
2025-12-09 11:51:31.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 7.949162006378174
2025-12-09 11:51:31.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0009999999072578703 Training loss: 7.7118449211120605
2025-12-09 11:51:31.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.0009999996290315154 Training loss: 7.657882213592529
2025-12-09 11:51:31.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0009999991653210384 Training loss: 7.514604568481445
2025-12-09 11:51:31.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0009999985161266117 Training loss: 7.554245471954346
2025-12-09 11:51:31.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0009999976814484759 Training loss: 7.221536159515381
2025-12-09 11:51:31.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0009999966612869405 Training loss: 7.4526214599609375
2025-12-09 11:51:31.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0009999954556423843 Training loss: 8.12584114074707
2025-12-09 11:51:31.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0009999940645152542 Training loss: 7.454758167266846
2025-12-09 11:51:31.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0009999924879060664 Training loss: 7.72800874710083
2025-12-09 11:51:31.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.000999990725815406 Training loss: 8.29466438293457
2025-12-09 11:51:32.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.0009999887782439264 Training loss: 7.393306255340576
2025-12-09 11:51:32.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.00099998664519235 Training loss: 7.434881687164307
2025-12-09 11:51:32.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0009999843266614685 Training loss: 7.8974432945251465
2025-12-09 11:51:32.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0009999818226521416 Training loss: 7.635008811950684
2025-12-09 11:51:32.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.0009999791331652982 Training loss: 8.055465698242188
2025-12-09 11:51:32.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0009999762582019365 Training loss: 7.24473237991333
2025-12-09 11:51:32.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.0009999731977631226 Training loss: 7.380916118621826
2025-12-09 11:51:32.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.0009999699518499921 Training loss: 7.839840888977051
2025-12-09 11:51:32.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0009999665204637486 Training loss: 7.4179887771606445
2025-12-09 11:51:32.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.0009999629036056656 Training loss: 8.006031036376953
2025-12-09 11:51:32.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.0009999591012770847 Training loss: 7.636643886566162
2025-12-09 11:51:32.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.0009999551134794165 Training loss: 7.822427272796631
2025-12-09 11:51:32.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.00099995094021414 Training loss: 7.856200218200684
2025-12-09 11:51:33.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.0009999465814828036 Training loss: 7.578744411468506
2025-12-09 11:51:33.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0009999420372870244 Training loss: 7.76528787612915
2025-12-09 11:51:33.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.0009999373076284876 Training loss: 7.5900750160217285
2025-12-09 11:51:33.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.0009999323925089486 Training loss: 7.537301063537598
2025-12-09 11:51:33.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.00099992729193023 Training loss: 7.551696300506592
2025-12-09 11:51:33.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0009999220058942244 Training loss: 7.406437873840332
2025-12-09 11:51:33.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.0009999165344028926 Training loss: 7.4949140548706055
2025-12-09 11:51:33.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.0009999108774582644 Training loss: 7.546969890594482
2025-12-09 11:51:33.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.0009999050350624381 Training loss: 7.231152057647705
2025-12-09 11:51:33.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0009998990072175814 Training loss: 7.676365375518799
2025-12-09 11:51:33.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.0009998927939259303 Training loss: 7.83461856842041
2025-12-09 11:51:33.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.0009998863951897897 Training loss: 7.45462703704834
2025-12-09 11:51:33.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0009998798110115333 Training loss: 7.449928283691406
2025-12-09 11:51:34.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0009998730413936037 Training loss: 7.587592124938965
2025-12-09 11:51:34.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.0009998660863385124 Training loss: 7.942193508148193
2025-12-09 11:51:34.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.0009998589458488389 Training loss: 7.5614728927612305
2025-12-09 11:51:34.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0009998516199272328 Training loss: 7.629098892211914
2025-12-09 11:51:34.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0009998441085764113 Training loss: 7.191569805145264
2025-12-09 11:51:34.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.0009998364117991612 Training loss: 7.454738140106201
2025-12-09 11:51:34.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0009998285295983375 Training loss: 7.530145168304443
2025-12-09 11:51:34.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.0009998204619768645 Training loss: 7.3579421043396
2025-12-09 11:51:34.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0009998122089377348 Training loss: 7.568492412567139
2025-12-09 11:51:34.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.0009998037704840102 Training loss: 7.078784942626953
2025-12-09 11:51:34.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.000999795146618821 Training loss: 7.527239799499512
2025-12-09 11:51:34.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0009997863373453664 Training loss: 7.4125518798828125
2025-12-09 11:51:35.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.000999777342666914 Training loss: 8.121725082397461
2025-12-09 11:51:35.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0009997681625868013 Training loss: 6.4106035232543945
2025-12-09 11:51:35.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0009997587971084334 Training loss: 7.228321075439453
2025-12-09 11:51:35.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.0009997492462352846 Training loss: 7.257291316986084
2025-12-09 11:51:35.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0009997395099708981 Training loss: 7.843899250030518
2025-12-09 11:51:35.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.0009997295883188856 Training loss: 7.281136512756348
2025-12-09 11:51:35.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.0009997194812829276 Training loss: 7.60674524307251
2025-12-09 11:51:35.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0009997091888667737 Training loss: 7.385125637054443
2025-12-09 11:51:35.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.000999698711074242 Training loss: 7.459008693695068
2025-12-09 11:51:35.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0009996880479092197 Training loss: 7.2276225090026855
2025-12-09 11:51:35.794 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.000999677199375662 Training loss: 7.41578483581543
2025-12-09 11:51:35.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0009996661654775938 Training loss: 7.486680507659912
2025-12-09 11:51:35.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.000999654946219108 Training loss: 7.280094623565674
2025-12-09 11:51:36.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.000999643541604367 Training loss: 7.440861225128174
2025-12-09 11:51:36.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.000999631951637601 Training loss: 7.489818096160889
2025-12-09 11:51:36.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.0009996201763231099 Training loss: 7.283863544464111
2025-12-09 11:51:36.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0009996082156652618 Training loss: 7.087177753448486
2025-12-09 11:51:36.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.000999596069668494 Training loss: 7.390439033508301
2025-12-09 11:51:36.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.000999583738337312 Training loss: 7.402914524078369
2025-12-09 11:51:36.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0009995712216762903 Training loss: 7.2034711837768555
2025-12-09 11:51:36.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.0009995585196900722 Training loss: 7.335602760314941
2025-12-09 11:51:36.662 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.00099954563238337 Training loss: 7.387183666229248
2025-12-09 11:51:36.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0009995325597609644 Training loss: 7.628028869628906
2025-12-09 11:51:36.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.000999519301827705 Training loss: 7.240253448486328
2025-12-09 11:51:36.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0009995058585885095 Training loss: 7.624595642089844
2025-12-09 11:51:36.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.0009994922300483656 Training loss: 7.40614128112793
2025-12-09 11:51:37.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.000999478416212329 Training loss: 6.919980525970459
2025-12-09 11:51:37.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.0009994644170855237 Training loss: 7.418173789978027
2025-12-09 11:51:37.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0009994502326731434 Training loss: 6.885125637054443
2025-12-09 11:51:37.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0009994358629804498 Training loss: 7.238650321960449
2025-12-09 11:51:37.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.0009994213080127738 Training loss: 7.454879283905029
2025-12-09 11:51:37.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.0009994065677755147 Training loss: 7.680546760559082
2025-12-09 11:51:37.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0009993916422741409 Training loss: 7.653872013092041
2025-12-09 11:51:37.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.000999376531514189 Training loss: 7.382719039916992
2025-12-09 11:51:37.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.0009993612355012646 Training loss: 7.311357021331787
2025-12-09 11:51:37.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.0009993457542410422 Training loss: 7.327200412750244
2025-12-09 11:51:37.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.000999330087739265 Training loss: 7.072585582733154
2025-12-09 11:51:37.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0009993142360017445 Training loss: 7.047201633453369
2025-12-09 11:51:38.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.0009992981990343613 Training loss: 7.482344150543213
2025-12-09 11:51:38.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.0009992819768430649 Training loss: 7.1165666580200195
2025-12-09 11:51:38.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0009992655694338725 Training loss: 7.362890720367432
2025-12-09 11:51:38.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.0009992489768128714 Training loss: 7.334911346435547
2025-12-09 11:51:38.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0009992321989862165 Training loss: 7.232119083404541
2025-12-09 11:51:38.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0009992152359601322 Training loss: 7.688632488250732
2025-12-09 11:51:38.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.000999198087740911 Training loss: 7.45456075668335
2025-12-09 11:51:38.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.0009991807543349145 Training loss: 7.181799411773682
2025-12-09 11:51:38.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.000999163235748573 Training loss: 6.350947380065918
2025-12-09 11:51:38.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0009991455319883849 Training loss: 7.700413703918457
2025-12-09 11:51:38.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0009991276430609181 Training loss: 7.11389684677124
2025-12-09 11:51:38.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.0009991095689728087 Training loss: 7.233581066131592
2025-12-09 11:51:38.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0009990913097307613 Training loss: 7.2600417137146
2025-12-09 11:51:39.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0009990728653415503 Training loss: 7.160192489624023
2025-12-09 11:51:39.113 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0009990542358120174 Training loss: 7.145639896392822
2025-12-09 11:51:39.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0009990354211490736 Training loss: 7.343530178070068
2025-12-09 11:51:39.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0009990164213596986 Training loss: 7.627938747406006
2025-12-09 11:51:39.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0009989972364509408 Training loss: 7.511548042297363
2025-12-09 11:51:39.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0009989778664299172 Training loss: 7.482534408569336
2025-12-09 11:51:39.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0009989583113038133 Training loss: 7.164377689361572
2025-12-09 11:51:39.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.0009989385710798837 Training loss: 7.134622573852539
2025-12-09 11:51:39.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.0009989186457654514 Training loss: 7.2337141036987305
2025-12-09 11:51:39.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.0009988985353679076 Training loss: 7.3521318435668945
2025-12-09 11:51:39.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0009988782398947132 Training loss: 7.426117420196533
2025-12-09 11:51:39.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.0009988577593533967 Training loss: 6.904088973999023
2025-12-09 11:51:39.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.000998837093751556 Training loss: 7.401229381561279
2025-12-09 11:51:40.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0009988162430968576 Training loss: 6.890913963317871
2025-12-09 11:51:40.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.000998795207397036 Training loss: 7.136641502380371
2025-12-09 11:51:40.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.000998773986659895 Training loss: 7.210264682769775
2025-12-09 11:51:40.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.0009987525808933069 Training loss: 7.895501613616943
2025-12-09 11:51:40.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0009987309901052122 Training loss: 7.0794782638549805
2025-12-09 11:51:40.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.000998709214303621 Training loss: 7.3572211265563965
2025-12-09 11:51:40.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.000998687253496611 Training loss: 7.09048318862915
2025-12-09 11:51:40.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0009986651076923287 Training loss: 7.007257461547852
2025-12-09 11:51:40.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.0009986427768989903 Training loss: 7.047978401184082
2025-12-09 11:51:40.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0009986202611248793 Training loss: 7.129632472991943
2025-12-09 11:51:40.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0009985975603783483 Training loss: 7.4686598777771
2025-12-09 11:51:40.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.000998574674667819 Training loss: 7.160953998565674
2025-12-09 11:51:41.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0009985516040017807 Training loss: 7.355093002319336
2025-12-09 11:51:41.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.0009985283483887923 Training loss: 6.938874244689941
2025-12-09 11:51:41.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.0009985049078374806 Training loss: 6.823058128356934
2025-12-09 11:51:41.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.0009984812823565416 Training loss: 7.537553787231445
2025-12-09 11:51:41.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0009984574719547395 Training loss: 6.954775333404541
2025-12-09 11:51:41.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.000998433476640907 Training loss: 7.279569625854492
2025-12-09 11:51:41.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0009984092964239462 Training loss: 7.324709415435791
2025-12-09 11:51:41.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.0009983849313128263 Training loss: 6.816145896911621
2025-12-09 11:51:41.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0009983603813165868 Training loss: 7.326923370361328
2025-12-09 11:51:41.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0009983356464443346 Training loss: 7.40024995803833
2025-12-09 11:51:41.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.0009983107267052458 Training loss: 7.733367443084717
2025-12-09 11:51:41.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0009982856221085643 Training loss: 7.488463401794434
2025-12-09 11:51:41.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.0009982603326636036 Training loss: 7.071522235870361
2025-12-09 11:51:42.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0009982348583797453 Training loss: 7.255638599395752
2025-12-09 11:51:42.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.0009982091992664392 Training loss: 6.841793060302734
2025-12-09 11:51:42.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0009981833553332044 Training loss: 7.197299003601074
2025-12-09 11:51:42.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.0009981573265896281 Training loss: 7.038275241851807
2025-12-09 11:51:42.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.000998131113045366 Training loss: 7.064846038818359
2025-12-09 11:51:42.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.0009981047147101425 Training loss: 7.700885772705078
2025-12-09 11:51:42.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.0009980781315937506 Training loss: 7.073884010314941
2025-12-09 11:51:42.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.000998051363706052 Training loss: 7.425408840179443
2025-12-09 11:51:42.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0009980244110569766 Training loss: 7.163933277130127
2025-12-09 11:51:42.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.0009979972736565226 Training loss: 7.391304016113281
2025-12-09 11:51:42.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0009979699515147579 Training loss: 7.262235164642334
2025-12-09 11:51:42.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0009979424446418172 Training loss: 7.219392776489258
2025-12-09 11:51:42.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.0009979147530479056 Training loss: 7.30437707901001
2025-12-09 11:51:43.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0009978868767432953 Training loss: 7.7664031982421875
2025-12-09 11:51:43.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.0009978588157383277 Training loss: 7.360193252563477
2025-12-09 11:51:43.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0009978305700434125 Training loss: 6.925174713134766
2025-12-09 11:51:43.290 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.000997802139669028 Training loss: 7.155736446380615
2025-12-09 11:51:43.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.0009977735246257209 Training loss: 6.662733554840088
2025-12-09 11:51:43.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.0009977447249241065 Training loss: 6.991751194000244
2025-12-09 11:51:43.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.0009977157405748687 Training loss: 7.265401840209961
2025-12-09 11:51:43.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0009976865715887596 Training loss: 8.081013679504395
2025-12-09 11:51:43.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.0009976572179766 Training loss: 6.704558372497559
2025-12-09 11:51:43.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.0009976276797492793 Training loss: 7.59977388381958
2025-12-09 11:51:43.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0009975979569177551 Training loss: 7.2764973640441895
2025-12-09 11:51:43.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0009975680494930539 Training loss: 6.72761344909668
2025-12-09 11:51:44.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00099753795748627 Training loss: 7.1143927574157715
2025-12-09 11:51:44.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0009975076809085669 Training loss: 7.0477447509765625
2025-12-09 11:51:44.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.0009974772197711762 Training loss: 7.247335433959961
2025-12-09 11:51:44.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.000997446574085398 Training loss: 7.2592034339904785
2025-12-09 11:51:44.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0009974157438626008 Training loss: 7.217883586883545
2025-12-09 11:51:44.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.0009973847291142217 Training loss: 7.004995346069336
2025-12-09 11:51:44.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.0009973535298517663 Training loss: 7.26678991317749
2025-12-09 11:51:44.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0009973221460868086 Training loss: 6.7732768058776855
2025-12-09 11:51:44.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.0009972905778309906 Training loss: 6.9399333000183105
2025-12-09 11:51:44.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0009972588250960234 Training loss: 7.2792510986328125
2025-12-09 11:51:44.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.0009972268878936862 Training loss: 7.042610168457031
2025-12-09 11:51:44.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.000997194766235827 Training loss: 7.079411506652832
2025-12-09 11:51:44.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0009971624601343614 Training loss: 7.24458646774292
2025-12-09 11:51:45.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.0009971299696012743 Training loss: 6.88248872756958
2025-12-09 11:51:45.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0009970972946486186 Training loss: 7.1275835037231445
2025-12-09 11:51:45.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.0009970644352885157 Training loss: 7.23030424118042
2025-12-09 11:51:45.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0009970313915331553 Training loss: 5.9850544929504395
2025-12-09 11:51:45.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0009969981633947955 Training loss: 7.189480781555176
2025-12-09 11:51:45.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0009969647508857632 Training loss: 7.276806354522705
2025-12-09 11:51:45.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.000996931154018453 Training loss: 7.428976535797119
2025-12-09 11:51:45.574 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0009968973728053288 Training loss: 7.114479064941406
2025-12-09 11:51:45.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0009968634072589219 Training loss: 7.42476749420166
2025-12-09 11:51:45.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0009968292573918325 Training loss: 6.774590015411377
2025-12-09 11:51:45.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.0009967949232167295 Training loss: 7.080799579620361
2025-12-09 11:51:45.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0009967604047463492 Training loss: 6.852575302124023
2025-12-09 11:51:45.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0009967257019934974 Training loss: 7.379705429077148
2025-12-09 11:51:46.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0009966908149710476 Training loss: 6.946845531463623
2025-12-09 11:51:46.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0009966557436919415 Training loss: 6.958642482757568
2025-12-09 11:51:46.207 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.00099662048816919 Training loss: 7.2441205978393555
2025-12-09 11:51:46.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.000996585048415871 Training loss: 7.296069622039795
2025-12-09 11:51:46.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.0009965494244451323 Training loss: 6.900549411773682
2025-12-09 11:51:46.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0009965136162701888 Training loss: 7.328319549560547
2025-12-09 11:51:46.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0009964776239043244 Training loss: 6.636282444000244
2025-12-09 11:51:46.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.0009964414473608912 Training loss: 6.6749796867370605
2025-12-09 11:51:46.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.0009964050866533092 Training loss: 7.186819553375244
2025-12-09 11:51:46.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.0009963685417950677 Training loss: 7.026028156280518
2025-12-09 11:51:46.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.000996331812799723 Training loss: 7.390953540802002
2025-12-09 11:51:46.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0009962948996809007 Training loss: 7.161046028137207
2025-12-09 11:51:46.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0009962578024522947 Training loss: 6.79483699798584
2025-12-09 11:51:47.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.0009962205211276665 Training loss: 7.042616367340088
2025-12-09 11:51:47.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0009961830557208464 Training loss: 6.725320816040039
2025-12-09 11:51:47.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.000996145406245733 Training loss: 6.895034313201904
2025-12-09 11:51:47.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0009961075727162928 Training loss: 6.762147426605225
2025-12-09 11:51:47.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0009960695551465611 Training loss: 7.215448379516602
2025-12-09 11:51:47.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.000996031353550641 Training loss: 6.986387252807617
2025-12-09 11:51:47.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0009959929679427047 Training loss: 6.179299831390381
2025-12-09 11:51:47.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0009959543983369913 Training loss: 7.039339065551758
2025-12-09 11:51:47.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.000995915644747809 Training loss: 6.293409824371338
2025-12-09 11:51:47.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0009958767071895347 Training loss: 6.663031578063965
2025-12-09 11:51:47.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.0009958375856766127 Training loss: 7.101485729217529
2025-12-09 11:51:47.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0009957982802235555 Training loss: 6.529369354248047
2025-12-09 11:51:48.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0009957587908449449 Training loss: 7.041457653045654
2025-12-09 11:51:48.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.0009957191175554295 Training loss: 6.436420917510986
2025-12-09 11:51:48.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0009956792603697273 Training loss: 6.843862533569336
2025-12-09 11:51:48.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.000995639219302624 Training loss: 6.743094444274902
2025-12-09 11:51:48.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.0009955989943689733 Training loss: 7.01346492767334
2025-12-09 11:51:48.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.0009955585855836978 Training loss: 7.159257888793945
2025-12-09 11:51:48.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0009955179929617875 Training loss: 6.781172752380371
2025-12-09 11:51:48.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.0009954772165183012 Training loss: 7.416774272918701
2025-12-09 11:51:48.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.0009954362562683658 Training loss: 6.740233421325684
2025-12-09 11:51:48.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.000995395112227176 Training loss: 6.697243690490723
2025-12-09 11:51:48.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.000995353784409995 Training loss: 7.148102760314941
2025-12-09 11:51:48.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.0009953122728321542 Training loss: 7.0362443923950195
2025-12-09 11:51:48.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.0009952705775090529 Training loss: 7.517597675323486
2025-12-09 11:51:49.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0009952286984561591 Training loss: 7.0032477378845215
2025-12-09 11:51:49.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0009951866356890083 Training loss: 6.99318790435791
2025-12-09 11:51:49.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.0009951443892232048 Training loss: 6.955536365509033
2025-12-09 11:51:49.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.0009951019590744203 Training loss: 7.104457855224609
2025-12-09 11:51:49.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.0009950593452583952 Training loss: 6.901458263397217
2025-12-09 11:51:49.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.0009950165477909379 Training loss: 7.048079967498779
2025-12-09 11:51:49.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0009949735666879252 Training loss: 6.805939197540283
2025-12-09 11:51:49.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.000994930401965301 Training loss: 7.167198181152344
2025-12-09 11:51:49.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.000994887053639079 Training loss: 6.8956427574157715
2025-12-09 11:51:49.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.0009948435217253394 Training loss: 6.7080206871032715
2025-12-09 11:51:49.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.0009947998062402312 Training loss: 7.784996509552002
2025-12-09 11:51:49.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.000994755907199972 Training loss: 7.21038818359375
2025-12-09 11:51:49.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.0009947118246208461 Training loss: 6.823456764221191
2025-12-09 11:51:50.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.0009946675585192075 Training loss: 7.3321661949157715
2025-12-09 11:51:50.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.0009946231089114773 Training loss: 6.85269832611084
2025-12-09 11:51:50.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.000994578475814145 Training loss: 6.910536766052246
2025-12-09 11:51:50.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.0009945336592437678 Training loss: 6.985767841339111
2025-12-09 11:51:50.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.0009944886592169711 Training loss: 7.095023155212402
2025-12-09 11:51:50.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.000994443475750449 Training loss: 6.90501070022583
2025-12-09 11:51:50.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.000994398108860963 Training loss: 6.746320724487305
2025-12-09 11:51:50.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0009943525585653428 Training loss: 6.5661301612854
2025-12-09 11:51:50.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0009943068248804859 Training loss: 6.880945682525635
2025-12-09 11:51:50.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.000994260907823358 Training loss: 6.765829086303711
2025-12-09 11:51:50.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.0009942148074109933 Training loss: 6.82588529586792
2025-12-09 11:51:50.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.0009941685236604934 Training loss: 7.0103888511657715
2025-12-09 11:51:51.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.0009941220565890278 Training loss: 7.12716007232666
2025-12-09 11:51:51.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.000994075406213835 Training loss: 7.056017875671387
2025-12-09 11:51:51.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.0009940285725522201 Training loss: 7.218402862548828
2025-12-09 11:51:51.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0009939815556215576 Training loss: 6.839756488800049
2025-12-09 11:51:51.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0009939343554392886 Training loss: 6.730384826660156
2025-12-09 11:51:51.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.0009938869720229233 Training loss: 6.677558898925781
2025-12-09 11:51:51.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.0009938394053900395 Training loss: 6.572259902954102
2025-12-09 11:51:51.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0009937916555582827 Training loss: 6.650160789489746
2025-12-09 11:51:51.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.000993743722545367 Training loss: 6.959914684295654
2025-12-09 11:51:51.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.0009936956063690734 Training loss: 6.507190227508545
2025-12-09 11:51:51.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.0009936473070472518 Training loss: 6.928470611572266
2025-12-09 11:51:51.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.0009935988245978198 Training loss: 6.948610305786133
2025-12-09 11:51:51.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0009935501590387628 Training loss: 6.894183158874512
2025-12-09 11:51:52.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.0009935013103881344 Training loss: 6.989917278289795
2025-12-09 11:51:52.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.0009934522786640555 Training loss: 6.2645039558410645
2025-12-09 11:51:52.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.0009934030638847156 Training loss: 6.982326507568359
2025-12-09 11:51:52.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.0009933536660683717 Training loss: 6.986245632171631
2025-12-09 11:51:52.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.0009933040852333488 Training loss: 6.916191101074219
2025-12-09 11:51:52.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.00099325432139804 Training loss: 7.006218910217285
2025-12-09 11:51:52.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.0009932043745809064 Training loss: 6.7732977867126465
2025-12-09 11:51:52.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.000993154244800476 Training loss: 7.092275142669678
2025-12-09 11:51:52.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.0009931039320753457 Training loss: 7.56545877456665
2025-12-09 11:51:52.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.00099305343642418 Training loss: 7.108737468719482
2025-12-09 11:51:52.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.0009930027578657114 Training loss: 6.900667667388916
2025-12-09 11:51:52.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.0009929518964187393 Training loss: 7.073702812194824
2025-12-09 11:51:53.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.0009929008521021325 Training loss: 7.016791820526123
2025-12-09 11:51:53.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.0009928496249348266 Training loss: 6.63998556137085
2025-12-09 11:51:53.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.000992798214935825 Training loss: 6.825158596038818
2025-12-09 11:51:53.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.0009927466221241995 Training loss: 7.141360759735107
2025-12-09 11:51:53.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.0009926948465190893 Training loss: 6.9679083824157715
2025-12-09 11:51:53.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.0009926428881397015 Training loss: 6.575485706329346
2025-12-09 11:51:53.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.0009925907470053111 Training loss: 6.757357120513916
2025-12-09 11:51:53.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.0009925384231352606 Training loss: 7.032236099243164
2025-12-09 11:51:53.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0009924859165489608 Training loss: 7.160279273986816
2025-12-09 11:51:53.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.0009924332272658897 Training loss: 7.830148696899414
2025-12-09 11:51:53.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.0009923803553055937 Training loss: 6.293642044067383
2025-12-09 11:51:53.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.0009923273006876864 Training loss: 6.6729021072387695
2025-12-09 11:51:53.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0009922740634318494 Training loss: 7.0829057693481445
2025-12-09 11:51:54.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.0009922206435578323 Training loss: 6.969257831573486
2025-12-09 11:51:54.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0009921670410854518 Training loss: 7.931784629821777
2025-12-09 11:51:54.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.0009921132560345928 Training loss: 6.6545000076293945
2025-12-09 11:51:54.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.0009920592884252082 Training loss: 7.865242958068848
2025-12-09 11:51:54.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.0009920051382773178 Training loss: 6.95018196105957
2025-12-09 11:51:54.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.00099195080561101 Training loss: 7.871253967285156
2025-12-09 11:51:54.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.0009918962904464407 Training loss: 6.756125450134277
2025-12-09 11:51:54.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.0009918415928038325 Training loss: 6.738308906555176
2025-12-09 11:51:54.662 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.000991786712703477 Training loss: 6.885183334350586
2025-12-09 11:51:54.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.0009917316501657334 Training loss: 6.607789993286133
2025-12-09 11:51:54.819 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0009916764052110274 Training loss: 6.857388019561768
2025-12-09 11:51:54.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.0009916209778598536 Training loss: 7.252175807952881
2025-12-09 11:51:54.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.0009915653681327736 Training loss: 6.903665542602539
2025-12-09 11:51:55.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.000991509576050417 Training loss: 6.971885681152344
2025-12-09 11:51:55.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.0009914536016334807 Training loss: 6.892545700073242
2025-12-09 11:51:55.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.0009913974449027297 Training loss: 6.945133686065674
2025-12-09 11:51:55.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.0009913411058789963 Training loss: 7.146856784820557
2025-12-09 11:51:55.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.0009912845845831805 Training loss: 6.92061185836792
2025-12-09 11:51:55.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.00099122788103625 Training loss: 6.670114040374756
2025-12-09 11:51:55.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.0009911709952592396 Training loss: 6.7619452476501465
2025-12-09 11:51:55.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.0009911139272732526 Training loss: 6.811689376831055
2025-12-09 11:51:55.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.0009910566770994593 Training loss: 7.168585777282715
2025-12-09 11:51:55.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.0009909992447590978 Training loss: 6.883388519287109
2025-12-09 11:51:55.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.0009909416302734736 Training loss: 6.835016250610352
2025-12-09 11:51:55.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.0009908838336639598 Training loss: 6.904512405395508
2025-12-09 11:51:56.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.000990825854951997 Training loss: 7.363039493560791
2025-12-09 11:51:56.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0009907676941590937 Training loss: 6.936519145965576
2025-12-09 11:51:56.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.0009907093513068259 Training loss: 7.142208099365234
2025-12-09 11:51:56.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.0009906508264168365 Training loss: 6.89478063583374
2025-12-09 11:51:56.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.0009905921195108368 Training loss: 7.276890277862549
2025-12-09 11:51:56.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.0009905332306106049 Training loss: 6.550714492797852
2025-12-09 11:51:56.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.000990474159737987 Training loss: 6.712150573730469
2025-12-09 11:51:56.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.0009904149069148963 Training loss: 7.3846540451049805
2025-12-09 11:51:56.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.000990355472163314 Training loss: 6.476271629333496
2025-12-09 11:51:56.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.0009902958555052881 Training loss: 7.377499103546143
2025-12-09 11:51:56.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.0009902360569629348 Training loss: 6.6583075523376465
2025-12-09 11:51:56.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.0009901760765584375 Training loss: 6.700573444366455
2025-12-09 11:51:56.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.000990115914314047 Training loss: 5.976311206817627
2025-12-09 11:51:57.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.0009900555702520816 Training loss: 7.150786399841309
2025-12-09 11:51:57.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.000989995044394927 Training loss: 6.73225212097168
2025-12-09 11:51:57.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0009899343367650365 Training loss: 6.670076847076416
2025-12-09 11:51:57.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0009898734473849304 Training loss: 7.647069454193115
2025-12-09 11:51:57.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.0009898123762771972 Training loss: 5.945245265960693
2025-12-09 11:51:57.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.000989751123464492 Training loss: 6.411357402801514
2025-12-09 11:51:57.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.0009896896889695376 Training loss: 6.578622341156006
2025-12-09 11:51:57.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0009896280728151248 Training loss: 6.572342395782471
2025-12-09 11:51:57.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.0009895662750241108 Training loss: 6.766505718231201
2025-12-09 11:51:57.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.0009895042956194209 Training loss: 6.690927505493164
2025-12-09 11:51:57.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.0009894421346240473 Training loss: 7.558456897735596
2025-12-09 11:51:57.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.0009893797920610496 Training loss: 6.825039863586426
2025-12-09 11:51:57.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.0009893172679535552 Training loss: 6.766757965087891
2025-12-09 11:51:58.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.0009892545623247585 Training loss: 5.7365899085998535
2025-12-09 11:51:58.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.0009891916751979218 Training loss: 6.800753116607666
2025-12-09 11:51:58.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.0009891286065963733 Training loss: 7.029073238372803
2025-12-09 11:51:58.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0009890653565435101 Training loss: 6.892744541168213
2025-12-09 11:51:58.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.0009890019250627959 Training loss: 6.657166004180908
2025-12-09 11:51:58.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.0009889383121777617 Training loss: 6.617234230041504
2025-12-09 11:51:58.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.000988874517912006 Training loss: 7.366568088531494
2025-12-09 11:51:58.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.0009888105422891941 Training loss: 6.510559558868408
2025-12-09 11:51:58.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0009887463853330593 Training loss: 6.6148810386657715
2025-12-09 11:51:58.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.000988682047067402 Training loss: 6.807354927062988
2025-12-09 11:51:58.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.000988617527516089 Training loss: 7.1765360832214355
2025-12-09 11:51:58.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.0009885528267030556 Training loss: 6.882092475891113
2025-12-09 11:51:59.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.0009884879446523036 Training loss: 6.561547756195068
2025-12-09 11:51:59.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.000988422881387902 Training loss: 6.449665069580078
2025-12-09 11:51:59.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.0009883576369339876 Training loss: 6.825136184692383
2025-12-09 11:51:59.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.0009882922113147636 Training loss: 6.908268928527832
2025-12-09 11:51:59.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.0009882266045545011 Training loss: 6.483221054077148
2025-12-09 11:51:59.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.0009881608166775384 Training loss: 6.835115909576416
2025-12-09 11:51:59.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.0009880948477082802 Training loss: 7.337255954742432
2025-12-09 11:51:59.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.0009880286976711992 Training loss: 6.579277515411377
2025-12-09 11:51:59.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.000987962366590835 Training loss: 6.672330379486084
2025-12-09 11:51:59.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.0009878958544917943 Training loss: 6.909595966339111
2025-12-09 11:51:59.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.0009878291613987509 Training loss: 6.81238317489624
2025-12-09 11:51:59.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.000987762287336446 Training loss: 7.144858360290527
2025-12-09 11:51:59.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.0009876952323296876 Training loss: 6.846282005310059
2025-12-09 11:52:00.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.0009876279964033511 Training loss: 5.952789306640625
2025-12-09 11:52:00.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.000987560579582379 Training loss: 6.963839530944824
2025-12-09 11:52:00.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.0009874929818917805 Training loss: 6.421079635620117
2025-12-09 11:52:00.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.0009874252033566326 Training loss: 7.02928352355957
2025-12-09 11:52:00.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.000987357244002079 Training loss: 6.621415615081787
2025-12-09 11:52:00.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.00098728910385333 Training loss: 6.480269432067871
2025-12-09 11:52:00.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.000987220782935664 Training loss: 6.810269832611084
2025-12-09 11:52:00.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.0009871522812744257 Training loss: 6.870401382446289
2025-12-09 11:52:00.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.0009870835988950268 Training loss: 5.766815185546875
2025-12-09 11:52:00.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.0009870147358229467 Training loss: 6.900834560394287
2025-12-09 11:52:00.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.0009869456920837312 Training loss: 7.588132858276367
2025-12-09 11:52:00.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.0009868764677029933 Training loss: 6.581240653991699
2025-12-09 11:52:00.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.0009868070627064133 Training loss: 6.702206134796143
2025-12-09 11:52:01.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.0009867374771197384 Training loss: 6.957586288452148
2025-12-09 11:52:01.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.0009866677109687822 Training loss: 6.612452507019043
2025-12-09 11:52:01.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.0009865977642794259 Training loss: 7.321042537689209
2025-12-09 11:52:01.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.0009865276370776177 Training loss: 6.948735237121582
2025-12-09 11:52:01.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.0009864573293893724 Training loss: 6.7049994468688965
2025-12-09 11:52:01.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.000986386841240772 Training loss: 6.51460075378418
2025-12-09 11:52:01.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0009863161726579655 Training loss: 7.0079474449157715
2025-12-09 11:52:01.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0009862453236671685 Training loss: 6.53166389465332
2025-12-09 11:52:01.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.000986174294294664 Training loss: 6.432826519012451
2025-12-09 11:52:01.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.0009861030845668014 Training loss: 6.7371931076049805
2025-12-09 11:52:01.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.0009860316945099973 Training loss: 6.665563106536865
2025-12-09 11:52:01.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0009859601241507354 Training loss: 6.6064300537109375
2025-12-09 11:52:02.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.0009858883735155658 Training loss: 6.750744342803955
2025-12-09 11:52:02.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.0009858164426311058 Training loss: 6.788314342498779
2025-12-09 11:52:02.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.0009857443315240395 Training loss: 6.785475730895996
2025-12-09 11:52:02.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.000985672040221118 Training loss: 6.284713268280029
2025-12-09 11:52:02.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.000985599568749159 Training loss: 6.744259357452393
2025-12-09 11:52:02.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.000985526917135047 Training loss: 7.025311470031738
2025-12-09 11:52:02.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.0009854540854057337 Training loss: 6.625792503356934
2025-12-09 11:52:02.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.000985381073588237 Training loss: 6.552813529968262
2025-12-09 11:52:02.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.0009853078817096423 Training loss: 5.741100788116455
2025-12-09 11:52:02.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.0009852345097971016 Training loss: 6.637726306915283
2025-12-09 11:52:02.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.0009851609578778332 Training loss: 5.639307022094727
2025-12-09 11:52:02.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0009850872259791227 Training loss: 6.932079315185547
2025-12-09 11:52:02.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.0009850133141283226 Training loss: 6.503615379333496
2025-12-09 11:52:03.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.0009849392223528514 Training loss: 6.5893731117248535
2025-12-09 11:52:03.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.000984864950680195 Training loss: 6.978758811950684
2025-12-09 11:52:03.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.000984790499137906 Training loss: 6.826613426208496
2025-12-09 11:52:03.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.0009847158677536033 Training loss: 6.880680084228516
2025-12-09 11:52:03.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.000984641056554973 Training loss: 6.36993408203125
2025-12-09 11:52:03.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.0009845660655697678 Training loss: 6.75480842590332
2025-12-09 11:52:03.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.0009844908948258067 Training loss: 6.621576309204102
2025-12-09 11:52:03.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.000984415544350976 Training loss: 6.542632102966309
2025-12-09 11:52:03.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.000984340014173228 Training loss: 6.983783721923828
2025-12-09 11:52:03.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.0009842643043205823 Training loss: 6.986233234405518
2025-12-09 11:52:03.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.0009841884148211247 Training loss: 6.875463485717773
2025-12-09 11:52:03.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.000984112345703008 Training loss: 6.616977214813232
2025-12-09 11:52:03.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.000984036096994451 Training loss: 6.789614200592041
2025-12-09 11:52:04.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.0009839596687237402 Training loss: 6.713520050048828
2025-12-09 11:52:04.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.0009838830609192278 Training loss: 6.673980236053467
2025-12-09 11:52:04.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.0009838062736093327 Training loss: 6.586526393890381
2025-12-09 11:52:04.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.0009837293068225407 Training loss: 7.0136189460754395
2025-12-09 11:52:04.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0009836521605874043 Training loss: 6.368414878845215
2025-12-09 11:52:04.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0009835748349325422 Training loss: 6.755921363830566
2025-12-09 11:52:04.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.0009834973298866393 Training loss: 6.926650047302246
2025-12-09 11:52:04.623 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.0009834196454784484 Training loss: 6.647897720336914
2025-12-09 11:52:04.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.0009833417817367873 Training loss: 6.856756210327148
2025-12-09 11:52:04.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.0009832637386905413 Training loss: 5.533633232116699
2025-12-09 11:52:04.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.0009831855163686617 Training loss: 6.666781425476074
2025-12-09 11:52:04.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.0009831071148001668 Training loss: 6.9459357261657715
2025-12-09 11:52:05.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.0009830285340141408 Training loss: 6.434450626373291
2025-12-09 11:52:05.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.0009829497740397348 Training loss: 6.810899257659912
2025-12-09 11:52:05.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.0009828708349061664 Training loss: 6.651659965515137
2025-12-09 11:52:05.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.0009827917166427196 Training loss: 6.572650909423828
2025-12-09 11:52:05.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.0009827124192787445 Training loss: 6.673948764801025
2025-12-09 11:52:05.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.000982632942843658 Training loss: 6.724452018737793
2025-12-09 11:52:05.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.0009825532873669433 Training loss: 7.096714973449707
2025-12-09 11:52:05.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0009824734528781505 Training loss: 6.515838146209717
2025-12-09 11:52:05.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.0009823934394068952 Training loss: 6.52962589263916
2025-12-09 11:52:05.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.0009823132469828602 Training loss: 6.5333123207092285
2025-12-09 11:52:05.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.000982232875635794 Training loss: 6.782810688018799
2025-12-09 11:52:05.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.0009821523253955122 Training loss: 6.419739246368408
2025-12-09 11:52:05.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.0009820715962918964 Training loss: 6.1019511222839355
2025-12-09 11:52:06.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.0009819906883548942 Training loss: 6.6626176834106445
2025-12-09 11:52:06.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.0009819096016145203 Training loss: 6.773568153381348
2025-12-09 11:52:06.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.000981828336100855 Training loss: 6.694509506225586
2025-12-09 11:52:06.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.0009817468918440454 Training loss: 6.718832969665527
2025-12-09 11:52:06.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.0009816652688743048 Training loss: 6.605858325958252
2025-12-09 11:52:06.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.0009815834672219127 Training loss: 6.849700450897217
2025-12-09 11:52:06.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.000981501486917215 Training loss: 6.502627849578857
2025-12-09 11:52:06.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.0009814193279906237 Training loss: 6.510743618011475
2025-12-09 11:52:06.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.000981336990472617 Training loss: 6.667941093444824
2025-12-09 11:52:06.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.00098125447439374 Training loss: 6.51879358291626
2025-12-09 11:52:06.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.0009811717797846033 Training loss: 6.515448093414307
2025-12-09 11:52:06.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.000981088906675884 Training loss: 7.43242883682251
2025-12-09 11:52:06.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0009810058550983253 Training loss: 7.302944183349609
2025-12-09 11:52:07.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.000980922625082737 Training loss: 7.089668273925781
2025-12-09 11:52:07.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.0009808392166599947 Training loss: 7.011878490447998
2025-12-09 11:52:07.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.0009807556298610403 Training loss: 6.866997718811035
2025-12-09 11:52:07.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.0009806718647168817 Training loss: 7.422089576721191
2025-12-09 11:52:07.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.0009805879212585933 Training loss: 6.9496283531188965
2025-12-09 11:52:07.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.0009805037995173154 Training loss: 7.184122562408447
2025-12-09 11:52:07.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.0009804194995242548 Training loss: 6.733880996704102
2025-12-09 11:52:07.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.0009803350213106836 Training loss: 6.7290449142456055
2025-12-09 11:52:07.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.000980250364907941 Training loss: 7.206080913543701
2025-12-09 11:52:07.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.0009801655303474318 Training loss: 6.761326789855957
2025-12-09 11:52:07.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.000980080517660627 Training loss: 7.296800136566162
2025-12-09 11:52:07.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.0009799953268790633 Training loss: 6.8048601150512695
2025-12-09 11:52:08.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.000979909958034344 Training loss: 6.765054702758789
2025-12-09 11:52:08.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.0009798244111581382 Training loss: 5.859954833984375
2025-12-09 11:52:08.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.0009797386862821812 Training loss: 6.723474502563477
2025-12-09 11:52:08.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.0009796527834382745 Training loss: 6.501086235046387
2025-12-09 11:52:08.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.0009795667026582847 Training loss: 6.523150444030762
2025-12-09 11:52:08.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.0009794804439741454 Training loss: 7.358277797698975
2025-12-09 11:52:08.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.000979394007417856 Training loss: 6.227413177490234
2025-12-09 11:52:08.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.0009793073930214817 Training loss: 6.898776054382324
2025-12-09 11:52:08.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.0009792206008171535 Training loss: 6.729556083679199
2025-12-09 11:52:08.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.0009791336308370687 Training loss: 6.8226189613342285
2025-12-09 11:52:08.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.0009790464831134903 Training loss: 6.6291375160217285
2025-12-09 11:52:08.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.0009789591576787476 Training loss: 6.760313034057617
2025-12-09 11:52:08.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.0009788716545652352 Training loss: 6.587923526763916
2025-12-09 11:52:09.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.0009787839738054146 Training loss: 7.269969940185547
2025-12-09 11:52:09.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.0009786961154318121 Training loss: 6.610448360443115
2025-12-09 11:52:09.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.0009786080794770206 Training loss: 6.912668228149414
2025-12-09 11:52:09.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.0009785198659736987 Training loss: 6.706114768981934
2025-12-09 11:52:09.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.0009784314749545706 Training loss: 7.382993221282959
2025-12-09 11:52:09.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.0009783429064524269 Training loss: 7.256167888641357
2025-12-09 11:52:09.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.0009782541605001234 Training loss: 6.628358364105225
2025-12-09 11:52:09.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.0009781652371305826 Training loss: 6.502195358276367
2025-12-09 11:52:09.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.0009780761363767914 Training loss: 6.813991069793701
2025-12-09 11:52:09.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.000977986858271804 Training loss: 7.088616847991943
2025-12-09 11:52:09.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.0009778974028487398 Training loss: 6.6760125160217285
2025-12-09 11:52:09.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.0009778077701407836 Training loss: 6.865967273712158
2025-12-09 11:52:10.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.0009777179601811866 Training loss: 6.940196990966797
2025-12-09 11:52:10.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.0009776279730032654 Training loss: 6.768579483032227
2025-12-09 11:52:10.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.0009775378086404024 Training loss: 6.609304904937744
2025-12-09 11:52:10.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.0009774474671260455 Training loss: 6.851918697357178
2025-12-09 11:52:10.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.000977356948493709 Training loss: 6.544038772583008
2025-12-09 11:52:10.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.000977266252776972 Training loss: 6.5261640548706055
2025-12-09 11:52:10.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.0009771753800094803 Training loss: 6.965754985809326
2025-12-09 11:52:10.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0009770843302249442 Training loss: 6.5921454429626465
2025-12-09 11:52:10.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.0009769931034571409 Training loss: 6.681338310241699
2025-12-09 11:52:10.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.0009769016997399121 Training loss: 6.915383815765381
2025-12-09 11:52:10.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.000976810119107166 Training loss: 6.7612690925598145
2025-12-09 11:52:10.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.0009767183615928764 Training loss: 7.09173583984375
2025-12-09 11:52:10.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.000976626427231082 Training loss: 6.5589518547058105
2025-12-09 11:52:11.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.0009765343160558879 Training loss: 7.1286940574646
2025-12-09 11:52:11.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.0009764420281014641 Training loss: 6.634679794311523
2025-12-09 11:52:11.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.0009763495634020466 Training loss: 7.143068790435791
2025-12-09 11:52:11.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0009762569219919371 Training loss: 6.486456394195557
2025-12-09 11:52:11.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.0009761641039055025 Training loss: 7.033620357513428
2025-12-09 11:52:11.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.0009760711091771755 Training loss: 6.618304252624512
2025-12-09 11:52:11.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.0009759779378414542 Training loss: 7.13875675201416
2025-12-09 11:52:11.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.0009758845899329021 Training loss: 6.769988059997559
2025-12-09 11:52:11.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.0009757910654861482 Training loss: 6.95413875579834
2025-12-09 11:52:11.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.0009756973645358876 Training loss: 6.866994857788086
2025-12-09 11:52:11.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.0009756034871168799 Training loss: 6.396811008453369
2025-12-09 11:52:11.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.0009755094332639511 Training loss: 7.147069454193115
2025-12-09 11:52:11.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.0009754152030119921 Training loss: 6.616905212402344
2025-12-09 11:52:12.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.0009753207963959591 Training loss: 6.705846786499023
2025-12-09 11:52:12.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.0009752262134508741 Training loss: 6.555948734283447
2025-12-09 11:52:12.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.0009751314542118246 Training loss: 6.6627516746521
2025-12-09 11:52:12.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0009750365187139631 Training loss: 6.69158935546875
2025-12-09 11:52:12.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0009749414069925077 Training loss: 6.806446075439453
2025-12-09 11:52:12.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.0009748461190827421 Training loss: 6.566777229309082
2025-12-09 11:52:12.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.0009747506550200146 Training loss: 6.478417873382568
2025-12-09 11:52:12.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.0009746550148397397 Training loss: 7.002801418304443
2025-12-09 11:52:12.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.0009745591985773971 Training loss: 6.7762131690979
2025-12-09 11:52:12.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0009744632062685312 Training loss: 6.729636192321777
2025-12-09 11:52:12.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.0009743670379487523 Training loss: 7.427866458892822
2025-12-09 11:52:12.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.0009742706936537357 Training loss: 6.64093017578125
2025-12-09 11:52:13.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.0009741741734192224 Training loss: 6.510167598724365
2025-12-09 11:52:13.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.0009740774772810182 Training loss: 8.304248809814453
2025-12-09 11:52:13.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.0009739806052749942 Training loss: 6.930253982543945
2025-12-09 11:52:13.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.0009738835574370871 Training loss: 6.767945766448975
2025-12-09 11:52:13.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.0009737863338032984 Training loss: 7.151718616485596
2025-12-09 11:52:13.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.0009736889344096951 Training loss: 6.902523040771484
2025-12-09 11:52:13.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.0009735913592924093 Training loss: 6.4863972663879395
2025-12-09 11:52:13.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.0009734936084876383 Training loss: 6.6821980476379395
2025-12-09 11:52:13.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.0009733956820316443 Training loss: 7.218986511230469
2025-12-09 11:52:13.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.0009732975799607554 Training loss: 6.480556964874268
2025-12-09 11:52:13.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.0009731993023113641 Training loss: 6.656052112579346
2025-12-09 11:52:13.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.0009731008491199284 Training loss: 6.812138557434082
2025-12-09 11:52:13.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0009730022204229714 Training loss: 6.7952423095703125
2025-12-09 11:52:14.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0009729034162570811 Training loss: 6.973319053649902
2025-12-09 11:52:14.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.0009728044366589108 Training loss: 6.47096586227417
2025-12-09 11:52:14.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.0009727052816651788 Training loss: 6.630427360534668
2025-12-09 11:52:14.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.0009726059513126685 Training loss: 6.596108436584473
2025-12-09 11:52:14.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.0009725064456382282 Training loss: 6.998650550842285
2025-12-09 11:52:14.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.0009724067646787717 Training loss: 6.88342809677124
2025-12-09 11:52:14.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0009723069084712771 Training loss: 6.634810447692871
2025-12-09 11:52:14.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.0009722068770527882 Training loss: 6.842645168304443
2025-12-09 11:52:14.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.0009721066704604133 Training loss: 6.6019673347473145
2025-12-09 11:52:14.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0009720062887313262 Training loss: 7.210868835449219
2025-12-09 11:52:14.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.000971905731902765 Training loss: 6.7473464012146
2025-12-09 11:52:14.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.0009718050000120333 Training loss: 6.5270538330078125
2025-12-09 11:52:14.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.0009717040930964996 Training loss: 6.493133068084717
2025-12-09 11:52:15.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.0009716030111935968 Training loss: 6.478216648101807
2025-12-09 11:52:15.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.0009715017543408234 Training loss: 6.97568416595459
2025-12-09 11:52:15.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0009714003225757424 Training loss: 6.112094879150391
2025-12-09 11:52:15.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.0009712987159359818 Training loss: 6.8926591873168945
2025-12-09 11:52:15.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.0009711969344592346 Training loss: 6.619769096374512
2025-12-09 11:52:15.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.0009710949781832585 Training loss: 6.339425563812256
2025-12-09 11:52:15.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.0009709928471458759 Training loss: 7.685328483581543
2025-12-09 11:52:15.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.0009708905413849743 Training loss: 6.851472854614258
2025-12-09 11:52:15.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0009707880609385058 Training loss: 7.002781867980957
2025-12-09 11:52:15.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.0009706854058444876 Training loss: 6.621540546417236
2025-12-09 11:52:15.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0009705825761410014 Training loss: 5.927811145782471
2025-12-09 11:52:15.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.0009704795718661938 Training loss: 7.565091609954834
2025-12-09 11:52:16.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.000970376393058276 Training loss: 6.860670566558838
2025-12-09 11:52:16.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.0009702730397555246 Training loss: 6.82455587387085
2025-12-09 11:52:16.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.0009701695119962799 Training loss: 6.646599769592285
2025-12-09 11:52:16.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.0009700658098189476 Training loss: 6.656980991363525
2025-12-09 11:52:16.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.0009699619332619979 Training loss: 6.3064494132995605
2025-12-09 11:52:16.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.0009698578823639658 Training loss: 6.761999130249023
2025-12-09 11:52:16.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.0009697536571634509 Training loss: 6.473255157470703
2025-12-09 11:52:16.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.0009696492576991174 Training loss: 7.0078206062316895
2025-12-09 11:52:16.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.0009695446840096944 Training loss: 6.794955730438232
2025-12-09 11:52:16.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.0009694399361339751 Training loss: 6.62446928024292
2025-12-09 11:52:16.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0009693350141108182 Training loss: 6.688542366027832
2025-12-09 11:52:16.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.000969229917979146 Training loss: 6.031070232391357
2025-12-09 11:52:16.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.000969124647777946 Training loss: 6.669424533843994
2025-12-09 11:52:17.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.0009690192035462701 Training loss: 6.504159450531006
2025-12-09 11:52:17.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.0009689135853232349 Training loss: 6.768467426300049
2025-12-09 11:52:17.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.0009688077931480212 Training loss: 6.855185508728027
2025-12-09 11:52:17.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.0009687018270598749 Training loss: 6.874655246734619
2025-12-09 11:52:17.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.0009685956870981059 Training loss: 6.906521797180176
2025-12-09 11:52:17.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.0009684893733020888 Training loss: 6.6745195388793945
2025-12-09 11:52:17.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.0009683828857112626 Training loss: 7.301733016967773
2025-12-09 11:52:17.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.0009682762243651309 Training loss: 6.5985918045043945
2025-12-09 11:52:17.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.0009681693893032617 Training loss: 6.90736722946167
2025-12-09 11:52:17.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.0009680623805652876 Training loss: 6.889953136444092
2025-12-09 11:52:17.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.0009679551981909053 Training loss: 6.483595371246338
2025-12-09 11:52:17.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.000967847842219876 Training loss: 6.534161567687988
2025-12-09 11:52:17.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.0009677403126920255 Training loss: 6.636340618133545
2025-12-09 11:52:18.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.0009676326096472441 Training loss: 6.538378715515137
2025-12-09 11:52:18.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.0009675247331254858 Training loss: 6.704431533813477
2025-12-09 11:52:18.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.0009674166831667697 Training loss: 7.3016886711120605
2025-12-09 11:52:18.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.0009673084598111788 Training loss: 6.827404022216797
2025-12-09 11:52:18.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.0009672000630988605 Training loss: 6.503829479217529
2025-12-09 11:52:18.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.0009670914930700268 Training loss: 6.953782081604004
2025-12-09 11:52:18.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.0009669827497649536 Training loss: 6.46366024017334
2025-12-09 11:52:18.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.0009668738332239813 Training loss: 6.5514302253723145
2025-12-09 11:52:18.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.0009667647434875144 Training loss: 6.568504333496094
2025-12-09 11:52:18.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.0009666554805960219 Training loss: 7.155602931976318
2025-12-09 11:52:18.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.0009665460445900368 Training loss: 7.051901340484619
2025-12-09 11:52:18.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.0009664364355101565 Training loss: 6.361676216125488
2025-12-09 11:52:19.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.0009663266533970423 Training loss: 6.632541656494141
2025-12-09 11:52:19.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.0009662166982914202 Training loss: 6.462021827697754
2025-12-09 11:52:19.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.00096610657023408 Training loss: 6.400888442993164
2025-12-09 11:52:19.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.0009659962692658757 Training loss: 6.400732040405273
2025-12-09 11:52:19.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.0009658857954277254 Training loss: 6.878224849700928
2025-12-09 11:52:19.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.0009657751487606115 Training loss: 6.444714069366455
2025-12-09 11:52:19.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.0009656643293055805 Training loss: 6.591592788696289
2025-12-09 11:52:19.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.0009655533371037426 Training loss: 6.751415729522705
2025-12-09 11:52:19.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.0009654421721962729 Training loss: 6.570725917816162
