2025-12-09 11:47:21.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 12.058746337890625
2025-12-09 11:47:21.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 12.047463417053223
2025-12-09 11:47:21.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 12.040019989013672
2025-12-09 11:47:21.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 12.021944046020508
2025-12-09 11:47:21.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 12.031246185302734
2025-12-09 11:47:21.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 12.065295219421387
2025-12-09 11:47:22.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 12.00881576538086
2025-12-09 11:47:22.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 12.023128509521484
2025-12-09 11:47:22.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 12.00207233428955
2025-12-09 11:47:22.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 12.027674674987793
2025-12-09 11:47:22.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 11.999529838562012
2025-12-09 11:47:22.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 11.977723121643066
2025-12-09 11:47:22.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 11.976625442504883
2025-12-09 11:47:22.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 11.928468704223633
2025-12-09 11:47:22.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 11.920300483703613
2025-12-09 11:47:22.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 11.904302597045898
2025-12-09 11:47:22.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 11.901408195495605
2025-12-09 11:47:22.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 11.890891075134277
2025-12-09 11:47:22.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 11.88991928100586
2025-12-09 11:47:23.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 11.795872688293457
2025-12-09 11:47:23.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 11.813419342041016
2025-12-09 11:47:23.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 11.757567405700684
2025-12-09 11:47:23.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 11.680413246154785
2025-12-09 11:47:23.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 11.652056694030762
2025-12-09 11:47:23.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 11.578988075256348
2025-12-09 11:47:23.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 11.663060188293457
2025-12-09 11:47:23.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 11.465970039367676
2025-12-09 11:47:23.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 11.491703987121582
2025-12-09 11:47:23.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 11.419609069824219
2025-12-09 11:47:23.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 11.319672584533691
2025-12-09 11:47:23.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 11.361021995544434
2025-12-09 11:47:23.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 11.285365104675293
2025-12-09 11:47:24.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 11.262641906738281
2025-12-09 11:47:24.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 11.219244956970215
2025-12-09 11:47:24.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 11.242781639099121
2025-12-09 11:47:24.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 11.137950897216797
2025-12-09 11:47:24.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 11.181000709533691
2025-12-09 11:47:24.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 11.154083251953125
2025-12-09 11:47:24.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 11.084664344787598
2025-12-09 11:47:24.677 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 11.035626411437988
2025-12-09 11:47:24.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 11.105875015258789
2025-12-09 11:47:24.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 11.026712417602539
2025-12-09 11:47:24.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 11.002145767211914
2025-12-09 11:47:24.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 10.960858345031738
2025-12-09 11:47:25.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 10.909406661987305
2025-12-09 11:47:25.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 10.91308307647705
2025-12-09 11:47:25.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 10.853530883789062
2025-12-09 11:47:25.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 10.888113021850586
2025-12-09 11:47:25.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 10.8202486038208
2025-12-09 11:47:25.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 10.823427200317383
2025-12-09 11:47:25.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 10.817632675170898
2025-12-09 11:47:25.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 10.772550582885742
2025-12-09 11:47:25.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 10.883918762207031
2025-12-09 11:47:25.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 10.823238372802734
2025-12-09 11:47:25.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 10.739999771118164
2025-12-09 11:47:25.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 10.612144470214844
2025-12-09 11:47:26.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 10.666644096374512
2025-12-09 11:47:26.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 10.70080280303955
2025-12-09 11:47:26.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 10.557497024536133
2025-12-09 11:47:26.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 10.502692222595215
2025-12-09 11:47:26.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 10.566631317138672
2025-12-09 11:47:26.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 10.496646881103516
2025-12-09 11:47:26.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 10.380380630493164
2025-12-09 11:47:26.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 10.398892402648926
2025-12-09 11:47:26.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 10.314779281616211
2025-12-09 11:47:26.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 10.539515495300293
2025-12-09 11:47:26.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 10.394402503967285
2025-12-09 11:47:26.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 10.577799797058105
2025-12-09 11:47:26.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 10.333544731140137
2025-12-09 11:47:27.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 10.443134307861328
2025-12-09 11:47:27.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 10.184123039245605
2025-12-09 11:47:27.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 10.223897933959961
2025-12-09 11:47:27.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 10.23540210723877
2025-12-09 11:47:27.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 10.014187812805176
2025-12-09 11:47:27.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 9.85098648071289
2025-12-09 11:47:27.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 9.939727783203125
2025-12-09 11:47:27.574 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 9.839680671691895
2025-12-09 11:47:27.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 9.80948543548584
2025-12-09 11:47:27.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 9.836109161376953
2025-12-09 11:47:27.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 9.646668434143066
2025-12-09 11:47:27.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 9.714461326599121
2025-12-09 11:47:27.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 9.672624588012695
2025-12-09 11:47:28.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 9.733128547668457
2025-12-09 11:47:28.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 9.54235553741455
2025-12-09 11:47:28.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 9.392038345336914
2025-12-09 11:47:28.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 9.572073936462402
2025-12-09 11:47:28.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 9.536100387573242
2025-12-09 11:47:28.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 9.174680709838867
2025-12-09 11:47:28.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 9.480826377868652
2025-12-09 11:47:28.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 9.246331214904785
2025-12-09 11:47:28.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 9.303801536560059
2025-12-09 11:47:28.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 9.311644554138184
2025-12-09 11:47:28.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 9.229165077209473
2025-12-09 11:47:28.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 9.218422889709473
2025-12-09 11:47:28.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 9.539928436279297
2025-12-09 11:47:29.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 9.035710334777832
2025-12-09 11:47:29.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 8.963011741638184
2025-12-09 11:47:29.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 9.026657104492188
2025-12-09 11:47:29.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 8.738920211791992
2025-12-09 11:47:29.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 8.914459228515625
2025-12-09 11:47:29.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.999999072578703e-05 Training loss: 8.772466659545898
2025-12-09 11:47:29.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 9.999996290315153e-05 Training loss: 8.583992958068848
2025-12-09 11:47:29.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 9.999991653210385e-05 Training loss: 8.858194351196289
2025-12-09 11:47:29.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 9.999985161266117e-05 Training loss: 8.779383659362793
2025-12-09 11:47:29.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 9.999976814484758e-05 Training loss: 9.296645164489746
2025-12-09 11:47:29.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 9.999966612869405e-05 Training loss: 8.78957748413086
2025-12-09 11:47:29.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 9.999954556423843e-05 Training loss: 8.651520729064941
2025-12-09 11:47:30.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 9.999940645152541e-05 Training loss: 9.349114418029785
2025-12-09 11:47:30.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 9.999924879060665e-05 Training loss: 8.576260566711426
2025-12-09 11:47:30.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 9.999907258154059e-05 Training loss: 8.531791687011719
2025-12-09 11:47:30.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 9.999887782439263e-05 Training loss: 8.679030418395996
2025-12-09 11:47:30.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 9.999866451923501e-05 Training loss: 8.676392555236816
2025-12-09 11:47:30.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 9.999843266614685e-05 Training loss: 8.471203804016113
2025-12-09 11:47:30.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 9.999818226521415e-05 Training loss: 8.759708404541016
2025-12-09 11:47:30.547 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 9.999791331652984e-05 Training loss: 8.160985946655273
2025-12-09 11:47:30.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 9.999762582019365e-05 Training loss: 8.373709678649902
2025-12-09 11:47:30.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 9.999731977631227e-05 Training loss: 8.332498550415039
2025-12-09 11:47:30.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 9.999699518499921e-05 Training loss: 8.683293342590332
2025-12-09 11:47:30.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 9.999665204637487e-05 Training loss: 8.186853408813477
2025-12-09 11:47:30.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 9.999629036056657e-05 Training loss: 8.22629451751709
2025-12-09 11:47:31.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 9.999591012770848e-05 Training loss: 8.368176460266113
2025-12-09 11:47:31.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 9.999551134794164e-05 Training loss: 8.082226753234863
2025-12-09 11:47:31.175 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 9.999509402141401e-05 Training loss: 8.09953498840332
2025-12-09 11:47:31.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 9.999465814828036e-05 Training loss: 8.319204330444336
2025-12-09 11:47:31.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 9.999420372870242e-05 Training loss: 8.269523620605469
2025-12-09 11:47:31.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 9.999373076284877e-05 Training loss: 8.027741432189941
2025-12-09 11:47:31.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 9.999323925089486e-05 Training loss: 8.21882152557373
2025-12-09 11:47:31.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 9.999272919302301e-05 Training loss: 8.01248550415039
2025-12-09 11:47:31.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 9.999220058942245e-05 Training loss: 8.270660400390625
2025-12-09 11:47:31.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 9.999165344028926e-05 Training loss: 7.498575687408447
2025-12-09 11:47:31.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 9.999108774582645e-05 Training loss: 8.05610466003418
2025-12-09 11:47:31.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 9.999050350624382e-05 Training loss: 7.899975299835205
2025-12-09 11:47:31.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 9.998990072175813e-05 Training loss: 8.86954402923584
2025-12-09 11:47:32.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 9.998927939259303e-05 Training loss: 7.979518890380859
2025-12-09 11:47:32.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 9.998863951897897e-05 Training loss: 7.935895919799805
2025-12-09 11:47:32.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 9.998798110115333e-05 Training loss: 8.103260040283203
2025-12-09 11:47:32.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 9.998730413936037e-05 Training loss: 8.180353164672852
2025-12-09 11:47:32.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 9.998660863385123e-05 Training loss: 8.024861335754395
2025-12-09 11:47:32.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 9.99858945848839e-05 Training loss: 8.005507469177246
2025-12-09 11:47:32.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 9.998516199272327e-05 Training loss: 7.742966651916504
2025-12-09 11:47:32.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 9.998441085764113e-05 Training loss: 8.05791187286377
2025-12-09 11:47:32.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 9.998364117991612e-05 Training loss: 7.645146369934082
2025-12-09 11:47:32.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 9.998285295983376e-05 Training loss: 7.88720178604126
2025-12-09 11:47:32.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 9.998204619768646e-05 Training loss: 7.845494747161865
2025-12-09 11:47:32.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 9.998122089377349e-05 Training loss: 7.736382961273193
2025-12-09 11:47:32.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 9.998037704840102e-05 Training loss: 7.898648738861084
2025-12-09 11:47:33.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 9.99795146618821e-05 Training loss: 7.7926859855651855
2025-12-09 11:47:33.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 9.997863373453663e-05 Training loss: 7.9229559898376465
2025-12-09 11:47:33.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 9.997773426669142e-05 Training loss: 7.756710052490234
2025-12-09 11:47:33.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 9.997681625868013e-05 Training loss: 7.707780361175537
2025-12-09 11:47:33.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 9.997587971084335e-05 Training loss: 7.649811744689941
2025-12-09 11:47:33.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 9.997492462352846e-05 Training loss: 7.6501288414001465
2025-12-09 11:47:33.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 9.997395099708982e-05 Training loss: 7.871026992797852
2025-12-09 11:47:33.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 9.997295883188856e-05 Training loss: 8.069583892822266
2025-12-09 11:47:33.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 9.997194812829276e-05 Training loss: 7.6219868659973145
2025-12-09 11:47:33.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 9.997091888667738e-05 Training loss: 7.783152103424072
2025-12-09 11:47:33.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 9.996987110742422e-05 Training loss: 7.605862617492676
2025-12-09 11:47:33.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 9.996880479092198e-05 Training loss: 7.753307819366455
2025-12-09 11:47:34.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 9.996771993756621e-05 Training loss: 7.683359622955322
2025-12-09 11:47:34.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 9.996661654775938e-05 Training loss: 7.814484596252441
2025-12-09 11:47:34.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 9.996549462191082e-05 Training loss: 8.049883842468262
2025-12-09 11:47:34.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 9.99643541604367e-05 Training loss: 7.695612907409668
2025-12-09 11:47:34.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 9.99631951637601e-05 Training loss: 7.40531063079834
2025-12-09 11:47:34.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 9.996201763231099e-05 Training loss: 7.4806952476501465
2025-12-09 11:47:34.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 9.996082156652618e-05 Training loss: 7.85573673248291
2025-12-09 11:47:34.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 9.995960696684939e-05 Training loss: 7.7657999992370605
2025-12-09 11:47:34.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 9.995837383373119e-05 Training loss: 7.216968059539795
2025-12-09 11:47:34.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 9.995712216762902e-05 Training loss: 7.372346878051758
2025-12-09 11:47:34.786 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 9.995585196900723e-05 Training loss: 7.580717086791992
2025-12-09 11:47:34.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 9.9954563238337e-05 Training loss: 7.686054706573486
2025-12-09 11:47:34.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 9.995325597609645e-05 Training loss: 8.39360523223877
2025-12-09 11:47:35.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 9.99519301827705e-05 Training loss: 7.529862880706787
2025-12-09 11:47:35.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 9.995058585885095e-05 Training loss: 7.752241134643555
2025-12-09 11:47:35.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 9.994922300483656e-05 Training loss: 7.554677963256836
2025-12-09 11:47:35.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 9.99478416212329e-05 Training loss: 7.25088357925415
2025-12-09 11:47:35.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 9.994644170855237e-05 Training loss: 7.45564079284668
2025-12-09 11:47:35.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 9.994502326731434e-05 Training loss: 8.467617988586426
2025-12-09 11:47:35.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 9.994358629804499e-05 Training loss: 7.768613815307617
2025-12-09 11:47:35.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 9.994213080127739e-05 Training loss: 7.329117774963379
2025-12-09 11:47:35.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 9.994065677755147e-05 Training loss: 7.530876636505127
2025-12-09 11:47:35.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 9.993916422741409e-05 Training loss: 7.753755569458008
2025-12-09 11:47:35.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 9.99376531514189e-05 Training loss: 7.614683151245117
2025-12-09 11:47:35.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 9.993612355012647e-05 Training loss: 7.653003692626953
2025-12-09 11:47:35.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 9.993457542410424e-05 Training loss: 7.476591110229492
2025-12-09 11:47:36.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 9.993300877392651e-05 Training loss: 7.5974812507629395
2025-12-09 11:47:36.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 9.993142360017446e-05 Training loss: 7.507686138153076
2025-12-09 11:47:36.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 9.992981990343614e-05 Training loss: 8.664939880371094
2025-12-09 11:47:36.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 9.992819768430647e-05 Training loss: 7.61230993270874
2025-12-09 11:47:36.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 9.992655694338725e-05 Training loss: 7.416517734527588
2025-12-09 11:47:36.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 9.992489768128713e-05 Training loss: 7.71442985534668
2025-12-09 11:47:36.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 9.992321989862166e-05 Training loss: 7.4928154945373535
2025-12-09 11:47:36.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 9.992152359601322e-05 Training loss: 7.319448947906494
2025-12-09 11:47:36.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 9.99198087740911e-05 Training loss: 7.874454975128174
2025-12-09 11:47:36.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 9.991807543349146e-05 Training loss: 7.694149017333984
2025-12-09 11:47:36.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 9.99163235748573e-05 Training loss: 7.245898246765137
2025-12-09 11:47:36.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 9.99145531988385e-05 Training loss: 7.1605706214904785
2025-12-09 11:47:36.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 9.99127643060918e-05 Training loss: 7.5001540184021
2025-12-09 11:47:37.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 9.991095689728087e-05 Training loss: 7.663257598876953
2025-12-09 11:47:37.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 9.990913097307614e-05 Training loss: 7.6622490882873535
2025-12-09 11:47:37.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 9.990728653415504e-05 Training loss: 7.675044536590576
2025-12-09 11:47:37.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 9.990542358120174e-05 Training loss: 7.6656951904296875
2025-12-09 11:47:37.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 9.990354211490735e-05 Training loss: 7.688006401062012
2025-12-09 11:47:37.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 9.990164213596986e-05 Training loss: 7.698512554168701
2025-12-09 11:47:37.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 9.989972364509408e-05 Training loss: 7.3362345695495605
2025-12-09 11:47:37.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 9.989778664299172e-05 Training loss: 7.295418739318848
2025-12-09 11:47:37.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 9.989583113038135e-05 Training loss: 7.531406402587891
2025-12-09 11:47:37.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 9.989385710798837e-05 Training loss: 7.101434707641602
2025-12-09 11:47:37.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 9.989186457654513e-05 Training loss: 7.554769039154053
2025-12-09 11:47:37.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 9.988985353679077e-05 Training loss: 7.53627347946167
2025-12-09 11:47:38.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 9.988782398947131e-05 Training loss: 7.668855667114258
2025-12-09 11:47:38.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 9.988577593533967e-05 Training loss: 7.125316619873047
2025-12-09 11:47:38.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 9.988370937515561e-05 Training loss: 7.807003498077393
2025-12-09 11:47:38.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 9.988162430968575e-05 Training loss: 7.413041591644287
2025-12-09 11:47:38.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 9.987952073970359e-05 Training loss: 7.819079399108887
2025-12-09 11:47:38.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 9.98773986659895e-05 Training loss: 7.294627666473389
2025-12-09 11:47:38.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 9.987525808933068e-05 Training loss: 7.038696765899658
2025-12-09 11:47:38.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 9.987309901052121e-05 Training loss: 7.80073356628418
2025-12-09 11:47:38.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 9.98709214303621e-05 Training loss: 7.401167392730713
2025-12-09 11:47:38.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 9.986872534966109e-05 Training loss: 7.352801322937012
2025-12-09 11:47:38.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 9.986651076923288e-05 Training loss: 7.673228740692139
2025-12-09 11:47:38.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 9.986427768989903e-05 Training loss: 7.5898847579956055
2025-12-09 11:47:38.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 9.986202611248793e-05 Training loss: 8.516287803649902
2025-12-09 11:47:39.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 9.985975603783484e-05 Training loss: 7.915626525878906
2025-12-09 11:47:39.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 9.98574674667819e-05 Training loss: 7.355075836181641
2025-12-09 11:47:39.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 9.985516040017807e-05 Training loss: 7.3626790046691895
2025-12-09 11:47:39.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 9.985283483887923e-05 Training loss: 7.475336074829102
2025-12-09 11:47:39.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 9.985049078374806e-05 Training loss: 7.818435192108154
2025-12-09 11:47:39.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 9.984812823565417e-05 Training loss: 7.797003746032715
2025-12-09 11:47:39.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 9.984574719547395e-05 Training loss: 7.4940080642700195
2025-12-09 11:47:39.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 9.984334766409071e-05 Training loss: 7.483902931213379
2025-12-09 11:47:39.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 9.98409296423946e-05 Training loss: 8.055243492126465
2025-12-09 11:47:39.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 9.983849313128264e-05 Training loss: 7.861867904663086
2025-12-09 11:47:39.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 9.983603813165869e-05 Training loss: 8.347960472106934
2025-12-09 11:47:39.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 9.983356464443347e-05 Training loss: 7.122816562652588
2025-12-09 11:47:39.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 9.983107267052457e-05 Training loss: 7.475600719451904
2025-12-09 11:47:40.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 9.982856221085644e-05 Training loss: 7.402277946472168
2025-12-09 11:47:40.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 9.982603326636037e-05 Training loss: 7.245658874511719
2025-12-09 11:47:40.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 9.982348583797454e-05 Training loss: 7.50010347366333
2025-12-09 11:47:40.295 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 9.982091992664392e-05 Training loss: 7.123426914215088
2025-12-09 11:47:40.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 9.981833553332045e-05 Training loss: 7.66259765625
2025-12-09 11:47:40.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 9.981573265896281e-05 Training loss: 8.309528350830078
2025-12-09 11:47:40.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 9.981311130453659e-05 Training loss: 7.3809003829956055
2025-12-09 11:47:40.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 9.981047147101426e-05 Training loss: 7.339447021484375
2025-12-09 11:47:40.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 9.980781315937507e-05 Training loss: 7.277618408203125
2025-12-09 11:47:40.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 9.98051363706052e-05 Training loss: 7.210360050201416
2025-12-09 11:47:40.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 9.980244110569765e-05 Training loss: 7.894155502319336
2025-12-09 11:47:40.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 9.979972736565226e-05 Training loss: 7.565732479095459
2025-12-09 11:47:41.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 9.979699515147578e-05 Training loss: 7.45833158493042
2025-12-09 11:47:41.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 9.979424446418173e-05 Training loss: 7.444190502166748
2025-12-09 11:47:41.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 9.979147530479056e-05 Training loss: 7.551541805267334
2025-12-09 11:47:41.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 9.978868767432954e-05 Training loss: 8.538854598999023
2025-12-09 11:47:41.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 9.978588157383277e-05 Training loss: 7.516109466552734
2025-12-09 11:47:41.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 9.978305700434125e-05 Training loss: 6.76131534576416
2025-12-09 11:47:41.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 9.97802139669028e-05 Training loss: 7.31398868560791
2025-12-09 11:47:41.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 9.97773524625721e-05 Training loss: 7.472067356109619
2025-12-09 11:47:41.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 9.977447249241066e-05 Training loss: 7.223167896270752
2025-12-09 11:47:41.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 9.977157405748687e-05 Training loss: 7.323052406311035
2025-12-09 11:47:41.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 9.976865715887595e-05 Training loss: 7.339308738708496
2025-12-09 11:47:41.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 9.976572179765999e-05 Training loss: 7.591770648956299
2025-12-09 11:47:41.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 9.976276797492793e-05 Training loss: 7.5346879959106445
2025-12-09 11:47:42.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 9.975979569177552e-05 Training loss: 7.210093975067139
2025-12-09 11:47:42.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 9.975680494930538e-05 Training loss: 7.438710689544678
2025-12-09 11:47:42.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 9.9753795748627e-05 Training loss: 7.2711029052734375
2025-12-09 11:47:42.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 9.975076809085669e-05 Training loss: 7.361930847167969
2025-12-09 11:47:42.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 9.974772197711761e-05 Training loss: 7.6838507652282715
2025-12-09 11:47:42.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 9.97446574085398e-05 Training loss: 7.157968997955322
2025-12-09 11:47:42.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 9.974157438626008e-05 Training loss: 7.221490383148193
2025-12-09 11:47:42.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 9.973847291142218e-05 Training loss: 7.182781219482422
2025-12-09 11:47:42.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 9.973535298517663e-05 Training loss: 7.274876117706299
2025-12-09 11:47:42.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 9.973221460868086e-05 Training loss: 7.5398945808410645
2025-12-09 11:47:42.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 9.972905778309906e-05 Training loss: 7.342170715332031
2025-12-09 11:47:42.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 9.972588250960234e-05 Training loss: 7.345520496368408
2025-12-09 11:47:42.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 9.972268878936863e-05 Training loss: 6.974417686462402
2025-12-09 11:47:43.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 9.97194766235827e-05 Training loss: 7.368894100189209
2025-12-09 11:47:43.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 9.971624601343615e-05 Training loss: 7.155433654785156
2025-12-09 11:47:43.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 9.971299696012743e-05 Training loss: 7.546354293823242
2025-12-09 11:47:43.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 9.970972946486185e-05 Training loss: 7.100396633148193
2025-12-09 11:47:43.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 9.970644352885157e-05 Training loss: 7.599368572235107
2025-12-09 11:47:43.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 9.970313915331553e-05 Training loss: 7.47255802154541
2025-12-09 11:47:43.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 9.969981633947956e-05 Training loss: 6.565474510192871
2025-12-09 11:47:43.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 9.969647508857631e-05 Training loss: 7.284725666046143
2025-12-09 11:47:43.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 9.969311540184532e-05 Training loss: 8.071304321289062
2025-12-09 11:47:43.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 9.968973728053288e-05 Training loss: 7.617247104644775
2025-12-09 11:47:43.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 9.968634072589218e-05 Training loss: 7.301468849182129
2025-12-09 11:47:43.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 9.968292573918325e-05 Training loss: 7.3002610206604
2025-12-09 11:47:43.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 9.967949232167294e-05 Training loss: 7.065669059753418
2025-12-09 11:47:44.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 9.967604047463493e-05 Training loss: 7.2260637283325195
2025-12-09 11:47:44.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 9.967257019934975e-05 Training loss: 7.721137046813965
2025-12-09 11:47:44.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 9.966908149710476e-05 Training loss: 7.137831687927246
2025-12-09 11:47:44.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 9.966557436919416e-05 Training loss: 7.210350036621094
2025-12-09 11:47:44.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 9.966204881691898e-05 Training loss: 7.28524923324585
2025-12-09 11:47:44.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 9.965850484158711e-05 Training loss: 7.557133674621582
2025-12-09 11:47:44.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 9.965494244451324e-05 Training loss: 7.142302513122559
2025-12-09 11:47:44.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 9.96513616270189e-05 Training loss: 7.2918524742126465
2025-12-09 11:47:44.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 9.964776239043246e-05 Training loss: 7.421982288360596
2025-12-09 11:47:44.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 9.964414473608912e-05 Training loss: 7.633086681365967
2025-12-09 11:47:44.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 9.964050866533094e-05 Training loss: 7.253627777099609
2025-12-09 11:47:44.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 9.963685417950677e-05 Training loss: 7.492575168609619
2025-12-09 11:47:45.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 9.96331812799723e-05 Training loss: 7.42072057723999
2025-12-09 11:47:45.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 9.962948996809008e-05 Training loss: 7.200303077697754
2025-12-09 11:47:45.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 9.962578024522948e-05 Training loss: 7.497224807739258
2025-12-09 11:47:45.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 9.962205211276665e-05 Training loss: 7.124241828918457
2025-12-09 11:47:45.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 9.961830557208464e-05 Training loss: 6.914914608001709
2025-12-09 11:47:45.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 9.961454062457329e-05 Training loss: 6.4792633056640625
2025-12-09 11:47:45.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 9.961075727162928e-05 Training loss: 7.118865013122559
2025-12-09 11:47:45.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 9.960695551465611e-05 Training loss: 7.10830020904541
2025-12-09 11:47:45.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 9.960313535506411e-05 Training loss: 7.653045177459717
2025-12-09 11:47:45.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 9.959929679427047e-05 Training loss: 7.521003246307373
2025-12-09 11:47:45.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 9.959543983369912e-05 Training loss: 7.318120956420898
2025-12-09 11:47:45.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 9.959156447478091e-05 Training loss: 7.060929298400879
2025-12-09 11:47:45.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 9.958767071895347e-05 Training loss: 7.1591877937316895
2025-12-09 11:47:46.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 9.958375856766127e-05 Training loss: 6.511119842529297
2025-12-09 11:47:46.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 9.957982802235556e-05 Training loss: 7.2660136222839355
2025-12-09 11:47:46.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 9.957587908449448e-05 Training loss: 6.824777126312256
2025-12-09 11:47:46.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 9.957191175554294e-05 Training loss: 8.41396427154541
2025-12-09 11:47:46.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 9.956792603697273e-05 Training loss: 7.069240570068359
2025-12-09 11:47:46.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 9.956392193026239e-05 Training loss: 7.455111980438232
2025-12-09 11:47:46.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 9.955989943689734e-05 Training loss: 7.155764102935791
2025-12-09 11:47:46.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 9.955585855836978e-05 Training loss: 7.226047992706299
2025-12-09 11:47:46.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 9.955179929617875e-05 Training loss: 7.078392505645752
2025-12-09 11:47:46.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 9.954772165183013e-05 Training loss: 7.140961170196533
2025-12-09 11:47:46.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 9.954362562683658e-05 Training loss: 7.301523685455322
2025-12-09 11:47:46.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 9.95395112227176e-05 Training loss: 7.440243244171143
2025-12-09 11:47:46.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 9.95353784409995e-05 Training loss: 6.91231632232666
2025-12-09 11:47:47.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 9.953122728321542e-05 Training loss: 7.041860103607178
2025-12-09 11:47:47.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 9.952705775090529e-05 Training loss: 7.334483623504639
2025-12-09 11:47:47.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 9.952286984561592e-05 Training loss: 7.1511335372924805
2025-12-09 11:47:47.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 9.951866356890084e-05 Training loss: 7.364853382110596
2025-12-09 11:47:47.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 9.951443892232047e-05 Training loss: 6.634129047393799
2025-12-09 11:47:47.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 9.951019590744203e-05 Training loss: 7.140320301055908
2025-12-09 11:47:47.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 9.950593452583952e-05 Training loss: 8.04305648803711
2025-12-09 11:47:47.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 9.95016547790938e-05 Training loss: 6.988540172576904
2025-12-09 11:47:47.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 9.949735666879252e-05 Training loss: 7.13421630859375
2025-12-09 11:47:47.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 9.949304019653012e-05 Training loss: 7.747879505157471
2025-12-09 11:47:47.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 9.94887053639079e-05 Training loss: 6.904531955718994
2025-12-09 11:47:47.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 9.948435217253393e-05 Training loss: 7.350003719329834
2025-12-09 11:47:48.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 9.947998062402313e-05 Training loss: 7.444461345672607
2025-12-09 11:47:48.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 9.947559071999719e-05 Training loss: 8.144964218139648
2025-12-09 11:47:48.175 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 9.947118246208462e-05 Training loss: 7.033306121826172
2025-12-09 11:47:48.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 9.946675585192075e-05 Training loss: 7.582684516906738
2025-12-09 11:47:48.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 9.946231089114774e-05 Training loss: 7.216197490692139
2025-12-09 11:47:48.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 9.945784758141448e-05 Training loss: 7.382091522216797
2025-12-09 11:47:48.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 9.945336592437678e-05 Training loss: 6.979730606079102
2025-12-09 11:47:48.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 9.944886592169713e-05 Training loss: 7.203716278076172
2025-12-09 11:47:48.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 9.944434757504492e-05 Training loss: 7.28632116317749
2025-12-09 11:47:48.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 9.94398108860963e-05 Training loss: 7.364989757537842
2025-12-09 11:47:48.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 9.943525585653428e-05 Training loss: 7.190920829772949
2025-12-09 11:47:48.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 9.94306824880486e-05 Training loss: 7.047240734100342
2025-12-09 11:47:48.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 9.942609078233581e-05 Training loss: 7.1847920417785645
2025-12-09 11:47:49.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 9.942148074109934e-05 Training loss: 7.153236389160156
2025-12-09 11:47:49.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 9.941685236604934e-05 Training loss: 7.402868270874023
2025-12-09 11:47:49.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 9.941220565890279e-05 Training loss: 7.332263469696045
2025-12-09 11:47:49.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 9.94075406213835e-05 Training loss: 7.9756059646606445
2025-12-09 11:47:49.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 9.940285725522203e-05 Training loss: 6.631132125854492
2025-12-09 11:47:49.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 9.939815556215575e-05 Training loss: 7.024997234344482
2025-12-09 11:47:49.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 9.939343554392886e-05 Training loss: 7.258488178253174
2025-12-09 11:47:49.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 9.938869720229234e-05 Training loss: 7.004754066467285
2025-12-09 11:47:49.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 9.938394053900395e-05 Training loss: 7.0125346183776855
2025-12-09 11:47:49.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 9.937916555582828e-05 Training loss: 6.923409461975098
2025-12-09 11:47:49.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 9.937437225453669e-05 Training loss: 7.559650421142578
2025-12-09 11:47:49.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 9.936956063690733e-05 Training loss: 7.283326148986816
2025-12-09 11:47:49.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 9.936473070472518e-05 Training loss: 7.2547712326049805
2025-12-09 11:47:50.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 9.935988245978199e-05 Training loss: 7.488759517669678
2025-12-09 11:47:50.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 9.935501590387628e-05 Training loss: 7.107236385345459
2025-12-09 11:47:50.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 9.935013103881343e-05 Training loss: 7.290452480316162
2025-12-09 11:47:50.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 9.934522786640555e-05 Training loss: 6.711036205291748
2025-12-09 11:47:50.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 9.934030638847155e-05 Training loss: 7.053341865539551
2025-12-09 11:47:50.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 9.933536660683717e-05 Training loss: 7.0018486976623535
2025-12-09 11:47:50.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 9.933040852333488e-05 Training loss: 6.935805797576904
2025-12-09 11:47:50.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 9.9325432139804e-05 Training loss: 6.281933784484863
2025-12-09 11:47:50.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 9.932043745809063e-05 Training loss: 7.315720081329346
2025-12-09 11:47:50.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 9.93154244800476e-05 Training loss: 7.2709641456604
2025-12-09 11:47:50.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.931039320753456e-05 Training loss: 7.3827619552612305
2025-12-09 11:47:50.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 9.9305343642418e-05 Training loss: 7.046770095825195
2025-12-09 11:47:51.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 9.930027578657113e-05 Training loss: 7.071276664733887
2025-12-09 11:47:51.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 9.929518964187395e-05 Training loss: 6.7774529457092285
2025-12-09 11:47:51.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 9.929008521021325e-05 Training loss: 6.998430252075195
2025-12-09 11:47:51.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 9.928496249348265e-05 Training loss: 7.254282474517822
2025-12-09 11:47:51.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 9.92798214935825e-05 Training loss: 7.382518768310547
2025-12-09 11:47:51.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 9.927466221241996e-05 Training loss: 7.444723129272461
2025-12-09 11:47:51.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 9.926948465190892e-05 Training loss: 5.9781880378723145
2025-12-09 11:47:51.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 9.926428881397015e-05 Training loss: 6.7414445877075195
2025-12-09 11:47:51.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 9.925907470053111e-05 Training loss: 7.185693264007568
2025-12-09 11:47:51.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 9.925384231352606e-05 Training loss: 7.639219284057617
2025-12-09 11:47:51.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 9.924859165489608e-05 Training loss: 6.999787330627441
2025-12-09 11:47:51.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 9.924332272658898e-05 Training loss: 6.844648361206055
2025-12-09 11:47:51.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 9.923803553055937e-05 Training loss: 6.967176914215088
2025-12-09 11:47:52.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 9.923273006876865e-05 Training loss: 6.918915748596191
2025-12-09 11:47:52.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 9.922740634318495e-05 Training loss: 6.811710357666016
2025-12-09 11:47:52.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 9.922206435578323e-05 Training loss: 7.108652591705322
2025-12-09 11:47:52.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 9.921670410854518e-05 Training loss: 7.286106109619141
2025-12-09 11:47:52.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 9.92113256034593e-05 Training loss: 6.945909023284912
2025-12-09 11:47:52.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 9.920592884252082e-05 Training loss: 7.706091403961182
2025-12-09 11:47:52.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 9.920051382773179e-05 Training loss: 7.048513889312744
2025-12-09 11:47:52.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 9.919508056110102e-05 Training loss: 6.9651384353637695
2025-12-09 11:47:52.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 9.918962904464407e-05 Training loss: 7.112910270690918
2025-12-09 11:47:52.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 9.918415928038325e-05 Training loss: 7.271515369415283
2025-12-09 11:47:52.831 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 9.917867127034772e-05 Training loss: 7.106359004974365
2025-12-09 11:47:52.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 9.917316501657334e-05 Training loss: 7.411102294921875
2025-12-09 11:47:52.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 9.916764052110274e-05 Training loss: 6.941203594207764
2025-12-09 11:47:53.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 9.916209778598535e-05 Training loss: 7.27545166015625
2025-12-09 11:47:53.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 9.915653681327737e-05 Training loss: 6.9497971534729
2025-12-09 11:47:53.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 9.915095760504169e-05 Training loss: 7.065344333648682
2025-12-09 11:47:53.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 9.914536016334808e-05 Training loss: 6.96903657913208
2025-12-09 11:47:53.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 9.913974449027298e-05 Training loss: 6.78751802444458
2025-12-09 11:47:53.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 9.913411058789963e-05 Training loss: 6.97876501083374
2025-12-09 11:47:53.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 9.912845845831805e-05 Training loss: 6.922370910644531
2025-12-09 11:47:53.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 9.912278810362498e-05 Training loss: 6.133237361907959
2025-12-09 11:47:53.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 9.911709952592397e-05 Training loss: 7.136641979217529
2025-12-09 11:47:53.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 9.911139272732526e-05 Training loss: 7.211658000946045
2025-12-09 11:47:53.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 9.910566770994594e-05 Training loss: 6.9560346603393555
2025-12-09 11:47:53.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 9.909992447590979e-05 Training loss: 7.075508117675781
2025-12-09 11:47:54.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 9.909416302734736e-05 Training loss: 7.219806671142578
2025-12-09 11:47:54.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 9.908838336639597e-05 Training loss: 6.598976135253906
2025-12-09 11:47:54.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 9.908258549519971e-05 Training loss: 7.1279377937316895
2025-12-09 11:47:54.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 9.907676941590939e-05 Training loss: 6.986969947814941
2025-12-09 11:47:54.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 9.907093513068259e-05 Training loss: 7.042565822601318
2025-12-09 11:47:54.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 9.906508264168366e-05 Training loss: 7.332411289215088
2025-12-09 11:47:54.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 9.905921195108368e-05 Training loss: 7.22831392288208
2025-12-09 11:47:54.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 9.90533230610605e-05 Training loss: 7.349850654602051
2025-12-09 11:47:54.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 9.90474159737987e-05 Training loss: 6.871868133544922
2025-12-09 11:47:54.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 9.904149069148963e-05 Training loss: 7.091795444488525
2025-12-09 11:47:54.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 9.903554721633139e-05 Training loss: 6.988157749176025
2025-12-09 11:47:54.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 9.902958555052882e-05 Training loss: 7.090649604797363
2025-12-09 11:47:54.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 9.902360569629349e-05 Training loss: 7.23708963394165
2025-12-09 11:47:55.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 9.901760765584375e-05 Training loss: 6.815766334533691
2025-12-09 11:47:55.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 9.901159143140471e-05 Training loss: 7.029305458068848
2025-12-09 11:47:55.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 9.900555702520816e-05 Training loss: 6.828954219818115
2025-12-09 11:47:55.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 9.89995044394927e-05 Training loss: 7.250179290771484
2025-12-09 11:47:55.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 9.899343367650365e-05 Training loss: 6.8299360275268555
2025-12-09 11:47:55.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 9.898734473849305e-05 Training loss: 7.130030632019043
2025-12-09 11:47:55.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 9.898123762771971e-05 Training loss: 7.0294976234436035
2025-12-09 11:47:55.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 9.89751123464492e-05 Training loss: 6.906290054321289
2025-12-09 11:47:55.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 9.896896889695378e-05 Training loss: 7.176604270935059
2025-12-09 11:47:55.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 9.896280728151248e-05 Training loss: 6.625710487365723
2025-12-09 11:47:55.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 9.895662750241108e-05 Training loss: 6.812738418579102
2025-12-09 11:47:55.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 9.89504295619421e-05 Training loss: 6.926389217376709
2025-12-09 11:47:55.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 9.894421346240473e-05 Training loss: 7.084692478179932
2025-12-09 11:47:56.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 9.893797920610496e-05 Training loss: 6.995283603668213
2025-12-09 11:47:56.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 9.893172679535553e-05 Training loss: 6.67564058303833
2025-12-09 11:47:56.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 9.892545623247586e-05 Training loss: 6.703566551208496
2025-12-09 11:47:56.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 9.891916751979218e-05 Training loss: 7.450158596038818
2025-12-09 11:47:56.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 9.891286065963734e-05 Training loss: 6.959616184234619
2025-12-09 11:47:56.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 9.890653565435101e-05 Training loss: 7.116901874542236
2025-12-09 11:47:56.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 9.89001925062796e-05 Training loss: 6.668600082397461
2025-12-09 11:47:56.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 9.889383121777617e-05 Training loss: 7.158792018890381
2025-12-09 11:47:56.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 9.88874517912006e-05 Training loss: 6.846454620361328
2025-12-09 11:47:56.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 9.888105422891943e-05 Training loss: 7.047648906707764
2025-12-09 11:47:56.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 9.887463853330594e-05 Training loss: 7.059458255767822
2025-12-09 11:47:56.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 9.886820470674018e-05 Training loss: 6.9202189445495605
2025-12-09 11:47:57.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 9.88617527516089e-05 Training loss: 6.837771892547607
2025-12-09 11:47:57.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 9.885528267030557e-05 Training loss: 7.271174907684326
2025-12-09 11:47:57.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 9.884879446523035e-05 Training loss: 6.958810806274414
2025-12-09 11:47:57.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 9.88422881387902e-05 Training loss: 6.8136372566223145
2025-12-09 11:47:57.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 9.883576369339875e-05 Training loss: 7.38771915435791
2025-12-09 11:47:57.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 9.882922113147637e-05 Training loss: 6.98392915725708
2025-12-09 11:47:57.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 9.882266045545012e-05 Training loss: 7.026437282562256
2025-12-09 11:47:57.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 9.881608166775383e-05 Training loss: 7.342523097991943
2025-12-09 11:47:57.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 9.880948477082804e-05 Training loss: 6.986699104309082
2025-12-09 11:47:57.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 9.880286976711992e-05 Training loss: 6.848290920257568
2025-12-09 11:47:57.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 9.87962366590835e-05 Training loss: 6.713563442230225
2025-12-09 11:47:57.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 9.878958544917942e-05 Training loss: 7.099308013916016
2025-12-09 11:47:57.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 9.87829161398751e-05 Training loss: 6.8011298179626465
2025-12-09 11:47:58.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 9.87762287336446e-05 Training loss: 6.965012073516846
2025-12-09 11:47:58.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 9.876952323296877e-05 Training loss: 7.082759380340576
2025-12-09 11:47:58.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 9.876279964033512e-05 Training loss: 6.919312953948975
2025-12-09 11:47:58.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 9.87560579582379e-05 Training loss: 6.867776393890381
2025-12-09 11:47:58.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 9.874929818917806e-05 Training loss: 7.074415683746338
2025-12-09 11:47:58.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 9.874252033566327e-05 Training loss: 7.062204837799072
2025-12-09 11:47:58.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 9.87357244002079e-05 Training loss: 6.6144561767578125
2025-12-09 11:47:58.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 9.8728910385333e-05 Training loss: 6.979772090911865
2025-12-09 11:47:58.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 9.872207829356641e-05 Training loss: 7.291295528411865
2025-12-09 11:47:58.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 9.871522812744256e-05 Training loss: 6.647942543029785
2025-12-09 11:47:58.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 9.870835988950268e-05 Training loss: 7.301982402801514
2025-12-09 11:47:58.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 9.870147358229467e-05 Training loss: 6.9203572273254395
2025-12-09 11:47:58.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 9.869456920837312e-05 Training loss: 7.212258338928223
2025-12-09 11:47:59.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 9.868764677029934e-05 Training loss: 7.433319568634033
2025-12-09 11:47:59.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 9.868070627064135e-05 Training loss: 6.765559673309326
2025-12-09 11:47:59.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 9.867374771197383e-05 Training loss: 7.278492450714111
2025-12-09 11:47:59.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 9.866677109687822e-05 Training loss: 7.1148858070373535
2025-12-09 11:47:59.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 9.86597764279426e-05 Training loss: 7.40189790725708
2025-12-09 11:47:59.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 9.865276370776177e-05 Training loss: 6.918796062469482
2025-12-09 11:47:59.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 9.864573293893725e-05 Training loss: 7.018254280090332
2025-12-09 11:47:59.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 9.863868412407721e-05 Training loss: 6.859600067138672
2025-12-09 11:47:59.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 9.863161726579655e-05 Training loss: 6.941996097564697
2025-12-09 11:47:59.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 9.862453236671685e-05 Training loss: 6.918183326721191
2025-12-09 11:47:59.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 9.861742942946639e-05 Training loss: 6.952181339263916
2025-12-09 11:47:59.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 9.861030845668014e-05 Training loss: 7.014543056488037
2025-12-09 11:48:00.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 9.860316945099973e-05 Training loss: 6.915017604827881
2025-12-09 11:48:00.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 9.859601241507353e-05 Training loss: 7.059138774871826
2025-12-09 11:48:00.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 9.858883735155657e-05 Training loss: 7.071444511413574
2025-12-09 11:48:00.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 9.858164426311059e-05 Training loss: 6.642602443695068
2025-12-09 11:48:00.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 9.857443315240397e-05 Training loss: 7.166582107543945
2025-12-09 11:48:00.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 9.856720402211182e-05 Training loss: 7.083230495452881
2025-12-09 11:48:00.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 9.855995687491591e-05 Training loss: 6.656909942626953
2025-12-09 11:48:00.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 9.855269171350471e-05 Training loss: 7.157357215881348
2025-12-09 11:48:00.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 9.854540854057337e-05 Training loss: 7.008232593536377
2025-12-09 11:48:00.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 9.85381073588237e-05 Training loss: 6.768768310546875
2025-12-09 11:48:00.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 9.853078817096424e-05 Training loss: 6.990975379943848
2025-12-09 11:48:00.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 9.852345097971016e-05 Training loss: 6.709018230438232
2025-12-09 11:48:00.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 9.851609578778332e-05 Training loss: 7.060492038726807
2025-12-09 11:48:01.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 9.850872259791228e-05 Training loss: 6.632411479949951
2025-12-09 11:48:01.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 9.850133141283226e-05 Training loss: 6.868953704833984
2025-12-09 11:48:01.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 9.849392223528514e-05 Training loss: 6.882602691650391
2025-12-09 11:48:01.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 9.84864950680195e-05 Training loss: 7.13527774810791
2025-12-09 11:48:01.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 9.84790499137906e-05 Training loss: 6.652709484100342
2025-12-09 11:48:01.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 9.847158677536034e-05 Training loss: 6.799656867980957
2025-12-09 11:48:01.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 9.84641056554973e-05 Training loss: 6.617558002471924
2025-12-09 11:48:01.597 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 9.845660655697679e-05 Training loss: 6.8556694984436035
2025-12-09 11:48:01.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 9.844908948258067e-05 Training loss: 6.946117401123047
2025-12-09 11:48:01.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 9.844155443509759e-05 Training loss: 6.813621997833252
2025-12-09 11:48:01.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 9.84340014173228e-05 Training loss: 6.742480754852295
2025-12-09 11:48:01.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 9.842643043205822e-05 Training loss: 7.269994258880615
2025-12-09 11:48:01.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 9.841884148211247e-05 Training loss: 6.8249711990356445
2025-12-09 11:48:02.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 9.84112345703008e-05 Training loss: 6.8056960105896
2025-12-09 11:48:02.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 9.84036096994451e-05 Training loss: 6.8502302169799805
2025-12-09 11:48:02.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 9.839596687237403e-05 Training loss: 7.1498703956604
2025-12-09 11:48:02.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 9.838830609192277e-05 Training loss: 6.573131561279297
2025-12-09 11:48:02.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 9.838062736093328e-05 Training loss: 7.27178955078125
2025-12-09 11:48:02.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 9.837293068225408e-05 Training loss: 6.837069511413574
2025-12-09 11:48:02.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 9.836521605874044e-05 Training loss: 7.032338619232178
2025-12-09 11:48:02.623 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 9.835748349325422e-05 Training loss: 6.900774002075195
2025-12-09 11:48:02.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 9.834973298866395e-05 Training loss: 6.932324409484863
2025-12-09 11:48:02.786 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 9.834196454784485e-05 Training loss: 7.108122825622559
2025-12-09 11:48:02.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 9.833417817367874e-05 Training loss: 7.030912399291992
2025-12-09 11:48:02.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 9.832637386905412e-05 Training loss: 6.872769832611084
2025-12-09 11:48:03.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 9.831855163686618e-05 Training loss: 6.858492851257324
2025-12-09 11:48:03.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 9.831071148001667e-05 Training loss: 7.080787181854248
2025-12-09 11:48:03.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 9.830285340141408e-05 Training loss: 6.7824296951293945
2025-12-09 11:48:03.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 9.829497740397349e-05 Training loss: 6.974208831787109
2025-12-09 11:48:03.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 9.828708349061664e-05 Training loss: 7.125760078430176
2025-12-09 11:48:03.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 9.827917166427195e-05 Training loss: 6.97523832321167
2025-12-09 11:48:03.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 9.827124192787444e-05 Training loss: 6.6570868492126465
2025-12-09 11:48:03.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 9.82632942843658e-05 Training loss: 6.9689106941223145
2025-12-09 11:48:03.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 9.825532873669435e-05 Training loss: 6.369747638702393
2025-12-09 11:48:03.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 9.824734528781505e-05 Training loss: 6.344858646392822
2025-12-09 11:48:03.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 9.823934394068952e-05 Training loss: 6.825485706329346
2025-12-09 11:48:03.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 9.823132469828601e-05 Training loss: 7.087259292602539
2025-12-09 11:48:03.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 9.822328756357942e-05 Training loss: 7.038547039031982
2025-12-09 11:48:04.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 9.821523253955122e-05 Training loss: 7.201675891876221
2025-12-09 11:48:04.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 9.820715962918964e-05 Training loss: 7.019094467163086
2025-12-09 11:48:04.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 9.819906883548943e-05 Training loss: 6.812409400939941
2025-12-09 11:48:04.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 9.819096016145203e-05 Training loss: 6.94157600402832
2025-12-09 11:48:04.363 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 9.81828336100855e-05 Training loss: 7.081506729125977
2025-12-09 11:48:04.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 9.817468918440454e-05 Training loss: 6.741630554199219
2025-12-09 11:48:04.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 9.816652688743049e-05 Training loss: 6.801320552825928
2025-12-09 11:48:04.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 9.815834672219127e-05 Training loss: 6.769839286804199
2025-12-09 11:48:04.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 9.815014869172149e-05 Training loss: 7.431736469268799
2025-12-09 11:48:04.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 9.814193279906237e-05 Training loss: 6.769658088684082
2025-12-09 11:48:04.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 9.81336990472617e-05 Training loss: 6.677889347076416
2025-12-09 11:48:04.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 9.8125447439374e-05 Training loss: 6.7448248863220215
2025-12-09 11:48:04.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 9.811717797846033e-05 Training loss: 6.938527584075928
2025-12-09 11:48:05.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 9.81088906675884e-05 Training loss: 6.797345161437988
2025-12-09 11:48:05.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 9.810058550983254e-05 Training loss: 6.682545185089111
2025-12-09 11:48:05.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 9.809226250827371e-05 Training loss: 7.036134719848633
2025-12-09 11:48:05.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 9.808392166599948e-05 Training loss: 6.953001499176025
2025-12-09 11:48:05.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 9.807556298610404e-05 Training loss: 7.0224504470825195
2025-12-09 11:48:05.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 9.806718647168818e-05 Training loss: 6.902774810791016
2025-12-09 11:48:05.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 9.805879212585933e-05 Training loss: 6.633796215057373
2025-12-09 11:48:05.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 9.805037995173155e-05 Training loss: 6.6283063888549805
2025-12-09 11:48:05.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 9.804194995242548e-05 Training loss: 6.573456287384033
2025-12-09 11:48:05.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 9.803350213106836e-05 Training loss: 6.478825092315674
2025-12-09 11:48:05.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 9.802503649079411e-05 Training loss: 6.529083251953125
2025-12-09 11:48:05.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 9.801655303474318e-05 Training loss: 6.625452518463135
2025-12-09 11:48:06.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 9.80080517660627e-05 Training loss: 7.100996017456055
2025-12-09 11:48:06.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 9.799953268790633e-05 Training loss: 6.822604179382324
2025-12-09 11:48:06.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 9.799099580343441e-05 Training loss: 7.569572448730469
2025-12-09 11:48:06.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 9.798244111581382e-05 Training loss: 7.148040771484375
2025-12-09 11:48:06.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 9.797386862821813e-05 Training loss: 6.871345520019531
2025-12-09 11:48:06.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 9.796527834382745e-05 Training loss: 7.117297649383545
2025-12-09 11:48:06.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 9.795667026582847e-05 Training loss: 6.767588138580322
2025-12-09 11:48:06.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 9.794804439741456e-05 Training loss: 6.4756059646606445
2025-12-09 11:48:06.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 9.79394007417856e-05 Training loss: 6.838159561157227
2025-12-09 11:48:06.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 9.793073930214817e-05 Training loss: 6.977770805358887
2025-12-09 11:48:06.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 9.792206008171533e-05 Training loss: 6.541825294494629
2025-12-09 11:48:06.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 9.791336308370687e-05 Training loss: 6.846035003662109
2025-12-09 11:48:06.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 9.790464831134903e-05 Training loss: 6.890985488891602
2025-12-09 11:48:07.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 9.789591576787476e-05 Training loss: 6.992082118988037
2025-12-09 11:48:07.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 9.788716545652353e-05 Training loss: 6.72558069229126
2025-12-09 11:48:07.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 9.787839738054146e-05 Training loss: 6.933849334716797
2025-12-09 11:48:07.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 9.786961154318121e-05 Training loss: 6.834643840789795
2025-12-09 11:48:07.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 9.786080794770207e-05 Training loss: 6.7137837409973145
2025-12-09 11:48:07.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 9.785198659736988e-05 Training loss: 7.065999507904053
2025-12-09 11:48:07.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 9.784314749545707e-05 Training loss: 6.7295637130737305
2025-12-09 11:48:07.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 9.78342906452427e-05 Training loss: 7.057391166687012
2025-12-09 11:48:07.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 9.782541605001235e-05 Training loss: 7.51981782913208
2025-12-09 11:48:07.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 9.781652371305824e-05 Training loss: 6.4841156005859375
2025-12-09 11:48:07.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 9.780761363767914e-05 Training loss: 6.184696674346924
2025-12-09 11:48:07.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 9.779868582718041e-05 Training loss: 6.745713710784912
2025-12-09 11:48:08.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 9.778974028487398e-05 Training loss: 7.116688251495361
2025-12-09 11:48:08.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 9.778077701407837e-05 Training loss: 6.217001438140869
2025-12-09 11:48:08.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 9.777179601811867e-05 Training loss: 6.896542072296143
2025-12-09 11:48:08.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 9.776279730032654e-05 Training loss: 7.337210178375244
2025-12-09 11:48:08.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 9.775378086404023e-05 Training loss: 7.015468120574951
2025-12-09 11:48:08.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 9.774474671260457e-05 Training loss: 6.999605655670166
2025-12-09 11:48:08.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 9.77356948493709e-05 Training loss: 6.696375370025635
2025-12-09 11:48:08.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 9.77266252776972e-05 Training loss: 7.096564292907715
2025-12-09 11:48:08.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 9.771753800094803e-05 Training loss: 6.44432258605957
2025-12-09 11:48:08.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 9.770843302249443e-05 Training loss: 6.943272113800049
2025-12-09 11:48:08.794 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 9.769931034571408e-05 Training loss: 6.726090908050537
2025-12-09 11:48:08.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 9.76901699739912e-05 Training loss: 6.6840362548828125
2025-12-09 11:48:08.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 9.768101191071661e-05 Training loss: 6.788958549499512
2025-12-09 11:48:09.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 9.767183615928765e-05 Training loss: 6.787280559539795
2025-12-09 11:48:09.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 9.766264272310822e-05 Training loss: 6.580959320068359
2025-12-09 11:48:09.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 9.765343160558879e-05 Training loss: 6.622275352478027
2025-12-09 11:48:09.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 9.764420281014642e-05 Training loss: 6.67003059387207
2025-12-09 11:48:09.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 9.763495634020467e-05 Training loss: 7.083355903625488
2025-12-09 11:48:09.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 9.762569219919372e-05 Training loss: 6.8015899658203125
2025-12-09 11:48:09.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 9.761641039055026e-05 Training loss: 6.986777305603027
2025-12-09 11:48:09.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 9.760711091771755e-05 Training loss: 7.184927463531494
2025-12-09 11:48:09.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 9.759779378414542e-05 Training loss: 6.543187618255615
2025-12-09 11:48:09.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 9.758845899329021e-05 Training loss: 6.801649570465088
2025-12-09 11:48:09.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 9.757910654861483e-05 Training loss: 6.911181926727295
2025-12-09 11:48:09.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 9.756973645358876e-05 Training loss: 6.973934650421143
2025-12-09 11:48:09.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 9.7560348711688e-05 Training loss: 6.9251790046691895
2025-12-09 11:48:10.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 9.755094332639512e-05 Training loss: 6.7273077964782715
2025-12-09 11:48:10.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 9.754152030119921e-05 Training loss: 6.676401138305664
2025-12-09 11:48:10.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 9.75320796395959e-05 Training loss: 6.7032928466796875
2025-12-09 11:48:10.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 9.752262134508742e-05 Training loss: 7.097793102264404
2025-12-09 11:48:10.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 9.751314542118246e-05 Training loss: 6.682460308074951
2025-12-09 11:48:10.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 9.750365187139632e-05 Training loss: 6.257428169250488
2025-12-09 11:48:10.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 9.749414069925078e-05 Training loss: 6.825041770935059
2025-12-09 11:48:10.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 9.74846119082742e-05 Training loss: 6.686817646026611
2025-12-09 11:48:10.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 9.747506550200146e-05 Training loss: 6.826496124267578
2025-12-09 11:48:10.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 9.746550148397398e-05 Training loss: 6.93682336807251
2025-12-09 11:48:10.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 9.745591985773971e-05 Training loss: 6.641208171844482
2025-12-09 11:48:10.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 9.744632062685311e-05 Training loss: 6.712526798248291
2025-12-09 11:48:11.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 9.743670379487522e-05 Training loss: 7.025758266448975
2025-12-09 11:48:11.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 9.742706936537358e-05 Training loss: 7.193492889404297
2025-12-09 11:48:11.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 9.741741734192224e-05 Training loss: 6.782867431640625
2025-12-09 11:48:11.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 9.740774772810182e-05 Training loss: 6.727471351623535
2025-12-09 11:48:11.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 9.739806052749943e-05 Training loss: 6.863407611846924
2025-12-09 11:48:11.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 9.738835574370871e-05 Training loss: 6.993798732757568
2025-12-09 11:48:11.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 9.737863338032985e-05 Training loss: 6.92694091796875
2025-12-09 11:48:11.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 9.736889344096952e-05 Training loss: 6.054592132568359
2025-12-09 11:48:11.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 9.735913592924093e-05 Training loss: 7.045905590057373
2025-12-09 11:48:11.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 9.734936084876383e-05 Training loss: 5.812610626220703
2025-12-09 11:48:11.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 9.733956820316444e-05 Training loss: 5.693755149841309
2025-12-09 11:48:11.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 9.732975799607555e-05 Training loss: 7.487269401550293
2025-12-09 11:48:11.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 9.731993023113642e-05 Training loss: 6.768971920013428
2025-12-09 11:48:12.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 9.731008491199284e-05 Training loss: 6.965523719787598
2025-12-09 11:48:12.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 9.730022204229714e-05 Training loss: 6.624269008636475
2025-12-09 11:48:12.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 9.729034162570811e-05 Training loss: 6.696186542510986
2025-12-09 11:48:12.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 9.728044366589108e-05 Training loss: 6.434374809265137
2025-12-09 11:48:12.354 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 9.727052816651788e-05 Training loss: 6.931676387786865
2025-12-09 11:48:12.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 9.726059513126685e-05 Training loss: 6.362941265106201
2025-12-09 11:48:12.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 9.725064456382283e-05 Training loss: 7.280350208282471
2025-12-09 11:48:12.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 9.724067646787717e-05 Training loss: 7.056229114532471
2025-12-09 11:48:12.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 9.723069084712772e-05 Training loss: 6.6999969482421875
2025-12-09 11:48:12.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 9.722068770527883e-05 Training loss: 6.561904430389404
2025-12-09 11:48:12.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 9.721066704604134e-05 Training loss: 6.645705223083496
2025-12-09 11:48:12.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 9.720062887313261e-05 Training loss: 7.062802314758301
2025-12-09 11:48:12.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 9.71905731902765e-05 Training loss: 7.07933235168457
2025-12-09 11:48:13.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 9.718050000120334e-05 Training loss: 6.760692596435547
2025-12-09 11:48:13.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 9.717040930964995e-05 Training loss: 6.936244010925293
2025-12-09 11:48:13.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 9.716030111935967e-05 Training loss: 6.4838175773620605
2025-12-09 11:48:13.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 9.715017543408233e-05 Training loss: 6.843307971954346
2025-12-09 11:48:13.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 9.714003225757424e-05 Training loss: 7.0926642417907715
2025-12-09 11:48:13.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 9.712987159359818e-05 Training loss: 5.8847270011901855
2025-12-09 11:48:13.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 9.711969344592346e-05 Training loss: 6.491323471069336
2025-12-09 11:48:13.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 9.710949781832585e-05 Training loss: 7.102264404296875
2025-12-09 11:48:13.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 9.709928471458759e-05 Training loss: 6.822762489318848
2025-12-09 11:48:13.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 9.708905413849743e-05 Training loss: 6.727867126464844
2025-12-09 11:48:13.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 9.707880609385059e-05 Training loss: 6.905406475067139
2025-12-09 11:48:13.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 9.706854058444876e-05 Training loss: 6.955163955688477
2025-12-09 11:48:14.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 9.705825761410014e-05 Training loss: 6.639646530151367
2025-12-09 11:48:14.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 9.704795718661939e-05 Training loss: 6.937645435333252
2025-12-09 11:48:14.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 9.703763930582761e-05 Training loss: 7.126399993896484
2025-12-09 11:48:14.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 9.702730397555247e-05 Training loss: 7.125583648681641
2025-12-09 11:48:14.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 9.7016951199628e-05 Training loss: 6.749417304992676
2025-12-09 11:48:14.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 9.700658098189475e-05 Training loss: 7.290666580200195
2025-12-09 11:48:14.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 9.69961933261998e-05 Training loss: 6.841743469238281
2025-12-09 11:48:14.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 9.698578823639659e-05 Training loss: 6.517068386077881
2025-12-09 11:48:14.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 9.697536571634509e-05 Training loss: 6.978731155395508
2025-12-09 11:48:14.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 9.696492576991174e-05 Training loss: 6.827451705932617
2025-12-09 11:48:14.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 9.695446840096944e-05 Training loss: 6.742269039154053
2025-12-09 11:48:14.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 9.694399361339752e-05 Training loss: 6.644808292388916
2025-12-09 11:48:14.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 9.693350141108182e-05 Training loss: 6.8003249168396
2025-12-09 11:48:15.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 9.692299179791459e-05 Training loss: 6.748841762542725
2025-12-09 11:48:15.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 9.69124647777946e-05 Training loss: 6.700552463531494
2025-12-09 11:48:15.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 9.690192035462702e-05 Training loss: 6.975743770599365
2025-12-09 11:48:15.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 9.689135853232349e-05 Training loss: 6.0929670333862305
2025-12-09 11:48:15.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 9.688077931480212e-05 Training loss: 6.548263072967529
2025-12-09 11:48:15.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 9.687018270598749e-05 Training loss: 7.4603986740112305
2025-12-09 11:48:15.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 9.685956870981058e-05 Training loss: 7.10015869140625
2025-12-09 11:48:15.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 9.684893733020888e-05 Training loss: 6.779463291168213
2025-12-09 11:48:15.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 9.683828857112627e-05 Training loss: 6.846255302429199
2025-12-09 11:48:15.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 9.682762243651308e-05 Training loss: 6.7962236404418945
2025-12-09 11:48:15.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 9.681693893032618e-05 Training loss: 6.758493900299072
2025-12-09 11:48:15.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 9.680623805652876e-05 Training loss: 6.733339309692383
2025-12-09 11:48:15.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 9.679551981909053e-05 Training loss: 6.618514537811279
2025-12-09 11:48:16.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 9.67847842219876e-05 Training loss: 6.436631202697754
2025-12-09 11:48:16.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 9.677403126920256e-05 Training loss: 6.336502552032471
2025-12-09 11:48:16.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 9.676326096472441e-05 Training loss: 7.577909469604492
2025-12-09 11:48:16.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 9.675247331254858e-05 Training loss: 7.03058385848999
2025-12-09 11:48:16.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 9.674166831667697e-05 Training loss: 7.383903503417969
2025-12-09 11:48:16.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 9.673084598111789e-05 Training loss: 6.710518836975098
2025-12-09 11:48:16.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 9.672000630988605e-05 Training loss: 6.777950286865234
2025-12-09 11:48:16.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 9.670914930700267e-05 Training loss: 6.8835344314575195
2025-12-09 11:48:16.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 9.669827497649536e-05 Training loss: 6.897540092468262
2025-12-09 11:48:16.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 9.668738332239813e-05 Training loss: 6.755372524261475
2025-12-09 11:48:16.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 9.667647434875145e-05 Training loss: 6.617744445800781
2025-12-09 11:48:16.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 9.66655480596022e-05 Training loss: 7.122166156768799
2025-12-09 11:48:17.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 9.665460445900368e-05 Training loss: 6.803271770477295
2025-12-09 11:48:17.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 9.664364355101565e-05 Training loss: 6.458399772644043
2025-12-09 11:48:17.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 9.663266533970424e-05 Training loss: 6.880390644073486
2025-12-09 11:48:17.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 9.662166982914203e-05 Training loss: 6.7874579429626465
2025-12-09 11:48:17.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 9.661065702340801e-05 Training loss: 6.5898284912109375
2025-12-09 11:48:17.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 9.659962692658758e-05 Training loss: 6.614902973175049
2025-12-09 11:48:17.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 9.658857954277254e-05 Training loss: 6.669793128967285
2025-12-09 11:48:17.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 9.657751487606115e-05 Training loss: 6.516036033630371
2025-12-09 11:48:17.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 9.656643293055804e-05 Training loss: 6.395203113555908
2025-12-09 11:48:17.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 9.655533371037426e-05 Training loss: 6.404778480529785
2025-12-09 11:48:18.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 9.65442172196273e-05 Training loss: 7.014291286468506
