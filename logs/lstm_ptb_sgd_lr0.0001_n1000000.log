2025-12-09 12:05:40.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 9.216480255126953
2025-12-09 12:05:40.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 9.216216087341309
2025-12-09 12:05:40.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 9.216020584106445
2025-12-09 12:05:40.982 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 9.215725898742676
2025-12-09 12:05:40.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 9.215909957885742
2025-12-09 12:05:41.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 9.216475486755371
2025-12-09 12:05:41.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 9.21578311920166
2025-12-09 12:05:41.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 9.216353416442871
2025-12-09 12:05:41.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 9.216560363769531
2025-12-09 12:05:41.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 9.21619987487793
2025-12-09 12:05:41.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 9.216386795043945
2025-12-09 12:05:41.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 9.215383529663086
2025-12-09 12:05:41.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 9.215715408325195
2025-12-09 12:05:41.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 9.216937065124512
2025-12-09 12:05:41.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 9.215704917907715
2025-12-09 12:05:41.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 9.21628475189209
2025-12-09 12:05:41.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 9.216143608093262
2025-12-09 12:05:41.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 9.216523170471191
2025-12-09 12:05:41.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 9.215832710266113
2025-12-09 12:05:41.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 9.2161283493042
2025-12-09 12:05:41.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 9.215944290161133
2025-12-09 12:05:41.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 9.214885711669922
2025-12-09 12:05:41.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 9.21649169921875
2025-12-09 12:05:41.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 9.216652870178223
2025-12-09 12:05:41.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 9.216233253479004
2025-12-09 12:05:41.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 9.215529441833496
2025-12-09 12:05:41.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 9.216647148132324
2025-12-09 12:05:41.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 9.216316223144531
2025-12-09 12:05:41.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 9.216132164001465
2025-12-09 12:05:41.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 9.216156959533691
2025-12-09 12:05:41.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 9.21660041809082
2025-12-09 12:05:41.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 9.21608829498291
2025-12-09 12:05:41.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 9.215408325195312
2025-12-09 12:05:41.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 9.215876579284668
2025-12-09 12:05:41.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 9.216455459594727
2025-12-09 12:05:41.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 9.215259552001953
2025-12-09 12:05:41.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 9.216957092285156
2025-12-09 12:05:41.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 9.216453552246094
2025-12-09 12:05:41.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 9.215868949890137
2025-12-09 12:05:41.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 9.2156982421875
2025-12-09 12:05:41.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 9.216080665588379
2025-12-09 12:05:41.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 9.216156959533691
2025-12-09 12:05:41.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 9.216625213623047
2025-12-09 12:05:41.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 9.215767860412598
2025-12-09 12:05:41.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 9.216554641723633
2025-12-09 12:05:41.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 9.215950965881348
2025-12-09 12:05:41.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 9.21597957611084
2025-12-09 12:05:41.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 9.21618366241455
2025-12-09 12:05:41.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 9.2157621383667
2025-12-09 12:05:41.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 9.215936660766602
2025-12-09 12:05:41.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 9.215818405151367
2025-12-09 12:05:41.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 9.216057777404785
2025-12-09 12:05:41.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 9.215912818908691
2025-12-09 12:05:41.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 9.215713500976562
2025-12-09 12:05:41.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 9.216167449951172
2025-12-09 12:05:41.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 9.215851783752441
2025-12-09 12:05:41.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 9.215932846069336
2025-12-09 12:05:41.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 9.215731620788574
2025-12-09 12:05:41.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 9.215514183044434
2025-12-09 12:05:41.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 9.215889930725098
2025-12-09 12:05:41.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 9.215699195861816
2025-12-09 12:05:41.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 9.215511322021484
2025-12-09 12:05:41.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 9.216255187988281
2025-12-09 12:05:41.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 9.215851783752441
2025-12-09 12:05:41.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 9.216216087341309
2025-12-09 12:05:41.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 9.215901374816895
2025-12-09 12:05:41.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 9.215893745422363
2025-12-09 12:05:42.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 9.216304779052734
2025-12-09 12:05:42.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 9.216137886047363
2025-12-09 12:05:42.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 9.215920448303223
2025-12-09 12:05:42.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 9.21590518951416
2025-12-09 12:05:42.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 9.216132164001465
2025-12-09 12:05:42.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 9.21547794342041
2025-12-09 12:05:42.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 9.215553283691406
2025-12-09 12:05:42.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 9.215867042541504
2025-12-09 12:05:42.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 9.214908599853516
2025-12-09 12:05:42.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 9.215465545654297
2025-12-09 12:05:42.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 9.2164306640625
2025-12-09 12:05:42.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 9.215973854064941
2025-12-09 12:05:42.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 9.215299606323242
2025-12-09 12:05:42.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 9.21566104888916
2025-12-09 12:05:42.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 9.216715812683105
2025-12-09 12:05:42.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 9.215557098388672
2025-12-09 12:05:42.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 9.21540641784668
2025-12-09 12:05:42.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 9.215571403503418
2025-12-09 12:05:42.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 9.215167045593262
2025-12-09 12:05:42.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 9.21541690826416
2025-12-09 12:05:42.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 9.21593189239502
2025-12-09 12:05:42.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 9.215261459350586
2025-12-09 12:05:42.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 9.216241836547852
2025-12-09 12:05:42.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 9.215725898742676
2025-12-09 12:05:42.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 9.215301513671875
2025-12-09 12:05:42.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 9.215414047241211
2025-12-09 12:05:42.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 9.215306282043457
2025-12-09 12:05:42.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 9.21546745300293
2025-12-09 12:05:42.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 9.215767860412598
2025-12-09 12:05:42.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 9.216033935546875
2025-12-09 12:05:42.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 9.215570449829102
2025-12-09 12:05:42.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 9.215289115905762
2025-12-09 12:05:42.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 9.215738296508789
2025-12-09 12:05:42.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.698463103929542e-05 Training loss: 9.215045928955078
2025-12-09 12:05:42.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 8.83022221559489e-05 Training loss: 9.215328216552734
2025-12-09 12:05:42.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 7.500000000000001e-05 Training loss: 9.215535163879395
2025-12-09 12:05:42.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 5.868240888334653e-05 Training loss: 9.215384483337402
2025-12-09 12:05:42.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 4.131759111665349e-05 Training loss: 9.215279579162598
2025-12-09 12:05:42.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 2.500000000000001e-05 Training loss: 9.215476989746094
2025-12-09 12:05:42.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 1.1697777844051105e-05 Training loss: 9.215153694152832
2025-12-09 12:05:42.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 3.0153689607045845e-06 Training loss: 9.215136528015137
2025-12-09 12:05:42.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0 Training loss: 9.215479850769043
