2025-12-09 10:24:34.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 0.0
2025-12-09 10:24:34.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 0.0
2025-12-09 10:24:34.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 0.0
2025-12-09 10:24:34.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 0.0
2025-12-09 10:24:34.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 0.0
2025-12-09 10:24:34.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 0.0
2025-12-09 10:24:34.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 0.0
2025-12-09 10:24:34.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 0.0
2025-12-09 10:24:34.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 0.0
2025-12-09 10:24:34.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 0.0
2025-12-09 10:24:34.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 0.0
2025-12-09 10:24:34.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 0.0
2025-12-09 10:24:34.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 0.0
2025-12-09 10:24:34.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 0.0
2025-12-09 10:24:34.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 0.0
2025-12-09 10:24:34.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 0.0
2025-12-09 10:24:34.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 0.0
2025-12-09 10:24:34.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 0.0
2025-12-09 10:24:34.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 0.0
2025-12-09 10:24:34.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 0.0
2025-12-09 10:24:34.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 0.0
2025-12-09 10:24:34.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 0.0
2025-12-09 10:24:34.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 0.0
2025-12-09 10:24:34.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 0.0
2025-12-09 10:24:34.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 0.0
2025-12-09 10:24:34.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 0.0
2025-12-09 10:24:34.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 0.0
2025-12-09 10:24:34.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 0.0
2025-12-09 10:24:34.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 0.0
2025-12-09 10:24:34.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 0.0
2025-12-09 10:24:34.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 0.0
2025-12-09 10:24:34.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 0.0
2025-12-09 10:24:34.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 0.0
2025-12-09 10:24:34.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 0.0
2025-12-09 10:24:34.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 0.0
2025-12-09 10:24:34.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 0.0
2025-12-09 10:24:34.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 0.0
2025-12-09 10:24:34.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 0.0
2025-12-09 10:24:34.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 0.0
2025-12-09 10:24:34.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 0.0
2025-12-09 10:24:34.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 0.0
2025-12-09 10:24:34.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 0.0
2025-12-09 10:24:34.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 0.0
2025-12-09 10:24:34.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 0.0
2025-12-09 10:24:34.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 0.0
2025-12-09 10:24:34.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 0.0
2025-12-09 10:24:34.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 0.0
2025-12-09 10:24:34.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 0.0
2025-12-09 10:24:34.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 0.0
2025-12-09 10:24:34.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 0.0
2025-12-09 10:24:34.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 0.0
2025-12-09 10:24:34.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 0.0
2025-12-09 10:24:34.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 0.0
2025-12-09 10:24:34.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 0.0
2025-12-09 10:24:34.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 0.0
2025-12-09 10:24:34.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 0.0
2025-12-09 10:24:34.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 0.0
2025-12-09 10:24:34.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 0.0
2025-12-09 10:24:34.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 0.0
2025-12-09 10:24:34.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 0.0
2025-12-09 10:24:34.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 0.0
2025-12-09 10:24:34.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 0.0
2025-12-09 10:24:34.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 0.0
2025-12-09 10:24:34.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 0.0
2025-12-09 10:24:34.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 0.0
2025-12-09 10:24:34.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 0.0
2025-12-09 10:24:34.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 0.0
2025-12-09 10:24:34.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 0.0
2025-12-09 10:24:34.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 0.0
2025-12-09 10:24:34.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 0.0
2025-12-09 10:24:34.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 0.0
2025-12-09 10:24:34.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 0.0
2025-12-09 10:24:34.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 0.0
2025-12-09 10:24:34.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 0.0
2025-12-09 10:24:34.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 0.0
2025-12-09 10:24:34.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 0.0
2025-12-09 10:24:34.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 0.0
2025-12-09 10:24:34.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 0.0
2025-12-09 10:24:34.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 0.0
2025-12-09 10:24:34.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 0.0
2025-12-09 10:24:34.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 0.0
2025-12-09 10:24:34.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 0.0
2025-12-09 10:24:34.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 0.0
2025-12-09 10:24:34.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 0.0
2025-12-09 10:24:34.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 0.0
2025-12-09 10:24:34.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 0.0
2025-12-09 10:24:34.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 0.0
2025-12-09 10:24:34.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 0.0
2025-12-09 10:24:34.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 0.0
2025-12-09 10:24:34.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 0.0
2025-12-09 10:24:34.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 0.0
2025-12-09 10:24:34.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 0.0
2025-12-09 10:24:34.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 0.0
2025-12-09 10:24:34.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 0.0
2025-12-09 10:24:34.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 0.0
2025-12-09 10:24:34.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 0.0
2025-12-09 10:24:34.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 0.0
2025-12-09 10:24:34.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 0.0
2025-12-09 10:24:34.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 0.0
2025-12-09 10:24:34.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 0.0
2025-12-09 10:24:34.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 100 LR: 0.0009999999748250069 Training loss: 0.0
2025-12-09 10:24:34.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 101 LR: 0.00099999989930003 Training loss: 0.0
2025-12-09 10:24:34.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 102 LR: 0.0009999997734250767 Training loss: 0.0
2025-12-09 10:24:34.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 103 LR: 0.00099999959720016 Training loss: 0.0
2025-12-09 10:24:34.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 104 LR: 0.0009999993706252977 Training loss: 0.0
2025-12-09 10:24:34.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 105 LR: 0.0009999990937005125 Training loss: 0.0
2025-12-09 10:24:34.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 106 LR: 0.000999998766425832 Training loss: 0.0
2025-12-09 10:24:34.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 107 LR: 0.0009999983888012895 Training loss: 0.0
2025-12-09 10:24:34.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 108 LR: 0.000999997960826923 Training loss: 0.0
2025-12-09 10:24:34.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 109 LR: 0.0009999974825027757 Training loss: 0.0
2025-12-09 10:24:34.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 110 LR: 0.0009999969538288952 Training loss: 0.0
2025-12-09 10:24:34.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 111 LR: 0.0009999963748053354 Training loss: 0.0
2025-12-09 10:24:34.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 112 LR: 0.0009999957454321542 Training loss: 0.0
2025-12-09 10:24:34.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 113 LR: 0.0009999950657094152 Training loss: 0.0
2025-12-09 10:24:34.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 114 LR: 0.0009999943356371866 Training loss: 0.0
2025-12-09 10:24:34.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 115 LR: 0.0009999935552155422 Training loss: 0.0
2025-12-09 10:24:34.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 116 LR: 0.0009999927244445607 Training loss: 0.0
2025-12-09 10:24:34.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 117 LR: 0.000999991843324325 Training loss: 0.0
2025-12-09 10:24:34.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 118 LR: 0.0009999909118549248 Training loss: 0.0
2025-12-09 10:24:34.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 119 LR: 0.0009999899300364532 Training loss: 0.0
2025-12-09 10:24:34.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 120 LR: 0.0009999888978690094 Training loss: 0.0
2025-12-09 10:24:34.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 121 LR: 0.0009999878153526974 Training loss: 0.0
2025-12-09 10:24:34.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 122 LR: 0.0009999866824876261 Training loss: 0.0
2025-12-09 10:24:34.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 123 LR: 0.0009999854992739094 Training loss: 0.0
2025-12-09 10:24:34.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 124 LR: 0.0009999842657116666 Training loss: 0.0
2025-12-09 10:24:34.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 125 LR: 0.000999982981801022 Training loss: 0.0
2025-12-09 10:24:34.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 126 LR: 0.0009999816475421046 Training loss: 0.0
2025-12-09 10:24:34.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 127 LR: 0.000999980262935049 Training loss: 0.0
2025-12-09 10:24:34.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 128 LR: 0.000999978827979995 Training loss: 0.0
2025-12-09 10:24:34.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 129 LR: 0.0009999773426770863 Training loss: 0.0
2025-12-09 10:24:34.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 130 LR: 0.0009999758070264732 Training loss: 0.0
2025-12-09 10:24:34.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 131 LR: 0.0009999742210283098 Training loss: 0.0
2025-12-09 10:24:34.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 132 LR: 0.000999972584682756 Training loss: 0.0
2025-12-09 10:24:34.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 133 LR: 0.0009999708979899768 Training loss: 0.0
2025-12-09 10:24:34.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 134 LR: 0.0009999691609501417 Training loss: 0.0
2025-12-09 10:24:34.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 135 LR: 0.000999967373563426 Training loss: 0.0
2025-12-09 10:24:34.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 136 LR: 0.000999965535830009 Training loss: 0.0
2025-12-09 10:24:34.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 137 LR: 0.0009999636477500764 Training loss: 0.0
2025-12-09 10:24:34.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 138 LR: 0.0009999617093238182 Training loss: 0.0
2025-12-09 10:24:34.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 139 LR: 0.0009999597205514296 Training loss: 0.0
2025-12-09 10:24:34.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 140 LR: 0.0009999576814331108 Training loss: 0.0
2025-12-09 10:24:34.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 141 LR: 0.0009999555919690674 Training loss: 0.0
2025-12-09 10:24:34.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 142 LR: 0.000999953452159509 Training loss: 0.0
2025-12-09 10:24:34.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 143 LR: 0.0009999512620046521 Training loss: 0.0
2025-12-09 10:24:34.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 144 LR: 0.0009999490215047166 Training loss: 0.0
2025-12-09 10:24:34.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 145 LR: 0.0009999467306599284 Training loss: 0.0
2025-12-09 10:24:34.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 146 LR: 0.0009999443894705181 Training loss: 0.0
2025-12-09 10:24:34.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 147 LR: 0.0009999419979367214 Training loss: 0.0
2025-12-09 10:24:34.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 148 LR: 0.0009999395560587794 Training loss: 0.0
2025-12-09 10:24:34.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 149 LR: 0.0009999370638369377 Training loss: 0.0
2025-12-09 10:24:34.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 150 LR: 0.000999934521271447 Training loss: 0.0
2025-12-09 10:24:34.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 151 LR: 0.000999931928362564 Training loss: 0.0
2025-12-09 10:24:34.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 152 LR: 0.0009999292851105494 Training loss: 0.0
2025-12-09 10:24:34.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 153 LR: 0.0009999265915156697 Training loss: 0.0
2025-12-09 10:24:34.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 154 LR: 0.0009999238475781956 Training loss: 0.0
2025-12-09 10:24:34.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 155 LR: 0.0009999210532984039 Training loss: 0.0
2025-12-09 10:24:34.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 156 LR: 0.0009999182086765756 Training loss: 0.0
2025-12-09 10:24:34.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 157 LR: 0.0009999153137129977 Training loss: 0.0
2025-12-09 10:24:34.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 158 LR: 0.0009999123684079612 Training loss: 0.0
2025-12-09 10:24:34.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 159 LR: 0.000999909372761763 Training loss: 0.0
2025-12-09 10:24:34.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 160 LR: 0.0009999063267747044 Training loss: 0.0
2025-12-09 10:24:34.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 161 LR: 0.0009999032304470925 Training loss: 0.0
2025-12-09 10:24:34.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 162 LR: 0.000999900083779239 Training loss: 0.0
2025-12-09 10:24:34.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 163 LR: 0.0009998968867714609 Training loss: 0.0
2025-12-09 10:24:34.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 164 LR: 0.0009998936394240796 Training loss: 0.0
2025-12-09 10:24:34.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 165 LR: 0.0009998903417374227 Training loss: 0.0
2025-12-09 10:24:34.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 166 LR: 0.0009998869937118222 Training loss: 0.0
2025-12-09 10:24:34.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 167 LR: 0.0009998835953476148 Training loss: 0.0
2025-12-09 10:24:34.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 168 LR: 0.0009998801466451432 Training loss: 0.0
2025-12-09 10:24:34.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 169 LR: 0.0009998766476047546 Training loss: 0.0
2025-12-09 10:24:34.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 170 LR: 0.0009998730982268011 Training loss: 0.0
2025-12-09 10:24:34.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 171 LR: 0.0009998694985116404 Training loss: 0.0
2025-12-09 10:24:34.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 172 LR: 0.0009998658484596348 Training loss: 0.0
2025-12-09 10:24:34.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 173 LR: 0.0009998621480711521 Training loss: 0.0
2025-12-09 10:24:34.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 174 LR: 0.0009998583973465647 Training loss: 0.0
2025-12-09 10:24:34.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 175 LR: 0.0009998545962862503 Training loss: 0.0
2025-12-09 10:24:34.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 176 LR: 0.0009998507448905915 Training loss: 0.0
2025-12-09 10:24:34.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 177 LR: 0.0009998468431599767 Training loss: 0.0
2025-12-09 10:24:34.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 178 LR: 0.0009998428910947983 Training loss: 0.0
2025-12-09 10:24:34.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 179 LR: 0.0009998388886954545 Training loss: 0.0
2025-12-09 10:24:34.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 180 LR: 0.0009998348359623484 Training loss: 0.0
2025-12-09 10:24:34.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 181 LR: 0.0009998307328958878 Training loss: 0.0
2025-12-09 10:24:34.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 182 LR: 0.0009998265794964863 Training loss: 0.0
2025-12-09 10:24:34.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 183 LR: 0.0009998223757645616 Training loss: 0.0
2025-12-09 10:24:34.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 184 LR: 0.0009998181217005376 Training loss: 0.0
2025-12-09 10:24:34.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 185 LR: 0.0009998138173048423 Training loss: 0.0
2025-12-09 10:24:34.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 186 LR: 0.0009998094625779093 Training loss: 0.0
2025-12-09 10:24:34.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 187 LR: 0.000999805057520177 Training loss: 0.0
2025-12-09 10:24:34.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 188 LR: 0.0009998006021320893 Training loss: 0.0
2025-12-09 10:24:34.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 189 LR: 0.0009997960964140947 Training loss: 0.0
2025-12-09 10:24:34.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 190 LR: 0.0009997915403666467 Training loss: 0.0
2025-12-09 10:24:34.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 191 LR: 0.000999786933990204 Training loss: 0.0
2025-12-09 10:24:34.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 192 LR: 0.0009997822772852313 Training loss: 0.0
2025-12-09 10:24:34.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 193 LR: 0.0009997775702521965 Training loss: 0.0
2025-12-09 10:24:34.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 194 LR: 0.0009997728128915743 Training loss: 0.0
2025-12-09 10:24:34.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 195 LR: 0.0009997680052038433 Training loss: 0.0
2025-12-09 10:24:34.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 196 LR: 0.000999763147189488 Training loss: 0.0
2025-12-09 10:24:34.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 197 LR: 0.0009997582388489973 Training loss: 0.0
2025-12-09 10:24:34.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 198 LR: 0.0009997532801828658 Training loss: 0.0
2025-12-09 10:24:34.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 199 LR: 0.0009997482711915926 Training loss: 0.0
2025-12-09 10:24:34.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 200 LR: 0.0009997432118756821 Training loss: 0.0
2025-12-09 10:24:34.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 201 LR: 0.000999738102235644 Training loss: 0.0
2025-12-09 10:24:34.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 202 LR: 0.0009997329422719926 Training loss: 0.0
2025-12-09 10:24:34.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 203 LR: 0.0009997277319852475 Training loss: 0.0
2025-12-09 10:24:34.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 204 LR: 0.0009997224713759335 Training loss: 0.0
2025-12-09 10:24:34.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 205 LR: 0.0009997171604445804 Training loss: 0.0
2025-12-09 10:24:34.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 206 LR: 0.0009997117991917227 Training loss: 0.0
2025-12-09 10:24:34.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 207 LR: 0.0009997063876179006 Training loss: 0.0
2025-12-09 10:24:34.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 208 LR: 0.000999700925723659 Training loss: 0.0
2025-12-09 10:24:34.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 209 LR: 0.0009996954135095479 Training loss: 0.0
2025-12-09 10:24:34.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 210 LR: 0.0009996898509761223 Training loss: 0.0
2025-12-09 10:24:34.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 211 LR: 0.0009996842381239423 Training loss: 0.0
2025-12-09 10:24:34.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 212 LR: 0.0009996785749535732 Training loss: 0.0
2025-12-09 10:24:34.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 213 LR: 0.0009996728614655853 Training loss: 0.0
2025-12-09 10:24:34.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 214 LR: 0.000999667097660554 Training loss: 0.0
2025-12-09 10:24:34.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 215 LR: 0.0009996612835390594 Training loss: 0.0
2025-12-09 10:24:34.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 216 LR: 0.0009996554191016875 Training loss: 0.0
2025-12-09 10:24:34.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 217 LR: 0.0009996495043490285 Training loss: 0.0
2025-12-09 10:24:34.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 218 LR: 0.000999643539281678 Training loss: 0.0
2025-12-09 10:24:34.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 219 LR: 0.0009996375239002368 Training loss: 0.0
2025-12-09 10:24:34.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 220 LR: 0.0009996314582053105 Training loss: 0.0
2025-12-09 10:24:34.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 221 LR: 0.0009996253421975104 Training loss: 0.0
2025-12-09 10:24:34.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 222 LR: 0.0009996191758774515 Training loss: 0.0
2025-12-09 10:24:34.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 223 LR: 0.0009996129592457557 Training loss: 0.0
2025-12-09 10:24:34.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 224 LR: 0.0009996066923030483 Training loss: 0.0
2025-12-09 10:24:34.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 225 LR: 0.0009996003750499607 Training loss: 0.0
2025-12-09 10:24:34.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 226 LR: 0.000999594007487129 Training loss: 0.0
2025-12-09 10:24:34.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 227 LR: 0.0009995875896151945 Training loss: 0.0
2025-12-09 10:24:34.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 228 LR: 0.0009995811214348034 Training loss: 0.0
2025-12-09 10:24:34.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 229 LR: 0.0009995746029466072 Training loss: 0.0
2025-12-09 10:24:34.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 230 LR: 0.0009995680341512618 Training loss: 0.0
2025-12-09 10:24:34.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 231 LR: 0.0009995614150494292 Training loss: 0.0
2025-12-09 10:24:34.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 232 LR: 0.0009995547456417757 Training loss: 0.0
2025-12-09 10:24:34.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 233 LR: 0.000999548025928973 Training loss: 0.0
2025-12-09 10:24:34.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 234 LR: 0.000999541255911698 Training loss: 0.0
2025-12-09 10:24:34.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 235 LR: 0.000999534435590632 Training loss: 0.0
2025-12-09 10:24:34.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 236 LR: 0.000999527564966462 Training loss: 0.0
2025-12-09 10:24:34.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 237 LR: 0.0009995206440398796 Training loss: 0.0
2025-12-09 10:24:34.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 238 LR: 0.0009995136728115825 Training loss: 0.0
2025-12-09 10:24:34.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 239 LR: 0.0009995066512822719 Training loss: 0.0
2025-12-09 10:24:34.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 240 LR: 0.0009994995794526554 Training loss: 0.0
2025-12-09 10:24:34.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 241 LR: 0.0009994924573234448 Training loss: 0.0
2025-12-09 10:24:34.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 242 LR: 0.0009994852848953573 Training loss: 0.0
2025-12-09 10:24:34.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 243 LR: 0.0009994780621691156 Training loss: 0.0
2025-12-09 10:24:34.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 244 LR: 0.0009994707891454464 Training loss: 0.0
2025-12-09 10:24:34.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 245 LR: 0.0009994634658250824 Training loss: 0.0
2025-12-09 10:24:34.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 246 LR: 0.0009994560922087612 Training loss: 0.0
2025-12-09 10:24:34.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 247 LR: 0.0009994486682972253 Training loss: 0.0
2025-12-09 10:24:34.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 248 LR: 0.0009994411940912218 Training loss: 0.0
2025-12-09 10:24:34.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 249 LR: 0.000999433669591504 Training loss: 0.0
2025-12-09 10:24:34.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 250 LR: 0.0009994260947988293 Training loss: 0.0
2025-12-09 10:24:34.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 251 LR: 0.0009994184697139604 Training loss: 0.0
2025-12-09 10:24:34.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 252 LR: 0.0009994107943376654 Training loss: 0.0
2025-12-09 10:24:34.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 253 LR: 0.0009994030686707172 Training loss: 0.0
2025-12-09 10:24:34.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 254 LR: 0.0009993952927138932 Training loss: 0.0
2025-12-09 10:24:34.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 255 LR: 0.0009993874664679773 Training loss: 0.0
2025-12-09 10:24:34.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 256 LR: 0.000999379589933757 Training loss: 0.0
2025-12-09 10:24:34.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 257 LR: 0.0009993716631120258 Training loss: 0.0
2025-12-09 10:24:34.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 258 LR: 0.0009993636860035817 Training loss: 0.0
2025-12-09 10:24:34.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 259 LR: 0.000999355658609228 Training loss: 0.0
2025-12-09 10:24:34.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 260 LR: 0.000999347580929773 Training loss: 0.0
2025-12-09 10:24:34.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 261 LR: 0.0009993394529660307 Training loss: 0.0
2025-12-09 10:24:34.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 262 LR: 0.000999331274718819 Training loss: 0.0
2025-12-09 10:24:34.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 263 LR: 0.0009993230461889616 Training loss: 0.0
2025-12-09 10:24:34.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 264 LR: 0.0009993147673772868 Training loss: 0.0
2025-12-09 10:24:34.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 265 LR: 0.000999306438284629 Training loss: 0.0
2025-12-09 10:24:34.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 266 LR: 0.0009992980589118264 Training loss: 0.0
2025-12-09 10:24:34.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 267 LR: 0.0009992896292597229 Training loss: 0.0
2025-12-09 10:24:34.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 268 LR: 0.0009992811493291674 Training loss: 0.0
2025-12-09 10:24:34.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 269 LR: 0.0009992726191210138 Training loss: 0.0
2025-12-09 10:24:34.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 270 LR: 0.0009992640386361211 Training loss: 0.0
2025-12-09 10:24:34.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 271 LR: 0.0009992554078753534 Training loss: 0.0
2025-12-09 10:24:34.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 272 LR: 0.0009992467268395797 Training loss: 0.0
2025-12-09 10:24:34.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 273 LR: 0.0009992379955296744 Training loss: 0.0
2025-12-09 10:24:34.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 274 LR: 0.0009992292139465165 Training loss: 0.0
2025-12-09 10:24:34.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 275 LR: 0.0009992203820909905 Training loss: 0.0
2025-12-09 10:24:34.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 276 LR: 0.0009992114999639856 Training loss: 0.0
2025-12-09 10:24:34.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 277 LR: 0.0009992025675663965 Training loss: 0.0
2025-12-09 10:24:34.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 278 LR: 0.0009991935848991222 Training loss: 0.0
2025-12-09 10:24:34.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 279 LR: 0.0009991845519630679 Training loss: 0.0
2025-12-09 10:24:34.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 280 LR: 0.0009991754687591428 Training loss: 0.0
2025-12-09 10:24:34.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 281 LR: 0.0009991663352882615 Training loss: 0.0
2025-12-09 10:24:34.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 282 LR: 0.0009991571515513438 Training loss: 0.0
2025-12-09 10:24:34.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 283 LR: 0.0009991479175493149 Training loss: 0.0
2025-12-09 10:24:34.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 284 LR: 0.0009991386332831042 Training loss: 0.0
2025-12-09 10:24:34.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 285 LR: 0.0009991292987536467 Training loss: 0.0
2025-12-09 10:24:34.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 286 LR: 0.0009991199139618827 Training loss: 0.0
2025-12-09 10:24:34.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 287 LR: 0.000999110478908757 Training loss: 0.0
2025-12-09 10:24:34.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 288 LR: 0.0009991009935952195 Training loss: 0.0
2025-12-09 10:24:34.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 289 LR: 0.0009990914580222257 Training loss: 0.0
2025-12-09 10:24:34.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 290 LR: 0.0009990818721907358 Training loss: 0.0
2025-12-09 10:24:34.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 291 LR: 0.000999072236101715 Training loss: 0.0
2025-12-09 10:24:34.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 292 LR: 0.0009990625497561336 Training loss: 0.0
2025-12-09 10:24:34.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 293 LR: 0.0009990528131549672 Training loss: 0.0
2025-12-09 10:24:34.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 294 LR: 0.0009990430262991961 Training loss: 0.0
2025-12-09 10:24:34.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 295 LR: 0.0009990331891898058 Training loss: 0.0
2025-12-09 10:24:34.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 296 LR: 0.0009990233018277873 Training loss: 0.0
2025-12-09 10:24:34.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 297 LR: 0.0009990133642141358 Training loss: 0.0
2025-12-09 10:24:34.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 298 LR: 0.0009990033763498522 Training loss: 0.0
2025-12-09 10:24:34.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 299 LR: 0.0009989933382359422 Training loss: 0.0
2025-12-09 10:24:34.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 300 LR: 0.0009989832498734168 Training loss: 0.0
2025-12-09 10:24:34.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 301 LR: 0.0009989731112632916 Training loss: 0.0
2025-12-09 10:24:34.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 302 LR: 0.000998962922406588 Training loss: 0.0
2025-12-09 10:24:34.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 303 LR: 0.0009989526833043317 Training loss: 0.0
2025-12-09 10:24:34.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 304 LR: 0.0009989423939575537 Training loss: 0.0
2025-12-09 10:24:34.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 305 LR: 0.0009989320543672903 Training loss: 0.0
2025-12-09 10:24:34.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 306 LR: 0.0009989216645345826 Training loss: 0.0
2025-12-09 10:24:34.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 307 LR: 0.0009989112244604772 Training loss: 0.0
2025-12-09 10:24:34.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 308 LR: 0.000998900734146025 Training loss: 0.0
2025-12-09 10:24:34.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 309 LR: 0.0009988901935922825 Training loss: 0.0
2025-12-09 10:24:34.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 310 LR: 0.0009988796028003112 Training loss: 0.0
2025-12-09 10:24:34.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 311 LR: 0.0009988689617711777 Training loss: 0.0
2025-12-09 10:24:34.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 312 LR: 0.0009988582705059532 Training loss: 0.0
2025-12-09 10:24:34.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 313 LR: 0.0009988475290057144 Training loss: 0.0
2025-12-09 10:24:34.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 314 LR: 0.0009988367372715434 Training loss: 0.0
2025-12-09 10:24:34.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 315 LR: 0.0009988258953045263 Training loss: 0.0
2025-12-09 10:24:34.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 316 LR: 0.0009988150031057554 Training loss: 0.0
2025-12-09 10:24:34.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 317 LR: 0.0009988040606763273 Training loss: 0.0
2025-12-09 10:24:34.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 318 LR: 0.000998793068017344 Training loss: 0.0
2025-12-09 10:24:34.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 319 LR: 0.0009987820251299122 Training loss: 0.0
2025-12-09 10:24:34.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 320 LR: 0.000998770932015144 Training loss: 0.0
2025-12-09 10:24:34.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 321 LR: 0.000998759788674157 Training loss: 0.0
2025-12-09 10:24:34.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 322 LR: 0.0009987485951080727 Training loss: 0.0
2025-12-09 10:24:34.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 323 LR: 0.0009987373513180185 Training loss: 0.0
2025-12-09 10:24:34.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 324 LR: 0.0009987260573051267 Training loss: 0.0
2025-12-09 10:24:34.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 325 LR: 0.0009987147130705348 Training loss: 0.0
2025-12-09 10:24:34.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 326 LR: 0.0009987033186153846 Training loss: 0.0
2025-12-09 10:24:34.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 327 LR: 0.0009986918739408241 Training loss: 0.0
2025-12-09 10:24:34.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 328 LR: 0.0009986803790480053 Training loss: 0.0
2025-12-09 10:24:34.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 329 LR: 0.0009986688339380862 Training loss: 0.0
2025-12-09 10:24:34.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 330 LR: 0.000998657238612229 Training loss: 0.0
2025-12-09 10:24:34.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 331 LR: 0.0009986455930716016 Training loss: 0.0
2025-12-09 10:24:34.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 332 LR: 0.0009986338973173767 Training loss: 0.0
2025-12-09 10:24:34.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 333 LR: 0.0009986221513507319 Training loss: 0.0
2025-12-09 10:24:34.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 334 LR: 0.00099861035517285 Training loss: 0.0
2025-12-09 10:24:34.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 335 LR: 0.0009985985087849192 Training loss: 0.0
2025-12-09 10:24:34.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 336 LR: 0.000998586612188132 Training loss: 0.0
2025-12-09 10:24:34.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 337 LR: 0.0009985746653836866 Training loss: 0.0
2025-12-09 10:24:34.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 338 LR: 0.0009985626683727863 Training loss: 0.0
2025-12-09 10:24:34.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 339 LR: 0.0009985506211566387 Training loss: 0.0
2025-12-09 10:24:34.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 340 LR: 0.0009985385237364572 Training loss: 0.0
2025-12-09 10:24:34.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 341 LR: 0.0009985263761134603 Training loss: 0.0
2025-12-09 10:24:34.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 342 LR: 0.0009985141782888705 Training loss: 0.0
2025-12-09 10:24:34.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 343 LR: 0.0009985019302639168 Training loss: 0.0
2025-12-09 10:24:34.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 344 LR: 0.0009984896320398326 Training loss: 0.0
2025-12-09 10:24:34.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 345 LR: 0.0009984772836178558 Training loss: 0.0
2025-12-09 10:24:34.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 346 LR: 0.00099846488499923 Training loss: 0.0
2025-12-09 10:24:34.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 347 LR: 0.0009984524361852042 Training loss: 0.0
2025-12-09 10:24:34.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 348 LR: 0.0009984399371770318 Training loss: 0.0
2025-12-09 10:24:34.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 349 LR: 0.0009984273879759713 Training loss: 0.0
2025-12-09 10:24:34.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 350 LR: 0.0009984147885832863 Training loss: 0.0
2025-12-09 10:24:34.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 351 LR: 0.0009984021390002458 Training loss: 0.0
2025-12-09 10:24:34.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 352 LR: 0.0009983894392281236 Training loss: 0.0
2025-12-09 10:24:34.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 353 LR: 0.0009983766892681985 Training loss: 0.0
2025-12-09 10:24:34.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 354 LR: 0.0009983638891217545 Training loss: 0.0
2025-12-09 10:24:34.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 355 LR: 0.0009983510387900803 Training loss: 0.0
2025-12-09 10:24:34.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 356 LR: 0.0009983381382744703 Training loss: 0.0
2025-12-09 10:24:34.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 357 LR: 0.0009983251875762232 Training loss: 0.0
2025-12-09 10:24:34.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 358 LR: 0.0009983121866966435 Training loss: 0.0
2025-12-09 10:24:34.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 359 LR: 0.0009982991356370402 Training loss: 0.0
2025-12-09 10:24:34.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 360 LR: 0.0009982860343987277 Training loss: 0.0
2025-12-09 10:24:34.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 361 LR: 0.0009982728829830252 Training loss: 0.0
2025-12-09 10:24:34.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 362 LR: 0.0009982596813912568 Training loss: 0.0
2025-12-09 10:24:34.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 363 LR: 0.0009982464296247522 Training loss: 0.0
2025-12-09 10:24:34.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 364 LR: 0.0009982331276848458 Training loss: 0.0
2025-12-09 10:24:34.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 365 LR: 0.000998219775572877 Training loss: 0.0
2025-12-09 10:24:34.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 366 LR: 0.0009982063732901904 Training loss: 0.0
2025-12-09 10:24:34.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 367 LR: 0.0009981929208381357 Training loss: 0.0
2025-12-09 10:24:34.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 368 LR: 0.0009981794182180677 Training loss: 0.0
2025-12-09 10:24:34.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 369 LR: 0.0009981658654313456 Training loss: 0.0
2025-12-09 10:24:34.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 370 LR: 0.0009981522624793347 Training loss: 0.0
2025-12-09 10:24:34.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 371 LR: 0.0009981386093634045 Training loss: 0.0
2025-12-09 10:24:34.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 372 LR: 0.00099812490608493 Training loss: 0.0
2025-12-09 10:24:34.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 373 LR: 0.000998111152645291 Training loss: 0.0
2025-12-09 10:24:34.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 374 LR: 0.0009980973490458728 Training loss: 0.0
2025-12-09 10:24:34.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 375 LR: 0.000998083495288065 Training loss: 0.0
2025-12-09 10:24:34.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 376 LR: 0.000998069591373263 Training loss: 0.0
2025-12-09 10:24:34.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 377 LR: 0.0009980556373028666 Training loss: 0.0
2025-12-09 10:24:34.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 378 LR: 0.000998041633078281 Training loss: 0.0
2025-12-09 10:24:34.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 379 LR: 0.000998027578700917 Training loss: 0.0
2025-12-09 10:24:34.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 380 LR: 0.0009980134741721892 Training loss: 0.0
2025-12-09 10:24:34.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 381 LR: 0.0009979993194935183 Training loss: 0.0
2025-12-09 10:24:34.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 382 LR: 0.0009979851146663292 Training loss: 0.0
2025-12-09 10:24:34.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 383 LR: 0.000997970859692053 Training loss: 0.0
2025-12-09 10:24:34.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 384 LR: 0.0009979565545721247 Training loss: 0.0
2025-12-09 10:24:34.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 385 LR: 0.0009979421993079852 Training loss: 0.0
2025-12-09 10:24:34.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 386 LR: 0.0009979277939010799 Training loss: 0.0
2025-12-09 10:24:34.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 387 LR: 0.000997913338352859 Training loss: 0.0
2025-12-09 10:24:34.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 388 LR: 0.0009978988326647788 Training loss: 0.0
2025-12-09 10:24:34.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 389 LR: 0.0009978842768382998 Training loss: 0.0
2025-12-09 10:24:34.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 390 LR: 0.0009978696708748875 Training loss: 0.0
2025-12-09 10:24:34.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 391 LR: 0.0009978550147760133 Training loss: 0.0
2025-12-09 10:24:34.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 392 LR: 0.0009978403085431525 Training loss: 0.0
2025-12-09 10:24:34.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 393 LR: 0.0009978255521777863 Training loss: 0.0
2025-12-09 10:24:34.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 394 LR: 0.0009978107456814008 Training loss: 0.0
2025-12-09 10:24:34.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 395 LR: 0.0009977958890554867 Training loss: 0.0
2025-12-09 10:24:34.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 396 LR: 0.00099778098230154 Training loss: 0.0
2025-12-09 10:24:34.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 397 LR: 0.0009977660254210621 Training loss: 0.0
2025-12-09 10:24:34.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 398 LR: 0.000997751018415559 Training loss: 0.0
2025-12-09 10:24:34.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 399 LR: 0.0009977359612865424 Training loss: 0.0
2025-12-09 10:24:34.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 400 LR: 0.0009977208540355277 Training loss: 0.0
2025-12-09 10:24:34.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 401 LR: 0.0009977056966640368 Training loss: 0.0
2025-12-09 10:24:34.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 402 LR: 0.0009976904891735958 Training loss: 0.0
2025-12-09 10:24:34.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 403 LR: 0.000997675231565736 Training loss: 0.0
2025-12-09 10:24:34.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 404 LR: 0.0009976599238419944 Training loss: 0.0
2025-12-09 10:24:34.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 405 LR: 0.0009976445660039117 Training loss: 0.0
2025-12-09 10:24:34.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 406 LR: 0.000997629158053035 Training loss: 0.0
2025-12-09 10:24:34.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 407 LR: 0.0009976136999909156 Training loss: 0.0
2025-12-09 10:24:34.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 408 LR: 0.0009975981918191102 Training loss: 0.0
2025-12-09 10:24:34.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 409 LR: 0.0009975826335391806 Training loss: 0.0
2025-12-09 10:24:34.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 410 LR: 0.0009975670251526935 Training loss: 0.0
2025-12-09 10:24:34.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 411 LR: 0.0009975513666612204 Training loss: 0.0
2025-12-09 10:24:34.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 412 LR: 0.0009975356580663383 Training loss: 0.0
2025-12-09 10:24:34.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 413 LR: 0.0009975198993696292 Training loss: 0.0
2025-12-09 10:24:34.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 414 LR: 0.0009975040905726798 Training loss: 0.0
2025-12-09 10:24:34.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 415 LR: 0.0009974882316770822 Training loss: 0.0
2025-12-09 10:24:34.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 416 LR: 0.000997472322684433 Training loss: 0.0
2025-12-09 10:24:34.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 417 LR: 0.0009974563635963348 Training loss: 0.0
2025-12-09 10:24:34.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 418 LR: 0.0009974403544143941 Training loss: 0.0
2025-12-09 10:24:34.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 419 LR: 0.0009974242951402235 Training loss: 0.0
2025-12-09 10:24:34.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 420 LR: 0.00099740818577544 Training loss: 0.0
2025-12-09 10:24:34.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 421 LR: 0.0009973920263216657 Training loss: 0.0
2025-12-09 10:24:34.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 422 LR: 0.000997375816780528 Training loss: 0.0
2025-12-09 10:24:34.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 423 LR: 0.0009973595571536593 Training loss: 0.0
2025-12-09 10:24:34.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 424 LR: 0.0009973432474426967 Training loss: 0.0
2025-12-09 10:24:34.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 425 LR: 0.0009973268876492826 Training loss: 0.0
2025-12-09 10:24:34.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 426 LR: 0.0009973104777750645 Training loss: 0.0
2025-12-09 10:24:34.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 427 LR: 0.0009972940178216952 Training loss: 0.0
2025-12-09 10:24:34.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 428 LR: 0.0009972775077908315 Training loss: 0.0
2025-12-09 10:24:34.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 429 LR: 0.0009972609476841367 Training loss: 0.0
2025-12-09 10:24:34.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 430 LR: 0.000997244337503278 Training loss: 0.0
2025-12-09 10:24:34.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 431 LR: 0.000997227677249928 Training loss: 0.0
2025-12-09 10:24:34.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 432 LR: 0.0009972109669257646 Training loss: 0.0
2025-12-09 10:24:34.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 433 LR: 0.0009971942065324705 Training loss: 0.0
2025-12-09 10:24:34.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 434 LR: 0.0009971773960717333 Training loss: 0.0
2025-12-09 10:24:34.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 435 LR: 0.000997160535545246 Training loss: 0.0
2025-12-09 10:24:34.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 436 LR: 0.000997143624954706 Training loss: 0.0
2025-12-09 10:24:34.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 437 LR: 0.000997126664301817 Training loss: 0.0
2025-12-09 10:24:34.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 438 LR: 0.0009971096535882865 Training loss: 0.0
2025-12-09 10:24:34.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 439 LR: 0.0009970925928158272 Training loss: 0.0
2025-12-09 10:24:34.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 440 LR: 0.0009970754819861576 Training loss: 0.0
2025-12-09 10:24:34.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 441 LR: 0.0009970583211010007 Training loss: 0.0
2025-12-09 10:24:34.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 442 LR: 0.0009970411101620843 Training loss: 0.0
2025-12-09 10:24:34.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 443 LR: 0.0009970238491711417 Training loss: 0.0
2025-12-09 10:24:34.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 444 LR: 0.0009970065381299112 Training loss: 0.0
2025-12-09 10:24:34.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 445 LR: 0.0009969891770401358 Training loss: 0.0
2025-12-09 10:24:34.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 446 LR: 0.0009969717659035638 Training loss: 0.0
2025-12-09 10:24:34.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 447 LR: 0.0009969543047219486 Training loss: 0.0
2025-12-09 10:24:34.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 448 LR: 0.0009969367934970486 Training loss: 0.0
2025-12-09 10:24:34.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 449 LR: 0.000996919232230627 Training loss: 0.0
2025-12-09 10:24:34.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 450 LR: 0.0009969016209244524 Training loss: 0.0
2025-12-09 10:24:34.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 451 LR: 0.0009968839595802983 Training loss: 0.0
2025-12-09 10:24:34.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 452 LR: 0.000996866248199943 Training loss: 0.0
2025-12-09 10:24:34.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 453 LR: 0.0009968484867851697 Training loss: 0.0
2025-12-09 10:24:34.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 454 LR: 0.000996830675337768 Training loss: 0.0
2025-12-09 10:24:34.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 455 LR: 0.0009968128138595305 Training loss: 0.0
2025-12-09 10:24:34.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 456 LR: 0.0009967949023522561 Training loss: 0.0
2025-12-09 10:24:34.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 457 LR: 0.000996776940817749 Training loss: 0.0
2025-12-09 10:24:34.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 458 LR: 0.0009967589292578173 Training loss: 0.0
2025-12-09 10:24:34.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 459 LR: 0.0009967408676742752 Training loss: 0.0
2025-12-09 10:24:34.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 460 LR: 0.0009967227560689412 Training loss: 0.0
2025-12-09 10:24:34.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 461 LR: 0.0009967045944436392 Training loss: 0.0
2025-12-09 10:24:34.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 462 LR: 0.000996686382800198 Training loss: 0.0
2025-12-09 10:24:34.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 463 LR: 0.000996668121140452 Training loss: 0.0
2025-12-09 10:24:34.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 464 LR: 0.0009966498094662398 Training loss: 0.0
2025-12-09 10:24:34.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 465 LR: 0.0009966314477794051 Training loss: 0.0
2025-12-09 10:24:34.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 466 LR: 0.0009966130360817974 Training loss: 0.0
2025-12-09 10:24:34.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 467 LR: 0.0009965945743752704 Training loss: 0.0
2025-12-09 10:24:34.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 468 LR: 0.0009965760626616835 Training loss: 0.0
2025-12-09 10:24:34.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 469 LR: 0.0009965575009429006 Training loss: 0.0
2025-12-09 10:24:34.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 470 LR: 0.000996538889220791 Training loss: 0.0
2025-12-09 10:24:34.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 471 LR: 0.0009965202274972286 Training loss: 0.0
2025-12-09 10:24:34.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 472 LR: 0.000996501515774093 Training loss: 0.0
2025-12-09 10:24:34.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 473 LR: 0.0009964827540532685 Training loss: 0.0
2025-12-09 10:24:34.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 474 LR: 0.0009964639423366442 Training loss: 0.0
2025-12-09 10:24:34.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 475 LR: 0.0009964450806261144 Training loss: 0.0
2025-12-09 10:24:34.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 476 LR: 0.0009964261689235786 Training loss: 0.0
2025-12-09 10:24:34.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 477 LR: 0.0009964072072309411 Training loss: 0.0
2025-12-09 10:24:34.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 478 LR: 0.0009963881955501114 Training loss: 0.0
2025-12-09 10:24:34.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 479 LR: 0.0009963691338830043 Training loss: 0.0
2025-12-09 10:24:34.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 480 LR: 0.0009963500222315387 Training loss: 0.0
2025-12-09 10:24:34.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 481 LR: 0.0009963308605976395 Training loss: 0.0
2025-12-09 10:24:34.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 482 LR: 0.0009963116489832362 Training loss: 0.0
2025-12-09 10:24:34.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 483 LR: 0.0009962923873902637 Training loss: 0.0
2025-12-09 10:24:34.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 484 LR: 0.0009962730758206612 Training loss: 0.0
2025-12-09 10:24:34.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 485 LR: 0.0009962537142763734 Training loss: 0.0
2025-12-09 10:24:34.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 486 LR: 0.00099623430275935 Training loss: 0.0
2025-12-09 10:24:34.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 487 LR: 0.0009962148412715462 Training loss: 0.0
2025-12-09 10:24:34.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 488 LR: 0.0009961953298149215 Training loss: 0.0
2025-12-09 10:24:34.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 489 LR: 0.0009961757683914405 Training loss: 0.0
2025-12-09 10:24:34.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 490 LR: 0.0009961561570030733 Training loss: 0.0
2025-12-09 10:24:34.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 491 LR: 0.0009961364956517947 Training loss: 0.0
2025-12-09 10:24:34.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 492 LR: 0.0009961167843395844 Training loss: 0.0
2025-12-09 10:24:34.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 493 LR: 0.0009960970230684276 Training loss: 0.0
2025-12-09 10:24:34.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 494 LR: 0.0009960772118403141 Training loss: 0.0
2025-12-09 10:24:34.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 495 LR: 0.000996057350657239 Training loss: 0.0
2025-12-09 10:24:34.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 496 LR: 0.0009960374395212022 Training loss: 0.0
2025-12-09 10:24:34.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 497 LR: 0.0009960174784342088 Training loss: 0.0
2025-12-09 10:24:34.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 498 LR: 0.000995997467398269 Training loss: 0.0
2025-12-09 10:24:34.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 499 LR: 0.0009959774064153978 Training loss: 0.0
2025-12-09 10:24:34.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 500 LR: 0.000995957295487615 Training loss: 0.0
2025-12-09 10:24:34.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 501 LR: 0.0009959371346169466 Training loss: 0.0
2025-12-09 10:24:34.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 502 LR: 0.000995916923805422 Training loss: 0.0
2025-12-09 10:24:34.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 503 LR: 0.000995896663055077 Training loss: 0.0
2025-12-09 10:24:34.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 504 LR: 0.0009958763523679514 Training loss: 0.0
2025-12-09 10:24:34.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 505 LR: 0.0009958559917460908 Training loss: 0.0
2025-12-09 10:24:34.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 506 LR: 0.0009958355811915452 Training loss: 0.0
2025-12-09 10:24:34.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 507 LR: 0.0009958151207063704 Training loss: 0.0
2025-12-09 10:24:34.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 508 LR: 0.0009957946102926263 Training loss: 0.0
2025-12-09 10:24:34.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 509 LR: 0.0009957740499523787 Training loss: 0.0
2025-12-09 10:24:34.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 510 LR: 0.0009957534396876975 Training loss: 0.0
2025-12-09 10:24:34.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 511 LR: 0.0009957327795006587 Training loss: 0.0
2025-12-09 10:24:34.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 512 LR: 0.0009957120693933428 Training loss: 0.0
2025-12-09 10:24:34.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 513 LR: 0.0009956913093678349 Training loss: 0.0
2025-12-09 10:24:34.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 514 LR: 0.0009956704994262256 Training loss: 0.0
2025-12-09 10:24:34.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 515 LR: 0.0009956496395706106 Training loss: 0.0
2025-12-09 10:24:34.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 516 LR: 0.0009956287298030905 Training loss: 0.0
2025-12-09 10:24:34.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 517 LR: 0.0009956077701257708 Training loss: 0.0
2025-12-09 10:24:34.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 518 LR: 0.0009955867605407624 Training loss: 0.0
2025-12-09 10:24:34.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 519 LR: 0.0009955657010501807 Training loss: 0.0
2025-12-09 10:24:34.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 520 LR: 0.0009955445916561463 Training loss: 0.0
2025-12-09 10:24:34.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 521 LR: 0.0009955234323607853 Training loss: 0.0
2025-12-09 10:24:34.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 522 LR: 0.000995502223166228 Training loss: 0.0
2025-12-09 10:24:34.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 523 LR: 0.0009954809640746105 Training loss: 0.0
2025-12-09 10:24:34.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 524 LR: 0.0009954596550880734 Training loss: 0.0
2025-12-09 10:24:34.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 525 LR: 0.0009954382962087628 Training loss: 0.0
2025-12-09 10:24:34.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 526 LR: 0.0009954168874388293 Training loss: 0.0
2025-12-09 10:24:34.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 527 LR: 0.0009953954287804285 Training loss: 0.0
2025-12-09 10:24:34.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 528 LR: 0.0009953739202357217 Training loss: 0.0
2025-12-09 10:24:34.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 529 LR: 0.000995352361806875 Training loss: 0.0
2025-12-09 10:24:34.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 530 LR: 0.0009953307534960585 Training loss: 0.0
2025-12-09 10:24:34.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 531 LR: 0.000995309095305449 Training loss: 0.0
2025-12-09 10:24:34.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 532 LR: 0.0009952873872372272 Training loss: 0.0
2025-12-09 10:24:34.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 533 LR: 0.0009952656292935788 Training loss: 0.0
2025-12-09 10:24:34.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 534 LR: 0.0009952438214766955 Training loss: 0.0
2025-12-09 10:24:34.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 535 LR: 0.0009952219637887724 Training loss: 0.0
2025-12-09 10:24:34.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 536 LR: 0.0009952000562320116 Training loss: 0.0
2025-12-09 10:24:34.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 537 LR: 0.0009951780988086184 Training loss: 0.0
2025-12-09 10:24:34.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 538 LR: 0.0009951560915208043 Training loss: 0.0
2025-12-09 10:24:34.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 539 LR: 0.0009951340343707852 Training loss: 0.0
2025-12-09 10:24:34.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 540 LR: 0.0009951119273607825 Training loss: 0.0
2025-12-09 10:24:34.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 541 LR: 0.0009950897704930222 Training loss: 0.0
2025-12-09 10:24:34.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 542 LR: 0.0009950675637697354 Training loss: 0.0
2025-12-09 10:24:34.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 543 LR: 0.0009950453071931589 Training loss: 0.0
2025-12-09 10:24:34.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 544 LR: 0.0009950230007655333 Training loss: 0.0
2025-12-09 10:24:34.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 545 LR: 0.0009950006444891049 Training loss: 0.0
2025-12-09 10:24:34.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 546 LR: 0.0009949782383661253 Training loss: 0.0
2025-12-09 10:24:34.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 547 LR: 0.0009949557823988506 Training loss: 0.0
2025-12-09 10:24:34.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 548 LR: 0.0009949332765895422 Training loss: 0.0
2025-12-09 10:24:34.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 549 LR: 0.0009949107209404665 Training loss: 0.0
2025-12-09 10:24:34.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 550 LR: 0.0009948881154538945 Training loss: 0.0
2025-12-09 10:24:34.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 551 LR: 0.000994865460132103 Training loss: 0.0
2025-12-09 10:24:34.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 552 LR: 0.000994842754977373 Training loss: 0.0
2025-12-09 10:24:34.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 553 LR: 0.0009948199999919914 Training loss: 0.0
2025-12-09 10:24:34.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 554 LR: 0.0009947971951782492 Training loss: 0.0
2025-12-09 10:24:34.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 555 LR: 0.0009947743405384428 Training loss: 0.0
2025-12-09 10:24:34.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 556 LR: 0.000994751436074874 Training loss: 0.0
2025-12-09 10:24:34.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 557 LR: 0.0009947284817898492 Training loss: 0.0
2025-12-09 10:24:34.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 558 LR: 0.0009947054776856797 Training loss: 0.0
2025-12-09 10:24:34.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 559 LR: 0.0009946824237646824 Training loss: 0.0
2025-12-09 10:24:34.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 560 LR: 0.0009946593200291782 Training loss: 0.0
2025-12-09 10:24:34.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 561 LR: 0.0009946361664814943 Training loss: 0.0
2025-12-09 10:24:34.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 562 LR: 0.0009946129631239618 Training loss: 0.0
2025-12-09 10:24:34.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 563 LR: 0.0009945897099589173 Training loss: 0.0
2025-12-09 10:24:34.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 564 LR: 0.0009945664069887028 Training loss: 0.0
2025-12-09 10:24:34.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 565 LR: 0.0009945430542156646 Training loss: 0.0
2025-12-09 10:24:34.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 566 LR: 0.0009945196516421542 Training loss: 0.0
2025-12-09 10:24:34.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 567 LR: 0.0009944961992705288 Training loss: 0.0
2025-12-09 10:24:34.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 568 LR: 0.0009944726971031492 Training loss: 0.0
2025-12-09 10:24:34.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 569 LR: 0.0009944491451423828 Training loss: 0.0
2025-12-09 10:24:34.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 570 LR: 0.000994425543390601 Training loss: 0.0
2025-12-09 10:24:34.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 571 LR: 0.0009944018918501805 Training loss: 0.0
2025-12-09 10:24:34.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 572 LR: 0.000994378190523503 Training loss: 0.0
2025-12-09 10:24:34.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 573 LR: 0.000994354439412955 Training loss: 0.0
2025-12-09 10:24:34.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 574 LR: 0.000994330638520929 Training loss: 0.0
2025-12-09 10:24:34.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 575 LR: 0.000994306787849821 Training loss: 0.0
2025-12-09 10:24:34.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 576 LR: 0.0009942828874020327 Training loss: 0.0
2025-12-09 10:24:34.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 577 LR: 0.0009942589371799715 Training loss: 0.0
2025-12-09 10:24:34.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 578 LR: 0.0009942349371860487 Training loss: 0.0
2025-12-09 10:24:34.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 579 LR: 0.0009942108874226813 Training loss: 0.0
2025-12-09 10:24:34.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 580 LR: 0.000994186787892291 Training loss: 0.0
2025-12-09 10:24:34.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 581 LR: 0.0009941626385973046 Training loss: 0.0
2025-12-09 10:24:34.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 582 LR: 0.0009941384395401542 Training loss: 0.0
2025-12-09 10:24:34.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 583 LR: 0.0009941141907232765 Training loss: 0.0
2025-12-09 10:24:34.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 584 LR: 0.0009940898921491131 Training loss: 0.0
2025-12-09 10:24:34.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 585 LR: 0.0009940655438201113 Training loss: 0.0
2025-12-09 10:24:34.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 586 LR: 0.0009940411457387227 Training loss: 0.0
2025-12-09 10:24:34.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 587 LR: 0.000994016697907404 Training loss: 0.0
2025-12-09 10:24:34.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 588 LR: 0.0009939922003286176 Training loss: 0.0
2025-12-09 10:24:34.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 589 LR: 0.00099396765300483 Training loss: 0.0
2025-12-09 10:24:34.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 590 LR: 0.0009939430559385133 Training loss: 0.0
2025-12-09 10:24:34.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 591 LR: 0.0009939184091321445 Training loss: 0.0
2025-12-09 10:24:34.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 592 LR: 0.0009938937125882053 Training loss: 0.0
2025-12-09 10:24:34.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 593 LR: 0.0009938689663091828 Training loss: 0.0
2025-12-09 10:24:34.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 594 LR: 0.0009938441702975688 Training loss: 0.0
2025-12-09 10:24:34.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 595 LR: 0.0009938193245558607 Training loss: 0.0
2025-12-09 10:24:34.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 596 LR: 0.0009937944290865598 Training loss: 0.0
2025-12-09 10:24:34.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 597 LR: 0.0009937694838921733 Training loss: 0.0
2025-12-09 10:24:34.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 598 LR: 0.0009937444889752136 Training loss: 0.0
2025-12-09 10:24:34.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 599 LR: 0.0009937194443381972 Training loss: 0.0
2025-12-09 10:24:34.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 600 LR: 0.0009936943499836463 Training loss: 0.0
2025-12-09 10:24:34.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 601 LR: 0.0009936692059140878 Training loss: 0.0
2025-12-09 10:24:34.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 602 LR: 0.000993644012132054 Training loss: 0.0
2025-12-09 10:24:34.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 603 LR: 0.0009936187686400814 Training loss: 0.0
2025-12-09 10:24:34.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 604 LR: 0.0009935934754407125 Training loss: 0.0
2025-12-09 10:24:34.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 605 LR: 0.000993568132536494 Training loss: 0.0
2025-12-09 10:24:34.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 606 LR: 0.0009935427399299782 Training loss: 0.0
2025-12-09 10:24:34.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 607 LR: 0.0009935172976237219 Training loss: 0.0
2025-12-09 10:24:34.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 608 LR: 0.000993491805620287 Training loss: 0.0
2025-12-09 10:24:34.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 609 LR: 0.0009934662639222412 Training loss: 0.0
2025-12-09 10:24:34.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 610 LR: 0.0009934406725321558 Training loss: 0.0
2025-12-09 10:24:34.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 611 LR: 0.0009934150314526084 Training loss: 0.0
2025-12-09 10:24:34.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 612 LR: 0.0009933893406861808 Training loss: 0.0
2025-12-09 10:24:34.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 613 LR: 0.00099336360023546 Training loss: 0.0
2025-12-09 10:24:34.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 614 LR: 0.0009933378101030382 Training loss: 0.0
2025-12-09 10:24:34.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 615 LR: 0.0009933119702915125 Training loss: 0.0
2025-12-09 10:24:34.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 616 LR: 0.0009932860808034847 Training loss: 0.0
2025-12-09 10:24:34.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 617 LR: 0.0009932601416415621 Training loss: 0.0
2025-12-09 10:24:34.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 618 LR: 0.0009932341528083569 Training loss: 0.0
2025-12-09 10:24:34.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 619 LR: 0.000993208114306486 Training loss: 0.0
2025-12-09 10:24:34.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 620 LR: 0.0009931820261385713 Training loss: 0.0
2025-12-09 10:24:34.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 621 LR: 0.0009931558883072402 Training loss: 0.0
2025-12-09 10:24:34.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 622 LR: 0.0009931297008151246 Training loss: 0.0
2025-12-09 10:24:34.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 623 LR: 0.0009931034636648617 Training loss: 0.0
2025-12-09 10:24:34.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 624 LR: 0.0009930771768590933 Training loss: 0.0
2025-12-09 10:24:34.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 625 LR: 0.0009930508404004668 Training loss: 0.0
2025-12-09 10:24:34.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 626 LR: 0.0009930244542916342 Training loss: 0.0
2025-12-09 10:24:34.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 627 LR: 0.0009929980185352525 Training loss: 0.0
2025-12-09 10:24:34.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 628 LR: 0.0009929715331339838 Training loss: 0.0
2025-12-09 10:24:34.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 629 LR: 0.0009929449980904952 Training loss: 0.0
2025-12-09 10:24:34.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 630 LR: 0.0009929184134074588 Training loss: 0.0
2025-12-09 10:24:34.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 631 LR: 0.0009928917790875517 Training loss: 0.0
2025-12-09 10:24:34.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 632 LR: 0.000992865095133456 Training loss: 0.0
2025-12-09 10:24:34.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 633 LR: 0.0009928383615478585 Training loss: 0.0
2025-12-09 10:24:34.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 634 LR: 0.0009928115783334518 Training loss: 0.0
2025-12-09 10:24:34.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 635 LR: 0.0009927847454929322 Training loss: 0.0
2025-12-09 10:24:34.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 636 LR: 0.0009927578630290026 Training loss: 0.0
2025-12-09 10:24:34.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 637 LR: 0.0009927309309443696 Training loss: 0.0
2025-12-09 10:24:34.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 638 LR: 0.000992703949241745 Training loss: 0.0
2025-12-09 10:24:34.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 639 LR: 0.0009926769179238466 Training loss: 0.0
2025-12-09 10:24:34.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 640 LR: 0.0009926498369933958 Training loss: 0.0
2025-12-09 10:24:34.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 641 LR: 0.00099262270645312 Training loss: 0.0
2025-12-09 10:24:34.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 642 LR: 0.0009925955263057511 Training loss: 0.0
2025-12-09 10:24:34.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 643 LR: 0.0009925682965540262 Training loss: 0.0
2025-12-09 10:24:34.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 644 LR: 0.0009925410172006873 Training loss: 0.0
2025-12-09 10:24:34.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 645 LR: 0.0009925136882484816 Training loss: 0.0
2025-12-09 10:24:34.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 646 LR: 0.0009924863097001608 Training loss: 0.0
2025-12-09 10:24:34.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 647 LR: 0.0009924588815584821 Training loss: 0.0
2025-12-09 10:24:34.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 648 LR: 0.0009924314038262075 Training loss: 0.0
2025-12-09 10:24:34.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 649 LR: 0.000992403876506104 Training loss: 0.0
2025-12-09 10:24:34.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 650 LR: 0.0009923762996009438 Training loss: 0.0
2025-12-09 10:24:34.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 651 LR: 0.0009923486731135034 Training loss: 0.0
2025-12-09 10:24:34.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 652 LR: 0.0009923209970465652 Training loss: 0.0
2025-12-09 10:24:34.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 653 LR: 0.0009922932714029162 Training loss: 0.0
2025-12-09 10:24:34.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 654 LR: 0.0009922654961853482 Training loss: 0.0
2025-12-09 10:24:34.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 655 LR: 0.000992237671396658 Training loss: 0.0
2025-12-09 10:24:34.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 656 LR: 0.000992209797039648 Training loss: 0.0
2025-12-09 10:24:34.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 657 LR: 0.0009921818731171248 Training loss: 0.0
2025-12-09 10:24:34.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 658 LR: 0.0009921538996319004 Training loss: 0.0
2025-12-09 10:24:34.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 659 LR: 0.0009921258765867918 Training loss: 0.0
2025-12-09 10:24:34.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 660 LR: 0.000992097803984621 Training loss: 0.0
2025-12-09 10:24:34.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 661 LR: 0.0009920696818282147 Training loss: 0.0
2025-12-09 10:24:34.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 662 LR: 0.000992041510120405 Training loss: 0.0
2025-12-09 10:24:34.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 663 LR: 0.0009920132888640285 Training loss: 0.0
2025-12-09 10:24:34.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 664 LR: 0.0009919850180619275 Training loss: 0.0
2025-12-09 10:24:34.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 665 LR: 0.0009919566977169485 Training loss: 0.0
2025-12-09 10:24:34.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 666 LR: 0.0009919283278319434 Training loss: 0.0
2025-12-09 10:24:34.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 667 LR: 0.0009918999084097694 Training loss: 0.0
2025-12-09 10:24:34.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 668 LR: 0.0009918714394532879 Training loss: 0.0
2025-12-09 10:24:34.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 669 LR: 0.0009918429209653662 Training loss: 0.0
2025-12-09 10:24:34.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 670 LR: 0.0009918143529488754 Training loss: 0.0
2025-12-09 10:24:34.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 671 LR: 0.000991785735406693 Training loss: 0.0
2025-12-09 10:24:34.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 672 LR: 0.0009917570683417004 Training loss: 0.0
2025-12-09 10:24:34.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 673 LR: 0.0009917283517567844 Training loss: 0.0
2025-12-09 10:24:34.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 674 LR: 0.0009916995856548369 Training loss: 0.0
2025-12-09 10:24:34.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 675 LR: 0.0009916707700387546 Training loss: 0.0
2025-12-09 10:24:34.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 676 LR: 0.0009916419049114393 Training loss: 0.0
2025-12-09 10:24:34.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 677 LR: 0.0009916129902757976 Training loss: 0.0
2025-12-09 10:24:34.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 678 LR: 0.000991584026134741 Training loss: 0.0
2025-12-09 10:24:34.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 679 LR: 0.0009915550124911866 Training loss: 0.0
2025-12-09 10:24:34.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 680 LR: 0.000991525949348056 Training loss: 0.0
2025-12-09 10:24:34.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 681 LR: 0.0009914968367082755 Training loss: 0.0
2025-12-09 10:24:34.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 682 LR: 0.0009914676745747771 Training loss: 0.0
2025-12-09 10:24:34.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 683 LR: 0.0009914384629504972 Training loss: 0.0
2025-12-09 10:24:34.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 684 LR: 0.0009914092018383778 Training loss: 0.0
2025-12-09 10:24:34.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 685 LR: 0.0009913798912413651 Training loss: 0.0
2025-12-09 10:24:34.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 686 LR: 0.0009913505311624107 Training loss: 0.0
2025-12-09 10:24:34.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 687 LR: 0.0009913211216044714 Training loss: 0.0
2025-12-09 10:24:34.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 688 LR: 0.0009912916625705087 Training loss: 0.0
2025-12-09 10:24:34.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 689 LR: 0.0009912621540634887 Training loss: 0.0
2025-12-09 10:24:34.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 690 LR: 0.0009912325960863835 Training loss: 0.0
2025-12-09 10:24:34.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 691 LR: 0.000991202988642169 Training loss: 0.0
2025-12-09 10:24:34.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 692 LR: 0.0009911733317338272 Training loss: 0.0
2025-12-09 10:24:34.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 693 LR: 0.0009911436253643444 Training loss: 0.0
2025-12-09 10:24:34.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 694 LR: 0.0009911138695367118 Training loss: 0.0
2025-12-09 10:24:34.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 695 LR: 0.0009910840642539261 Training loss: 0.0
2025-12-09 10:24:34.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 696 LR: 0.0009910542095189884 Training loss: 0.0
2025-12-09 10:24:34.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 697 LR: 0.0009910243053349054 Training loss: 0.0
2025-12-09 10:24:34.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 698 LR: 0.0009909943517046884 Training loss: 0.0
2025-12-09 10:24:34.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 699 LR: 0.0009909643486313534 Training loss: 0.0
2025-12-09 10:24:34.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 700 LR: 0.000990934296117922 Training loss: 0.0
2025-12-09 10:24:34.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 701 LR: 0.0009909041941674203 Training loss: 0.0
2025-12-09 10:24:34.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 702 LR: 0.0009908740427828798 Training loss: 0.0
2025-12-09 10:24:34.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 703 LR: 0.0009908438419673367 Training loss: 0.0
2025-12-09 10:24:34.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 704 LR: 0.000990813591723832 Training loss: 0.0
2025-12-09 10:24:34.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 705 LR: 0.000990783292055412 Training loss: 0.0
2025-12-09 10:24:34.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 706 LR: 0.000990752942965128 Training loss: 0.0
2025-12-09 10:24:34.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 707 LR: 0.0009907225444560361 Training loss: 0.0
2025-12-09 10:24:34.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 708 LR: 0.0009906920965311974 Training loss: 0.0
2025-12-09 10:24:34.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 709 LR: 0.000990661599193678 Training loss: 0.0
2025-12-09 10:24:34.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 710 LR: 0.0009906310524465491 Training loss: 0.0
2025-12-09 10:24:34.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 711 LR: 0.0009906004562928864 Training loss: 0.0
2025-12-09 10:24:34.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 712 LR: 0.0009905698107357714 Training loss: 0.0
2025-12-09 10:24:34.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 713 LR: 0.0009905391157782896 Training loss: 0.0
2025-12-09 10:24:34.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 714 LR: 0.0009905083714235325 Training loss: 0.0
2025-12-09 10:24:34.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 715 LR: 0.0009904775776745957 Training loss: 0.0
2025-12-09 10:24:34.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 716 LR: 0.0009904467345345804 Training loss: 0.0
2025-12-09 10:24:34.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 717 LR: 0.0009904158420065922 Training loss: 0.0
2025-12-09 10:24:34.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 718 LR: 0.0009903849000937423 Training loss: 0.0
2025-12-09 10:24:34.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 719 LR: 0.0009903539087991462 Training loss: 0.0
2025-12-09 10:24:34.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 720 LR: 0.000990322868125925 Training loss: 0.0
2025-12-09 10:24:34.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 721 LR: 0.0009902917780772044 Training loss: 0.0
2025-12-09 10:24:34.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 722 LR: 0.000990260638656115 Training loss: 0.0
2025-12-09 10:24:34.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 723 LR: 0.0009902294498657929 Training loss: 0.0
2025-12-09 10:24:34.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 724 LR: 0.0009901982117093786 Training loss: 0.0
2025-12-09 10:24:34.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 725 LR: 0.0009901669241900177 Training loss: 0.0
2025-12-09 10:24:34.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 726 LR: 0.000990135587310861 Training loss: 0.0
2025-12-09 10:24:34.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 727 LR: 0.000990104201075064 Training loss: 0.0
2025-12-09 10:24:34.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 728 LR: 0.0009900727654857874 Training loss: 0.0
2025-12-09 10:24:34.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 729 LR: 0.0009900412805461966 Training loss: 0.0
2025-12-09 10:24:34.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 730 LR: 0.0009900097462594625 Training loss: 0.0
2025-12-09 10:24:34.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 731 LR: 0.0009899781626287604 Training loss: 0.0
2025-12-09 10:24:34.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 732 LR: 0.0009899465296572705 Training loss: 0.0
2025-12-09 10:24:34.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 733 LR: 0.0009899148473481785 Training loss: 0.0
2025-12-09 10:24:34.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 734 LR: 0.0009898831157046748 Training loss: 0.0
2025-12-09 10:24:34.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 735 LR: 0.0009898513347299548 Training loss: 0.0
2025-12-09 10:24:34.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 736 LR: 0.0009898195044272188 Training loss: 0.0
2025-12-09 10:24:34.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 737 LR: 0.000989787624799672 Training loss: 0.0
2025-12-09 10:24:34.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 738 LR: 0.000989755695850525 Training loss: 0.0
2025-12-09 10:24:34.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 739 LR: 0.0009897237175829927 Training loss: 0.0
2025-12-09 10:24:34.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 740 LR: 0.0009896916900002954 Training loss: 0.0
2025-12-09 10:24:34.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 741 LR: 0.0009896596131056584 Training loss: 0.0
2025-12-09 10:24:34.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 742 LR: 0.0009896274869023117 Training loss: 0.0
2025-12-09 10:24:34.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 743 LR: 0.0009895953113934904 Training loss: 0.0
2025-12-09 10:24:34.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 744 LR: 0.0009895630865824347 Training loss: 0.0
2025-12-09 10:24:34.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 745 LR: 0.0009895308124723897 Training loss: 0.0
2025-12-09 10:24:34.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 746 LR: 0.000989498489066605 Training loss: 0.0
2025-12-09 10:24:34.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 747 LR: 0.000989466116368336 Training loss: 0.0
2025-12-09 10:24:34.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 748 LR: 0.0009894336943808426 Training loss: 0.0
2025-12-09 10:24:34.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 749 LR: 0.0009894012231073895 Training loss: 0.0
2025-12-09 10:24:34.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 750 LR: 0.0009893687025512464 Training loss: 0.0
2025-12-09 10:24:34.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 751 LR: 0.0009893361327156886 Training loss: 0.0
2025-12-09 10:24:34.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 752 LR: 0.0009893035136039955 Training loss: 0.0
2025-12-09 10:24:34.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 753 LR: 0.0009892708452194521 Training loss: 0.0
2025-12-09 10:24:34.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 754 LR: 0.0009892381275653477 Training loss: 0.0
2025-12-09 10:24:34.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 755 LR: 0.0009892053606449776 Training loss: 0.0
2025-12-09 10:24:34.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 756 LR: 0.0009891725444616409 Training loss: 0.0
2025-12-09 10:24:34.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 757 LR: 0.0009891396790186423 Training loss: 0.0
2025-12-09 10:24:34.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 758 LR: 0.0009891067643192915 Training loss: 0.0
2025-12-09 10:24:34.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 759 LR: 0.0009890738003669028 Training loss: 0.0
2025-12-09 10:24:34.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 760 LR: 0.0009890407871647959 Training loss: 0.0
2025-12-09 10:24:34.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 761 LR: 0.000989007724716295 Training loss: 0.0
2025-12-09 10:24:34.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 762 LR: 0.0009889746130247296 Training loss: 0.0
2025-12-09 10:24:34.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 763 LR: 0.0009889414520934344 Training loss: 0.0
2025-12-09 10:24:34.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 764 LR: 0.000988908241925748 Training loss: 0.0
2025-12-09 10:24:34.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 765 LR: 0.0009888749825250152 Training loss: 0.0
2025-12-09 10:24:34.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 766 LR: 0.0009888416738945847 Training loss: 0.0
2025-12-09 10:24:34.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 767 LR: 0.0009888083160378112 Training loss: 0.0
2025-12-09 10:24:34.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 768 LR: 0.0009887749089580538 Training loss: 0.0
2025-12-09 10:24:34.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 769 LR: 0.0009887414526586764 Training loss: 0.0
2025-12-09 10:24:34.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 770 LR: 0.000988707947143048 Training loss: 0.0
2025-12-09 10:24:34.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 771 LR: 0.0009886743924145426 Training loss: 0.0
2025-12-09 10:24:34.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 772 LR: 0.0009886407884765393 Training loss: 0.0
2025-12-09 10:24:34.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 773 LR: 0.0009886071353324222 Training loss: 0.0
2025-12-09 10:24:34.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 774 LR: 0.0009885734329855799 Training loss: 0.0
2025-12-09 10:24:34.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 775 LR: 0.000988539681439406 Training loss: 0.0
2025-12-09 10:24:34.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 776 LR: 0.0009885058806972998 Training loss: 0.0
2025-12-09 10:24:34.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 777 LR: 0.0009884720307626648 Training loss: 0.0
2025-12-09 10:24:34.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 778 LR: 0.0009884381316389093 Training loss: 0.0
2025-12-09 10:24:34.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 779 LR: 0.0009884041833294476 Training loss: 0.0
2025-12-09 10:24:34.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 780 LR: 0.0009883701858376978 Training loss: 0.0
2025-12-09 10:24:34.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 781 LR: 0.000988336139167084 Training loss: 0.0
2025-12-09 10:24:34.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 782 LR: 0.0009883020433210342 Training loss: 0.0
2025-12-09 10:24:34.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 783 LR: 0.0009882678983029818 Training loss: 0.0
2025-12-09 10:24:34.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 784 LR: 0.0009882337041163655 Training loss: 0.0
2025-12-09 10:24:34.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 785 LR: 0.0009881994607646286 Training loss: 0.0
2025-12-09 10:24:34.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 786 LR: 0.0009881651682512194 Training loss: 0.0
2025-12-09 10:24:34.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 787 LR: 0.0009881308265795913 Training loss: 0.0
2025-12-09 10:24:34.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 788 LR: 0.000988096435753202 Training loss: 0.0
2025-12-09 10:24:34.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 789 LR: 0.000988061995775515 Training loss: 0.0
2025-12-09 10:24:34.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 790 LR: 0.0009880275066499985 Training loss: 0.0
2025-12-09 10:24:34.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 791 LR: 0.0009879929683801255 Training loss: 0.0
2025-12-09 10:24:34.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 792 LR: 0.0009879583809693738 Training loss: 0.0
2025-12-09 10:24:34.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 793 LR: 0.0009879237444212264 Training loss: 0.0
2025-12-09 10:24:34.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 794 LR: 0.0009878890587391716 Training loss: 0.0
2025-12-09 10:24:34.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 795 LR: 0.0009878543239267015 Training loss: 0.0
2025-12-09 10:24:34.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 796 LR: 0.0009878195399873147 Training loss: 0.0
2025-12-09 10:24:34.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 797 LR: 0.0009877847069245133 Training loss: 0.0
2025-12-09 10:24:34.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 798 LR: 0.0009877498247418055 Training loss: 0.0
2025-12-09 10:24:34.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 799 LR: 0.0009877148934427035 Training loss: 0.0
2025-12-09 10:24:34.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 800 LR: 0.0009876799130307252 Training loss: 0.0
2025-12-09 10:24:34.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 801 LR: 0.000987644883509393 Training loss: 0.0
2025-12-09 10:24:34.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 802 LR: 0.0009876098048822342 Training loss: 0.0
2025-12-09 10:24:34.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 803 LR: 0.0009875746771527815 Training loss: 0.0
2025-12-09 10:24:34.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 804 LR: 0.0009875395003245723 Training loss: 0.0
2025-12-09 10:24:34.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 805 LR: 0.0009875042744011487 Training loss: 0.0
2025-12-09 10:24:34.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 806 LR: 0.0009874689993860579 Training loss: 0.0
2025-12-09 10:24:34.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 807 LR: 0.0009874336752828522 Training loss: 0.0
2025-12-09 10:24:34.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 808 LR: 0.0009873983020950888 Training loss: 0.0
2025-12-09 10:24:34.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 809 LR: 0.0009873628798263297 Training loss: 0.0
2025-12-09 10:24:34.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 810 LR: 0.000987327408480142 Training loss: 0.0
2025-12-09 10:24:34.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 811 LR: 0.0009872918880600974 Training loss: 0.0
2025-12-09 10:24:34.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 812 LR: 0.0009872563185697731 Training loss: 0.0
2025-12-09 10:24:34.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 813 LR: 0.000987220700012751 Training loss: 0.0
2025-12-09 10:24:34.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 814 LR: 0.0009871850323926177 Training loss: 0.0
2025-12-09 10:24:34.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 815 LR: 0.0009871493157129648 Training loss: 0.0
2025-12-09 10:24:34.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 816 LR: 0.0009871135499773893 Training loss: 0.0
2025-12-09 10:24:34.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 817 LR: 0.0009870777351894927 Training loss: 0.0
2025-12-09 10:24:34.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 818 LR: 0.0009870418713528813 Training loss: 0.0
2025-12-09 10:24:34.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 819 LR: 0.0009870059584711668 Training loss: 0.0
2025-12-09 10:24:34.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 820 LR: 0.0009869699965479658 Training loss: 0.0
2025-12-09 10:24:34.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 821 LR: 0.0009869339855868992 Training loss: 0.0
2025-12-09 10:24:34.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 822 LR: 0.0009868979255915939 Training loss: 0.0
2025-12-09 10:24:34.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 823 LR: 0.0009868618165656804 Training loss: 0.0
2025-12-09 10:24:34.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 824 LR: 0.0009868256585127955 Training loss: 0.0
2025-12-09 10:24:34.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 825 LR: 0.0009867894514365802 Training loss: 0.0
2025-12-09 10:24:34.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 826 LR: 0.0009867531953406804 Training loss: 0.0
2025-12-09 10:24:34.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 827 LR: 0.0009867168902287472 Training loss: 0.0
2025-12-09 10:24:34.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 828 LR: 0.0009866805361044362 Training loss: 0.0
2025-12-09 10:24:34.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 829 LR: 0.000986644132971409 Training loss: 0.0
2025-12-09 10:24:34.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 830 LR: 0.0009866076808333305 Training loss: 0.0
2025-12-09 10:24:34.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 831 LR: 0.000986571179693872 Training loss: 0.0
2025-12-09 10:24:34.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 832 LR: 0.0009865346295567091 Training loss: 0.0
2025-12-09 10:24:34.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 833 LR: 0.0009864980304255223 Training loss: 0.0
2025-12-09 10:24:34.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 834 LR: 0.000986461382303997 Training loss: 0.0
2025-12-09 10:24:34.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 835 LR: 0.0009864246851958238 Training loss: 0.0
2025-12-09 10:24:34.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 836 LR: 0.0009863879391046983 Training loss: 0.0
2025-12-09 10:24:34.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 837 LR: 0.0009863511440343206 Training loss: 0.0
2025-12-09 10:24:34.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 838 LR: 0.000986314299988396 Training loss: 0.0
2025-12-09 10:24:34.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 839 LR: 0.0009862774069706345 Training loss: 0.0
2025-12-09 10:24:34.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 840 LR: 0.0009862404649847516 Training loss: 0.0
2025-12-09 10:24:34.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 841 LR: 0.0009862034740344672 Training loss: 0.0
2025-12-09 10:24:34.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 842 LR: 0.0009861664341235064 Training loss: 0.0
2025-12-09 10:24:34.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 843 LR: 0.0009861293452555987 Training loss: 0.0
2025-12-09 10:24:34.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 844 LR: 0.0009860922074344794 Training loss: 0.0
2025-12-09 10:24:34.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 845 LR: 0.0009860550206638881 Training loss: 0.0
2025-12-09 10:24:34.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 846 LR: 0.0009860177849475692 Training loss: 0.0
2025-12-09 10:24:34.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 847 LR: 0.0009859805002892731 Training loss: 0.0
2025-12-09 10:24:34.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 848 LR: 0.0009859431666927538 Training loss: 0.0
2025-12-09 10:24:34.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 849 LR: 0.000985905784161771 Training loss: 0.0
2025-12-09 10:24:35.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 850 LR: 0.0009858683527000887 Training loss: 0.0
2025-12-09 10:24:35.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 851 LR: 0.0009858308723114768 Training loss: 0.0
2025-12-09 10:24:35.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 852 LR: 0.0009857933429997094 Training loss: 0.0
2025-12-09 10:24:35.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 853 LR: 0.0009857557647685656 Training loss: 0.0
2025-12-09 10:24:35.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 854 LR: 0.0009857181376218295 Training loss: 0.0
2025-12-09 10:24:35.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 855 LR: 0.0009856804615632903 Training loss: 0.0
2025-12-09 10:24:35.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 856 LR: 0.0009856427365967418 Training loss: 0.0
2025-12-09 10:24:35.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 857 LR: 0.0009856049627259833 Training loss: 0.0
2025-12-09 10:24:35.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 858 LR: 0.000985567139954818 Training loss: 0.0
2025-12-09 10:24:35.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 859 LR: 0.000985529268287055 Training loss: 0.0
2025-12-09 10:24:35.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 860 LR: 0.0009854913477265084 Training loss: 0.0
2025-12-09 10:24:35.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 861 LR: 0.000985453378276996 Training loss: 0.0
2025-12-09 10:24:35.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 862 LR: 0.0009854153599423417 Training loss: 0.0
2025-12-09 10:24:35.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 863 LR: 0.000985377292726374 Training loss: 0.0
2025-12-09 10:24:35.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 864 LR: 0.0009853391766329262 Training loss: 0.0
2025-12-09 10:24:35.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 865 LR: 0.0009853010116658368 Training loss: 0.0
2025-12-09 10:24:35.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 866 LR: 0.0009852627978289485 Training loss: 0.0
2025-12-09 10:24:35.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 867 LR: 0.0009852245351261097 Training loss: 0.0
2025-12-09 10:24:35.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 868 LR: 0.0009851862235611738 Training loss: 0.0
2025-12-09 10:24:35.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 869 LR: 0.0009851478631379982 Training loss: 0.0
2025-12-09 10:24:35.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 870 LR: 0.000985109453860446 Training loss: 0.0
2025-12-09 10:24:35.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 871 LR: 0.0009850709957323854 Training loss: 0.0
2025-12-09 10:24:35.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 872 LR: 0.0009850324887576887 Training loss: 0.0
2025-12-09 10:24:35.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 873 LR: 0.0009849939329402335 Training loss: 0.0
2025-12-09 10:24:35.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 874 LR: 0.0009849553282839025 Training loss: 0.0
2025-12-09 10:24:35.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 875 LR: 0.0009849166747925835 Training loss: 0.0
2025-12-09 10:24:35.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 876 LR: 0.0009848779724701685 Training loss: 0.0
2025-12-09 10:24:35.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 877 LR: 0.0009848392213205547 Training loss: 0.0
2025-12-09 10:24:35.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 878 LR: 0.0009848004213476448 Training loss: 0.0
2025-12-09 10:24:35.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 879 LR: 0.0009847615725553456 Training loss: 0.0
2025-12-09 10:24:35.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 880 LR: 0.0009847226749475696 Training loss: 0.0
2025-12-09 10:24:35.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 881 LR: 0.000984683728528233 Training loss: 0.0
2025-12-09 10:24:35.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 882 LR: 0.0009846447333012587 Training loss: 0.0
2025-12-09 10:24:35.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 883 LR: 0.0009846056892705729 Training loss: 0.0
2025-12-09 10:24:35.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 884 LR: 0.0009845665964401072 Training loss: 0.0
2025-12-09 10:24:35.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 885 LR: 0.0009845274548137986 Training loss: 0.0
2025-12-09 10:24:35.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 886 LR: 0.0009844882643955885 Training loss: 0.0
2025-12-09 10:24:35.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 887 LR: 0.0009844490251894238 Training loss: 0.0
2025-12-09 10:24:35.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 888 LR: 0.000984409737199255 Training loss: 0.0
2025-12-09 10:24:35.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 889 LR: 0.0009843704004290394 Training loss: 0.0
2025-12-09 10:24:35.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 890 LR: 0.0009843310148827374 Training loss: 0.0
2025-12-09 10:24:35.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 891 LR: 0.0009842915805643156 Training loss: 0.0
2025-12-09 10:24:35.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 892 LR: 0.0009842520974777448 Training loss: 0.0
2025-12-09 10:24:35.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 893 LR: 0.0009842125656270011 Training loss: 0.0
2025-12-09 10:24:35.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 894 LR: 0.0009841729850160652 Training loss: 0.0
2025-12-09 10:24:35.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 895 LR: 0.0009841333556489232 Training loss: 0.0
2025-12-09 10:24:35.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 896 LR: 0.0009840936775295653 Training loss: 0.0
2025-12-09 10:24:35.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 897 LR: 0.0009840539506619874 Training loss: 0.0
2025-12-09 10:24:35.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 898 LR: 0.00098401417505019 Training loss: 0.0
2025-12-09 10:24:35.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 899 LR: 0.0009839743506981783 Training loss: 0.0
2025-12-09 10:24:35.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 900 LR: 0.0009839344776099625 Training loss: 0.0
2025-12-09 10:24:35.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 901 LR: 0.0009838945557895584 Training loss: 0.0
2025-12-09 10:24:35.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 902 LR: 0.0009838545852409856 Training loss: 0.0
2025-12-09 10:24:35.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 903 LR: 0.0009838145659682694 Training loss: 0.0
2025-12-09 10:24:35.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 904 LR: 0.0009837744979754395 Training loss: 0.0
2025-12-09 10:24:35.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 905 LR: 0.0009837343812665311 Training loss: 0.0
2025-12-09 10:24:35.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 906 LR: 0.0009836942158455836 Training loss: 0.0
2025-12-09 10:24:35.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 907 LR: 0.0009836540017166418 Training loss: 0.0
2025-12-09 10:24:35.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 908 LR: 0.0009836137388837553 Training loss: 0.0
2025-12-09 10:24:35.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 909 LR: 0.0009835734273509786 Training loss: 0.0
2025-12-09 10:24:35.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 910 LR: 0.0009835330671223708 Training loss: 0.0
2025-12-09 10:24:35.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 911 LR: 0.0009834926582019967 Training loss: 0.0
2025-12-09 10:24:35.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 912 LR: 0.0009834522005939248 Training loss: 0.0
2025-12-09 10:24:35.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 913 LR: 0.0009834116943022299 Training loss: 0.0
2025-12-09 10:24:35.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 914 LR: 0.0009833711393309901 Training loss: 0.0
2025-12-09 10:24:35.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 915 LR: 0.00098333053568429 Training loss: 0.0
2025-12-09 10:24:35.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 916 LR: 0.0009832898833662185 Training loss: 0.0
2025-12-09 10:24:35.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 917 LR: 0.0009832491823808687 Training loss: 0.0
2025-12-09 10:24:35.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 918 LR: 0.0009832084327323395 Training loss: 0.0
2025-12-09 10:24:35.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 919 LR: 0.0009831676344247342 Training loss: 0.0
2025-12-09 10:24:35.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 920 LR: 0.0009831267874621616 Training loss: 0.0
2025-12-09 10:24:35.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 921 LR: 0.0009830858918487345 Training loss: 0.0
2025-12-09 10:24:35.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 922 LR: 0.0009830449475885714 Training loss: 0.0
2025-12-09 10:24:35.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 923 LR: 0.0009830039546857954 Training loss: 0.0
2025-12-09 10:24:35.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 924 LR: 0.0009829629131445341 Training loss: 0.0
2025-12-09 10:24:35.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 925 LR: 0.000982921822968921 Training loss: 0.0
2025-12-09 10:24:35.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 926 LR: 0.0009828806841630934 Training loss: 0.0
2025-12-09 10:24:35.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 927 LR: 0.000982839496731194 Training loss: 0.0
2025-12-09 10:24:35.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 928 LR: 0.0009827982606773705 Training loss: 0.0
2025-12-09 10:24:35.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 929 LR: 0.0009827569760057755 Training loss: 0.0
2025-12-09 10:24:35.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 930 LR: 0.0009827156427205661 Training loss: 0.0
2025-12-09 10:24:35.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 931 LR: 0.0009826742608259047 Training loss: 0.0
2025-12-09 10:24:35.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 932 LR: 0.0009826328303259586 Training loss: 0.0
2025-12-09 10:24:35.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 933 LR: 0.0009825913512248995 Training loss: 0.0
2025-12-09 10:24:35.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 934 LR: 0.0009825498235269045 Training loss: 0.0
2025-12-09 10:24:35.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 935 LR: 0.0009825082472361558 Training loss: 0.0
2025-12-09 10:24:35.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 936 LR: 0.0009824666223568394 Training loss: 0.0
2025-12-09 10:24:35.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 937 LR: 0.0009824249488931476 Training loss: 0.0
2025-12-09 10:24:35.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 938 LR: 0.0009823832268492766 Training loss: 0.0
2025-12-09 10:24:35.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 939 LR: 0.000982341456229428 Training loss: 0.0
2025-12-09 10:24:35.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 940 LR: 0.0009822996370378078 Training loss: 0.0
2025-12-09 10:24:35.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 941 LR: 0.0009822577692786272 Training loss: 0.0
2025-12-09 10:24:35.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 942 LR: 0.0009822158529561025 Training loss: 0.0
2025-12-09 10:24:35.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 943 LR: 0.0009821738880744547 Training loss: 0.0
2025-12-09 10:24:35.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 944 LR: 0.0009821318746379096 Training loss: 0.0
2025-12-09 10:24:35.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 945 LR: 0.0009820898126506978 Training loss: 0.0
2025-12-09 10:24:35.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 946 LR: 0.000982047702117055 Training loss: 0.0
2025-12-09 10:24:35.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 947 LR: 0.000982005543041222 Training loss: 0.0
2025-12-09 10:24:35.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 948 LR: 0.0009819633354274438 Training loss: 0.0
2025-12-09 10:24:35.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 949 LR: 0.000981921079279971 Training loss: 0.0
2025-12-09 10:24:35.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 950 LR: 0.0009818787746030588 Training loss: 0.0
2025-12-09 10:24:35.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 951 LR: 0.000981836421400967 Training loss: 0.0
2025-12-09 10:24:35.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 952 LR: 0.000981794019677961 Training loss: 0.0
2025-12-09 10:24:35.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 953 LR: 0.0009817515694383102 Training loss: 0.0
2025-12-09 10:24:35.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 954 LR: 0.0009817090706862894 Training loss: 0.0
2025-12-09 10:24:35.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 955 LR: 0.0009816665234261787 Training loss: 0.0
2025-12-09 10:24:35.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 956 LR: 0.0009816239276622622 Training loss: 0.0
2025-12-09 10:24:35.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 957 LR: 0.0009815812833988292 Training loss: 0.0
2025-12-09 10:24:35.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 958 LR: 0.000981538590640174 Training loss: 0.0
2025-12-09 10:24:35.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 959 LR: 0.0009814958493905962 Training loss: 0.0
2025-12-09 10:24:35.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 960 LR: 0.0009814530596543994 Training loss: 0.0
2025-12-09 10:24:35.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 961 LR: 0.0009814102214358927 Training loss: 0.0
2025-12-09 10:24:35.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 962 LR: 0.00098136733473939 Training loss: 0.0
2025-12-09 10:24:35.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 963 LR: 0.0009813243995692097 Training loss: 0.0
2025-12-09 10:24:35.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 964 LR: 0.0009812814159296758 Training loss: 0.0
2025-12-09 10:24:35.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 965 LR: 0.000981238383825116 Training loss: 0.0
2025-12-09 10:24:35.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 966 LR: 0.0009811953032598643 Training loss: 0.0
2025-12-09 10:24:35.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 967 LR: 0.000981152174238259 Training loss: 0.0
2025-12-09 10:24:35.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 968 LR: 0.0009811089967646427 Training loss: 0.0
2025-12-09 10:24:35.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 969 LR: 0.0009810657708433637 Training loss: 0.0
2025-12-09 10:24:35.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 970 LR: 0.0009810224964787746 Training loss: 0.0
2025-12-09 10:24:35.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 971 LR: 0.0009809791736752334 Training loss: 0.0
2025-12-09 10:24:35.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 972 LR: 0.0009809358024371025 Training loss: 0.0
2025-12-09 10:24:35.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 973 LR: 0.0009808923827687493 Training loss: 0.0
2025-12-09 10:24:35.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 974 LR: 0.0009808489146745465 Training loss: 0.0
2025-12-09 10:24:35.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 975 LR: 0.000980805398158871 Training loss: 0.0
2025-12-09 10:24:35.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 976 LR: 0.0009807618332261052 Training loss: 0.0
2025-12-09 10:24:35.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 977 LR: 0.000980718219880636 Training loss: 0.0
2025-12-09 10:24:35.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 978 LR: 0.0009806745581268552 Training loss: 0.0
2025-12-09 10:24:35.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 979 LR: 0.0009806308479691594 Training loss: 0.0
2025-12-09 10:24:35.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 980 LR: 0.0009805870894119505 Training loss: 0.0
2025-12-09 10:24:35.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 981 LR: 0.0009805432824596348 Training loss: 0.0
2025-12-09 10:24:35.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 982 LR: 0.0009804994271166237 Training loss: 0.0
2025-12-09 10:24:35.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 983 LR: 0.0009804555233873333 Training loss: 0.0
2025-12-09 10:24:35.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 984 LR: 0.000980411571276185 Training loss: 0.0
2025-12-09 10:24:35.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 985 LR: 0.0009803675707876047 Training loss: 0.0
2025-12-09 10:24:35.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 986 LR: 0.000980323521926023 Training loss: 0.0
2025-12-09 10:24:35.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 987 LR: 0.000980279424695876 Training loss: 0.0
2025-12-09 10:24:35.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 988 LR: 0.000980235279101604 Training loss: 0.0
2025-12-09 10:24:35.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 989 LR: 0.0009801910851476522 Training loss: 0.0
2025-12-09 10:24:35.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 990 LR: 0.0009801468428384716 Training loss: 0.0
2025-12-09 10:24:35.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 991 LR: 0.000980102552178517 Training loss: 0.0
2025-12-09 10:24:35.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 992 LR: 0.0009800582131722483 Training loss: 0.0
2025-12-09 10:24:35.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 993 LR: 0.000980013825824131 Training loss: 0.0
2025-12-09 10:24:35.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 994 LR: 0.0009799693901386345 Training loss: 0.0
2025-12-09 10:24:35.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 995 LR: 0.0009799249061202336 Training loss: 0.0
2025-12-09 10:24:35.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 996 LR: 0.0009798803737734077 Training loss: 0.0
2025-12-09 10:24:35.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 997 LR: 0.0009798357931026412 Training loss: 0.0
2025-12-09 10:24:35.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 998 LR: 0.0009797911641124236 Training loss: 0.0
2025-12-09 10:24:35.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 999 LR: 0.0009797464868072487 Training loss: 0.0
2025-12-09 10:24:35.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 1000 LR: 0.000979701761191616 Training loss: 0.0
2025-12-09 10:24:35.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 1001 LR: 0.0009796569872700287 Training loss: 0.0
2025-12-09 10:24:35.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 1002 LR: 0.0009796121650469962 Training loss: 0.0
2025-12-09 10:24:35.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 1003 LR: 0.0009795672945270317 Training loss: 0.0
2025-12-09 10:24:35.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 1004 LR: 0.0009795223757146539 Training loss: 0.0
2025-12-09 10:24:35.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 1005 LR: 0.000979477408614386 Training loss: 0.0
2025-12-09 10:24:35.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 1006 LR: 0.0009794323932307558 Training loss: 0.0
2025-12-09 10:24:35.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 1007 LR: 0.000979387329568297 Training loss: 0.0
2025-12-09 10:24:35.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 1008 LR: 0.0009793422176315471 Training loss: 0.0
2025-12-09 10:24:35.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 1009 LR: 0.0009792970574250492 Training loss: 0.0
2025-12-09 10:24:35.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 1010 LR: 0.0009792518489533505 Training loss: 0.0
2025-12-09 10:24:35.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 1011 LR: 0.000979206592221004 Training loss: 0.0
2025-12-09 10:24:35.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 1012 LR: 0.0009791612872325666 Training loss: 0.0
2025-12-09 10:24:35.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 1013 LR: 0.0009791159339926007 Training loss: 0.0
2025-12-09 10:24:35.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 1014 LR: 0.0009790705325056735 Training loss: 0.0
2025-12-09 10:24:35.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 1015 LR: 0.0009790250827763566 Training loss: 0.0
2025-12-09 10:24:35.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 1016 LR: 0.000978979584809227 Training loss: 0.0
2025-12-09 10:24:35.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 1017 LR: 0.0009789340386088664 Training loss: 0.0
2025-12-09 10:24:35.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 1018 LR: 0.000978888444179861 Training loss: 0.0
2025-12-09 10:24:35.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 1019 LR: 0.0009788428015268028 Training loss: 0.0
2025-12-09 10:24:35.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 1020 LR: 0.0009787971106542872 Training loss: 0.0
2025-12-09 10:24:35.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 1021 LR: 0.0009787513715669158 Training loss: 0.0
2025-12-09 10:24:35.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 1022 LR: 0.0009787055842692943 Training loss: 0.0
2025-12-09 10:24:35.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 1023 LR: 0.0009786597487660335 Training loss: 0.0
2025-12-09 10:24:35.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 1024 LR: 0.0009786138650617494 Training loss: 0.0
2025-12-09 10:24:35.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 1025 LR: 0.000978567933161062 Training loss: 0.0
2025-12-09 10:24:35.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 1026 LR: 0.000978521953068597 Training loss: 0.0
2025-12-09 10:24:35.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 1027 LR: 0.000978475924788984 Training loss: 0.0
2025-12-09 10:24:35.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 1028 LR: 0.0009784298483268587 Training loss: 0.0
2025-12-09 10:24:35.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 1029 LR: 0.0009783837236868609 Training loss: 0.0
2025-12-09 10:24:35.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 1030 LR: 0.000978337550873635 Training loss: 0.0
2025-12-09 10:24:35.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 1031 LR: 0.000978291329891831 Training loss: 0.0
2025-12-09 10:24:35.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 1032 LR: 0.000978245060746103 Training loss: 0.0
2025-12-09 10:24:35.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 1033 LR: 0.0009781987434411105 Training loss: 0.0
2025-12-09 10:24:35.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 1034 LR: 0.0009781523779815178 Training loss: 0.0
2025-12-09 10:24:35.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 1035 LR: 0.0009781059643719937 Training loss: 0.0
2025-12-09 10:24:35.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 1036 LR: 0.0009780595026172118 Training loss: 0.0
2025-12-09 10:24:35.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 1037 LR: 0.0009780129927218512 Training loss: 0.0
2025-12-09 10:24:35.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 1038 LR: 0.0009779664346905954 Training loss: 0.0
2025-12-09 10:24:35.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 1039 LR: 0.0009779198285281327 Training loss: 0.0
2025-12-09 10:24:35.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 1040 LR: 0.0009778731742391563 Training loss: 0.0
2025-12-09 10:24:35.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 1041 LR: 0.0009778264718283644 Training loss: 0.0
2025-12-09 10:24:35.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 1042 LR: 0.0009777797213004595 Training loss: 0.0
2025-12-09 10:24:35.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 1043 LR: 0.0009777329226601501 Training loss: 0.0
2025-12-09 10:24:35.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 1044 LR: 0.0009776860759121485 Training loss: 0.0
2025-12-09 10:24:35.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 1045 LR: 0.0009776391810611717 Training loss: 0.0
2025-12-09 10:24:35.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 1046 LR: 0.000977592238111943 Training loss: 0.0
2025-12-09 10:24:35.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 1047 LR: 0.0009775452470691885 Training loss: 0.0
2025-12-09 10:24:35.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 1048 LR: 0.000977498207937641 Training loss: 0.0
2025-12-09 10:24:35.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 1049 LR: 0.0009774511207220368 Training loss: 0.0
2025-12-09 10:24:35.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 1050 LR: 0.0009774039854271181 Training loss: 0.0
2025-12-09 10:24:35.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 1051 LR: 0.000977356802057631 Training loss: 0.0
2025-12-09 10:24:35.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 1052 LR: 0.000977309570618327 Training loss: 0.0
2025-12-09 10:24:35.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 1053 LR: 0.0009772622911139622 Training loss: 0.0
2025-12-09 10:24:35.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 1054 LR: 0.0009772149635492978 Training loss: 0.0
2025-12-09 10:24:35.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 1055 LR: 0.0009771675879290996 Training loss: 0.0
2025-12-09 10:24:35.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 1056 LR: 0.0009771201642581385 Training loss: 0.0
2025-12-09 10:24:35.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 1057 LR: 0.0009770726925411896 Training loss: 0.0
2025-12-09 10:24:35.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 1058 LR: 0.0009770251727830338 Training loss: 0.0
2025-12-09 10:24:35.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 1059 LR: 0.0009769776049884564 Training loss: 0.0
2025-12-09 10:24:35.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 1060 LR: 0.000976929989162247 Training loss: 0.0
2025-12-09 10:24:35.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 1061 LR: 0.0009768823253092007 Training loss: 0.0
2025-12-09 10:24:35.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 1062 LR: 0.0009768346134341173 Training loss: 0.0
2025-12-09 10:24:35.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 1063 LR: 0.0009767868535418014 Training loss: 0.0
2025-12-09 10:24:35.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 1064 LR: 0.0009767390456370624 Training loss: 0.0
2025-12-09 10:24:35.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 1065 LR: 0.0009766911897247147 Training loss: 0.0
2025-12-09 10:24:35.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 1066 LR: 0.0009766432858095769 Training loss: 0.0
2025-12-09 10:24:35.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 1067 LR: 0.0009765953338964734 Training loss: 0.0
2025-12-09 10:24:35.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 1068 LR: 0.000976547333990233 Training loss: 0.0
2025-12-09 10:24:35.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 1069 LR: 0.0009764992860956889 Training loss: 0.0
2025-12-09 10:24:35.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 1070 LR: 0.0009764511902176799 Training loss: 0.0
2025-12-09 10:24:35.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 1071 LR: 0.0009764030463610489 Training loss: 0.0
2025-12-09 10:24:35.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 1072 LR: 0.0009763548545306443 Training loss: 0.0
2025-12-09 10:24:35.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 1073 LR: 0.0009763066147313188 Training loss: 0.0
2025-12-09 10:24:35.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 1074 LR: 0.0009762583269679303 Training loss: 0.0
2025-12-09 10:24:35.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 1075 LR: 0.0009762099912453413 Training loss: 0.0
2025-12-09 10:24:35.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 1076 LR: 0.0009761616075684191 Training loss: 0.0
2025-12-09 10:24:35.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 1077 LR: 0.000976113175942036 Training loss: 0.0
2025-12-09 10:24:35.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 1078 LR: 0.0009760646963710693 Training loss: 0.0
2025-12-09 10:24:35.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 1079 LR: 0.0009760161688604008 Training loss: 0.0
2025-12-09 10:24:35.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 1080 LR: 0.0009759675934149168 Training loss: 0.0
2025-12-09 10:24:35.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 1081 LR: 0.0009759189700395094 Training loss: 0.0
2025-12-09 10:24:35.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 1082 LR: 0.0009758702987390746 Training loss: 0.0
2025-12-09 10:24:35.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 1083 LR: 0.0009758215795185139 Training loss: 0.0
2025-12-09 10:24:35.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 1084 LR: 0.000975772812382733 Training loss: 0.0
2025-12-09 10:24:35.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 1085 LR: 0.0009757239973366429 Training loss: 0.0
2025-12-09 10:24:35.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 1086 LR: 0.0009756751343851594 Training loss: 0.0
2025-12-09 10:24:35.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 1087 LR: 0.0009756262235332029 Training loss: 0.0
2025-12-09 10:24:35.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 1088 LR: 0.0009755772647856986 Training loss: 0.0
2025-12-09 10:24:35.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 1089 LR: 0.0009755282581475768 Training loss: 0.0
2025-12-09 10:24:35.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 1090 LR: 0.0009754792036237724 Training loss: 0.0
2025-12-09 10:24:35.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 1091 LR: 0.0009754301012192253 Training loss: 0.0
2025-12-09 10:24:35.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 1092 LR: 0.0009753809509388798 Training loss: 0.0
2025-12-09 10:24:35.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 1093 LR: 0.0009753317527876857 Training loss: 0.0
2025-12-09 10:24:35.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 1094 LR: 0.000975282506770597 Training loss: 0.0
2025-12-09 10:24:35.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 1095 LR: 0.0009752332128925731 Training loss: 0.0
2025-12-09 10:24:35.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 1096 LR: 0.0009751838711585775 Training loss: 0.0
2025-12-09 10:24:35.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 1097 LR: 0.0009751344815735791 Training loss: 0.0
2025-12-09 10:24:35.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 1098 LR: 0.0009750850441425514 Training loss: 0.0
2025-12-09 10:24:35.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 1099 LR: 0.0009750355588704727 Training loss: 0.0
2025-12-09 10:24:35.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 1100 LR: 0.0009749860257623263 Training loss: 0.0
2025-12-09 10:24:35.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 1101 LR: 0.0009749364448231 Training loss: 0.0
2025-12-09 10:24:35.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 1102 LR: 0.0009748868160577869 Training loss: 0.0
2025-12-09 10:24:35.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 1103 LR: 0.0009748371394713842 Training loss: 0.0
2025-12-09 10:24:35.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 1104 LR: 0.0009747874150688947 Training loss: 0.0
2025-12-09 10:24:35.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 1105 LR: 0.0009747376428553254 Training loss: 0.0
2025-12-09 10:24:35.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 1106 LR: 0.0009746878228356885 Training loss: 0.0
2025-12-09 10:24:35.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 1107 LR: 0.0009746379550150009 Training loss: 0.0
2025-12-09 10:24:35.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 1108 LR: 0.000974588039398284 Training loss: 0.0
2025-12-09 10:24:35.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 1109 LR: 0.0009745380759905647 Training loss: 0.0
2025-12-09 10:24:35.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 1110 LR: 0.0009744880647968742 Training loss: 0.0
2025-12-09 10:24:35.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 1111 LR: 0.0009744380058222483 Training loss: 0.0
2025-12-09 10:24:35.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 1112 LR: 0.0009743878990717283 Training loss: 0.0
2025-12-09 10:24:35.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 1113 LR: 0.0009743377445503599 Training loss: 0.0
2025-12-09 10:24:35.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 1114 LR: 0.0009742875422631936 Training loss: 0.0
2025-12-09 10:24:35.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 1115 LR: 0.0009742372922152847 Training loss: 0.0
2025-12-09 10:24:35.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 1116 LR: 0.0009741869944116935 Training loss: 0.0
2025-12-09 10:24:35.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 1117 LR: 0.000974136648857485 Training loss: 0.0
2025-12-09 10:24:35.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 1118 LR: 0.0009740862555577288 Training loss: 0.0
2025-12-09 10:24:35.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 1119 LR: 0.0009740358145174998 Training loss: 0.0
2025-12-09 10:24:35.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 1120 LR: 0.0009739853257418772 Training loss: 0.0
2025-12-09 10:24:35.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 1121 LR: 0.0009739347892359451 Training loss: 0.0
2025-12-09 10:24:35.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 1122 LR: 0.0009738842050047929 Training loss: 0.0
2025-12-09 10:24:35.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 1123 LR: 0.0009738335730535142 Training loss: 0.0
2025-12-09 10:24:35.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 1124 LR: 0.0009737828933872075 Training loss: 0.0
2025-12-09 10:24:35.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 1125 LR: 0.0009737321660109766 Training loss: 0.0
2025-12-09 10:24:35.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 1126 LR: 0.0009736813909299294 Training loss: 0.0
2025-12-09 10:24:35.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 1127 LR: 0.000973630568149179 Training loss: 0.0
2025-12-09 10:24:35.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 1128 LR: 0.0009735796976738435 Training loss: 0.0
2025-12-09 10:24:35.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 1129 LR: 0.0009735287795090455 Training loss: 0.0
2025-12-09 10:24:35.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 1130 LR: 0.0009734778136599123 Training loss: 0.0
2025-12-09 10:24:35.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 1131 LR: 0.000973426800131576 Training loss: 0.0
2025-12-09 10:24:35.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 1132 LR: 0.0009733757389291742 Training loss: 0.0
2025-12-09 10:24:35.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 1133 LR: 0.0009733246300578483 Training loss: 0.0
2025-12-09 10:24:35.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 1134 LR: 0.000973273473522745 Training loss: 0.0
2025-12-09 10:24:35.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 1135 LR: 0.000973222269329016 Training loss: 0.0
2025-12-09 10:24:35.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 1136 LR: 0.0009731710174818173 Training loss: 0.0
2025-12-09 10:24:35.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 1137 LR: 0.0009731197179863103 Training loss: 0.0
2025-12-09 10:24:35.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 1138 LR: 0.0009730683708476604 Training loss: 0.0
2025-12-09 10:24:35.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 1139 LR: 0.0009730169760710386 Training loss: 0.0
2025-12-09 10:24:35.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 1140 LR: 0.0009729655336616203 Training loss: 0.0
2025-12-09 10:24:35.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 1141 LR: 0.0009729140436245857 Training loss: 0.0
2025-12-09 10:24:35.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 1142 LR: 0.0009728625059651197 Training loss: 0.0
2025-12-09 10:24:35.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 1143 LR: 0.0009728109206884125 Training loss: 0.0
2025-12-09 10:24:35.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 1144 LR: 0.0009727592877996585 Training loss: 0.0
2025-12-09 10:24:35.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 1145 LR: 0.000972707607304057 Training loss: 0.0
2025-12-09 10:24:35.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 1146 LR: 0.0009726558792068125 Training loss: 0.0
2025-12-09 10:24:35.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 1147 LR: 0.0009726041035131339 Training loss: 0.0
2025-12-09 10:24:35.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 1148 LR: 0.0009725522802282349 Training loss: 0.0
2025-12-09 10:24:35.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 1149 LR: 0.0009725004093573342 Training loss: 0.0
2025-12-09 10:24:35.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 1150 LR: 0.0009724484909056553 Training loss: 0.0
2025-12-09 10:24:35.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 1151 LR: 0.0009723965248784264 Training loss: 0.0
2025-12-09 10:24:35.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 1152 LR: 0.0009723445112808801 Training loss: 0.0
2025-12-09 10:24:35.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 1153 LR: 0.0009722924501182547 Training loss: 0.0
2025-12-09 10:24:35.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 1154 LR: 0.0009722403413957924 Training loss: 0.0
2025-12-09 10:24:35.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 1155 LR: 0.0009721881851187406 Training loss: 0.0
2025-12-09 10:24:35.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 1156 LR: 0.0009721359812923515 Training loss: 0.0
2025-12-09 10:24:35.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 1157 LR: 0.0009720837299218818 Training loss: 0.0
2025-12-09 10:24:35.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 1158 LR: 0.0009720314310125937 Training loss: 0.0
2025-12-09 10:24:35.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 1159 LR: 0.0009719790845697534 Training loss: 0.0
2025-12-09 10:24:35.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 1160 LR: 0.0009719266905986321 Training loss: 0.0
2025-12-09 10:24:35.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 1161 LR: 0.0009718742491045061 Training loss: 0.0
2025-12-09 10:24:35.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 1162 LR: 0.000971821760092656 Training loss: 0.0
2025-12-09 10:24:35.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 1163 LR: 0.0009717692235683675 Training loss: 0.0
2025-12-09 10:24:35.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 1164 LR: 0.0009717166395369312 Training loss: 0.0
2025-12-09 10:24:35.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 1165 LR: 0.0009716640080036422 Training loss: 0.0
2025-12-09 10:24:35.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 1166 LR: 0.0009716113289738004 Training loss: 0.0
2025-12-09 10:24:35.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 1167 LR: 0.0009715586024527108 Training loss: 0.0
2025-12-09 10:24:35.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 1168 LR: 0.0009715058284456828 Training loss: 0.0
2025-12-09 10:24:35.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 1169 LR: 0.0009714530069580309 Training loss: 0.0
2025-12-09 10:24:35.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 1170 LR: 0.0009714001379950739 Training loss: 0.0
2025-12-09 10:24:35.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 1171 LR: 0.0009713472215621359 Training loss: 0.0
2025-12-09 10:24:35.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 1172 LR: 0.0009712942576645458 Training loss: 0.0
2025-12-09 10:24:35.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 1173 LR: 0.0009712412463076368 Training loss: 0.0
2025-12-09 10:24:35.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 1174 LR: 0.000971188187496747 Training loss: 0.0
2025-12-09 10:24:35.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 1175 LR: 0.0009711350812372197 Training loss: 0.0
2025-12-09 10:24:35.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 1176 LR: 0.0009710819275344027 Training loss: 0.0
2025-12-09 10:24:35.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 1177 LR: 0.0009710287263936483 Training loss: 0.0
2025-12-09 10:24:35.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 1178 LR: 0.0009709754778203142 Training loss: 0.0
2025-12-09 10:24:35.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 1179 LR: 0.0009709221818197624 Training loss: 0.0
2025-12-09 10:24:35.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 1180 LR: 0.0009708688383973596 Training loss: 0.0
2025-12-09 10:24:35.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 1181 LR: 0.0009708154475584779 Training loss: 0.0
2025-12-09 10:24:35.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 1182 LR: 0.0009707620093084932 Training loss: 0.0
2025-12-09 10:24:35.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 1183 LR: 0.0009707085236527873 Training loss: 0.0
2025-12-09 10:24:35.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 1184 LR: 0.0009706549905967458 Training loss: 0.0
2025-12-09 10:24:35.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 1185 LR: 0.0009706014101457599 Training loss: 0.0
2025-12-09 10:24:35.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 1186 LR: 0.0009705477823052246 Training loss: 0.0
2025-12-09 10:24:35.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 1187 LR: 0.0009704941070805405 Training loss: 0.0
2025-12-09 10:24:35.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 1188 LR: 0.0009704403844771128 Training loss: 0.0
2025-12-09 10:24:35.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 1189 LR: 0.0009703866145003512 Training loss: 0.0
2025-12-09 10:24:35.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 1190 LR: 0.0009703327971556703 Training loss: 0.0
2025-12-09 10:24:35.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 1191 LR: 0.0009702789324484897 Training loss: 0.0
2025-12-09 10:24:35.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 1192 LR: 0.0009702250203842336 Training loss: 0.0
2025-12-09 10:24:35.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 1193 LR: 0.0009701710609683306 Training loss: 0.0
2025-12-09 10:24:35.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 1194 LR: 0.0009701170542062148 Training loss: 0.0
2025-12-09 10:24:35.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 1195 LR: 0.0009700630001033244 Training loss: 0.0
2025-12-09 10:24:35.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 1196 LR: 0.0009700088986651027 Training loss: 0.0
2025-12-09 10:24:35.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 1197 LR: 0.0009699547498969979 Training loss: 0.0
2025-12-09 10:24:35.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 1198 LR: 0.0009699005538044626 Training loss: 0.0
2025-12-09 10:24:35.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 1199 LR: 0.0009698463103929542 Training loss: 0.0
2025-12-09 10:24:35.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 1200 LR: 0.0009697920196679353 Training loss: 0.0
2025-12-09 10:24:35.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 1201 LR: 0.000969737681634873 Training loss: 0.0
2025-12-09 10:24:35.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 1202 LR: 0.000969683296299239 Training loss: 0.0
2025-12-09 10:24:35.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 1203 LR: 0.0009696288636665098 Training loss: 0.0
2025-12-09 10:24:35.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 1204 LR: 0.0009695743837421669 Training loss: 0.0
2025-12-09 10:24:35.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 1205 LR: 0.0009695198565316965 Training loss: 0.0
2025-12-09 10:24:35.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 1206 LR: 0.0009694652820405893 Training loss: 0.0
2025-12-09 10:24:35.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 1207 LR: 0.0009694106602743411 Training loss: 0.0
2025-12-09 10:24:35.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 1208 LR: 0.0009693559912384522 Training loss: 0.0
2025-12-09 10:24:35.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 1209 LR: 0.0009693012749384279 Training loss: 0.0
2025-12-09 10:24:35.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 1210 LR: 0.0009692465113797779 Training loss: 0.0
2025-12-09 10:24:35.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 1211 LR: 0.0009691917005680173 Training loss: 0.0
2025-12-09 10:24:35.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 1212 LR: 0.000969136842508665 Training loss: 0.0
2025-12-09 10:24:35.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 1213 LR: 0.0009690819372072457 Training loss: 0.0
2025-12-09 10:24:35.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 1214 LR: 0.0009690269846692881 Training loss: 0.0
2025-12-09 10:24:35.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 1215 LR: 0.000968971984900326 Training loss: 0.0
2025-12-09 10:24:35.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 1216 LR: 0.0009689169379058978 Training loss: 0.0
2025-12-09 10:24:35.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 1217 LR: 0.0009688618436915469 Training loss: 0.0
2025-12-09 10:24:35.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 1218 LR: 0.000968806702262821 Training loss: 0.0
2025-12-09 10:24:35.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 1219 LR: 0.0009687515136252732 Training loss: 0.0
2025-12-09 10:24:35.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 1220 LR: 0.0009686962777844606 Training loss: 0.0
2025-12-09 10:24:35.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 1221 LR: 0.0009686409947459458 Training loss: 0.0
2025-12-09 10:24:35.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 1222 LR: 0.0009685856645152955 Training loss: 0.0
2025-12-09 10:24:35.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 1223 LR: 0.0009685302870980817 Training loss: 0.0
2025-12-09 10:24:35.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 1224 LR: 0.000968474862499881 Training loss: 0.0
2025-12-09 10:24:35.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 1225 LR: 0.0009684193907262741 Training loss: 0.0
2025-12-09 10:24:35.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 1226 LR: 0.0009683638717828476 Training loss: 0.0
2025-12-09 10:24:35.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 1227 LR: 0.000968308305675192 Training loss: 0.0
2025-12-09 10:24:35.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 1228 LR: 0.0009682526924089027 Training loss: 0.0
2025-12-09 10:24:35.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 1229 LR: 0.0009681970319895803 Training loss: 0.0
2025-12-09 10:24:35.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 1230 LR: 0.0009681413244228295 Training loss: 0.0
2025-12-09 10:24:35.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 1231 LR: 0.0009680855697142601 Training loss: 0.0
2025-12-09 10:24:35.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 1232 LR: 0.0009680297678694867 Training loss: 0.0
2025-12-09 10:24:35.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 1233 LR: 0.0009679739188941283 Training loss: 0.0
2025-12-09 10:24:35.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 1234 LR: 0.0009679180227938094 Training loss: 0.0
2025-12-09 10:24:35.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 1235 LR: 0.0009678620795741581 Training loss: 0.0
2025-12-09 10:24:35.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 1236 LR: 0.0009678060892408083 Training loss: 0.0
2025-12-09 10:24:35.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 1237 LR: 0.0009677500517993982 Training loss: 0.0
2025-12-09 10:24:35.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 1238 LR: 0.0009676939672555706 Training loss: 0.0
2025-12-09 10:24:35.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 1239 LR: 0.0009676378356149733 Training loss: 0.0
2025-12-09 10:24:35.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 1240 LR: 0.0009675816568832587 Training loss: 0.0
2025-12-09 10:24:35.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 1241 LR: 0.0009675254310660842 Training loss: 0.0
2025-12-09 10:24:35.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 1242 LR: 0.0009674691581691114 Training loss: 0.0
2025-12-09 10:24:35.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 1243 LR: 0.0009674128381980072 Training loss: 0.0
2025-12-09 10:24:35.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 1244 LR: 0.000967356471158443 Training loss: 0.0
2025-12-09 10:24:35.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 1245 LR: 0.000967300057056095 Training loss: 0.0
2025-12-09 10:24:35.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 1246 LR: 0.0009672435958966441 Training loss: 0.0
2025-12-09 10:24:35.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 1247 LR: 0.0009671870876857758 Training loss: 0.0
2025-12-09 10:24:35.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 1248 LR: 0.0009671305324291805 Training loss: 0.0
2025-12-09 10:24:35.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 1249 LR: 0.0009670739301325534 Training loss: 0.0
2025-12-09 10:24:35.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 1250 LR: 0.0009670172808015942 Training loss: 0.0
2025-12-09 10:24:35.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 1251 LR: 0.0009669605844420078 Training loss: 0.0
2025-12-09 10:24:35.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 1252 LR: 0.0009669038410595033 Training loss: 0.0
2025-12-09 10:24:35.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 1253 LR: 0.0009668470506597946 Training loss: 0.0
2025-12-09 10:24:35.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 1254 LR: 0.0009667902132486009 Training loss: 0.0
2025-12-09 10:24:35.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 1255 LR: 0.0009667333288316453 Training loss: 0.0
2025-12-09 10:24:35.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 1256 LR: 0.0009666763974146564 Training loss: 0.0
2025-12-09 10:24:35.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 1257 LR: 0.000966619419003367 Training loss: 0.0
2025-12-09 10:24:35.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 1258 LR: 0.0009665623936035149 Training loss: 0.0
2025-12-09 10:24:35.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 1259 LR: 0.0009665053212208426 Training loss: 0.0
2025-12-09 10:24:35.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 1260 LR: 0.000966448201861097 Training loss: 0.0
2025-12-09 10:24:35.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 1261 LR: 0.0009663910355300305 Training loss: 0.0
2025-12-09 10:24:35.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 1262 LR: 0.0009663338222333993 Training loss: 0.0
2025-12-09 10:24:35.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 1263 LR: 0.000966276561976965 Training loss: 0.0
2025-12-09 10:24:35.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 1264 LR: 0.0009662192547664936 Training loss: 0.0
2025-12-09 10:24:35.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 1265 LR: 0.0009661619006077561 Training loss: 0.0
2025-12-09 10:24:35.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 1266 LR: 0.000966104499506528 Training loss: 0.0
2025-12-09 10:24:35.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 1267 LR: 0.0009660470514685895 Training loss: 0.0
2025-12-09 10:24:35.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 1268 LR: 0.0009659895564997256 Training loss: 0.0
2025-12-09 10:24:35.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 1269 LR: 0.0009659320146057262 Training loss: 0.0
2025-12-09 10:24:35.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 1270 LR: 0.0009658744257923858 Training loss: 0.0
2025-12-09 10:24:35.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 1271 LR: 0.0009658167900655031 Training loss: 0.0
2025-12-09 10:24:35.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 1272 LR: 0.0009657591074308827 Training loss: 0.0
2025-12-09 10:24:35.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 1273 LR: 0.0009657013778943328 Training loss: 0.0
2025-12-09 10:24:35.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 1274 LR: 0.000965643601461667 Training loss: 0.0
2025-12-09 10:24:35.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 1275 LR: 0.000965585778138703 Training loss: 0.0
2025-12-09 10:24:35.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 1276 LR: 0.0009655279079312642 Training loss: 0.0
2025-12-09 10:24:35.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 1277 LR: 0.0009654699908451777 Training loss: 0.0
2025-12-09 10:24:35.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 1278 LR: 0.0009654120268862758 Training loss: 0.0
2025-12-09 10:24:35.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 1279 LR: 0.0009653540160603955 Training loss: 0.0
2025-12-09 10:24:35.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 1280 LR: 0.0009652959583733787 Training loss: 0.0
2025-12-09 10:24:35.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 1281 LR: 0.0009652378538310715 Training loss: 0.0
2025-12-09 10:24:35.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 1282 LR: 0.0009651797024393252 Training loss: 0.0
2025-12-09 10:24:35.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 1283 LR: 0.0009651215042039955 Training loss: 0.0
2025-12-09 10:24:35.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 1284 LR: 0.0009650632591309431 Training loss: 0.0
2025-12-09 10:24:35.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 1285 LR: 0.0009650049672260333 Training loss: 0.0
2025-12-09 10:24:35.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 1286 LR: 0.0009649466284951358 Training loss: 0.0
2025-12-09 10:24:35.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 1287 LR: 0.0009648882429441257 Training loss: 0.0
2025-12-09 10:24:35.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 1288 LR: 0.0009648298105788822 Training loss: 0.0
2025-12-09 10:24:35.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 1289 LR: 0.0009647713314052896 Training loss: 0.0
2025-12-09 10:24:35.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 1290 LR: 0.0009647128054292366 Training loss: 0.0
2025-12-09 10:24:35.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 1291 LR: 0.0009646542326566167 Training loss: 0.0
2025-12-09 10:24:35.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 1292 LR: 0.0009645956130933284 Training loss: 0.0
2025-12-09 10:24:35.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 1293 LR: 0.0009645369467452746 Training loss: 0.0
2025-12-09 10:24:35.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 1294 LR: 0.0009644782336183629 Training loss: 0.0
2025-12-09 10:24:35.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 1295 LR: 0.0009644194737185058 Training loss: 0.0
2025-12-09 10:24:35.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 1296 LR: 0.0009643606670516205 Training loss: 0.0
2025-12-09 10:24:35.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 1297 LR: 0.0009643018136236285 Training loss: 0.0
2025-12-09 10:24:35.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 1298 LR: 0.0009642429134404568 Training loss: 0.0
2025-12-09 10:24:35.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 1299 LR: 0.0009641839665080363 Training loss: 0.0
2025-12-09 10:24:35.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 1300 LR: 0.0009641249728323031 Training loss: 0.0
2025-12-09 10:24:35.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 1301 LR: 0.0009640659324191978 Training loss: 0.0
2025-12-09 10:24:35.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 1302 LR: 0.000964006845274666 Training loss: 0.0
2025-12-09 10:24:35.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 1303 LR: 0.0009639477114046573 Training loss: 0.0
2025-12-09 10:24:35.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 1304 LR: 0.000963888530815127 Training loss: 0.0
2025-12-09 10:24:35.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 1305 LR: 0.0009638293035120341 Training loss: 0.0
2025-12-09 10:24:35.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 1306 LR: 0.0009637700295013432 Training loss: 0.0
2025-12-09 10:24:35.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 1307 LR: 0.0009637107087890229 Training loss: 0.0
2025-12-09 10:24:35.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 1308 LR: 0.0009636513413810471 Training loss: 0.0
2025-12-09 10:24:35.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 1309 LR: 0.0009635919272833937 Training loss: 0.0
2025-12-09 10:24:35.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 1310 LR: 0.000963532466502046 Training loss: 0.0
2025-12-09 10:24:35.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 1311 LR: 0.0009634729590429916 Training loss: 0.0
2025-12-09 10:24:35.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 1312 LR: 0.000963413404912223 Training loss: 0.0
2025-12-09 10:24:35.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 1313 LR: 0.000963353804115737 Training loss: 0.0
2025-12-09 10:24:35.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 1314 LR: 0.0009632941566595357 Training loss: 0.0
2025-12-09 10:24:35.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 1315 LR: 0.0009632344625496255 Training loss: 0.0
2025-12-09 10:24:35.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 1316 LR: 0.0009631747217920177 Training loss: 0.0
2025-12-09 10:24:35.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 1317 LR: 0.0009631149343927281 Training loss: 0.0
2025-12-09 10:24:35.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 1318 LR: 0.000963055100357777 Training loss: 0.0
2025-12-09 10:24:35.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 1319 LR: 0.0009629952196931902 Training loss: 0.0
2025-12-09 10:24:35.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 1320 LR: 0.0009629352924049974 Training loss: 0.0
2025-12-09 10:24:35.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 1321 LR: 0.0009628753184992334 Training loss: 0.0
2025-12-09 10:24:35.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 1322 LR: 0.0009628152979819373 Training loss: 0.0
2025-12-09 10:24:35.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 1323 LR: 0.0009627552308591534 Training loss: 0.0
2025-12-09 10:24:35.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 1324 LR: 0.0009626951171369304 Training loss: 0.0
2025-12-09 10:24:35.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 1325 LR: 0.0009626349568213219 Training loss: 0.0
2025-12-09 10:24:35.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 1326 LR: 0.0009625747499183859 Training loss: 0.0
2025-12-09 10:24:35.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 1327 LR: 0.0009625144964341852 Training loss: 0.0
2025-12-09 10:24:35.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 1328 LR: 0.0009624541963747874 Training loss: 0.0
2025-12-09 10:24:35.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 1329 LR: 0.0009623938497462645 Training loss: 0.0
2025-12-09 10:24:35.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 1330 LR: 0.0009623334565546937 Training loss: 0.0
2025-12-09 10:24:35.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 1331 LR: 0.0009622730168061567 Training loss: 0.0
2025-12-09 10:24:35.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 1332 LR: 0.0009622125305067393 Training loss: 0.0
2025-12-09 10:24:35.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 1333 LR: 0.0009621519976625327 Training loss: 0.0
2025-12-09 10:24:35.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 1334 LR: 0.0009620914182796326 Training loss: 0.0
2025-12-09 10:24:35.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 1335 LR: 0.0009620307923641394 Training loss: 0.0
2025-12-09 10:24:35.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 1336 LR: 0.000961970119922158 Training loss: 0.0
2025-12-09 10:24:35.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 1337 LR: 0.0009619094009597982 Training loss: 0.0
2025-12-09 10:24:35.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 1338 LR: 0.0009618486354831744 Training loss: 0.0
2025-12-09 10:24:35.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 1339 LR: 0.0009617878234984055 Training loss: 0.0
2025-12-09 10:24:35.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 1340 LR: 0.0009617269650116156 Training loss: 0.0
2025-12-09 10:24:35.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 1341 LR: 0.0009616660600289329 Training loss: 0.0
2025-12-09 10:24:35.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 1342 LR: 0.0009616051085564905 Training loss: 0.0
2025-12-09 10:24:35.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 1343 LR: 0.0009615441106004263 Training loss: 0.0
2025-12-09 10:24:35.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 1344 LR: 0.0009614830661668829 Training loss: 0.0
2025-12-09 10:24:35.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 1345 LR: 0.0009614219752620073 Training loss: 0.0
2025-12-09 10:24:35.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 1346 LR: 0.0009613608378919514 Training loss: 0.0
2025-12-09 10:24:35.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 1347 LR: 0.0009612996540628718 Training loss: 0.0
2025-12-09 10:24:35.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 1348 LR: 0.0009612384237809295 Training loss: 0.0
2025-12-09 10:24:35.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 1349 LR: 0.0009611771470522907 Training loss: 0.0
2025-12-09 10:24:35.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 1350 LR: 0.0009611158238831258 Training loss: 0.0
2025-12-09 10:24:35.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 1351 LR: 0.0009610544542796101 Training loss: 0.0
2025-12-09 10:24:35.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 1352 LR: 0.0009609930382479233 Training loss: 0.0
2025-12-09 10:24:35.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 1353 LR: 0.0009609315757942503 Training loss: 0.0
2025-12-09 10:24:35.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 1354 LR: 0.0009608700669247802 Training loss: 0.0
2025-12-09 10:24:35.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 1355 LR: 0.0009608085116457069 Training loss: 0.0
2025-12-09 10:24:35.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 1356 LR: 0.0009607469099632291 Training loss: 0.0
2025-12-09 10:24:35.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 1357 LR: 0.0009606852618835502 Training loss: 0.0
2025-12-09 10:24:35.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 1358 LR: 0.000960623567412878 Training loss: 0.0
2025-12-09 10:24:35.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 1359 LR: 0.0009605618265574251 Training loss: 0.0
2025-12-09 10:24:35.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 1360 LR: 0.0009605000393234089 Training loss: 0.0
2025-12-09 10:24:35.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 1361 LR: 0.0009604382057170513 Training loss: 0.0
2025-12-09 10:24:35.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 1362 LR: 0.000960376325744579 Training loss: 0.0
2025-12-09 10:24:35.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 1363 LR: 0.0009603143994122233 Training loss: 0.0
2025-12-09 10:24:35.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 1364 LR: 0.0009602524267262203 Training loss: 0.0
2025-12-09 10:24:35.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 1365 LR: 0.0009601904076928103 Training loss: 0.0
2025-12-09 10:24:35.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 1366 LR: 0.000960128342318239 Training loss: 0.0
2025-12-09 10:24:35.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 1367 LR: 0.0009600662306087561 Training loss: 0.0
2025-12-09 10:24:35.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 1368 LR: 0.0009600040725706164 Training loss: 0.0
2025-12-09 10:24:35.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 1369 LR: 0.0009599418682100792 Training loss: 0.0
2025-12-09 10:24:35.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 1370 LR: 0.0009598796175334085 Training loss: 0.0
2025-12-09 10:24:35.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 1371 LR: 0.0009598173205468728 Training loss: 0.0
2025-12-09 10:24:35.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 1372 LR: 0.0009597549772567455 Training loss: 0.0
2025-12-09 10:24:35.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 1373 LR: 0.0009596925876693047 Training loss: 0.0
2025-12-09 10:24:35.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 1374 LR: 0.0009596301517908328 Training loss: 0.0
2025-12-09 10:24:35.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 1375 LR: 0.0009595676696276172 Training loss: 0.0
2025-12-09 10:24:35.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 1376 LR: 0.0009595051411859499 Training loss: 0.0
2025-12-09 10:24:35.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 1377 LR: 0.0009594425664721274 Training loss: 0.0
2025-12-09 10:24:35.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 1378 LR: 0.000959379945492451 Training loss: 0.0
2025-12-09 10:24:35.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 1379 LR: 0.0009593172782532268 Training loss: 0.0
2025-12-09 10:24:35.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 1380 LR: 0.0009592545647607652 Training loss: 0.0
2025-12-09 10:24:35.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 1381 LR: 0.0009591918050213813 Training loss: 0.0
2025-12-09 10:24:35.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 1382 LR: 0.0009591289990413954 Training loss: 0.0
2025-12-09 10:24:35.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 1383 LR: 0.0009590661468271318 Training loss: 0.0
2025-12-09 10:24:35.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 1384 LR: 0.0009590032483849198 Training loss: 0.0
2025-12-09 10:24:35.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 1385 LR: 0.0009589403037210932 Training loss: 0.0
2025-12-09 10:24:35.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 1386 LR: 0.0009588773128419905 Training loss: 0.0
2025-12-09 10:24:35.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 1387 LR: 0.000958814275753955 Training loss: 0.0
2025-12-09 10:24:35.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 1388 LR: 0.0009587511924633347 Training loss: 0.0
2025-12-09 10:24:35.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 1389 LR: 0.0009586880629764817 Training loss: 0.0
2025-12-09 10:24:35.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 1390 LR: 0.0009586248872997532 Training loss: 0.0
2025-12-09 10:24:35.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 1391 LR: 0.0009585616654395112 Training loss: 0.0
2025-12-09 10:24:35.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 1392 LR: 0.0009584983974021222 Training loss: 0.0
2025-12-09 10:24:35.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 1393 LR: 0.000958435083193957 Training loss: 0.0
2025-12-09 10:24:35.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 1394 LR: 0.0009583717228213914 Training loss: 0.0
2025-12-09 10:24:35.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 1395 LR: 0.000958308316290806 Training loss: 0.0
2025-12-09 10:24:35.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 1396 LR: 0.0009582448636085854 Training loss: 0.0
2025-12-09 10:24:35.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 1397 LR: 0.0009581813647811198 Training loss: 0.0
2025-12-09 10:24:35.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 1398 LR: 0.0009581178198148033 Training loss: 0.0
2025-12-09 10:24:35.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 1399 LR: 0.0009580542287160348 Training loss: 0.0
2025-12-09 10:24:35.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 1400 LR: 0.0009579905914912181 Training loss: 0.0
2025-12-09 10:24:35.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 1401 LR: 0.0009579269081467614 Training loss: 0.0
2025-12-09 10:24:35.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 1402 LR: 0.0009578631786890774 Training loss: 0.0
2025-12-09 10:24:35.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 1403 LR: 0.0009577994031245839 Training loss: 0.0
2025-12-09 10:24:35.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 1404 LR: 0.0009577355814597031 Training loss: 0.0
2025-12-09 10:24:35.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 1405 LR: 0.0009576717137008618 Training loss: 0.0
2025-12-09 10:24:35.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 1406 LR: 0.0009576077998544912 Training loss: 0.0
2025-12-09 10:24:35.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 1407 LR: 0.0009575438399270279 Training loss: 0.0
2025-12-09 10:24:35.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 1408 LR: 0.0009574798339249124 Training loss: 0.0
2025-12-09 10:24:35.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 1409 LR: 0.0009574157818545901 Training loss: 0.0
2025-12-09 10:24:35.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 1410 LR: 0.0009573516837225112 Training loss: 0.0
2025-12-09 10:24:35.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 1411 LR: 0.0009572875395351301 Training loss: 0.0
2025-12-09 10:24:35.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 1412 LR: 0.0009572233492989064 Training loss: 0.0
2025-12-09 10:24:35.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 1413 LR: 0.0009571591130203039 Training loss: 0.0
2025-12-09 10:24:35.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 1414 LR: 0.0009570948307057912 Training loss: 0.0
2025-12-09 10:24:35.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 1415 LR: 0.0009570305023618417 Training loss: 0.0
2025-12-09 10:24:35.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 1416 LR: 0.0009569661279949329 Training loss: 0.0
2025-12-09 10:24:35.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 1417 LR: 0.0009569017076115476 Training loss: 0.0
2025-12-09 10:24:35.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 1418 LR: 0.0009568372412181729 Training loss: 0.0
2025-12-09 10:24:35.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 1419 LR: 0.0009567727288213005 Training loss: 0.0
2025-12-09 10:24:35.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 1420 LR: 0.0009567081704274267 Training loss: 0.0
2025-12-09 10:24:35.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 1421 LR: 0.0009566435660430528 Training loss: 0.0
2025-12-09 10:24:35.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 1422 LR: 0.0009565789156746841 Training loss: 0.0
2025-12-09 10:24:35.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 1423 LR: 0.0009565142193288312 Training loss: 0.0
2025-12-09 10:24:35.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 1424 LR: 0.0009564494770120089 Training loss: 0.0
2025-12-09 10:24:35.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 1425 LR: 0.0009563846887307368 Training loss: 0.0
2025-12-09 10:24:35.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 1426 LR: 0.000956319854491539 Training loss: 0.0
2025-12-09 10:24:35.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 1427 LR: 0.0009562549743009443 Training loss: 0.0
2025-12-09 10:24:35.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 1428 LR: 0.0009561900481654861 Training loss: 0.0
2025-12-09 10:24:35.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 1429 LR: 0.0009561250760917027 Training loss: 0.0
2025-12-09 10:24:35.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 1430 LR: 0.0009560600580861365 Training loss: 0.0
2025-12-09 10:24:35.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 1431 LR: 0.0009559949941553349 Training loss: 0.0
2025-12-09 10:24:35.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 1432 LR: 0.00095592988430585 Training loss: 0.0
2025-12-09 10:24:35.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 1433 LR: 0.0009558647285442381 Training loss: 0.0
2025-12-09 10:24:35.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 1434 LR: 0.0009557995268770608 Training loss: 0.0
2025-12-09 10:24:35.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 1435 LR: 0.0009557342793108832 Training loss: 0.0
2025-12-09 10:24:35.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 1436 LR: 0.0009556689858522763 Training loss: 0.0
2025-12-09 10:24:35.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 1437 LR: 0.000955603646507815 Training loss: 0.0
2025-12-09 10:24:35.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 1438 LR: 0.000955538261284079 Training loss: 0.0
2025-12-09 10:24:35.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 1439 LR: 0.0009554728301876525 Training loss: 0.0
2025-12-09 10:24:35.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 1440 LR: 0.0009554073532251246 Training loss: 0.0
2025-12-09 10:24:35.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 1441 LR: 0.0009553418304030885 Training loss: 0.0
2025-12-09 10:24:35.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 1442 LR: 0.0009552762617281428 Training loss: 0.0
2025-12-09 10:24:35.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 1443 LR: 0.0009552106472068898 Training loss: 0.0
2025-12-09 10:24:35.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 1444 LR: 0.000955144986845937 Training loss: 0.0
2025-12-09 10:24:35.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 1445 LR: 0.0009550792806518966 Training loss: 0.0
2025-12-09 10:24:35.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 1446 LR: 0.0009550135286313851 Training loss: 0.0
2025-12-09 10:24:35.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 1447 LR: 0.0009549477307910237 Training loss: 0.0
2025-12-09 10:24:35.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 1448 LR: 0.0009548818871374383 Training loss: 0.0
2025-12-09 10:24:35.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 1449 LR: 0.0009548159976772592 Training loss: 0.0
2025-12-09 10:24:35.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 1450 LR: 0.0009547500624171217 Training loss: 0.0
2025-12-09 10:24:35.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 1451 LR: 0.0009546840813636653 Training loss: 0.0
2025-12-09 10:24:35.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 1452 LR: 0.0009546180545235343 Training loss: 0.0
2025-12-09 10:24:35.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 1453 LR: 0.0009545519819033777 Training loss: 0.0
2025-12-09 10:24:35.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 1454 LR: 0.000954485863509849 Training loss: 0.0
2025-12-09 10:24:35.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 1455 LR: 0.0009544196993496062 Training loss: 0.0
2025-12-09 10:24:35.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 1456 LR: 0.0009543534894293121 Training loss: 0.0
2025-12-09 10:24:35.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 1457 LR: 0.000954287233755634 Training loss: 0.0
2025-12-09 10:24:35.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 1458 LR: 0.0009542209323352441 Training loss: 0.0
2025-12-09 10:24:35.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 1459 LR: 0.0009541545851748186 Training loss: 0.0
2025-12-09 10:24:35.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 1460 LR: 0.0009540881922810388 Training loss: 0.0
2025-12-09 10:24:35.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 1461 LR: 0.0009540217536605905 Training loss: 0.0
2025-12-09 10:24:35.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 1462 LR: 0.0009539552693201641 Training loss: 0.0
2025-12-09 10:24:35.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 1463 LR: 0.0009538887392664543 Training loss: 0.0
2025-12-09 10:24:35.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 1464 LR: 0.000953822163506161 Training loss: 0.0
2025-12-09 10:24:35.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 1465 LR: 0.0009537555420459882 Training loss: 0.0
2025-12-09 10:24:35.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 1466 LR: 0.0009536888748926449 Training loss: 0.0
2025-12-09 10:24:35.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 1467 LR: 0.0009536221620528441 Training loss: 0.0
2025-12-09 10:24:35.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 1468 LR: 0.000953555403533304 Training loss: 0.0
2025-12-09 10:24:35.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 1469 LR: 0.0009534885993407473 Training loss: 0.0
2025-12-09 10:24:35.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 1470 LR: 0.0009534217494819011 Training loss: 0.0
2025-12-09 10:24:35.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 1471 LR: 0.000953354853963497 Training loss: 0.0
2025-12-09 10:24:35.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 1472 LR: 0.0009532879127922716 Training loss: 0.0
2025-12-09 10:24:35.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 1473 LR: 0.0009532209259749658 Training loss: 0.0
2025-12-09 10:24:35.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 1474 LR: 0.0009531538935183251 Training loss: 0.0
2025-12-09 10:24:35.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 1475 LR: 0.0009530868154290997 Training loss: 0.0
2025-12-09 10:24:35.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 1476 LR: 0.0009530196917140444 Training loss: 0.0
2025-12-09 10:24:35.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 1477 LR: 0.0009529525223799185 Training loss: 0.0
2025-12-09 10:24:35.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 1478 LR: 0.000952885307433486 Training loss: 0.0
2025-12-09 10:24:35.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 1479 LR: 0.0009528180468815154 Training loss: 0.0
2025-12-09 10:24:35.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 1480 LR: 0.0009527507407307799 Training loss: 0.0
2025-12-09 10:24:35.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 1481 LR: 0.0009526833889880573 Training loss: 0.0
2025-12-09 10:24:35.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 1482 LR: 0.0009526159916601299 Training loss: 0.0
2025-12-09 10:24:35.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 1483 LR: 0.0009525485487537842 Training loss: 0.0
2025-12-09 10:24:35.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 1484 LR: 0.0009524810602758122 Training loss: 0.0
2025-12-09 10:24:35.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 1485 LR: 0.0009524135262330098 Training loss: 0.0
2025-12-09 10:24:35.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 1486 LR: 0.0009523459466321777 Training loss: 0.0
2025-12-09 10:24:35.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 1487 LR: 0.0009522783214801211 Training loss: 0.0
2025-12-09 10:24:35.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 1488 LR: 0.0009522106507836498 Training loss: 0.0
2025-12-09 10:24:35.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 1489 LR: 0.0009521429345495787 Training loss: 0.0
2025-12-09 10:24:35.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 1490 LR: 0.0009520751727847261 Training loss: 0.0
2025-12-09 10:24:35.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 1491 LR: 0.0009520073654959162 Training loss: 0.0
2025-12-09 10:24:35.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 1492 LR: 0.0009519395126899768 Training loss: 0.0
2025-12-09 10:24:35.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 1493 LR: 0.000951871614373741 Training loss: 0.0
2025-12-09 10:24:35.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 1494 LR: 0.0009518036705540459 Training loss: 0.0
2025-12-09 10:24:35.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 1495 LR: 0.0009517356812377335 Training loss: 0.0
2025-12-09 10:24:35.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 1496 LR: 0.0009516676464316505 Training loss: 0.0
2025-12-09 10:24:35.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 1497 LR: 0.0009515995661426478 Training loss: 0.0
2025-12-09 10:24:35.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 1498 LR: 0.000951531440377581 Training loss: 0.0
2025-12-09 10:24:35.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 1499 LR: 0.0009514632691433108 Training loss: 0.0
2025-12-09 10:24:35.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 1500 LR: 0.0009513950524467014 Training loss: 0.0
2025-12-09 10:24:35.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 1501 LR: 0.0009513267902946228 Training loss: 0.0
2025-12-09 10:24:35.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 1502 LR: 0.0009512584826939487 Training loss: 0.0
2025-12-09 10:24:35.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 1503 LR: 0.0009511901296515577 Training loss: 0.0
2025-12-09 10:24:35.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 1504 LR: 0.000951121731174333 Training loss: 0.0
2025-12-09 10:24:35.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 1505 LR: 0.0009510532872691624 Training loss: 0.0
2025-12-09 10:24:35.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 1506 LR: 0.0009509847979429381 Training loss: 0.0
2025-12-09 10:24:35.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 1507 LR: 0.000950916263202557 Training loss: 0.0
2025-12-09 10:24:35.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 1508 LR: 0.0009508476830549205 Training loss: 0.0
2025-12-09 10:24:35.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 1509 LR: 0.0009507790575069346 Training loss: 0.0
2025-12-09 10:24:35.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 1510 LR: 0.00095071038656551 Training loss: 0.0
2025-12-09 10:24:35.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 1511 LR: 0.0009506416702375617 Training loss: 0.0
2025-12-09 10:24:35.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 1512 LR: 0.0009505729085300097 Training loss: 0.0
2025-12-09 10:24:35.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 1513 LR: 0.000950504101449778 Training loss: 0.0
2025-12-09 10:24:35.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 1514 LR: 0.0009504352490037958 Training loss: 0.0
2025-12-09 10:24:35.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 1515 LR: 0.0009503663511989962 Training loss: 0.0
2025-12-09 10:24:35.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 1516 LR: 0.0009502974080423173 Training loss: 0.0
2025-12-09 10:24:35.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 1517 LR: 0.0009502284195407018 Training loss: 0.0
2025-12-09 10:24:35.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 1518 LR: 0.0009501593857010968 Training loss: 0.0
2025-12-09 10:24:35.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 1519 LR: 0.0009500903065304539 Training loss: 0.0
2025-12-09 10:24:35.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 1520 LR: 0.0009500211820357296 Training loss: 0.0
2025-12-09 10:24:35.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 1521 LR: 0.0009499520122238844 Training loss: 0.0
2025-12-09 10:24:35.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 1522 LR: 0.0009498827971018839 Training loss: 0.0
2025-12-09 10:24:35.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 1523 LR: 0.0009498135366766982 Training loss: 0.0
2025-12-09 10:24:35.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 1524 LR: 0.0009497442309553016 Training loss: 0.0
2025-12-09 10:24:35.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 1525 LR: 0.0009496748799446733 Training loss: 0.0
2025-12-09 10:24:35.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 1526 LR: 0.0009496054836517967 Training loss: 0.0
2025-12-09 10:24:35.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 1527 LR: 0.0009495360420836603 Training loss: 0.0
2025-12-09 10:24:35.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 1528 LR: 0.0009494665552472567 Training loss: 0.0
2025-12-09 10:24:35.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 1529 LR: 0.0009493970231495835 Training loss: 0.0
2025-12-09 10:24:35.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 1530 LR: 0.0009493274457976422 Training loss: 0.0
2025-12-09 10:24:35.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 1531 LR: 0.0009492578231984394 Training loss: 0.0
2025-12-09 10:24:35.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 1532 LR: 0.0009491881553589863 Training loss: 0.0
2025-12-09 10:24:35.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 1533 LR: 0.000949118442286298 Training loss: 0.0
2025-12-09 10:24:35.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 1534 LR: 0.0009490486839873949 Training loss: 0.0
2025-12-09 10:24:35.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 1535 LR: 0.0009489788804693016 Training loss: 0.0
2025-12-09 10:24:35.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 1536 LR: 0.0009489090317390474 Training loss: 0.0
2025-12-09 10:24:35.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 1537 LR: 0.0009488391378036661 Training loss: 0.0
2025-12-09 10:24:35.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 1538 LR: 0.0009487691986701957 Training loss: 0.0
2025-12-09 10:24:35.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 1539 LR: 0.0009486992143456792 Training loss: 0.0
2025-12-09 10:24:35.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 1540 LR: 0.0009486291848371642 Training loss: 0.0
2025-12-09 10:24:35.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 1541 LR: 0.0009485591101517026 Training loss: 0.0
2025-12-09 10:24:35.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 1542 LR: 0.0009484889902963509 Training loss: 0.0
2025-12-09 10:24:35.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 1543 LR: 0.00094841882527817 Training loss: 0.0
2025-12-09 10:24:35.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 1544 LR: 0.0009483486151042258 Training loss: 0.0
2025-12-09 10:24:35.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 1545 LR: 0.0009482783597815883 Training loss: 0.0
2025-12-09 10:24:35.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 1546 LR: 0.0009482080593173324 Training loss: 0.0
2025-12-09 10:24:35.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 1547 LR: 0.000948137713718537 Training loss: 0.0
2025-12-09 10:24:35.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 1548 LR: 0.000948067322992286 Training loss: 0.0
2025-12-09 10:24:35.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 1549 LR: 0.0009479968871456679 Training loss: 0.0
2025-12-09 10:24:35.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 1550 LR: 0.0009479264061857756 Training loss: 0.0
2025-12-09 10:24:35.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 1551 LR: 0.0009478558801197064 Training loss: 0.0
2025-12-09 10:24:35.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 1552 LR: 0.0009477853089545624 Training loss: 0.0
2025-12-09 10:24:35.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 1553 LR: 0.0009477146926974501 Training loss: 0.0
2025-12-09 10:24:35.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 1554 LR: 0.0009476440313554803 Training loss: 0.0
2025-12-09 10:24:35.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 1555 LR: 0.0009475733249357689 Training loss: 0.0
2025-12-09 10:24:35.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 1556 LR: 0.0009475025734454359 Training loss: 0.0
2025-12-09 10:24:35.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 1557 LR: 0.0009474317768916059 Training loss: 0.0
2025-12-09 10:24:35.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 1558 LR: 0.0009473609352814084 Training loss: 0.0
2025-12-09 10:24:35.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 1559 LR: 0.0009472900486219768 Training loss: 0.0
2025-12-09 10:24:35.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 1560 LR: 0.0009472191169204496 Training loss: 0.0
2025-12-09 10:24:35.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 1561 LR: 0.0009471481401839697 Training loss: 0.0
2025-12-09 10:24:35.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 1562 LR: 0.000947077118419684 Training loss: 0.0
2025-12-09 10:24:35.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 1563 LR: 0.000947006051634745 Training loss: 0.0
2025-12-09 10:24:35.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 1564 LR: 0.0009469349398363088 Training loss: 0.0
2025-12-09 10:24:35.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 1565 LR: 0.0009468637830315364 Training loss: 0.0
2025-12-09 10:24:35.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 1566 LR: 0.0009467925812275931 Training loss: 0.0
2025-12-09 10:24:35.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 1567 LR: 0.0009467213344316492 Training loss: 0.0
2025-12-09 10:24:35.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 1568 LR: 0.0009466500426508791 Training loss: 0.0
2025-12-09 10:24:35.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 1569 LR: 0.000946578705892462 Training loss: 0.0
2025-12-09 10:24:35.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 1570 LR: 0.0009465073241635814 Training loss: 0.0
2025-12-09 10:24:35.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 1571 LR: 0.0009464358974714253 Training loss: 0.0
2025-12-09 10:24:35.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 1572 LR: 0.0009463644258231868 Training loss: 0.0
2025-12-09 10:24:35.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 1573 LR: 0.0009462929092260628 Training loss: 0.0
2025-12-09 10:24:35.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 1574 LR: 0.000946221347687255 Training loss: 0.0
2025-12-09 10:24:35.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 1575 LR: 0.0009461497412139697 Training loss: 0.0
2025-12-09 10:24:35.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 1576 LR: 0.0009460780898134176 Training loss: 0.0
2025-12-09 10:24:35.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 1577 LR: 0.0009460063934928142 Training loss: 0.0
2025-12-09 10:24:35.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 1578 LR: 0.000945934652259379 Training loss: 0.0
2025-12-09 10:24:35.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 1579 LR: 0.0009458628661203367 Training loss: 0.0
2025-12-09 10:24:35.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 1580 LR: 0.0009457910350829158 Training loss: 0.0
2025-12-09 10:24:35.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 1581 LR: 0.00094571915915435 Training loss: 0.0
2025-12-09 10:24:35.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 1582 LR: 0.000945647238341877 Training loss: 0.0
2025-12-09 10:24:35.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 1583 LR: 0.0009455752726527394 Training loss: 0.0
2025-12-09 10:24:35.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 1584 LR: 0.0009455032620941839 Training loss: 0.0
2025-12-09 10:24:35.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 1585 LR: 0.0009454312066734622 Training loss: 0.0
2025-12-09 10:24:35.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 1586 LR: 0.0009453591063978302 Training loss: 0.0
2025-12-09 10:24:35.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 1587 LR: 0.0009452869612745483 Training loss: 0.0
2025-12-09 10:24:35.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 1588 LR: 0.0009452147713108816 Training loss: 0.0
2025-12-09 10:24:35.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 1589 LR: 0.0009451425365140996 Training loss: 0.0
2025-12-09 10:24:35.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 1590 LR: 0.0009450702568914763 Training loss: 0.0
2025-12-09 10:24:35.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 1591 LR: 0.0009449979324502904 Training loss: 0.0
2025-12-09 10:24:35.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 1592 LR: 0.0009449255631978249 Training loss: 0.0
2025-12-09 10:24:35.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 1593 LR: 0.0009448531491413672 Training loss: 0.0
2025-12-09 10:24:35.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 1594 LR: 0.0009447806902882097 Training loss: 0.0
2025-12-09 10:24:35.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 1595 LR: 0.0009447081866456489 Training loss: 0.0
2025-12-09 10:24:35.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 1596 LR: 0.0009446356382209857 Training loss: 0.0
2025-12-09 10:24:35.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 1597 LR: 0.0009445630450215259 Training loss: 0.0
2025-12-09 10:24:35.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 1598 LR: 0.0009444904070545798 Training loss: 0.0
2025-12-09 10:24:35.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 1599 LR: 0.0009444177243274617 Training loss: 0.0
2025-12-09 10:24:35.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 1600 LR: 0.0009443449968474911 Training loss: 0.0
2025-12-09 10:24:35.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 1601 LR: 0.0009442722246219914 Training loss: 0.0
2025-12-09 10:24:35.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 1602 LR: 0.0009441994076582908 Training loss: 0.0
2025-12-09 10:24:35.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 1603 LR: 0.000944126545963722 Training loss: 0.0
2025-12-09 10:24:35.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 1604 LR: 0.0009440536395456222 Training loss: 0.0
2025-12-09 10:24:35.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 1605 LR: 0.000943980688411333 Training loss: 0.0
2025-12-09 10:24:35.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 1606 LR: 0.0009439076925682006 Training loss: 0.0
2025-12-09 10:24:35.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 1607 LR: 0.0009438346520235759 Training loss: 0.0
2025-12-09 10:24:35.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 1608 LR: 0.0009437615667848137 Training loss: 0.0
2025-12-09 10:24:35.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 1609 LR: 0.0009436884368592739 Training loss: 0.0
2025-12-09 10:24:35.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 1610 LR: 0.0009436152622543207 Training loss: 0.0
2025-12-09 10:24:35.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 1611 LR: 0.0009435420429773227 Training loss: 0.0
2025-12-09 10:24:35.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 1612 LR: 0.0009434687790356531 Training loss: 0.0
2025-12-09 10:24:35.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 1613 LR: 0.0009433954704366896 Training loss: 0.0
2025-12-09 10:24:35.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 1614 LR: 0.0009433221171878144 Training loss: 0.0
2025-12-09 10:24:35.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 1615 LR: 0.0009432487192964141 Training loss: 0.0
2025-12-09 10:24:35.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 1616 LR: 0.0009431752767698798 Training loss: 0.0
2025-12-09 10:24:35.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 1617 LR: 0.0009431017896156073 Training loss: 0.0
2025-12-09 10:24:35.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 1618 LR: 0.0009430282578409968 Training loss: 0.0
2025-12-09 10:24:35.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 1619 LR: 0.0009429546814534529 Training loss: 0.0
2025-12-09 10:24:35.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 1620 LR: 0.0009428810604603845 Training loss: 0.0
2025-12-09 10:24:35.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 1621 LR: 0.0009428073948692055 Training loss: 0.0
2025-12-09 10:24:35.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 1622 LR: 0.000942733684687334 Training loss: 0.0
2025-12-09 10:24:35.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 1623 LR: 0.0009426599299221925 Training loss: 0.0
2025-12-09 10:24:35.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 1624 LR: 0.0009425861305812082 Training loss: 0.0
2025-12-09 10:24:35.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 1625 LR: 0.0009425122866718128 Training loss: 0.0
2025-12-09 10:24:35.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 1626 LR: 0.0009424383982014422 Training loss: 0.0
2025-12-09 10:24:35.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 1627 LR: 0.0009423644651775368 Training loss: 0.0
2025-12-09 10:24:35.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 1628 LR: 0.0009422904876075419 Training loss: 0.0
2025-12-09 10:24:35.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 1629 LR: 0.0009422164654989072 Training loss: 0.0
2025-12-09 10:24:35.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 1630 LR: 0.0009421423988590865 Training loss: 0.0
2025-12-09 10:24:35.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 1631 LR: 0.0009420682876955382 Training loss: 0.0
2025-12-09 10:24:35.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 1632 LR: 0.0009419941320157255 Training loss: 0.0
2025-12-09 10:24:35.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 1633 LR: 0.0009419199318271156 Training loss: 0.0
2025-12-09 10:24:35.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 1634 LR: 0.0009418456871371809 Training loss: 0.0
2025-12-09 10:24:35.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 1635 LR: 0.0009417713979533975 Training loss: 0.0
2025-12-09 10:24:35.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 1636 LR: 0.0009416970642832464 Training loss: 0.0
2025-12-09 10:24:35.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 1637 LR: 0.0009416226861342131 Training loss: 0.0
2025-12-09 10:24:35.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 1638 LR: 0.0009415482635137873 Training loss: 0.0
2025-12-09 10:24:35.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 1639 LR: 0.0009414737964294635 Training loss: 0.0
2025-12-09 10:24:35.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 1640 LR: 0.0009413992848887405 Training loss: 0.0
2025-12-09 10:24:35.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 1641 LR: 0.0009413247288991216 Training loss: 0.0
2025-12-09 10:24:35.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 1642 LR: 0.0009412501284681144 Training loss: 0.0
2025-12-09 10:24:35.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 1643 LR: 0.0009411754836032315 Training loss: 0.0
2025-12-09 10:24:35.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 1644 LR: 0.0009411007943119894 Training loss: 0.0
2025-12-09 10:24:35.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 1645 LR: 0.0009410260606019094 Training loss: 0.0
2025-12-09 10:24:35.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 1646 LR: 0.0009409512824805172 Training loss: 0.0
2025-12-09 10:24:35.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 1647 LR: 0.0009408764599553429 Training loss: 0.0
2025-12-09 10:24:35.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 1648 LR: 0.0009408015930339211 Training loss: 0.0
2025-12-09 10:24:35.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 1649 LR: 0.000940726681723791 Training loss: 0.0
2025-12-09 10:24:35.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 1650 LR: 0.0009406517260324961 Training loss: 0.0
2025-12-09 10:24:35.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 1651 LR: 0.0009405767259675845 Training loss: 0.0
2025-12-09 10:24:35.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 1652 LR: 0.0009405016815366086 Training loss: 0.0
2025-12-09 10:24:35.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 1653 LR: 0.0009404265927471254 Training loss: 0.0
2025-12-09 10:24:35.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 1654 LR: 0.0009403514596066963 Training loss: 0.0
2025-12-09 10:24:35.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 1655 LR: 0.0009402762821228874 Training loss: 0.0
2025-12-09 10:24:35.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 1656 LR: 0.0009402010603032689 Training loss: 0.0
2025-12-09 10:24:35.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 1657 LR: 0.0009401257941554157 Training loss: 0.0
2025-12-09 10:24:35.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 1658 LR: 0.0009400504836869069 Training loss: 0.0
2025-12-09 10:24:35.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 1659 LR: 0.0009399751289053266 Training loss: 0.0
2025-12-09 10:24:35.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 1660 LR: 0.0009398997298182628 Training loss: 0.0
2025-12-09 10:24:35.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 1661 LR: 0.0009398242864333083 Training loss: 0.0
2025-12-09 10:24:35.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 1662 LR: 0.0009397487987580601 Training loss: 0.0
2025-12-09 10:24:35.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 1663 LR: 0.00093967326680012 Training loss: 0.0
2025-12-09 10:24:35.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 1664 LR: 0.0009395976905670939 Training loss: 0.0
2025-12-09 10:24:35.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 1665 LR: 0.0009395220700665923 Training loss: 0.0
2025-12-09 10:24:35.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 1666 LR: 0.0009394464053062303 Training loss: 0.0
2025-12-09 10:24:35.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 1667 LR: 0.0009393706962936275 Training loss: 0.0
2025-12-09 10:24:35.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 1668 LR: 0.0009392949430364075 Training loss: 0.0
2025-12-09 10:24:35.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 1669 LR: 0.0009392191455421988 Training loss: 0.0
2025-12-09 10:24:35.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 1670 LR: 0.0009391433038186341 Training loss: 0.0
2025-12-09 10:24:35.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 1671 LR: 0.0009390674178733507 Training loss: 0.0
2025-12-09 10:24:35.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 1672 LR: 0.0009389914877139902 Training loss: 0.0
2025-12-09 10:24:35.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 1673 LR: 0.0009389155133481993 Training loss: 0.0
2025-12-09 10:24:35.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 1674 LR: 0.0009388394947836278 Training loss: 0.0
2025-12-09 10:24:35.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 1675 LR: 0.0009387634320279315 Training loss: 0.0
2025-12-09 10:24:35.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 1676 LR: 0.0009386873250887693 Training loss: 0.0
2025-12-09 10:24:35.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 1677 LR: 0.0009386111739738057 Training loss: 0.0
2025-12-09 10:24:35.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 1678 LR: 0.0009385349786907086 Training loss: 0.0
2025-12-09 10:24:35.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 1679 LR: 0.0009384587392471515 Training loss: 0.0
2025-12-09 10:24:35.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 1680 LR: 0.0009383824556508111 Training loss: 0.0
2025-12-09 10:24:35.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 1681 LR: 0.0009383061279093697 Training loss: 0.0
2025-12-09 10:24:35.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 1682 LR: 0.0009382297560305129 Training loss: 0.0
2025-12-09 10:24:35.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 1683 LR: 0.0009381533400219318 Training loss: 0.0
2025-12-09 10:24:35.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 1684 LR: 0.0009380768798913213 Training loss: 0.0
2025-12-09 10:24:35.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 1685 LR: 0.0009380003756463811 Training loss: 0.0
2025-12-09 10:24:35.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 1686 LR: 0.0009379238272948149 Training loss: 0.0
2025-12-09 10:24:35.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 1687 LR: 0.0009378472348443314 Training loss: 0.0
2025-12-09 10:24:35.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 1688 LR: 0.0009377705983026432 Training loss: 0.0
2025-12-09 10:24:35.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 1689 LR: 0.0009376939176774678 Training loss: 0.0
2025-12-09 10:24:35.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 1690 LR: 0.000937617192976527 Training loss: 0.0
2025-12-09 10:24:35.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 1691 LR: 0.0009375404242075467 Training loss: 0.0
2025-12-09 10:24:35.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 1692 LR: 0.0009374636113782575 Training loss: 0.0
2025-12-09 10:24:35.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 1693 LR: 0.0009373867544963948 Training loss: 0.0
2025-12-09 10:24:35.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 1694 LR: 0.0009373098535696979 Training loss: 0.0
2025-12-09 10:24:35.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 1695 LR: 0.0009372329086059108 Training loss: 0.0
2025-12-09 10:24:35.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 1696 LR: 0.0009371559196127815 Training loss: 0.0
2025-12-09 10:24:35.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 1697 LR: 0.0009370788865980632 Training loss: 0.0
2025-12-09 10:24:35.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 1698 LR: 0.000937001809569513 Training loss: 0.0
2025-12-09 10:24:35.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 1699 LR: 0.0009369246885348925 Training loss: 0.0
2025-12-09 10:24:35.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 1700 LR: 0.0009368475235019678 Training loss: 0.0
2025-12-09 10:24:35.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 1701 LR: 0.0009367703144785096 Training loss: 0.0
2025-12-09 10:24:35.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 1702 LR: 0.0009366930614722924 Training loss: 0.0
2025-12-09 10:24:35.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 1703 LR: 0.000936615764491096 Training loss: 0.0
2025-12-09 10:24:35.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 1704 LR: 0.0009365384235427042 Training loss: 0.0
2025-12-09 10:24:35.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 1705 LR: 0.0009364610386349048 Training loss: 0.0
2025-12-09 10:24:35.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 1706 LR: 0.000936383609775491 Training loss: 0.0
2025-12-09 10:24:35.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 1707 LR: 0.0009363061369722595 Training loss: 0.0
2025-12-09 10:24:35.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 1708 LR: 0.0009362286202330121 Training loss: 0.0
2025-12-09 10:24:35.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 1709 LR: 0.0009361510595655545 Training loss: 0.0
2025-12-09 10:24:35.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 1710 LR: 0.0009360734549776971 Training loss: 0.0
2025-12-09 10:24:35.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 1711 LR: 0.0009359958064772547 Training loss: 0.0
2025-12-09 10:24:35.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 1712 LR: 0.0009359181140720464 Training loss: 0.0
2025-12-09 10:24:35.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 1713 LR: 0.000935840377769896 Training loss: 0.0
2025-12-09 10:24:35.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 1714 LR: 0.0009357625975786317 Training loss: 0.0
2025-12-09 10:24:35.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 1715 LR: 0.0009356847735060856 Training loss: 0.0
2025-12-09 10:24:35.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 1716 LR: 0.0009356069055600948 Training loss: 0.0
2025-12-09 10:24:35.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 1717 LR: 0.0009355289937485004 Training loss: 0.0
2025-12-09 10:24:35.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 1718 LR: 0.0009354510380791484 Training loss: 0.0
2025-12-09 10:24:35.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 1719 LR: 0.0009353730385598887 Training loss: 0.0
2025-12-09 10:24:35.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 1720 LR: 0.0009352949951985758 Training loss: 0.0
2025-12-09 10:24:35.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 1721 LR: 0.000935216908003069 Training loss: 0.0
2025-12-09 10:24:35.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 1722 LR: 0.0009351387769812314 Training loss: 0.0
2025-12-09 10:24:35.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 1723 LR: 0.0009350606021409308 Training loss: 0.0
2025-12-09 10:24:35.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 1724 LR: 0.0009349823834900395 Training loss: 0.0
2025-12-09 10:24:35.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 1725 LR: 0.0009349041210364342 Training loss: 0.0
2025-12-09 10:24:35.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 1726 LR: 0.0009348258147879957 Training loss: 0.0
2025-12-09 10:24:35.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 1727 LR: 0.0009347474647526095 Training loss: 0.0
2025-12-09 10:24:35.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 1728 LR: 0.0009346690709381656 Training loss: 0.0
2025-12-09 10:24:35.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 1729 LR: 0.0009345906333525581 Training loss: 0.0
2025-12-09 10:24:35.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 1730 LR: 0.0009345121520036857 Training loss: 0.0
2025-12-09 10:24:35.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 1731 LR: 0.0009344336268994515 Training loss: 0.0
2025-12-09 10:24:35.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 1732 LR: 0.000934355058047763 Training loss: 0.0
2025-12-09 10:24:35.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 1733 LR: 0.000934276445456532 Training loss: 0.0
2025-12-09 10:24:35.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 1734 LR: 0.0009341977891336749 Training loss: 0.0
2025-12-09 10:24:35.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 1735 LR: 0.0009341190890871122 Training loss: 0.0
2025-12-09 10:24:35.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 1736 LR: 0.0009340403453247691 Training loss: 0.0
2025-12-09 10:24:35.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 1737 LR: 0.0009339615578545752 Training loss: 0.0
2025-12-09 10:24:35.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 1738 LR: 0.0009338827266844643 Training loss: 0.0
2025-12-09 10:24:35.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 1739 LR: 0.0009338038518223745 Training loss: 0.0
2025-12-09 10:24:35.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 1740 LR: 0.000933724933276249 Training loss: 0.0
2025-12-09 10:24:35.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 1741 LR: 0.0009336459710540344 Training loss: 0.0
2025-12-09 10:24:35.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 1742 LR: 0.0009335669651636823 Training loss: 0.0
2025-12-09 10:24:35.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 1743 LR: 0.0009334879156131489 Training loss: 0.0
2025-12-09 10:24:35.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 1744 LR: 0.0009334088224103941 Training loss: 0.0
2025-12-09 10:24:35.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 1745 LR: 0.0009333296855633829 Training loss: 0.0
2025-12-09 10:24:35.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 1746 LR: 0.0009332505050800839 Training loss: 0.0
2025-12-09 10:24:35.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 1747 LR: 0.0009331712809684711 Training loss: 0.0
2025-12-09 10:24:35.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 1748 LR: 0.0009330920132365222 Training loss: 0.0
2025-12-09 10:24:35.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 1749 LR: 0.0009330127018922195 Training loss: 0.0
2025-12-09 10:24:35.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 1750 LR: 0.0009329333469435492 Training loss: 0.0
2025-12-09 10:24:35.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 1751 LR: 0.000932853948398503 Training loss: 0.0
2025-12-09 10:24:35.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 1752 LR: 0.0009327745062650761 Training loss: 0.0
2025-12-09 10:24:35.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 1753 LR: 0.0009326950205512681 Training loss: 0.0
2025-12-09 10:24:35.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 1754 LR: 0.0009326154912650833 Training loss: 0.0
2025-12-09 10:24:35.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 1755 LR: 0.0009325359184145306 Training loss: 0.0
2025-12-09 10:24:35.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 1756 LR: 0.0009324563020076227 Training loss: 0.0
2025-12-09 10:24:35.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 1757 LR: 0.0009323766420523768 Training loss: 0.0
2025-12-09 10:24:35.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 1758 LR: 0.000932296938556815 Training loss: 0.0
2025-12-09 10:24:35.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 1759 LR: 0.0009322171915289634 Training loss: 0.0
2025-12-09 10:24:35.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 1760 LR: 0.0009321374009768524 Training loss: 0.0
2025-12-09 10:24:35.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 1761 LR: 0.0009320575669085169 Training loss: 0.0
2025-12-09 10:24:35.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 1762 LR: 0.0009319776893319962 Training loss: 0.0
2025-12-09 10:24:35.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 1763 LR: 0.0009318977682553341 Training loss: 0.0
2025-12-09 10:24:35.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 1764 LR: 0.0009318178036865785 Training loss: 0.0
2025-12-09 10:24:35.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 1765 LR: 0.0009317377956337819 Training loss: 0.0
2025-12-09 10:24:35.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 1766 LR: 0.0009316577441050012 Training loss: 0.0
2025-12-09 10:24:35.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 1767 LR: 0.0009315776491082972 Training loss: 0.0
2025-12-09 10:24:35.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 1768 LR: 0.0009314975106517361 Training loss: 0.0
2025-12-09 10:24:35.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 1769 LR: 0.0009314173287433873 Training loss: 0.0
2025-12-09 10:24:35.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 1770 LR: 0.0009313371033913253 Training loss: 0.0
2025-12-09 10:24:35.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 1771 LR: 0.0009312568346036287 Training loss: 0.0
2025-12-09 10:24:35.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 1772 LR: 0.0009311765223883808 Training loss: 0.0
2025-12-09 10:24:35.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 1773 LR: 0.0009310961667536688 Training loss: 0.0
2025-12-09 10:24:35.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 1774 LR: 0.0009310157677075847 Training loss: 0.0
2025-12-09 10:24:35.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 1775 LR: 0.0009309353252582246 Training loss: 0.0
2025-12-09 10:24:35.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 1776 LR: 0.0009308548394136889 Training loss: 0.0
2025-12-09 10:24:35.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 1777 LR: 0.0009307743101820827 Training loss: 0.0
2025-12-09 10:24:35.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 1778 LR: 0.0009306937375715152 Training loss: 0.0
2025-12-09 10:24:35.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 1779 LR: 0.0009306131215901003 Training loss: 0.0
2025-12-09 10:24:35.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 1780 LR: 0.0009305324622459557 Training loss: 0.0
2025-12-09 10:24:35.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 1781 LR: 0.000930451759547204 Training loss: 0.0
2025-12-09 10:24:35.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 1782 LR: 0.0009303710135019718 Training loss: 0.0
2025-12-09 10:24:35.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 1783 LR: 0.0009302902241183904 Training loss: 0.0
2025-12-09 10:24:35.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 1784 LR: 0.0009302093914045952 Training loss: 0.0
2025-12-09 10:24:35.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 1785 LR: 0.000930128515368726 Training loss: 0.0
2025-12-09 10:24:35.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 1786 LR: 0.0009300475960189272 Training loss: 0.0
2025-12-09 10:24:35.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 1787 LR: 0.0009299666333633471 Training loss: 0.0
2025-12-09 10:24:35.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 1788 LR: 0.0009298856274101388 Training loss: 0.0
2025-12-09 10:24:35.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 1789 LR: 0.0009298045781674596 Training loss: 0.0
2025-12-09 10:24:35.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 1790 LR: 0.0009297234856434712 Training loss: 0.0
2025-12-09 10:24:35.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 1791 LR: 0.0009296423498463396 Training loss: 0.0
2025-12-09 10:24:35.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 1792 LR: 0.0009295611707842349 Training loss: 0.0
2025-12-09 10:24:35.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 1793 LR: 0.0009294799484653322 Training loss: 0.0
2025-12-09 10:24:35.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 1794 LR: 0.0009293986828978105 Training loss: 0.0
2025-12-09 10:24:35.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 1795 LR: 0.0009293173740898531 Training loss: 0.0
2025-12-09 10:24:35.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 1796 LR: 0.0009292360220496479 Training loss: 0.0
2025-12-09 10:24:35.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 1797 LR: 0.000929154626785387 Training loss: 0.0
2025-12-09 10:24:35.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 1798 LR: 0.000929073188305267 Training loss: 0.0
2025-12-09 10:24:35.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 1799 LR: 0.0009289917066174886 Training loss: 0.0
2025-12-09 10:24:35.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 1800 LR: 0.000928910181730257 Training loss: 0.0
2025-12-09 10:24:35.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 1801 LR: 0.000928828613651782 Training loss: 0.0
2025-12-09 10:24:35.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 1802 LR: 0.0009287470023902773 Training loss: 0.0
2025-12-09 10:24:35.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 1803 LR: 0.0009286653479539611 Training loss: 0.0
2025-12-09 10:24:35.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 1804 LR: 0.0009285836503510562 Training loss: 0.0
2025-12-09 10:24:35.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 1805 LR: 0.0009285019095897893 Training loss: 0.0
2025-12-09 10:24:35.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 1806 LR: 0.000928420125678392 Training loss: 0.0
2025-12-09 10:24:35.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 1807 LR: 0.0009283382986250997 Training loss: 0.0
2025-12-09 10:24:35.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 1808 LR: 0.0009282564284381524 Training loss: 0.0
2025-12-09 10:24:35.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 1809 LR: 0.0009281745151257945 Training loss: 0.0
2025-12-09 10:24:35.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 1810 LR: 0.0009280925586962747 Training loss: 0.0
2025-12-09 10:24:35.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 1811 LR: 0.0009280105591578458 Training loss: 0.0
2025-12-09 10:24:35.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 1812 LR: 0.0009279285165187654 Training loss: 0.0
2025-12-09 10:24:35.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 1813 LR: 0.0009278464307872951 Training loss: 0.0
2025-12-09 10:24:35.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 1814 LR: 0.000927764301971701 Training loss: 0.0
2025-12-09 10:24:35.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 1815 LR: 0.0009276821300802534 Training loss: 0.0
2025-12-09 10:24:35.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 1816 LR: 0.0009275999151212269 Training loss: 0.0
2025-12-09 10:24:35.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 1817 LR: 0.0009275176571029007 Training loss: 0.0
2025-12-09 10:24:35.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 1818 LR: 0.000927435356033558 Training loss: 0.0
2025-12-09 10:24:35.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 1819 LR: 0.0009273530119214868 Training loss: 0.0
2025-12-09 10:24:35.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 1820 LR: 0.0009272706247749789 Training loss: 0.0
2025-12-09 10:24:35.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 1821 LR: 0.0009271881946023308 Training loss: 0.0
2025-12-09 10:24:35.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 1822 LR: 0.0009271057214118432 Training loss: 0.0
2025-12-09 10:24:35.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 1823 LR: 0.0009270232052118213 Training loss: 0.0
2025-12-09 10:24:35.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 1824 LR: 0.000926940646010574 Training loss: 0.0
2025-12-09 10:24:35.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 1825 LR: 0.0009268580438164156 Training loss: 0.0
2025-12-09 10:24:35.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 1826 LR: 0.0009267753986376637 Training loss: 0.0
2025-12-09 10:24:35.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 1827 LR: 0.0009266927104826409 Training loss: 0.0
2025-12-09 10:24:35.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 1828 LR: 0.0009266099793596739 Training loss: 0.0
2025-12-09 10:24:35.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 1829 LR: 0.0009265272052770935 Training loss: 0.0
2025-12-09 10:24:35.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 1830 LR: 0.0009264443882432354 Training loss: 0.0
2025-12-09 10:24:35.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 1831 LR: 0.0009263615282664388 Training loss: 0.0
2025-12-09 10:24:35.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 1832 LR: 0.0009262786253550481 Training loss: 0.0
2025-12-09 10:24:35.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 1833 LR: 0.0009261956795174116 Training loss: 0.0
2025-12-09 10:24:35.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 1834 LR: 0.0009261126907618817 Training loss: 0.0
2025-12-09 10:24:35.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 1835 LR: 0.0009260296590968156 Training loss: 0.0
2025-12-09 10:24:35.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 1836 LR: 0.0009259465845305744 Training loss: 0.0
2025-12-09 10:24:35.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 1837 LR: 0.0009258634670715238 Training loss: 0.0
2025-12-09 10:24:35.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 1838 LR: 0.0009257803067280337 Training loss: 0.0
2025-12-09 10:24:35.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 1839 LR: 0.0009256971035084784 Training loss: 0.0
2025-12-09 10:24:35.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 1840 LR: 0.0009256138574212365 Training loss: 0.0
2025-12-09 10:24:35.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 1841 LR: 0.0009255305684746908 Training loss: 0.0
2025-12-09 10:24:35.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 1842 LR: 0.0009254472366772284 Training loss: 0.0
2025-12-09 10:24:35.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 1843 LR: 0.0009253638620372409 Training loss: 0.0
2025-12-09 10:24:35.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 1844 LR: 0.0009252804445631242 Training loss: 0.0
2025-12-09 10:24:35.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 1845 LR: 0.0009251969842632784 Training loss: 0.0
2025-12-09 10:24:35.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 1846 LR: 0.0009251134811461077 Training loss: 0.0
2025-12-09 10:24:35.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 1847 LR: 0.0009250299352200213 Training loss: 0.0
2025-12-09 10:24:35.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 1848 LR: 0.000924946346493432 Training loss: 0.0
2025-12-09 10:24:35.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 1849 LR: 0.0009248627149747573 Training loss: 0.0
2025-12-09 10:24:35.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 1850 LR: 0.0009247790406724186 Training loss: 0.0
2025-12-09 10:24:35.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 1851 LR: 0.0009246953235948423 Training loss: 0.0
2025-12-09 10:24:35.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 1852 LR: 0.0009246115637504586 Training loss: 0.0
2025-12-09 10:24:35.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 1853 LR: 0.0009245277611477019 Training loss: 0.0
2025-12-09 10:24:35.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 1854 LR: 0.0009244439157950113 Training loss: 0.0
2025-12-09 10:24:35.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 1855 LR: 0.0009243600277008301 Training loss: 0.0
2025-12-09 10:24:35.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 1856 LR: 0.0009242760968736056 Training loss: 0.0
2025-12-09 10:24:35.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 1857 LR: 0.0009241921233217898 Training loss: 0.0
2025-12-09 10:24:35.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 1858 LR: 0.0009241081070538389 Training loss: 0.0
2025-12-09 10:24:35.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 1859 LR: 0.0009240240480782129 Training loss: 0.0
2025-12-09 10:24:35.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 1860 LR: 0.000923939946403377 Training loss: 0.0
2025-12-09 10:24:35.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 1861 LR: 0.0009238558020378003 Training loss: 0.0
2025-12-09 10:24:35.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 1862 LR: 0.0009237716149899559 Training loss: 0.0
2025-12-09 10:24:35.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 1863 LR: 0.0009236873852683213 Training loss: 0.0
2025-12-09 10:24:35.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 1864 LR: 0.0009236031128813787 Training loss: 0.0
2025-12-09 10:24:35.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 1865 LR: 0.0009235187978376141 Training loss: 0.0
2025-12-09 10:24:35.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 1866 LR: 0.0009234344401455183 Training loss: 0.0
2025-12-09 10:24:35.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 1867 LR: 0.0009233500398135859 Training loss: 0.0
2025-12-09 10:24:35.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 1868 LR: 0.0009232655968503161 Training loss: 0.0
2025-12-09 10:24:35.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 1869 LR: 0.0009231811112642122 Training loss: 0.0
2025-12-09 10:24:35.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 1870 LR: 0.000923096583063782 Training loss: 0.0
2025-12-09 10:24:35.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 1871 LR: 0.0009230120122575375 Training loss: 0.0
2025-12-09 10:24:35.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 1872 LR: 0.000922927398853995 Training loss: 0.0
2025-12-09 10:24:35.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 1873 LR: 0.0009228427428616748 Training loss: 0.0
2025-12-09 10:24:35.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 1874 LR: 0.0009227580442891022 Training loss: 0.0
2025-12-09 10:24:35.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 1875 LR: 0.0009226733031448061 Training loss: 0.0
2025-12-09 10:24:35.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 1876 LR: 0.0009225885194373198 Training loss: 0.0
2025-12-09 10:24:35.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 1877 LR: 0.0009225036931751811 Training loss: 0.0
2025-12-09 10:24:35.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 1878 LR: 0.0009224188243669323 Training loss: 0.0
2025-12-09 10:24:35.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 1879 LR: 0.0009223339130211192 Training loss: 0.0
2025-12-09 10:24:35.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 1880 LR: 0.0009222489591462927 Training loss: 0.0
2025-12-09 10:24:35.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 1881 LR: 0.0009221639627510075 Training loss: 0.0
2025-12-09 10:24:35.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 1882 LR: 0.000922078923843823 Training loss: 0.0
2025-12-09 10:24:35.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 1883 LR: 0.0009219938424333023 Training loss: 0.0
2025-12-09 10:24:35.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 1884 LR: 0.0009219087185280132 Training loss: 0.0
2025-12-09 10:24:35.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 1885 LR: 0.0009218235521365277 Training loss: 0.0
2025-12-09 10:24:35.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 1886 LR: 0.000921738343267422 Training loss: 0.0
2025-12-09 10:24:35.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 1887 LR: 0.0009216530919292767 Training loss: 0.0
2025-12-09 10:24:35.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 1888 LR: 0.0009215677981306767 Training loss: 0.0
2025-12-09 10:24:35.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 1889 LR: 0.0009214824618802108 Training loss: 0.0
2025-12-09 10:24:35.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 1890 LR: 0.0009213970831864726 Training loss: 0.0
2025-12-09 10:24:35.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 1891 LR: 0.0009213116620580596 Training loss: 0.0
2025-12-09 10:24:35.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 1892 LR: 0.0009212261985035739 Training loss: 0.0
2025-12-09 10:24:35.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 1893 LR: 0.0009211406925316213 Training loss: 0.0
2025-12-09 10:24:35.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 1894 LR: 0.0009210551441508126 Training loss: 0.0
2025-12-09 10:24:35.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 1895 LR: 0.0009209695533697624 Training loss: 0.0
2025-12-09 10:24:35.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 1896 LR: 0.0009208839201970898 Training loss: 0.0
2025-12-09 10:24:35.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 1897 LR: 0.0009207982446414178 Training loss: 0.0
2025-12-09 10:24:35.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 1898 LR: 0.0009207125267113741 Training loss: 0.0
2025-12-09 10:24:35.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 1899 LR: 0.0009206267664155906 Training loss: 0.0
2025-12-09 10:24:35.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 1900 LR: 0.0009205409637627032 Training loss: 0.0
2025-12-09 10:24:35.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 1901 LR: 0.0009204551187613521 Training loss: 0.0
2025-12-09 10:24:35.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 1902 LR: 0.0009203692314201822 Training loss: 0.0
2025-12-09 10:24:35.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 1903 LR: 0.0009202833017478421 Training loss: 0.0
2025-12-09 10:24:35.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 1904 LR: 0.0009201973297529851 Training loss: 0.0
2025-12-09 10:24:35.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 1905 LR: 0.0009201113154442684 Training loss: 0.0
2025-12-09 10:24:35.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 1906 LR: 0.000920025258830354 Training loss: 0.0
2025-12-09 10:24:35.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 1907 LR: 0.0009199391599199072 Training loss: 0.0
2025-12-09 10:24:35.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 1908 LR: 0.0009198530187215986 Training loss: 0.0
2025-12-09 10:24:35.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 1909 LR: 0.0009197668352441024 Training loss: 0.0
2025-12-09 10:24:35.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 1910 LR: 0.0009196806094960976 Training loss: 0.0
2025-12-09 10:24:35.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 1911 LR: 0.0009195943414862666 Training loss: 0.0
2025-12-09 10:24:35.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 1912 LR: 0.0009195080312232971 Training loss: 0.0
2025-12-09 10:24:35.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 1913 LR: 0.0009194216787158805 Training loss: 0.0
2025-12-09 10:24:35.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 1914 LR: 0.0009193352839727121 Training loss: 0.0
2025-12-09 10:24:35.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 1915 LR: 0.000919248847002492 Training loss: 0.0
2025-12-09 10:24:35.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 1916 LR: 0.0009191623678139247 Training loss: 0.0
2025-12-09 10:24:35.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 1917 LR: 0.0009190758464157183 Training loss: 0.0
2025-12-09 10:24:35.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 1918 LR: 0.0009189892828165856 Training loss: 0.0
2025-12-09 10:24:35.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 1919 LR: 0.0009189026770252437 Training loss: 0.0
2025-12-09 10:24:35.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 1920 LR: 0.0009188160290504136 Training loss: 0.0
2025-12-09 10:24:35.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 1921 LR: 0.0009187293389008209 Training loss: 0.0
2025-12-09 10:24:35.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 1922 LR: 0.0009186426065851952 Training loss: 0.0
2025-12-09 10:24:35.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 1923 LR: 0.0009185558321122704 Training loss: 0.0
2025-12-09 10:24:35.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 1924 LR: 0.0009184690154907849 Training loss: 0.0
2025-12-09 10:24:35.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 1925 LR: 0.0009183821567294809 Training loss: 0.0
2025-12-09 10:24:35.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 1926 LR: 0.0009182952558371052 Training loss: 0.0
2025-12-09 10:24:35.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 1927 LR: 0.0009182083128224086 Training loss: 0.0
2025-12-09 10:24:35.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 1928 LR: 0.0009181213276941465 Training loss: 0.0
2025-12-09 10:24:35.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 1929 LR: 0.000918034300461078 Training loss: 0.0
2025-12-09 10:24:35.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 1930 LR: 0.0009179472311319669 Training loss: 0.0
2025-12-09 10:24:35.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 1931 LR: 0.0009178601197155811 Training loss: 0.0
2025-12-09 10:24:35.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 1932 LR: 0.0009177729662206926 Training loss: 0.0
2025-12-09 10:24:35.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 1933 LR: 0.0009176857706560779 Training loss: 0.0
2025-12-09 10:24:35.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 1934 LR: 0.0009175985330305176 Training loss: 0.0
2025-12-09 10:24:35.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 1935 LR: 0.0009175112533527963 Training loss: 0.0
2025-12-09 10:24:35.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 1936 LR: 0.0009174239316317032 Training loss: 0.0
2025-12-09 10:24:35.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 1937 LR: 0.0009173365678760318 Training loss: 0.0
2025-12-09 10:24:35.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 1938 LR: 0.0009172491620945793 Training loss: 0.0
2025-12-09 10:24:35.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 1939 LR: 0.0009171617142961477 Training loss: 0.0
2025-12-09 10:24:35.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 1940 LR: 0.0009170742244895427 Training loss: 0.0
2025-12-09 10:24:35.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 1941 LR: 0.0009169866926835748 Training loss: 0.0
2025-12-09 10:24:35.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 1942 LR: 0.0009168991188870584 Training loss: 0.0
2025-12-09 10:24:35.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 1943 LR: 0.0009168115031088121 Training loss: 0.0
2025-12-09 10:24:35.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 1944 LR: 0.0009167238453576588 Training loss: 0.0
2025-12-09 10:24:35.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 1945 LR: 0.0009166361456424257 Training loss: 0.0
2025-12-09 10:24:35.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 1946 LR: 0.0009165484039719443 Training loss: 0.0
2025-12-09 10:24:35.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 1947 LR: 0.0009164606203550497 Training loss: 0.0
2025-12-09 10:24:35.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 1948 LR: 0.0009163727948005823 Training loss: 0.0
2025-12-09 10:24:35.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 1949 LR: 0.0009162849273173857 Training loss: 0.0
2025-12-09 10:24:35.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 1950 LR: 0.0009161970179143084 Training loss: 0.0
2025-12-09 10:24:35.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 1951 LR: 0.0009161090666002028 Training loss: 0.0
2025-12-09 10:24:35.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 1952 LR: 0.0009160210733839254 Training loss: 0.0
2025-12-09 10:24:35.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 1953 LR: 0.0009159330382743374 Training loss: 0.0
2025-12-09 10:24:35.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 1954 LR: 0.0009158449612803039 Training loss: 0.0
2025-12-09 10:24:35.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 1955 LR: 0.0009157568424106941 Training loss: 0.0
2025-12-09 10:24:35.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 1956 LR: 0.0009156686816743817 Training loss: 0.0
2025-12-09 10:24:35.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 1957 LR: 0.0009155804790802444 Training loss: 0.0
2025-12-09 10:24:35.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 1958 LR: 0.0009154922346371641 Training loss: 0.0
2025-12-09 10:24:35.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 1959 LR: 0.0009154039483540273 Training loss: 0.0
2025-12-09 10:24:35.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 1960 LR: 0.0009153156202397243 Training loss: 0.0
2025-12-09 10:24:35.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 1961 LR: 0.0009152272503031495 Training loss: 0.0
2025-12-09 10:24:35.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 1962 LR: 0.0009151388385532023 Training loss: 0.0
2025-12-09 10:24:35.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 1963 LR: 0.0009150503849987852 Training loss: 0.0
2025-12-09 10:24:35.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 1964 LR: 0.0009149618896488055 Training loss: 0.0
2025-12-09 10:24:35.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 1965 LR: 0.0009148733525121751 Training loss: 0.0
2025-12-09 10:24:35.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 1966 LR: 0.0009147847735978094 Training loss: 0.0
2025-12-09 10:24:35.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 1967 LR: 0.0009146961529146284 Training loss: 0.0
2025-12-09 10:24:35.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 1968 LR: 0.0009146074904715561 Training loss: 0.0
2025-12-09 10:24:35.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 1969 LR: 0.0009145187862775209 Training loss: 0.0
2025-12-09 10:24:35.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 1970 LR: 0.0009144300403414552 Training loss: 0.0
2025-12-09 10:24:35.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 1971 LR: 0.0009143412526722959 Training loss: 0.0
2025-12-09 10:24:35.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 1972 LR: 0.0009142524232789836 Training loss: 0.0
2025-12-09 10:24:35.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 1973 LR: 0.0009141635521704636 Training loss: 0.0
2025-12-09 10:24:35.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 1974 LR: 0.0009140746393556853 Training loss: 0.0
2025-12-09 10:24:35.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 1975 LR: 0.0009139856848436024 Training loss: 0.0
2025-12-09 10:24:35.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 1976 LR: 0.0009138966886431721 Training loss: 0.0
2025-12-09 10:24:35.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 1977 LR: 0.0009138076507633566 Training loss: 0.0
2025-12-09 10:24:35.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 1978 LR: 0.0009137185712131219 Training loss: 0.0
2025-12-09 10:24:35.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 1979 LR: 0.0009136294500014386 Training loss: 0.0
2025-12-09 10:24:35.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 1980 LR: 0.0009135402871372809 Training loss: 0.0
2025-12-09 10:24:35.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 1981 LR: 0.0009134510826296277 Training loss: 0.0
2025-12-09 10:24:35.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 1982 LR: 0.0009133618364874617 Training loss: 0.0
2025-12-09 10:24:35.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 1983 LR: 0.0009132725487197701 Training loss: 0.0
2025-12-09 10:24:35.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 1984 LR: 0.000913183219335544 Training loss: 0.0
2025-12-09 10:24:35.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 1985 LR: 0.0009130938483437791 Training loss: 0.0
2025-12-09 10:24:35.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 1986 LR: 0.0009130044357534752 Training loss: 0.0
2025-12-09 10:24:35.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 1987 LR: 0.0009129149815736358 Training loss: 0.0
2025-12-09 10:24:35.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 1988 LR: 0.000912825485813269 Training loss: 0.0
2025-12-09 10:24:35.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 1989 LR: 0.000912735948481387 Training loss: 0.0
2025-12-09 10:24:35.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 1990 LR: 0.0009126463695870064 Training loss: 0.0
2025-12-09 10:24:35.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 1991 LR: 0.0009125567491391475 Training loss: 0.0
2025-12-09 10:24:35.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 1992 LR: 0.0009124670871468355 Training loss: 0.0
2025-12-09 10:24:35.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 1993 LR: 0.000912377383619099 Training loss: 0.0
2025-12-09 10:24:35.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 1994 LR: 0.0009122876385649712 Training loss: 0.0
2025-12-09 10:24:35.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 1995 LR: 0.0009121978519934894 Training loss: 0.0
2025-12-09 10:24:35.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 1996 LR: 0.0009121080239136954 Training loss: 0.0
2025-12-09 10:24:35.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 1997 LR: 0.0009120181543346346 Training loss: 0.0
2025-12-09 10:24:35.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 1998 LR: 0.000911928243265357 Training loss: 0.0
2025-12-09 10:24:35.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 1999 LR: 0.0009118382907149164 Training loss: 0.0
2025-12-09 10:24:35.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 2000 LR: 0.0009117482966923714 Training loss: 0.0
2025-12-09 10:24:35.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 2001 LR: 0.0009116582612067838 Training loss: 0.0
2025-12-09 10:24:35.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 2002 LR: 0.000911568184267221 Training loss: 0.0
2025-12-09 10:24:35.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 2003 LR: 0.0009114780658827531 Training loss: 0.0
2025-12-09 10:24:35.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 2004 LR: 0.0009113879060624553 Training loss: 0.0
2025-12-09 10:24:35.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 2005 LR: 0.0009112977048154065 Training loss: 0.0
2025-12-09 10:24:35.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 2006 LR: 0.0009112074621506901 Training loss: 0.0
2025-12-09 10:24:35.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 2007 LR: 0.0009111171780773937 Training loss: 0.0
2025-12-09 10:24:35.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 2008 LR: 0.0009110268526046084 Training loss: 0.0
2025-12-09 10:24:35.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 2009 LR: 0.0009109364857414306 Training loss: 0.0
2025-12-09 10:24:35.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 2010 LR: 0.0009108460774969598 Training loss: 0.0
2025-12-09 10:24:35.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 2011 LR: 0.0009107556278803002 Training loss: 0.0
2025-12-09 10:24:35.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 2012 LR: 0.0009106651369005601 Training loss: 0.0
2025-12-09 10:24:35.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 2013 LR: 0.000910574604566852 Training loss: 0.0
2025-12-09 10:24:35.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 2014 LR: 0.0009104840308882925 Training loss: 0.0
2025-12-09 10:24:35.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 2015 LR: 0.0009103934158740022 Training loss: 0.0
2025-12-09 10:24:35.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 2016 LR: 0.0009103027595331062 Training loss: 0.0
2025-12-09 10:24:35.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 2017 LR: 0.0009102120618747336 Training loss: 0.0
2025-12-09 10:24:35.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 2018 LR: 0.0009101213229080177 Training loss: 0.0
2025-12-09 10:24:35.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 2019 LR: 0.0009100305426420956 Training loss: 0.0
2025-12-09 10:24:35.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 2020 LR: 0.0009099397210861091 Training loss: 0.0
2025-12-09 10:24:35.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 2021 LR: 0.0009098488582492039 Training loss: 0.0
2025-12-09 10:24:35.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 2022 LR: 0.00090975795414053 Training loss: 0.0
2025-12-09 10:24:35.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 2023 LR: 0.0009096670087692413 Training loss: 0.0
2025-12-09 10:24:35.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 2024 LR: 0.0009095760221444959 Training loss: 0.0
2025-12-09 10:24:35.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 2025 LR: 0.0009094849942754564 Training loss: 0.0
2025-12-09 10:24:35.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 2026 LR: 0.0009093939251712891 Training loss: 0.0
2025-12-09 10:24:35.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 2027 LR: 0.0009093028148411649 Training loss: 0.0
2025-12-09 10:24:35.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 2028 LR: 0.0009092116632942582 Training loss: 0.0
2025-12-09 10:24:35.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 2029 LR: 0.0009091204705397484 Training loss: 0.0
2025-12-09 10:24:35.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 2030 LR: 0.0009090292365868183 Training loss: 0.0
2025-12-09 10:24:35.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 2031 LR: 0.0009089379614446553 Training loss: 0.0
2025-12-09 10:24:35.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 2032 LR: 0.0009088466451224507 Training loss: 0.0
2025-12-09 10:24:35.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 2033 LR: 0.0009087552876294002 Training loss: 0.0
2025-12-09 10:24:35.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 2034 LR: 0.0009086638889747034 Training loss: 0.0
2025-12-09 10:24:35.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 2035 LR: 0.0009085724491675642 Training loss: 0.0
2025-12-09 10:24:35.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 2036 LR: 0.0009084809682171906 Training loss: 0.0
2025-12-09 10:24:35.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 2037 LR: 0.0009083894461327947 Training loss: 0.0
2025-12-09 10:24:35.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 2038 LR: 0.0009082978829235926 Training loss: 0.0
2025-12-09 10:24:35.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 2039 LR: 0.0009082062785988049 Training loss: 0.0
2025-12-09 10:24:35.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 2040 LR: 0.0009081146331676562 Training loss: 0.0
2025-12-09 10:24:35.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 2041 LR: 0.000908022946639375 Training loss: 0.0
2025-12-09 10:24:35.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 2042 LR: 0.0009079312190231943 Training loss: 0.0
2025-12-09 10:24:35.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 2043 LR: 0.0009078394503283509 Training loss: 0.0
2025-12-09 10:24:35.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 2044 LR: 0.0009077476405640861 Training loss: 0.0
2025-12-09 10:24:35.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 2045 LR: 0.0009076557897396451 Training loss: 0.0
2025-12-09 10:24:35.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 2046 LR: 0.0009075638978642771 Training loss: 0.0
2025-12-09 10:24:35.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 2047 LR: 0.0009074719649472358 Training loss: 0.0
2025-12-09 10:24:35.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 2048 LR: 0.0009073799909977789 Training loss: 0.0
2025-12-09 10:24:35.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 2049 LR: 0.0009072879760251679 Training loss: 0.0
2025-12-09 10:24:35.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 2050 LR: 0.0009071959200386688 Training loss: 0.0
2025-12-09 10:24:35.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 2051 LR: 0.0009071038230475519 Training loss: 0.0
2025-12-09 10:24:35.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 2052 LR: 0.000907011685061091 Training loss: 0.0
2025-12-09 10:24:35.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 2053 LR: 0.0009069195060885647 Training loss: 0.0
2025-12-09 10:24:35.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 2054 LR: 0.000906827286139255 Training loss: 0.0
2025-12-09 10:24:35.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 2055 LR: 0.000906735025222449 Training loss: 0.0
2025-12-09 10:24:35.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 2056 LR: 0.000906642723347437 Training loss: 0.0
2025-12-09 10:24:35.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 2057 LR: 0.0009065503805235138 Training loss: 0.0
2025-12-09 10:24:35.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 2058 LR: 0.0009064579967599785 Training loss: 0.0
2025-12-09 10:24:35.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 2059 LR: 0.0009063655720661341 Training loss: 0.0
2025-12-09 10:24:35.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 2060 LR: 0.0009062731064512875 Training loss: 0.0
2025-12-09 10:24:35.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 2061 LR: 0.0009061805999247503 Training loss: 0.0
2025-12-09 10:24:35.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 2062 LR: 0.000906088052495838 Training loss: 0.0
2025-12-09 10:24:35.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 2063 LR: 0.0009059954641738697 Training loss: 0.0
2025-12-09 10:24:35.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 2064 LR: 0.0009059028349681692 Training loss: 0.0
2025-12-09 10:24:35.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 2065 LR: 0.0009058101648880645 Training loss: 0.0
2025-12-09 10:24:35.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 2066 LR: 0.0009057174539428873 Training loss: 0.0
2025-12-09 10:24:35.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 2067 LR: 0.0009056247021419734 Training loss: 0.0
2025-12-09 10:24:35.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 2068 LR: 0.0009055319094946634 Training loss: 0.0
2025-12-09 10:24:35.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 2069 LR: 0.000905439076010301 Training loss: 0.0
2025-12-09 10:24:35.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 2070 LR: 0.0009053462016982347 Training loss: 0.0
2025-12-09 10:24:35.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 2071 LR: 0.0009052532865678172 Training loss: 0.0
2025-12-09 10:24:35.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 2072 LR: 0.0009051603306284047 Training loss: 0.0
2025-12-09 10:24:35.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 2073 LR: 0.0009050673338893579 Training loss: 0.0
2025-12-09 10:24:35.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 2074 LR: 0.0009049742963600418 Training loss: 0.0
2025-12-09 10:24:35.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 2075 LR: 0.000904881218049825 Training loss: 0.0
2025-12-09 10:24:35.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 2076 LR: 0.0009047880989680807 Training loss: 0.0
2025-12-09 10:24:35.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 2077 LR: 0.0009046949391241859 Training loss: 0.0
2025-12-09 10:24:35.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 2078 LR: 0.0009046017385275218 Training loss: 0.0
2025-12-09 10:24:35.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 2079 LR: 0.0009045084971874737 Training loss: 0.0
2025-12-09 10:24:35.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 2080 LR: 0.0009044152151134311 Training loss: 0.0
2025-12-09 10:24:35.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 2081 LR: 0.0009043218923147873 Training loss: 0.0
2025-12-09 10:24:35.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 2082 LR: 0.00090422852880094 Training loss: 0.0
2025-12-09 10:24:35.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 2083 LR: 0.000904135124581291 Training loss: 0.0
2025-12-09 10:24:35.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 2084 LR: 0.0009040416796652459 Training loss: 0.0
2025-12-09 10:24:35.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 2085 LR: 0.0009039481940622148 Training loss: 0.0
2025-12-09 10:24:35.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 2086 LR: 0.0009038546677816115 Training loss: 0.0
2025-12-09 10:24:35.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 2087 LR: 0.0009037611008328543 Training loss: 0.0
2025-12-09 10:24:35.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 2088 LR: 0.0009036674932253652 Training loss: 0.0
2025-12-09 10:24:35.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 2089 LR: 0.0009035738449685707 Training loss: 0.0
2025-12-09 10:24:35.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 2090 LR: 0.0009034801560719011 Training loss: 0.0
2025-12-09 10:24:35.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 2091 LR: 0.0009033864265447906 Training loss: 0.0
2025-12-09 10:24:35.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 2092 LR: 0.0009032926563966781 Training loss: 0.0
2025-12-09 10:24:35.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 2093 LR: 0.0009031988456370062 Training loss: 0.0
2025-12-09 10:24:35.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 2094 LR: 0.0009031049942752215 Training loss: 0.0
2025-12-09 10:24:35.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 2095 LR: 0.000903011102320775 Training loss: 0.0
2025-12-09 10:24:35.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 2096 LR: 0.0009029171697831213 Training loss: 0.0
2025-12-09 10:24:35.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 2097 LR: 0.0009028231966717199 Training loss: 0.0
2025-12-09 10:24:35.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 2098 LR: 0.0009027291829960335 Training loss: 0.0
2025-12-09 10:24:35.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 2099 LR: 0.0009026351287655293 Training loss: 0.0
2025-12-09 10:24:35.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 2100 LR: 0.0009025410339896788 Training loss: 0.0
2025-12-09 10:24:35.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 2101 LR: 0.000902446898677957 Training loss: 0.0
2025-12-09 10:24:35.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 2102 LR: 0.0009023527228398438 Training loss: 0.0
2025-12-09 10:24:35.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 2103 LR: 0.0009022585064848221 Training loss: 0.0
2025-12-09 10:24:35.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 2104 LR: 0.0009021642496223801 Training loss: 0.0
2025-12-09 10:24:35.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 2105 LR: 0.0009020699522620091 Training loss: 0.0
2025-12-09 10:24:35.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 2106 LR: 0.0009019756144132047 Training loss: 0.0
2025-12-09 10:24:35.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 2107 LR: 0.0009018812360854671 Training loss: 0.0
2025-12-09 10:24:35.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 2108 LR: 0.0009017868172882999 Training loss: 0.0
2025-12-09 10:24:35.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 2109 LR: 0.0009016923580312113 Training loss: 0.0
2025-12-09 10:24:35.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 2110 LR: 0.0009015978583237132 Training loss: 0.0
2025-12-09 10:24:35.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 2111 LR: 0.0009015033181753218 Training loss: 0.0
2025-12-09 10:24:35.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 2112 LR: 0.0009014087375955574 Training loss: 0.0
2025-12-09 10:24:35.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 2113 LR: 0.0009013141165939438 Training loss: 0.0
2025-12-09 10:24:35.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 2114 LR: 0.0009012194551800098 Training loss: 0.0
2025-12-09 10:24:35.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 2115 LR: 0.0009011247533632876 Training loss: 0.0
2025-12-09 10:24:35.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 2116 LR: 0.0009010300111533138 Training loss: 0.0
2025-12-09 10:24:35.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 2117 LR: 0.0009009352285596286 Training loss: 0.0
2025-12-09 10:24:35.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 2118 LR: 0.0009008404055917772 Training loss: 0.0
2025-12-09 10:24:35.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 2119 LR: 0.0009007455422593077 Training loss: 0.0
2025-12-09 10:24:35.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 2120 LR: 0.000900650638571773 Training loss: 0.0
2025-12-09 10:24:35.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 2121 LR: 0.0009005556945387301 Training loss: 0.0
2025-12-09 10:24:35.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 2122 LR: 0.0009004607101697397 Training loss: 0.0
2025-12-09 10:24:35.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 2123 LR: 0.0009003656854743667 Training loss: 0.0
2025-12-09 10:24:35.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 2124 LR: 0.0009002706204621802 Training loss: 0.0
2025-12-09 10:24:35.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 2125 LR: 0.0009001755151427531 Training loss: 0.0
2025-12-09 10:24:35.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 2126 LR: 0.0009000803695256627 Training loss: 0.0
2025-12-09 10:24:35.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 2127 LR: 0.00089998518362049 Training loss: 0.0
2025-12-09 10:24:35.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 2128 LR: 0.0008998899574368201 Training loss: 0.0
2025-12-09 10:24:35.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 2129 LR: 0.0008997946909842425 Training loss: 0.0
2025-12-09 10:24:35.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 2130 LR: 0.0008996993842723504 Training loss: 0.0
2025-12-09 10:24:35.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 2131 LR: 0.0008996040373107414 Training loss: 0.0
2025-12-09 10:24:35.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 2132 LR: 0.0008995086501090167 Training loss: 0.0
2025-12-09 10:24:35.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 2133 LR: 0.0008994132226767819 Training loss: 0.0
2025-12-09 10:24:35.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 2134 LR: 0.0008993177550236464 Training loss: 0.0
2025-12-09 10:24:35.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 2135 LR: 0.0008992222471592239 Training loss: 0.0
2025-12-09 10:24:35.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 2136 LR: 0.0008991266990931321 Training loss: 0.0
2025-12-09 10:24:35.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 2137 LR: 0.0008990311108349927 Training loss: 0.0
2025-12-09 10:24:35.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 2138 LR: 0.0008989354823944314 Training loss: 0.0
2025-12-09 10:24:35.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 2139 LR: 0.0008988398137810777 Training loss: 0.0
2025-12-09 10:24:35.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 2140 LR: 0.0008987441050045658 Training loss: 0.0
2025-12-09 10:24:35.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 2141 LR: 0.0008986483560745334 Training loss: 0.0
2025-12-09 10:24:35.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 2142 LR: 0.0008985525670006225 Training loss: 0.0
2025-12-09 10:24:35.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 2143 LR: 0.000898456737792479 Training loss: 0.0
2025-12-09 10:24:35.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 2144 LR: 0.0008983608684597529 Training loss: 0.0
2025-12-09 10:24:35.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 2145 LR: 0.0008982649590120981 Training loss: 0.0
2025-12-09 10:24:35.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 2146 LR: 0.000898169009459173 Training loss: 0.0
2025-12-09 10:24:35.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 2147 LR: 0.0008980730198106394 Training loss: 0.0
2025-12-09 10:24:35.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 2148 LR: 0.0008979769900761638 Training loss: 0.0
2025-12-09 10:24:35.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 2149 LR: 0.0008978809202654162 Training loss: 0.0
2025-12-09 10:24:35.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 2150 LR: 0.0008977848103880706 Training loss: 0.0
2025-12-09 10:24:35.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 2151 LR: 0.0008976886604538055 Training loss: 0.0
2025-12-09 10:24:35.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 2152 LR: 0.0008975924704723033 Training loss: 0.0
2025-12-09 10:24:35.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 2153 LR: 0.0008974962404532502 Training loss: 0.0
2025-12-09 10:24:35.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 2154 LR: 0.0008973999704063365 Training loss: 0.0
2025-12-09 10:24:35.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 2155 LR: 0.0008973036603412566 Training loss: 0.0
2025-12-09 10:24:35.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 2156 LR: 0.0008972073102677091 Training loss: 0.0
2025-12-09 10:24:35.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 2157 LR: 0.0008971109201953962 Training loss: 0.0
2025-12-09 10:24:35.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 2158 LR: 0.0008970144901340246 Training loss: 0.0
2025-12-09 10:24:35.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 2159 LR: 0.0008969180200933046 Training loss: 0.0
2025-12-09 10:24:35.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 2160 LR: 0.000896821510082951 Training loss: 0.0
2025-12-09 10:24:35.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 2161 LR: 0.0008967249601126821 Training loss: 0.0
2025-12-09 10:24:35.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 2162 LR: 0.0008966283701922205 Training loss: 0.0
2025-12-09 10:24:35.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 2163 LR: 0.000896531740331293 Training loss: 0.0
2025-12-09 10:24:35.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 2164 LR: 0.00089643507053963 Training loss: 0.0
2025-12-09 10:24:35.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 2165 LR: 0.0008963383608269664 Training loss: 0.0
2025-12-09 10:24:35.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 2166 LR: 0.0008962416112030405 Training loss: 0.0
2025-12-09 10:24:35.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 2167 LR: 0.0008961448216775954 Training loss: 0.0
2025-12-09 10:24:35.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 2168 LR: 0.0008960479922603775 Training loss: 0.0
2025-12-09 10:24:36.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 2169 LR: 0.0008959511229611376 Training loss: 0.0
2025-12-09 10:24:36.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 2170 LR: 0.0008958542137896304 Training loss: 0.0
2025-12-09 10:24:36.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 2171 LR: 0.0008957572647556148 Training loss: 0.0
2025-12-09 10:24:36.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 2172 LR: 0.0008956602758688534 Training loss: 0.0
2025-12-09 10:24:36.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 2173 LR: 0.000895563247139113 Training loss: 0.0
2025-12-09 10:24:36.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 2174 LR: 0.0008954661785761646 Training loss: 0.0
2025-12-09 10:24:36.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 2175 LR: 0.0008953690701897827 Training loss: 0.0
2025-12-09 10:24:36.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 2176 LR: 0.0008952719219897464 Training loss: 0.0
2025-12-09 10:24:36.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 2177 LR: 0.0008951747339858382 Training loss: 0.0
2025-12-09 10:24:36.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 2178 LR: 0.0008950775061878452 Training loss: 0.0
2025-12-09 10:24:36.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 2179 LR: 0.0008949802386055581 Training loss: 0.0
2025-12-09 10:24:36.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 2180 LR: 0.0008948829312487718 Training loss: 0.0
2025-12-09 10:24:36.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 2181 LR: 0.0008947855841272852 Training loss: 0.0
2025-12-09 10:24:36.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 2182 LR: 0.0008946881972509009 Training loss: 0.0
2025-12-09 10:24:36.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 2183 LR: 0.0008945907706294261 Training loss: 0.0
2025-12-09 10:24:36.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 2184 LR: 0.0008944933042726714 Training loss: 0.0
2025-12-09 10:24:36.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 2185 LR: 0.0008943957981904518 Training loss: 0.0
2025-12-09 10:24:36.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 2186 LR: 0.000894298252392586 Training loss: 0.0
2025-12-09 10:24:36.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 2187 LR: 0.0008942006668888971 Training loss: 0.0
2025-12-09 10:24:36.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 2188 LR: 0.0008941030416892117 Training loss: 0.0
2025-12-09 10:24:36.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 2189 LR: 0.0008940053768033609 Training loss: 0.0
2025-12-09 10:24:36.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 2190 LR: 0.0008939076722411795 Training loss: 0.0
2025-12-09 10:24:36.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 2191 LR: 0.0008938099280125062 Training loss: 0.0
2025-12-09 10:24:36.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 2192 LR: 0.0008937121441271839 Training loss: 0.0
2025-12-09 10:24:36.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 2193 LR: 0.0008936143205950595 Training loss: 0.0
2025-12-09 10:24:36.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 2194 LR: 0.0008935164574259837 Training loss: 0.0
2025-12-09 10:24:36.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 2195 LR: 0.0008934185546298116 Training loss: 0.0
2025-12-09 10:24:36.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 2196 LR: 0.0008933206122164017 Training loss: 0.0
2025-12-09 10:24:36.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 2197 LR: 0.0008932226301956169 Training loss: 0.0
2025-12-09 10:24:36.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 2198 LR: 0.0008931246085773239 Training loss: 0.0
2025-12-09 10:24:36.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 2199 LR: 0.0008930265473713938 Training loss: 0.0
2025-12-09 10:24:36.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 2200 LR: 0.000892928446587701 Training loss: 0.0
2025-12-09 10:24:36.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 2201 LR: 0.0008928303062361244 Training loss: 0.0
2025-12-09 10:24:36.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 2202 LR: 0.0008927321263265467 Training loss: 0.0
2025-12-09 10:24:36.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 2203 LR: 0.0008926339068688546 Training loss: 0.0
2025-12-09 10:24:36.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 2204 LR: 0.0008925356478729387 Training loss: 0.0
2025-12-09 10:24:36.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 2205 LR: 0.0008924373493486941 Training loss: 0.0
2025-12-09 10:24:36.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 2206 LR: 0.000892339011306019 Training loss: 0.0
2025-12-09 10:24:36.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 2207 LR: 0.0008922406337548161 Training loss: 0.0
2025-12-09 10:24:36.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 2208 LR: 0.0008921422167049923 Training loss: 0.0
2025-12-09 10:24:36.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 2209 LR: 0.0008920437601664579 Training loss: 0.0
2025-12-09 10:24:36.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 2210 LR: 0.0008919452641491276 Training loss: 0.0
2025-12-09 10:24:36.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 2211 LR: 0.0008918467286629199 Training loss: 0.0
2025-12-09 10:24:36.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 2212 LR: 0.0008917481537177574 Training loss: 0.0
2025-12-09 10:24:36.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 2213 LR: 0.0008916495393235665 Training loss: 0.0
2025-12-09 10:24:36.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 2214 LR: 0.0008915508854902777 Training loss: 0.0
2025-12-09 10:24:36.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 2215 LR: 0.0008914521922278255 Training loss: 0.0
2025-12-09 10:24:36.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 2216 LR: 0.0008913534595461482 Training loss: 0.0
2025-12-09 10:24:36.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 2217 LR: 0.0008912546874551882 Training loss: 0.0
2025-12-09 10:24:36.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 2218 LR: 0.0008911558759648919 Training loss: 0.0
2025-12-09 10:24:36.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 2219 LR: 0.0008910570250852097 Training loss: 0.0
2025-12-09 10:24:36.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 2220 LR: 0.0008909581348260957 Training loss: 0.0
2025-12-09 10:24:36.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 2221 LR: 0.0008908592051975082 Training loss: 0.0
2025-12-09 10:24:36.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 2222 LR: 0.0008907602362094093 Training loss: 0.0
2025-12-09 10:24:36.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 2223 LR: 0.0008906612278717657 Training loss: 0.0
2025-12-09 10:24:36.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 2224 LR: 0.0008905621801945467 Training loss: 0.0
2025-12-09 10:24:36.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 2225 LR: 0.0008904630931877271 Training loss: 0.0
2025-12-09 10:24:36.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 2226 LR: 0.0008903639668612846 Training loss: 0.0
2025-12-09 10:24:36.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 2227 LR: 0.0008902648012252013 Training loss: 0.0
2025-12-09 10:24:36.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 2228 LR: 0.0008901655962894633 Training loss: 0.0
2025-12-09 10:24:36.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 2229 LR: 0.0008900663520640604 Training loss: 0.0
2025-12-09 10:24:36.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 2230 LR: 0.0008899670685589865 Training loss: 0.0
2025-12-09 10:24:36.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 2231 LR: 0.0008898677457842395 Training loss: 0.0
2025-12-09 10:24:36.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 2232 LR: 0.0008897683837498211 Training loss: 0.0
2025-12-09 10:24:36.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 2233 LR: 0.0008896689824657372 Training loss: 0.0
2025-12-09 10:24:36.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 2234 LR: 0.0008895695419419972 Training loss: 0.0
2025-12-09 10:24:36.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 2235 LR: 0.0008894700621886152 Training loss: 0.0
2025-12-09 10:24:36.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 2236 LR: 0.0008893705432156085 Training loss: 0.0
2025-12-09 10:24:36.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 2237 LR: 0.000889270985032999 Training loss: 0.0
2025-12-09 10:24:36.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 2238 LR: 0.0008891713876508116 Training loss: 0.0
2025-12-09 10:24:36.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 2239 LR: 0.0008890717510790764 Training loss: 0.0
2025-12-09 10:24:36.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 2240 LR: 0.0008889720753278264 Training loss: 0.0
2025-12-09 10:24:36.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 2241 LR: 0.000888872360407099 Training loss: 0.0
2025-12-09 10:24:36.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 2242 LR: 0.0008887726063269355 Training loss: 0.0
2025-12-09 10:24:36.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 2243 LR: 0.0008886728130973814 Training loss: 0.0
2025-12-09 10:24:36.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 2244 LR: 0.0008885729807284854 Training loss: 0.0
2025-12-09 10:24:36.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 2245 LR: 0.0008884731092303011 Training loss: 0.0
2025-12-09 10:24:36.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 2246 LR: 0.0008883731986128853 Training loss: 0.0
2025-12-09 10:24:36.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 2247 LR: 0.0008882732488862988 Training loss: 0.0
2025-12-09 10:24:36.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 2248 LR: 0.000888173260060607 Training loss: 0.0
2025-12-09 10:24:36.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 2249 LR: 0.0008880732321458784 Training loss: 0.0
2025-12-09 10:24:36.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 2250 LR: 0.0008879731651521861 Training loss: 0.0
2025-12-09 10:24:36.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 2251 LR: 0.0008878730590896064 Training loss: 0.0
2025-12-09 10:24:36.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 2252 LR: 0.0008877729139682205 Training loss: 0.0
2025-12-09 10:24:36.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 2253 LR: 0.0008876727297981127 Training loss: 0.0
2025-12-09 10:24:36.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 2254 LR: 0.0008875725065893717 Training loss: 0.0
2025-12-09 10:24:36.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 2255 LR: 0.0008874722443520898 Training loss: 0.0
2025-12-09 10:24:36.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 2256 LR: 0.0008873719430963636 Training loss: 0.0
2025-12-09 10:24:36.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 2257 LR: 0.0008872716028322931 Training loss: 0.0
2025-12-09 10:24:36.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 2258 LR: 0.000887171223569983 Training loss: 0.0
2025-12-09 10:24:36.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 2259 LR: 0.0008870708053195413 Training loss: 0.0
2025-12-09 10:24:36.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 2260 LR: 0.00088697034809108 Training loss: 0.0
2025-12-09 10:24:36.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 2261 LR: 0.0008868698518947151 Training loss: 0.0
2025-12-09 10:24:36.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 2262 LR: 0.0008867693167405671 Training loss: 0.0
2025-12-09 10:24:36.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 2263 LR: 0.0008866687426387592 Training loss: 0.0
2025-12-09 10:24:36.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 2264 LR: 0.0008865681295994194 Training loss: 0.0
2025-12-09 10:24:36.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 2265 LR: 0.0008864674776326798 Training loss: 0.0
2025-12-09 10:24:36.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 2266 LR: 0.0008863667867486755 Training loss: 0.0
2025-12-09 10:24:36.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 2267 LR: 0.0008862660569575465 Training loss: 0.0
2025-12-09 10:24:36.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 2268 LR: 0.0008861652882694362 Training loss: 0.0
2025-12-09 10:24:36.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 2269 LR: 0.0008860644806944918 Training loss: 0.0
2025-12-09 10:24:36.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 2270 LR: 0.0008859636342428647 Training loss: 0.0
2025-12-09 10:24:36.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 2271 LR: 0.0008858627489247104 Training loss: 0.0
2025-12-09 10:24:36.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 2272 LR: 0.0008857618247501877 Training loss: 0.0
2025-12-09 10:24:36.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 2273 LR: 0.00088566086172946 Training loss: 0.0
2025-12-09 10:24:36.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 2274 LR: 0.0008855598598726938 Training loss: 0.0
2025-12-09 10:24:36.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 2275 LR: 0.0008854588191900604 Training loss: 0.0
2025-12-09 10:24:36.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 2276 LR: 0.0008853577396917345 Training loss: 0.0
2025-12-09 10:24:36.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 2277 LR: 0.0008852566213878947 Training loss: 0.0
2025-12-09 10:24:36.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 2278 LR: 0.0008851554642887237 Training loss: 0.0
2025-12-09 10:24:36.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 2279 LR: 0.0008850542684044079 Training loss: 0.0
2025-12-09 10:24:36.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 2280 LR: 0.0008849530337451378 Training loss: 0.0
2025-12-09 10:24:36.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 2281 LR: 0.0008848517603211078 Training loss: 0.0
2025-12-09 10:24:36.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 2282 LR: 0.0008847504481425161 Training loss: 0.0
2025-12-09 10:24:36.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 2283 LR: 0.0008846490972195647 Training loss: 0.0
2025-12-09 10:24:36.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 2284 LR: 0.0008845477075624598 Training loss: 0.0
2025-12-09 10:24:36.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 2285 LR: 0.0008844462791814112 Training loss: 0.0
2025-12-09 10:24:36.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 2286 LR: 0.0008843448120866329 Training loss: 0.0
2025-12-09 10:24:36.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 2287 LR: 0.0008842433062883426 Training loss: 0.0
2025-12-09 10:24:36.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 2288 LR: 0.0008841417617967617 Training loss: 0.0
2025-12-09 10:24:36.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 2289 LR: 0.0008840401786221159 Training loss: 0.0
2025-12-09 10:24:36.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 2290 LR: 0.0008839385567746348 Training loss: 0.0
2025-12-09 10:24:36.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 2291 LR: 0.0008838368962645513 Training loss: 0.0
2025-12-09 10:24:36.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 2292 LR: 0.000883735197102103 Training loss: 0.0
2025-12-09 10:24:36.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 2293 LR: 0.0008836334592975309 Training loss: 0.0
2025-12-09 10:24:36.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 2294 LR: 0.00088353168286108 Training loss: 0.0
2025-12-09 10:24:36.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 2295 LR: 0.0008834298678029989 Training loss: 0.0
2025-12-09 10:24:36.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 2296 LR: 0.0008833280141335406 Training loss: 0.0
2025-12-09 10:24:36.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 2297 LR: 0.0008832261218629621 Training loss: 0.0
2025-12-09 10:24:36.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 2298 LR: 0.0008831241910015233 Training loss: 0.0
2025-12-09 10:24:36.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 2299 LR: 0.000883022221559489 Training loss: 0.0
2025-12-09 10:24:36.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 2300 LR: 0.0008829202135471276 Training loss: 0.0
2025-12-09 10:24:36.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 2301 LR: 0.000882818166974711 Training loss: 0.0
2025-12-09 10:24:36.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 2302 LR: 0.0008827160818525156 Training loss: 0.0
2025-12-09 10:24:36.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 2303 LR: 0.0008826139581908211 Training loss: 0.0
2025-12-09 10:24:36.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 2304 LR: 0.0008825117959999116 Training loss: 0.0
2025-12-09 10:24:36.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 2305 LR: 0.0008824095952900746 Training loss: 0.0
2025-12-09 10:24:36.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 2306 LR: 0.0008823073560716019 Training loss: 0.0
2025-12-09 10:24:36.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 2307 LR: 0.000882205078354789 Training loss: 0.0
2025-12-09 10:24:36.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 2308 LR: 0.000882102762149935 Training loss: 0.0
2025-12-09 10:24:36.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 2309 LR: 0.0008820004074673434 Training loss: 0.0
2025-12-09 10:24:36.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 2310 LR: 0.0008818980143173212 Training loss: 0.0
2025-12-09 10:24:36.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 2311 LR: 0.0008817955827101794 Training loss: 0.0
2025-12-09 10:24:36.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 2312 LR: 0.0008816931126562328 Training loss: 0.0
2025-12-09 10:24:36.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 2313 LR: 0.0008815906041658002 Training loss: 0.0
2025-12-09 10:24:36.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 2314 LR: 0.0008814880572492043 Training loss: 0.0
2025-12-09 10:24:36.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 2315 LR: 0.0008813854719167713 Training loss: 0.0
2025-12-09 10:24:36.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 2316 LR: 0.000881282848178832 Training loss: 0.0
2025-12-09 10:24:36.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 2317 LR: 0.00088118018604572 Training loss: 0.0
2025-12-09 10:24:36.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 2318 LR: 0.0008810774855277739 Training loss: 0.0
2025-12-09 10:24:36.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 2319 LR: 0.0008809747466353355 Training loss: 0.0
2025-12-09 10:24:36.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 2320 LR: 0.0008808719693787503 Training loss: 0.0
2025-12-09 10:24:36.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 2321 LR: 0.0008807691537683684 Training loss: 0.0
2025-12-09 10:24:36.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 2322 LR: 0.0008806662998145431 Training loss: 0.0
2025-12-09 10:24:36.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 2323 LR: 0.0008805634075276318 Training loss: 0.0
2025-12-09 10:24:36.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 2324 LR: 0.0008804604769179958 Training loss: 0.0
2025-12-09 10:24:36.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 2325 LR: 0.000880357507996 Training loss: 0.0
2025-12-09 10:24:36.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 2326 LR: 0.0008802545007720137 Training loss: 0.0
2025-12-09 10:24:36.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 2327 LR: 0.0008801514552564096 Training loss: 0.0
2025-12-09 10:24:36.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 2328 LR: 0.0008800483714595644 Training loss: 0.0
2025-12-09 10:24:36.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 2329 LR: 0.0008799452493918585 Training loss: 0.0
2025-12-09 10:24:36.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 2330 LR: 0.0008798420890636765 Training loss: 0.0
2025-12-09 10:24:36.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 2331 LR: 0.0008797388904854064 Training loss: 0.0
2025-12-09 10:24:36.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 2332 LR: 0.0008796356536674404 Training loss: 0.0
2025-12-09 10:24:36.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 2333 LR: 0.0008795323786201745 Training loss: 0.0
2025-12-09 10:24:36.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 2334 LR: 0.0008794290653540085 Training loss: 0.0
2025-12-09 10:24:36.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 2335 LR: 0.000879325713879346 Training loss: 0.0
2025-12-09 10:24:36.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 2336 LR: 0.0008792223242065944 Training loss: 0.0
2025-12-09 10:24:36.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 2337 LR: 0.0008791188963461653 Training loss: 0.0
2025-12-09 10:24:36.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 2338 LR: 0.0008790154303084737 Training loss: 0.0
2025-12-09 10:24:36.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 2339 LR: 0.0008789119261039385 Training loss: 0.0
2025-12-09 10:24:36.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 2340 LR: 0.0008788083837429827 Training loss: 0.0
2025-12-09 10:24:36.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 2341 LR: 0.000878704803236033 Training loss: 0.0
2025-12-09 10:24:36.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 2342 LR: 0.0008786011845935202 Training loss: 0.0
2025-12-09 10:24:36.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 2343 LR: 0.0008784975278258782 Training loss: 0.0
2025-12-09 10:24:36.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 2344 LR: 0.0008783938329435457 Training loss: 0.0
2025-12-09 10:24:36.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 2345 LR: 0.0008782900999569645 Training loss: 0.0
2025-12-09 10:24:36.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 2346 LR: 0.0008781863288765806 Training loss: 0.0
2025-12-09 10:24:36.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 2347 LR: 0.0008780825197128437 Training loss: 0.0
2025-12-09 10:24:36.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 2348 LR: 0.0008779786724762075 Training loss: 0.0
2025-12-09 10:24:36.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 2349 LR: 0.0008778747871771292 Training loss: 0.0
2025-12-09 10:24:36.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 2350 LR: 0.0008777708638260702 Training loss: 0.0
2025-12-09 10:24:36.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 2351 LR: 0.0008776669024334956 Training loss: 0.0
2025-12-09 10:24:36.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 2352 LR: 0.0008775629030098741 Training loss: 0.0
2025-12-09 10:24:36.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 2353 LR: 0.0008774588655656788 Training loss: 0.0
2025-12-09 10:24:36.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 2354 LR: 0.000877354790111386 Training loss: 0.0
2025-12-09 10:24:36.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 2355 LR: 0.0008772506766574761 Training loss: 0.0
2025-12-09 10:24:36.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 2356 LR: 0.0008771465252144334 Training loss: 0.0
2025-12-09 10:24:36.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 2357 LR: 0.0008770423357927461 Training loss: 0.0
2025-12-09 10:24:36.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 2358 LR: 0.0008769381084029058 Training loss: 0.0
2025-12-09 10:24:36.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 2359 LR: 0.0008768338430554083 Training loss: 0.0
2025-12-09 10:24:36.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 2360 LR: 0.0008767295397607529 Training loss: 0.0
2025-12-09 10:24:36.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 2361 LR: 0.0008766251985294434 Training loss: 0.0
2025-12-09 10:24:36.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 2362 LR: 0.0008765208193719867 Training loss: 0.0
2025-12-09 10:24:36.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 2363 LR: 0.0008764164022988937 Training loss: 0.0
2025-12-09 10:24:36.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 2364 LR: 0.0008763119473206794 Training loss: 0.0
2025-12-09 10:24:36.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 2365 LR: 0.0008762074544478622 Training loss: 0.0
2025-12-09 10:24:36.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 2366 LR: 0.0008761029236909647 Training loss: 0.0
2025-12-09 10:24:36.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 2367 LR: 0.000875998355060513 Training loss: 0.0
2025-12-09 10:24:36.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 2368 LR: 0.0008758937485670373 Training loss: 0.0
2025-12-09 10:24:36.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 2369 LR: 0.0008757891042210713 Training loss: 0.0
2025-12-09 10:24:36.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 2370 LR: 0.000875684422033153 Training loss: 0.0
2025-12-09 10:24:36.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 2371 LR: 0.0008755797020138234 Training loss: 0.0
2025-12-09 10:24:36.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 2372 LR: 0.0008754749441736283 Training loss: 0.0
2025-12-09 10:24:36.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 2373 LR: 0.0008753701485231164 Training loss: 0.0
2025-12-09 10:24:36.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 2374 LR: 0.0008752653150728412 Training loss: 0.0
2025-12-09 10:24:36.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 2375 LR: 0.0008751604438333587 Training loss: 0.0
2025-12-09 10:24:36.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 2376 LR: 0.0008750555348152298 Training loss: 0.0
2025-12-09 10:24:36.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 2377 LR: 0.0008749505880290188 Training loss: 0.0
2025-12-09 10:24:36.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 2378 LR: 0.0008748456034852939 Training loss: 0.0
2025-12-09 10:24:36.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 2379 LR: 0.0008747405811946271 Training loss: 0.0
2025-12-09 10:24:36.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 2380 LR: 0.0008746355211675938 Training loss: 0.0
2025-12-09 10:24:36.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 2381 LR: 0.0008745304234147739 Training loss: 0.0
2025-12-09 10:24:36.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 2382 LR: 0.0008744252879467507 Training loss: 0.0
2025-12-09 10:24:36.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 2383 LR: 0.0008743201147741112 Training loss: 0.0
2025-12-09 10:24:36.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 2384 LR: 0.0008742149039074463 Training loss: 0.0
2025-12-09 10:24:36.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 2385 LR: 0.0008741096553573506 Training loss: 0.0
2025-12-09 10:24:36.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 2386 LR: 0.0008740043691344233 Training loss: 0.0
2025-12-09 10:24:36.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 2387 LR: 0.000873899045249266 Training loss: 0.0
2025-12-09 10:24:36.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 2388 LR: 0.0008737936837124852 Training loss: 0.0
2025-12-09 10:24:36.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 2389 LR: 0.0008736882845346905 Training loss: 0.0
2025-12-09 10:24:36.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 2390 LR: 0.0008735828477264959 Training loss: 0.0
2025-12-09 10:24:36.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 2391 LR: 0.0008734773732985186 Training loss: 0.0
2025-12-09 10:24:36.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 2392 LR: 0.0008733718612613802 Training loss: 0.0
2025-12-09 10:24:36.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 2393 LR: 0.0008732663116257055 Training loss: 0.0
2025-12-09 10:24:36.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 2394 LR: 0.0008731607244021236 Training loss: 0.0
2025-12-09 10:24:36.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 2395 LR: 0.0008730550996012668 Training loss: 0.0
2025-12-09 10:24:36.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 2396 LR: 0.0008729494372337716 Training loss: 0.0
2025-12-09 10:24:36.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 2397 LR: 0.0008728437373102785 Training loss: 0.0
2025-12-09 10:24:36.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 2398 LR: 0.0008727379998414311 Training loss: 0.0
2025-12-09 10:24:36.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 2399 LR: 0.0008726322248378774 Training loss: 0.0
2025-12-09 10:24:36.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 2400 LR: 0.0008725264123102687 Training loss: 0.0
2025-12-09 10:24:36.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 2401 LR: 0.0008724205622692607 Training loss: 0.0
2025-12-09 10:24:36.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 2402 LR: 0.0008723146747255122 Training loss: 0.0
2025-12-09 10:24:36.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 2403 LR: 0.000872208749689686 Training loss: 0.0
2025-12-09 10:24:36.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 2404 LR: 0.000872102787172449 Training loss: 0.0
2025-12-09 10:24:36.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 2405 LR: 0.0008719967871844715 Training loss: 0.0
2025-12-09 10:24:36.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 2406 LR: 0.0008718907497364277 Training loss: 0.0
2025-12-09 10:24:36.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 2407 LR: 0.0008717846748389956 Training loss: 0.0
2025-12-09 10:24:36.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 2408 LR: 0.000871678562502857 Training loss: 0.0
2025-12-09 10:24:36.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 2409 LR: 0.0008715724127386971 Training loss: 0.0
2025-12-09 10:24:36.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 2410 LR: 0.0008714662255572056 Training loss: 0.0
2025-12-09 10:24:36.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 2411 LR: 0.0008713600009690752 Training loss: 0.0
2025-12-09 10:24:36.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 2412 LR: 0.0008712537389850031 Training loss: 0.0
2025-12-09 10:24:36.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 2413 LR: 0.0008711474396156893 Training loss: 0.0
2025-12-09 10:24:36.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 2414 LR: 0.0008710411028718388 Training loss: 0.0
2025-12-09 10:24:36.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 2415 LR: 0.0008709347287641592 Training loss: 0.0
2025-12-09 10:24:36.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 2416 LR: 0.0008708283173033627 Training loss: 0.0
2025-12-09 10:24:36.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 2417 LR: 0.0008707218685001647 Training loss: 0.0
2025-12-09 10:24:36.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 2418 LR: 0.0008706153823652847 Training loss: 0.0
2025-12-09 10:24:36.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 2419 LR: 0.0008705088589094458 Training loss: 0.0
2025-12-09 10:24:36.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 2420 LR: 0.000870402298143375 Training loss: 0.0
2025-12-09 10:24:36.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 2421 LR: 0.0008702957000778029 Training loss: 0.0
2025-12-09 10:24:36.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 2422 LR: 0.0008701890647234641 Training loss: 0.0
2025-12-09 10:24:36.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 2423 LR: 0.0008700823920910963 Training loss: 0.0
2025-12-09 10:24:36.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 2424 LR: 0.0008699756821914419 Training loss: 0.0
2025-12-09 10:24:36.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 2425 LR: 0.0008698689350352465 Training loss: 0.0
2025-12-09 10:24:36.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 2426 LR: 0.0008697621506332594 Training loss: 0.0
2025-12-09 10:24:36.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 2427 LR: 0.0008696553289962338 Training loss: 0.0
2025-12-09 10:24:36.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 2428 LR: 0.0008695484701349268 Training loss: 0.0
2025-12-09 10:24:36.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 2429 LR: 0.0008694415740600988 Training loss: 0.0
2025-12-09 10:24:36.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 2430 LR: 0.0008693346407825144 Training loss: 0.0
2025-12-09 10:24:36.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 2431 LR: 0.0008692276703129421 Training loss: 0.0
2025-12-09 10:24:36.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 2432 LR: 0.000869120662662153 Training loss: 0.0
2025-12-09 10:24:36.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 2433 LR: 0.0008690136178409236 Training loss: 0.0
2025-12-09 10:24:36.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 2434 LR: 0.000868906535860033 Training loss: 0.0
2025-12-09 10:24:36.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 2435 LR: 0.0008687994167302642 Training loss: 0.0
2025-12-09 10:24:36.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 2436 LR: 0.0008686922604624044 Training loss: 0.0
2025-12-09 10:24:36.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 2437 LR: 0.0008685850670672439 Training loss: 0.0
2025-12-09 10:24:36.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 2438 LR: 0.0008684778365555772 Training loss: 0.0
2025-12-09 10:24:36.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 2439 LR: 0.0008683705689382025 Training loss: 0.0
2025-12-09 10:24:36.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 2440 LR: 0.0008682632642259216 Training loss: 0.0
2025-12-09 10:24:36.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 2441 LR: 0.0008681559224295401 Training loss: 0.0
2025-12-09 10:24:36.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 2442 LR: 0.0008680485435598673 Training loss: 0.0
2025-12-09 10:24:36.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 2443 LR: 0.000867941127627716 Training loss: 0.0
2025-12-09 10:24:36.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 2444 LR: 0.0008678336746439035 Training loss: 0.0
2025-12-09 10:24:36.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 2445 LR: 0.0008677261846192499 Training loss: 0.0
2025-12-09 10:24:36.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 2446 LR: 0.0008676186575645796 Training loss: 0.0
2025-12-09 10:24:36.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 2447 LR: 0.0008675110934907205 Training loss: 0.0
2025-12-09 10:24:36.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 2448 LR: 0.0008674034924085044 Training loss: 0.0
2025-12-09 10:24:36.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 2449 LR: 0.0008672958543287666 Training loss: 0.0
2025-12-09 10:24:36.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 2450 LR: 0.0008671881792623464 Training loss: 0.0
2025-12-09 10:24:36.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 2451 LR: 0.0008670804672200865 Training loss: 0.0
2025-12-09 10:24:36.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 2452 LR: 0.0008669727182128337 Training loss: 0.0
2025-12-09 10:24:36.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 2453 LR: 0.0008668649322514381 Training loss: 0.0
2025-12-09 10:24:36.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 2454 LR: 0.0008667571093467541 Training loss: 0.0
2025-12-09 10:24:36.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 2455 LR: 0.000866649249509639 Training loss: 0.0
2025-12-09 10:24:36.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 2456 LR: 0.0008665413527509546 Training loss: 0.0
2025-12-09 10:24:36.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 2457 LR: 0.0008664334190815659 Training loss: 0.0
2025-12-09 10:24:36.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 2458 LR: 0.000866325448512342 Training loss: 0.0
2025-12-09 10:24:36.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 2459 LR: 0.0008662174410541554 Training loss: 0.0
2025-12-09 10:24:36.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 2460 LR: 0.0008661093967178826 Training loss: 0.0
2025-12-09 10:24:36.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 2461 LR: 0.0008660013155144035 Training loss: 0.0
2025-12-09 10:24:36.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 2462 LR: 0.000865893197454602 Training loss: 0.0
2025-12-09 10:24:36.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 2463 LR: 0.0008657850425493655 Training loss: 0.0
2025-12-09 10:24:36.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 2464 LR: 0.0008656768508095852 Training loss: 0.0
2025-12-09 10:24:36.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 2465 LR: 0.0008655686222461561 Training loss: 0.0
2025-12-09 10:24:36.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 2466 LR: 0.0008654603568699767 Training loss: 0.0
2025-12-09 10:24:36.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 2467 LR: 0.0008653520546919493 Training loss: 0.0
2025-12-09 10:24:36.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 2468 LR: 0.0008652437157229801 Training loss: 0.0
2025-12-09 10:24:36.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 2469 LR: 0.0008651353399739787 Training loss: 0.0
2025-12-09 10:24:36.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 2470 LR: 0.0008650269274558585 Training loss: 0.0
2025-12-09 10:24:36.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 2471 LR: 0.0008649184781795368 Training loss: 0.0
2025-12-09 10:24:36.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 2472 LR: 0.0008648099921559341 Training loss: 0.0
2025-12-09 10:24:36.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 2473 LR: 0.0008647014693959754 Training loss: 0.0
2025-12-09 10:24:36.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 2474 LR: 0.0008645929099105886 Training loss: 0.0
2025-12-09 10:24:36.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 2475 LR: 0.0008644843137107057 Training loss: 0.0
2025-12-09 10:24:36.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 2476 LR: 0.0008643756808072625 Training loss: 0.0
2025-12-09 10:24:36.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 2477 LR: 0.0008642670112111983 Training loss: 0.0
2025-12-09 10:24:36.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 2478 LR: 0.0008641583049334558 Training loss: 0.0
2025-12-09 10:24:36.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 2479 LR: 0.0008640495619849821 Training loss: 0.0
2025-12-09 10:24:36.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 2480 LR: 0.0008639407823767274 Training loss: 0.0
2025-12-09 10:24:36.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 2481 LR: 0.0008638319661196459 Training loss: 0.0
2025-12-09 10:24:36.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 2482 LR: 0.0008637231132246954 Training loss: 0.0
2025-12-09 10:24:36.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 2483 LR: 0.0008636142237028372 Training loss: 0.0
2025-12-09 10:24:36.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 2484 LR: 0.0008635052975650369 Training loss: 0.0
2025-12-09 10:24:36.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 2485 LR: 0.0008633963348222629 Training loss: 0.0
2025-12-09 10:24:36.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 2486 LR: 0.000863287335485488 Training loss: 0.0
2025-12-09 10:24:36.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 2487 LR: 0.0008631782995656883 Training loss: 0.0
2025-12-09 10:24:36.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 2488 LR: 0.0008630692270738438 Training loss: 0.0
2025-12-09 10:24:36.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 2489 LR: 0.0008629601180209381 Training loss: 0.0
2025-12-09 10:24:36.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 2490 LR: 0.0008628509724179583 Training loss: 0.0
2025-12-09 10:24:36.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 2491 LR: 0.0008627417902758956 Training loss: 0.0
2025-12-09 10:24:36.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 2492 LR: 0.0008626325716057446 Training loss: 0.0
2025-12-09 10:24:36.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 2493 LR: 0.0008625233164185035 Training loss: 0.0
2025-12-09 10:24:36.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 2494 LR: 0.0008624140247251744 Training loss: 0.0
2025-12-09 10:24:36.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 2495 LR: 0.0008623046965367629 Training loss: 0.0
2025-12-09 10:24:36.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 2496 LR: 0.0008621953318642783 Training loss: 0.0
2025-12-09 10:24:36.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 2497 LR: 0.0008620859307187339 Training loss: 0.0
2025-12-09 10:24:36.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 2498 LR: 0.0008619764931111459 Training loss: 0.0
2025-12-09 10:24:36.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 2499 LR: 0.000861867019052535 Training loss: 0.0
2025-12-09 10:24:36.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 2500 LR: 0.0008617575085539253 Training loss: 0.0
2025-12-09 10:24:36.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 2501 LR: 0.0008616479616263444 Training loss: 0.0
2025-12-09 10:24:36.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 2502 LR: 0.0008615383782808237 Training loss: 0.0
2025-12-09 10:24:36.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 2503 LR: 0.0008614287585283981 Training loss: 0.0
2025-12-09 10:24:36.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 2504 LR: 0.0008613191023801064 Training loss: 0.0
2025-12-09 10:24:36.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 2505 LR: 0.0008612094098469909 Training loss: 0.0
2025-12-09 10:24:36.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 2506 LR: 0.000861099680940098 Training loss: 0.0
2025-12-09 10:24:36.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 2507 LR: 0.0008609899156704768 Training loss: 0.0
2025-12-09 10:24:36.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 2508 LR: 0.0008608801140491811 Training loss: 0.0
2025-12-09 10:24:36.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 2509 LR: 0.0008607702760872678 Training loss: 0.0
2025-12-09 10:24:36.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 2510 LR: 0.0008606604017957976 Training loss: 0.0
2025-12-09 10:24:36.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 2511 LR: 0.0008605504911858347 Training loss: 0.0
2025-12-09 10:24:36.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 2512 LR: 0.0008604405442684473 Training loss: 0.0
2025-12-09 10:24:36.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 2513 LR: 0.000860330561054707 Training loss: 0.0
2025-12-09 10:24:36.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 2514 LR: 0.0008602205415556888 Training loss: 0.0
2025-12-09 10:24:36.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 2515 LR: 0.0008601104857824722 Training loss: 0.0
2025-12-09 10:24:36.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 2516 LR: 0.0008600003937461394 Training loss: 0.0
2025-12-09 10:24:36.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 2517 LR: 0.0008598902654577768 Training loss: 0.0
2025-12-09 10:24:36.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 2518 LR: 0.0008597801009284743 Training loss: 0.0
2025-12-09 10:24:36.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 2519 LR: 0.0008596699001693256 Training loss: 0.0
2025-12-09 10:24:36.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 2520 LR: 0.0008595596631914277 Training loss: 0.0
2025-12-09 10:24:36.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 2521 LR: 0.0008594493900058816 Training loss: 0.0
2025-12-09 10:24:36.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 2522 LR: 0.0008593390806237917 Training loss: 0.0
2025-12-09 10:24:36.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 2523 LR: 0.0008592287350562663 Training loss: 0.0
2025-12-09 10:24:36.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 2524 LR: 0.0008591183533144171 Training loss: 0.0
2025-12-09 10:24:36.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 2525 LR: 0.0008590079354093594 Training loss: 0.0
2025-12-09 10:24:36.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 2526 LR: 0.0008588974813522126 Training loss: 0.0
2025-12-09 10:24:36.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 2527 LR: 0.0008587869911540992 Training loss: 0.0
2025-12-09 10:24:36.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 2528 LR: 0.0008586764648261456 Training loss: 0.0
2025-12-09 10:24:36.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 2529 LR: 0.0008585659023794818 Training loss: 0.0
2025-12-09 10:24:36.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 2530 LR: 0.0008584553038252414 Training loss: 0.0
2025-12-09 10:24:36.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 2531 LR: 0.0008583446691745618 Training loss: 0.0
2025-12-09 10:24:36.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 2532 LR: 0.0008582339984385838 Training loss: 0.0
2025-12-09 10:24:36.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 2533 LR: 0.0008581232916284518 Training loss: 0.0
2025-12-09 10:24:36.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 2534 LR: 0.0008580125487553143 Training loss: 0.0
2025-12-09 10:24:36.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 2535 LR: 0.0008579017698303229 Training loss: 0.0
2025-12-09 10:24:36.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 2536 LR: 0.0008577909548646331 Training loss: 0.0
2025-12-09 10:24:36.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 2537 LR: 0.000857680103869404 Training loss: 0.0
2025-12-09 10:24:36.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 2538 LR: 0.000857569216855798 Training loss: 0.0
2025-12-09 10:24:36.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 2539 LR: 0.0008574582938349817 Training loss: 0.0
2025-12-09 10:24:36.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 2540 LR: 0.0008573473348181251 Training loss: 0.0
2025-12-09 10:24:36.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 2541 LR: 0.0008572363398164017 Training loss: 0.0
2025-12-09 10:24:36.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 2542 LR: 0.0008571253088409886 Training loss: 0.0
2025-12-09 10:24:36.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 2543 LR: 0.0008570142419030666 Training loss: 0.0
2025-12-09 10:24:36.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 2544 LR: 0.0008569031390138202 Training loss: 0.0
2025-12-09 10:24:36.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 2545 LR: 0.0008567920001844376 Training loss: 0.0
2025-12-09 10:24:36.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 2546 LR: 0.0008566808254261102 Training loss: 0.0
2025-12-09 10:24:36.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 2547 LR: 0.0008565696147500337 Training loss: 0.0
2025-12-09 10:24:36.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 2548 LR: 0.0008564583681674065 Training loss: 0.0
2025-12-09 10:24:36.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 2549 LR: 0.0008563470856894315 Training loss: 0.0
2025-12-09 10:24:36.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 2550 LR: 0.0008562357673273146 Training loss: 0.0
2025-12-09 10:24:36.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 2551 LR: 0.0008561244130922658 Training loss: 0.0
2025-12-09 10:24:36.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 2552 LR: 0.0008560130229954983 Training loss: 0.0
2025-12-09 10:24:36.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 2553 LR: 0.0008559015970482292 Training loss: 0.0
2025-12-09 10:24:36.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 2554 LR: 0.0008557901352616789 Training loss: 0.0
2025-12-09 10:24:36.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 2555 LR: 0.0008556786376470717 Training loss: 0.0
2025-12-09 10:24:36.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 2556 LR: 0.0008555671042156355 Training loss: 0.0
2025-12-09 10:24:36.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 2557 LR: 0.0008554555349786015 Training loss: 0.0
2025-12-09 10:24:36.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 2558 LR: 0.000855343929947205 Training loss: 0.0
2025-12-09 10:24:36.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 2559 LR: 0.0008552322891326845 Training loss: 0.0
2025-12-09 10:24:36.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 2560 LR: 0.000855120612546282 Training loss: 0.0
2025-12-09 10:24:36.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 2561 LR: 0.0008550089001992437 Training loss: 0.0
2025-12-09 10:24:36.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 2562 LR: 0.0008548971521028188 Training loss: 0.0
2025-12-09 10:24:36.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 2563 LR: 0.0008547853682682604 Training loss: 0.0
2025-12-09 10:24:36.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 2564 LR: 0.0008546735487068252 Training loss: 0.0
2025-12-09 10:24:36.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 2565 LR: 0.0008545616934297733 Training loss: 0.0
2025-12-09 10:24:36.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 2566 LR: 0.0008544498024483687 Training loss: 0.0
2025-12-09 10:24:36.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 2567 LR: 0.0008543378757738785 Training loss: 0.0
2025-12-09 10:24:36.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 2568 LR: 0.0008542259134175739 Training loss: 0.0
2025-12-09 10:24:36.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 2569 LR: 0.0008541139153907296 Training loss: 0.0
2025-12-09 10:24:36.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 2570 LR: 0.0008540018817046238 Training loss: 0.0
2025-12-09 10:24:36.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 2571 LR: 0.000853889812370538 Training loss: 0.0
2025-12-09 10:24:36.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 2572 LR: 0.0008537777073997579 Training loss: 0.0
2025-12-09 10:24:36.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 2573 LR: 0.0008536655668035723 Training loss: 0.0
2025-12-09 10:24:36.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 2574 LR: 0.0008535533905932737 Training loss: 0.0
2025-12-09 10:24:36.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 2575 LR: 0.0008534411787801586 Training loss: 0.0
2025-12-09 10:24:36.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 2576 LR: 0.0008533289313755263 Training loss: 0.0
2025-12-09 10:24:36.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 2577 LR: 0.0008532166483906803 Training loss: 0.0
2025-12-09 10:24:36.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 2578 LR: 0.0008531043298369274 Training loss: 0.0
2025-12-09 10:24:36.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 2579 LR: 0.0008529919757255782 Training loss: 0.0
2025-12-09 10:24:36.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 2580 LR: 0.0008528795860679468 Training loss: 0.0
2025-12-09 10:24:36.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 2581 LR: 0.0008527671608753506 Training loss: 0.0
2025-12-09 10:24:36.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 2582 LR: 0.0008526547001591109 Training loss: 0.0
2025-12-09 10:24:36.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 2583 LR: 0.0008525422039305529 Training loss: 0.0
2025-12-09 10:24:36.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 2584 LR: 0.0008524296722010042 Training loss: 0.0
2025-12-09 10:24:36.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 2585 LR: 0.0008523171049817973 Training loss: 0.0
2025-12-09 10:24:36.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 2586 LR: 0.0008522045022842676 Training loss: 0.0
2025-12-09 10:24:36.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 2587 LR: 0.0008520918641197542 Training loss: 0.0
2025-12-09 10:24:36.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 2588 LR: 0.0008519791904995996 Training loss: 0.0
2025-12-09 10:24:36.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 2589 LR: 0.0008518664814351503 Training loss: 0.0
2025-12-09 10:24:36.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 2590 LR: 0.0008517537369377557 Training loss: 0.0
2025-12-09 10:24:36.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 2591 LR: 0.0008516409570187696 Training loss: 0.0
2025-12-09 10:24:36.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 2592 LR: 0.0008515281416895488 Training loss: 0.0
2025-12-09 10:24:36.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 2593 LR: 0.0008514152909614536 Training loss: 0.0
2025-12-09 10:24:36.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 2594 LR: 0.0008513024048458484 Training loss: 0.0
2025-12-09 10:24:36.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 2595 LR: 0.0008511894833541005 Training loss: 0.0
2025-12-09 10:24:36.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 2596 LR: 0.0008510765264975813 Training loss: 0.0
2025-12-09 10:24:36.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 2597 LR: 0.0008509635342876654 Training loss: 0.0
2025-12-09 10:24:36.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 2598 LR: 0.0008508505067357313 Training loss: 0.0
2025-12-09 10:24:36.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 2599 LR: 0.0008507374438531607 Training loss: 0.0
2025-12-09 10:24:36.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 2600 LR: 0.0008506243456513391 Training loss: 0.0
2025-12-09 10:24:36.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 2601 LR: 0.0008505112121416553 Training loss: 0.0
2025-12-09 10:24:36.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 2602 LR: 0.0008503980433355024 Training loss: 0.0
2025-12-09 10:24:36.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 2603 LR: 0.0008502848392442759 Training loss: 0.0
2025-12-09 10:24:36.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 2604 LR: 0.0008501715998793757 Training loss: 0.0
2025-12-09 10:24:36.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 2605 LR: 0.0008500583252522052 Training loss: 0.0
2025-12-09 10:24:36.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 2606 LR: 0.0008499450153741705 Training loss: 0.0
2025-12-09 10:24:36.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 2607 LR: 0.0008498316702566827 Training loss: 0.0
2025-12-09 10:24:36.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 2608 LR: 0.000849718289911155 Training loss: 0.0
2025-12-09 10:24:36.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 2609 LR: 0.0008496048743490053 Training loss: 0.0
2025-12-09 10:24:36.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 2610 LR: 0.0008494914235816542 Training loss: 0.0
2025-12-09 10:24:36.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 2611 LR: 0.0008493779376205264 Training loss: 0.0
2025-12-09 10:24:36.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 2612 LR: 0.0008492644164770498 Training loss: 0.0
2025-12-09 10:24:36.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 2613 LR: 0.0008491508601626561 Training loss: 0.0
2025-12-09 10:24:36.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 2614 LR: 0.0008490372686887802 Training loss: 0.0
2025-12-09 10:24:36.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 2615 LR: 0.0008489236420668609 Training loss: 0.0
2025-12-09 10:24:36.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 2616 LR: 0.0008488099803083404 Training loss: 0.0
2025-12-09 10:24:36.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 2617 LR: 0.0008486962834246645 Training loss: 0.0
2025-12-09 10:24:36.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 2618 LR: 0.0008485825514272824 Training loss: 0.0
2025-12-09 10:24:36.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 2619 LR: 0.0008484687843276469 Training loss: 0.0
2025-12-09 10:24:36.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 2620 LR: 0.0008483549821372142 Training loss: 0.0
2025-12-09 10:24:36.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 2621 LR: 0.0008482411448674446 Training loss: 0.0
2025-12-09 10:24:36.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 2622 LR: 0.0008481272725298009 Training loss: 0.0
2025-12-09 10:24:36.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 2623 LR: 0.0008480133651357505 Training loss: 0.0
2025-12-09 10:24:36.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 2624 LR: 0.0008478994226967638 Training loss: 0.0
2025-12-09 10:24:36.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 2625 LR: 0.0008477854452243148 Training loss: 0.0
2025-12-09 10:24:36.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 2626 LR: 0.0008476714327298809 Training loss: 0.0
2025-12-09 10:24:36.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 2627 LR: 0.0008475573852249434 Training loss: 0.0
2025-12-09 10:24:36.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 2628 LR: 0.0008474433027209865 Training loss: 0.0
2025-12-09 10:24:36.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 2629 LR: 0.0008473291852294987 Training loss: 0.0
2025-12-09 10:24:36.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 2630 LR: 0.0008472150327619714 Training loss: 0.0
2025-12-09 10:24:36.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 2631 LR: 0.0008471008453298998 Training loss: 0.0
2025-12-09 10:24:36.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 2632 LR: 0.0008469866229447824 Training loss: 0.0
2025-12-09 10:24:36.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 2633 LR: 0.0008468723656181219 Training loss: 0.0
2025-12-09 10:24:36.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 2634 LR: 0.0008467580733614232 Training loss: 0.0
2025-12-09 10:24:36.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 2635 LR: 0.0008466437461861964 Training loss: 0.0
2025-12-09 10:24:36.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 2636 LR: 0.0008465293841039539 Training loss: 0.0
2025-12-09 10:24:36.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 2637 LR: 0.0008464149871262117 Training loss: 0.0
2025-12-09 10:24:36.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 2638 LR: 0.0008463005552644898 Training loss: 0.0
2025-12-09 10:24:36.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 2639 LR: 0.0008461860885303114 Training loss: 0.0
2025-12-09 10:24:36.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 2640 LR: 0.0008460715869352035 Training loss: 0.0
2025-12-09 10:24:36.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 2641 LR: 0.0008459570504906962 Training loss: 0.0
2025-12-09 10:24:36.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 2642 LR: 0.0008458424792083233 Training loss: 0.0
2025-12-09 10:24:36.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 2643 LR: 0.0008457278730996223 Training loss: 0.0
2025-12-09 10:24:36.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 2644 LR: 0.0008456132321761338 Training loss: 0.0
2025-12-09 10:24:36.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 2645 LR: 0.0008454985564494025 Training loss: 0.0
2025-12-09 10:24:36.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 2646 LR: 0.000845383845930976 Training loss: 0.0
2025-12-09 10:24:36.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 2647 LR: 0.0008452691006324055 Training loss: 0.0
2025-12-09 10:24:36.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 2648 LR: 0.0008451543205652461 Training loss: 0.0
2025-12-09 10:24:36.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 2649 LR: 0.000845039505741056 Training loss: 0.0
2025-12-09 10:24:36.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 2650 LR: 0.0008449246561713972 Training loss: 0.0
2025-12-09 10:24:36.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 2651 LR: 0.0008448097718678349 Training loss: 0.0
2025-12-09 10:24:36.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 2652 LR: 0.000844694852841938 Training loss: 0.0
2025-12-09 10:24:36.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 2653 LR: 0.000844579899105279 Training loss: 0.0
2025-12-09 10:24:36.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 2654 LR: 0.0008444649106694334 Training loss: 0.0
2025-12-09 10:24:36.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 2655 LR: 0.0008443498875459808 Training loss: 0.0
2025-12-09 10:24:36.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 2656 LR: 0.000844234829746504 Training loss: 0.0
2025-12-09 10:24:36.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 2657 LR: 0.0008441197372825892 Training loss: 0.0
2025-12-09 10:24:36.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 2658 LR: 0.0008440046101658263 Training loss: 0.0
2025-12-09 10:24:36.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 2659 LR: 0.0008438894484078086 Training loss: 0.0
2025-12-09 10:24:36.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 2660 LR: 0.0008437742520201327 Training loss: 0.0
2025-12-09 10:24:36.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 2661 LR: 0.0008436590210143991 Training loss: 0.0
2025-12-09 10:24:36.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 2662 LR: 0.0008435437554022115 Training loss: 0.0
2025-12-09 10:24:36.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 2663 LR: 0.0008434284551951771 Training loss: 0.0
2025-12-09 10:24:36.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 2664 LR: 0.0008433131204049067 Training loss: 0.0
2025-12-09 10:24:36.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 2665 LR: 0.0008431977510430145 Training loss: 0.0
2025-12-09 10:24:36.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 2666 LR: 0.0008430823471211182 Training loss: 0.0
2025-12-09 10:24:36.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 2667 LR: 0.0008429669086508389 Training loss: 0.0
2025-12-09 10:24:36.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 2668 LR: 0.0008428514356438011 Training loss: 0.0
2025-12-09 10:24:36.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 2669 LR: 0.0008427359281116334 Training loss: 0.0
2025-12-09 10:24:36.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 2670 LR: 0.0008426203860659669 Training loss: 0.0
2025-12-09 10:24:36.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 2671 LR: 0.000842504809518437 Training loss: 0.0
2025-12-09 10:24:36.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 2672 LR: 0.0008423891984806822 Training loss: 0.0
2025-12-09 10:24:36.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 2673 LR: 0.0008422735529643444 Training loss: 0.0
2025-12-09 10:24:36.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 2674 LR: 0.0008421578729810691 Training loss: 0.0
2025-12-09 10:24:36.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 2675 LR: 0.0008420421585425055 Training loss: 0.0
2025-12-09 10:24:36.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 2676 LR: 0.0008419264096603059 Training loss: 0.0
2025-12-09 10:24:36.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 2677 LR: 0.000841810626346126 Training loss: 0.0
2025-12-09 10:24:36.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 2678 LR: 0.0008416948086116256 Training loss: 0.0
2025-12-09 10:24:36.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 2679 LR: 0.0008415789564684673 Training loss: 0.0
2025-12-09 10:24:36.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 2680 LR: 0.0008414630699283173 Training loss: 0.0
2025-12-09 10:24:36.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 2681 LR: 0.0008413471490028455 Training loss: 0.0
2025-12-09 10:24:36.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 2682 LR: 0.0008412311937037254 Training loss: 0.0
2025-12-09 10:24:36.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 2683 LR: 0.0008411152040426331 Training loss: 0.0
2025-12-09 10:24:36.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 2684 LR: 0.0008409991800312493 Training loss: 0.0
2025-12-09 10:24:36.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 2685 LR: 0.0008408831216812574 Training loss: 0.0
2025-12-09 10:24:36.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 2686 LR: 0.0008407670290043444 Training loss: 0.0
2025-12-09 10:24:36.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 2687 LR: 0.0008406509020122008 Training loss: 0.0
2025-12-09 10:24:36.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 2688 LR: 0.0008405347407165208 Training loss: 0.0
2025-12-09 10:24:36.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 2689 LR: 0.0008404185451290017 Training loss: 0.0
2025-12-09 10:24:36.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 2690 LR: 0.0008403023152613445 Training loss: 0.0
2025-12-09 10:24:36.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 2691 LR: 0.0008401860511252534 Training loss: 0.0
2025-12-09 10:24:36.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 2692 LR: 0.0008400697527324361 Training loss: 0.0
2025-12-09 10:24:36.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 2693 LR: 0.0008399534200946043 Training loss: 0.0
2025-12-09 10:24:36.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 2694 LR: 0.0008398370532234722 Training loss: 0.0
2025-12-09 10:24:36.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 2695 LR: 0.0008397206521307583 Training loss: 0.0
2025-12-09 10:24:36.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 2696 LR: 0.0008396042168281839 Training loss: 0.0
2025-12-09 10:24:36.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 2697 LR: 0.0008394877473274742 Training loss: 0.0
2025-12-09 10:24:36.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 2698 LR: 0.0008393712436403576 Training loss: 0.0
2025-12-09 10:24:36.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 2699 LR: 0.0008392547057785661 Training loss: 0.0
2025-12-09 10:24:36.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 2700 LR: 0.000839138133753835 Training loss: 0.0
2025-12-09 10:24:36.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 2701 LR: 0.000839021527577903 Training loss: 0.0
2025-12-09 10:24:36.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 2702 LR: 0.0008389048872625127 Training loss: 0.0
2025-12-09 10:24:36.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 2703 LR: 0.0008387882128194093 Training loss: 0.0
2025-12-09 10:24:36.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 2704 LR: 0.0008386715042603423 Training loss: 0.0
2025-12-09 10:24:36.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 2705 LR: 0.0008385547615970639 Training loss: 0.0
2025-12-09 10:24:36.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 2706 LR: 0.0008384379848413304 Training loss: 0.0
2025-12-09 10:24:36.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 2707 LR: 0.000838321174004901 Training loss: 0.0
2025-12-09 10:24:36.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 2708 LR: 0.0008382043290995387 Training loss: 0.0
2025-12-09 10:24:36.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 2709 LR: 0.0008380874501370098 Training loss: 0.0
2025-12-09 10:24:36.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 2710 LR: 0.0008379705371290838 Training loss: 0.0
2025-12-09 10:24:36.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 2711 LR: 0.0008378535900875339 Training loss: 0.0
2025-12-09 10:24:36.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 2712 LR: 0.000837736609024137 Training loss: 0.0
2025-12-09 10:24:36.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 2713 LR: 0.0008376195939506726 Training loss: 0.0
2025-12-09 10:24:36.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 2714 LR: 0.0008375025448789242 Training loss: 0.0
2025-12-09 10:24:36.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 2715 LR: 0.000837385461820679 Training loss: 0.0
2025-12-09 10:24:36.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 2716 LR: 0.000837268344787727 Training loss: 0.0
2025-12-09 10:24:36.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 2717 LR: 0.0008371511937918616 Training loss: 0.0
2025-12-09 10:24:36.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 2718 LR: 0.0008370340088448807 Training loss: 0.0
2025-12-09 10:24:36.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 2719 LR: 0.0008369167899585841 Training loss: 0.0
2025-12-09 10:24:36.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 2720 LR: 0.0008367995371447759 Training loss: 0.0
2025-12-09 10:24:36.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 2721 LR: 0.0008366822504152636 Training loss: 0.0
2025-12-09 10:24:36.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 2722 LR: 0.0008365649297818579 Training loss: 0.0
2025-12-09 10:24:36.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 2723 LR: 0.0008364475752563728 Training loss: 0.0
2025-12-09 10:24:36.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 2724 LR: 0.0008363301868506264 Training loss: 0.0
2025-12-09 10:24:36.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 2725 LR: 0.0008362127645764391 Training loss: 0.0
2025-12-09 10:24:36.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 2726 LR: 0.0008360953084456357 Training loss: 0.0
2025-12-09 10:24:36.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 2727 LR: 0.0008359778184700439 Training loss: 0.0
2025-12-09 10:24:36.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 2728 LR: 0.0008358602946614952 Training loss: 0.0
2025-12-09 10:24:36.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 2729 LR: 0.0008357427370318238 Training loss: 0.0
2025-12-09 10:24:36.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 2730 LR: 0.000835625145592868 Training loss: 0.0
2025-12-09 10:24:36.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 2731 LR: 0.0008355075203564693 Training loss: 0.0
2025-12-09 10:24:36.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 2732 LR: 0.0008353898613344724 Training loss: 0.0
2025-12-09 10:24:36.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 2733 LR: 0.0008352721685387257 Training loss: 0.0
2025-12-09 10:24:36.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 2734 LR: 0.0008351544419810807 Training loss: 0.0
2025-12-09 10:24:36.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 2735 LR: 0.0008350366816733927 Training loss: 0.0
2025-12-09 10:24:36.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 2736 LR: 0.0008349188876275199 Training loss: 0.0
2025-12-09 10:24:36.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 2737 LR: 0.0008348010598553244 Training loss: 0.0
2025-12-09 10:24:36.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 2738 LR: 0.0008346831983686711 Training loss: 0.0
2025-12-09 10:24:36.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 2739 LR: 0.0008345653031794292 Training loss: 0.0
2025-12-09 10:24:36.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 2740 LR: 0.0008344473742994703 Training loss: 0.0
2025-12-09 10:24:36.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 2741 LR: 0.0008343294117406699 Training loss: 0.0
2025-12-09 10:24:36.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 2742 LR: 0.0008342114155149068 Training loss: 0.0
2025-12-09 10:24:36.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 2743 LR: 0.0008340933856340636 Training loss: 0.0
2025-12-09 10:24:36.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 2744 LR: 0.0008339753221100252 Training loss: 0.0
2025-12-09 10:24:36.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 2745 LR: 0.0008338572249546813 Training loss: 0.0
2025-12-09 10:24:36.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 2746 LR: 0.0008337390941799239 Training loss: 0.0
2025-12-09 10:24:36.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 2747 LR: 0.0008336209297976489 Training loss: 0.0
2025-12-09 10:24:36.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 2748 LR: 0.0008335027318197555 Training loss: 0.0
2025-12-09 10:24:36.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 2749 LR: 0.0008333845002581458 Training loss: 0.0
2025-12-09 10:24:36.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 2750 LR: 0.0008332662351247263 Training loss: 0.0
2025-12-09 10:24:36.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 2751 LR: 0.000833147936431406 Training loss: 0.0
2025-12-09 10:24:36.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 2752 LR: 0.0008330296041900976 Training loss: 0.0
2025-12-09 10:24:36.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 2753 LR: 0.0008329112384127171 Training loss: 0.0
2025-12-09 10:24:36.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 2754 LR: 0.0008327928391111841 Training loss: 0.0
2025-12-09 10:24:36.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 2755 LR: 0.0008326744062974212 Training loss: 0.0
2025-12-09 10:24:36.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 2756 LR: 0.0008325559399833547 Training loss: 0.0
2025-12-09 10:24:36.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 2757 LR: 0.0008324374401809143 Training loss: 0.0
2025-12-09 10:24:36.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 2758 LR: 0.0008323189069020327 Training loss: 0.0
2025-12-09 10:24:36.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 2759 LR: 0.0008322003401586462 Training loss: 0.0
2025-12-09 10:24:36.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 2760 LR: 0.0008320817399626946 Training loss: 0.0
2025-12-09 10:24:36.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 2761 LR: 0.0008319631063261208 Training loss: 0.0
2025-12-09 10:24:36.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 2762 LR: 0.0008318444392608713 Training loss: 0.0
2025-12-09 10:24:36.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 2763 LR: 0.0008317257387788959 Training loss: 0.0
2025-12-09 10:24:36.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 2764 LR: 0.0008316070048921476 Training loss: 0.0
2025-12-09 10:24:36.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 2765 LR: 0.0008314882376125832 Training loss: 0.0
2025-12-09 10:24:36.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 2766 LR: 0.000831369436952162 Training loss: 0.0
2025-12-09 10:24:36.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 2767 LR: 0.0008312506029228478 Training loss: 0.0
2025-12-09 10:24:36.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 2768 LR: 0.0008311317355366068 Training loss: 0.0
2025-12-09 10:24:36.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 2769 LR: 0.0008310128348054094 Training loss: 0.0
2025-12-09 10:24:36.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 2770 LR: 0.0008308939007412282 Training loss: 0.0
2025-12-09 10:24:36.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 2771 LR: 0.0008307749333560405 Training loss: 0.0
2025-12-09 10:24:36.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 2772 LR: 0.0008306559326618259 Training loss: 0.0
2025-12-09 10:24:36.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 2773 LR: 0.0008305368986705682 Training loss: 0.0
2025-12-09 10:24:36.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 2774 LR: 0.0008304178313942535 Training loss: 0.0
2025-12-09 10:24:36.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 2775 LR: 0.0008302987308448724 Training loss: 0.0
2025-12-09 10:24:36.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 2776 LR: 0.0008301795970344181 Training loss: 0.0
2025-12-09 10:24:36.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 2777 LR: 0.0008300604299748875 Training loss: 0.0
2025-12-09 10:24:36.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 2778 LR: 0.0008299412296782805 Training loss: 0.0
2025-12-09 10:24:36.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 2779 LR: 0.0008298219961566008 Training loss: 0.0
2025-12-09 10:24:36.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 2780 LR: 0.0008297027294218551 Training loss: 0.0
2025-12-09 10:24:36.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 2781 LR: 0.0008295834294860534 Training loss: 0.0
2025-12-09 10:24:36.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 2782 LR: 0.0008294640963612097 Training loss: 0.0
2025-12-09 10:24:36.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 2783 LR: 0.0008293447300593402 Training loss: 0.0
2025-12-09 10:24:36.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 2784 LR: 0.0008292253305924656 Training loss: 0.0
2025-12-09 10:24:36.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 2785 LR: 0.0008291058979726092 Training loss: 0.0
2025-12-09 10:24:36.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 2786 LR: 0.0008289864322117977 Training loss: 0.0
2025-12-09 10:24:36.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 2787 LR: 0.0008288669333220615 Training loss: 0.0
2025-12-09 10:24:36.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 2788 LR: 0.0008287474013154343 Training loss: 0.0
2025-12-09 10:24:36.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 2789 LR: 0.0008286278362039527 Training loss: 0.0
2025-12-09 10:24:36.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 2790 LR: 0.000828508237999657 Training loss: 0.0
2025-12-09 10:24:36.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 2791 LR: 0.0008283886067145907 Training loss: 0.0
2025-12-09 10:24:36.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 2792 LR: 0.0008282689423608008 Training loss: 0.0
2025-12-09 10:24:36.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 2793 LR: 0.0008281492449503372 Training loss: 0.0
2025-12-09 10:24:36.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 2794 LR: 0.0008280295144952537 Training loss: 0.0
2025-12-09 10:24:36.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 2795 LR: 0.0008279097510076071 Training loss: 0.0
2025-12-09 10:24:36.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 2796 LR: 0.0008277899544994574 Training loss: 0.0
2025-12-09 10:24:36.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 2797 LR: 0.0008276701249828684 Training loss: 0.0
2025-12-09 10:24:36.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 2798 LR: 0.0008275502624699067 Training loss: 0.0
2025-12-09 10:24:36.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 2799 LR: 0.0008274303669726426 Training loss: 0.0
2025-12-09 10:24:36.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 2800 LR: 0.0008273104385031494 Training loss: 0.0
2025-12-09 10:24:36.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 2801 LR: 0.0008271904770735042 Training loss: 0.0
2025-12-09 10:24:36.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 2802 LR: 0.0008270704826957866 Training loss: 0.0
2025-12-09 10:24:36.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 2803 LR: 0.0008269504553820806 Training loss: 0.0
2025-12-09 10:24:36.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 2804 LR: 0.0008268303951444727 Training loss: 0.0
2025-12-09 10:24:36.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 2805 LR: 0.0008267103019950528 Training loss: 0.0
2025-12-09 10:24:36.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 2806 LR: 0.0008265901759459145 Training loss: 0.0
2025-12-09 10:24:36.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 2807 LR: 0.0008264700170091543 Training loss: 0.0
2025-12-09 10:24:36.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 2808 LR: 0.0008263498251968724 Training loss: 0.0
2025-12-09 10:24:36.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 2809 LR: 0.0008262296005211721 Training loss: 0.0
2025-12-09 10:24:36.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 2810 LR: 0.00082610934299416 Training loss: 0.0
2025-12-09 10:24:36.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 2811 LR: 0.0008259890526279459 Training loss: 0.0
2025-12-09 10:24:36.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 2812 LR: 0.000825868729434643 Training loss: 0.0
2025-12-09 10:24:36.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 2813 LR: 0.0008257483734263682 Training loss: 0.0
2025-12-09 10:24:36.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 2814 LR: 0.0008256279846152409 Training loss: 0.0
2025-12-09 10:24:36.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 2815 LR: 0.0008255075630133846 Training loss: 0.0
2025-12-09 10:24:36.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 2816 LR: 0.0008253871086329255 Training loss: 0.0
2025-12-09 10:24:36.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 2817 LR: 0.0008252666214859935 Training loss: 0.0
2025-12-09 10:24:36.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 2818 LR: 0.0008251461015847217 Training loss: 0.0
2025-12-09 10:24:36.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 2819 LR: 0.0008250255489412463 Training loss: 0.0
2025-12-09 10:24:36.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 2820 LR: 0.000824904963567707 Training loss: 0.0
2025-12-09 10:24:36.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 2821 LR: 0.0008247843454762467 Training loss: 0.0
2025-12-09 10:24:36.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 2822 LR: 0.0008246636946790118 Training loss: 0.0
2025-12-09 10:24:36.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 2823 LR: 0.0008245430111881518 Training loss: 0.0
2025-12-09 10:24:36.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 2824 LR: 0.0008244222950158193 Training loss: 0.0
2025-12-09 10:24:36.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 2825 LR: 0.0008243015461741706 Training loss: 0.0
2025-12-09 10:24:36.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 2826 LR: 0.0008241807646753652 Training loss: 0.0
2025-12-09 10:24:36.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 2827 LR: 0.0008240599505315655 Training loss: 0.0
2025-12-09 10:24:36.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 2828 LR: 0.0008239391037549378 Training loss: 0.0
2025-12-09 10:24:36.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 2829 LR: 0.0008238182243576511 Training loss: 0.0
2025-12-09 10:24:36.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 2830 LR: 0.0008236973123518781 Training loss: 0.0
2025-12-09 10:24:36.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 2831 LR: 0.0008235763677497945 Training loss: 0.0
2025-12-09 10:24:36.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 2832 LR: 0.0008234553905635797 Training loss: 0.0
2025-12-09 10:24:36.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 2833 LR: 0.0008233343808054157 Training loss: 0.0
2025-12-09 10:24:36.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 2834 LR: 0.0008232133384874887 Training loss: 0.0
2025-12-09 10:24:36.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 2835 LR: 0.0008230922636219871 Training loss: 0.0
2025-12-09 10:24:36.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 2836 LR: 0.0008229711562211036 Training loss: 0.0
2025-12-09 10:24:36.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 2837 LR: 0.0008228500162970332 Training loss: 0.0
2025-12-09 10:24:36.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 2838 LR: 0.0008227288438619753 Training loss: 0.0
2025-12-09 10:24:36.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 2839 LR: 0.0008226076389281315 Training loss: 0.0
2025-12-09 10:24:36.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 2840 LR: 0.0008224864015077074 Training loss: 0.0
2025-12-09 10:24:36.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 2841 LR: 0.0008223651316129115 Training loss: 0.0
2025-12-09 10:24:36.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 2842 LR: 0.0008222438292559555 Training loss: 0.0
2025-12-09 10:24:36.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 2843 LR: 0.0008221224944490548 Training loss: 0.0
2025-12-09 10:24:36.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 2844 LR: 0.0008220011272044277 Training loss: 0.0
2025-12-09 10:24:36.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 2845 LR: 0.000821879727534296 Training loss: 0.0
2025-12-09 10:24:36.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 2846 LR: 0.0008217582954508845 Training loss: 0.0
2025-12-09 10:24:36.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 2847 LR: 0.0008216368309664213 Training loss: 0.0
2025-12-09 10:24:36.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 2848 LR: 0.0008215153340931381 Training loss: 0.0
2025-12-09 10:24:36.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 2849 LR: 0.0008213938048432696 Training loss: 0.0
2025-12-09 10:24:36.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 2850 LR: 0.0008212722432290538 Training loss: 0.0
2025-12-09 10:24:36.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 2851 LR: 0.0008211506492627319 Training loss: 0.0
2025-12-09 10:24:36.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 2852 LR: 0.0008210290229565483 Training loss: 0.0
2025-12-09 10:24:36.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 2853 LR: 0.000820907364322751 Training loss: 0.0
2025-12-09 10:24:36.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 2854 LR: 0.0008207856733735908 Training loss: 0.0
2025-12-09 10:24:36.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 2855 LR: 0.000820663950121322 Training loss: 0.0
2025-12-09 10:24:36.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 2856 LR: 0.0008205421945782024 Training loss: 0.0
2025-12-09 10:24:36.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 2857 LR: 0.0008204204067564924 Training loss: 0.0
2025-12-09 10:24:36.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 2858 LR: 0.0008202985866684562 Training loss: 0.0
2025-12-09 10:24:36.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 2859 LR: 0.0008201767343263612 Training loss: 0.0
2025-12-09 10:24:36.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 2860 LR: 0.0008200548497424778 Training loss: 0.0
2025-12-09 10:24:36.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 2861 LR: 0.0008199329329290797 Training loss: 0.0
2025-12-09 10:24:36.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 2862 LR: 0.000819810983898444 Training loss: 0.0
2025-12-09 10:24:36.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 2863 LR: 0.000819689002662851 Training loss: 0.0
2025-12-09 10:24:36.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 2864 LR: 0.0008195669892345843 Training loss: 0.0
2025-12-09 10:24:36.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 2865 LR: 0.0008194449436259303 Training loss: 0.0
2025-12-09 10:24:36.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 2866 LR: 0.0008193228658491795 Training loss: 0.0
2025-12-09 10:24:36.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 2867 LR: 0.0008192007559166247 Training loss: 0.0
2025-12-09 10:24:36.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 2868 LR: 0.0008190786138405626 Training loss: 0.0
2025-12-09 10:24:36.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 2869 LR: 0.0008189564396332927 Training loss: 0.0
2025-12-09 10:24:36.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 2870 LR: 0.000818834233307118 Training loss: 0.0
2025-12-09 10:24:36.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 2871 LR: 0.0008187119948743449 Training loss: 0.0
2025-12-09 10:24:36.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 2872 LR: 0.0008185897243472826 Training loss: 0.0
2025-12-09 10:24:36.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 2873 LR: 0.0008184674217382437 Training loss: 0.0
2025-12-09 10:24:36.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 2874 LR: 0.0008183450870595441 Training loss: 0.0
2025-12-09 10:24:36.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 2875 LR: 0.0008182227203235031 Training loss: 0.0
2025-12-09 10:24:36.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 2876 LR: 0.0008181003215424427 Training loss: 0.0
2025-12-09 10:24:36.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 2877 LR: 0.0008179778907286887 Training loss: 0.0
2025-12-09 10:24:36.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 2878 LR: 0.00081785542789457 Training loss: 0.0
2025-12-09 10:24:36.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 2879 LR: 0.0008177329330524181 Training loss: 0.0
2025-12-09 10:24:36.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 2880 LR: 0.0008176104062145687 Training loss: 0.0
2025-12-09 10:24:36.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 2881 LR: 0.00081748784739336 Training loss: 0.0
2025-12-09 10:24:36.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 2882 LR: 0.0008173652566011338 Training loss: 0.0
2025-12-09 10:24:36.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 2883 LR: 0.000817242633850235 Training loss: 0.0
2025-12-09 10:24:36.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 2884 LR: 0.0008171199791530116 Training loss: 0.0
2025-12-09 10:24:36.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 2885 LR: 0.000816997292521815 Training loss: 0.0
2025-12-09 10:24:36.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 2886 LR: 0.0008168745739689997 Training loss: 0.0
2025-12-09 10:24:36.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 2887 LR: 0.0008167518235069235 Training loss: 0.0
2025-12-09 10:24:36.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 2888 LR: 0.0008166290411479473 Training loss: 0.0
2025-12-09 10:24:36.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 2889 LR: 0.0008165062269044352 Training loss: 0.0
2025-12-09 10:24:36.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 2890 LR: 0.0008163833807887549 Training loss: 0.0
2025-12-09 10:24:36.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 2891 LR: 0.0008162605028132768 Training loss: 0.0
2025-12-09 10:24:36.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 2892 LR: 0.0008161375929903746 Training loss: 0.0
2025-12-09 10:24:36.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 2893 LR: 0.0008160146513324255 Training loss: 0.0
2025-12-09 10:24:36.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 2894 LR: 0.0008158916778518096 Training loss: 0.0
2025-12-09 10:24:36.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 2895 LR: 0.0008157686725609105 Training loss: 0.0
2025-12-09 10:24:36.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 2896 LR: 0.0008156456354721146 Training loss: 0.0
2025-12-09 10:24:36.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 2897 LR: 0.0008155225665978119 Training loss: 0.0
2025-12-09 10:24:36.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 2898 LR: 0.0008153994659503954 Training loss: 0.0
2025-12-09 10:24:36.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 2899 LR: 0.0008152763335422613 Training loss: 0.0
2025-12-09 10:24:36.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 2900 LR: 0.000815153169385809 Training loss: 0.0
2025-12-09 10:24:36.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 2901 LR: 0.0008150299734934412 Training loss: 0.0
2025-12-09 10:24:36.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 2902 LR: 0.0008149067458775636 Training loss: 0.0
2025-12-09 10:24:36.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 2903 LR: 0.0008147834865505854 Training loss: 0.0
2025-12-09 10:24:36.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 2904 LR: 0.0008146601955249188 Training loss: 0.0
2025-12-09 10:24:36.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 2905 LR: 0.0008145368728129789 Training loss: 0.0
2025-12-09 10:24:36.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 2906 LR: 0.0008144135184271848 Training loss: 0.0
2025-12-09 10:24:36.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 2907 LR: 0.0008142901323799578 Training loss: 0.0
2025-12-09 10:24:36.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 2908 LR: 0.0008141667146837231 Training loss: 0.0
2025-12-09 10:24:36.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 2909 LR: 0.0008140432653509088 Training loss: 0.0
2025-12-09 10:24:36.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 2910 LR: 0.0008139197843939464 Training loss: 0.0
2025-12-09 10:24:36.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 2911 LR: 0.0008137962718252701 Training loss: 0.0
2025-12-09 10:24:36.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 2912 LR: 0.000813672727657318 Training loss: 0.0
2025-12-09 10:24:36.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 2913 LR: 0.0008135491519025307 Training loss: 0.0
2025-12-09 10:24:36.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 2914 LR: 0.0008134255445733522 Training loss: 0.0
2025-12-09 10:24:36.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 2915 LR: 0.0008133019056822303 Training loss: 0.0
2025-12-09 10:24:36.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 2916 LR: 0.0008131782352416148 Training loss: 0.0
2025-12-09 10:24:36.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 2917 LR: 0.0008130545332639598 Training loss: 0.0
2025-12-09 10:24:36.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 2918 LR: 0.0008129307997617217 Training loss: 0.0
2025-12-09 10:24:36.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 2919 LR: 0.0008128070347473608 Training loss: 0.0
2025-12-09 10:24:36.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 2920 LR: 0.0008126832382333399 Training loss: 0.0
2025-12-09 10:24:36.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 2921 LR: 0.0008125594102321255 Training loss: 0.0
2025-12-09 10:24:36.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 2922 LR: 0.000812435550756187 Training loss: 0.0
2025-12-09 10:24:36.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 2923 LR: 0.0008123116598179971 Training loss: 0.0
2025-12-09 10:24:36.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 2924 LR: 0.0008121877374300317 Training loss: 0.0
2025-12-09 10:24:36.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 2925 LR: 0.0008120637836047697 Training loss: 0.0
2025-12-09 10:24:36.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 2926 LR: 0.0008119397983546931 Training loss: 0.0
2025-12-09 10:24:36.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 2927 LR: 0.0008118157816922874 Training loss: 0.0
2025-12-09 10:24:36.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 2928 LR: 0.000811691733630041 Training loss: 0.0
2025-12-09 10:24:36.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 2929 LR: 0.0008115676541804455 Training loss: 0.0
2025-12-09 10:24:36.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 2930 LR: 0.000811443543355996 Training loss: 0.0
2025-12-09 10:24:36.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 2931 LR: 0.0008113194011691899 Training loss: 0.0
2025-12-09 10:24:36.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 2932 LR: 0.0008111952276325287 Training loss: 0.0
2025-12-09 10:24:36.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 2933 LR: 0.0008110710227585168 Training loss: 0.0
2025-12-09 10:24:36.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 2934 LR: 0.0008109467865596612 Training loss: 0.0
2025-12-09 10:24:36.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 2935 LR: 0.0008108225190484727 Training loss: 0.0
2025-12-09 10:24:36.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 2936 LR: 0.0008106982202374651 Training loss: 0.0
2025-12-09 10:24:36.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 2937 LR: 0.0008105738901391552 Training loss: 0.0
2025-12-09 10:24:36.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 2938 LR: 0.0008104495287660631 Training loss: 0.0
2025-12-09 10:24:36.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 2939 LR: 0.0008103251361307119 Training loss: 0.0
2025-12-09 10:24:36.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 2940 LR: 0.0008102007122456281 Training loss: 0.0
2025-12-09 10:24:36.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 2941 LR: 0.0008100762571233409 Training loss: 0.0
2025-12-09 10:24:36.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 2942 LR: 0.0008099517707763832 Training loss: 0.0
2025-12-09 10:24:36.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 2943 LR: 0.0008098272532172906 Training loss: 0.0
2025-12-09 10:24:36.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 2944 LR: 0.0008097027044586021 Training loss: 0.0
2025-12-09 10:24:36.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 2945 LR: 0.0008095781245128597 Training loss: 0.0
2025-12-09 10:24:36.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 2946 LR: 0.0008094535133926086 Training loss: 0.0
2025-12-09 10:24:36.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 2947 LR: 0.0008093288711103972 Training loss: 0.0
2025-12-09 10:24:36.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 2948 LR: 0.0008092041976787771 Training loss: 0.0
2025-12-09 10:24:36.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 2949 LR: 0.0008090794931103026 Training loss: 0.0
2025-12-09 10:24:36.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 2950 LR: 0.0008089547574175317 Training loss: 0.0
2025-12-09 10:24:36.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 2951 LR: 0.000808829990613025 Training loss: 0.0
2025-12-09 10:24:36.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 2952 LR: 0.0008087051927093469 Training loss: 0.0
2025-12-09 10:24:36.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 2953 LR: 0.0008085803637190642 Training loss: 0.0
2025-12-09 10:24:36.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 2954 LR: 0.0008084555036547474 Training loss: 0.0
2025-12-09 10:24:36.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 2955 LR: 0.0008083306125289698 Training loss: 0.0
2025-12-09 10:24:36.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 2956 LR: 0.0008082056903543079 Training loss: 0.0
2025-12-09 10:24:36.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 2957 LR: 0.0008080807371433416 Training loss: 0.0
2025-12-09 10:24:36.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 2958 LR: 0.0008079557529086532 Training loss: 0.0
2025-12-09 10:24:36.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 2959 LR: 0.0008078307376628291 Training loss: 0.0
2025-12-09 10:24:36.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 2960 LR: 0.0008077056914184582 Training loss: 0.0
2025-12-09 10:24:36.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 2961 LR: 0.0008075806141881326 Training loss: 0.0
2025-12-09 10:24:36.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 2962 LR: 0.0008074555059844474 Training loss: 0.0
2025-12-09 10:24:36.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 2963 LR: 0.0008073303668200011 Training loss: 0.0
2025-12-09 10:24:36.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 2964 LR: 0.0008072051967073955 Training loss: 0.0
2025-12-09 10:24:36.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 2965 LR: 0.000807079995659235 Training loss: 0.0
2025-12-09 10:24:36.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 2966 LR: 0.0008069547636881272 Training loss: 0.0
2025-12-09 10:24:36.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 2967 LR: 0.000806829500806683 Training loss: 0.0
2025-12-09 10:24:36.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 2968 LR: 0.0008067042070275167 Training loss: 0.0
2025-12-09 10:24:36.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 2969 LR: 0.000806578882363245 Training loss: 0.0
2025-12-09 10:24:36.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 2970 LR: 0.0008064535268264883 Training loss: 0.0
2025-12-09 10:24:36.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 2971 LR: 0.0008063281404298699 Training loss: 0.0
2025-12-09 10:24:36.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 2972 LR: 0.000806202723186016 Training loss: 0.0
2025-12-09 10:24:36.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 2973 LR: 0.0008060772751075562 Training loss: 0.0
2025-12-09 10:24:36.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 2974 LR: 0.0008059517962071233 Training loss: 0.0
2025-12-09 10:24:36.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 2975 LR: 0.0008058262864973529 Training loss: 0.0
2025-12-09 10:24:36.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 2976 LR: 0.0008057007459908839 Training loss: 0.0
2025-12-09 10:24:36.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 2977 LR: 0.0008055751747003579 Training loss: 0.0
2025-12-09 10:24:36.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 2978 LR: 0.0008054495726384204 Training loss: 0.0
2025-12-09 10:24:36.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 2979 LR: 0.0008053239398177191 Training loss: 0.0
2025-12-09 10:24:36.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 2980 LR: 0.0008051982762509055 Training loss: 0.0
2025-12-09 10:24:36.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 2981 LR: 0.0008050725819506339 Training loss: 0.0
2025-12-09 10:24:36.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 2982 LR: 0.0008049468569295615 Training loss: 0.0
2025-12-09 10:24:36.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 2983 LR: 0.000804821101200349 Training loss: 0.0
2025-12-09 10:24:36.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 2984 LR: 0.0008046953147756601 Training loss: 0.0
2025-12-09 10:24:36.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 2985 LR: 0.0008045694976681612 Training loss: 0.0
2025-12-09 10:24:36.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 2986 LR: 0.0008044436498905222 Training loss: 0.0
2025-12-09 10:24:36.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 2987 LR: 0.000804317771455416 Training loss: 0.0
2025-12-09 10:24:36.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 2988 LR: 0.0008041918623755187 Training loss: 0.0
2025-12-09 10:24:36.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 2989 LR: 0.0008040659226635089 Training loss: 0.0
2025-12-09 10:24:36.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 2990 LR: 0.0008039399523320691 Training loss: 0.0
2025-12-09 10:24:36.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 2991 LR: 0.0008038139513938846 Training loss: 0.0
2025-12-09 10:24:36.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 2992 LR: 0.0008036879198616433 Training loss: 0.0
2025-12-09 10:24:36.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 2993 LR: 0.0008035618577480369 Training loss: 0.0
2025-12-09 10:24:36.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 2994 LR: 0.0008034357650657598 Training loss: 0.0
2025-12-09 10:24:36.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 2995 LR: 0.0008033096418275092 Training loss: 0.0
2025-12-09 10:24:36.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 2996 LR: 0.0008031834880459863 Training loss: 0.0
2025-12-09 10:24:36.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 2997 LR: 0.0008030573037338942 Training loss: 0.0
2025-12-09 10:24:36.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 2998 LR: 0.00080293108890394 Training loss: 0.0
2025-12-09 10:24:36.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 2999 LR: 0.0008028048435688333 Training loss: 0.0
2025-12-09 10:24:36.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 3000 LR: 0.0008026785677412874 Training loss: 0.0
2025-12-09 10:24:36.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 3001 LR: 0.0008025522614340178 Training loss: 0.0
2025-12-09 10:24:36.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 3002 LR: 0.0008024259246597438 Training loss: 0.0
2025-12-09 10:24:36.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 3003 LR: 0.0008022995574311875 Training loss: 0.0
2025-12-09 10:24:36.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 3004 LR: 0.0008021731597610739 Training loss: 0.0
2025-12-09 10:24:36.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 3005 LR: 0.0008020467316621316 Training loss: 0.0
2025-12-09 10:24:36.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 3006 LR: 0.0008019202731470916 Training loss: 0.0
2025-12-09 10:24:36.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 3007 LR: 0.0008017937842286883 Training loss: 0.0
2025-12-09 10:24:36.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 3008 LR: 0.0008016672649196593 Training loss: 0.0
2025-12-09 10:24:36.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 3009 LR: 0.0008015407152327448 Training loss: 0.0
2025-12-09 10:24:36.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 3010 LR: 0.0008014141351806886 Training loss: 0.0
2025-12-09 10:24:36.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 3011 LR: 0.0008012875247762372 Training loss: 0.0
2025-12-09 10:24:36.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 3012 LR: 0.0008011608840321403 Training loss: 0.0
2025-12-09 10:24:36.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 3013 LR: 0.0008010342129611507 Training loss: 0.0
2025-12-09 10:24:36.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 3014 LR: 0.0008009075115760243 Training loss: 0.0
2025-12-09 10:24:36.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 3015 LR: 0.0008007807798895194 Training loss: 0.0
2025-12-09 10:24:36.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 3016 LR: 0.0008006540179143982 Training loss: 0.0
2025-12-09 10:24:36.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 3017 LR: 0.0008005272256634258 Training loss: 0.0
2025-12-09 10:24:36.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 3018 LR: 0.00080040040314937 Training loss: 0.0
2025-12-09 10:24:36.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 3019 LR: 0.0008002735503850016 Training loss: 0.0
2025-12-09 10:24:36.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 3020 LR: 0.000800146667383095 Training loss: 0.0
2025-12-09 10:24:36.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 3021 LR: 0.0008000197541564271 Training loss: 0.0
2025-12-09 10:24:36.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 3022 LR: 0.0007998928107177784 Training loss: 0.0
2025-12-09 10:24:36.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 3023 LR: 0.0007997658370799317 Training loss: 0.0
2025-12-09 10:24:36.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 3024 LR: 0.0007996388332556734 Training loss: 0.0
2025-12-09 10:24:36.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 3025 LR: 0.0007995117992577929 Training loss: 0.0
2025-12-09 10:24:36.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 3026 LR: 0.0007993847350990824 Training loss: 0.0
2025-12-09 10:24:36.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 3027 LR: 0.0007992576407923372 Training loss: 0.0
2025-12-09 10:24:36.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 3028 LR: 0.0007991305163503558 Training loss: 0.0
2025-12-09 10:24:36.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 3029 LR: 0.0007990033617859396 Training loss: 0.0
2025-12-09 10:24:36.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 3030 LR: 0.0007988761771118931 Training loss: 0.0
2025-12-09 10:24:36.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 3031 LR: 0.0007987489623410236 Training loss: 0.0
2025-12-09 10:24:36.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 3032 LR: 0.0007986217174861419 Training loss: 0.0
2025-12-09 10:24:36.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 3033 LR: 0.0007984944425600614 Training loss: 0.0
2025-12-09 10:24:36.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 3034 LR: 0.0007983671375755985 Training loss: 0.0
2025-12-09 10:24:36.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 3035 LR: 0.0007982398025455732 Training loss: 0.0
2025-12-09 10:24:36.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 3036 LR: 0.0007981124374828079 Training loss: 0.0
2025-12-09 10:24:36.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 3037 LR: 0.0007979850424001283 Training loss: 0.0
2025-12-09 10:24:36.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 3038 LR: 0.0007978576173103631 Training loss: 0.0
2025-12-09 10:24:36.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 3039 LR: 0.000797730162226344 Training loss: 0.0
2025-12-09 10:24:36.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 3040 LR: 0.0007976026771609057 Training loss: 0.0
2025-12-09 10:24:36.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 3041 LR: 0.0007974751621268859 Training loss: 0.0
2025-12-09 10:24:36.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 3042 LR: 0.0007973476171371255 Training loss: 0.0
2025-12-09 10:24:36.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 3043 LR: 0.0007972200422044682 Training loss: 0.0
2025-12-09 10:24:36.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 3044 LR: 0.0007970924373417607 Training loss: 0.0
2025-12-09 10:24:36.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 3045 LR: 0.000796964802561853 Training loss: 0.0
2025-12-09 10:24:36.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 3046 LR: 0.0007968371378775977 Training loss: 0.0
2025-12-09 10:24:36.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 3047 LR: 0.0007967094433018508 Training loss: 0.0
2025-12-09 10:24:36.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 3048 LR: 0.000796581718847471 Training loss: 0.0
2025-12-09 10:24:36.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 3049 LR: 0.0007964539645273203 Training loss: 0.0
2025-12-09 10:24:36.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 3050 LR: 0.0007963261803542634 Training loss: 0.0
2025-12-09 10:24:36.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 3051 LR: 0.0007961983663411684 Training loss: 0.0
2025-12-09 10:24:36.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 3052 LR: 0.0007960705225009058 Training loss: 0.0
2025-12-09 10:24:36.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 3053 LR: 0.0007959426488463499 Training loss: 0.0
2025-12-09 10:24:36.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 3054 LR: 0.0007958147453903773 Training loss: 0.0
2025-12-09 10:24:36.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 3055 LR: 0.0007956868121458678 Training loss: 0.0
2025-12-09 10:24:36.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 3056 LR: 0.0007955588491257045 Training loss: 0.0
2025-12-09 10:24:36.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 3057 LR: 0.0007954308563427732 Training loss: 0.0
2025-12-09 10:24:36.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 3058 LR: 0.0007953028338099627 Training loss: 0.0
2025-12-09 10:24:36.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 3059 LR: 0.000795174781540165 Training loss: 0.0
2025-12-09 10:24:36.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 3060 LR: 0.0007950466995462748 Training loss: 0.0
2025-12-09 10:24:36.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 3061 LR: 0.0007949185878411899 Training loss: 0.0
2025-12-09 10:24:36.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 3062 LR: 0.0007947904464378115 Training loss: 0.0
2025-12-09 10:24:36.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 3063 LR: 0.0007946622753490433 Training loss: 0.0
2025-12-09 10:24:36.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 3064 LR: 0.0007945340745877918 Training loss: 0.0
2025-12-09 10:24:36.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 3065 LR: 0.000794405844166967 Training loss: 0.0
2025-12-09 10:24:36.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 3066 LR: 0.000794277584099482 Training loss: 0.0
2025-12-09 10:24:36.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 3067 LR: 0.0007941492943982522 Training loss: 0.0
2025-12-09 10:24:36.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 3068 LR: 0.0007940209750761964 Training loss: 0.0
2025-12-09 10:24:36.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 3069 LR: 0.0007938926261462366 Training loss: 0.0
2025-12-09 10:24:36.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 3070 LR: 0.0007937642476212974 Training loss: 0.0
2025-12-09 10:24:36.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 3071 LR: 0.0007936358395143064 Training loss: 0.0
2025-12-09 10:24:36.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 3072 LR: 0.0007935074018381945 Training loss: 0.0
2025-12-09 10:24:36.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 3073 LR: 0.000793378934605895 Training loss: 0.0
2025-12-09 10:24:36.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 3074 LR: 0.0007932504378303451 Training loss: 0.0
2025-12-09 10:24:36.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 3075 LR: 0.0007931219115244841 Training loss: 0.0
2025-12-09 10:24:36.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 3076 LR: 0.0007929933557012546 Training loss: 0.0
2025-12-09 10:24:36.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 3077 LR: 0.0007928647703736023 Training loss: 0.0
2025-12-09 10:24:36.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 3078 LR: 0.0007927361555544754 Training loss: 0.0
2025-12-09 10:24:36.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 3079 LR: 0.0007926075112568258 Training loss: 0.0
2025-12-09 10:24:36.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 3080 LR: 0.0007924788374936079 Training loss: 0.0
2025-12-09 10:24:36.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 3081 LR: 0.0007923501342777788 Training loss: 0.0
2025-12-09 10:24:36.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 3082 LR: 0.0007922214016222993 Training loss: 0.0
2025-12-09 10:24:36.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 3083 LR: 0.0007920926395401326 Training loss: 0.0
2025-12-09 10:24:36.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 3084 LR: 0.0007919638480442453 Training loss: 0.0
2025-12-09 10:24:36.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 3085 LR: 0.0007918350271476064 Training loss: 0.0
2025-12-09 10:24:36.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 3086 LR: 0.0007917061768631881 Training loss: 0.0
2025-12-09 10:24:36.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 3087 LR: 0.000791577297203966 Training loss: 0.0
2025-12-09 10:24:36.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 3088 LR: 0.0007914483881829178 Training loss: 0.0
2025-12-09 10:24:36.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 3089 LR: 0.0007913194498130252 Training loss: 0.0
2025-12-09 10:24:36.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 3090 LR: 0.0007911904821072717 Training loss: 0.0
2025-12-09 10:24:36.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 3091 LR: 0.0007910614850786447 Training loss: 0.0
2025-12-09 10:24:36.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 3092 LR: 0.0007909324587401341 Training loss: 0.0
2025-12-09 10:24:36.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 3093 LR: 0.0007908034031047329 Training loss: 0.0
2025-12-09 10:24:36.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 3094 LR: 0.000790674318185437 Training loss: 0.0
2025-12-09 10:24:36.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 3095 LR: 0.0007905452039952452 Training loss: 0.0
2025-12-09 10:24:36.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 3096 LR: 0.0007904160605471594 Training loss: 0.0
2025-12-09 10:24:36.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 3097 LR: 0.000790286887854184 Training loss: 0.0
2025-12-09 10:24:36.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 3098 LR: 0.0007901576859293271 Training loss: 0.0
2025-12-09 10:24:36.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 3099 LR: 0.0007900284547855992 Training loss: 0.0
2025-12-09 10:24:36.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 3100 LR: 0.0007898991944360137 Training loss: 0.0
2025-12-09 10:24:36.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 3101 LR: 0.0007897699048935873 Training loss: 0.0
2025-12-09 10:24:36.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 3102 LR: 0.0007896405861713394 Training loss: 0.0
2025-12-09 10:24:36.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 3103 LR: 0.0007895112382822925 Training loss: 0.0
2025-12-09 10:24:36.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 3104 LR: 0.0007893818612394717 Training loss: 0.0
2025-12-09 10:24:36.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 3105 LR: 0.0007892524550559054 Training loss: 0.0
2025-12-09 10:24:36.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 3106 LR: 0.0007891230197446249 Training loss: 0.0
2025-12-09 10:24:36.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 3107 LR: 0.0007889935553186641 Training loss: 0.0
2025-12-09 10:24:36.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 3108 LR: 0.0007888640617910603 Training loss: 0.0
2025-12-09 10:24:36.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 3109 LR: 0.0007887345391748532 Training loss: 0.0
2025-12-09 10:24:36.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 3110 LR: 0.0007886049874830862 Training loss: 0.0
2025-12-09 10:24:36.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 3111 LR: 0.0007884754067288047 Training loss: 0.0
2025-12-09 10:24:36.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 3112 LR: 0.0007883457969250576 Training loss: 0.0
2025-12-09 10:24:36.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 3113 LR: 0.0007882161580848966 Training loss: 0.0
2025-12-09 10:24:36.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 3114 LR: 0.0007880864902213764 Training loss: 0.0
2025-12-09 10:24:36.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 3115 LR: 0.0007879567933475547 Training loss: 0.0
2025-12-09 10:24:36.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 3116 LR: 0.0007878270674764916 Training loss: 0.0
2025-12-09 10:24:36.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 3117 LR: 0.0007876973126212507 Training loss: 0.0
2025-12-09 10:24:36.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 3118 LR: 0.0007875675287948983 Training loss: 0.0
2025-12-09 10:24:36.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 3119 LR: 0.0007874377160105036 Training loss: 0.0
2025-12-09 10:24:36.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 3120 LR: 0.0007873078742811388 Training loss: 0.0
2025-12-09 10:24:36.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 3121 LR: 0.000787178003619879 Training loss: 0.0
2025-12-09 10:24:36.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 3122 LR: 0.0007870481040398019 Training loss: 0.0
2025-12-09 10:24:36.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 3123 LR: 0.0007869181755539887 Training loss: 0.0
2025-12-09 10:24:36.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 3124 LR: 0.0007867882181755231 Training loss: 0.0
2025-12-09 10:24:36.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 3125 LR: 0.0007866582319174918 Training loss: 0.0
2025-12-09 10:24:36.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 3126 LR: 0.0007865282167929842 Training loss: 0.0
2025-12-09 10:24:36.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 3127 LR: 0.0007863981728150931 Training loss: 0.0
2025-12-09 10:24:36.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 3128 LR: 0.0007862680999969139 Training loss: 0.0
2025-12-09 10:24:36.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 3129 LR: 0.0007861379983515449 Training loss: 0.0
2025-12-09 10:24:36.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 3130 LR: 0.0007860078678920872 Training loss: 0.0
2025-12-09 10:24:36.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 3131 LR: 0.000785877708631645 Training loss: 0.0
2025-12-09 10:24:36.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 3132 LR: 0.0007857475205833254 Training loss: 0.0
2025-12-09 10:24:36.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 3133 LR: 0.0007856173037602383 Training loss: 0.0
2025-12-09 10:24:36.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 3134 LR: 0.0007854870581754966 Training loss: 0.0
2025-12-09 10:24:36.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 3135 LR: 0.000785356783842216 Training loss: 0.0
2025-12-09 10:24:36.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 3136 LR: 0.0007852264807735147 Training loss: 0.0
2025-12-09 10:24:36.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 3137 LR: 0.000785096148982515 Training loss: 0.0
2025-12-09 10:24:36.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 3138 LR: 0.0007849657884823408 Training loss: 0.0
2025-12-09 10:24:36.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 3139 LR: 0.0007848353992861195 Training loss: 0.0
2025-12-09 10:24:36.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 3140 LR: 0.0007847049814069811 Training loss: 0.0
2025-12-09 10:24:36.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 3141 LR: 0.0007845745348580591 Training loss: 0.0
2025-12-09 10:24:36.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 3142 LR: 0.0007844440596524891 Training loss: 0.0
2025-12-09 10:24:36.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 3143 LR: 0.00078431355580341 Training loss: 0.0
2025-12-09 10:24:36.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 3144 LR: 0.0007841830233239638 Training loss: 0.0
2025-12-09 10:24:36.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 3145 LR: 0.0007840524622272949 Training loss: 0.0
2025-12-09 10:24:36.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 3146 LR: 0.0007839218725265507 Training loss: 0.0
2025-12-09 10:24:36.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 3147 LR: 0.0007837912542348818 Training loss: 0.0
2025-12-09 10:24:36.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 3148 LR: 0.0007836606073654413 Training loss: 0.0
2025-12-09 10:24:36.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 3149 LR: 0.0007835299319313853 Training loss: 0.0
2025-12-09 10:24:36.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 3150 LR: 0.0007833992279458732 Training loss: 0.0
2025-12-09 10:24:36.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 3151 LR: 0.0007832684954220664 Training loss: 0.0
2025-12-09 10:24:36.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 3152 LR: 0.0007831377343731298 Training loss: 0.0
2025-12-09 10:24:36.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 3153 LR: 0.0007830069448122312 Training loss: 0.0
2025-12-09 10:24:36.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 3154 LR: 0.000782876126752541 Training loss: 0.0
2025-12-09 10:24:36.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 3155 LR: 0.0007827452802072328 Training loss: 0.0
2025-12-09 10:24:36.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 3156 LR: 0.0007826144051894824 Training loss: 0.0
2025-12-09 10:24:36.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 3157 LR: 0.0007824835017124689 Training loss: 0.0
2025-12-09 10:24:36.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 3158 LR: 0.0007823525697893749 Training loss: 0.0
2025-12-09 10:24:36.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 3159 LR: 0.0007822216094333848 Training loss: 0.0
2025-12-09 10:24:36.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 3160 LR: 0.0007820906206576861 Training loss: 0.0
2025-12-09 10:24:36.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 3161 LR: 0.0007819596034754697 Training loss: 0.0
2025-12-09 10:24:36.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 3162 LR: 0.000781828557899929 Training loss: 0.0
2025-12-09 10:24:36.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 3163 LR: 0.0007816974839442604 Training loss: 0.0
2025-12-09 10:24:36.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 3164 LR: 0.0007815663816216625 Training loss: 0.0
2025-12-09 10:24:36.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 3165 LR: 0.000781435250945338 Training loss: 0.0
2025-12-09 10:24:36.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 3166 LR: 0.0007813040919284913 Training loss: 0.0
2025-12-09 10:24:36.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 3167 LR: 0.0007811729045843302 Training loss: 0.0
2025-12-09 10:24:36.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 3168 LR: 0.0007810416889260653 Training loss: 0.0
2025-12-09 10:24:36.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 3169 LR: 0.0007809104449669101 Training loss: 0.0
2025-12-09 10:24:36.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 3170 LR: 0.0007807791727200809 Training loss: 0.0
2025-12-09 10:24:36.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 3171 LR: 0.0007806478721987965 Training loss: 0.0
2025-12-09 10:24:36.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 3172 LR: 0.000780516543416279 Training loss: 0.0
2025-12-09 10:24:36.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 3173 LR: 0.0007803851863857533 Training loss: 0.0
2025-12-09 10:24:36.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 3174 LR: 0.000780253801120447 Training loss: 0.0
2025-12-09 10:24:36.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 3175 LR: 0.0007801223876335907 Training loss: 0.0
2025-12-09 10:24:36.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 3176 LR: 0.0007799909459384176 Training loss: 0.0
2025-12-09 10:24:36.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 3177 LR: 0.0007798594760481637 Training loss: 0.0
2025-12-09 10:24:36.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 3178 LR: 0.0007797279779760684 Training loss: 0.0
2025-12-09 10:24:36.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 3179 LR: 0.0007795964517353734 Training loss: 0.0
2025-12-09 10:24:36.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 3180 LR: 0.0007794648973393234 Training loss: 0.0
2025-12-09 10:24:36.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 3181 LR: 0.0007793333148011657 Training loss: 0.0
2025-12-09 10:24:36.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 3182 LR: 0.000779201704134151 Training loss: 0.0
2025-12-09 10:24:36.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 3183 LR: 0.0007790700653515323 Training loss: 0.0
2025-12-09 10:24:36.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 3184 LR: 0.0007789383984665657 Training loss: 0.0
2025-12-09 10:24:36.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 3185 LR: 0.00077880670349251 Training loss: 0.0
2025-12-09 10:24:36.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 3186 LR: 0.0007786749804426267 Training loss: 0.0
2025-12-09 10:24:36.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 3187 LR: 0.0007785432293301806 Training loss: 0.0
2025-12-09 10:24:36.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 3188 LR: 0.000778411450168439 Training loss: 0.0
2025-12-09 10:24:36.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 3189 LR: 0.000778279642970672 Training loss: 0.0
2025-12-09 10:24:36.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 3190 LR: 0.0007781478077501524 Training loss: 0.0
2025-12-09 10:24:36.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 3191 LR: 0.0007780159445201563 Training loss: 0.0
2025-12-09 10:24:36.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 3192 LR: 0.0007778840532939622 Training loss: 0.0
2025-12-09 10:24:36.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 3193 LR: 0.0007777521340848514 Training loss: 0.0
2025-12-09 10:24:36.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 3194 LR: 0.0007776201869061085 Training loss: 0.0
2025-12-09 10:24:36.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 3195 LR: 0.0007774882117710202 Training loss: 0.0
2025-12-09 10:24:36.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 3196 LR: 0.0007773562086928767 Training loss: 0.0
2025-12-09 10:24:36.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 3197 LR: 0.0007772241776849704 Training loss: 0.0
2025-12-09 10:24:36.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 3198 LR: 0.0007770921187605972 Training loss: 0.0
2025-12-09 10:24:36.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 3199 LR: 0.0007769600319330552 Training loss: 0.0
2025-12-09 10:24:36.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 3200 LR: 0.0007768279172156453 Training loss: 0.0
2025-12-09 10:24:36.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 3201 LR: 0.000776695774621672 Training loss: 0.0
2025-12-09 10:24:36.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 3202 LR: 0.0007765636041644418 Training loss: 0.0
2025-12-09 10:24:36.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 3203 LR: 0.000776431405857264 Training loss: 0.0
2025-12-09 10:24:36.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 3204 LR: 0.0007762991797134513 Training loss: 0.0
2025-12-09 10:24:36.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 3205 LR: 0.0007761669257463188 Training loss: 0.0
2025-12-09 10:24:36.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 3206 LR: 0.0007760346439691843 Training loss: 0.0
2025-12-09 10:24:36.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 3207 LR: 0.0007759023343953688 Training loss: 0.0
2025-12-09 10:24:36.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 3208 LR: 0.0007757699970381959 Training loss: 0.0
2025-12-09 10:24:36.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 3209 LR: 0.0007756376319109917 Training loss: 0.0
2025-12-09 10:24:36.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 3210 LR: 0.0007755052390270855 Training loss: 0.0
2025-12-09 10:24:36.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 3211 LR: 0.0007753728183998093 Training loss: 0.0
2025-12-09 10:24:36.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 3212 LR: 0.0007752403700424978 Training loss: 0.0
2025-12-09 10:24:36.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 3213 LR: 0.0007751078939684886 Training loss: 0.0
2025-12-09 10:24:36.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 3214 LR: 0.0007749753901911219 Training loss: 0.0
2025-12-09 10:24:36.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 3215 LR: 0.0007748428587237412 Training loss: 0.0
2025-12-09 10:24:36.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 3216 LR: 0.000774710299579692 Training loss: 0.0
2025-12-09 10:24:36.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 3217 LR: 0.0007745777127723231 Training loss: 0.0
2025-12-09 10:24:36.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 3218 LR: 0.0007744450983149859 Training loss: 0.0
2025-12-09 10:24:36.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 3219 LR: 0.0007743124562210351 Training loss: 0.0
2025-12-09 10:24:36.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 3220 LR: 0.0007741797865038273 Training loss: 0.0
2025-12-09 10:24:36.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 3221 LR: 0.0007740470891767224 Training loss: 0.0
2025-12-09 10:24:36.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 3222 LR: 0.0007739143642530832 Training loss: 0.0
2025-12-09 10:24:36.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 3223 LR: 0.0007737816117462751 Training loss: 0.0
2025-12-09 10:24:36.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 3224 LR: 0.0007736488316696662 Training loss: 0.0
2025-12-09 10:24:36.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 3225 LR: 0.0007735160240366274 Training loss: 0.0
2025-12-09 10:24:36.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 3226 LR: 0.0007733831888605325 Training loss: 0.0
2025-12-09 10:24:36.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 3227 LR: 0.0007732503261547579 Training loss: 0.0
2025-12-09 10:24:36.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 3228 LR: 0.0007731174359326829 Training loss: 0.0
2025-12-09 10:24:36.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 3229 LR: 0.0007729845182076895 Training loss: 0.0
2025-12-09 10:24:36.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 3230 LR: 0.0007728515729931629 Training loss: 0.0
2025-12-09 10:24:36.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 3231 LR: 0.00077271860030249 Training loss: 0.0
2025-12-09 10:24:36.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 3232 LR: 0.0007725856001490617 Training loss: 0.0
2025-12-09 10:24:36.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 3233 LR: 0.000772452572546271 Training loss: 0.0
2025-12-09 10:24:36.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 3234 LR: 0.0007723195175075137 Training loss: 0.0
2025-12-09 10:24:36.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 3235 LR: 0.0007721864350461882 Training loss: 0.0
2025-12-09 10:24:36.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 3236 LR: 0.0007720533251756962 Training loss: 0.0
2025-12-09 10:24:36.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 3237 LR: 0.000771920187909442 Training loss: 0.0
2025-12-09 10:24:36.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 3238 LR: 0.0007717870232608322 Training loss: 0.0
2025-12-09 10:24:36.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 3239 LR: 0.0007716538312432765 Training loss: 0.0
2025-12-09 10:24:36.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 3240 LR: 0.0007715206118701876 Training loss: 0.0
2025-12-09 10:24:36.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 3241 LR: 0.0007713873651549805 Training loss: 0.0
2025-12-09 10:24:36.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 3242 LR: 0.0007712540911110731 Training loss: 0.0
2025-12-09 10:24:36.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 3243 LR: 0.0007711207897518861 Training loss: 0.0
2025-12-09 10:24:36.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 3244 LR: 0.0007709874610908429 Training loss: 0.0
2025-12-09 10:24:36.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 3245 LR: 0.00077085410514137 Training loss: 0.0
2025-12-09 10:24:36.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 3246 LR: 0.0007707207219168959 Training loss: 0.0
2025-12-09 10:24:36.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 3247 LR: 0.0007705873114308528 Training loss: 0.0
2025-12-09 10:24:36.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 3248 LR: 0.0007704538736966746 Training loss: 0.0
2025-12-09 10:24:36.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 3249 LR: 0.0007703204087277988 Training loss: 0.0
2025-12-09 10:24:36.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 3250 LR: 0.0007701869165376653 Training loss: 0.0
2025-12-09 10:24:36.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 3251 LR: 0.0007700533971397165 Training loss: 0.0
2025-12-09 10:24:36.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 3252 LR: 0.0007699198505473982 Training loss: 0.0
2025-12-09 10:24:36.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 3253 LR: 0.0007697862767741583 Training loss: 0.0
2025-12-09 10:24:36.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 3254 LR: 0.0007696526758334477 Training loss: 0.0
2025-12-09 10:24:36.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 3255 LR: 0.00076951904773872 Training loss: 0.0
2025-12-09 10:24:36.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 3256 LR: 0.0007693853925034315 Training loss: 0.0
2025-12-09 10:24:36.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 3257 LR: 0.0007692517101410414 Training loss: 0.0
2025-12-09 10:24:36.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 3258 LR: 0.0007691180006650116 Training loss: 0.0
2025-12-09 10:24:36.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 3259 LR: 0.0007689842640888063 Training loss: 0.0
2025-12-09 10:24:36.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 3260 LR: 0.000768850500425893 Training loss: 0.0
2025-12-09 10:24:36.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 3261 LR: 0.0007687167096897419 Training loss: 0.0
2025-12-09 10:24:36.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 3262 LR: 0.0007685828918938251 Training loss: 0.0
2025-12-09 10:24:36.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 3263 LR: 0.0007684490470516185 Training loss: 0.0
2025-12-09 10:24:36.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 3264 LR: 0.0007683151751766004 Training loss: 0.0
2025-12-09 10:24:36.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 3265 LR: 0.0007681812762822516 Training loss: 0.0
2025-12-09 10:24:36.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 3266 LR: 0.0007680473503820553 Training loss: 0.0
2025-12-09 10:24:36.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 3267 LR: 0.0007679133974894983 Training loss: 0.0
2025-12-09 10:24:36.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 3268 LR: 0.0007677794176180696 Training loss: 0.0
2025-12-09 10:24:36.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 3269 LR: 0.0007676454107812607 Training loss: 0.0
2025-12-09 10:24:36.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 3270 LR: 0.0007675113769925663 Training loss: 0.0
2025-12-09 10:24:36.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 3271 LR: 0.0007673773162654836 Training loss: 0.0
2025-12-09 10:24:36.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 3272 LR: 0.0007672432286135125 Training loss: 0.0
2025-12-09 10:24:36.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 3273 LR: 0.0007671091140501556 Training loss: 0.0
2025-12-09 10:24:36.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 3274 LR: 0.0007669749725889182 Training loss: 0.0
2025-12-09 10:24:36.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 3275 LR: 0.0007668408042433082 Training loss: 0.0
2025-12-09 10:24:36.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 3276 LR: 0.0007667066090268367 Training loss: 0.0
2025-12-09 10:24:36.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 3277 LR: 0.0007665723869530169 Training loss: 0.0
2025-12-09 10:24:36.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 3278 LR: 0.000766438138035365 Training loss: 0.0
2025-12-09 10:24:36.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 3279 LR: 0.0007663038622873999 Training loss: 0.0
2025-12-09 10:24:36.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 3280 LR: 0.0007661695597226433 Training loss: 0.0
2025-12-09 10:24:36.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 3281 LR: 0.0007660352303546191 Training loss: 0.0
2025-12-09 10:24:36.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 3282 LR: 0.0007659008741968546 Training loss: 0.0
2025-12-09 10:24:36.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 3283 LR: 0.0007657664912628794 Training loss: 0.0
2025-12-09 10:24:36.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 3284 LR: 0.0007656320815662257 Training loss: 0.0
2025-12-09 10:24:36.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 3285 LR: 0.0007654976451204287 Training loss: 0.0
2025-12-09 10:24:36.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 3286 LR: 0.0007653631819390262 Training loss: 0.0
2025-12-09 10:24:36.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 3287 LR: 0.0007652286920355584 Training loss: 0.0
2025-12-09 10:24:36.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 3288 LR: 0.0007650941754235685 Training loss: 0.0
2025-12-09 10:24:36.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 3289 LR: 0.0007649596321166025 Training loss: 0.0
2025-12-09 10:24:36.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 3290 LR: 0.0007648250621282087 Training loss: 0.0
2025-12-09 10:24:36.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 3291 LR: 0.0007646904654719385 Training loss: 0.0
2025-12-09 10:24:36.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 3292 LR: 0.0007645558421613456 Training loss: 0.0
2025-12-09 10:24:36.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 3293 LR: 0.0007644211922099867 Training loss: 0.0
2025-12-09 10:24:36.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 3294 LR: 0.0007642865156314209 Training loss: 0.0
2025-12-09 10:24:36.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 3295 LR: 0.0007641518124392104 Training loss: 0.0
2025-12-09 10:24:36.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 3296 LR: 0.0007640170826469194 Training loss: 0.0
2025-12-09 10:24:36.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 3297 LR: 0.0007638823262681155 Training loss: 0.0
2025-12-09 10:24:36.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 3298 LR: 0.0007637475433163685 Training loss: 0.0
2025-12-09 10:24:36.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 3299 LR: 0.0007636127338052513 Training loss: 0.0
2025-12-09 10:24:36.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 3300 LR: 0.0007634778977483389 Training loss: 0.0
2025-12-09 10:24:36.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 3301 LR: 0.0007633430351592093 Training loss: 0.0
2025-12-09 10:24:36.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 3302 LR: 0.0007632081460514433 Training loss: 0.0
2025-12-09 10:24:36.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 3303 LR: 0.0007630732304386243 Training loss: 0.0
2025-12-09 10:24:36.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 3304 LR: 0.0007629382883343381 Training loss: 0.0
2025-12-09 10:24:36.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 3305 LR: 0.0007628033197521736 Training loss: 0.0
2025-12-09 10:24:36.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 3306 LR: 0.0007626683247057218 Training loss: 0.0
2025-12-09 10:24:36.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 3307 LR: 0.000762533303208577 Training loss: 0.0
2025-12-09 10:24:36.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 3308 LR: 0.0007623982552743356 Training loss: 0.0
2025-12-09 10:24:36.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 3309 LR: 0.0007622631809165971 Training loss: 0.0
2025-12-09 10:24:36.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 3310 LR: 0.0007621280801489637 Training loss: 0.0
2025-12-09 10:24:36.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 3311 LR: 0.0007619929529850397 Training loss: 0.0
2025-12-09 10:24:36.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 3312 LR: 0.0007618577994384323 Training loss: 0.0
2025-12-09 10:24:36.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 3313 LR: 0.0007617226195227518 Training loss: 0.0
2025-12-09 10:24:36.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 3314 LR: 0.0007615874132516108 Training loss: 0.0
2025-12-09 10:24:36.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 3315 LR: 0.0007614521806386243 Training loss: 0.0
2025-12-09 10:24:36.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 3316 LR: 0.0007613169216974104 Training loss: 0.0
2025-12-09 10:24:36.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 3317 LR: 0.0007611816364415895 Training loss: 0.0
2025-12-09 10:24:36.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 3318 LR: 0.0007610463248847852 Training loss: 0.0
2025-12-09 10:24:36.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 3319 LR: 0.000760910987040623 Training loss: 0.0
2025-12-09 10:24:36.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 3320 LR: 0.0007607756229227316 Training loss: 0.0
2025-12-09 10:24:36.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 3321 LR: 0.0007606402325447421 Training loss: 0.0
2025-12-09 10:24:36.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 3322 LR: 0.0007605048159202883 Training loss: 0.0
2025-12-09 10:24:36.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 3323 LR: 0.0007603693730630066 Training loss: 0.0
2025-12-09 10:24:36.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 3324 LR: 0.0007602339039865362 Training loss: 0.0
2025-12-09 10:24:36.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 3325 LR: 0.0007600984087045186 Training loss: 0.0
2025-12-09 10:24:36.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 3326 LR: 0.0007599628872305988 Training loss: 0.0
2025-12-09 10:24:36.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 3327 LR: 0.000759827339578423 Training loss: 0.0
2025-12-09 10:24:36.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 3328 LR: 0.0007596917657616413 Training loss: 0.0
2025-12-09 10:24:36.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 3329 LR: 0.000759556165793906 Training loss: 0.0
2025-12-09 10:24:36.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 3330 LR: 0.0007594205396888718 Training loss: 0.0
2025-12-09 10:24:36.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 3331 LR: 0.0007592848874601963 Training loss: 0.0
2025-12-09 10:24:36.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 3332 LR: 0.0007591492091215399 Training loss: 0.0
2025-12-09 10:24:36.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 3333 LR: 0.0007590135046865651 Training loss: 0.0
2025-12-09 10:24:36.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 3334 LR: 0.0007588777741689375 Training loss: 0.0
2025-12-09 10:24:36.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 3335 LR: 0.0007587420175823252 Training loss: 0.0
2025-12-09 10:24:36.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 3336 LR: 0.0007586062349403987 Training loss: 0.0
2025-12-09 10:24:36.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 3337 LR: 0.0007584704262568315 Training loss: 0.0
2025-12-09 10:24:36.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 3338 LR: 0.0007583345915452993 Training loss: 0.0
2025-12-09 10:24:36.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 3339 LR: 0.000758198730819481 Training loss: 0.0
2025-12-09 10:24:36.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 3340 LR: 0.0007580628440930575 Training loss: 0.0
2025-12-09 10:24:36.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 3341 LR: 0.0007579269313797126 Training loss: 0.0
2025-12-09 10:24:36.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 3342 LR: 0.0007577909926931328 Training loss: 0.0
2025-12-09 10:24:36.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 3343 LR: 0.0007576550280470072 Training loss: 0.0
2025-12-09 10:24:36.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 3344 LR: 0.0007575190374550272 Training loss: 0.0
2025-12-09 10:24:36.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 3345 LR: 0.0007573830209308872 Training loss: 0.0
2025-12-09 10:24:36.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 3346 LR: 0.0007572469784882839 Training loss: 0.0
2025-12-09 10:24:36.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 3347 LR: 0.000757110910140917 Training loss: 0.0
2025-12-09 10:24:36.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 3348 LR: 0.0007569748159024887 Training loss: 0.0
2025-12-09 10:24:36.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 3349 LR: 0.0007568386957867032 Training loss: 0.0
2025-12-09 10:24:36.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 3350 LR: 0.0007567025498072681 Training loss: 0.0
2025-12-09 10:24:36.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 3351 LR: 0.0007565663779778933 Training loss: 0.0
2025-12-09 10:24:36.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 3352 LR: 0.0007564301803122913 Training loss: 0.0
2025-12-09 10:24:36.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 3353 LR: 0.0007562939568241771 Training loss: 0.0
2025-12-09 10:24:36.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 3354 LR: 0.0007561577075272686 Training loss: 0.0
2025-12-09 10:24:36.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 3355 LR: 0.0007560214324352858 Training loss: 0.0
2025-12-09 10:24:36.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 3356 LR: 0.0007558851315619518 Training loss: 0.0
2025-12-09 10:24:36.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 3357 LR: 0.000755748804920992 Training loss: 0.0
2025-12-09 10:24:36.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 3358 LR: 0.0007556124525261346 Training loss: 0.0
2025-12-09 10:24:36.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 3359 LR: 0.0007554760743911103 Training loss: 0.0
2025-12-09 10:24:36.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 3360 LR: 0.0007553396705296523 Training loss: 0.0
2025-12-09 10:24:36.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 3361 LR: 0.0007552032409554963 Training loss: 0.0
2025-12-09 10:24:36.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 3362 LR: 0.000755066785682381 Training loss: 0.0
2025-12-09 10:24:36.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 3363 LR: 0.0007549303047240474 Training loss: 0.0
2025-12-09 10:24:36.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 3364 LR: 0.0007547937980942389 Training loss: 0.0
2025-12-09 10:24:36.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 3365 LR: 0.0007546572658067021 Training loss: 0.0
2025-12-09 10:24:36.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 3366 LR: 0.0007545207078751857 Training loss: 0.0
2025-12-09 10:24:36.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 3367 LR: 0.0007543841243134408 Training loss: 0.0
2025-12-09 10:24:36.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 3368 LR: 0.0007542475151352216 Training loss: 0.0
2025-12-09 10:24:36.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 3369 LR: 0.0007541108803542846 Training loss: 0.0
2025-12-09 10:24:36.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 3370 LR: 0.0007539742199843889 Training loss: 0.0
2025-12-09 10:24:36.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 3371 LR: 0.0007538375340392961 Training loss: 0.0
2025-12-09 10:24:36.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 3372 LR: 0.0007537008225327706 Training loss: 0.0
2025-12-09 10:24:36.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 3373 LR: 0.0007535640854785793 Training loss: 0.0
2025-12-09 10:24:36.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 3374 LR: 0.0007534273228904916 Training loss: 0.0
2025-12-09 10:24:36.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 3375 LR: 0.0007532905347822791 Training loss: 0.0
2025-12-09 10:24:36.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 3376 LR: 0.0007531537211677168 Training loss: 0.0
2025-12-09 10:24:36.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 3377 LR: 0.0007530168820605818 Training loss: 0.0
2025-12-09 10:24:36.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 3378 LR: 0.0007528800174746538 Training loss: 0.0
2025-12-09 10:24:36.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 3379 LR: 0.0007527431274237149 Training loss: 0.0
2025-12-09 10:24:36.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 3380 LR: 0.0007526062119215498 Training loss: 0.0
2025-12-09 10:24:36.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 3381 LR: 0.0007524692709819463 Training loss: 0.0
2025-12-09 10:24:36.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 3382 LR: 0.0007523323046186941 Training loss: 0.0
2025-12-09 10:24:36.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 3383 LR: 0.0007521953128455855 Training loss: 0.0
2025-12-09 10:24:36.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 3384 LR: 0.000752058295676416 Training loss: 0.0
2025-12-09 10:24:36.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 3385 LR: 0.0007519212531249829 Training loss: 0.0
2025-12-09 10:24:36.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 3386 LR: 0.0007517841852050866 Training loss: 0.0
2025-12-09 10:24:36.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 3387 LR: 0.0007516470919305298 Training loss: 0.0
2025-12-09 10:24:36.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 3388 LR: 0.0007515099733151177 Training loss: 0.0
2025-12-09 10:24:36.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 3389 LR: 0.0007513728293726579 Training loss: 0.0
2025-12-09 10:24:36.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 3390 LR: 0.0007512356601169615 Training loss: 0.0
2025-12-09 10:24:36.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 3391 LR: 0.0007510984655618407 Training loss: 0.0
2025-12-09 10:24:36.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 3392 LR: 0.0007509612457211113 Training loss: 0.0
2025-12-09 10:24:36.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 3393 LR: 0.0007508240006085914 Training loss: 0.0
2025-12-09 10:24:36.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 3394 LR: 0.0007506867302381015 Training loss: 0.0
2025-12-09 10:24:36.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 3395 LR: 0.0007505494346234647 Training loss: 0.0
2025-12-09 10:24:36.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 3396 LR: 0.0007504121137785066 Training loss: 0.0
2025-12-09 10:24:36.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 3397 LR: 0.0007502747677170556 Training loss: 0.0
2025-12-09 10:24:36.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 3398 LR: 0.0007501373964529423 Training loss: 0.0
2025-12-09 10:24:36.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 3399 LR: 0.00075 Training loss: 0.0
2025-12-09 10:24:36.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 3400 LR: 0.0007498625783720647 Training loss: 0.0
2025-12-09 10:24:36.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 3401 LR: 0.0007497251315829744 Training loss: 0.0
2025-12-09 10:24:36.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 3402 LR: 0.0007495876596465702 Training loss: 0.0
2025-12-09 10:24:36.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 3403 LR: 0.0007494501625766956 Training loss: 0.0
2025-12-09 10:24:36.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 3404 LR: 0.0007493126403871964 Training loss: 0.0
2025-12-09 10:24:36.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 3405 LR: 0.0007491750930919213 Training loss: 0.0
2025-12-09 10:24:36.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 3406 LR: 0.0007490375207047209 Training loss: 0.0
2025-12-09 10:24:36.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 3407 LR: 0.0007488999232394491 Training loss: 0.0
2025-12-09 10:24:36.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 3408 LR: 0.0007487623007099617 Training loss: 0.0
2025-12-09 10:24:36.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 3409 LR: 0.0007486246531301177 Training loss: 0.0
2025-12-09 10:24:36.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 3410 LR: 0.0007484869805137777 Training loss: 0.0
2025-12-09 10:24:36.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 3411 LR: 0.0007483492828748057 Training loss: 0.0
2025-12-09 10:24:36.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 3412 LR: 0.0007482115602270676 Training loss: 0.0
2025-12-09 10:24:36.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 3413 LR: 0.0007480738125844322 Training loss: 0.0
2025-12-09 10:24:36.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 3414 LR: 0.0007479360399607706 Training loss: 0.0
2025-12-09 10:24:36.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 3415 LR: 0.0007477982423699567 Training loss: 0.0
2025-12-09 10:24:36.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 3416 LR: 0.0007476604198258665 Training loss: 0.0
2025-12-09 10:24:36.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 3417 LR: 0.0007475225723423788 Training loss: 0.0
2025-12-09 10:24:36.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 3418 LR: 0.0007473846999333748 Training loss: 0.0
2025-12-09 10:24:36.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 3419 LR: 0.0007472468026127384 Training loss: 0.0
2025-12-09 10:24:36.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 3420 LR: 0.0007471088803943557 Training loss: 0.0
2025-12-09 10:24:36.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 3421 LR: 0.0007469709332921155 Training loss: 0.0
2025-12-09 10:24:36.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 3422 LR: 0.0007468329613199091 Training loss: 0.0
2025-12-09 10:24:36.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 3423 LR: 0.0007466949644916301 Training loss: 0.0
2025-12-09 10:24:36.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 3424 LR: 0.0007465569428211752 Training loss: 0.0
2025-12-09 10:24:36.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 3425 LR: 0.0007464188963224428 Training loss: 0.0
2025-12-09 10:24:36.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 3426 LR: 0.0007462808250093341 Training loss: 0.0
2025-12-09 10:24:36.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 3427 LR: 0.0007461427288957532 Training loss: 0.0
2025-12-09 10:24:36.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 3428 LR: 0.0007460046079956062 Training loss: 0.0
2025-12-09 10:24:36.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 3429 LR: 0.000745866462322802 Training loss: 0.0
2025-12-09 10:24:36.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 3430 LR: 0.0007457282918912516 Training loss: 0.0
2025-12-09 10:24:36.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 3431 LR: 0.000745590096714869 Training loss: 0.0
2025-12-09 10:24:36.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 3432 LR: 0.0007454518768075704 Training loss: 0.0
2025-12-09 10:24:36.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 3433 LR: 0.0007453136321832745 Training loss: 0.0
2025-12-09 10:24:36.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 3434 LR: 0.0007451753628559026 Training loss: 0.0
2025-12-09 10:24:36.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 3435 LR: 0.0007450370688393784 Training loss: 0.0
2025-12-09 10:24:36.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 3436 LR: 0.0007448987501476281 Training loss: 0.0
2025-12-09 10:24:36.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 3437 LR: 0.0007447604067945802 Training loss: 0.0
2025-12-09 10:24:36.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 3438 LR: 0.0007446220387941661 Training loss: 0.0
2025-12-09 10:24:36.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 3439 LR: 0.0007444836461603195 Training loss: 0.0
2025-12-09 10:24:36.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 3440 LR: 0.0007443452289069763 Training loss: 0.0
2025-12-09 10:24:36.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 3441 LR: 0.0007442067870480752 Training loss: 0.0
2025-12-09 10:24:36.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 3442 LR: 0.0007440683205975574 Training loss: 0.0
2025-12-09 10:24:36.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 3443 LR: 0.0007439298295693664 Training loss: 0.0
2025-12-09 10:24:36.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 3444 LR: 0.0007437913139774481 Training loss: 0.0
2025-12-09 10:24:36.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 3445 LR: 0.0007436527738357514 Training loss: 0.0
2025-12-09 10:24:36.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 3446 LR: 0.0007435142091582268 Training loss: 0.0
2025-12-09 10:24:36.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 3447 LR: 0.0007433756199588282 Training loss: 0.0
2025-12-09 10:24:36.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 3448 LR: 0.0007432370062515112 Training loss: 0.0
2025-12-09 10:24:36.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 3449 LR: 0.0007430983680502344 Training loss: 0.0
2025-12-09 10:24:36.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 3450 LR: 0.0007429597053689585 Training loss: 0.0
2025-12-09 10:24:36.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 3451 LR: 0.000742821018221647 Training loss: 0.0
2025-12-09 10:24:36.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 3452 LR: 0.0007426823066222656 Training loss: 0.0
2025-12-09 10:24:36.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 3453 LR: 0.0007425435705847825 Training loss: 0.0
2025-12-09 10:24:36.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 3454 LR: 0.0007424048101231686 Training loss: 0.0
2025-12-09 10:24:36.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 3455 LR: 0.0007422660252513969 Training loss: 0.0
2025-12-09 10:24:36.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 3456 LR: 0.0007421272159834429 Training loss: 0.0
2025-12-09 10:24:36.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 3457 LR: 0.000741988382333285 Training loss: 0.0
2025-12-09 10:24:36.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 3458 LR: 0.0007418495243149038 Training loss: 0.0
2025-12-09 10:24:36.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 3459 LR: 0.0007417106419422819 Training loss: 0.0
2025-12-09 10:24:36.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 3460 LR: 0.0007415717352294051 Training loss: 0.0
2025-12-09 10:24:36.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 3461 LR: 0.000741432804190261 Training loss: 0.0
2025-12-09 10:24:36.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 3462 LR: 0.0007412938488388403 Training loss: 0.0
2025-12-09 10:24:36.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 3463 LR: 0.0007411548691891356 Training loss: 0.0
2025-12-09 10:24:36.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 3464 LR: 0.0007410158652551421 Training loss: 0.0
2025-12-09 10:24:36.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 3465 LR: 0.0007408768370508576 Training loss: 0.0
2025-12-09 10:24:36.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 3466 LR: 0.0007407377845902823 Training loss: 0.0
2025-12-09 10:24:36.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 3467 LR: 0.0007405987078874186 Training loss: 0.0
2025-12-09 10:24:36.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 3468 LR: 0.0007404596069562714 Training loss: 0.0
2025-12-09 10:24:36.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 3469 LR: 0.0007403204818108486 Training loss: 0.0
2025-12-09 10:24:36.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 3470 LR: 0.0007401813324651598 Training loss: 0.0
2025-12-09 10:24:36.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 3471 LR: 0.0007400421589332175 Training loss: 0.0
2025-12-09 10:24:36.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 3472 LR: 0.0007399029612290362 Training loss: 0.0
2025-12-09 10:24:36.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 3473 LR: 0.0007397637393666333 Training loss: 0.0
2025-12-09 10:24:36.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 3474 LR: 0.0007396244933600284 Training loss: 0.0
2025-12-09 10:24:36.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 3475 LR: 0.0007394852232232436 Training loss: 0.0
2025-12-09 10:24:36.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 3476 LR: 0.0007393459289703035 Training loss: 0.0
2025-12-09 10:24:36.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 3477 LR: 0.0007392066106152347 Training loss: 0.0
2025-12-09 10:24:36.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 3478 LR: 0.000739067268172067 Training loss: 0.0
2025-12-09 10:24:36.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 3479 LR: 0.0007389279016548316 Training loss: 0.0
2025-12-09 10:24:36.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 3480 LR: 0.0007387885110775632 Training loss: 0.0
2025-12-09 10:24:36.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 3481 LR: 0.0007386490964542982 Training loss: 0.0
2025-12-09 10:24:36.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 3482 LR: 0.000738509657799076 Training loss: 0.0
2025-12-09 10:24:36.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 3483 LR: 0.0007383701951259375 Training loss: 0.0
2025-12-09 10:24:36.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 3484 LR: 0.0007382307084489269 Training loss: 0.0
2025-12-09 10:24:36.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 3485 LR: 0.0007380911977820907 Training loss: 0.0
2025-12-09 10:24:36.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 3486 LR: 0.0007379516631394772 Training loss: 0.0
2025-12-09 10:24:36.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 3487 LR: 0.0007378121045351377 Training loss: 0.0
2025-12-09 10:24:37.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 3488 LR: 0.0007376725219831258 Training loss: 0.0
2025-12-09 10:24:37.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 3489 LR: 0.0007375329154974975 Training loss: 0.0
2025-12-09 10:24:37.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 3490 LR: 0.0007373932850923111 Training loss: 0.0
2025-12-09 10:24:37.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 3491 LR: 0.0007372536307816273 Training loss: 0.0
2025-12-09 10:24:37.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 3492 LR: 0.0007371139525795094 Training loss: 0.0
2025-12-09 10:24:37.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 3493 LR: 0.0007369742505000232 Training loss: 0.0
2025-12-09 10:24:37.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 3494 LR: 0.0007368345245572362 Training loss: 0.0
2025-12-09 10:24:37.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 3495 LR: 0.0007366947747652191 Training loss: 0.0
2025-12-09 10:24:37.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 3496 LR: 0.0007365550011380446 Training loss: 0.0
2025-12-09 10:24:37.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 3497 LR: 0.0007364152036897882 Training loss: 0.0
2025-12-09 10:24:37.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 3498 LR: 0.0007362753824345271 Training loss: 0.0
2025-12-09 10:24:37.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 3499 LR: 0.0007361355373863414 Training loss: 0.0
2025-12-09 10:24:37.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 3500 LR: 0.0007359956685593136 Training loss: 0.0
2025-12-09 10:24:37.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 3501 LR: 0.0007358557759675284 Training loss: 0.0
2025-12-09 10:24:37.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 3502 LR: 0.000735715859625073 Training loss: 0.0
2025-12-09 10:24:37.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 3503 LR: 0.0007355759195460371 Training loss: 0.0
2025-12-09 10:24:37.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 3504 LR: 0.0007354359557445125 Training loss: 0.0
2025-12-09 10:24:37.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 3505 LR: 0.0007352959682345936 Training loss: 0.0
2025-12-09 10:24:37.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 3506 LR: 0.0007351559570303771 Training loss: 0.0
2025-12-09 10:24:37.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 3507 LR: 0.0007350159221459621 Training loss: 0.0
2025-12-09 10:24:37.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 3508 LR: 0.0007348758635954503 Training loss: 0.0
2025-12-09 10:24:37.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 3509 LR: 0.0007347357813929454 Training loss: 0.0
2025-12-09 10:24:37.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 3510 LR: 0.0007345956755525538 Training loss: 0.0
2025-12-09 10:24:37.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 3511 LR: 0.0007344555460883839 Training loss: 0.0
2025-12-09 10:24:37.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 3512 LR: 0.0007343153930145472 Training loss: 0.0
2025-12-09 10:24:37.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 3513 LR: 0.0007341752163451567 Training loss: 0.0
2025-12-09 10:24:37.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 3514 LR: 0.0007340350160943283 Training loss: 0.0
2025-12-09 10:24:37.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 3515 LR: 0.0007338947922761802 Training loss: 0.0
2025-12-09 10:24:37.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 3516 LR: 0.0007337545449048329 Training loss: 0.0
2025-12-09 10:24:37.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 3517 LR: 0.0007336142739944094 Training loss: 0.0
2025-12-09 10:24:37.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 3518 LR: 0.0007334739795590347 Training loss: 0.0
2025-12-09 10:24:37.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 3519 LR: 0.0007333336616128369 Training loss: 0.0
2025-12-09 10:24:37.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 3520 LR: 0.0007331933201699457 Training loss: 0.0
2025-12-09 10:24:37.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 3521 LR: 0.0007330529552444933 Training loss: 0.0
2025-12-09 10:24:37.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 3522 LR: 0.0007329125668506149 Training loss: 0.0
2025-12-09 10:24:37.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 3523 LR: 0.0007327721550024475 Training loss: 0.0
2025-12-09 10:24:37.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 3524 LR: 0.0007326317197141304 Training loss: 0.0
2025-12-09 10:24:37.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 3525 LR: 0.0007324912609998054 Training loss: 0.0
2025-12-09 10:24:37.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 3526 LR: 0.0007323507788736166 Training loss: 0.0
2025-12-09 10:24:37.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 3527 LR: 0.000732210273349711 Training loss: 0.0
2025-12-09 10:24:37.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 3528 LR: 0.0007320697444422371 Training loss: 0.0
2025-12-09 10:24:37.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 3529 LR: 0.0007319291921653463 Training loss: 0.0
2025-12-09 10:24:37.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 3530 LR: 0.0007317886165331924 Training loss: 0.0
2025-12-09 10:24:37.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 3531 LR: 0.0007316480175599309 Training loss: 0.0
2025-12-09 10:24:37.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 3532 LR: 0.0007315073952597204 Training loss: 0.0
2025-12-09 10:24:37.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 3533 LR: 0.0007313667496467215 Training loss: 0.0
2025-12-09 10:24:37.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 3534 LR: 0.0007312260807350974 Training loss: 0.0
2025-12-09 10:24:37.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 3535 LR: 0.0007310853885390133 Training loss: 0.0
2025-12-09 10:24:37.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 3536 LR: 0.0007309446730726368 Training loss: 0.0
2025-12-09 10:24:37.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 3537 LR: 0.000730803934350138 Training loss: 0.0
2025-12-09 10:24:37.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 3538 LR: 0.0007306631723856895 Training loss: 0.0
2025-12-09 10:24:37.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 3539 LR: 0.0007305223871934656 Training loss: 0.0
2025-12-09 10:24:37.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 3540 LR: 0.0007303815787876438 Training loss: 0.0
2025-12-09 10:24:37.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 3541 LR: 0.0007302407471824032 Training loss: 0.0
2025-12-09 10:24:37.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 3542 LR: 0.0007300998923919259 Training loss: 0.0
2025-12-09 10:24:37.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 3543 LR: 0.0007299590144303954 Training loss: 0.0
2025-12-09 10:24:37.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 3544 LR: 0.0007298181133119987 Training loss: 0.0
2025-12-09 10:24:37.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 3545 LR: 0.0007296771890509242 Training loss: 0.0
2025-12-09 10:24:37.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 3546 LR: 0.000729536241661363 Training loss: 0.0
2025-12-09 10:24:37.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 3547 LR: 0.0007293952711575086 Training loss: 0.0
2025-12-09 10:24:37.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 3548 LR: 0.0007292542775535567 Training loss: 0.0
2025-12-09 10:24:37.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 3549 LR: 0.0007291132608637052 Training loss: 0.0
2025-12-09 10:24:37.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 3550 LR: 0.0007289722211021546 Training loss: 0.0
2025-12-09 10:24:37.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 3551 LR: 0.0007288311582831077 Training loss: 0.0
2025-12-09 10:24:37.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 3552 LR: 0.0007286900724207694 Training loss: 0.0
2025-12-09 10:24:37.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 3553 LR: 0.0007285489635293472 Training loss: 0.0
2025-12-09 10:24:37.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 3554 LR: 0.0007284078316230504 Training loss: 0.0
2025-12-09 10:24:37.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 3555 LR: 0.0007282666767160912 Training loss: 0.0
2025-12-09 10:24:37.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 3556 LR: 0.000728125498822684 Training loss: 0.0
2025-12-09 10:24:37.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 3557 LR: 0.0007279842979570453 Training loss: 0.0
2025-12-09 10:24:37.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 3558 LR: 0.0007278430741333941 Training loss: 0.0
2025-12-09 10:24:37.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 3559 LR: 0.0007277018273659516 Training loss: 0.0
2025-12-09 10:24:37.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 3560 LR: 0.0007275605576689411 Training loss: 0.0
2025-12-09 10:24:37.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 3561 LR: 0.000727419265056589 Training loss: 0.0
2025-12-09 10:24:37.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 3562 LR: 0.0007272779495431228 Training loss: 0.0
2025-12-09 10:24:37.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 3563 LR: 0.0007271366111427734 Training loss: 0.0
2025-12-09 10:24:37.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 3564 LR: 0.0007269952498697733 Training loss: 0.0
2025-12-09 10:24:37.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 3565 LR: 0.0007268538657383581 Training loss: 0.0
2025-12-09 10:24:37.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 3566 LR: 0.0007267124587627647 Training loss: 0.0
2025-12-09 10:24:37.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 3567 LR: 0.0007265710289572328 Training loss: 0.0
2025-12-09 10:24:37.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 3568 LR: 0.0007264295763360045 Training loss: 0.0
2025-12-09 10:24:37.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 3569 LR: 0.0007262881009133242 Training loss: 0.0
2025-12-09 10:24:37.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 3570 LR: 0.0007261466027034383 Training loss: 0.0
2025-12-09 10:24:37.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 3571 LR: 0.0007260050817205955 Training loss: 0.0
2025-12-09 10:24:37.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 3572 LR: 0.0007258635379790474 Training loss: 0.0
2025-12-09 10:24:37.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 3573 LR: 0.0007257219714930471 Training loss: 0.0
2025-12-09 10:24:37.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 3574 LR: 0.0007255803822768504 Training loss: 0.0
2025-12-09 10:24:37.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 3575 LR: 0.0007254387703447154 Training loss: 0.0
2025-12-09 10:24:37.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 3576 LR: 0.0007252971357109025 Training loss: 0.0
2025-12-09 10:24:37.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 3577 LR: 0.0007251554783896741 Training loss: 0.0
2025-12-09 10:24:37.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 3578 LR: 0.0007250137983952951 Training loss: 0.0
2025-12-09 10:24:37.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 3579 LR: 0.0007248720957420329 Training loss: 0.0
2025-12-09 10:24:37.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 3580 LR: 0.0007247303704441568 Training loss: 0.0
2025-12-09 10:24:37.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 3581 LR: 0.0007245886225159386 Training loss: 0.0
2025-12-09 10:24:37.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 3582 LR: 0.0007244468519716521 Training loss: 0.0
2025-12-09 10:24:37.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 3583 LR: 0.0007243050588255737 Training loss: 0.0
2025-12-09 10:24:37.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 3584 LR: 0.0007241632430919822 Training loss: 0.0
2025-12-09 10:24:37.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 3585 LR: 0.0007240214047851582 Training loss: 0.0
2025-12-09 10:24:37.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 3586 LR: 0.0007238795439193849 Training loss: 0.0
2025-12-09 10:24:37.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 3587 LR: 0.0007237376605089477 Training loss: 0.0
2025-12-09 10:24:37.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 3588 LR: 0.000723595754568134 Training loss: 0.0
2025-12-09 10:24:37.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 3589 LR: 0.0007234538261112341 Training loss: 0.0
2025-12-09 10:24:37.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 3590 LR: 0.00072331187515254 Training loss: 0.0
2025-12-09 10:24:37.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 3591 LR: 0.000723169901706346 Training loss: 0.0
2025-12-09 10:24:37.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 3592 LR: 0.0007230279057869494 Training loss: 0.0
2025-12-09 10:24:37.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 3593 LR: 0.0007228858874086485 Training loss: 0.0
2025-12-09 10:24:37.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 3594 LR: 0.0007227438465857447 Training loss: 0.0
2025-12-09 10:24:37.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 3595 LR: 0.000722601783332542 Training loss: 0.0
2025-12-09 10:24:37.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 3596 LR: 0.0007224596976633457 Training loss: 0.0
2025-12-09 10:24:37.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 3597 LR: 0.0007223175895924637 Training loss: 0.0
2025-12-09 10:24:37.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 3598 LR: 0.0007221754591342067 Training loss: 0.0
2025-12-09 10:24:37.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 3599 LR: 0.0007220333063028871 Training loss: 0.0
2025-12-09 10:24:37.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 3600 LR: 0.0007218911311128196 Training loss: 0.0
2025-12-09 10:24:37.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 3601 LR: 0.0007217489335783211 Training loss: 0.0
2025-12-09 10:24:37.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 3602 LR: 0.0007216067137137112 Training loss: 0.0
2025-12-09 10:24:37.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 3603 LR: 0.0007214644715333114 Training loss: 0.0
2025-12-09 10:24:37.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 3604 LR: 0.0007213222070514453 Training loss: 0.0
2025-12-09 10:24:37.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 3605 LR: 0.0007211799202824389 Training loss: 0.0
2025-12-09 10:24:37.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 3606 LR: 0.0007210376112406205 Training loss: 0.0
2025-12-09 10:24:37.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 3607 LR: 0.000720895279940321 Training loss: 0.0
2025-12-09 10:24:37.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 3608 LR: 0.0007207529263958726 Training loss: 0.0
2025-12-09 10:24:37.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 3609 LR: 0.0007206105506216106 Training loss: 0.0
2025-12-09 10:24:37.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 3610 LR: 0.0007204681526318724 Training loss: 0.0
2025-12-09 10:24:37.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 3611 LR: 0.0007203257324409971 Training loss: 0.0
2025-12-09 10:24:37.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 3612 LR: 0.0007201832900633265 Training loss: 0.0
2025-12-09 10:24:37.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 3613 LR: 0.0007200408255132046 Training loss: 0.0
2025-12-09 10:24:37.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 3614 LR: 0.0007198983388049778 Training loss: 0.0
2025-12-09 10:24:37.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 3615 LR: 0.000719755829952994 Training loss: 0.0
2025-12-09 10:24:37.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 3616 LR: 0.0007196132989716044 Training loss: 0.0
2025-12-09 10:24:37.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 3617 LR: 0.0007194707458751615 Training loss: 0.0
2025-12-09 10:24:37.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 3618 LR: 0.0007193281706780206 Training loss: 0.0
2025-12-09 10:24:37.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 3619 LR: 0.0007191855733945387 Training loss: 0.0
2025-12-09 10:24:37.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 3620 LR: 0.0007190429540390757 Training loss: 0.0
2025-12-09 10:24:37.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 3621 LR: 0.0007189003126259932 Training loss: 0.0
2025-12-09 10:24:37.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 3622 LR: 0.0007187576491696552 Training loss: 0.0
2025-12-09 10:24:37.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 3623 LR: 0.000718614963684428 Training loss: 0.0
2025-12-09 10:24:37.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 3624 LR: 0.0007184722561846798 Training loss: 0.0
2025-12-09 10:24:37.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 3625 LR: 0.0007183295266847815 Training loss: 0.0
2025-12-09 10:24:37.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 3626 LR: 0.0007181867751991056 Training loss: 0.0
2025-12-09 10:24:37.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 3627 LR: 0.0007180440017420277 Training loss: 0.0
2025-12-09 10:24:37.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 3628 LR: 0.0007179012063279246 Training loss: 0.0
2025-12-09 10:24:37.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 3629 LR: 0.0007177583889711762 Training loss: 0.0
2025-12-09 10:24:37.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 3630 LR: 0.0007176155496861638 Training loss: 0.0
2025-12-09 10:24:37.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 3631 LR: 0.0007174726884872716 Training loss: 0.0
2025-12-09 10:24:37.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 3632 LR: 0.0007173298053888855 Training loss: 0.0
2025-12-09 10:24:37.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 3633 LR: 0.000717186900405394 Training loss: 0.0
2025-12-09 10:24:37.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 3634 LR: 0.0007170439735511876 Training loss: 0.0
2025-12-09 10:24:37.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 3635 LR: 0.0007169010248406589 Training loss: 0.0
2025-12-09 10:24:37.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 3636 LR: 0.000716758054288203 Training loss: 0.0
2025-12-09 10:24:37.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 3637 LR: 0.0007166150619082171 Training loss: 0.0
2025-12-09 10:24:37.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 3638 LR: 0.0007164720477151002 Training loss: 0.0
2025-12-09 10:24:37.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 3639 LR: 0.0007163290117232541 Training loss: 0.0
2025-12-09 10:24:37.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 3640 LR: 0.0007161859539470824 Training loss: 0.0
2025-12-09 10:24:37.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 3641 LR: 0.0007160428744009912 Training loss: 0.0
2025-12-09 10:24:37.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 3642 LR: 0.0007158997730993883 Training loss: 0.0
2025-12-09 10:24:37.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 3643 LR: 0.0007157566500566843 Training loss: 0.0
2025-12-09 10:24:37.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 3644 LR: 0.0007156135052872914 Training loss: 0.0
2025-12-09 10:24:37.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 3645 LR: 0.0007154703388056245 Training loss: 0.0
2025-12-09 10:24:37.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 3646 LR: 0.0007153271506261003 Training loss: 0.0
2025-12-09 10:24:37.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 3647 LR: 0.000715183940763138 Training loss: 0.0
2025-12-09 10:24:37.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 3648 LR: 0.0007150407092311586 Training loss: 0.0
2025-12-09 10:24:37.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 3649 LR: 0.0007148974560445859 Training loss: 0.0
2025-12-09 10:24:37.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 3650 LR: 0.000714754181217845 Training loss: 0.0
2025-12-09 10:24:37.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 3651 LR: 0.0007146108847653641 Training loss: 0.0
2025-12-09 10:24:37.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 3652 LR: 0.000714467566701573 Training loss: 0.0
2025-12-09 10:24:37.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 3653 LR: 0.0007143242270409038 Training loss: 0.0
2025-12-09 10:24:37.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 3654 LR: 0.0007141808657977907 Training loss: 0.0
2025-12-09 10:24:37.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 3655 LR: 0.0007140374829866702 Training loss: 0.0
2025-12-09 10:24:37.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 3656 LR: 0.0007138940786219813 Training loss: 0.0
2025-12-09 10:24:37.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 3657 LR: 0.0007137506527181643 Training loss: 0.0
2025-12-09 10:24:37.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 3658 LR: 0.0007136072052896625 Training loss: 0.0
2025-12-09 10:24:37.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 3659 LR: 0.0007134637363509209 Training loss: 0.0
2025-12-09 10:24:37.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 3660 LR: 0.0007133202459163871 Training loss: 0.0
2025-12-09 10:24:37.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 3661 LR: 0.0007131767340005102 Training loss: 0.0
2025-12-09 10:24:37.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 3662 LR: 0.000713033200617742 Training loss: 0.0
2025-12-09 10:24:37.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 3663 LR: 0.0007128896457825364 Training loss: 0.0
2025-12-09 10:24:37.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 3664 LR: 0.0007127460695093493 Training loss: 0.0
2025-12-09 10:24:37.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 3665 LR: 0.0007126024718126387 Training loss: 0.0
2025-12-09 10:24:37.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 3666 LR: 0.0007124588527068652 Training loss: 0.0
2025-12-09 10:24:37.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 3667 LR: 0.0007123152122064909 Training loss: 0.0
2025-12-09 10:24:37.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 3668 LR: 0.0007121715503259806 Training loss: 0.0
2025-12-09 10:24:37.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 3669 LR: 0.0007120278670798009 Training loss: 0.0
2025-12-09 10:24:37.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 3670 LR: 0.0007118841624824208 Training loss: 0.0
2025-12-09 10:24:37.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 3671 LR: 0.0007117404365483116 Training loss: 0.0
2025-12-09 10:24:37.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 3672 LR: 0.0007115966892919459 Training loss: 0.0
2025-12-09 10:24:37.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 3673 LR: 0.0007114529207277996 Training loss: 0.0
2025-12-09 10:24:37.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 3674 LR: 0.0007113091308703497 Training loss: 0.0
2025-12-09 10:24:37.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 3675 LR: 0.0007111653197340764 Training loss: 0.0
2025-12-09 10:24:37.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 3676 LR: 0.0007110214873334611 Training loss: 0.0
2025-12-09 10:24:37.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 3677 LR: 0.0007108776336829877 Training loss: 0.0
2025-12-09 10:24:37.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 3678 LR: 0.0007107337587971423 Training loss: 0.0
2025-12-09 10:24:37.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 3679 LR: 0.0007105898626904133 Training loss: 0.0
2025-12-09 10:24:37.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 3680 LR: 0.0007104459453772909 Training loss: 0.0
2025-12-09 10:24:37.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 3681 LR: 0.0007103020068722674 Training loss: 0.0
2025-12-09 10:24:37.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 3682 LR: 0.0007101580471898377 Training loss: 0.0
2025-12-09 10:24:37.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 3683 LR: 0.0007100140663444985 Training loss: 0.0
2025-12-09 10:24:37.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 3684 LR: 0.0007098700643507484 Training loss: 0.0
2025-12-09 10:24:37.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 3685 LR: 0.0007097260412230886 Training loss: 0.0
2025-12-09 10:24:37.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 3686 LR: 0.0007095819969760221 Training loss: 0.0
2025-12-09 10:24:37.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 3687 LR: 0.0007094379316240544 Training loss: 0.0
2025-12-09 10:24:37.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 3688 LR: 0.0007092938451816926 Training loss: 0.0
2025-12-09 10:24:37.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 3689 LR: 0.0007091497376634463 Training loss: 0.0
2025-12-09 10:24:37.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 3690 LR: 0.0007090056090838274 Training loss: 0.0
2025-12-09 10:24:37.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 3691 LR: 0.0007088614594573491 Training loss: 0.0
2025-12-09 10:24:37.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 3692 LR: 0.0007087172887985276 Training loss: 0.0
2025-12-09 10:24:37.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 3693 LR: 0.0007085730971218808 Training loss: 0.0
2025-12-09 10:24:37.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 3694 LR: 0.000708428884441929 Training loss: 0.0
2025-12-09 10:24:37.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 3695 LR: 0.0007082846507731941 Training loss: 0.0
2025-12-09 10:24:37.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 3696 LR: 0.0007081403961302007 Training loss: 0.0
2025-12-09 10:24:37.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 3697 LR: 0.0007079961205274748 Training loss: 0.0
2025-12-09 10:24:37.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 3698 LR: 0.0007078518239795456 Training loss: 0.0
2025-12-09 10:24:37.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 3699 LR: 0.0007077075065009433 Training loss: 0.0
2025-12-09 10:24:37.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 3700 LR: 0.0007075631681062006 Training loss: 0.0
2025-12-09 10:24:37.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 3701 LR: 0.0007074188088098528 Training loss: 0.0
2025-12-09 10:24:37.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 3702 LR: 0.0007072744286264366 Training loss: 0.0
2025-12-09 10:24:37.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 3703 LR: 0.000707130027570491 Training loss: 0.0
2025-12-09 10:24:37.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 3704 LR: 0.0007069856056565573 Training loss: 0.0
2025-12-09 10:24:37.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 3705 LR: 0.0007068411628991788 Training loss: 0.0
2025-12-09 10:24:37.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 3706 LR: 0.0007066966993129008 Training loss: 0.0
2025-12-09 10:24:37.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 3707 LR: 0.000706552214912271 Training loss: 0.0
2025-12-09 10:24:37.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 3708 LR: 0.0007064077097118385 Training loss: 0.0
2025-12-09 10:24:37.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 3709 LR: 0.0007062631837261557 Training loss: 0.0
2025-12-09 10:24:37.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 3710 LR: 0.0007061186369697756 Training loss: 0.0
2025-12-09 10:24:37.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 3711 LR: 0.0007059740694572545 Training loss: 0.0
2025-12-09 10:24:37.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 3712 LR: 0.0007058294812031503 Training loss: 0.0
2025-12-09 10:24:37.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 3713 LR: 0.000705684872222023 Training loss: 0.0
2025-12-09 10:24:37.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 3714 LR: 0.0007055402425284346 Training loss: 0.0
2025-12-09 10:24:37.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 3715 LR: 0.0007053955921369493 Training loss: 0.0
2025-12-09 10:24:37.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 3716 LR: 0.0007052509210621336 Training loss: 0.0
2025-12-09 10:24:37.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 3717 LR: 0.000705106229318556 Training loss: 0.0
2025-12-09 10:24:37.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 3718 LR: 0.0007049615169207864 Training loss: 0.0
2025-12-09 10:24:37.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 3719 LR: 0.0007048167838833977 Training loss: 0.0
2025-12-09 10:24:37.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 3720 LR: 0.0007046720302209646 Training loss: 0.0
2025-12-09 10:24:37.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 3721 LR: 0.0007045272559480636 Training loss: 0.0
2025-12-09 10:24:37.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 3722 LR: 0.0007043824610792735 Training loss: 0.0
2025-12-09 10:24:37.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 3723 LR: 0.0007042376456291751 Training loss: 0.0
2025-12-09 10:24:37.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 3724 LR: 0.0007040928096123516 Training loss: 0.0
2025-12-09 10:24:37.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 3725 LR: 0.0007039479530433874 Training loss: 0.0
2025-12-09 10:24:37.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 3726 LR: 0.0007038030759368702 Training loss: 0.0
2025-12-09 10:24:37.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 3727 LR: 0.0007036581783073887 Training loss: 0.0
2025-12-09 10:24:37.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 3728 LR: 0.0007035132601695344 Training loss: 0.0
2025-12-09 10:24:37.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 3729 LR: 0.0007033683215379002 Training loss: 0.0
2025-12-09 10:24:37.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 3730 LR: 0.0007032233624270816 Training loss: 0.0
2025-12-09 10:24:37.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 3731 LR: 0.0007030783828516759 Training loss: 0.0
2025-12-09 10:24:37.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 3732 LR: 0.0007029333828262827 Training loss: 0.0
2025-12-09 10:24:37.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 3733 LR: 0.0007027883623655035 Training loss: 0.0
2025-12-09 10:24:37.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 3734 LR: 0.0007026433214839417 Training loss: 0.0
2025-12-09 10:24:37.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 3735 LR: 0.0007024982601962027 Training loss: 0.0
2025-12-09 10:24:37.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 3736 LR: 0.0007023531785168947 Training loss: 0.0
2025-12-09 10:24:37.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 3737 LR: 0.0007022080764606272 Training loss: 0.0
2025-12-09 10:24:37.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 3738 LR: 0.0007020629540420118 Training loss: 0.0
2025-12-09 10:24:37.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 3739 LR: 0.0007019178112756625 Training loss: 0.0
2025-12-09 10:24:37.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 3740 LR: 0.0007017726481761951 Training loss: 0.0
2025-12-09 10:24:37.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 3741 LR: 0.0007016274647582276 Training loss: 0.0
2025-12-09 10:24:37.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 3742 LR: 0.0007014822610363798 Training loss: 0.0
2025-12-09 10:24:37.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 3743 LR: 0.0007013370370252739 Training loss: 0.0
2025-12-09 10:24:37.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 3744 LR: 0.000701191792739534 Training loss: 0.0
2025-12-09 10:24:37.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 3745 LR: 0.0007010465281937859 Training loss: 0.0
2025-12-09 10:24:37.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 3746 LR: 0.000700901243402658 Training loss: 0.0
2025-12-09 10:24:37.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 3747 LR: 0.0007007559383807804 Training loss: 0.0
2025-12-09 10:24:37.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 3748 LR: 0.0007006106131427853 Training loss: 0.0
2025-12-09 10:24:37.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 3749 LR: 0.0007004652677033068 Training loss: 0.0
2025-12-09 10:24:37.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 3750 LR: 0.0007003199020769815 Training loss: 0.0
2025-12-09 10:24:37.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 3751 LR: 0.0007001745162784476 Training loss: 0.0
2025-12-09 10:24:37.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 3752 LR: 0.0007000291103223452 Training loss: 0.0
2025-12-09 10:24:37.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 3753 LR: 0.0006998836842233169 Training loss: 0.0
2025-12-09 10:24:37.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 3754 LR: 0.0006997382379960071 Training loss: 0.0
2025-12-09 10:24:37.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 3755 LR: 0.0006995927716550623 Training loss: 0.0
2025-12-09 10:24:37.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 3756 LR: 0.0006994472852151308 Training loss: 0.0
2025-12-09 10:24:37.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 3757 LR: 0.000699301778690863 Training loss: 0.0
2025-12-09 10:24:37.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 3758 LR: 0.0006991562520969116 Training loss: 0.0
2025-12-09 10:24:37.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 3759 LR: 0.0006990107054479312 Training loss: 0.0
2025-12-09 10:24:37.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 3760 LR: 0.0006988651387585781 Training loss: 0.0
2025-12-09 10:24:37.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 3761 LR: 0.0006987195520435109 Training loss: 0.0
2025-12-09 10:24:37.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 3762 LR: 0.0006985739453173903 Training loss: 0.0
2025-12-09 10:24:37.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 3763 LR: 0.000698428318594879 Training loss: 0.0
2025-12-09 10:24:37.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 3764 LR: 0.0006982826718906413 Training loss: 0.0
2025-12-09 10:24:37.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 3765 LR: 0.0006981370052193439 Training loss: 0.0
2025-12-09 10:24:37.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 3766 LR: 0.0006979913185956555 Training loss: 0.0
2025-12-09 10:24:37.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 3767 LR: 0.0006978456120342468 Training loss: 0.0
2025-12-09 10:24:37.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 3768 LR: 0.0006976998855497905 Training loss: 0.0
2025-12-09 10:24:37.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 3769 LR: 0.000697554139156961 Training loss: 0.0
2025-12-09 10:24:37.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 3770 LR: 0.0006974083728704351 Training loss: 0.0
2025-12-09 10:24:37.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 3771 LR: 0.0006972625867048914 Training loss: 0.0
2025-12-09 10:24:37.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 3772 LR: 0.0006971167806750108 Training loss: 0.0
2025-12-09 10:24:37.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 3773 LR: 0.0006969709547954755 Training loss: 0.0
2025-12-09 10:24:37.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 3774 LR: 0.0006968251090809707 Training loss: 0.0
2025-12-09 10:24:37.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 3775 LR: 0.0006966792435461827 Training loss: 0.0
2025-12-09 10:24:37.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 3776 LR: 0.0006965333582058002 Training loss: 0.0
2025-12-09 10:24:37.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 3777 LR: 0.000696387453074514 Training loss: 0.0
2025-12-09 10:24:37.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 3778 LR: 0.0006962415281670167 Training loss: 0.0
2025-12-09 10:24:37.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 3779 LR: 0.0006960955834980027 Training loss: 0.0
2025-12-09 10:24:37.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 3780 LR: 0.000695949619082169 Training loss: 0.0
2025-12-09 10:24:37.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 3781 LR: 0.000695803634934214 Training loss: 0.0
2025-12-09 10:24:37.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 3782 LR: 0.0006956576310688382 Training loss: 0.0
2025-12-09 10:24:37.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 3783 LR: 0.0006955116075007443 Training loss: 0.0
2025-12-09 10:24:37.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 3784 LR: 0.0006953655642446368 Training loss: 0.0
2025-12-09 10:24:37.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 3785 LR: 0.0006952195013152226 Training loss: 0.0
2025-12-09 10:24:37.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 3786 LR: 0.0006950734187272097 Training loss: 0.0
2025-12-09 10:24:37.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 3787 LR: 0.000694927316495309 Training loss: 0.0
2025-12-09 10:24:37.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 3788 LR: 0.0006947811946342329 Training loss: 0.0
2025-12-09 10:24:37.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 3789 LR: 0.0006946350531586958 Training loss: 0.0
2025-12-09 10:24:37.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 3790 LR: 0.0006944888920834141 Training loss: 0.0
2025-12-09 10:24:37.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 3791 LR: 0.0006943427114231063 Training loss: 0.0
2025-12-09 10:24:37.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 3792 LR: 0.0006941965111924929 Training loss: 0.0
2025-12-09 10:24:37.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 3793 LR: 0.0006940502914062961 Training loss: 0.0
2025-12-09 10:24:37.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 3794 LR: 0.0006939040520792401 Training loss: 0.0
2025-12-09 10:24:37.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 3795 LR: 0.0006937577932260515 Training loss: 0.0
2025-12-09 10:24:37.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 3796 LR: 0.0006936115148614584 Training loss: 0.0
2025-12-09 10:24:37.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 3797 LR: 0.000693465217000191 Training loss: 0.0
2025-12-09 10:24:37.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 3798 LR: 0.0006933188996569817 Training loss: 0.0
2025-12-09 10:24:37.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 3799 LR: 0.0006931725628465643 Training loss: 0.0
2025-12-09 10:24:37.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 3800 LR: 0.0006930262065836752 Training loss: 0.0
2025-12-09 10:24:37.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 3801 LR: 0.0006928798308830524 Training loss: 0.0
2025-12-09 10:24:37.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 3802 LR: 0.000692733435759436 Training loss: 0.0
2025-12-09 10:24:37.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 3803 LR: 0.0006925870212275676 Training loss: 0.0
2025-12-09 10:24:37.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 3804 LR: 0.0006924405873021917 Training loss: 0.0
2025-12-09 10:24:37.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 3805 LR: 0.0006922941339980537 Training loss: 0.0
2025-12-09 10:24:37.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 3806 LR: 0.0006921476613299018 Training loss: 0.0
2025-12-09 10:24:37.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 3807 LR: 0.0006920011693124857 Training loss: 0.0
2025-12-09 10:24:37.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 3808 LR: 0.0006918546579605571 Training loss: 0.0
2025-12-09 10:24:37.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 3809 LR: 0.0006917081272888696 Training loss: 0.0
2025-12-09 10:24:37.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 3810 LR: 0.000691561577312179 Training loss: 0.0
2025-12-09 10:24:37.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 3811 LR: 0.0006914150080452428 Training loss: 0.0
2025-12-09 10:24:37.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 3812 LR: 0.0006912684195028207 Training loss: 0.0
2025-12-09 10:24:37.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 3813 LR: 0.0006911218116996737 Training loss: 0.0
2025-12-09 10:24:37.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 3814 LR: 0.0006909751846505656 Training loss: 0.0
2025-12-09 10:24:37.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 3815 LR: 0.0006908285383702616 Training loss: 0.0
2025-12-09 10:24:37.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 3816 LR: 0.0006906818728735292 Training loss: 0.0
2025-12-09 10:24:37.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 3817 LR: 0.0006905351881751372 Training loss: 0.0
2025-12-09 10:24:37.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 3818 LR: 0.0006903884842898569 Training loss: 0.0
2025-12-09 10:24:37.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 3819 LR: 0.0006902417612324615 Training loss: 0.0
2025-12-09 10:24:37.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 3820 LR: 0.0006900950190177262 Training loss: 0.0
2025-12-09 10:24:37.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 3821 LR: 0.0006899482576604274 Training loss: 0.0
2025-12-09 10:24:37.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 3822 LR: 0.0006898014771753444 Training loss: 0.0
2025-12-09 10:24:37.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 3823 LR: 0.0006896546775772576 Training loss: 0.0
2025-12-09 10:24:37.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 3824 LR: 0.0006895078588809502 Training loss: 0.0
2025-12-09 10:24:37.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 3825 LR: 0.0006893610211012067 Training loss: 0.0
2025-12-09 10:24:37.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 3826 LR: 0.0006892141642528133 Training loss: 0.0
2025-12-09 10:24:37.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 3827 LR: 0.0006890672883505588 Training loss: 0.0
2025-12-09 10:24:37.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 3828 LR: 0.0006889203934092337 Training loss: 0.0
2025-12-09 10:24:37.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 3829 LR: 0.00068877347944363 Training loss: 0.0
2025-12-09 10:24:37.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 3830 LR: 0.0006886265464685421 Training loss: 0.0
2025-12-09 10:24:37.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 3831 LR: 0.0006884795944987661 Training loss: 0.0
2025-12-09 10:24:37.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 3832 LR: 0.0006883326235491001 Training loss: 0.0
2025-12-09 10:24:37.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 3833 LR: 0.0006881856336343441 Training loss: 0.0
2025-12-09 10:24:37.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 3834 LR: 0.0006880386247692999 Training loss: 0.0
2025-12-09 10:24:37.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 3835 LR: 0.0006878915969687714 Training loss: 0.0
2025-12-09 10:24:37.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 3836 LR: 0.0006877445502475642 Training loss: 0.0
2025-12-09 10:24:37.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 3837 LR: 0.0006875974846204859 Training loss: 0.0
2025-12-09 10:24:37.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 3838 LR: 0.000687450400102346 Training loss: 0.0
2025-12-09 10:24:37.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 3839 LR: 0.0006873032967079561 Training loss: 0.0
2025-12-09 10:24:37.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 3840 LR: 0.0006871561744521291 Training loss: 0.0
2025-12-09 10:24:37.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 3841 LR: 0.0006870090333496807 Training loss: 0.0
2025-12-09 10:24:37.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 3842 LR: 0.0006868618734154276 Training loss: 0.0
2025-12-09 10:24:37.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 3843 LR: 0.0006867146946641891 Training loss: 0.0
2025-12-09 10:24:37.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 3844 LR: 0.0006865674971107858 Training loss: 0.0
2025-12-09 10:24:37.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 3845 LR: 0.0006864202807700407 Training loss: 0.0
2025-12-09 10:24:37.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 3846 LR: 0.0006862730456567785 Training loss: 0.0
2025-12-09 10:24:37.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 3847 LR: 0.0006861257917858257 Training loss: 0.0
2025-12-09 10:24:37.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 3848 LR: 0.0006859785191720106 Training loss: 0.0
2025-12-09 10:24:37.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 3849 LR: 0.0006858312278301637 Training loss: 0.0
2025-12-09 10:24:37.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 3850 LR: 0.0006856839177751175 Training loss: 0.0
2025-12-09 10:24:37.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 3851 LR: 0.0006855365890217057 Training loss: 0.0
2025-12-09 10:24:37.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 3852 LR: 0.0006853892415847645 Training loss: 0.0
2025-12-09 10:24:37.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 3853 LR: 0.0006852418754791316 Training loss: 0.0
2025-12-09 10:24:37.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 3854 LR: 0.0006850944907196471 Training loss: 0.0
2025-12-09 10:24:37.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 3855 LR: 0.0006849470873211522 Training loss: 0.0
2025-12-09 10:24:37.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 3856 LR: 0.0006847996652984909 Training loss: 0.0
2025-12-09 10:24:37.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 3857 LR: 0.0006846522246665084 Training loss: 0.0
2025-12-09 10:24:37.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 3858 LR: 0.0006845047654400518 Training loss: 0.0
2025-12-09 10:24:37.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 3859 LR: 0.0006843572876339704 Training loss: 0.0
2025-12-09 10:24:37.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 3860 LR: 0.0006842097912631151 Training loss: 0.0
2025-12-09 10:24:37.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 3861 LR: 0.0006840622763423391 Training loss: 0.0
2025-12-09 10:24:37.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 3862 LR: 0.0006839147428864967 Training loss: 0.0
2025-12-09 10:24:37.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 3863 LR: 0.0006837671909104447 Training loss: 0.0
2025-12-09 10:24:37.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 3864 LR: 0.0006836196204290417 Training loss: 0.0
2025-12-09 10:24:37.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 3865 LR: 0.0006834720314571479 Training loss: 0.0
2025-12-09 10:24:37.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 3866 LR: 0.0006833244240096256 Training loss: 0.0
2025-12-09 10:24:37.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 3867 LR: 0.0006831767981013388 Training loss: 0.0
2025-12-09 10:24:37.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 3868 LR: 0.0006830291537471534 Training loss: 0.0
2025-12-09 10:24:37.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 3869 LR: 0.0006828814909619373 Training loss: 0.0
2025-12-09 10:24:37.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 3870 LR: 0.00068273380976056 Training loss: 0.0
2025-12-09 10:24:37.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 3871 LR: 0.0006825861101578931 Training loss: 0.0
2025-12-09 10:24:37.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 3872 LR: 0.0006824383921688097 Training loss: 0.0
2025-12-09 10:24:37.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 3873 LR: 0.0006822906558081856 Training loss: 0.0
2025-12-09 10:24:37.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 3874 LR: 0.0006821429010908972 Training loss: 0.0
2025-12-09 10:24:37.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 3875 LR: 0.0006819951280318237 Training loss: 0.0
2025-12-09 10:24:37.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 3876 LR: 0.0006818473366458457 Training loss: 0.0
2025-12-09 10:24:37.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 3877 LR: 0.000681699526947846 Training loss: 0.0
2025-12-09 10:24:37.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 3878 LR: 0.0006815516989527087 Training loss: 0.0
2025-12-09 10:24:37.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 3879 LR: 0.0006814038526753205 Training loss: 0.0
2025-12-09 10:24:37.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 3880 LR: 0.0006812559881305693 Training loss: 0.0
2025-12-09 10:24:37.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 3881 LR: 0.000681108105333345 Training loss: 0.0
2025-12-09 10:24:37.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 3882 LR: 0.0006809602042985393 Training loss: 0.0
2025-12-09 10:24:37.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 3883 LR: 0.000680812285041046 Training loss: 0.0
2025-12-09 10:24:37.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 3884 LR: 0.0006806643475757608 Training loss: 0.0
2025-12-09 10:24:37.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 3885 LR: 0.0006805163919175807 Training loss: 0.0
2025-12-09 10:24:37.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 3886 LR: 0.0006803684180814047 Training loss: 0.0
2025-12-09 10:24:37.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 3887 LR: 0.0006802204260821339 Training loss: 0.0
2025-12-09 10:24:37.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 3888 LR: 0.0006800724159346714 Training loss: 0.0
2025-12-09 10:24:37.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 3889 LR: 0.0006799243876539213 Training loss: 0.0
2025-12-09 10:24:37.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 3890 LR: 0.0006797763412547904 Training loss: 0.0
2025-12-09 10:24:37.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 3891 LR: 0.0006796282767521869 Training loss: 0.0
2025-12-09 10:24:37.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 3892 LR: 0.0006794801941610207 Training loss: 0.0
2025-12-09 10:24:37.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 3893 LR: 0.0006793320934962039 Training loss: 0.0
2025-12-09 10:24:37.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 3894 LR: 0.0006791839747726501 Training loss: 0.0
2025-12-09 10:24:37.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 3895 LR: 0.0006790358380052751 Training loss: 0.0
2025-12-09 10:24:37.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 3896 LR: 0.0006788876832089961 Training loss: 0.0
2025-12-09 10:24:37.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 3897 LR: 0.0006787395103987323 Training loss: 0.0
2025-12-09 10:24:37.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 3898 LR: 0.0006785913195894047 Training loss: 0.0
2025-12-09 10:24:37.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 3899 LR: 0.0006784431107959359 Training loss: 0.0
2025-12-09 10:24:37.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 3900 LR: 0.000678294884033251 Training loss: 0.0
2025-12-09 10:24:37.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 3901 LR: 0.000678146639316276 Training loss: 0.0
2025-12-09 10:24:37.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 3902 LR: 0.0006779983766599393 Training loss: 0.0
2025-12-09 10:24:37.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 3903 LR: 0.0006778500960791709 Training loss: 0.0
2025-12-09 10:24:37.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 3904 LR: 0.000677701797588903 Training loss: 0.0
2025-12-09 10:24:37.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 3905 LR: 0.0006775534812040686 Training loss: 0.0
2025-12-09 10:24:37.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 3906 LR: 0.0006774051469396037 Training loss: 0.0
2025-12-09 10:24:37.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 3907 LR: 0.0006772567948104452 Training loss: 0.0
2025-12-09 10:24:37.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 3908 LR: 0.0006771084248315323 Training loss: 0.0
2025-12-09 10:24:37.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 3909 LR: 0.0006769600370178059 Training loss: 0.0
2025-12-09 10:24:37.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 3910 LR: 0.0006768116313842087 Training loss: 0.0
2025-12-09 10:24:37.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 3911 LR: 0.0006766632079456852 Training loss: 0.0
2025-12-09 10:24:37.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 3912 LR: 0.0006765147667171812 Training loss: 0.0
2025-12-09 10:24:37.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 3913 LR: 0.000676366307713645 Training loss: 0.0
2025-12-09 10:24:37.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 3914 LR: 0.0006762178309500267 Training loss: 0.0
2025-12-09 10:24:37.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 3915 LR: 0.0006760693364412776 Training loss: 0.0
2025-12-09 10:24:37.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 3916 LR: 0.0006759208242023509 Training loss: 0.0
2025-12-09 10:24:37.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 3917 LR: 0.0006757722942482022 Training loss: 0.0
2025-12-09 10:24:37.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 3918 LR: 0.0006756237465937882 Training loss: 0.0
2025-12-09 10:24:37.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 3919 LR: 0.0006754751812540679 Training loss: 0.0
2025-12-09 10:24:37.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 3920 LR: 0.0006753265982440014 Training loss: 0.0
2025-12-09 10:24:37.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 3921 LR: 0.0006751779975785515 Training loss: 0.0
2025-12-09 10:24:37.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 3922 LR: 0.0006750293792726819 Training loss: 0.0
2025-12-09 10:24:37.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 3923 LR: 0.0006748807433413586 Training loss: 0.0
2025-12-09 10:24:37.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 3924 LR: 0.0006747320897995492 Training loss: 0.0
2025-12-09 10:24:37.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 3925 LR: 0.0006745834186622231 Training loss: 0.0
2025-12-09 10:24:37.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 3926 LR: 0.0006744347299443517 Training loss: 0.0
2025-12-09 10:24:37.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 3927 LR: 0.0006742860236609076 Training loss: 0.0
2025-12-09 10:24:37.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 3928 LR: 0.0006741372998268658 Training loss: 0.0
2025-12-09 10:24:37.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 3929 LR: 0.0006739885584572025 Training loss: 0.0
2025-12-09 10:24:37.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 3930 LR: 0.0006738397995668965 Training loss: 0.0
2025-12-09 10:24:37.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 3931 LR: 0.000673691023170927 Training loss: 0.0
2025-12-09 10:24:37.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 3932 LR: 0.0006735422292842764 Training loss: 0.0
2025-12-09 10:24:37.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 3933 LR: 0.0006733934179219281 Training loss: 0.0
2025-12-09 10:24:37.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 3934 LR: 0.0006732445890988675 Training loss: 0.0
2025-12-09 10:24:37.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 3935 LR: 0.0006730957428300813 Training loss: 0.0
2025-12-09 10:24:37.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 3936 LR: 0.0006729468791305584 Training loss: 0.0
2025-12-09 10:24:37.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 3937 LR: 0.0006727979980152898 Training loss: 0.0
2025-12-09 10:24:37.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 3938 LR: 0.0006726490994992673 Training loss: 0.0
2025-12-09 10:24:37.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 3939 LR: 0.0006725001835974853 Training loss: 0.0
2025-12-09 10:24:37.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 3940 LR: 0.0006723512503249396 Training loss: 0.0
2025-12-09 10:24:37.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 3941 LR: 0.0006722022996966278 Training loss: 0.0
2025-12-09 10:24:37.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 3942 LR: 0.0006720533317275489 Training loss: 0.0
2025-12-09 10:24:37.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 3943 LR: 0.0006719043464327042 Training loss: 0.0
2025-12-09 10:24:37.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 3944 LR: 0.0006717553438270966 Training loss: 0.0
2025-12-09 10:24:37.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 3945 LR: 0.0006716063239257306 Training loss: 0.0
2025-12-09 10:24:37.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 3946 LR: 0.0006714572867436126 Training loss: 0.0
2025-12-09 10:24:37.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 3947 LR: 0.0006713082322957503 Training loss: 0.0
2025-12-09 10:24:37.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 3948 LR: 0.0006711591605971537 Training loss: 0.0
2025-12-09 10:24:37.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 3949 LR: 0.0006710100716628344 Training loss: 0.0
2025-12-09 10:24:37.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 3950 LR: 0.0006708609655078056 Training loss: 0.0
2025-12-09 10:24:37.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 3951 LR: 0.0006707118421470822 Training loss: 0.0
2025-12-09 10:24:37.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 3952 LR: 0.0006705627015956807 Training loss: 0.0
2025-12-09 10:24:37.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 3953 LR: 0.0006704135438686203 Training loss: 0.0
2025-12-09 10:24:37.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 3954 LR: 0.0006702643689809204 Training loss: 0.0
2025-12-09 10:24:37.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 3955 LR: 0.0006701151769476033 Training loss: 0.0
2025-12-09 10:24:37.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 3956 LR: 0.0006699659677836926 Training loss: 0.0
2025-12-09 10:24:37.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 3957 LR: 0.0006698167415042134 Training loss: 0.0
2025-12-09 10:24:37.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 3958 LR: 0.000669667498124193 Training loss: 0.0
2025-12-09 10:24:37.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 3959 LR: 0.0006695182376586602 Training loss: 0.0
2025-12-09 10:24:37.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 3960 LR: 0.0006693689601226458 Training loss: 0.0
2025-12-09 10:24:37.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 3961 LR: 0.0006692196655311814 Training loss: 0.0
2025-12-09 10:24:37.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 3962 LR: 0.0006690703538993015 Training loss: 0.0
2025-12-09 10:24:37.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 3963 LR: 0.0006689210252420415 Training loss: 0.0
2025-12-09 10:24:37.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 3964 LR: 0.000668771679574439 Training loss: 0.0
2025-12-09 10:24:37.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 3965 LR: 0.0006686223169115327 Training loss: 0.0
2025-12-09 10:24:37.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 3966 LR: 0.0006684729372683639 Training loss: 0.0
2025-12-09 10:24:37.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 3967 LR: 0.0006683235406599749 Training loss: 0.0
2025-12-09 10:24:37.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 3968 LR: 0.00066817412710141 Training loss: 0.0
2025-12-09 10:24:37.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 3969 LR: 0.000668024696607715 Training loss: 0.0
2025-12-09 10:24:37.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 3970 LR: 0.0006678752491939377 Training loss: 0.0
2025-12-09 10:24:37.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 3971 LR: 0.0006677257848751275 Training loss: 0.0
2025-12-09 10:24:37.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 3972 LR: 0.0006675763036663354 Training loss: 0.0
2025-12-09 10:24:37.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 3973 LR: 0.0006674268055826138 Training loss: 0.0
2025-12-09 10:24:37.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 3974 LR: 0.0006672772906390176 Training loss: 0.0
2025-12-09 10:24:37.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 3975 LR: 0.0006671277588506029 Training loss: 0.0
2025-12-09 10:24:37.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 3976 LR: 0.0006669782102324274 Training loss: 0.0
2025-12-09 10:24:37.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 3977 LR: 0.0006668286447995507 Training loss: 0.0
2025-12-09 10:24:37.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 3978 LR: 0.000666679062567034 Training loss: 0.0
2025-12-09 10:24:37.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 3979 LR: 0.0006665294635499404 Training loss: 0.0
2025-12-09 10:24:37.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 3980 LR: 0.0006663798477633343 Training loss: 0.0
2025-12-09 10:24:37.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 3981 LR: 0.000666230215222282 Training loss: 0.0
2025-12-09 10:24:37.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 3982 LR: 0.0006660805659418516 Training loss: 0.0
2025-12-09 10:24:37.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 3983 LR: 0.000665930899937113 Training loss: 0.0
2025-12-09 10:24:37.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 3984 LR: 0.000665781217223137 Training loss: 0.0
2025-12-09 10:24:37.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 3985 LR: 0.0006656315178149971 Training loss: 0.0
2025-12-09 10:24:37.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 3986 LR: 0.0006654818017277677 Training loss: 0.0
2025-12-09 10:24:37.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 3987 LR: 0.0006653320689765257 Training loss: 0.0
2025-12-09 10:24:37.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 3988 LR: 0.0006651823195763486 Training loss: 0.0
2025-12-09 10:24:37.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 3989 LR: 0.0006650325535423167 Training loss: 0.0
2025-12-09 10:24:37.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 3990 LR: 0.000664882770889511 Training loss: 0.0
2025-12-09 10:24:37.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 3991 LR: 0.0006647329716330148 Training loss: 0.0
2025-12-09 10:24:37.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 3992 LR: 0.0006645831557879129 Training loss: 0.0
2025-12-09 10:24:37.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 3993 LR: 0.0006644333233692916 Training loss: 0.0
2025-12-09 10:24:37.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 3994 LR: 0.0006642834743922392 Training loss: 0.0
2025-12-09 10:24:37.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 3995 LR: 0.0006641336088718456 Training loss: 0.0
2025-12-09 10:24:37.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 3996 LR: 0.0006639837268232018 Training loss: 0.0
2025-12-09 10:24:37.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 3997 LR: 0.0006638338282614014 Training loss: 0.0
2025-12-09 10:24:37.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 3998 LR: 0.0006636839132015389 Training loss: 0.0
2025-12-09 10:24:37.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 3999 LR: 0.0006635339816587109 Training loss: 0.0
2025-12-09 10:24:37.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 4000 LR: 0.0006633840336480154 Training loss: 0.0
2025-12-09 10:24:37.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 4001 LR: 0.0006632340691845519 Training loss: 0.0
2025-12-09 10:24:37.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 4002 LR: 0.0006630840882834225 Training loss: 0.0
2025-12-09 10:24:37.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 4003 LR: 0.0006629340909597297 Training loss: 0.0
2025-12-09 10:24:37.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 4004 LR: 0.0006627840772285784 Training loss: 0.0
2025-12-09 10:24:37.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 4005 LR: 0.0006626340471050749 Training loss: 0.0
2025-12-09 10:24:37.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 4006 LR: 0.0006624840006043274 Training loss: 0.0
2025-12-09 10:24:37.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 4007 LR: 0.0006623339377414456 Training loss: 0.0
2025-12-09 10:24:37.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 4008 LR: 0.0006621838585315405 Training loss: 0.0
2025-12-09 10:24:37.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 4009 LR: 0.0006620337629897252 Training loss: 0.0
2025-12-09 10:24:37.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 4010 LR: 0.0006618836511311148 Training loss: 0.0
2025-12-09 10:24:37.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 4011 LR: 0.0006617335229708249 Training loss: 0.0
2025-12-09 10:24:37.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 4012 LR: 0.0006615833785239737 Training loss: 0.0
2025-12-09 10:24:37.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 4013 LR: 0.0006614332178056805 Training loss: 0.0
2025-12-09 10:24:37.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 4014 LR: 0.0006612830408310671 Training loss: 0.0
2025-12-09 10:24:37.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 4015 LR: 0.0006611328476152556 Training loss: 0.0
2025-12-09 10:24:37.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 4016 LR: 0.0006609826381733708 Training loss: 0.0
2025-12-09 10:24:37.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 4017 LR: 0.0006608324125205389 Training loss: 0.0
2025-12-09 10:24:37.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 4018 LR: 0.0006606821706718873 Training loss: 0.0
2025-12-09 10:24:37.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 4019 LR: 0.0006605319126425454 Training loss: 0.0
2025-12-09 10:24:37.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 4020 LR: 0.0006603816384476444 Training loss: 0.0
2025-12-09 10:24:37.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 4021 LR: 0.000660231348102317 Training loss: 0.0
2025-12-09 10:24:37.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 4022 LR: 0.000660081041621697 Training loss: 0.0
2025-12-09 10:24:37.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 4023 LR: 0.0006599307190209205 Training loss: 0.0
2025-12-09 10:24:37.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 4024 LR: 0.000659780380315125 Training loss: 0.0
2025-12-09 10:24:37.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 4025 LR: 0.0006596300255194496 Training loss: 0.0
2025-12-09 10:24:37.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 4026 LR: 0.000659479654649035 Training loss: 0.0
2025-12-09 10:24:37.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 4027 LR: 0.0006593292677190234 Training loss: 0.0
2025-12-09 10:24:37.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 4028 LR: 0.0006591788647445591 Training loss: 0.0
2025-12-09 10:24:37.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 4029 LR: 0.0006590284457407876 Training loss: 0.0
2025-12-09 10:24:37.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 4030 LR: 0.0006588780107228557 Training loss: 0.0
2025-12-09 10:24:37.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 4031 LR: 0.0006587275597059125 Training loss: 0.0
2025-12-09 10:24:37.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 4032 LR: 0.0006585770927051085 Training loss: 0.0
2025-12-09 10:24:37.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 4033 LR: 0.0006584266097355954 Training loss: 0.0
2025-12-09 10:24:37.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 4034 LR: 0.0006582761108125272 Training loss: 0.0
2025-12-09 10:24:37.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 4035 LR: 0.000658125595951059 Training loss: 0.0
2025-12-09 10:24:37.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 4036 LR: 0.0006579750651663476 Training loss: 0.0
2025-12-09 10:24:37.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 4037 LR: 0.0006578245184735513 Training loss: 0.0
2025-12-09 10:24:37.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 4038 LR: 0.0006576739558878304 Training loss: 0.0
2025-12-09 10:24:37.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 4039 LR: 0.0006575233774243465 Training loss: 0.0
2025-12-09 10:24:37.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 4040 LR: 0.0006573727830982628 Training loss: 0.0
2025-12-09 10:24:37.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 4041 LR: 0.000657222172924744 Training loss: 0.0
2025-12-09 10:24:37.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 4042 LR: 0.0006570715469189568 Training loss: 0.0
2025-12-09 10:24:37.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 4043 LR: 0.0006569209050960691 Training loss: 0.0
2025-12-09 10:24:37.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 4044 LR: 0.0006567702474712507 Training loss: 0.0
2025-12-09 10:24:37.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 4045 LR: 0.0006566195740596725 Training loss: 0.0
2025-12-09 10:24:37.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 4046 LR: 0.0006564688848765075 Training loss: 0.0
2025-12-09 10:24:37.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 4047 LR: 0.0006563181799369301 Training loss: 0.0
2025-12-09 10:24:37.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 4048 LR: 0.0006561674592561164 Training loss: 0.0
2025-12-09 10:24:37.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 4049 LR: 0.0006560167228492435 Training loss: 0.0
2025-12-09 10:24:37.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 4050 LR: 0.0006558659707314911 Training loss: 0.0
2025-12-09 10:24:37.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 4051 LR: 0.0006557152029180398 Training loss: 0.0
2025-12-09 10:24:37.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 4052 LR: 0.0006555644194240716 Training loss: 0.0
2025-12-09 10:24:37.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 4053 LR: 0.0006554136202647707 Training loss: 0.0
2025-12-09 10:24:37.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 4054 LR: 0.0006552628054553224 Training loss: 0.0
2025-12-09 10:24:37.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 4055 LR: 0.0006551119750109141 Training loss: 0.0
2025-12-09 10:24:37.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 4056 LR: 0.000654961128946734 Training loss: 0.0
2025-12-09 10:24:37.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 4057 LR: 0.0006548102672779725 Training loss: 0.0
2025-12-09 10:24:37.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 4058 LR: 0.0006546593900198213 Training loss: 0.0
2025-12-09 10:24:37.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 4059 LR: 0.0006545084971874737 Training loss: 0.0
2025-12-09 10:24:37.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 4060 LR: 0.0006543575887961248 Training loss: 0.0
2025-12-09 10:24:37.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 4061 LR: 0.0006542066648609708 Training loss: 0.0
2025-12-09 10:24:37.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 4062 LR: 0.0006540557253972098 Training loss: 0.0
2025-12-09 10:24:37.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 4063 LR: 0.0006539047704200417 Training loss: 0.0
2025-12-09 10:24:37.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 4064 LR: 0.0006537537999446672 Training loss: 0.0
2025-12-09 10:24:37.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 4065 LR: 0.0006536028139862894 Training loss: 0.0
2025-12-09 10:24:37.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 4066 LR: 0.0006534518125601124 Training loss: 0.0
2025-12-09 10:24:37.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 4067 LR: 0.000653300795681342 Training loss: 0.0
2025-12-09 10:24:37.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 4068 LR: 0.000653149763365186 Training loss: 0.0
2025-12-09 10:24:37.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 4069 LR: 0.0006529987156268526 Training loss: 0.0
2025-12-09 10:24:37.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 4070 LR: 0.0006528476524815529 Training loss: 0.0
2025-12-09 10:24:37.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 4071 LR: 0.0006526965739444987 Training loss: 0.0
2025-12-09 10:24:37.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 4072 LR: 0.0006525454800309038 Training loss: 0.0
2025-12-09 10:24:37.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 4073 LR: 0.0006523943707559831 Training loss: 0.0
2025-12-09 10:24:37.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 4074 LR: 0.0006522432461349536 Training loss: 0.0
2025-12-09 10:24:37.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 4075 LR: 0.0006520921061830332 Training loss: 0.0
2025-12-09 10:24:37.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 4076 LR: 0.000651940950915442 Training loss: 0.0
2025-12-09 10:24:37.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 4077 LR: 0.0006517897803474011 Training loss: 0.0
2025-12-09 10:24:37.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 4078 LR: 0.0006516385944941337 Training loss: 0.0
2025-12-09 10:24:37.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 4079 LR: 0.0006514873933708637 Training loss: 0.0
2025-12-09 10:24:37.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 4080 LR: 0.0006513361769928174 Training loss: 0.0
2025-12-09 10:24:37.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 4081 LR: 0.0006511849453752223 Training loss: 0.0
2025-12-09 10:24:37.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 4082 LR: 0.0006510336985333074 Training loss: 0.0
2025-12-09 10:24:37.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 4083 LR: 0.0006508824364823031 Training loss: 0.0
2025-12-09 10:24:37.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 4084 LR: 0.0006507311592374415 Training loss: 0.0
2025-12-09 10:24:37.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 4085 LR: 0.0006505798668139563 Training loss: 0.0
2025-12-09 10:24:37.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 4086 LR: 0.0006504285592270828 Training loss: 0.0
2025-12-09 10:24:37.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 4087 LR: 0.0006502772364920573 Training loss: 0.0
2025-12-09 10:24:37.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 4088 LR: 0.0006501258986241184 Training loss: 0.0
2025-12-09 10:24:37.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 4089 LR: 0.0006499745456385053 Training loss: 0.0
2025-12-09 10:24:37.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 4090 LR: 0.0006498231775504598 Training loss: 0.0
2025-12-09 10:24:37.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 4091 LR: 0.0006496717943752243 Training loss: 0.0
2025-12-09 10:24:37.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 4092 LR: 0.0006495203961280433 Training loss: 0.0
2025-12-09 10:24:37.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 4093 LR: 0.0006493689828241624 Training loss: 0.0
2025-12-09 10:24:37.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 4094 LR: 0.0006492175544788293 Training loss: 0.0
2025-12-09 10:24:37.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 4095 LR: 0.0006490661111072923 Training loss: 0.0
2025-12-09 10:24:37.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 4096 LR: 0.0006489146527248019 Training loss: 0.0
2025-12-09 10:24:37.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 4097 LR: 0.0006487631793466104 Training loss: 0.0
2025-12-09 10:24:37.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 4098 LR: 0.0006486116909879705 Training loss: 0.0
2025-12-09 10:24:37.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 4099 LR: 0.0006484601876641375 Training loss: 0.0
2025-12-09 10:24:37.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 4100 LR: 0.0006483086693903676 Training loss: 0.0
2025-12-09 10:24:37.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 4101 LR: 0.0006481571361819188 Training loss: 0.0
2025-12-09 10:24:37.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 4102 LR: 0.0006480055880540504 Training loss: 0.0
2025-12-09 10:24:37.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 4103 LR: 0.0006478540250220234 Training loss: 0.0
2025-12-09 10:24:37.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 4104 LR: 0.0006477024471011001 Training loss: 0.0
2025-12-09 10:24:37.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 4105 LR: 0.0006475508543065444 Training loss: 0.0
2025-12-09 10:24:37.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 4106 LR: 0.0006473992466536217 Training loss: 0.0
2025-12-09 10:24:37.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 4107 LR: 0.0006472476241575989 Training loss: 0.0
2025-12-09 10:24:37.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 4108 LR: 0.0006470959868337444 Training loss: 0.0
2025-12-09 10:24:37.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 4109 LR: 0.000646944334697328 Training loss: 0.0
2025-12-09 10:24:37.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 4110 LR: 0.0006467926677636211 Training loss: 0.0
2025-12-09 10:24:37.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 4111 LR: 0.0006466409860478966 Training loss: 0.0
2025-12-09 10:24:37.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 4112 LR: 0.0006464892895654289 Training loss: 0.0
2025-12-09 10:24:37.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 4113 LR: 0.0006463375783314938 Training loss: 0.0
2025-12-09 10:24:37.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 4114 LR: 0.0006461858523613684 Training loss: 0.0
2025-12-09 10:24:37.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 4115 LR: 0.0006460341116703317 Training loss: 0.0
2025-12-09 10:24:37.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 4116 LR: 0.000645882356273664 Training loss: 0.0
2025-12-09 10:24:37.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 4117 LR: 0.000645730586186647 Training loss: 0.0
2025-12-09 10:24:37.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 4118 LR: 0.0006455788014245639 Training loss: 0.0
2025-12-09 10:24:37.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 4119 LR: 0.0006454270020026995 Training loss: 0.0
2025-12-09 10:24:37.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 4120 LR: 0.00064527518793634 Training loss: 0.0
2025-12-09 10:24:37.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 4121 LR: 0.0006451233592407731 Training loss: 0.0
2025-12-09 10:24:37.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 4122 LR: 0.0006449715159312879 Training loss: 0.0
2025-12-09 10:24:37.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 4123 LR: 0.0006448196580231748 Training loss: 0.0
2025-12-09 10:24:37.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 4124 LR: 0.0006446677855317265 Training loss: 0.0
2025-12-09 10:24:37.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 4125 LR: 0.0006445158984722358 Training loss: 0.0
2025-12-09 10:24:37.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 4126 LR: 0.0006443639968599981 Training loss: 0.0
2025-12-09 10:24:37.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 4127 LR: 0.0006442120807103101 Training loss: 0.0
2025-12-09 10:24:37.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 4128 LR: 0.0006440601500384694 Training loss: 0.0
2025-12-09 10:24:37.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 4129 LR: 0.0006439082048597755 Training loss: 0.0
2025-12-09 10:24:37.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 4130 LR: 0.0006437562451895293 Training loss: 0.0
2025-12-09 10:24:37.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 4131 LR: 0.0006436042710430332 Training loss: 0.0
2025-12-09 10:24:37.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 4132 LR: 0.0006434522824355908 Training loss: 0.0
2025-12-09 10:24:37.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 4133 LR: 0.0006433002793825075 Training loss: 0.0
2025-12-09 10:24:37.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 4134 LR: 0.0006431482618990902 Training loss: 0.0
2025-12-09 10:24:37.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 4135 LR: 0.0006429962300006467 Training loss: 0.0
2025-12-09 10:24:37.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 4136 LR: 0.0006428441837024868 Training loss: 0.0
2025-12-09 10:24:37.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 4137 LR: 0.0006426921230199214 Training loss: 0.0
2025-12-09 10:24:37.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 4138 LR: 0.0006425400479682633 Training loss: 0.0
2025-12-09 10:24:37.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 4139 LR: 0.0006423879585628261 Training loss: 0.0
2025-12-09 10:24:37.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 4140 LR: 0.0006422358548189254 Training loss: 0.0
2025-12-09 10:24:37.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 4141 LR: 0.000642083736751878 Training loss: 0.0
2025-12-09 10:24:37.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 4142 LR: 0.0006419316043770024 Training loss: 0.0
2025-12-09 10:24:37.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 4143 LR: 0.0006417794577096179 Training loss: 0.0
2025-12-09 10:24:37.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 4144 LR: 0.0006416272967650459 Training loss: 0.0
2025-12-09 10:24:37.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 4145 LR: 0.000641475121558609 Training loss: 0.0
2025-12-09 10:24:37.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 4146 LR: 0.0006413229321056314 Training loss: 0.0
2025-12-09 10:24:37.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 4147 LR: 0.0006411707284214383 Training loss: 0.0
2025-12-09 10:24:37.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 4148 LR: 0.0006410185105213567 Training loss: 0.0
2025-12-09 10:24:37.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 4149 LR: 0.0006408662784207149 Training loss: 0.0
2025-12-09 10:24:37.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 4150 LR: 0.0006407140321348428 Training loss: 0.0
2025-12-09 10:24:37.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 4151 LR: 0.0006405617716790713 Training loss: 0.0
2025-12-09 10:24:37.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 4152 LR: 0.0006404094970687334 Training loss: 0.0
2025-12-09 10:24:37.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 4153 LR: 0.0006402572083191631 Training loss: 0.0
2025-12-09 10:24:37.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 4154 LR: 0.0006401049054456957 Training loss: 0.0
2025-12-09 10:24:37.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 4155 LR: 0.0006399525884636681 Training loss: 0.0
2025-12-09 10:24:37.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 4156 LR: 0.0006398002573884188 Training loss: 0.0
2025-12-09 10:24:37.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 4157 LR: 0.0006396479122352872 Training loss: 0.0
2025-12-09 10:24:37.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 4158 LR: 0.0006394955530196147 Training loss: 0.0
2025-12-09 10:24:37.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 4159 LR: 0.0006393431797567439 Training loss: 0.0
2025-12-09 10:24:37.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 4160 LR: 0.0006391907924620186 Training loss: 0.0
2025-12-09 10:24:37.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 4161 LR: 0.0006390383911507845 Training loss: 0.0
2025-12-09 10:24:37.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 4162 LR: 0.000638885975838388 Training loss: 0.0
2025-12-09 10:24:37.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 4163 LR: 0.0006387335465401776 Training loss: 0.0
2025-12-09 10:24:37.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 4164 LR: 0.0006385811032715029 Training loss: 0.0
2025-12-09 10:24:37.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 4165 LR: 0.0006384286460477149 Training loss: 0.0
2025-12-09 10:24:37.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 4166 LR: 0.0006382761748841661 Training loss: 0.0
2025-12-09 10:24:37.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 4167 LR: 0.0006381236897962102 Training loss: 0.0
2025-12-09 10:24:37.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 4168 LR: 0.0006379711907992025 Training loss: 0.0
2025-12-09 10:24:37.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 4169 LR: 0.0006378186779084996 Training loss: 0.0
2025-12-09 10:24:37.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 4170 LR: 0.0006376661511394597 Training loss: 0.0
2025-12-09 10:24:37.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 4171 LR: 0.0006375136105074422 Training loss: 0.0
2025-12-09 10:24:37.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 4172 LR: 0.0006373610560278077 Training loss: 0.0
2025-12-09 10:24:37.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 4173 LR: 0.0006372084877159188 Training loss: 0.0
2025-12-09 10:24:37.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 4174 LR: 0.0006370559055871389 Training loss: 0.0
2025-12-09 10:24:37.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 4175 LR: 0.0006369033096568329 Training loss: 0.0
2025-12-09 10:24:37.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 4176 LR: 0.0006367506999403675 Training loss: 0.0
2025-12-09 10:24:37.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 4177 LR: 0.0006365980764531105 Training loss: 0.0
2025-12-09 10:24:37.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 4178 LR: 0.0006364454392104307 Training loss: 0.0
2025-12-09 10:24:37.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 4179 LR: 0.0006362927882276989 Training loss: 0.0
2025-12-09 10:24:37.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 4180 LR: 0.0006361401235202872 Training loss: 0.0
2025-12-09 10:24:37.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 4181 LR: 0.0006359874451035688 Training loss: 0.0
2025-12-09 10:24:37.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 4182 LR: 0.0006358347529929183 Training loss: 0.0
2025-12-09 10:24:37.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 4183 LR: 0.0006356820472037119 Training loss: 0.0
2025-12-09 10:24:37.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 4184 LR: 0.000635529327751327 Training loss: 0.0
2025-12-09 10:24:37.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 4185 LR: 0.0006353765946511428 Training loss: 0.0
2025-12-09 10:24:37.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 4186 LR: 0.0006352238479185388 Training loss: 0.0
2025-12-09 10:24:37.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 4187 LR: 0.0006350710875688972 Training loss: 0.0
2025-12-09 10:24:37.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 4188 LR: 0.0006349183136176009 Training loss: 0.0
2025-12-09 10:24:37.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 4189 LR: 0.000634765526080034 Training loss: 0.0
2025-12-09 10:24:37.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 4190 LR: 0.0006346127249715823 Training loss: 0.0
2025-12-09 10:24:37.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 4191 LR: 0.0006344599103076329 Training loss: 0.0
2025-12-09 10:24:37.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 4192 LR: 0.0006343070821035742 Training loss: 0.0
2025-12-09 10:24:37.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 4193 LR: 0.000634154240374796 Training loss: 0.0
2025-12-09 10:24:37.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 4194 LR: 0.0006340013851366895 Training loss: 0.0
2025-12-09 10:24:37.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 4195 LR: 0.0006338485164046471 Training loss: 0.0
2025-12-09 10:24:37.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 4196 LR: 0.0006336956341940629 Training loss: 0.0
2025-12-09 10:24:37.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 4197 LR: 0.000633542738520332 Training loss: 0.0
2025-12-09 10:24:37.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 4198 LR: 0.0006333898293988509 Training loss: 0.0
2025-12-09 10:24:37.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 4199 LR: 0.0006332369068450174 Training loss: 0.0
2025-12-09 10:24:37.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 4200 LR: 0.0006330839708742314 Training loss: 0.0
2025-12-09 10:24:37.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 4201 LR: 0.000632931021501893 Training loss: 0.0
2025-12-09 10:24:37.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 4202 LR: 0.0006327780587434044 Training loss: 0.0
2025-12-09 10:24:37.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 4203 LR: 0.0006326250826141688 Training loss: 0.0
2025-12-09 10:24:37.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 4204 LR: 0.0006324720931295913 Training loss: 0.0
2025-12-09 10:24:37.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 4205 LR: 0.0006323190903050775 Training loss: 0.0
2025-12-09 10:24:37.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 4206 LR: 0.0006321660741560349 Training loss: 0.0
2025-12-09 10:24:37.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 4207 LR: 0.0006320130446978722 Training loss: 0.0
2025-12-09 10:24:37.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 4208 LR: 0.0006318600019459996 Training loss: 0.0
2025-12-09 10:24:37.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 4209 LR: 0.0006317069459158283 Training loss: 0.0
2025-12-09 10:24:37.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 4210 LR: 0.0006315538766227713 Training loss: 0.0
2025-12-09 10:24:37.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 4211 LR: 0.0006314007940822425 Training loss: 0.0
2025-12-09 10:24:37.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 4212 LR: 0.0006312476983096572 Training loss: 0.0
2025-12-09 10:24:37.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 4213 LR: 0.0006310945893204324 Training loss: 0.0
2025-12-09 10:24:37.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 4214 LR: 0.0006309414671299859 Training loss: 0.0
2025-12-09 10:24:37.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 4215 LR: 0.0006307883317537375 Training loss: 0.0
2025-12-09 10:24:37.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 4216 LR: 0.0006306351832071074 Training loss: 0.0
2025-12-09 10:24:37.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 4217 LR: 0.000630482021505518 Training loss: 0.0
2025-12-09 10:24:37.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 4218 LR: 0.0006303288466643927 Training loss: 0.0
2025-12-09 10:24:37.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 4219 LR: 0.0006301756586991561 Training loss: 0.0
2025-12-09 10:24:37.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 4220 LR: 0.0006300224576252341 Training loss: 0.0
2025-12-09 10:24:37.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 4221 LR: 0.0006298692434580542 Training loss: 0.0
2025-12-09 10:24:37.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 4222 LR: 0.0006297160162130452 Training loss: 0.0
2025-12-09 10:24:37.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 4223 LR: 0.0006295627759056368 Training loss: 0.0
2025-12-09 10:24:37.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 4224 LR: 0.0006294095225512603 Training loss: 0.0
2025-12-09 10:24:37.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 4225 LR: 0.0006292562561653485 Training loss: 0.0
2025-12-09 10:24:37.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 4226 LR: 0.0006291029767633353 Training loss: 0.0
2025-12-09 10:24:37.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 4227 LR: 0.0006289496843606559 Training loss: 0.0
2025-12-09 10:24:37.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 4228 LR: 0.0006287963789727468 Training loss: 0.0
2025-12-09 10:24:37.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 4229 LR: 0.0006286430606150459 Training loss: 0.0
2025-12-09 10:24:37.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 4230 LR: 0.0006284897293029922 Training loss: 0.0
2025-12-09 10:24:37.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 4231 LR: 0.0006283363850520262 Training loss: 0.0
2025-12-09 10:24:37.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 4232 LR: 0.0006281830278775899 Training loss: 0.0
2025-12-09 10:24:37.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 4233 LR: 0.0006280296577951261 Training loss: 0.0
2025-12-09 10:24:37.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 4234 LR: 0.0006278762748200794 Training loss: 0.0
2025-12-09 10:24:37.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 4235 LR: 0.0006277228789678953 Training loss: 0.0
2025-12-09 10:24:37.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 4236 LR: 0.0006275694702540206 Training loss: 0.0
2025-12-09 10:24:37.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 4237 LR: 0.000627416048693904 Training loss: 0.0
2025-12-09 10:24:37.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 4238 LR: 0.0006272626143029946 Training loss: 0.0
2025-12-09 10:24:37.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 4239 LR: 0.0006271091670967436 Training loss: 0.0
2025-12-09 10:24:37.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 4240 LR: 0.0006269557070906028 Training loss: 0.0
2025-12-09 10:24:37.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 4241 LR: 0.0006268022343000256 Training loss: 0.0
2025-12-09 10:24:37.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 4242 LR: 0.0006266487487404672 Training loss: 0.0
2025-12-09 10:24:37.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 4243 LR: 0.0006264952504273831 Training loss: 0.0
2025-12-09 10:24:37.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 4244 LR: 0.0006263417393762307 Training loss: 0.0
2025-12-09 10:24:37.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 4245 LR: 0.0006261882156024688 Training loss: 0.0
2025-12-09 10:24:37.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 4246 LR: 0.000626034679121557 Training loss: 0.0
2025-12-09 10:24:37.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 4247 LR: 0.0006258811299489563 Training loss: 0.0
2025-12-09 10:24:37.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 4248 LR: 0.0006257275681001293 Training loss: 0.0
2025-12-09 10:24:37.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 4249 LR: 0.0006255739935905395 Training loss: 0.0
2025-12-09 10:24:37.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 4250 LR: 0.0006254204064356524 Training loss: 0.0
2025-12-09 10:24:37.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 4251 LR: 0.0006252668066509335 Training loss: 0.0
2025-12-09 10:24:37.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 4252 LR: 0.0006251131942518507 Training loss: 0.0
2025-12-09 10:24:37.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 4253 LR: 0.0006249595692538726 Training loss: 0.0
2025-12-09 10:24:37.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 4254 LR: 0.0006248059316724693 Training loss: 0.0
2025-12-09 10:24:37.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 4255 LR: 0.0006246522815231121 Training loss: 0.0
2025-12-09 10:24:37.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 4256 LR: 0.0006244986188212734 Training loss: 0.0
2025-12-09 10:24:37.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 4257 LR: 0.0006243449435824276 Training loss: 0.0
2025-12-09 10:24:37.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 4258 LR: 0.000624191255822049 Training loss: 0.0
2025-12-09 10:24:37.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 4259 LR: 0.0006240375555556145 Training loss: 0.0
2025-12-09 10:24:37.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 4260 LR: 0.0006238838427986014 Training loss: 0.0
2025-12-09 10:24:37.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 4261 LR: 0.0006237301175664891 Training loss: 0.0
2025-12-09 10:24:37.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 4262 LR: 0.0006235763798747569 Training loss: 0.0
2025-12-09 10:24:37.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 4263 LR: 0.0006234226297388869 Training loss: 0.0
2025-12-09 10:24:37.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 4264 LR: 0.0006232688671743612 Training loss: 0.0
2025-12-09 10:24:37.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 4265 LR: 0.0006231150921966643 Training loss: 0.0
2025-12-09 10:24:37.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 4266 LR: 0.0006229613048212807 Training loss: 0.0
2025-12-09 10:24:37.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 4267 LR: 0.0006228075050636972 Training loss: 0.0
2025-12-09 10:24:37.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 4268 LR: 0.0006226536929394013 Training loss: 0.0
2025-12-09 10:24:37.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 4269 LR: 0.000622499868463882 Training loss: 0.0
2025-12-09 10:24:37.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 4270 LR: 0.000622346031652629 Training loss: 0.0
2025-12-09 10:24:37.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 4271 LR: 0.0006221921825211342 Training loss: 0.0
2025-12-09 10:24:37.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 4272 LR: 0.0006220383210848899 Training loss: 0.0
2025-12-09 10:24:37.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 4273 LR: 0.0006218844473593899 Training loss: 0.0
2025-12-09 10:24:37.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 4274 LR: 0.0006217305613601295 Training loss: 0.0
2025-12-09 10:24:37.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 4275 LR: 0.0006215766631026048 Training loss: 0.0
2025-12-09 10:24:37.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 4276 LR: 0.0006214227526023136 Training loss: 0.0
2025-12-09 10:24:37.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 4277 LR: 0.0006212688298747545 Training loss: 0.0
2025-12-09 10:24:37.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 4278 LR: 0.0006211148949354275 Training loss: 0.0
2025-12-09 10:24:37.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 4279 LR: 0.0006209609477998338 Training loss: 0.0
2025-12-09 10:24:37.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 4280 LR: 0.0006208069884834762 Training loss: 0.0
2025-12-09 10:24:37.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 4281 LR: 0.000620653017001858 Training loss: 0.0
2025-12-09 10:24:37.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 4282 LR: 0.0006204990333704843 Training loss: 0.0
2025-12-09 10:24:37.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 4283 LR: 0.0006203450376048614 Training loss: 0.0
2025-12-09 10:24:37.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 4284 LR: 0.0006201910297204962 Training loss: 0.0
2025-12-09 10:24:37.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 4285 LR: 0.0006200370097328978 Training loss: 0.0
2025-12-09 10:24:37.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 4286 LR: 0.0006198829776575758 Training loss: 0.0
2025-12-09 10:24:37.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 4287 LR: 0.0006197289335100412 Training loss: 0.0
2025-12-09 10:24:37.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 4288 LR: 0.0006195748773058064 Training loss: 0.0
2025-12-09 10:24:37.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 4289 LR: 0.0006194208090603844 Training loss: 0.0
2025-12-09 10:24:37.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 4290 LR: 0.0006192667287892905 Training loss: 0.0
2025-12-09 10:24:37.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 4291 LR: 0.0006191126365080402 Training loss: 0.0
2025-12-09 10:24:37.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 4292 LR: 0.0006189585322321506 Training loss: 0.0
2025-12-09 10:24:37.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 4293 LR: 0.00061880441597714 Training loss: 0.0
2025-12-09 10:24:37.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 4294 LR: 0.000618650287758528 Training loss: 0.0
2025-12-09 10:24:37.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 4295 LR: 0.0006184961475918355 Training loss: 0.0
2025-12-09 10:24:37.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 4296 LR: 0.000618341995492584 Training loss: 0.0
2025-12-09 10:24:37.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 4297 LR: 0.0006181878314762967 Training loss: 0.0
2025-12-09 10:24:37.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 4298 LR: 0.0006180336555584983 Training loss: 0.0
2025-12-09 10:24:37.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 4299 LR: 0.0006178794677547138 Training loss: 0.0
2025-12-09 10:24:37.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 4300 LR: 0.0006177252680804699 Training loss: 0.0
2025-12-09 10:24:37.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 4301 LR: 0.0006175710565512949 Training loss: 0.0
2025-12-09 10:24:37.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 4302 LR: 0.0006174168331827179 Training loss: 0.0
2025-12-09 10:24:37.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 4303 LR: 0.000617262597990269 Training loss: 0.0
2025-12-09 10:24:37.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 4304 LR: 0.0006171083509894795 Training loss: 0.0
2025-12-09 10:24:37.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 4305 LR: 0.0006169540921958823 Training loss: 0.0
2025-12-09 10:24:37.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 4306 LR: 0.0006167998216250113 Training loss: 0.0
2025-12-09 10:24:37.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 4307 LR: 0.0006166455392924014 Training loss: 0.0
2025-12-09 10:24:37.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 4308 LR: 0.000616491245213589 Training loss: 0.0
2025-12-09 10:24:37.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 4309 LR: 0.0006163369394041111 Training loss: 0.0
2025-12-09 10:24:37.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 4310 LR: 0.0006161826218795069 Training loss: 0.0
2025-12-09 10:24:37.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 4311 LR: 0.0006160282926553158 Training loss: 0.0
2025-12-09 10:24:37.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 4312 LR: 0.0006158739517470786 Training loss: 0.0
2025-12-09 10:24:37.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 4313 LR: 0.0006157195991703378 Training loss: 0.0
2025-12-09 10:24:37.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 4314 LR: 0.0006155652349406365 Training loss: 0.0
2025-12-09 10:24:37.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 4315 LR: 0.0006154108590735193 Training loss: 0.0
2025-12-09 10:24:37.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 4316 LR: 0.0006152564715845315 Training loss: 0.0
2025-12-09 10:24:37.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 4317 LR: 0.0006151020724892204 Training loss: 0.0
2025-12-09 10:24:37.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 4318 LR: 0.0006149476618031338 Training loss: 0.0
2025-12-09 10:24:37.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 4319 LR: 0.0006147932395418205 Training loss: 0.0
2025-12-09 10:24:37.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 4320 LR: 0.0006146388057208313 Training loss: 0.0
2025-12-09 10:24:37.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 4321 LR: 0.0006144843603557175 Training loss: 0.0
2025-12-09 10:24:37.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 4322 LR: 0.0006143299034620318 Training loss: 0.0
2025-12-09 10:24:37.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 4323 LR: 0.0006141754350553279 Training loss: 0.0
2025-12-09 10:24:37.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 4324 LR: 0.0006140209551511608 Training loss: 0.0
2025-12-09 10:24:37.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 4325 LR: 0.0006138664637650866 Training loss: 0.0
2025-12-09 10:24:37.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 4326 LR: 0.0006137119609126628 Training loss: 0.0
2025-12-09 10:24:37.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 4327 LR: 0.0006135574466094475 Training loss: 0.0
2025-12-09 10:24:37.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 4328 LR: 0.0006134029208710003 Training loss: 0.0
2025-12-09 10:24:37.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 4329 LR: 0.0006132483837128823 Training loss: 0.0
2025-12-09 10:24:37.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 4330 LR: 0.0006130938351506551 Training loss: 0.0
2025-12-09 10:24:37.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 4331 LR: 0.0006129392751998817 Training loss: 0.0
2025-12-09 10:24:37.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 4332 LR: 0.0006127847038761264 Training loss: 0.0
2025-12-09 10:24:37.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 4333 LR: 0.0006126301211949545 Training loss: 0.0
2025-12-09 10:24:37.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 4334 LR: 0.0006124755271719325 Training loss: 0.0
2025-12-09 10:24:37.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 4335 LR: 0.0006123209218226281 Training loss: 0.0
2025-12-09 10:24:37.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 4336 LR: 0.0006121663051626098 Training loss: 0.0
2025-12-09 10:24:37.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 4337 LR: 0.0006120116772074478 Training loss: 0.0
2025-12-09 10:24:37.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 4338 LR: 0.0006118570379727127 Training loss: 0.0
2025-12-09 10:24:37.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 4339 LR: 0.0006117023874739772 Training loss: 0.0
2025-12-09 10:24:37.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 4340 LR: 0.0006115477257268142 Training loss: 0.0
2025-12-09 10:24:37.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 4341 LR: 0.0006113930527467984 Training loss: 0.0
2025-12-09 10:24:37.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 4342 LR: 0.0006112383685495051 Training loss: 0.0
2025-12-09 10:24:37.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 4343 LR: 0.0006110836731505111 Training loss: 0.0
2025-12-09 10:24:37.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 4344 LR: 0.0006109289665653944 Training loss: 0.0
2025-12-09 10:24:37.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 4345 LR: 0.0006107742488097338 Training loss: 0.0
2025-12-09 10:24:37.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 4346 LR: 0.0006106195198991093 Training loss: 0.0
2025-12-09 10:24:37.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 4347 LR: 0.0006104647798491021 Training loss: 0.0
2025-12-09 10:24:37.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 4348 LR: 0.0006103100286752948 Training loss: 0.0
2025-12-09 10:24:37.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 4349 LR: 0.0006101552663932703 Training loss: 0.0
2025-12-09 10:24:37.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 4350 LR: 0.0006100004930186138 Training loss: 0.0
2025-12-09 10:24:37.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 4351 LR: 0.0006098457085669105 Training loss: 0.0
2025-12-09 10:24:37.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 4352 LR: 0.0006096909130537475 Training loss: 0.0
2025-12-09 10:24:37.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 4353 LR: 0.0006095361064947124 Training loss: 0.0
2025-12-09 10:24:37.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 4354 LR: 0.0006093812889053945 Training loss: 0.0
2025-12-09 10:24:37.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 4355 LR: 0.0006092264603013836 Training loss: 0.0
2025-12-09 10:24:37.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 4356 LR: 0.0006090716206982714 Training loss: 0.0
2025-12-09 10:24:37.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 4357 LR: 0.0006089167701116498 Training loss: 0.0
2025-12-09 10:24:37.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 4358 LR: 0.0006087619085571124 Training loss: 0.0
2025-12-09 10:24:37.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 4359 LR: 0.0006086070360502539 Training loss: 0.0
2025-12-09 10:24:37.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 4360 LR: 0.0006084521526066698 Training loss: 0.0
2025-12-09 10:24:37.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 4361 LR: 0.000608297258241957 Training loss: 0.0
2025-12-09 10:24:37.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 4362 LR: 0.000608142352971713 Training loss: 0.0
2025-12-09 10:24:37.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 4363 LR: 0.0006079874368115373 Training loss: 0.0
2025-12-09 10:24:37.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 4364 LR: 0.0006078325097770295 Training loss: 0.0
2025-12-09 10:24:37.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 4365 LR: 0.000607677571883791 Training loss: 0.0
2025-12-09 10:24:37.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 4366 LR: 0.000607522623147424 Training loss: 0.0
2025-12-09 10:24:37.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 4367 LR: 0.0006073676635835317 Training loss: 0.0
2025-12-09 10:24:37.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 4368 LR: 0.0006072126932077185 Training loss: 0.0
2025-12-09 10:24:37.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 4369 LR: 0.0006070577120355903 Training loss: 0.0
2025-12-09 10:24:37.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 4370 LR: 0.0006069027200827532 Training loss: 0.0
2025-12-09 10:24:37.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 4371 LR: 0.0006067477173648153 Training loss: 0.0
2025-12-09 10:24:37.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 4372 LR: 0.0006065927038973849 Training loss: 0.0
2025-12-09 10:24:37.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 4373 LR: 0.0006064376796960724 Training loss: 0.0
2025-12-09 10:24:37.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 4374 LR: 0.0006062826447764884 Training loss: 0.0
2025-12-09 10:24:37.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 4375 LR: 0.000606127599154245 Training loss: 0.0
2025-12-09 10:24:37.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 4376 LR: 0.0006059725428449552 Training loss: 0.0
2025-12-09 10:24:37.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 4377 LR: 0.0006058174758642331 Training loss: 0.0
2025-12-09 10:24:37.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 4378 LR: 0.0006056623982276944 Training loss: 0.0
2025-12-09 10:24:37.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 4379 LR: 0.0006055073099509549 Training loss: 0.0
2025-12-09 10:24:37.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 4380 LR: 0.0006053522110496322 Training loss: 0.0
2025-12-09 10:24:37.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 4381 LR: 0.0006051971015393447 Training loss: 0.0
2025-12-09 10:24:37.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 4382 LR: 0.000605041981435712 Training loss: 0.0
2025-12-09 10:24:37.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 4383 LR: 0.0006048868507543547 Training loss: 0.0
2025-12-09 10:24:37.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 4384 LR: 0.0006047317095108943 Training loss: 0.0
2025-12-09 10:24:37.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 4385 LR: 0.0006045765577209535 Training loss: 0.0
2025-12-09 10:24:37.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 4386 LR: 0.0006044213954001565 Training loss: 0.0
2025-12-09 10:24:37.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 4387 LR: 0.0006042662225641276 Training loss: 0.0
2025-12-09 10:24:37.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 4388 LR: 0.0006041110392284931 Training loss: 0.0
2025-12-09 10:24:37.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 4389 LR: 0.0006039558454088796 Training loss: 0.0
2025-12-09 10:24:37.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 4390 LR: 0.0006038006411209156 Training loss: 0.0
2025-12-09 10:24:37.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 4391 LR: 0.0006036454263802297 Training loss: 0.0
2025-12-09 10:24:37.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 4392 LR: 0.0006034902012024521 Training loss: 0.0
2025-12-09 10:24:37.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 4393 LR: 0.0006033349656032143 Training loss: 0.0
2025-12-09 10:24:37.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 4394 LR: 0.0006031797195981481 Training loss: 0.0
2025-12-09 10:24:37.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 4395 LR: 0.000603024463202887 Training loss: 0.0
2025-12-09 10:24:37.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 4396 LR: 0.0006028691964330654 Training loss: 0.0
2025-12-09 10:24:37.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 4397 LR: 0.0006027139193043184 Training loss: 0.0
2025-12-09 10:24:37.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 4398 LR: 0.0006025586318322827 Training loss: 0.0
2025-12-09 10:24:37.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 4399 LR: 0.0006024033340325954 Training loss: 0.0
2025-12-09 10:24:37.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 4400 LR: 0.0006022480259208951 Training loss: 0.0
2025-12-09 10:24:37.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 4401 LR: 0.0006020927075128216 Training loss: 0.0
2025-12-09 10:24:37.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 4402 LR: 0.0006019373788240151 Training loss: 0.0
2025-12-09 10:24:37.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 4403 LR: 0.0006017820398701174 Training loss: 0.0
2025-12-09 10:24:37.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 4404 LR: 0.0006016266906667711 Training loss: 0.0
2025-12-09 10:24:37.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 4405 LR: 0.0006014713312296198 Training loss: 0.0
2025-12-09 10:24:37.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 4406 LR: 0.0006013159615743082 Training loss: 0.0
2025-12-09 10:24:37.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 4407 LR: 0.0006011605817164822 Training loss: 0.0
2025-12-09 10:24:37.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 4408 LR: 0.0006010051916717882 Training loss: 0.0
2025-12-09 10:24:37.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 4409 LR: 0.0006008497914558743 Training loss: 0.0
2025-12-09 10:24:37.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 4410 LR: 0.0006006943810843891 Training loss: 0.0
2025-12-09 10:24:37.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 4411 LR: 0.0006005389605729824 Training loss: 0.0
2025-12-09 10:24:37.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 4412 LR: 0.0006003835299373052 Training loss: 0.0
2025-12-09 10:24:37.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 4413 LR: 0.0006002280891930093 Training loss: 0.0
2025-12-09 10:24:37.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 4414 LR: 0.0006000726383557476 Training loss: 0.0
2025-12-09 10:24:37.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 4415 LR: 0.0005999171774411737 Training loss: 0.0
2025-12-09 10:24:37.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 4416 LR: 0.000599761706464943 Training loss: 0.0
2025-12-09 10:24:37.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 4417 LR: 0.0005996062254427112 Training loss: 0.0
2025-12-09 10:24:37.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 4418 LR: 0.000599450734390135 Training loss: 0.0
2025-12-09 10:24:37.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 4419 LR: 0.0005992952333228728 Training loss: 0.0
2025-12-09 10:24:37.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 4420 LR: 0.0005991397222565832 Training loss: 0.0
2025-12-09 10:24:37.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 4421 LR: 0.0005989842012069264 Training loss: 0.0
2025-12-09 10:24:37.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 4422 LR: 0.0005988286701895631 Training loss: 0.0
2025-12-09 10:24:37.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 4423 LR: 0.0005986731292201555 Training loss: 0.0
2025-12-09 10:24:37.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 4424 LR: 0.0005985175783143666 Training loss: 0.0
2025-12-09 10:24:37.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 4425 LR: 0.0005983620174878601 Training loss: 0.0
2025-12-09 10:24:37.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 4426 LR: 0.0005982064467563011 Training loss: 0.0
2025-12-09 10:24:37.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 4427 LR: 0.0005980508661353556 Training loss: 0.0
2025-12-09 10:24:37.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 4428 LR: 0.0005978952756406908 Training loss: 0.0
2025-12-09 10:24:37.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 4429 LR: 0.0005977396752879741 Training loss: 0.0
2025-12-09 10:24:37.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 4430 LR: 0.000597584065092875 Training loss: 0.0
2025-12-09 10:24:37.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 4431 LR: 0.0005974284450710631 Training loss: 0.0
2025-12-09 10:24:37.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 4432 LR: 0.0005972728152382096 Training loss: 0.0
2025-12-09 10:24:37.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 4433 LR: 0.0005971171756099861 Training loss: 0.0
2025-12-09 10:24:37.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 4434 LR: 0.0005969615262020657 Training loss: 0.0
2025-12-09 10:24:37.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 4435 LR: 0.0005968058670301222 Training loss: 0.0
2025-12-09 10:24:37.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 4436 LR: 0.0005966501981098306 Training loss: 0.0
2025-12-09 10:24:37.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 4437 LR: 0.0005964945194568669 Training loss: 0.0
2025-12-09 10:24:37.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 4438 LR: 0.0005963388310869075 Training loss: 0.0
2025-12-09 10:24:37.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 4439 LR: 0.0005961831330156305 Training loss: 0.0
2025-12-09 10:24:37.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 4440 LR: 0.0005960274252587147 Training loss: 0.0
2025-12-09 10:24:37.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 4441 LR: 0.0005958717078318397 Training loss: 0.0
2025-12-09 10:24:37.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 4442 LR: 0.0005957159807506863 Training loss: 0.0
2025-12-09 10:24:37.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 4443 LR: 0.0005955602440309365 Training loss: 0.0
2025-12-09 10:24:37.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 4444 LR: 0.0005954044976882724 Training loss: 0.0
2025-12-09 10:24:37.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 4445 LR: 0.0005952487417383782 Training loss: 0.0
2025-12-09 10:24:37.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 4446 LR: 0.0005950929761969383 Training loss: 0.0
2025-12-09 10:24:37.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 4447 LR: 0.0005949372010796383 Training loss: 0.0
2025-12-09 10:24:37.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 4448 LR: 0.0005947814164021648 Training loss: 0.0
2025-12-09 10:24:37.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 4449 LR: 0.0005946256221802051 Training loss: 0.0
2025-12-09 10:24:37.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 4450 LR: 0.0005944698184294479 Training loss: 0.0
2025-12-09 10:24:37.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 4451 LR: 0.0005943140051655828 Training loss: 0.0
2025-12-09 10:24:37.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 4452 LR: 0.0005941581824042997 Training loss: 0.0
2025-12-09 10:24:37.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 4453 LR: 0.0005940023501612902 Training loss: 0.0
2025-12-09 10:24:37.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 4454 LR: 0.0005938465084522468 Training loss: 0.0
2025-12-09 10:24:37.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 4455 LR: 0.0005936906572928624 Training loss: 0.0
2025-12-09 10:24:37.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 4456 LR: 0.0005935347966988314 Training loss: 0.0
2025-12-09 10:24:37.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 4457 LR: 0.0005933789266858489 Training loss: 0.0
2025-12-09 10:24:37.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 4458 LR: 0.0005932230472696112 Training loss: 0.0
2025-12-09 10:24:37.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 4459 LR: 0.0005930671584658151 Training loss: 0.0
2025-12-09 10:24:37.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 4460 LR: 0.0005929112602901586 Training loss: 0.0
2025-12-09 10:24:37.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 4461 LR: 0.0005927553527583407 Training loss: 0.0
2025-12-09 10:24:37.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 4462 LR: 0.0005925994358860616 Training loss: 0.0
2025-12-09 10:24:37.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 4463 LR: 0.0005924435096890216 Training loss: 0.0
2025-12-09 10:24:37.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 4464 LR: 0.0005922875741829227 Training loss: 0.0
2025-12-09 10:24:37.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 4465 LR: 0.0005921316293834676 Training loss: 0.0
2025-12-09 10:24:37.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 4466 LR: 0.0005919756753063601 Training loss: 0.0
2025-12-09 10:24:37.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 4467 LR: 0.0005918197119673046 Training loss: 0.0
2025-12-09 10:24:37.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 4468 LR: 0.0005916637393820064 Training loss: 0.0
2025-12-09 10:24:37.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 4469 LR: 0.0005915077575661722 Training loss: 0.0
2025-12-09 10:24:37.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 4470 LR: 0.0005913517665355096 Training loss: 0.0
2025-12-09 10:24:37.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 4471 LR: 0.0005911957663057263 Training loss: 0.0
2025-12-09 10:24:37.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 4472 LR: 0.000591039756892532 Training loss: 0.0
2025-12-09 10:24:37.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 4473 LR: 0.0005908837383116367 Training loss: 0.0
2025-12-09 10:24:37.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 4474 LR: 0.0005907277105787513 Training loss: 0.0
2025-12-09 10:24:37.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 4475 LR: 0.0005905716737095879 Training loss: 0.0
2025-12-09 10:24:37.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 4476 LR: 0.0005904156277198595 Training loss: 0.0
2025-12-09 10:24:37.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 4477 LR: 0.0005902595726252801 Training loss: 0.0
2025-12-09 10:24:37.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 4478 LR: 0.0005901035084415639 Training loss: 0.0
2025-12-09 10:24:37.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 4479 LR: 0.000589947435184427 Training loss: 0.0
2025-12-09 10:24:37.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 4480 LR: 0.0005897913528695858 Training loss: 0.0
2025-12-09 10:24:37.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 4481 LR: 0.0005896352615127578 Training loss: 0.0
2025-12-09 10:24:37.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 4482 LR: 0.0005894791611296613 Training loss: 0.0
2025-12-09 10:24:37.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 4483 LR: 0.000589323051736016 Training loss: 0.0
2025-12-09 10:24:37.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 4484 LR: 0.0005891669333475415 Training loss: 0.0
2025-12-09 10:24:37.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 4485 LR: 0.0005890108059799596 Training loss: 0.0
2025-12-09 10:24:37.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 4486 LR: 0.0005888546696489918 Training loss: 0.0
2025-12-09 10:24:37.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 4487 LR: 0.0005886985243703612 Training loss: 0.0
2025-12-09 10:24:37.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 4488 LR: 0.0005885423701597918 Training loss: 0.0
2025-12-09 10:24:37.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 4489 LR: 0.0005883862070330078 Training loss: 0.0
2025-12-09 10:24:37.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 4490 LR: 0.0005882300350057353 Training loss: 0.0
2025-12-09 10:24:37.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 4491 LR: 0.0005880738540937008 Training loss: 0.0
2025-12-09 10:24:37.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 4492 LR: 0.0005879176643126316 Training loss: 0.0
2025-12-09 10:24:37.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 4493 LR: 0.000587761465678256 Training loss: 0.0
2025-12-09 10:24:37.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 4494 LR: 0.0005876052582063031 Training loss: 0.0
2025-12-09 10:24:37.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 4495 LR: 0.0005874490419125033 Training loss: 0.0
2025-12-09 10:24:37.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 4496 LR: 0.0005872928168125871 Training loss: 0.0
2025-12-09 10:24:37.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 4497 LR: 0.0005871365829222869 Training loss: 0.0
2025-12-09 10:24:37.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 4498 LR: 0.0005869803402573351 Training loss: 0.0
2025-12-09 10:24:37.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 4499 LR: 0.0005868240888334653 Training loss: 0.0
2025-12-09 10:24:37.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 4500 LR: 0.0005866678286664122 Training loss: 0.0
2025-12-09 10:24:37.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 4501 LR: 0.0005865115597719111 Training loss: 0.0
2025-12-09 10:24:37.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 4502 LR: 0.0005863552821656984 Training loss: 0.0
2025-12-09 10:24:37.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 4503 LR: 0.0005861989958635109 Training loss: 0.0
2025-12-09 10:24:37.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 4504 LR: 0.0005860427008810872 Training loss: 0.0
2025-12-09 10:24:37.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 4505 LR: 0.0005858863972341656 Training loss: 0.0
2025-12-09 10:24:37.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 4506 LR: 0.0005857300849384863 Training loss: 0.0
2025-12-09 10:24:37.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 4507 LR: 0.0005855737640097897 Training loss: 0.0
2025-12-09 10:24:37.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 4508 LR: 0.0005854174344638175 Training loss: 0.0
2025-12-09 10:24:37.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 4509 LR: 0.0005852610963163119 Training loss: 0.0
2025-12-09 10:24:37.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 4510 LR: 0.0005851047495830163 Training loss: 0.0
2025-12-09 10:24:37.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 4511 LR: 0.0005849483942796747 Training loss: 0.0
2025-12-09 10:24:37.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 4512 LR: 0.0005847920304220322 Training loss: 0.0
2025-12-09 10:24:37.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 4513 LR: 0.0005846356580258345 Training loss: 0.0
2025-12-09 10:24:37.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 4514 LR: 0.0005844792771068283 Training loss: 0.0
2025-12-09 10:24:37.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 4515 LR: 0.0005843228876807613 Training loss: 0.0
2025-12-09 10:24:37.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 4516 LR: 0.0005841664897633819 Training loss: 0.0
2025-12-09 10:24:37.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 4517 LR: 0.0005840100833704392 Training loss: 0.0
2025-12-09 10:24:37.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 4518 LR: 0.0005838536685176833 Training loss: 0.0
2025-12-09 10:24:37.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 4519 LR: 0.0005836972452208654 Training loss: 0.0
2025-12-09 10:24:37.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 4520 LR: 0.000583540813495737 Training loss: 0.0
2025-12-09 10:24:37.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 4521 LR: 0.0005833843733580511 Training loss: 0.0
2025-12-09 10:24:37.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 4522 LR: 0.0005832279248235611 Training loss: 0.0
2025-12-09 10:24:37.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 4523 LR: 0.0005830714679080215 Training loss: 0.0
2025-12-09 10:24:37.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 4524 LR: 0.0005829150026271871 Training loss: 0.0
2025-12-09 10:24:37.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 4525 LR: 0.0005827585289968143 Training loss: 0.0
2025-12-09 10:24:37.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 4526 LR: 0.0005826020470326599 Training loss: 0.0
2025-12-09 10:24:37.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 4527 LR: 0.0005824455567504817 Training loss: 0.0
2025-12-09 10:24:37.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 4528 LR: 0.000582289058166038 Training loss: 0.0
2025-12-09 10:24:37.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 4529 LR: 0.0005821325512950885 Training loss: 0.0
2025-12-09 10:24:37.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 4530 LR: 0.0005819760361533933 Training loss: 0.0
2025-12-09 10:24:37.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 4531 LR: 0.0005818195127567136 Training loss: 0.0
2025-12-09 10:24:37.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 4532 LR: 0.0005816629811208112 Training loss: 0.0
2025-12-09 10:24:37.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 4533 LR: 0.0005815064412614487 Training loss: 0.0
2025-12-09 10:24:37.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 4534 LR: 0.00058134989319439 Training loss: 0.0
2025-12-09 10:24:37.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 4535 LR: 0.0005811933369353991 Training loss: 0.0
2025-12-09 10:24:37.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 4536 LR: 0.0005810367725002415 Training loss: 0.0
2025-12-09 10:24:37.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 4537 LR: 0.000580880199904683 Training loss: 0.0
2025-12-09 10:24:37.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 4538 LR: 0.0005807236191644907 Training loss: 0.0
2025-12-09 10:24:37.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 4539 LR: 0.0005805670302954321 Training loss: 0.0
2025-12-09 10:24:37.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 4540 LR: 0.0005804104333132757 Training loss: 0.0
2025-12-09 10:24:37.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 4541 LR: 0.0005802538282337909 Training loss: 0.0
2025-12-09 10:24:37.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 4542 LR: 0.0005800972150727479 Training loss: 0.0
2025-12-09 10:24:37.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 4543 LR: 0.0005799405938459175 Training loss: 0.0
2025-12-09 10:24:37.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 4544 LR: 0.0005797839645690715 Training loss: 0.0
2025-12-09 10:24:37.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 4545 LR: 0.0005796273272579823 Training loss: 0.0
2025-12-09 10:24:37.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 4546 LR: 0.0005794706819284236 Training loss: 0.0
2025-12-09 10:24:37.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 4547 LR: 0.0005793140285961692 Training loss: 0.0
2025-12-09 10:24:37.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 4548 LR: 0.0005791573672769944 Training loss: 0.0
2025-12-09 10:24:37.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 4549 LR: 0.000579000697986675 Training loss: 0.0
2025-12-09 10:24:37.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 4550 LR: 0.0005788440207409874 Training loss: 0.0
2025-12-09 10:24:37.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 4551 LR: 0.0005786873355557089 Training loss: 0.0
2025-12-09 10:24:37.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 4552 LR: 0.000578530642446618 Training loss: 0.0
2025-12-09 10:24:37.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 4553 LR: 0.0005783739414294937 Training loss: 0.0
2025-12-09 10:24:37.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 4554 LR: 0.0005782172325201155 Training loss: 0.0
2025-12-09 10:24:37.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 4555 LR: 0.0005780605157342641 Training loss: 0.0
2025-12-09 10:24:37.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 4556 LR: 0.0005779037910877209 Training loss: 0.0
2025-12-09 10:24:37.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 4557 LR: 0.0005777470585962682 Training loss: 0.0
2025-12-09 10:24:37.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 4558 LR: 0.0005775903182756887 Training loss: 0.0
2025-12-09 10:24:37.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 4559 LR: 0.0005774335701417662 Training loss: 0.0
2025-12-09 10:24:37.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 4560 LR: 0.0005772768142102853 Training loss: 0.0
2025-12-09 10:24:37.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 4561 LR: 0.0005771200504970316 Training loss: 0.0
2025-12-09 10:24:37.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 4562 LR: 0.0005769632790177906 Training loss: 0.0
2025-12-09 10:24:37.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 4563 LR: 0.0005768064997883497 Training loss: 0.0
2025-12-09 10:24:37.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 4564 LR: 0.0005766497128244963 Training loss: 0.0
2025-12-09 10:24:37.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 4565 LR: 0.0005764929181420191 Training loss: 0.0
2025-12-09 10:24:37.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 4566 LR: 0.000576336115756707 Training loss: 0.0
2025-12-09 10:24:37.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 4567 LR: 0.00057617930568435 Training loss: 0.0
2025-12-09 10:24:37.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 4568 LR: 0.0005760224879407392 Training loss: 0.0
2025-12-09 10:24:37.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 4569 LR: 0.0005758656625416658 Training loss: 0.0
2025-12-09 10:24:37.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 4570 LR: 0.0005757088295029224 Training loss: 0.0
2025-12-09 10:24:37.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 4571 LR: 0.0005755519888403018 Training loss: 0.0
2025-12-09 10:24:37.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 4572 LR: 0.0005753951405695981 Training loss: 0.0
2025-12-09 10:24:37.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 4573 LR: 0.0005752382847066058 Training loss: 0.0
2025-12-09 10:24:37.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 4574 LR: 0.0005750814212671201 Training loss: 0.0
2025-12-09 10:24:37.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 4575 LR: 0.0005749245502669375 Training loss: 0.0
2025-12-09 10:24:37.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 4576 LR: 0.0005747676717218548 Training loss: 0.0
2025-12-09 10:24:37.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 4577 LR: 0.0005746107856476695 Training loss: 0.0
2025-12-09 10:24:37.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 4578 LR: 0.00057445389206018 Training loss: 0.0
2025-12-09 10:24:37.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 4579 LR: 0.0005742969909751859 Training loss: 0.0
2025-12-09 10:24:37.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 4580 LR: 0.0005741400824084868 Training loss: 0.0
2025-12-09 10:24:37.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 4581 LR: 0.0005739831663758834 Training loss: 0.0
2025-12-09 10:24:37.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 4582 LR: 0.000573826242893177 Training loss: 0.0
2025-12-09 10:24:37.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 4583 LR: 0.00057366931197617 Training loss: 0.0
2025-12-09 10:24:37.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 4584 LR: 0.0005735123736406655 Training loss: 0.0
2025-12-09 10:24:37.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 4585 LR: 0.0005733554279024667 Training loss: 0.0
2025-12-09 10:24:37.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 4586 LR: 0.0005731984747773786 Training loss: 0.0
2025-12-09 10:24:37.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 4587 LR: 0.0005730415142812059 Training loss: 0.0
2025-12-09 10:24:37.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 4588 LR: 0.0005728845464297547 Training loss: 0.0
2025-12-09 10:24:37.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 4589 LR: 0.0005727275712388318 Training loss: 0.0
2025-12-09 10:24:37.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 4590 LR: 0.0005725705887242444 Training loss: 0.0
2025-12-09 10:24:37.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 4591 LR: 0.0005724135989018007 Training loss: 0.0
2025-12-09 10:24:37.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 4592 LR: 0.0005722566017873096 Training loss: 0.0
2025-12-09 10:24:37.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 4593 LR: 0.0005720995973965806 Training loss: 0.0
2025-12-09 10:24:37.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 4594 LR: 0.0005719425857454241 Training loss: 0.0
2025-12-09 10:24:37.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 4595 LR: 0.0005717855668496513 Training loss: 0.0
2025-12-09 10:24:37.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 4596 LR: 0.0005716285407250739 Training loss: 0.0
2025-12-09 10:24:37.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 4597 LR: 0.0005714715073875043 Training loss: 0.0
2025-12-09 10:24:37.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 4598 LR: 0.0005713144668527558 Training loss: 0.0
2025-12-09 10:24:37.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 4599 LR: 0.0005711574191366427 Training loss: 0.0
2025-12-09 10:24:37.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 4600 LR: 0.0005710003642549793 Training loss: 0.0
2025-12-09 10:24:37.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 4601 LR: 0.000570843302223581 Training loss: 0.0
2025-12-09 10:24:37.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 4602 LR: 0.0005706862330582642 Training loss: 0.0
2025-12-09 10:24:37.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 4603 LR: 0.0005705291567748459 Training loss: 0.0
2025-12-09 10:24:37.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 4604 LR: 0.0005703720733891432 Training loss: 0.0
2025-12-09 10:24:37.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 4605 LR: 0.0005702149829169746 Training loss: 0.0
2025-12-09 10:24:37.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 4606 LR: 0.0005700578853741593 Training loss: 0.0
2025-12-09 10:24:37.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 4607 LR: 0.0005699007807765168 Training loss: 0.0
2025-12-09 10:24:37.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 4608 LR: 0.0005697436691398675 Training loss: 0.0
2025-12-09 10:24:37.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 4609 LR: 0.0005695865504800327 Training loss: 0.0
2025-12-09 10:24:37.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 4610 LR: 0.0005694294248128342 Training loss: 0.0
2025-12-09 10:24:37.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 4611 LR: 0.0005692722921540945 Training loss: 0.0
2025-12-09 10:24:37.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 4612 LR: 0.0005691151525196369 Training loss: 0.0
2025-12-09 10:24:37.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 4613 LR: 0.0005689580059252853 Training loss: 0.0
2025-12-09 10:24:37.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 4614 LR: 0.0005688008523868645 Training loss: 0.0
2025-12-09 10:24:37.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 4615 LR: 0.0005686436919201996 Training loss: 0.0
2025-12-09 10:24:37.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 4616 LR: 0.0005684865245411168 Training loss: 0.0
2025-12-09 10:24:37.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 4617 LR: 0.0005683293502654429 Training loss: 0.0
2025-12-09 10:24:37.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 4618 LR: 0.0005681721691090054 Training loss: 0.0
2025-12-09 10:24:37.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 4619 LR: 0.0005680149810876322 Training loss: 0.0
2025-12-09 10:24:37.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 4620 LR: 0.0005678577862171522 Training loss: 0.0
2025-12-09 10:24:37.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 4621 LR: 0.0005677005845133951 Training loss: 0.0
2025-12-09 10:24:37.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 4622 LR: 0.000567543375992191 Training loss: 0.0
2025-12-09 10:24:37.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 4623 LR: 0.0005673861606693707 Training loss: 0.0
2025-12-09 10:24:37.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 4624 LR: 0.0005672289385607659 Training loss: 0.0
2025-12-09 10:24:37.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 4625 LR: 0.0005670717096822089 Training loss: 0.0
2025-12-09 10:24:37.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 4626 LR: 0.0005669144740495326 Training loss: 0.0
2025-12-09 10:24:37.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 4627 LR: 0.0005667572316785705 Training loss: 0.0
2025-12-09 10:24:37.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 4628 LR: 0.0005665999825851569 Training loss: 0.0
2025-12-09 10:24:37.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 4629 LR: 0.0005664427267851271 Training loss: 0.0
2025-12-09 10:24:37.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 4630 LR: 0.0005662854642943163 Training loss: 0.0
2025-12-09 10:24:37.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 4631 LR: 0.0005661281951285613 Training loss: 0.0
2025-12-09 10:24:37.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 4632 LR: 0.0005659709193036985 Training loss: 0.0
2025-12-09 10:24:37.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 4633 LR: 0.0005658136368355665 Training loss: 0.0
2025-12-09 10:24:37.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 4634 LR: 0.0005656563477400026 Training loss: 0.0
2025-12-09 10:24:37.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 4635 LR: 0.0005654990520328465 Training loss: 0.0
2025-12-09 10:24:37.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 4636 LR: 0.0005653417497299374 Training loss: 0.0
2025-12-09 10:24:37.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 4637 LR: 0.0005651844408471161 Training loss: 0.0
2025-12-09 10:24:37.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 4638 LR: 0.0005650271254002234 Training loss: 0.0
2025-12-09 10:24:37.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 4639 LR: 0.0005648698034051009 Training loss: 0.0
2025-12-09 10:24:37.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 4640 LR: 0.0005647124748775909 Training loss: 0.0
2025-12-09 10:24:37.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 4641 LR: 0.0005645551398335367 Training loss: 0.0
2025-12-09 10:24:37.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 4642 LR: 0.0005643977982887814 Training loss: 0.0
2025-12-09 10:24:37.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 4643 LR: 0.0005642404502591697 Training loss: 0.0
2025-12-09 10:24:37.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 4644 LR: 0.0005640830957605465 Training loss: 0.0
2025-12-09 10:24:37.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 4645 LR: 0.0005639257348087572 Training loss: 0.0
2025-12-09 10:24:37.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 4646 LR: 0.0005637683674196481 Training loss: 0.0
2025-12-09 10:24:37.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 4647 LR: 0.0005636109936090661 Training loss: 0.0
2025-12-09 10:24:37.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 4648 LR: 0.0005634536133928591 Training loss: 0.0
2025-12-09 10:24:37.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 4649 LR: 0.0005632962267868747 Training loss: 0.0
2025-12-09 10:24:37.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 4650 LR: 0.000563138833806962 Training loss: 0.0
2025-12-09 10:24:37.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 4651 LR: 0.0005629814344689705 Training loss: 0.0
2025-12-09 10:24:37.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 4652 LR: 0.0005628240287887504 Training loss: 0.0
2025-12-09 10:24:37.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 4653 LR: 0.0005626666167821521 Training loss: 0.0
2025-12-09 10:24:37.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 4654 LR: 0.0005625091984650274 Training loss: 0.0
2025-12-09 10:24:37.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 4655 LR: 0.000562351773853228 Training loss: 0.0
2025-12-09 10:24:37.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 4656 LR: 0.0005621943429626068 Training loss: 0.0
2025-12-09 10:24:37.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 4657 LR: 0.0005620369058090168 Training loss: 0.0
2025-12-09 10:24:37.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 4658 LR: 0.0005618794624083121 Training loss: 0.0
2025-12-09 10:24:37.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 4659 LR: 0.0005617220127763474 Training loss: 0.0
2025-12-09 10:24:37.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 4660 LR: 0.0005615645569289776 Training loss: 0.0
2025-12-09 10:24:37.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 4661 LR: 0.0005614070948820586 Training loss: 0.0
2025-12-09 10:24:37.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 4662 LR: 0.0005612496266514468 Training loss: 0.0
2025-12-09 10:24:37.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 4663 LR: 0.0005610921522529994 Training loss: 0.0
2025-12-09 10:24:37.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 4664 LR: 0.0005609346717025737 Training loss: 0.0
2025-12-09 10:24:37.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 4665 LR: 0.0005607771850160285 Training loss: 0.0
2025-12-09 10:24:37.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 4666 LR: 0.0005606196922092223 Training loss: 0.0
2025-12-09 10:24:37.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 4667 LR: 0.0005604621932980147 Training loss: 0.0
2025-12-09 10:24:37.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 4668 LR: 0.000560304688298266 Training loss: 0.0
2025-12-09 10:24:37.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 4669 LR: 0.0005601471772258368 Training loss: 0.0
2025-12-09 10:24:37.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 4670 LR: 0.0005599896600965884 Training loss: 0.0
2025-12-09 10:24:37.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 4671 LR: 0.0005598321369263829 Training loss: 0.0
2025-12-09 10:24:37.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 4672 LR: 0.000559674607731083 Training loss: 0.0
2025-12-09 10:24:37.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 4673 LR: 0.0005595170725265516 Training loss: 0.0
2025-12-09 10:24:37.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 4674 LR: 0.0005593595313286526 Training loss: 0.0
2025-12-09 10:24:37.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 4675 LR: 0.0005592019841532506 Training loss: 0.0
2025-12-09 10:24:37.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 4676 LR: 0.0005590444310162103 Training loss: 0.0
2025-12-09 10:24:37.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 4677 LR: 0.0005588868719333974 Training loss: 0.0
2025-12-09 10:24:37.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 4678 LR: 0.000558729306920678 Training loss: 0.0
2025-12-09 10:24:37.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 4679 LR: 0.0005585717359939192 Training loss: 0.0
2025-12-09 10:24:37.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 4680 LR: 0.0005584141591689881 Training loss: 0.0
2025-12-09 10:24:37.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 4681 LR: 0.0005582565764617527 Training loss: 0.0
2025-12-09 10:24:37.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 4682 LR: 0.0005580989878880817 Training loss: 0.0
2025-12-09 10:24:37.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 4683 LR: 0.0005579413934638444 Training loss: 0.0
2025-12-09 10:24:37.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 4684 LR: 0.00055778379320491 Training loss: 0.0
2025-12-09 10:24:37.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 4685 LR: 0.0005576261871271494 Training loss: 0.0
2025-12-09 10:24:37.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 4686 LR: 0.0005574685752464334 Training loss: 0.0
2025-12-09 10:24:37.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 4687 LR: 0.0005573109575786333 Training loss: 0.0
2025-12-09 10:24:37.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 4688 LR: 0.0005571533341396215 Training loss: 0.0
2025-12-09 10:24:37.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 4689 LR: 0.0005569957049452703 Training loss: 0.0
2025-12-09 10:24:37.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 4690 LR: 0.0005568380700114535 Training loss: 0.0
2025-12-09 10:24:37.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 4691 LR: 0.0005566804293540443 Training loss: 0.0
2025-12-09 10:24:37.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 4692 LR: 0.0005565227829889175 Training loss: 0.0
2025-12-09 10:24:37.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 4693 LR: 0.000556365130931948 Training loss: 0.0
2025-12-09 10:24:37.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 4694 LR: 0.0005562074731990114 Training loss: 0.0
2025-12-09 10:24:37.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 4695 LR: 0.0005560498098059837 Training loss: 0.0
2025-12-09 10:24:37.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 4696 LR: 0.0005558921407687417 Training loss: 0.0
2025-12-09 10:24:37.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 4697 LR: 0.0005557344661031627 Training loss: 0.0
2025-12-09 10:24:37.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 4698 LR: 0.0005555767858251246 Training loss: 0.0
2025-12-09 10:24:37.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 4699 LR: 0.0005554190999505056 Training loss: 0.0
2025-12-09 10:24:37.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 4700 LR: 0.0005552614084951847 Training loss: 0.0
2025-12-09 10:24:37.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 4701 LR: 0.0005551037114750415 Training loss: 0.0
2025-12-09 10:24:37.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 4702 LR: 0.000554946008905956 Training loss: 0.0
2025-12-09 10:24:37.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 4703 LR: 0.000554788300803809 Training loss: 0.0
2025-12-09 10:24:37.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 4704 LR: 0.0005546305871844816 Training loss: 0.0
2025-12-09 10:24:37.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 4705 LR: 0.0005544728680638557 Training loss: 0.0
2025-12-09 10:24:37.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 4706 LR: 0.0005543151434578132 Training loss: 0.0
2025-12-09 10:24:37.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 4707 LR: 0.0005541574133822374 Training loss: 0.0
2025-12-09 10:24:37.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 4708 LR: 0.0005539996778530115 Training loss: 0.0
2025-12-09 10:24:37.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 4709 LR: 0.0005538419368860196 Training loss: 0.0
2025-12-09 10:24:37.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 4710 LR: 0.000553684190497146 Training loss: 0.0
2025-12-09 10:24:37.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 4711 LR: 0.0005535264387022759 Training loss: 0.0
2025-12-09 10:24:37.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 4712 LR: 0.0005533686815172949 Training loss: 0.0
2025-12-09 10:24:37.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 4713 LR: 0.0005532109189580893 Training loss: 0.0
2025-12-09 10:24:37.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 4714 LR: 0.0005530531510405454 Training loss: 0.0
2025-12-09 10:24:37.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 4715 LR: 0.0005528953777805507 Training loss: 0.0
2025-12-09 10:24:37.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 4716 LR: 0.0005527375991939929 Training loss: 0.0
2025-12-09 10:24:37.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 4717 LR: 0.0005525798152967605 Training loss: 0.0
2025-12-09 10:24:37.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 4718 LR: 0.0005524220261047419 Training loss: 0.0
2025-12-09 10:24:37.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 4719 LR: 0.0005522642316338268 Training loss: 0.0
2025-12-09 10:24:37.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 4720 LR: 0.000552106431899905 Training loss: 0.0
2025-12-09 10:24:37.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 4721 LR: 0.0005519486269188669 Training loss: 0.0
2025-12-09 10:24:37.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 4722 LR: 0.0005517908167066035 Training loss: 0.0
2025-12-09 10:24:37.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 4723 LR: 0.0005516330012790062 Training loss: 0.0
2025-12-09 10:24:37.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 4724 LR: 0.0005514751806519673 Training loss: 0.0
2025-12-09 10:24:37.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 4725 LR: 0.0005513173548413789 Training loss: 0.0
2025-12-09 10:24:37.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 4726 LR: 0.0005511595238631344 Training loss: 0.0
2025-12-09 10:24:37.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 4727 LR: 0.0005510016877331271 Training loss: 0.0
2025-12-09 10:24:37.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 4728 LR: 0.0005508438464672515 Training loss: 0.0
2025-12-09 10:24:37.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 4729 LR: 0.0005506860000814017 Training loss: 0.0
2025-12-09 10:24:37.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 4730 LR: 0.0005505281485914731 Training loss: 0.0
2025-12-09 10:24:37.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 4731 LR: 0.0005503702920133614 Training loss: 0.0
2025-12-09 10:24:37.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 4732 LR: 0.0005502124303629627 Training loss: 0.0
2025-12-09 10:24:37.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 4733 LR: 0.0005500545636561737 Training loss: 0.0
2025-12-09 10:24:37.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 4734 LR: 0.0005498966919088913 Training loss: 0.0
2025-12-09 10:24:37.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 4735 LR: 0.0005497388151370135 Training loss: 0.0
2025-12-09 10:24:37.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 4736 LR: 0.0005495809333564384 Training loss: 0.0
2025-12-09 10:24:37.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 4737 LR: 0.0005494230465830647 Training loss: 0.0
2025-12-09 10:24:37.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 4738 LR: 0.0005492651548327915 Training loss: 0.0
2025-12-09 10:24:37.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 4739 LR: 0.0005491072581215186 Training loss: 0.0
2025-12-09 10:24:37.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 4740 LR: 0.0005489493564651461 Training loss: 0.0
2025-12-09 10:24:37.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 4741 LR: 0.0005487914498795748 Training loss: 0.0
2025-12-09 10:24:37.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 4742 LR: 0.0005486335383807058 Training loss: 0.0
2025-12-09 10:24:37.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 4743 LR: 0.0005484756219844408 Training loss: 0.0
2025-12-09 10:24:37.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 4744 LR: 0.000548317700706682 Training loss: 0.0
2025-12-09 10:24:37.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 4745 LR: 0.000548159774563332 Training loss: 0.0
2025-12-09 10:24:37.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 4746 LR: 0.000548001843570294 Training loss: 0.0
2025-12-09 10:24:37.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 4747 LR: 0.0005478439077434719 Training loss: 0.0
2025-12-09 10:24:37.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 4748 LR: 0.0005476859670987694 Training loss: 0.0
2025-12-09 10:24:37.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 4749 LR: 0.0005475280216520913 Training loss: 0.0
2025-12-09 10:24:37.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 4750 LR: 0.0005473700714193428 Training loss: 0.0
2025-12-09 10:24:37.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 4751 LR: 0.0005472121164164295 Training loss: 0.0
2025-12-09 10:24:37.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 4752 LR: 0.0005470541566592572 Training loss: 0.0
2025-12-09 10:24:37.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 4753 LR: 0.0005468961921637327 Training loss: 0.0
2025-12-09 10:24:37.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 4754 LR: 0.0005467382229457629 Training loss: 0.0
2025-12-09 10:24:37.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 4755 LR: 0.0005465802490212554 Training loss: 0.0
2025-12-09 10:24:37.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 4756 LR: 0.000546422270406118 Training loss: 0.0
2025-12-09 10:24:37.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 4757 LR: 0.0005462642871162592 Training loss: 0.0
2025-12-09 10:24:37.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 4758 LR: 0.000546106299167588 Training loss: 0.0
2025-12-09 10:24:37.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 4759 LR: 0.0005459483065760138 Training loss: 0.0
2025-12-09 10:24:37.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 4760 LR: 0.0005457903093574463 Training loss: 0.0
2025-12-09 10:24:37.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 4761 LR: 0.0005456323075277959 Training loss: 0.0
2025-12-09 10:24:37.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 4762 LR: 0.0005454743011029735 Training loss: 0.0
2025-12-09 10:24:37.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 4763 LR: 0.0005453162900988901 Training loss: 0.0
2025-12-09 10:24:37.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 4764 LR: 0.0005451582745314576 Training loss: 0.0
2025-12-09 10:24:37.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 4765 LR: 0.0005450002544165881 Training loss: 0.0
2025-12-09 10:24:37.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 4766 LR: 0.000544842229770194 Training loss: 0.0
2025-12-09 10:24:37.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 4767 LR: 0.000544684200608189 Training loss: 0.0
2025-12-09 10:24:37.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 4768 LR: 0.000544526166946486 Training loss: 0.0
2025-12-09 10:24:37.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 4769 LR: 0.0005443681288009991 Training loss: 0.0
2025-12-09 10:24:37.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 4770 LR: 0.000544210086187643 Training loss: 0.0
2025-12-09 10:24:37.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 4771 LR: 0.0005440520391223323 Training loss: 0.0
2025-12-09 10:24:37.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 4772 LR: 0.0005438939876209825 Training loss: 0.0
2025-12-09 10:24:37.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 4773 LR: 0.0005437359316995094 Training loss: 0.0
2025-12-09 10:24:37.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 4774 LR: 0.0005435778713738292 Training loss: 0.0
2025-12-09 10:24:37.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 4775 LR: 0.0005434198066598584 Training loss: 0.0
2025-12-09 10:24:37.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 4776 LR: 0.0005432617375735144 Training loss: 0.0
2025-12-09 10:24:37.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 4777 LR: 0.0005431036641307146 Training loss: 0.0
2025-12-09 10:24:37.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 4778 LR: 0.000542945586347377 Training loss: 0.0
2025-12-09 10:24:37.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 4779 LR: 0.0005427875042394199 Training loss: 0.0
2025-12-09 10:24:37.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 4780 LR: 0.0005426294178227624 Training loss: 0.0
2025-12-09 10:24:37.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 4781 LR: 0.0005424713271133237 Training loss: 0.0
2025-12-09 10:24:37.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 4782 LR: 0.0005423132321270235 Training loss: 0.0
2025-12-09 10:24:37.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 4783 LR: 0.000542155132879782 Training loss: 0.0
2025-12-09 10:24:37.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 4784 LR: 0.0005419970293875197 Training loss: 0.0
2025-12-09 10:24:37.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 4785 LR: 0.0005418389216661579 Training loss: 0.0
2025-12-09 10:24:37.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 4786 LR: 0.0005416808097316176 Training loss: 0.0
2025-12-09 10:24:37.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 4787 LR: 0.000541522693599821 Training loss: 0.0
2025-12-09 10:24:37.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 4788 LR: 0.0005413645732866902 Training loss: 0.0
2025-12-09 10:24:37.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 4789 LR: 0.0005412064488081482 Training loss: 0.0
2025-12-09 10:24:37.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 4790 LR: 0.0005410483201801177 Training loss: 0.0
2025-12-09 10:24:38.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 4791 LR: 0.0005408901874185226 Training loss: 0.0
2025-12-09 10:24:38.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 4792 LR: 0.0005407320505392867 Training loss: 0.0
2025-12-09 10:24:38.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 4793 LR: 0.0005405739095583345 Training loss: 0.0
2025-12-09 10:24:38.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 4794 LR: 0.0005404157644915907 Training loss: 0.0
2025-12-09 10:24:38.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 4795 LR: 0.0005402576153549804 Training loss: 0.0
2025-12-09 10:24:38.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 4796 LR: 0.0005400994621644294 Training loss: 0.0
2025-12-09 10:24:38.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 4797 LR: 0.0005399413049358638 Training loss: 0.0
2025-12-09 10:24:38.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 4798 LR: 0.0005397831436852097 Training loss: 0.0
2025-12-09 10:24:38.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 4799 LR: 0.0005396249784283942 Training loss: 0.0
2025-12-09 10:24:38.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 4800 LR: 0.0005394668091813446 Training loss: 0.0
2025-12-09 10:24:38.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 4801 LR: 0.0005393086359599882 Training loss: 0.0
2025-12-09 10:24:38.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 4802 LR: 0.0005391504587802532 Training loss: 0.0
2025-12-09 10:24:38.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 4803 LR: 0.0005389922776580682 Training loss: 0.0
2025-12-09 10:24:38.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 4804 LR: 0.0005388340926093619 Training loss: 0.0
2025-12-09 10:24:38.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 4805 LR: 0.0005386759036500635 Training loss: 0.0
2025-12-09 10:24:38.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 4806 LR: 0.0005385177107961026 Training loss: 0.0
2025-12-09 10:24:38.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 4807 LR: 0.0005383595140634093 Training loss: 0.0
2025-12-09 10:24:38.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 4808 LR: 0.0005382013134679141 Training loss: 0.0
2025-12-09 10:24:38.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 4809 LR: 0.0005380431090255476 Training loss: 0.0
2025-12-09 10:24:38.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 4810 LR: 0.0005378849007522411 Training loss: 0.0
2025-12-09 10:24:38.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 4811 LR: 0.0005377266886639259 Training loss: 0.0
2025-12-09 10:24:38.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 4812 LR: 0.0005375684727765345 Training loss: 0.0
2025-12-09 10:24:38.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 4813 LR: 0.0005374102531059988 Training loss: 0.0
2025-12-09 10:24:38.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 4814 LR: 0.0005372520296682516 Training loss: 0.0
2025-12-09 10:24:38.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 4815 LR: 0.0005370938024792261 Training loss: 0.0
2025-12-09 10:24:38.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 4816 LR: 0.0005369355715548556 Training loss: 0.0
2025-12-09 10:24:38.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 4817 LR: 0.0005367773369110741 Training loss: 0.0
2025-12-09 10:24:38.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 4818 LR: 0.0005366190985638159 Training loss: 0.0
2025-12-09 10:24:38.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 4819 LR: 0.0005364608565290155 Training loss: 0.0
2025-12-09 10:24:38.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 4820 LR: 0.0005363026108226076 Training loss: 0.0
2025-12-09 10:24:38.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 4821 LR: 0.0005361443614605279 Training loss: 0.0
2025-12-09 10:24:38.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 4822 LR: 0.0005359861084587119 Training loss: 0.0
2025-12-09 10:24:38.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 4823 LR: 0.0005358278518330959 Training loss: 0.0
2025-12-09 10:24:38.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 4824 LR: 0.0005356695915996161 Training loss: 0.0
2025-12-09 10:24:38.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 4825 LR: 0.0005355113277742095 Training loss: 0.0
2025-12-09 10:24:38.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 4826 LR: 0.0005353530603728132 Training loss: 0.0
2025-12-09 10:24:38.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 4827 LR: 0.0005351947894113645 Training loss: 0.0
2025-12-09 10:24:38.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 4828 LR: 0.0005350365149058016 Training loss: 0.0
2025-12-09 10:24:38.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 4829 LR: 0.0005348782368720626 Training loss: 0.0
2025-12-09 10:24:38.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 4830 LR: 0.000534719955326086 Training loss: 0.0
2025-12-09 10:24:38.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 4831 LR: 0.0005345616702838111 Training loss: 0.0
2025-12-09 10:24:38.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 4832 LR: 0.0005344033817611767 Training loss: 0.0
2025-12-09 10:24:38.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 4833 LR: 0.0005342450897741227 Training loss: 0.0
2025-12-09 10:24:38.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 4834 LR: 0.0005340867943385894 Training loss: 0.0
2025-12-09 10:24:38.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 4835 LR: 0.0005339284954705165 Training loss: 0.0
2025-12-09 10:24:38.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 4836 LR: 0.0005337701931858453 Training loss: 0.0
2025-12-09 10:24:38.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 4837 LR: 0.0005336118875005165 Training loss: 0.0
2025-12-09 10:24:38.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 4838 LR: 0.0005334535784304714 Training loss: 0.0
2025-12-09 10:24:38.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 4839 LR: 0.000533295265991652 Training loss: 0.0
2025-12-09 10:24:38.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 4840 LR: 0.0005331369502000002 Training loss: 0.0
2025-12-09 10:24:38.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 4841 LR: 0.0005329786310714583 Training loss: 0.0
2025-12-09 10:24:38.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 4842 LR: 0.0005328203086219693 Training loss: 0.0
2025-12-09 10:24:38.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 4843 LR: 0.0005326619828674761 Training loss: 0.0
2025-12-09 10:24:38.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 4844 LR: 0.0005325036538239221 Training loss: 0.0
2025-12-09 10:24:38.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 4845 LR: 0.0005323453215072509 Training loss: 0.0
2025-12-09 10:24:38.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 4846 LR: 0.000532186985933407 Training loss: 0.0
2025-12-09 10:24:38.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 4847 LR: 0.0005320286471183343 Training loss: 0.0
2025-12-09 10:24:38.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 4848 LR: 0.0005318703050779778 Training loss: 0.0
2025-12-09 10:24:38.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 4849 LR: 0.0005317119598282822 Training loss: 0.0
2025-12-09 10:24:38.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 4850 LR: 0.0005315536113851935 Training loss: 0.0
2025-12-09 10:24:38.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 4851 LR: 0.0005313952597646568 Training loss: 0.0
2025-12-09 10:24:38.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 4852 LR: 0.0005312369049826183 Training loss: 0.0
2025-12-09 10:24:38.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 4853 LR: 0.0005310785470550243 Training loss: 0.0
2025-12-09 10:24:38.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 4854 LR: 0.0005309201859978216 Training loss: 0.0
2025-12-09 10:24:38.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 4855 LR: 0.0005307618218269569 Training loss: 0.0
2025-12-09 10:24:38.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 4856 LR: 0.0005306034545583775 Training loss: 0.0
2025-12-09 10:24:38.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 4857 LR: 0.0005304450842080312 Training loss: 0.0
2025-12-09 10:24:38.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 4858 LR: 0.0005302867107918657 Training loss: 0.0
2025-12-09 10:24:38.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 4859 LR: 0.0005301283343258293 Training loss: 0.0
2025-12-09 10:24:38.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 4860 LR: 0.0005299699548258704 Training loss: 0.0
2025-12-09 10:24:38.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 4861 LR: 0.000529811572307938 Training loss: 0.0
2025-12-09 10:24:38.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 4862 LR: 0.000529653186787981 Training loss: 0.0
2025-12-09 10:24:38.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 4863 LR: 0.0005294947982819488 Training loss: 0.0
2025-12-09 10:24:38.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 4864 LR: 0.0005293364068057912 Training loss: 0.0
2025-12-09 10:24:38.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 4865 LR: 0.0005291780123754585 Training loss: 0.0
2025-12-09 10:24:38.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 4866 LR: 0.0005290196150069006 Training loss: 0.0
2025-12-09 10:24:38.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 4867 LR: 0.0005288612147160681 Training loss: 0.0
2025-12-09 10:24:38.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 4868 LR: 0.0005287028115189122 Training loss: 0.0
2025-12-09 10:24:38.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 4869 LR: 0.000528544405431384 Training loss: 0.0
2025-12-09 10:24:38.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 4870 LR: 0.000528385996469435 Training loss: 0.0
2025-12-09 10:24:38.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 4871 LR: 0.0005282275846490168 Training loss: 0.0
2025-12-09 10:24:38.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 4872 LR: 0.0005280691699860817 Training loss: 0.0
2025-12-09 10:24:38.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 4873 LR: 0.0005279107524965819 Training loss: 0.0
2025-12-09 10:24:38.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 4874 LR: 0.0005277523321964701 Training loss: 0.0
2025-12-09 10:24:38.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 4875 LR: 0.0005275939091016992 Training loss: 0.0
2025-12-09 10:24:38.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 4876 LR: 0.0005274354832282224 Training loss: 0.0
2025-12-09 10:24:38.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 4877 LR: 0.0005272770545919934 Training loss: 0.0
2025-12-09 10:24:38.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 4878 LR: 0.0005271186232089654 Training loss: 0.0
2025-12-09 10:24:38.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 4879 LR: 0.000526960189095093 Training loss: 0.0
2025-12-09 10:24:38.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 4880 LR: 0.0005268017522663303 Training loss: 0.0
2025-12-09 10:24:38.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 4881 LR: 0.0005266433127386319 Training loss: 0.0
2025-12-09 10:24:38.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 4882 LR: 0.0005264848705279525 Training loss: 0.0
2025-12-09 10:24:38.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 4883 LR: 0.0005263264256502474 Training loss: 0.0
2025-12-09 10:24:38.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 4884 LR: 0.000526167978121472 Training loss: 0.0
2025-12-09 10:24:38.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 4885 LR: 0.0005260095279575819 Training loss: 0.0
2025-12-09 10:24:38.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 4886 LR: 0.000525851075174533 Training loss: 0.0
2025-12-09 10:24:38.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 4887 LR: 0.0005256926197882815 Training loss: 0.0
2025-12-09 10:24:38.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 4888 LR: 0.000525534161814784 Training loss: 0.0
2025-12-09 10:24:38.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 4889 LR: 0.0005253757012699972 Training loss: 0.0
2025-12-09 10:24:38.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 4890 LR: 0.0005252172381698777 Training loss: 0.0
2025-12-09 10:24:38.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 4891 LR: 0.0005250587725303831 Training loss: 0.0
2025-12-09 10:24:38.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 4892 LR: 0.000524900304367471 Training loss: 0.0
2025-12-09 10:24:38.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 4893 LR: 0.0005247418336970988 Training loss: 0.0
2025-12-09 10:24:38.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 4894 LR: 0.0005245833605352246 Training loss: 0.0
2025-12-09 10:24:38.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 4895 LR: 0.0005244248848978067 Training loss: 0.0
2025-12-09 10:24:38.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 4896 LR: 0.0005242664068008036 Training loss: 0.0
2025-12-09 10:24:38.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 4897 LR: 0.0005241079262601738 Training loss: 0.0
2025-12-09 10:24:38.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 4898 LR: 0.0005239494432918765 Training loss: 0.0
2025-12-09 10:24:38.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 4899 LR: 0.0005237909579118712 Training loss: 0.0
2025-12-09 10:24:38.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 4900 LR: 0.0005236324701361169 Training loss: 0.0
2025-12-09 10:24:38.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 4901 LR: 0.0005234739799805735 Training loss: 0.0
2025-12-09 10:24:38.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 4902 LR: 0.000523315487461201 Training loss: 0.0
2025-12-09 10:24:38.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 4903 LR: 0.0005231569925939596 Training loss: 0.0
2025-12-09 10:24:38.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 4904 LR: 0.0005229984953948096 Training loss: 0.0
2025-12-09 10:24:38.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 4905 LR: 0.0005228399958797117 Training loss: 0.0
2025-12-09 10:24:38.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 4906 LR: 0.0005226814940646269 Training loss: 0.0
2025-12-09 10:24:38.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 4907 LR: 0.0005225229899655162 Training loss: 0.0
2025-12-09 10:24:38.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 4908 LR: 0.0005223644835983413 Training loss: 0.0
2025-12-09 10:24:38.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 4909 LR: 0.0005222059749790631 Training loss: 0.0
2025-12-09 10:24:38.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 4910 LR: 0.0005220474641236441 Training loss: 0.0
2025-12-09 10:24:38.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 4911 LR: 0.0005218889510480461 Training loss: 0.0
2025-12-09 10:24:38.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 4912 LR: 0.000521730435768231 Training loss: 0.0
2025-12-09 10:24:38.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 4913 LR: 0.0005215719183001619 Training loss: 0.0
2025-12-09 10:24:38.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 4914 LR: 0.0005214133986598013 Training loss: 0.0
2025-12-09 10:24:38.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 4915 LR: 0.0005212548768631118 Training loss: 0.0
2025-12-09 10:24:38.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 4916 LR: 0.0005210963529260568 Training loss: 0.0
2025-12-09 10:24:38.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 4917 LR: 0.0005209378268645998 Training loss: 0.0
2025-12-09 10:24:38.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 4918 LR: 0.0005207792986947042 Training loss: 0.0
2025-12-09 10:24:38.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 4919 LR: 0.0005206207684323337 Training loss: 0.0
2025-12-09 10:24:38.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 4920 LR: 0.0005204622360934524 Training loss: 0.0
2025-12-09 10:24:38.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 4921 LR: 0.0005203037016940246 Training loss: 0.0
2025-12-09 10:24:38.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 4922 LR: 0.0005201451652500144 Training loss: 0.0
2025-12-09 10:24:38.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 4923 LR: 0.0005199866267773868 Training loss: 0.0
2025-12-09 10:24:38.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 4924 LR: 0.0005198280862921062 Training loss: 0.0
2025-12-09 10:24:38.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 4925 LR: 0.0005196695438101379 Training loss: 0.0
2025-12-09 10:24:38.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 4926 LR: 0.0005195109993474473 Training loss: 0.0
2025-12-09 10:24:38.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 4927 LR: 0.0005193524529199994 Training loss: 0.0
2025-12-09 10:24:38.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 4928 LR: 0.00051919390454376 Training loss: 0.0
2025-12-09 10:24:38.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 4929 LR: 0.000519035354234695 Training loss: 0.0
2025-12-09 10:24:38.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 4930 LR: 0.0005188768020087704 Training loss: 0.0
2025-12-09 10:24:38.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 4931 LR: 0.0005187182478819523 Training loss: 0.0
2025-12-09 10:24:38.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 4932 LR: 0.0005185596918702071 Training loss: 0.0
2025-12-09 10:24:38.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 4933 LR: 0.0005184011339895015 Training loss: 0.0
2025-12-09 10:24:38.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 4934 LR: 0.0005182425742558023 Training loss: 0.0
2025-12-09 10:24:38.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 4935 LR: 0.0005180840126850763 Training loss: 0.0
2025-12-09 10:24:38.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 4936 LR: 0.0005179254492932906 Training loss: 0.0
2025-12-09 10:24:38.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 4937 LR: 0.0005177668840964127 Training loss: 0.0
2025-12-09 10:24:38.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 4938 LR: 0.0005176083171104102 Training loss: 0.0
2025-12-09 10:24:38.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 4939 LR: 0.0005174497483512506 Training loss: 0.0
2025-12-09 10:24:38.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 4940 LR: 0.0005172911778349017 Training loss: 0.0
2025-12-09 10:24:38.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 4941 LR: 0.0005171326055773318 Training loss: 0.0
2025-12-09 10:24:38.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 4942 LR: 0.0005169740315945088 Training loss: 0.0
2025-12-09 10:24:38.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 4943 LR: 0.0005168154559024014 Training loss: 0.0
2025-12-09 10:24:38.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 4944 LR: 0.000516656878516978 Training loss: 0.0
2025-12-09 10:24:38.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 4945 LR: 0.0005164982994542075 Training loss: 0.0
2025-12-09 10:24:38.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 4946 LR: 0.0005163397187300586 Training loss: 0.0
2025-12-09 10:24:38.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 4947 LR: 0.0005161811363605006 Training loss: 0.0
2025-12-09 10:24:38.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 4948 LR: 0.0005160225523615026 Training loss: 0.0
2025-12-09 10:24:38.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 4949 LR: 0.0005158639667490339 Training loss: 0.0
2025-12-09 10:24:38.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 4950 LR: 0.0005157053795390641 Training loss: 0.0
2025-12-09 10:24:38.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 4951 LR: 0.0005155467907475632 Training loss: 0.0
2025-12-09 10:24:38.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 4952 LR: 0.0005153882003905008 Training loss: 0.0
2025-12-09 10:24:38.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 4953 LR: 0.0005152296084838472 Training loss: 0.0
2025-12-09 10:24:38.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 4954 LR: 0.0005150710150435723 Training loss: 0.0
2025-12-09 10:24:38.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 4955 LR: 0.0005149124200856466 Training loss: 0.0
2025-12-09 10:24:38.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 4956 LR: 0.0005147538236260406 Training loss: 0.0
2025-12-09 10:24:38.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 4957 LR: 0.0005145952256807249 Training loss: 0.0
2025-12-09 10:24:38.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 4958 LR: 0.0005144366262656705 Training loss: 0.0
2025-12-09 10:24:38.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 4959 LR: 0.0005142780253968481 Training loss: 0.0
2025-12-09 10:24:38.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 4960 LR: 0.0005141194230902291 Training loss: 0.0
2025-12-09 10:24:38.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 4961 LR: 0.0005139608193617845 Training loss: 0.0
2025-12-09 10:24:38.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 4962 LR: 0.0005138022142274857 Training loss: 0.0
2025-12-09 10:24:38.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 4963 LR: 0.0005136436077033044 Training loss: 0.0
2025-12-09 10:24:38.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 4964 LR: 0.0005134849998052123 Training loss: 0.0
2025-12-09 10:24:38.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 4965 LR: 0.0005133263905491808 Training loss: 0.0
2025-12-09 10:24:38.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 4966 LR: 0.0005131677799511822 Training loss: 0.0
2025-12-09 10:24:38.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 4967 LR: 0.0005130091680271887 Training loss: 0.0
2025-12-09 10:24:38.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 4968 LR: 0.0005128505547931723 Training loss: 0.0
2025-12-09 10:24:38.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 4969 LR: 0.0005126919402651053 Training loss: 0.0
2025-12-09 10:24:38.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 4970 LR: 0.0005125333244589602 Training loss: 0.0
2025-12-09 10:24:38.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 4971 LR: 0.0005123747073907098 Training loss: 0.0
2025-12-09 10:24:38.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 4972 LR: 0.0005122160890763266 Training loss: 0.0
2025-12-09 10:24:38.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 4973 LR: 0.0005120574695317837 Training loss: 0.0
2025-12-09 10:24:38.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 4974 LR: 0.0005118988487730537 Training loss: 0.0
2025-12-09 10:24:38.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 4975 LR: 0.0005117402268161102 Training loss: 0.0
2025-12-09 10:24:38.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 4976 LR: 0.000511581603676926 Training loss: 0.0
2025-12-09 10:24:38.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 4977 LR: 0.0005114229793714749 Training loss: 0.0
2025-12-09 10:24:38.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 4978 LR: 0.0005112643539157298 Training loss: 0.0
2025-12-09 10:24:38.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 4979 LR: 0.0005111057273256647 Training loss: 0.0
2025-12-09 10:24:38.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 4980 LR: 0.0005109470996172531 Training loss: 0.0
2025-12-09 10:24:38.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 4981 LR: 0.000510788470806469 Training loss: 0.0
2025-12-09 10:24:38.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 4982 LR: 0.000510629840909286 Training loss: 0.0
2025-12-09 10:24:38.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 4983 LR: 0.0005104712099416785 Training loss: 0.0
2025-12-09 10:24:38.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 4984 LR: 0.0005103125779196204 Training loss: 0.0
2025-12-09 10:24:38.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 4985 LR: 0.0005101539448590859 Training loss: 0.0
2025-12-09 10:24:38.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 4986 LR: 0.0005099953107760494 Training loss: 0.0
2025-12-09 10:24:38.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 4987 LR: 0.0005098366756864856 Training loss: 0.0
2025-12-09 10:24:38.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 4988 LR: 0.0005096780396063686 Training loss: 0.0
2025-12-09 10:24:38.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 4989 LR: 0.0005095194025516733 Training loss: 0.0
2025-12-09 10:24:38.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 4990 LR: 0.0005093607645383745 Training loss: 0.0
2025-12-09 10:24:38.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 4991 LR: 0.000509202125582447 Training loss: 0.0
2025-12-09 10:24:38.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 4992 LR: 0.0005090434856998656 Training loss: 0.0
2025-12-09 10:24:38.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 4993 LR: 0.0005088848449066054 Training loss: 0.0
2025-12-09 10:24:38.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 4994 LR: 0.0005087262032186418 Training loss: 0.0
2025-12-09 10:24:38.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 4995 LR: 0.0005085675606519497 Training loss: 0.0
2025-12-09 10:24:38.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 4996 LR: 0.0005084089172225042 Training loss: 0.0
2025-12-09 10:24:38.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 4997 LR: 0.0005082502729462813 Training loss: 0.0
2025-12-09 10:24:38.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 4998 LR: 0.000508091627839256 Training loss: 0.0
2025-12-09 10:24:38.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 4999 LR: 0.000507932981917404 Training loss: 0.0
2025-12-09 10:24:38.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 5000 LR: 0.0005077743351967009 Training loss: 0.0
2025-12-09 10:24:38.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 5001 LR: 0.0005076156876931225 Training loss: 0.0
2025-12-09 10:24:38.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 5002 LR: 0.0005074570394226446 Training loss: 0.0
2025-12-09 10:24:38.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 5003 LR: 0.0005072983904012429 Training loss: 0.0
2025-12-09 10:24:38.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 5004 LR: 0.0005071397406448937 Training loss: 0.0
2025-12-09 10:24:38.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 5005 LR: 0.0005069810901695728 Training loss: 0.0
2025-12-09 10:24:38.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 5006 LR: 0.000506822438991256 Training loss: 0.0
2025-12-09 10:24:38.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 5007 LR: 0.0005066637871259201 Training loss: 0.0
2025-12-09 10:24:38.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 5008 LR: 0.000506505134589541 Training loss: 0.0
2025-12-09 10:24:38.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 5009 LR: 0.0005063464813980949 Training loss: 0.0
2025-12-09 10:24:38.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 5010 LR: 0.0005061878275675583 Training loss: 0.0
2025-12-09 10:24:38.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 5011 LR: 0.0005060291731139076 Training loss: 0.0
2025-12-09 10:24:38.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 5012 LR: 0.0005058705180531193 Training loss: 0.0
2025-12-09 10:24:38.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 5013 LR: 0.0005057118624011702 Training loss: 0.0
2025-12-09 10:24:38.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 5014 LR: 0.0005055532061740367 Training loss: 0.0
2025-12-09 10:24:38.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 5015 LR: 0.0005053945493876952 Training loss: 0.0
2025-12-09 10:24:38.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 5016 LR: 0.0005052358920581229 Training loss: 0.0
2025-12-09 10:24:38.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 5017 LR: 0.0005050772342012966 Training loss: 0.0
2025-12-09 10:24:38.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 5018 LR: 0.0005049185758331927 Training loss: 0.0
2025-12-09 10:24:38.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 5019 LR: 0.0005047599169697884 Training loss: 0.0
2025-12-09 10:24:38.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 5020 LR: 0.0005046012576270606 Training loss: 0.0
2025-12-09 10:24:38.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 5021 LR: 0.0005044425978209863 Training loss: 0.0
2025-12-09 10:24:38.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 5022 LR: 0.0005042839375675425 Training loss: 0.0
2025-12-09 10:24:38.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 5023 LR: 0.0005041252768827063 Training loss: 0.0
2025-12-09 10:24:38.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 5024 LR: 0.0005039666157824549 Training loss: 0.0
2025-12-09 10:24:38.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 5025 LR: 0.0005038079542827653 Training loss: 0.0
2025-12-09 10:24:38.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 5026 LR: 0.0005036492923996149 Training loss: 0.0
2025-12-09 10:24:38.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 5027 LR: 0.0005034906301489807 Training loss: 0.0
2025-12-09 10:24:38.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 5028 LR: 0.0005033319675468403 Training loss: 0.0
2025-12-09 10:24:38.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 5029 LR: 0.000503173304609171 Training loss: 0.0
2025-12-09 10:24:38.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 5030 LR: 0.0005030146413519497 Training loss: 0.0
2025-12-09 10:24:38.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 5031 LR: 0.0005028559777911542 Training loss: 0.0
2025-12-09 10:24:38.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 5032 LR: 0.0005026973139427618 Training loss: 0.0
2025-12-09 10:24:38.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 5033 LR: 0.0005025386498227502 Training loss: 0.0
2025-12-09 10:24:38.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 5034 LR: 0.0005023799854470963 Training loss: 0.0
2025-12-09 10:24:38.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 5035 LR: 0.0005022213208317781 Training loss: 0.0
2025-12-09 10:24:38.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 5036 LR: 0.000502062655992773 Training loss: 0.0
2025-12-09 10:24:38.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 5037 LR: 0.0005019039909460583 Training loss: 0.0
2025-12-09 10:24:38.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 5038 LR: 0.0005017453257076119 Training loss: 0.0
2025-12-09 10:24:38.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 5039 LR: 0.0005015866602934111 Training loss: 0.0
2025-12-09 10:24:38.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 5040 LR: 0.000501427994719434 Training loss: 0.0
2025-12-09 10:24:38.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 5041 LR: 0.0005012693290016576 Training loss: 0.0
2025-12-09 10:24:38.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 5042 LR: 0.0005011106631560598 Training loss: 0.0
2025-12-09 10:24:38.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 5043 LR: 0.0005009519971986183 Training loss: 0.0
2025-12-09 10:24:38.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 5044 LR: 0.0005007933311453107 Training loss: 0.0
2025-12-09 10:24:38.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 5045 LR: 0.0005006346650121147 Training loss: 0.0
2025-12-09 10:24:38.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 5046 LR: 0.0005004759988150079 Training loss: 0.0
2025-12-09 10:24:38.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 5047 LR: 0.0005003173325699681 Training loss: 0.0
2025-12-09 10:24:38.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 5048 LR: 0.0005001586662929731 Training loss: 0.0
2025-12-09 10:24:38.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 5049 LR: 0.0005 Training loss: 0.0
2025-12-09 10:24:38.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 5050 LR: 0.0004998413337070272 Training loss: 0.0
2025-12-09 10:24:38.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 5051 LR: 0.000499682667430032 Training loss: 0.0
2025-12-09 10:24:38.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 5052 LR: 0.0004995240011849922 Training loss: 0.0
2025-12-09 10:24:38.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 5053 LR: 0.0004993653349878853 Training loss: 0.0
2025-12-09 10:24:38.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 5054 LR: 0.0004992066688546894 Training loss: 0.0
2025-12-09 10:24:38.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 5055 LR: 0.0004990480028013818 Training loss: 0.0
2025-12-09 10:24:38.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 5056 LR: 0.0004988893368439404 Training loss: 0.0
2025-12-09 10:24:38.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 5057 LR: 0.0004987306709983425 Training loss: 0.0
2025-12-09 10:24:38.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 5058 LR: 0.0004985720052805662 Training loss: 0.0
2025-12-09 10:24:38.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 5059 LR: 0.0004984133397065889 Training loss: 0.0
2025-12-09 10:24:38.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 5060 LR: 0.0004982546742923883 Training loss: 0.0
2025-12-09 10:24:38.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 5061 LR: 0.0004980960090539417 Training loss: 0.0
2025-12-09 10:24:38.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 5062 LR: 0.0004979373440072273 Training loss: 0.0
2025-12-09 10:24:38.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 5063 LR: 0.000497778679168222 Training loss: 0.0
2025-12-09 10:24:38.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 5064 LR: 0.0004976200145529039 Training loss: 0.0
2025-12-09 10:24:38.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 5065 LR: 0.00049746135017725 Training loss: 0.0
2025-12-09 10:24:38.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 5066 LR: 0.0004973026860572382 Training loss: 0.0
2025-12-09 10:24:38.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 5067 LR: 0.0004971440222088459 Training loss: 0.0
2025-12-09 10:24:38.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 5068 LR: 0.0004969853586480504 Training loss: 0.0
2025-12-09 10:24:38.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 5069 LR: 0.0004968266953908291 Training loss: 0.0
2025-12-09 10:24:38.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 5070 LR: 0.0004966680324531598 Training loss: 0.0
2025-12-09 10:24:38.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 5071 LR: 0.0004965093698510193 Training loss: 0.0
2025-12-09 10:24:38.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 5072 LR: 0.0004963507076003853 Training loss: 0.0
2025-12-09 10:24:38.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 5073 LR: 0.0004961920457172347 Training loss: 0.0
2025-12-09 10:24:38.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 5074 LR: 0.0004960333842175453 Training loss: 0.0
2025-12-09 10:24:38.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 5075 LR: 0.0004958747231172938 Training loss: 0.0
2025-12-09 10:24:38.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 5076 LR: 0.0004957160624324576 Training loss: 0.0
2025-12-09 10:24:38.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 5077 LR: 0.0004955574021790137 Training loss: 0.0
2025-12-09 10:24:38.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 5078 LR: 0.0004953987423729396 Training loss: 0.0
2025-12-09 10:24:38.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 5079 LR: 0.0004952400830302117 Training loss: 0.0
2025-12-09 10:24:38.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 5080 LR: 0.0004950814241668076 Training loss: 0.0
2025-12-09 10:24:38.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 5081 LR: 0.0004949227657987035 Training loss: 0.0
2025-12-09 10:24:38.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 5082 LR: 0.0004947641079418773 Training loss: 0.0
2025-12-09 10:24:38.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 5083 LR: 0.0004946054506123048 Training loss: 0.0
2025-12-09 10:24:38.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 5084 LR: 0.0004944467938259636 Training loss: 0.0
2025-12-09 10:24:38.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 5085 LR: 0.00049428813759883 Training loss: 0.0
2025-12-09 10:24:38.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 5086 LR: 0.0004941294819468808 Training loss: 0.0
2025-12-09 10:24:38.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 5087 LR: 0.0004939708268860924 Training loss: 0.0
2025-12-09 10:24:38.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 5088 LR: 0.000493812172432442 Training loss: 0.0
2025-12-09 10:24:38.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 5089 LR: 0.0004936535186019053 Training loss: 0.0
2025-12-09 10:24:38.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 5090 LR: 0.0004934948654104593 Training loss: 0.0
2025-12-09 10:24:38.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 5091 LR: 0.0004933362128740799 Training loss: 0.0
2025-12-09 10:24:38.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 5092 LR: 0.000493177561008744 Training loss: 0.0
2025-12-09 10:24:38.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 5093 LR: 0.0004930189098304274 Training loss: 0.0
2025-12-09 10:24:38.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 5094 LR: 0.0004928602593551065 Training loss: 0.0
2025-12-09 10:24:38.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 5095 LR: 0.000492701609598757 Training loss: 0.0
2025-12-09 10:24:38.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 5096 LR: 0.0004925429605773555 Training loss: 0.0
2025-12-09 10:24:38.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 5097 LR: 0.0004923843123068775 Training loss: 0.0
2025-12-09 10:24:38.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 5098 LR: 0.0004922256648032992 Training loss: 0.0
2025-12-09 10:24:38.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 5099 LR: 0.000492067018082596 Training loss: 0.0
2025-12-09 10:24:38.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 5100 LR: 0.0004919083721607441 Training loss: 0.0
2025-12-09 10:24:38.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 5101 LR: 0.0004917497270537188 Training loss: 0.0
2025-12-09 10:24:38.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 5102 LR: 0.0004915910827774958 Training loss: 0.0
2025-12-09 10:24:38.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 5103 LR: 0.0004914324393480503 Training loss: 0.0
2025-12-09 10:24:38.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 5104 LR: 0.0004912737967813582 Training loss: 0.0
2025-12-09 10:24:38.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 5105 LR: 0.0004911151550933945 Training loss: 0.0
2025-12-09 10:24:38.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 5106 LR: 0.0004909565143001345 Training loss: 0.0
2025-12-09 10:24:38.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 5107 LR: 0.000490797874417553 Training loss: 0.0
2025-12-09 10:24:38.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 5108 LR: 0.0004906392354616255 Training loss: 0.0
2025-12-09 10:24:38.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 5109 LR: 0.0004904805974483267 Training loss: 0.0
2025-12-09 10:24:38.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 5110 LR: 0.0004903219603936314 Training loss: 0.0
2025-12-09 10:24:38.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 5111 LR: 0.0004901633243135144 Training loss: 0.0
2025-12-09 10:24:38.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 5112 LR: 0.0004900046892239506 Training loss: 0.0
2025-12-09 10:24:38.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 5113 LR: 0.000489846055140914 Training loss: 0.0
2025-12-09 10:24:38.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 5114 LR: 0.0004896874220803797 Training loss: 0.0
2025-12-09 10:24:38.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 5115 LR: 0.0004895287900583215 Training loss: 0.0
2025-12-09 10:24:38.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 5116 LR: 0.0004893701590907141 Training loss: 0.0
2025-12-09 10:24:38.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 5117 LR: 0.000489211529193531 Training loss: 0.0
2025-12-09 10:24:38.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 5118 LR: 0.0004890529003827469 Training loss: 0.0
2025-12-09 10:24:38.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 5119 LR: 0.0004888942726743353 Training loss: 0.0
2025-12-09 10:24:38.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 5120 LR: 0.0004887356460842703 Training loss: 0.0
2025-12-09 10:24:38.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 5121 LR: 0.0004885770206285252 Training loss: 0.0
2025-12-09 10:24:38.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 5122 LR: 0.000488418396323074 Training loss: 0.0
2025-12-09 10:24:38.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 5123 LR: 0.0004882597731838898 Training loss: 0.0
2025-12-09 10:24:38.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 5124 LR: 0.00048810115122694634 Training loss: 0.0
2025-12-09 10:24:38.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 5125 LR: 0.00048794253046821633 Training loss: 0.0
2025-12-09 10:24:38.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 5126 LR: 0.00048778391092367345 Training loss: 0.0
2025-12-09 10:24:38.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 5127 LR: 0.0004876252926092903 Training loss: 0.0
2025-12-09 10:24:38.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 5128 LR: 0.0004874666755410399 Training loss: 0.0
2025-12-09 10:24:38.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 5129 LR: 0.0004873080597348947 Training loss: 0.0
2025-12-09 10:24:38.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 5130 LR: 0.0004871494452068279 Training loss: 0.0
2025-12-09 10:24:38.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 5131 LR: 0.00048699083197281136 Training loss: 0.0
2025-12-09 10:24:38.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 5132 LR: 0.00048683222004881785 Training loss: 0.0
2025-12-09 10:24:38.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 5133 LR: 0.0004866736094508191 Training loss: 0.0
2025-12-09 10:24:38.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 5134 LR: 0.0004865150001947879 Training loss: 0.0
2025-12-09 10:24:38.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 5135 LR: 0.0004863563922966957 Training loss: 0.0
2025-12-09 10:24:38.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 5136 LR: 0.00048619778577251434 Training loss: 0.0
2025-12-09 10:24:38.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 5137 LR: 0.00048603918063821566 Training loss: 0.0
2025-12-09 10:24:38.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 5138 LR: 0.00048588057690977094 Training loss: 0.0
2025-12-09 10:24:38.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 5139 LR: 0.0004857219746031519 Training loss: 0.0
2025-12-09 10:24:38.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 5140 LR: 0.00048556337373432956 Training loss: 0.0
2025-12-09 10:24:38.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 5141 LR: 0.0004854047743192752 Training loss: 0.0
2025-12-09 10:24:38.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 5142 LR: 0.00048524617637395943 Training loss: 0.0
2025-12-09 10:24:38.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 5143 LR: 0.00048508757991435367 Training loss: 0.0
2025-12-09 10:24:38.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 5144 LR: 0.00048492898495642786 Training loss: 0.0
2025-12-09 10:24:38.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 5145 LR: 0.00048477039151615303 Training loss: 0.0
2025-12-09 10:24:38.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 5146 LR: 0.00048461179960949925 Training loss: 0.0
2025-12-09 10:24:38.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 5147 LR: 0.00048445320925243697 Training loss: 0.0
2025-12-09 10:24:38.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 5148 LR: 0.00048429462046093585 Training loss: 0.0
2025-12-09 10:24:38.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 5149 LR: 0.0004841360332509663 Training loss: 0.0
2025-12-09 10:24:38.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 5150 LR: 0.0004839774476384976 Training loss: 0.0
2025-12-09 10:24:38.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 5151 LR: 0.00048381886363949955 Training loss: 0.0
2025-12-09 10:24:38.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 5152 LR: 0.0004836602812699413 Training loss: 0.0
2025-12-09 10:24:38.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 5153 LR: 0.00048350170054579255 Training loss: 0.0
2025-12-09 10:24:38.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 5154 LR: 0.000483343121483022 Training loss: 0.0
2025-12-09 10:24:38.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 5155 LR: 0.00048318454409759874 Training loss: 0.0
2025-12-09 10:24:38.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 5156 LR: 0.0004830259684054912 Training loss: 0.0
2025-12-09 10:24:38.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 5157 LR: 0.00048286739442266835 Training loss: 0.0
2025-12-09 10:24:38.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 5158 LR: 0.00048270882216509836 Training loss: 0.0
2025-12-09 10:24:38.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 5159 LR: 0.0004825502516487497 Training loss: 0.0
2025-12-09 10:24:38.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 5160 LR: 0.00048239168288958986 Training loss: 0.0
2025-12-09 10:24:38.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 5161 LR: 0.00048223311590358734 Training loss: 0.0
2025-12-09 10:24:38.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 5162 LR: 0.0004820745507067095 Training loss: 0.0
2025-12-09 10:24:38.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 5163 LR: 0.0004819159873149239 Training loss: 0.0
2025-12-09 10:24:38.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 5164 LR: 0.0004817574257441978 Training loss: 0.0
2025-12-09 10:24:38.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 5165 LR: 0.0004815988660104986 Training loss: 0.0
2025-12-09 10:24:38.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 5166 LR: 0.00048144030812979287 Training loss: 0.0
2025-12-09 10:24:38.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 5167 LR: 0.00048128175211804787 Training loss: 0.0
2025-12-09 10:24:38.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 5168 LR: 0.0004811231979912296 Training loss: 0.0
2025-12-09 10:24:38.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 5169 LR: 0.00048096464576530507 Training loss: 0.0
2025-12-09 10:24:38.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 5170 LR: 0.00048080609545624004 Training loss: 0.0
2025-12-09 10:24:38.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 5171 LR: 0.0004806475470800008 Training loss: 0.0
2025-12-09 10:24:38.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 5172 LR: 0.0004804890006525528 Training loss: 0.0
2025-12-09 10:24:38.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 5173 LR: 0.00048033045618986215 Training loss: 0.0
2025-12-09 10:24:38.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 5174 LR: 0.00048017191370789385 Training loss: 0.0
2025-12-09 10:24:38.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 5175 LR: 0.00048001337322261346 Training loss: 0.0
2025-12-09 10:24:38.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 5176 LR: 0.00047985483474998576 Training loss: 0.0
2025-12-09 10:24:38.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 5177 LR: 0.00047969629830597573 Training loss: 0.0
2025-12-09 10:24:38.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 5178 LR: 0.00047953776390654765 Training loss: 0.0
2025-12-09 10:24:38.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 5179 LR: 0.00047937923156766646 Training loss: 0.0
2025-12-09 10:24:38.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 5180 LR: 0.0004792207013052959 Training loss: 0.0
2025-12-09 10:24:38.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 5181 LR: 0.0004790621731354003 Training loss: 0.0
2025-12-09 10:24:38.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 5182 LR: 0.00047890364707394307 Training loss: 0.0
2025-12-09 10:24:38.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 5183 LR: 0.0004787451231368882 Training loss: 0.0
2025-12-09 10:24:38.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 5184 LR: 0.0004785866013401988 Training loss: 0.0
2025-12-09 10:24:38.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 5185 LR: 0.0004784280816998382 Training loss: 0.0
2025-12-09 10:24:38.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 5186 LR: 0.00047826956423176886 Training loss: 0.0
2025-12-09 10:24:38.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 5187 LR: 0.00047811104895195407 Training loss: 0.0
2025-12-09 10:24:38.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 5188 LR: 0.00047795253587635595 Training loss: 0.0
2025-12-09 10:24:38.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 5189 LR: 0.00047779402502093696 Training loss: 0.0
2025-12-09 10:24:38.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 5190 LR: 0.0004776355164016588 Training loss: 0.0
2025-12-09 10:24:38.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 5191 LR: 0.0004774770100344838 Training loss: 0.0
2025-12-09 10:24:38.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 5192 LR: 0.00047731850593537314 Training loss: 0.0
2025-12-09 10:24:38.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 5193 LR: 0.0004771600041202884 Training loss: 0.0
2025-12-09 10:24:38.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 5194 LR: 0.00047700150460519043 Training loss: 0.0
2025-12-09 10:24:38.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 5195 LR: 0.00047684300740604053 Training loss: 0.0
2025-12-09 10:24:38.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 5196 LR: 0.000476684512538799 Training loss: 0.0
2025-12-09 10:24:38.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 5197 LR: 0.00047652602001942656 Training loss: 0.0
2025-12-09 10:24:38.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 5198 LR: 0.000476367529863883 Training loss: 0.0
2025-12-09 10:24:38.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 5199 LR: 0.0004762090420881289 Training loss: 0.0
2025-12-09 10:24:38.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 5200 LR: 0.00047605055670812334 Training loss: 0.0
2025-12-09 10:24:38.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 5201 LR: 0.0004758920737398263 Training loss: 0.0
2025-12-09 10:24:38.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 5202 LR: 0.00047573359319919646 Training loss: 0.0
2025-12-09 10:24:38.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 5203 LR: 0.00047557511510219335 Training loss: 0.0
2025-12-09 10:24:38.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 5204 LR: 0.00047541663946477545 Training loss: 0.0
2025-12-09 10:24:38.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 5205 LR: 0.0004752581663029013 Training loss: 0.0
2025-12-09 10:24:38.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 5206 LR: 0.000475099695632529 Training loss: 0.0
2025-12-09 10:24:38.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 5207 LR: 0.00047494122746961686 Training loss: 0.0
2025-12-09 10:24:38.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 5208 LR: 0.0004747827618301222 Training loss: 0.0
2025-12-09 10:24:38.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 5209 LR: 0.00047462429873000296 Training loss: 0.0
2025-12-09 10:24:38.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 5210 LR: 0.000474465838185216 Training loss: 0.0
2025-12-09 10:24:38.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 5211 LR: 0.00047430738021171854 Training loss: 0.0
2025-12-09 10:24:38.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 5212 LR: 0.000474148924825467 Training loss: 0.0
2025-12-09 10:24:38.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 5213 LR: 0.00047399047204241826 Training loss: 0.0
2025-12-09 10:24:38.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 5214 LR: 0.0004738320218785281 Training loss: 0.0
2025-12-09 10:24:38.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 5215 LR: 0.0004736735743497528 Training loss: 0.0
2025-12-09 10:24:38.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 5216 LR: 0.00047351512947204754 Training loss: 0.0
2025-12-09 10:24:38.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 5217 LR: 0.0004733566872613683 Training loss: 0.0
2025-12-09 10:24:38.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 5218 LR: 0.00047319824773366976 Training loss: 0.0
2025-12-09 10:24:38.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 5219 LR: 0.0004730398109049071 Training loss: 0.0
2025-12-09 10:24:38.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 5220 LR: 0.0004728813767910347 Training loss: 0.0
2025-12-09 10:24:38.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 5221 LR: 0.0004727229454080068 Training loss: 0.0
2025-12-09 10:24:38.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 5222 LR: 0.00047256451677177763 Training loss: 0.0
2025-12-09 10:24:38.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 5223 LR: 0.00047240609089830085 Training loss: 0.0
2025-12-09 10:24:38.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 5224 LR: 0.00047224766780353 Training loss: 0.0
2025-12-09 10:24:38.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 5225 LR: 0.00047208924750341807 Training loss: 0.0
2025-12-09 10:24:38.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 5226 LR: 0.0004719308300139184 Training loss: 0.0
2025-12-09 10:24:38.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 5227 LR: 0.00047177241535098323 Training loss: 0.0
2025-12-09 10:24:38.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 5228 LR: 0.0004716140035305652 Training loss: 0.0
2025-12-09 10:24:38.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 5229 LR: 0.000471455594568616 Training loss: 0.0
2025-12-09 10:24:38.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 5230 LR: 0.00047129718848108786 Training loss: 0.0
2025-12-09 10:24:38.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 5231 LR: 0.00047113878528393197 Training loss: 0.0
2025-12-09 10:24:38.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 5232 LR: 0.0004709803849930997 Training loss: 0.0
2025-12-09 10:24:38.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 5233 LR: 0.0004708219876245416 Training loss: 0.0
2025-12-09 10:24:38.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 5234 LR: 0.0004706635931942089 Training loss: 0.0
2025-12-09 10:24:38.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 5235 LR: 0.00047050520171805136 Training loss: 0.0
2025-12-09 10:24:38.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 5236 LR: 0.0004703468132120193 Training loss: 0.0
2025-12-09 10:24:38.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 5237 LR: 0.0004701884276920622 Training loss: 0.0
2025-12-09 10:24:38.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 5238 LR: 0.0004700300451741298 Training loss: 0.0
2025-12-09 10:24:38.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 5239 LR: 0.00046987166567417086 Training loss: 0.0
2025-12-09 10:24:38.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 5240 LR: 0.00046971328920813446 Training loss: 0.0
2025-12-09 10:24:38.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 5241 LR: 0.00046955491579196896 Training loss: 0.0
2025-12-09 10:24:38.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 5242 LR: 0.0004693965454416227 Training loss: 0.0
2025-12-09 10:24:38.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 5243 LR: 0.00046923817817304324 Training loss: 0.0
2025-12-09 10:24:38.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 5244 LR: 0.00046907981400217866 Training loss: 0.0
2025-12-09 10:24:38.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 5245 LR: 0.0004689214529449758 Training loss: 0.0
2025-12-09 10:24:38.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 5246 LR: 0.00046876309501738195 Training loss: 0.0
2025-12-09 10:24:38.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 5247 LR: 0.0004686047402353433 Training loss: 0.0
2025-12-09 10:24:38.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 5248 LR: 0.0004684463886148067 Training loss: 0.0
2025-12-09 10:24:38.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 5249 LR: 0.00046828804017171776 Training loss: 0.0
2025-12-09 10:24:38.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 5250 LR: 0.0004681296949220225 Training loss: 0.0
2025-12-09 10:24:38.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 5251 LR: 0.0004679713528816658 Training loss: 0.0
2025-12-09 10:24:38.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 5252 LR: 0.0004678130140665932 Training loss: 0.0
2025-12-09 10:24:38.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 5253 LR: 0.00046765467849274915 Training loss: 0.0
2025-12-09 10:24:38.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 5254 LR: 0.00046749634617607817 Training loss: 0.0
2025-12-09 10:24:38.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 5255 LR: 0.000467338017132524 Training loss: 0.0
2025-12-09 10:24:38.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 5256 LR: 0.00046717969137803086 Training loss: 0.0
2025-12-09 10:24:38.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 5257 LR: 0.00046702136892854177 Training loss: 0.0
2025-12-09 10:24:38.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 5258 LR: 0.00046686304980000004 Training loss: 0.0
2025-12-09 10:24:38.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 5259 LR: 0.00046670473400834805 Training loss: 0.0
2025-12-09 10:24:38.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 5260 LR: 0.0004665464215695287 Training loss: 0.0
2025-12-09 10:24:38.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 5261 LR: 0.00046638811249948367 Training loss: 0.0
2025-12-09 10:24:38.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 5262 LR: 0.00046622980681415484 Training loss: 0.0
2025-12-09 10:24:38.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 5263 LR: 0.0004660715045294834 Training loss: 0.0
2025-12-09 10:24:38.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 5264 LR: 0.00046591320566141074 Training loss: 0.0
2025-12-09 10:24:38.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 5265 LR: 0.0004657549102258771 Training loss: 0.0
2025-12-09 10:24:38.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 5266 LR: 0.00046559661823882334 Training loss: 0.0
2025-12-09 10:24:38.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 5267 LR: 0.0004654383297161889 Training loss: 0.0
2025-12-09 10:24:38.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 5268 LR: 0.00046528004467391397 Training loss: 0.0
2025-12-09 10:24:38.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 5269 LR: 0.00046512176312793734 Training loss: 0.0
2025-12-09 10:24:38.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 5270 LR: 0.0004649634850941984 Training loss: 0.0
2025-12-09 10:24:38.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 5271 LR: 0.00046480521058863544 Training loss: 0.0
2025-12-09 10:24:38.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 5272 LR: 0.00046464693962718697 Training loss: 0.0
2025-12-09 10:24:38.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 5273 LR: 0.00046448867222579043 Training loss: 0.0
2025-12-09 10:24:38.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 5274 LR: 0.00046433040840038387 Training loss: 0.0
2025-12-09 10:24:38.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 5275 LR: 0.0004641721481669041 Training loss: 0.0
2025-12-09 10:24:38.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 5276 LR: 0.00046401389154128816 Training loss: 0.0
2025-12-09 10:24:38.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 5277 LR: 0.0004638556385394721 Training loss: 0.0
2025-12-09 10:24:38.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 5278 LR: 0.0004636973891773925 Training loss: 0.0
2025-12-09 10:24:38.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 5279 LR: 0.00046353914347098467 Training loss: 0.0
2025-12-09 10:24:38.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 5280 LR: 0.00046338090143618427 Training loss: 0.0
2025-12-09 10:24:38.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 5281 LR: 0.0004632226630889258 Training loss: 0.0
2025-12-09 10:24:38.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 5282 LR: 0.0004630644284451444 Training loss: 0.0
2025-12-09 10:24:38.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 5283 LR: 0.00046290619752077395 Training loss: 0.0
2025-12-09 10:24:38.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 5284 LR: 0.0004627479703317485 Training loss: 0.0
2025-12-09 10:24:38.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 5285 LR: 0.0004625897468940012 Training loss: 0.0
2025-12-09 10:24:38.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 5286 LR: 0.00046243152722346553 Training loss: 0.0
2025-12-09 10:24:38.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 5287 LR: 0.00046227331133607397 Training loss: 0.0
2025-12-09 10:24:38.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 5288 LR: 0.0004621150992477591 Training loss: 0.0
2025-12-09 10:24:38.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 5289 LR: 0.0004619568909744524 Training loss: 0.0
2025-12-09 10:24:38.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 5290 LR: 0.000461798686532086 Training loss: 0.0
2025-12-09 10:24:38.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 5291 LR: 0.0004616404859365907 Training loss: 0.0
2025-12-09 10:24:38.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 5292 LR: 0.00046148228920389747 Training loss: 0.0
2025-12-09 10:24:38.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 5293 LR: 0.0004613240963499365 Training loss: 0.0
2025-12-09 10:24:38.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 5294 LR: 0.0004611659073906382 Training loss: 0.0
2025-12-09 10:24:38.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 5295 LR: 0.00046100772234193186 Training loss: 0.0
2025-12-09 10:24:38.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 5296 LR: 0.00046084954121974685 Training loss: 0.0
2025-12-09 10:24:38.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 5297 LR: 0.0004606913640400118 Training loss: 0.0
2025-12-09 10:24:38.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 5298 LR: 0.00046053319081865553 Training loss: 0.0
2025-12-09 10:24:38.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 5299 LR: 0.00046037502157160573 Training loss: 0.0
2025-12-09 10:24:38.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 5300 LR: 0.00046021685631479034 Training loss: 0.0
2025-12-09 10:24:38.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 5301 LR: 0.0004600586950641362 Training loss: 0.0
2025-12-09 10:24:38.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 5302 LR: 0.00045990053783557063 Training loss: 0.0
2025-12-09 10:24:38.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 5303 LR: 0.0004597423846450196 Training loss: 0.0
2025-12-09 10:24:38.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 5304 LR: 0.0004595842355084094 Training loss: 0.0
2025-12-09 10:24:38.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 5305 LR: 0.0004594260904416656 Training loss: 0.0
2025-12-09 10:24:38.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 5306 LR: 0.00045926794946071336 Training loss: 0.0
2025-12-09 10:24:38.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 5307 LR: 0.0004591098125814776 Training loss: 0.0
2025-12-09 10:24:38.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 5308 LR: 0.00045895167981988233 Training loss: 0.0
2025-12-09 10:24:38.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 5309 LR: 0.00045879355119185207 Training loss: 0.0
2025-12-09 10:24:38.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 5310 LR: 0.00045863542671330986 Training loss: 0.0
2025-12-09 10:24:38.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 5311 LR: 0.00045847730640017926 Training loss: 0.0
2025-12-09 10:24:38.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 5312 LR: 0.0004583191902683825 Training loss: 0.0
2025-12-09 10:24:38.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 5313 LR: 0.00045816107833384235 Training loss: 0.0
2025-12-09 10:24:38.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 5314 LR: 0.00045800297061248036 Training loss: 0.0
2025-12-09 10:24:38.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 5315 LR: 0.00045784486712021824 Training loss: 0.0
2025-12-09 10:24:38.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 5316 LR: 0.00045768676787297653 Training loss: 0.0
2025-12-09 10:24:38.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 5317 LR: 0.00045752867288667646 Training loss: 0.0
2025-12-09 10:24:38.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 5318 LR: 0.0004573705821772377 Training loss: 0.0
2025-12-09 10:24:38.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 5319 LR: 0.0004572124957605803 Training loss: 0.0
2025-12-09 10:24:38.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 5320 LR: 0.00045705441365262315 Training loss: 0.0
2025-12-09 10:24:38.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 5321 LR: 0.0004568963358692856 Training loss: 0.0
2025-12-09 10:24:38.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 5322 LR: 0.0004567382624264857 Training loss: 0.0
2025-12-09 10:24:38.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 5323 LR: 0.00045658019334014174 Training loss: 0.0
2025-12-09 10:24:38.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 5324 LR: 0.00045642212862617086 Training loss: 0.0
2025-12-09 10:24:38.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 5325 LR: 0.0004562640683004907 Training loss: 0.0
2025-12-09 10:24:38.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 5326 LR: 0.00045610601237901753 Training loss: 0.0
2025-12-09 10:24:38.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 5327 LR: 0.00045594796087766786 Training loss: 0.0
2025-12-09 10:24:38.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 5328 LR: 0.0004557899138123571 Training loss: 0.0
2025-12-09 10:24:38.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 5329 LR: 0.00045563187119900103 Training loss: 0.0
2025-12-09 10:24:38.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 5330 LR: 0.0004554738330535142 Training loss: 0.0
2025-12-09 10:24:38.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 5331 LR: 0.00045531579939181124 Training loss: 0.0
2025-12-09 10:24:38.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 5332 LR: 0.00045515777022980597 Training loss: 0.0
2025-12-09 10:24:38.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 5333 LR: 0.0004549997455834121 Training loss: 0.0
2025-12-09 10:24:38.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 5334 LR: 0.0004548417254685425 Training loss: 0.0
2025-12-09 10:24:38.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 5335 LR: 0.00045468370990111 Training loss: 0.0
2025-12-09 10:24:38.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 5336 LR: 0.0004545256988970266 Training loss: 0.0
2025-12-09 10:24:38.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 5337 LR: 0.0004543676924722042 Training loss: 0.0
2025-12-09 10:24:38.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 5338 LR: 0.00045420969064255374 Training loss: 0.0
2025-12-09 10:24:38.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 5339 LR: 0.00045405169342398633 Training loss: 0.0
2025-12-09 10:24:38.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 5340 LR: 0.0004538937008324121 Training loss: 0.0
2025-12-09 10:24:38.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 5341 LR: 0.000453735712883741 Training loss: 0.0
2025-12-09 10:24:38.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 5342 LR: 0.0004535777295938821 Training loss: 0.0
2025-12-09 10:24:38.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 5343 LR: 0.00045341975097874484 Training loss: 0.0
2025-12-09 10:24:38.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 5344 LR: 0.0004532617770542372 Training loss: 0.0
2025-12-09 10:24:38.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 5345 LR: 0.0004531038078362675 Training loss: 0.0
2025-12-09 10:24:38.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 5346 LR: 0.00045294584334074284 Training loss: 0.0
2025-12-09 10:24:38.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 5347 LR: 0.00045278788358357064 Training loss: 0.0
2025-12-09 10:24:38.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 5348 LR: 0.0004526299285806572 Training loss: 0.0
2025-12-09 10:24:38.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 5349 LR: 0.0004524719783479088 Training loss: 0.0
2025-12-09 10:24:38.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 5350 LR: 0.00045231403290123056 Training loss: 0.0
2025-12-09 10:24:38.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 5351 LR: 0.0004521560922565282 Training loss: 0.0
2025-12-09 10:24:38.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 5352 LR: 0.00045199815642970594 Training loss: 0.0
2025-12-09 10:24:38.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 5353 LR: 0.0004518402254366681 Training loss: 0.0
2025-12-09 10:24:38.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 5354 LR: 0.000451682299293318 Training loss: 0.0
2025-12-09 10:24:38.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 5355 LR: 0.0004515243780155593 Training loss: 0.0
2025-12-09 10:24:38.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 5356 LR: 0.0004513664616192943 Training loss: 0.0
2025-12-09 10:24:38.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 5357 LR: 0.0004512085501204253 Training loss: 0.0
2025-12-09 10:24:38.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 5358 LR: 0.00045105064353485386 Training loss: 0.0
2025-12-09 10:24:38.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 5359 LR: 0.00045089274187848144 Training loss: 0.0
2025-12-09 10:24:38.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 5360 LR: 0.00045073484516720846 Training loss: 0.0
2025-12-09 10:24:38.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 5361 LR: 0.0004505769534169354 Training loss: 0.0
2025-12-09 10:24:38.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 5362 LR: 0.00045041906664356146 Training loss: 0.0
2025-12-09 10:24:38.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 5363 LR: 0.00045026118486298655 Training loss: 0.0
2025-12-09 10:24:38.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 5364 LR: 0.0004501033080911086 Training loss: 0.0
2025-12-09 10:24:38.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 5365 LR: 0.0004499454363438264 Training loss: 0.0
2025-12-09 10:24:38.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 5366 LR: 0.00044978756963703724 Training loss: 0.0
2025-12-09 10:24:38.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 5367 LR: 0.00044962970798663866 Training loss: 0.0
2025-12-09 10:24:38.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 5368 LR: 0.0004494718514085268 Training loss: 0.0
2025-12-09 10:24:38.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 5369 LR: 0.00044931399991859835 Training loss: 0.0
2025-12-09 10:24:38.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 5370 LR: 0.0004491561535327486 Training loss: 0.0
2025-12-09 10:24:38.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 5371 LR: 0.00044899831226687294 Training loss: 0.0
2025-12-09 10:24:38.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 5372 LR: 0.0004488404761368656 Training loss: 0.0
2025-12-09 10:24:38.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 5373 LR: 0.00044868264515862113 Training loss: 0.0
2025-12-09 10:24:38.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 5374 LR: 0.0004485248193480328 Training loss: 0.0
2025-12-09 10:24:38.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 5375 LR: 0.00044836699872099383 Training loss: 0.0
2025-12-09 10:24:38.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 5376 LR: 0.0004482091832933965 Training loss: 0.0
2025-12-09 10:24:38.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 5377 LR: 0.0004480513730811332 Training loss: 0.0
2025-12-09 10:24:38.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 5378 LR: 0.00044789356810009506 Training loss: 0.0
2025-12-09 10:24:38.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 5379 LR: 0.00044773576836617336 Training loss: 0.0
2025-12-09 10:24:38.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 5380 LR: 0.00044757797389525806 Training loss: 0.0
2025-12-09 10:24:38.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 5381 LR: 0.00044742018470323965 Training loss: 0.0
2025-12-09 10:24:38.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 5382 LR: 0.00044726240080600706 Training loss: 0.0
2025-12-09 10:24:38.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 5383 LR: 0.00044710462221944934 Training loss: 0.0
2025-12-09 10:24:38.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 5384 LR: 0.00044694684895945453 Training loss: 0.0
2025-12-09 10:24:38.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 5385 LR: 0.0004467890810419108 Training loss: 0.0
2025-12-09 10:24:38.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 5386 LR: 0.00044663131848270507 Training loss: 0.0
2025-12-09 10:24:38.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 5387 LR: 0.0004464735612977242 Training loss: 0.0
2025-12-09 10:24:38.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 5388 LR: 0.000446315809502854 Training loss: 0.0
2025-12-09 10:24:38.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 5389 LR: 0.00044615806311398056 Training loss: 0.0
2025-12-09 10:24:38.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 5390 LR: 0.00044600032214698855 Training loss: 0.0
2025-12-09 10:24:38.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 5391 LR: 0.0004458425866177627 Training loss: 0.0
2025-12-09 10:24:38.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 5392 LR: 0.000445684856542187 Training loss: 0.0
2025-12-09 10:24:38.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 5393 LR: 0.0004455271319361445 Training loss: 0.0
2025-12-09 10:24:38.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 5394 LR: 0.0004453694128155186 Training loss: 0.0
2025-12-09 10:24:38.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 5395 LR: 0.000445211699196191 Training loss: 0.0
2025-12-09 10:24:38.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 5396 LR: 0.0004450539910940441 Training loss: 0.0
2025-12-09 10:24:38.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 5397 LR: 0.00044489628852495866 Training loss: 0.0
2025-12-09 10:24:38.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 5398 LR: 0.00044473859150481553 Training loss: 0.0
2025-12-09 10:24:38.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 5399 LR: 0.00044458090004949454 Training loss: 0.0
2025-12-09 10:24:38.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 5400 LR: 0.0004444232141748756 Training loss: 0.0
2025-12-09 10:24:38.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 5401 LR: 0.00044426553389683733 Training loss: 0.0
2025-12-09 10:24:38.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 5402 LR: 0.0004441078592312584 Training loss: 0.0
2025-12-09 10:24:38.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 5403 LR: 0.00044395019019401633 Training loss: 0.0
2025-12-09 10:24:38.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 5404 LR: 0.00044379252680098877 Training loss: 0.0
2025-12-09 10:24:38.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 5405 LR: 0.0004436348690680521 Training loss: 0.0
2025-12-09 10:24:38.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 5406 LR: 0.0004434772170110827 Training loss: 0.0
2025-12-09 10:24:38.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 5407 LR: 0.0004433195706459558 Training loss: 0.0
2025-12-09 10:24:38.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 5408 LR: 0.00044316192998854675 Training loss: 0.0
2025-12-09 10:24:38.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 5409 LR: 0.0004430042950547297 Training loss: 0.0
2025-12-09 10:24:38.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 5410 LR: 0.00044284666586037877 Training loss: 0.0
2025-12-09 10:24:38.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 5411 LR: 0.00044268904242136673 Training loss: 0.0
2025-12-09 10:24:38.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 5412 LR: 0.00044253142475356676 Training loss: 0.0
2025-12-09 10:24:38.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 5413 LR: 0.00044237381287285066 Training loss: 0.0
2025-12-09 10:24:38.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 5414 LR: 0.0004422162067950901 Training loss: 0.0
2025-12-09 10:24:38.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 5415 LR: 0.0004420586065361558 Training loss: 0.0
2025-12-09 10:24:38.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 5416 LR: 0.00044190101211191837 Training loss: 0.0
2025-12-09 10:24:38.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 5417 LR: 0.00044174342353824736 Training loss: 0.0
2025-12-09 10:24:38.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 5418 LR: 0.0004415858408310121 Training loss: 0.0
2025-12-09 10:24:38.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 5419 LR: 0.0004414282640060809 Training loss: 0.0
2025-12-09 10:24:38.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 5420 LR: 0.000441270693079322 Training loss: 0.0
2025-12-09 10:24:38.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 5421 LR: 0.00044111312806660276 Training loss: 0.0
2025-12-09 10:24:38.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 5422 LR: 0.0004409555689837899 Training loss: 0.0
2025-12-09 10:24:38.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 5423 LR: 0.0004407980158467495 Training loss: 0.0
2025-12-09 10:24:38.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 5424 LR: 0.00044064046867134756 Training loss: 0.0
2025-12-09 10:24:38.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 5425 LR: 0.0004404829274734485 Training loss: 0.0
2025-12-09 10:24:38.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 5426 LR: 0.00044032539226891715 Training loss: 0.0
2025-12-09 10:24:38.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 5427 LR: 0.0004401678630736172 Training loss: 0.0
2025-12-09 10:24:38.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 5428 LR: 0.0004400103399034118 Training loss: 0.0
2025-12-09 10:24:38.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 5429 LR: 0.0004398528227741633 Training loss: 0.0
2025-12-09 10:24:38.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 5430 LR: 0.0004396953117017342 Training loss: 0.0
2025-12-09 10:24:38.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 5431 LR: 0.0004395378067019854 Training loss: 0.0
2025-12-09 10:24:38.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 5432 LR: 0.0004393803077907779 Training loss: 0.0
2025-12-09 10:24:38.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 5433 LR: 0.0004392228149839716 Training loss: 0.0
2025-12-09 10:24:38.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 5434 LR: 0.00043906532829742634 Training loss: 0.0
2025-12-09 10:24:38.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 5435 LR: 0.0004389078477470008 Training loss: 0.0
2025-12-09 10:24:38.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 5436 LR: 0.0004387503733485533 Training loss: 0.0
2025-12-09 10:24:38.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 5437 LR: 0.00043859290511794144 Training loss: 0.0
2025-12-09 10:24:38.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 5438 LR: 0.0004384354430710225 Training loss: 0.0
2025-12-09 10:24:38.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 5439 LR: 0.00043827798722365264 Training loss: 0.0
2025-12-09 10:24:38.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 5440 LR: 0.000438120537591688 Training loss: 0.0
2025-12-09 10:24:38.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 5441 LR: 0.0004379630941909832 Training loss: 0.0
2025-12-09 10:24:38.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 5442 LR: 0.00043780565703739334 Training loss: 0.0
2025-12-09 10:24:38.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 5443 LR: 0.000437648226146772 Training loss: 0.0
2025-12-09 10:24:38.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 5444 LR: 0.0004374908015349728 Training loss: 0.0
2025-12-09 10:24:38.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 5445 LR: 0.00043733338321784784 Training loss: 0.0
2025-12-09 10:24:38.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 5446 LR: 0.00043717597121124976 Training loss: 0.0
2025-12-09 10:24:38.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 5447 LR: 0.00043701856553102946 Training loss: 0.0
2025-12-09 10:24:38.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 5448 LR: 0.00043686116619303804 Training loss: 0.0
2025-12-09 10:24:38.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 5449 LR: 0.00043670377321312535 Training loss: 0.0
2025-12-09 10:24:38.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 5450 LR: 0.00043654638660714105 Training loss: 0.0
2025-12-09 10:24:38.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 5451 LR: 0.0004363890063909338 Training loss: 0.0
2025-12-09 10:24:38.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 5452 LR: 0.000436231632580352 Training loss: 0.0
2025-12-09 10:24:38.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 5453 LR: 0.0004360742651912428 Training loss: 0.0
2025-12-09 10:24:38.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 5454 LR: 0.0004359169042394536 Training loss: 0.0
2025-12-09 10:24:38.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 5455 LR: 0.0004357595497408303 Training loss: 0.0
2025-12-09 10:24:38.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 5456 LR: 0.0004356022017112187 Training loss: 0.0
2025-12-09 10:24:38.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 5457 LR: 0.00043544486016646334 Training loss: 0.0
2025-12-09 10:24:38.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 5458 LR: 0.0004352875251224092 Training loss: 0.0
2025-12-09 10:24:38.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 5459 LR: 0.0004351301965948991 Training loss: 0.0
2025-12-09 10:24:38.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 5460 LR: 0.0004349728745997767 Training loss: 0.0
2025-12-09 10:24:38.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 5461 LR: 0.0004348155591528839 Training loss: 0.0
2025-12-09 10:24:38.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 5462 LR: 0.0004346582502700627 Training loss: 0.0
2025-12-09 10:24:38.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 5463 LR: 0.00043450094796715355 Training loss: 0.0
2025-12-09 10:24:38.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 5464 LR: 0.0004343436522599975 Training loss: 0.0
2025-12-09 10:24:38.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 5465 LR: 0.00043418636316443367 Training loss: 0.0
2025-12-09 10:24:38.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 5466 LR: 0.0004340290806963014 Training loss: 0.0
2025-12-09 10:24:38.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 5467 LR: 0.0004338718048714387 Training loss: 0.0
2025-12-09 10:24:38.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 5468 LR: 0.0004337145357056837 Training loss: 0.0
2025-12-09 10:24:38.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 5469 LR: 0.000433557273214873 Training loss: 0.0
2025-12-09 10:24:38.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 5470 LR: 0.00043340001741484313 Training loss: 0.0
2025-12-09 10:24:38.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 5471 LR: 0.0004332427683214295 Training loss: 0.0
2025-12-09 10:24:38.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 5472 LR: 0.0004330855259504675 Training loss: 0.0
2025-12-09 10:24:38.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 5473 LR: 0.00043292829031779114 Training loss: 0.0
2025-12-09 10:24:38.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 5474 LR: 0.0004327710614392341 Training loss: 0.0
2025-12-09 10:24:38.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 5475 LR: 0.0004326138393306292 Training loss: 0.0
2025-12-09 10:24:38.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 5476 LR: 0.00043245662400780903 Training loss: 0.0
2025-12-09 10:24:38.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 5477 LR: 0.000432299415486605 Training loss: 0.0
2025-12-09 10:24:38.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 5478 LR: 0.00043214221378284787 Training loss: 0.0
2025-12-09 10:24:38.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 5479 LR: 0.000431985018912368 Training loss: 0.0
2025-12-09 10:24:38.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 5480 LR: 0.00043182783089099476 Training loss: 0.0
2025-12-09 10:24:38.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 5481 LR: 0.0004316706497345572 Training loss: 0.0
2025-12-09 10:24:38.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 5482 LR: 0.0004315134754588833 Training loss: 0.0
2025-12-09 10:24:38.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 5483 LR: 0.0004313563080798006 Training loss: 0.0
2025-12-09 10:24:38.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 5484 LR: 0.0004311991476131356 Training loss: 0.0
2025-12-09 10:24:38.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 5485 LR: 0.0004310419940747148 Training loss: 0.0
2025-12-09 10:24:38.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 5486 LR: 0.00043088484748036315 Training loss: 0.0
2025-12-09 10:24:38.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 5487 LR: 0.00043072770784590564 Training loss: 0.0
2025-12-09 10:24:38.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 5488 LR: 0.00043057057518716593 Training loss: 0.0
2025-12-09 10:24:38.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 5489 LR: 0.0004304134495199674 Training loss: 0.0
2025-12-09 10:24:38.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 5490 LR: 0.0004302563308601325 Training loss: 0.0
2025-12-09 10:24:38.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 5491 LR: 0.00043009921922348336 Training loss: 0.0
2025-12-09 10:24:38.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 5492 LR: 0.0004299421146258408 Training loss: 0.0
2025-12-09 10:24:38.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 5493 LR: 0.00042978501708302555 Training loss: 0.0
2025-12-09 10:24:38.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 5494 LR: 0.0004296279266108569 Training loss: 0.0
2025-12-09 10:24:38.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 5495 LR: 0.00042947084322515435 Training loss: 0.0
2025-12-09 10:24:38.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 5496 LR: 0.00042931376694173583 Training loss: 0.0
2025-12-09 10:24:38.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 5497 LR: 0.00042915669777641915 Training loss: 0.0
2025-12-09 10:24:38.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 5498 LR: 0.00042899963574502087 Training loss: 0.0
2025-12-09 10:24:38.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 5499 LR: 0.0004288425808633575 Training loss: 0.0
2025-12-09 10:24:38.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 5500 LR: 0.00042868553314724423 Training loss: 0.0
2025-12-09 10:24:38.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 5501 LR: 0.00042852849261249595 Training loss: 0.0
2025-12-09 10:24:38.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 5502 LR: 0.00042837145927492623 Training loss: 0.0
2025-12-09 10:24:38.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 5503 LR: 0.0004282144331503488 Training loss: 0.0
2025-12-09 10:24:38.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 5504 LR: 0.0004280574142545759 Training loss: 0.0
2025-12-09 10:24:38.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 5505 LR: 0.00042790040260341956 Training loss: 0.0
2025-12-09 10:24:38.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 5506 LR: 0.0004277433982126905 Training loss: 0.0
2025-12-09 10:24:38.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 5507 LR: 0.00042758640109819945 Training loss: 0.0
2025-12-09 10:24:38.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 5508 LR: 0.00042742941127575575 Training loss: 0.0
2025-12-09 10:24:38.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 5509 LR: 0.0004272724287611684 Training loss: 0.0
2025-12-09 10:24:38.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 5510 LR: 0.00042711545357024527 Training loss: 0.0
2025-12-09 10:24:38.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 5511 LR: 0.00042695848571879425 Training loss: 0.0
2025-12-09 10:24:38.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 5512 LR: 0.00042680152522262156 Training loss: 0.0
2025-12-09 10:24:38.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 5513 LR: 0.00042664457209753336 Training loss: 0.0
2025-12-09 10:24:38.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 5514 LR: 0.00042648762635933465 Training loss: 0.0
2025-12-09 10:24:38.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 5515 LR: 0.00042633068802383007 Training loss: 0.0
2025-12-09 10:24:38.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 5516 LR: 0.0004261737571068231 Training loss: 0.0
2025-12-09 10:24:38.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 5517 LR: 0.0004260168336241169 Training loss: 0.0
2025-12-09 10:24:38.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 5518 LR: 0.00042585991759151325 Training loss: 0.0
2025-12-09 10:24:38.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 5519 LR: 0.00042570300902481425 Training loss: 0.0
2025-12-09 10:24:38.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 5520 LR: 0.00042554610793981985 Training loss: 0.0
2025-12-09 10:24:38.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 5521 LR: 0.00042538921435233057 Training loss: 0.0
2025-12-09 10:24:38.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 5522 LR: 0.0004252323282781453 Training loss: 0.0
2025-12-09 10:24:38.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 5523 LR: 0.00042507544973306255 Training loss: 0.0
2025-12-09 10:24:38.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 5524 LR: 0.0004249185787328798 Training loss: 0.0
2025-12-09 10:24:38.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 5525 LR: 0.00042476171529339435 Training loss: 0.0
2025-12-09 10:24:38.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 5526 LR: 0.000424604859430402 Training loss: 0.0
2025-12-09 10:24:38.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 5527 LR: 0.00042444801115969834 Training loss: 0.0
2025-12-09 10:24:38.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 5528 LR: 0.00042429117049707765 Training loss: 0.0
2025-12-09 10:24:38.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 5529 LR: 0.00042413433745833423 Training loss: 0.0
2025-12-09 10:24:38.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 5530 LR: 0.0004239775120592609 Training loss: 0.0
2025-12-09 10:24:38.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 5531 LR: 0.00042382069431565005 Training loss: 0.0
2025-12-09 10:24:38.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 5532 LR: 0.0004236638842432931 Training loss: 0.0
2025-12-09 10:24:38.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 5533 LR: 0.00042350708185798106 Training loss: 0.0
2025-12-09 10:24:38.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 5534 LR: 0.0004233502871755036 Training loss: 0.0
2025-12-09 10:24:38.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 5535 LR: 0.00042319350021165035 Training loss: 0.0
2025-12-09 10:24:38.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 5536 LR: 0.00042303672098220927 Training loss: 0.0
2025-12-09 10:24:38.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 5537 LR: 0.00042287994950296847 Training loss: 0.0
2025-12-09 10:24:38.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 5538 LR: 0.00042272318578971457 Training loss: 0.0
2025-12-09 10:24:38.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 5539 LR: 0.0004225664298582339 Training loss: 0.0
2025-12-09 10:24:38.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 5540 LR: 0.00042240968172431133 Training loss: 0.0
2025-12-09 10:24:38.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 5541 LR: 0.00042225294140373196 Training loss: 0.0
2025-12-09 10:24:38.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 5542 LR: 0.0004220962089122791 Training loss: 0.0
2025-12-09 10:24:38.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 5543 LR: 0.00042193948426573605 Training loss: 0.0
2025-12-09 10:24:38.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 5544 LR: 0.0004217827674798845 Training loss: 0.0
2025-12-09 10:24:38.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 5545 LR: 0.0004216260585705064 Training loss: 0.0
2025-12-09 10:24:38.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 5546 LR: 0.00042146935755338187 Training loss: 0.0
2025-12-09 10:24:38.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 5547 LR: 0.00042131266444429106 Training loss: 0.0
2025-12-09 10:24:38.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 5548 LR: 0.0004211559792590126 Training loss: 0.0
2025-12-09 10:24:38.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 5549 LR: 0.000420999302013325 Training loss: 0.0
2025-12-09 10:24:38.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 5550 LR: 0.0004208426327230055 Training loss: 0.0
2025-12-09 10:24:38.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 5551 LR: 0.0004206859714038308 Training loss: 0.0
2025-12-09 10:24:38.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 5552 LR: 0.0004205293180715764 Training loss: 0.0
2025-12-09 10:24:38.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 5553 LR: 0.0004203726727420178 Training loss: 0.0
2025-12-09 10:24:38.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 5554 LR: 0.0004202160354309286 Training loss: 0.0
2025-12-09 10:24:38.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 5555 LR: 0.0004200594061540826 Training loss: 0.0
2025-12-09 10:24:38.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 5556 LR: 0.00041990278492725215 Training loss: 0.0
2025-12-09 10:24:38.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 5557 LR: 0.00041974617176620914 Training loss: 0.0
2025-12-09 10:24:38.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 5558 LR: 0.00041958956668672424 Training loss: 0.0
2025-12-09 10:24:38.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 5559 LR: 0.000419432969704568 Training loss: 0.0
2025-12-09 10:24:38.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 5560 LR: 0.0004192763808355094 Training loss: 0.0
2025-12-09 10:24:38.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 5561 LR: 0.0004191198000953171 Training loss: 0.0
2025-12-09 10:24:38.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 5562 LR: 0.0004189632274997588 Training loss: 0.0
2025-12-09 10:24:38.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 5563 LR: 0.000418806663064601 Training loss: 0.0
2025-12-09 10:24:38.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 5564 LR: 0.0004186501068056102 Training loss: 0.0
2025-12-09 10:24:38.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 5565 LR: 0.00041849355873855134 Training loss: 0.0
2025-12-09 10:24:38.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 5566 LR: 0.00041833701887918903 Training loss: 0.0
2025-12-09 10:24:38.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 5567 LR: 0.0004181804872432864 Training loss: 0.0
2025-12-09 10:24:38.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 5568 LR: 0.00041802396384660675 Training loss: 0.0
2025-12-09 10:24:38.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 5569 LR: 0.00041786744870491154 Training loss: 0.0
2025-12-09 10:24:38.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 5570 LR: 0.0004177109418339621 Training loss: 0.0
2025-12-09 10:24:38.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 5571 LR: 0.0004175544432495184 Training loss: 0.0
2025-12-09 10:24:38.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 5572 LR: 0.0004173979529673402 Training loss: 0.0
2025-12-09 10:24:38.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 5573 LR: 0.0004172414710031858 Training loss: 0.0
2025-12-09 10:24:38.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 5574 LR: 0.00041708499737281305 Training loss: 0.0
2025-12-09 10:24:38.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 5575 LR: 0.0004169285320919786 Training loss: 0.0
2025-12-09 10:24:38.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 5576 LR: 0.00041677207517643895 Training loss: 0.0
2025-12-09 10:24:38.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 5577 LR: 0.0004166156266419489 Training loss: 0.0
2025-12-09 10:24:38.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 5578 LR: 0.0004164591865042631 Training loss: 0.0
2025-12-09 10:24:38.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 5579 LR: 0.0004163027547791347 Training loss: 0.0
2025-12-09 10:24:38.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 5580 LR: 0.00041614633148231696 Training loss: 0.0
2025-12-09 10:24:38.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 5581 LR: 0.000415989916629561 Training loss: 0.0
2025-12-09 10:24:38.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 5582 LR: 0.0004158335102366183 Training loss: 0.0
2025-12-09 10:24:38.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 5583 LR: 0.00041567711231923875 Training loss: 0.0
2025-12-09 10:24:38.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 5584 LR: 0.0004155207228931718 Training loss: 0.0
2025-12-09 10:24:38.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 5585 LR: 0.00041536434197416555 Training loss: 0.0
2025-12-09 10:24:38.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 5586 LR: 0.0004152079695779679 Training loss: 0.0
2025-12-09 10:24:38.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 5587 LR: 0.00041505160572032535 Training loss: 0.0
2025-12-09 10:24:38.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 5588 LR: 0.00041489525041698384 Training loss: 0.0
2025-12-09 10:24:38.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 5589 LR: 0.0004147389036836881 Training loss: 0.0
2025-12-09 10:24:38.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 5590 LR: 0.0004145825655361827 Training loss: 0.0
2025-12-09 10:24:38.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 5591 LR: 0.0004144262359902104 Training loss: 0.0
2025-12-09 10:24:38.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 5592 LR: 0.0004142699150615139 Training loss: 0.0
2025-12-09 10:24:38.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 5593 LR: 0.00041411360276583445 Training loss: 0.0
2025-12-09 10:24:38.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 5594 LR: 0.0004139572991189131 Training loss: 0.0
2025-12-09 10:24:38.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 5595 LR: 0.00041380100413648916 Training loss: 0.0
2025-12-09 10:24:38.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 5596 LR: 0.0004136447178343019 Training loss: 0.0
2025-12-09 10:24:38.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 5597 LR: 0.00041348844022808895 Training loss: 0.0
2025-12-09 10:24:38.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 5598 LR: 0.000413332171333588 Training loss: 0.0
2025-12-09 10:24:38.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 5599 LR: 0.00041317591116653486 Training loss: 0.0
2025-12-09 10:24:38.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 5600 LR: 0.0004130196597426652 Training loss: 0.0
2025-12-09 10:24:38.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 5601 LR: 0.00041286341707771326 Training loss: 0.0
2025-12-09 10:24:38.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 5602 LR: 0.00041270718318741294 Training loss: 0.0
2025-12-09 10:24:38.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 5603 LR: 0.0004125509580874969 Training loss: 0.0
2025-12-09 10:24:38.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 5604 LR: 0.000412394741793697 Training loss: 0.0
2025-12-09 10:24:38.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 5605 LR: 0.000412238534321744 Training loss: 0.0
2025-12-09 10:24:38.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 5606 LR: 0.00041208233568736845 Training loss: 0.0
2025-12-09 10:24:38.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 5607 LR: 0.00041192614590629915 Training loss: 0.0
2025-12-09 10:24:38.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 5608 LR: 0.00041176996499426465 Training loss: 0.0
2025-12-09 10:24:38.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 5609 LR: 0.0004116137929669921 Training loss: 0.0
2025-12-09 10:24:38.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 5610 LR: 0.0004114576298402084 Training loss: 0.0
2025-12-09 10:24:38.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 5611 LR: 0.00041130147562963885 Training loss: 0.0
2025-12-09 10:24:38.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 5612 LR: 0.0004111453303510083 Training loss: 0.0
2025-12-09 10:24:38.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 5613 LR: 0.0004109891940200404 Training loss: 0.0
2025-12-09 10:24:38.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 5614 LR: 0.0004108330666524585 Training loss: 0.0
2025-12-09 10:24:38.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 5615 LR: 0.00041067694826398406 Training loss: 0.0
2025-12-09 10:24:38.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 5616 LR: 0.0004105208388703387 Training loss: 0.0
2025-12-09 10:24:38.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 5617 LR: 0.0004103647384872423 Training loss: 0.0
2025-12-09 10:24:38.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 5618 LR: 0.0004102086471304144 Training loss: 0.0
2025-12-09 10:24:38.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 5619 LR: 0.00041005256481557305 Training loss: 0.0
2025-12-09 10:24:38.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 5620 LR: 0.0004098964915584362 Training loss: 0.0
2025-12-09 10:24:38.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 5621 LR: 0.00040974042737472005 Training loss: 0.0
2025-12-09 10:24:38.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 5622 LR: 0.0004095843722801405 Training loss: 0.0
2025-12-09 10:24:38.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 5623 LR: 0.000409428326290412 Training loss: 0.0
2025-12-09 10:24:38.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 5624 LR: 0.0004092722894212487 Training loss: 0.0
2025-12-09 10:24:38.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 5625 LR: 0.00040911626168836337 Training loss: 0.0
2025-12-09 10:24:38.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 5626 LR: 0.00040896024310746806 Training loss: 0.0
2025-12-09 10:24:38.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 5627 LR: 0.00040880423369427354 Training loss: 0.0
2025-12-09 10:24:38.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 5628 LR: 0.0004086482334644905 Training loss: 0.0
2025-12-09 10:24:38.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 5629 LR: 0.00040849224243382767 Training loss: 0.0
2025-12-09 10:24:38.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 5630 LR: 0.0004083362606179937 Training loss: 0.0
2025-12-09 10:24:38.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 5631 LR: 0.00040818028803269547 Training loss: 0.0
2025-12-09 10:24:38.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 5632 LR: 0.0004080243246936399 Training loss: 0.0
2025-12-09 10:24:38.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 5633 LR: 0.0004078683706165323 Training loss: 0.0
2025-12-09 10:24:38.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 5634 LR: 0.00040771242581707736 Training loss: 0.0
2025-12-09 10:24:38.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 5635 LR: 0.0004075564903109784 Training loss: 0.0
2025-12-09 10:24:38.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 5636 LR: 0.00040740056411393854 Training loss: 0.0
2025-12-09 10:24:38.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 5637 LR: 0.0004072446472416592 Training loss: 0.0
2025-12-09 10:24:38.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 5638 LR: 0.0004070887397098415 Training loss: 0.0
2025-12-09 10:24:38.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 5639 LR: 0.000406932841534185 Training loss: 0.0
2025-12-09 10:24:38.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 5640 LR: 0.0004067769527303889 Training loss: 0.0
2025-12-09 10:24:38.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 5641 LR: 0.0004066210733141511 Training loss: 0.0
2025-12-09 10:24:38.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 5642 LR: 0.0004064652033011687 Training loss: 0.0
2025-12-09 10:24:38.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 5643 LR: 0.0004063093427071376 Training loss: 0.0
2025-12-09 10:24:38.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 5644 LR: 0.0004061534915477533 Training loss: 0.0
2025-12-09 10:24:38.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 5645 LR: 0.0004059976498387098 Training loss: 0.0
2025-12-09 10:24:38.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 5646 LR: 0.00040584181759570044 Training loss: 0.0
2025-12-09 10:24:38.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 5647 LR: 0.00040568599483441746 Training loss: 0.0
2025-12-09 10:24:38.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 5648 LR: 0.00040553018157055213 Training loss: 0.0
2025-12-09 10:24:38.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 5649 LR: 0.0004053743778197951 Training loss: 0.0
2025-12-09 10:24:38.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 5650 LR: 0.0004052185835978353 Training loss: 0.0
2025-12-09 10:24:38.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 5651 LR: 0.00040506279892036187 Training loss: 0.0
2025-12-09 10:24:38.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 5652 LR: 0.00040490702380306177 Training loss: 0.0
2025-12-09 10:24:38.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 5653 LR: 0.00040475125826162196 Training loss: 0.0
2025-12-09 10:24:38.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 5654 LR: 0.0004045955023117276 Training loss: 0.0
2025-12-09 10:24:38.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 5655 LR: 0.0004044397559690638 Training loss: 0.0
2025-12-09 10:24:38.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 5656 LR: 0.0004042840192493138 Training loss: 0.0
2025-12-09 10:24:38.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 5657 LR: 0.00040412829216816056 Training loss: 0.0
2025-12-09 10:24:38.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 5658 LR: 0.00040397257474128544 Training loss: 0.0
2025-12-09 10:24:38.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 5659 LR: 0.0004038168669843697 Training loss: 0.0
2025-12-09 10:24:38.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 5660 LR: 0.00040366116891309264 Training loss: 0.0
2025-12-09 10:24:38.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 5661 LR: 0.0004035054805431334 Training loss: 0.0
2025-12-09 10:24:38.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 5662 LR: 0.00040334980189016934 Training loss: 0.0
2025-12-09 10:24:38.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 5663 LR: 0.00040319413296987784 Training loss: 0.0
2025-12-09 10:24:38.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 5664 LR: 0.00040303847379793447 Training loss: 0.0
2025-12-09 10:24:38.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 5665 LR: 0.0004028828243900141 Training loss: 0.0
2025-12-09 10:24:38.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 5666 LR: 0.0004027271847617905 Training loss: 0.0
2025-12-09 10:24:38.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 5667 LR: 0.00040257155492893706 Training loss: 0.0
2025-12-09 10:24:38.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 5668 LR: 0.0004024159349071251 Training loss: 0.0
2025-12-09 10:24:38.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 5669 LR: 0.000402260324712026 Training loss: 0.0
2025-12-09 10:24:38.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 5670 LR: 0.0004021047243593093 Training loss: 0.0
2025-12-09 10:24:38.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 5671 LR: 0.00040194913386464444 Training loss: 0.0
2025-12-09 10:24:38.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 5672 LR: 0.00040179355324369896 Training loss: 0.0
2025-12-09 10:24:38.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 5673 LR: 0.0004016379825121401 Training loss: 0.0
2025-12-09 10:24:38.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 5674 LR: 0.00040148242168563356 Training loss: 0.0
2025-12-09 10:24:38.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 5675 LR: 0.0004013268707798447 Training loss: 0.0
2025-12-09 10:24:38.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 5676 LR: 0.0004011713298104369 Training loss: 0.0
2025-12-09 10:24:38.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 5677 LR: 0.0004010157987930738 Training loss: 0.0
2025-12-09 10:24:38.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 5678 LR: 0.00040086027774341687 Training loss: 0.0
2025-12-09 10:24:38.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 5679 LR: 0.00040070476667712743 Training loss: 0.0
2025-12-09 10:24:38.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 5680 LR: 0.000400549265609865 Training loss: 0.0
2025-12-09 10:24:38.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 5681 LR: 0.00040039377455728905 Training loss: 0.0
2025-12-09 10:24:38.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 5682 LR: 0.0004002382935350571 Training loss: 0.0
2025-12-09 10:24:38.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 5683 LR: 0.00040008282255882645 Training loss: 0.0
2025-12-09 10:24:38.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 5684 LR: 0.0003999273616442526 Training loss: 0.0
2025-12-09 10:24:38.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 5685 LR: 0.00039977191080699085 Training loss: 0.0
2025-12-09 10:24:38.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 5686 LR: 0.0003996164700626949 Training loss: 0.0
2025-12-09 10:24:38.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 5687 LR: 0.0003994610394270178 Training loss: 0.0
2025-12-09 10:24:38.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 5688 LR: 0.000399305618915611 Training loss: 0.0
2025-12-09 10:24:38.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 5689 LR: 0.0003991502085441259 Training loss: 0.0
2025-12-09 10:24:38.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 5690 LR: 0.00039899480832821183 Training loss: 0.0
2025-12-09 10:24:38.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 5691 LR: 0.000398839418283518 Training loss: 0.0
2025-12-09 10:24:38.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 5692 LR: 0.0003986840384256917 Training loss: 0.0
2025-12-09 10:24:38.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 5693 LR: 0.0003985286687703802 Training loss: 0.0
2025-12-09 10:24:38.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 5694 LR: 0.0003983733093332289 Training loss: 0.0
2025-12-09 10:24:38.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 5695 LR: 0.00039821796012988263 Training loss: 0.0
2025-12-09 10:24:38.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 5696 LR: 0.0003980626211759848 Training loss: 0.0
2025-12-09 10:24:38.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 5697 LR: 0.00039790729248717844 Training loss: 0.0
2025-12-09 10:24:38.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 5698 LR: 0.00039775197407910487 Training loss: 0.0
2025-12-09 10:24:38.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 5699 LR: 0.0003975966659674047 Training loss: 0.0
2025-12-09 10:24:38.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 5700 LR: 0.00039744136816771735 Training loss: 0.0
2025-12-09 10:24:38.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 5701 LR: 0.00039728608069568164 Training loss: 0.0
2025-12-09 10:24:38.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 5702 LR: 0.00039713080356693466 Training loss: 0.0
2025-12-09 10:24:38.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 5703 LR: 0.0003969755367971131 Training loss: 0.0
2025-12-09 10:24:38.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 5704 LR: 0.0003968202804018518 Training loss: 0.0
2025-12-09 10:24:38.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 5705 LR: 0.0003966650343967858 Training loss: 0.0
2025-12-09 10:24:38.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 5706 LR: 0.0003965097987975478 Training loss: 0.0
2025-12-09 10:24:38.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 5707 LR: 0.00039635457361977046 Training loss: 0.0
2025-12-09 10:24:38.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 5708 LR: 0.0003961993588790844 Training loss: 0.0
2025-12-09 10:24:38.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 5709 LR: 0.0003960441545911204 Training loss: 0.0
2025-12-09 10:24:38.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 5710 LR: 0.00039588896077150695 Training loss: 0.0
2025-12-09 10:24:38.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 5711 LR: 0.00039573377743587246 Training loss: 0.0
2025-12-09 10:24:38.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 5712 LR: 0.0003955786045998436 Training loss: 0.0
2025-12-09 10:24:38.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 5713 LR: 0.00039542344227904656 Training loss: 0.0
2025-12-09 10:24:38.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 5714 LR: 0.00039526829048910575 Training loss: 0.0
2025-12-09 10:24:38.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 5715 LR: 0.00039511314924564546 Training loss: 0.0
2025-12-09 10:24:38.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 5716 LR: 0.000394958018564288 Training loss: 0.0
2025-12-09 10:24:38.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 5717 LR: 0.0003948028984606554 Training loss: 0.0
2025-12-09 10:24:38.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 5718 LR: 0.0003946477889503678 Training loss: 0.0
2025-12-09 10:24:38.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 5719 LR: 0.0003944926900490452 Training loss: 0.0
2025-12-09 10:24:38.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 5720 LR: 0.00039433760177230574 Training loss: 0.0
2025-12-09 10:24:38.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 5721 LR: 0.0003941825241357669 Training loss: 0.0
2025-12-09 10:24:38.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 5722 LR: 0.00039402745715504486 Training loss: 0.0
2025-12-09 10:24:38.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 5723 LR: 0.00039387240084575516 Training loss: 0.0
2025-12-09 10:24:38.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 5724 LR: 0.00039371735522351166 Training loss: 0.0
2025-12-09 10:24:38.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 5725 LR: 0.00039356232030392767 Training loss: 0.0
2025-12-09 10:24:38.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 5726 LR: 0.000393407296102615 Training loss: 0.0
2025-12-09 10:24:38.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 5727 LR: 0.00039325228263518486 Training loss: 0.0
2025-12-09 10:24:38.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 5728 LR: 0.0003930972799172468 Training loss: 0.0
2025-12-09 10:24:38.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 5729 LR: 0.0003929422879644099 Training loss: 0.0
2025-12-09 10:24:38.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 5730 LR: 0.0003927873067922814 Training loss: 0.0
2025-12-09 10:24:38.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 5731 LR: 0.0003926323364164684 Training loss: 0.0
2025-12-09 10:24:38.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 5732 LR: 0.00039247737685257623 Training loss: 0.0
2025-12-09 10:24:38.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 5733 LR: 0.0003923224281162091 Training loss: 0.0
2025-12-09 10:24:38.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 5734 LR: 0.0003921674902229706 Training loss: 0.0
2025-12-09 10:24:38.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 5735 LR: 0.00039201256318846273 Training loss: 0.0
2025-12-09 10:24:38.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 5736 LR: 0.000391857647028287 Training loss: 0.0
2025-12-09 10:24:38.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 5737 LR: 0.0003917027417580432 Training loss: 0.0
2025-12-09 10:24:38.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 5738 LR: 0.0003915478473933303 Training loss: 0.0
2025-12-09 10:24:38.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 5739 LR: 0.0003913929639497462 Training loss: 0.0
2025-12-09 10:24:38.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 5740 LR: 0.00039123809144288774 Training loss: 0.0
2025-12-09 10:24:38.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 5741 LR: 0.00039108322988835035 Training loss: 0.0
2025-12-09 10:24:38.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 5742 LR: 0.0003909283793017289 Training loss: 0.0
2025-12-09 10:24:38.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 5743 LR: 0.0003907735396986165 Training loss: 0.0
2025-12-09 10:24:38.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 5744 LR: 0.0003906187110946058 Training loss: 0.0
2025-12-09 10:24:38.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 5745 LR: 0.0003904638935052877 Training loss: 0.0
2025-12-09 10:24:38.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 5746 LR: 0.00039030908694625275 Training loss: 0.0
2025-12-09 10:24:38.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 5747 LR: 0.0003901542914330896 Training loss: 0.0
2025-12-09 10:24:38.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 5748 LR: 0.00038999950698138643 Training loss: 0.0
2025-12-09 10:24:38.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 5749 LR: 0.00038984473360672965 Training loss: 0.0
2025-12-09 10:24:38.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 5750 LR: 0.0003896899713247055 Training loss: 0.0
2025-12-09 10:24:38.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 5751 LR: 0.00038953522015089804 Training loss: 0.0
2025-12-09 10:24:38.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 5752 LR: 0.000389380480100891 Training loss: 0.0
2025-12-09 10:24:38.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 5753 LR: 0.0003892257511902664 Training loss: 0.0
2025-12-09 10:24:38.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 5754 LR: 0.0003890710334346058 Training loss: 0.0
2025-12-09 10:24:38.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 5755 LR: 0.000388916326849489 Training loss: 0.0
2025-12-09 10:24:38.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 5756 LR: 0.00038876163145049514 Training loss: 0.0
2025-12-09 10:24:38.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 5757 LR: 0.0003886069472532017 Training loss: 0.0
2025-12-09 10:24:38.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 5758 LR: 0.00038845227427318594 Training loss: 0.0
2025-12-09 10:24:38.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 5759 LR: 0.0003882976125260229 Training loss: 0.0
2025-12-09 10:24:38.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 5760 LR: 0.0003881429620272874 Training loss: 0.0
2025-12-09 10:24:38.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 5761 LR: 0.0003879883227925523 Training loss: 0.0
2025-12-09 10:24:38.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 5762 LR: 0.0003878336948373903 Training loss: 0.0
2025-12-09 10:24:38.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 5763 LR: 0.000387679078177372 Training loss: 0.0
2025-12-09 10:24:38.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 5764 LR: 0.0003875244728280676 Training loss: 0.0
2025-12-09 10:24:38.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 5765 LR: 0.0003873698788050455 Training loss: 0.0
2025-12-09 10:24:38.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 5766 LR: 0.0003872152961238737 Training loss: 0.0
2025-12-09 10:24:38.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 5767 LR: 0.0003870607248001184 Training loss: 0.0
2025-12-09 10:24:38.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 5768 LR: 0.0003869061648493452 Training loss: 0.0
2025-12-09 10:24:38.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 5769 LR: 0.00038675161628711776 Training loss: 0.0
2025-12-09 10:24:38.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 5770 LR: 0.0003865970791289999 Training loss: 0.0
2025-12-09 10:24:38.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 5771 LR: 0.0003864425533905527 Training loss: 0.0
2025-12-09 10:24:38.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 5772 LR: 0.00038628803908733746 Training loss: 0.0
2025-12-09 10:24:38.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 5773 LR: 0.00038613353623491344 Training loss: 0.0
2025-12-09 10:24:38.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 5774 LR: 0.0003859790448488394 Training loss: 0.0
2025-12-09 10:24:38.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 5775 LR: 0.0003858245649446721 Training loss: 0.0
2025-12-09 10:24:38.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 5776 LR: 0.0003856700965379683 Training loss: 0.0
2025-12-09 10:24:38.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 5777 LR: 0.0003855156396442825 Training loss: 0.0
2025-12-09 10:24:38.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 5778 LR: 0.0003853611942791688 Training loss: 0.0
2025-12-09 10:24:38.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 5779 LR: 0.0003852067604581794 Training loss: 0.0
2025-12-09 10:24:38.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 5780 LR: 0.0003850523381968664 Training loss: 0.0
2025-12-09 10:24:38.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 5781 LR: 0.00038489792751077964 Training loss: 0.0
2025-12-09 10:24:38.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 5782 LR: 0.0003847435284154685 Training loss: 0.0
2025-12-09 10:24:38.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 5783 LR: 0.00038458914092648073 Training loss: 0.0
2025-12-09 10:24:38.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 5784 LR: 0.0003844347650593635 Training loss: 0.0
2025-12-09 10:24:38.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 5785 LR: 0.0003842804008296622 Training loss: 0.0
2025-12-09 10:24:38.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 5786 LR: 0.0003841260482529214 Training loss: 0.0
2025-12-09 10:24:38.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 5787 LR: 0.0003839717073446842 Training loss: 0.0
2025-12-09 10:24:38.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 5788 LR: 0.00038381737812049314 Training loss: 0.0
2025-12-09 10:24:38.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 5789 LR: 0.0003836630605958888 Training loss: 0.0
2025-12-09 10:24:38.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 5790 LR: 0.0003835087547864112 Training loss: 0.0
2025-12-09 10:24:38.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 5791 LR: 0.00038335446070759857 Training loss: 0.0
2025-12-09 10:24:38.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 5792 LR: 0.00038320017837498876 Training loss: 0.0
2025-12-09 10:24:38.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 5793 LR: 0.0003830459078041177 Training loss: 0.0
2025-12-09 10:24:38.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 5794 LR: 0.00038289164901052057 Training loss: 0.0
2025-12-09 10:24:38.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 5795 LR: 0.0003827374020097311 Training loss: 0.0
2025-12-09 10:24:38.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 5796 LR: 0.00038258316681728213 Training loss: 0.0
2025-12-09 10:24:38.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 5797 LR: 0.000382428943448705 Training loss: 0.0
2025-12-09 10:24:38.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 5798 LR: 0.00038227473191953013 Training loss: 0.0
2025-12-09 10:24:38.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 5799 LR: 0.0003821205322452863 Training loss: 0.0
2025-12-09 10:24:38.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 5800 LR: 0.0003819663444415019 Training loss: 0.0
2025-12-09 10:24:38.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 5801 LR: 0.0003818121685237033 Training loss: 0.0
2025-12-09 10:24:38.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 5802 LR: 0.0003816580045074162 Training loss: 0.0
2025-12-09 10:24:38.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 5803 LR: 0.0003815038524081646 Training loss: 0.0
2025-12-09 10:24:38.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 5804 LR: 0.00038134971224147203 Training loss: 0.0
2025-12-09 10:24:38.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 5805 LR: 0.00038119558402285994 Training loss: 0.0
2025-12-09 10:24:38.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 5806 LR: 0.0003810414677678495 Training loss: 0.0
2025-12-09 10:24:38.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 5807 LR: 0.0003808873634919599 Training loss: 0.0
2025-12-09 10:24:38.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 5808 LR: 0.00038073327121070967 Training loss: 0.0
2025-12-09 10:24:38.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 5809 LR: 0.0003805791909396155 Training loss: 0.0
2025-12-09 10:24:38.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 5810 LR: 0.00038042512269419377 Training loss: 0.0
2025-12-09 10:24:38.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 5811 LR: 0.0003802710664899588 Training loss: 0.0
2025-12-09 10:24:38.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 5812 LR: 0.00038011702234242426 Training loss: 0.0
2025-12-09 10:24:38.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 5813 LR: 0.0003799629902671021 Training loss: 0.0
2025-12-09 10:24:38.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 5814 LR: 0.0003798089702795038 Training loss: 0.0
2025-12-09 10:24:38.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 5815 LR: 0.00037965496239513873 Training loss: 0.0
2025-12-09 10:24:38.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 5816 LR: 0.00037950096662951575 Training loss: 0.0
2025-12-09 10:24:38.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 5817 LR: 0.00037934698299814195 Training loss: 0.0
2025-12-09 10:24:38.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 5818 LR: 0.00037919301151652385 Training loss: 0.0
2025-12-09 10:24:38.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 5819 LR: 0.0003790390522001662 Training loss: 0.0
2025-12-09 10:24:38.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 5820 LR: 0.00037888510506457263 Training loss: 0.0
2025-12-09 10:24:38.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 5821 LR: 0.0003787311701252457 Training loss: 0.0
2025-12-09 10:24:38.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 5822 LR: 0.0003785772473976864 Training loss: 0.0
2025-12-09 10:24:38.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 5823 LR: 0.0003784233368973952 Training loss: 0.0
2025-12-09 10:24:38.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 5824 LR: 0.00037826943863987055 Training loss: 0.0
2025-12-09 10:24:38.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 5825 LR: 0.00037811555264061024 Training loss: 0.0
2025-12-09 10:24:38.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 5826 LR: 0.0003779616789151102 Training loss: 0.0
2025-12-09 10:24:38.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 5827 LR: 0.00037780781747886593 Training loss: 0.0
2025-12-09 10:24:38.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 5828 LR: 0.000377653968347371 Training loss: 0.0
2025-12-09 10:24:38.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 5829 LR: 0.0003775001315361183 Training loss: 0.0
2025-12-09 10:24:38.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 5830 LR: 0.0003773463070605987 Training loss: 0.0
2025-12-09 10:24:38.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 5831 LR: 0.000377192494936303 Training loss: 0.0
2025-12-09 10:24:38.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 5832 LR: 0.0003770386951787193 Training loss: 0.0
2025-12-09 10:24:38.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 5833 LR: 0.0003768849078033359 Training loss: 0.0
2025-12-09 10:24:38.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 5834 LR: 0.00037673113282563883 Training loss: 0.0
2025-12-09 10:24:38.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 5835 LR: 0.0003765773702611134 Training loss: 0.0
2025-12-09 10:24:38.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 5836 LR: 0.0003764236201252431 Training loss: 0.0
2025-12-09 10:24:38.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 5837 LR: 0.00037626988243351123 Training loss: 0.0
2025-12-09 10:24:38.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 5838 LR: 0.0003761161572013986 Training loss: 0.0
2025-12-09 10:24:38.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 5839 LR: 0.0003759624444443858 Training loss: 0.0
2025-12-09 10:24:38.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 5840 LR: 0.0003758087441779511 Training loss: 0.0
2025-12-09 10:24:38.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 5841 LR: 0.0003756550564175727 Training loss: 0.0
2025-12-09 10:24:38.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 5842 LR: 0.00037550138117872664 Training loss: 0.0
2025-12-09 10:24:38.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 5843 LR: 0.00037534771847688817 Training loss: 0.0
2025-12-09 10:24:38.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 5844 LR: 0.00037519406832753083 Training loss: 0.0
2025-12-09 10:24:38.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 5845 LR: 0.0003750404307461276 Training loss: 0.0
2025-12-09 10:24:38.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 5846 LR: 0.00037488680574814946 Training loss: 0.0
2025-12-09 10:24:38.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 5847 LR: 0.00037473319334906677 Training loss: 0.0
2025-12-09 10:24:38.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 5848 LR: 0.00037457959356434773 Training loss: 0.0
2025-12-09 10:24:38.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 5849 LR: 0.00037442600640946044 Training loss: 0.0
2025-12-09 10:24:38.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 5850 LR: 0.00037427243189987083 Training loss: 0.0
2025-12-09 10:24:38.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 5851 LR: 0.00037411887005104396 Training loss: 0.0
2025-12-09 10:24:38.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 5852 LR: 0.00037396532087844315 Training loss: 0.0
2025-12-09 10:24:38.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 5853 LR: 0.0003738117843975314 Training loss: 0.0
2025-12-09 10:24:38.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 5854 LR: 0.0003736582606237693 Training loss: 0.0
2025-12-09 10:24:38.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 5855 LR: 0.00037350474957261706 Training loss: 0.0
2025-12-09 10:24:38.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 5856 LR: 0.00037335125125953283 Training loss: 0.0
2025-12-09 10:24:38.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 5857 LR: 0.00037319776569997437 Training loss: 0.0
2025-12-09 10:24:38.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 5858 LR: 0.00037304429290939737 Training loss: 0.0
2025-12-09 10:24:38.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 5859 LR: 0.00037289083290325663 Training loss: 0.0
2025-12-09 10:24:38.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 5860 LR: 0.0003727373856970053 Training loss: 0.0
2025-12-09 10:24:38.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 5861 LR: 0.0003725839513060961 Training loss: 0.0
2025-12-09 10:24:38.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 5862 LR: 0.00037243052974597927 Training loss: 0.0
2025-12-09 10:24:38.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 5863 LR: 0.0003722771210321048 Training loss: 0.0
2025-12-09 10:24:38.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 5864 LR: 0.00037212372517992054 Training loss: 0.0
2025-12-09 10:24:38.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 5865 LR: 0.0003719703422048739 Training loss: 0.0
2025-12-09 10:24:38.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 5866 LR: 0.00037181697212241004 Training loss: 0.0
2025-12-09 10:24:38.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 5867 LR: 0.0003716636149479737 Training loss: 0.0
2025-12-09 10:24:38.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 5868 LR: 0.0003715102706970078 Training loss: 0.0
2025-12-09 10:24:38.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 5869 LR: 0.0003713569393849543 Training loss: 0.0
2025-12-09 10:24:38.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 5870 LR: 0.00037120362102725313 Training loss: 0.0
2025-12-09 10:24:38.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 5871 LR: 0.0003710503156393441 Training loss: 0.0
2025-12-09 10:24:38.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 5872 LR: 0.0003708970232366646 Training loss: 0.0
2025-12-09 10:24:38.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 5873 LR: 0.00037074374383465146 Training loss: 0.0
2025-12-09 10:24:38.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 5874 LR: 0.0003705904774487396 Training loss: 0.0
2025-12-09 10:24:38.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 5875 LR: 0.00037043722409436334 Training loss: 0.0
2025-12-09 10:24:38.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 5876 LR: 0.00037028398378695485 Training loss: 0.0
2025-12-09 10:24:38.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 5877 LR: 0.0003701307565419458 Training loss: 0.0
2025-12-09 10:24:38.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 5878 LR: 0.0003699775423747659 Training loss: 0.0
2025-12-09 10:24:38.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 5879 LR: 0.00036982434130084397 Training loss: 0.0
2025-12-09 10:24:38.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 5880 LR: 0.0003696711533356073 Training loss: 0.0
2025-12-09 10:24:38.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 5881 LR: 0.00036951797849448203 Training loss: 0.0
2025-12-09 10:24:38.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 5882 LR: 0.00036936481679289255 Training loss: 0.0
2025-12-09 10:24:38.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 5883 LR: 0.0003692116682462626 Training loss: 0.0
2025-12-09 10:24:38.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 5884 LR: 0.000369058532870014 Training loss: 0.0
2025-12-09 10:24:38.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 5885 LR: 0.0003689054106795677 Training loss: 0.0
2025-12-09 10:24:38.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 5886 LR: 0.00036875230169034276 Training loss: 0.0
2025-12-09 10:24:38.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 5887 LR: 0.00036859920591775756 Training loss: 0.0
2025-12-09 10:24:38.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 5888 LR: 0.0003684461233772287 Training loss: 0.0
2025-12-09 10:24:38.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 5889 LR: 0.00036829305408417166 Training loss: 0.0
2025-12-09 10:24:38.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 5890 LR: 0.00036813999805400036 Training loss: 0.0
2025-12-09 10:24:38.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 5891 LR: 0.00036798695530212776 Training loss: 0.0
2025-12-09 10:24:38.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 5892 LR: 0.00036783392584396516 Training loss: 0.0
2025-12-09 10:24:38.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 5893 LR: 0.00036768090969492264 Training loss: 0.0
2025-12-09 10:24:38.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 5894 LR: 0.00036752790687040866 Training loss: 0.0
2025-12-09 10:24:38.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 5895 LR: 0.00036737491738583116 Training loss: 0.0
2025-12-09 10:24:38.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 5896 LR: 0.0003672219412565956 Training loss: 0.0
2025-12-09 10:24:38.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 5897 LR: 0.00036706897849810705 Training loss: 0.0
2025-12-09 10:24:38.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 5898 LR: 0.00036691602912576865 Training loss: 0.0
2025-12-09 10:24:38.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 5899 LR: 0.0003667630931549826 Training loss: 0.0
2025-12-09 10:24:38.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 5900 LR: 0.0003666101706011492 Training loss: 0.0
2025-12-09 10:24:38.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 5901 LR: 0.0003664572614796682 Training loss: 0.0
2025-12-09 10:24:38.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 5902 LR: 0.00036630436580593716 Training loss: 0.0
2025-12-09 10:24:38.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 5903 LR: 0.000366151483595353 Training loss: 0.0
2025-12-09 10:24:38.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 5904 LR: 0.0003659986148633107 Training loss: 0.0
2025-12-09 10:24:38.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 5905 LR: 0.00036584575962520405 Training loss: 0.0
2025-12-09 10:24:38.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 5906 LR: 0.00036569291789642595 Training loss: 0.0
2025-12-09 10:24:38.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 5907 LR: 0.00036554008969236717 Training loss: 0.0
2025-12-09 10:24:38.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 5908 LR: 0.0003653872750284179 Training loss: 0.0
2025-12-09 10:24:38.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 5909 LR: 0.00036523447391996613 Training loss: 0.0
2025-12-09 10:24:38.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 5910 LR: 0.0003650816863823992 Training loss: 0.0
2025-12-09 10:24:38.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 5911 LR: 0.00036492891243110283 Training loss: 0.0
2025-12-09 10:24:38.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 5912 LR: 0.00036477615208146133 Training loss: 0.0
2025-12-09 10:24:38.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 5913 LR: 0.0003646234053488574 Training loss: 0.0
2025-12-09 10:24:38.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 5914 LR: 0.00036447067224867305 Training loss: 0.0
2025-12-09 10:24:38.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 5915 LR: 0.0003643179527962882 Training loss: 0.0
2025-12-09 10:24:38.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 5916 LR: 0.00036416524700708184 Training loss: 0.0
2025-12-09 10:24:38.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 5917 LR: 0.00036401255489643125 Training loss: 0.0
2025-12-09 10:24:38.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 5918 LR: 0.0003638598764797129 Training loss: 0.0
2025-12-09 10:24:38.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 5919 LR: 0.00036370721177230114 Training loss: 0.0
2025-12-09 10:24:38.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 5920 LR: 0.0003635545607895695 Training loss: 0.0
2025-12-09 10:24:38.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 5921 LR: 0.00036340192354688964 Training loss: 0.0
2025-12-09 10:24:38.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 5922 LR: 0.00036324930005963253 Training loss: 0.0
2025-12-09 10:24:38.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 5923 LR: 0.0003630966903431671 Training loss: 0.0
2025-12-09 10:24:38.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 5924 LR: 0.0003629440944128613 Training loss: 0.0
2025-12-09 10:24:38.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 5925 LR: 0.00036279151228408126 Training loss: 0.0
2025-12-09 10:24:38.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 5926 LR: 0.00036263894397219244 Training loss: 0.0
2025-12-09 10:24:38.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 5927 LR: 0.0003624863894925579 Training loss: 0.0
2025-12-09 10:24:38.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 5928 LR: 0.00036233384886054045 Training loss: 0.0
2025-12-09 10:24:38.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 5929 LR: 0.00036218132209150044 Training loss: 0.0
2025-12-09 10:24:38.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 5930 LR: 0.0003620288092007977 Training loss: 0.0
2025-12-09 10:24:38.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 5931 LR: 0.00036187631020378986 Training loss: 0.0
2025-12-09 10:24:38.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 5932 LR: 0.00036172382511583405 Training loss: 0.0
2025-12-09 10:24:38.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 5933 LR: 0.0003615713539522851 Training loss: 0.0
2025-12-09 10:24:38.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 5934 LR: 0.00036141889672849724 Training loss: 0.0
2025-12-09 10:24:38.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 5935 LR: 0.0003612664534598224 Training loss: 0.0
2025-12-09 10:24:38.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 5936 LR: 0.0003611140241616121 Training loss: 0.0
2025-12-09 10:24:38.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 5937 LR: 0.0003609616088492157 Training loss: 0.0
2025-12-09 10:24:38.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 5938 LR: 0.0003608092075379815 Training loss: 0.0
2025-12-09 10:24:38.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 5939 LR: 0.0003606568202432562 Training loss: 0.0
2025-12-09 10:24:38.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 5940 LR: 0.0003605044469803854 Training loss: 0.0
2025-12-09 10:24:38.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 5941 LR: 0.00036035208776471296 Training loss: 0.0
2025-12-09 10:24:38.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 5942 LR: 0.0003601997426115815 Training loss: 0.0
2025-12-09 10:24:38.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 5943 LR: 0.0003600474115363319 Training loss: 0.0
2025-12-09 10:24:38.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 5944 LR: 0.0003598950945543045 Training loss: 0.0
2025-12-09 10:24:38.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 5945 LR: 0.00035974279168083696 Training loss: 0.0
2025-12-09 10:24:38.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 5946 LR: 0.0003595905029312666 Training loss: 0.0
2025-12-09 10:24:38.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 5947 LR: 0.0003594382283209286 Training loss: 0.0
2025-12-09 10:24:38.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 5948 LR: 0.0003592859678651573 Training loss: 0.0
2025-12-09 10:24:38.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 5949 LR: 0.0003591337215792851 Training loss: 0.0
2025-12-09 10:24:38.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 5950 LR: 0.0003589814894786435 Training loss: 0.0
2025-12-09 10:24:38.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 5951 LR: 0.0003588292715785617 Training loss: 0.0
2025-12-09 10:24:38.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 5952 LR: 0.00035867706789436874 Training loss: 0.0
2025-12-09 10:24:38.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 5953 LR: 0.0003585248784413909 Training loss: 0.0
2025-12-09 10:24:38.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 5954 LR: 0.00035837270323495413 Training loss: 0.0
2025-12-09 10:24:38.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 5955 LR: 0.00035822054229038206 Training loss: 0.0
2025-12-09 10:24:38.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 5956 LR: 0.0003580683956229977 Training loss: 0.0
2025-12-09 10:24:38.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 5957 LR: 0.0003579162632481219 Training loss: 0.0
2025-12-09 10:24:38.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 5958 LR: 0.00035776414518107457 Training loss: 0.0
2025-12-09 10:24:38.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 5959 LR: 0.00035761204143717383 Training loss: 0.0
2025-12-09 10:24:38.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 5960 LR: 0.0003574599520317369 Training loss: 0.0
2025-12-09 10:24:38.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 5961 LR: 0.00035730787698007847 Training loss: 0.0
2025-12-09 10:24:38.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 5962 LR: 0.00035715581629751326 Training loss: 0.0
2025-12-09 10:24:38.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 5963 LR: 0.00035700376999935334 Training loss: 0.0
2025-12-09 10:24:38.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 5964 LR: 0.00035685173810090986 Training loss: 0.0
2025-12-09 10:24:38.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 5965 LR: 0.00035669972061749236 Training loss: 0.0
2025-12-09 10:24:38.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 5966 LR: 0.0003565477175644092 Training loss: 0.0
2025-12-09 10:24:38.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 5967 LR: 0.00035639572895696686 Training loss: 0.0
2025-12-09 10:24:38.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 5968 LR: 0.0003562437548104708 Training loss: 0.0
2025-12-09 10:24:38.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 5969 LR: 0.0003560917951402245 Training loss: 0.0
2025-12-09 10:24:38.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 5970 LR: 0.00035593984996153073 Training loss: 0.0
2025-12-09 10:24:38.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 5971 LR: 0.00035578791928968993 Training loss: 0.0
2025-12-09 10:24:38.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 5972 LR: 0.00035563600314000187 Training loss: 0.0
2025-12-09 10:24:38.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 5973 LR: 0.0003554841015277641 Training loss: 0.0
2025-12-09 10:24:38.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 5974 LR: 0.0003553322144682737 Training loss: 0.0
2025-12-09 10:24:38.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 5975 LR: 0.0003551803419768251 Training loss: 0.0
2025-12-09 10:24:38.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 5976 LR: 0.00035502848406871227 Training loss: 0.0
2025-12-09 10:24:38.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 5977 LR: 0.0003548766407592269 Training loss: 0.0
2025-12-09 10:24:38.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 5978 LR: 0.00035472481206365997 Training loss: 0.0
2025-12-09 10:24:38.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 5979 LR: 0.00035457299799730046 Training loss: 0.0
2025-12-09 10:24:38.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 5980 LR: 0.0003544211985754362 Training loss: 0.0
2025-12-09 10:24:38.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 5981 LR: 0.000354269413813353 Training loss: 0.0
2025-12-09 10:24:38.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 5982 LR: 0.00035411764372633605 Training loss: 0.0
2025-12-09 10:24:38.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 5983 LR: 0.00035396588832966826 Training loss: 0.0
2025-12-09 10:24:38.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 5984 LR: 0.00035381414763863166 Training loss: 0.0
2025-12-09 10:24:38.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 5985 LR: 0.0003536624216685062 Training loss: 0.0
2025-12-09 10:24:38.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 5986 LR: 0.00035351071043457106 Training loss: 0.0
2025-12-09 10:24:38.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 5987 LR: 0.0003533590139521033 Training loss: 0.0
2025-12-09 10:24:38.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 5988 LR: 0.0003532073322363789 Training loss: 0.0
2025-12-09 10:24:38.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 5989 LR: 0.0003530556653026721 Training loss: 0.0
2025-12-09 10:24:38.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 5990 LR: 0.00035290401316625576 Training loss: 0.0
2025-12-09 10:24:38.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 5991 LR: 0.00035275237584240127 Training loss: 0.0
2025-12-09 10:24:38.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 5992 LR: 0.00035260075334637834 Training loss: 0.0
2025-12-09 10:24:38.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 5993 LR: 0.00035244914569345574 Training loss: 0.0
2025-12-09 10:24:38.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 5994 LR: 0.0003522975528989 Training loss: 0.0
2025-12-09 10:24:38.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 5995 LR: 0.0003521459749779768 Training loss: 0.0
2025-12-09 10:24:38.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 5996 LR: 0.00035199441194594963 Training loss: 0.0
2025-12-09 10:24:38.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 5997 LR: 0.00035184286381808135 Training loss: 0.0
2025-12-09 10:24:38.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 5998 LR: 0.0003516913306096325 Training loss: 0.0
2025-12-09 10:24:38.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 5999 LR: 0.00035153981233586274 Training loss: 0.0
2025-12-09 10:24:38.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 6000 LR: 0.00035138830901202956 Training loss: 0.0
2025-12-09 10:24:38.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 6001 LR: 0.0003512368206533898 Training loss: 0.0
2025-12-09 10:24:38.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 6002 LR: 0.000351085347275198 Training loss: 0.0
2025-12-09 10:24:38.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 6003 LR: 0.00035093388889270786 Training loss: 0.0
2025-12-09 10:24:38.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 6004 LR: 0.0003507824455211708 Training loss: 0.0
2025-12-09 10:24:38.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 6005 LR: 0.0003506310171758376 Training loss: 0.0
2025-12-09 10:24:38.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 6006 LR: 0.00035047960387195673 Training loss: 0.0
2025-12-09 10:24:38.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 6007 LR: 0.00035032820562477574 Training loss: 0.0
2025-12-09 10:24:38.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 6008 LR: 0.00035017682244954017 Training loss: 0.0
2025-12-09 10:24:38.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 6009 LR: 0.00035002545436149473 Training loss: 0.0
2025-12-09 10:24:38.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 6010 LR: 0.00034987410137588183 Training loss: 0.0
2025-12-09 10:24:38.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 6011 LR: 0.00034972276350794286 Training loss: 0.0
2025-12-09 10:24:38.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 6012 LR: 0.00034957144077291737 Training loss: 0.0
2025-12-09 10:24:38.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 6013 LR: 0.0003494201331860438 Training loss: 0.0
2025-12-09 10:24:38.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 6014 LR: 0.0003492688407625586 Training loss: 0.0
2025-12-09 10:24:38.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 6015 LR: 0.0003491175635176972 Training loss: 0.0
2025-12-09 10:24:38.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 6016 LR: 0.00034896630146669273 Training loss: 0.0
2025-12-09 10:24:38.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 6017 LR: 0.00034881505462477783 Training loss: 0.0
2025-12-09 10:24:38.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 6018 LR: 0.0003486638230071826 Training loss: 0.0
2025-12-09 10:24:38.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 6019 LR: 0.0003485126066291364 Training loss: 0.0
2025-12-09 10:24:38.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 6020 LR: 0.0003483614055058664 Training loss: 0.0
2025-12-09 10:24:38.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 6021 LR: 0.000348210219652599 Training loss: 0.0
2025-12-09 10:24:38.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 6022 LR: 0.00034805904908455804 Training loss: 0.0
2025-12-09 10:24:38.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 6023 LR: 0.00034790789381696684 Training loss: 0.0
2025-12-09 10:24:38.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 6024 LR: 0.00034775675386504657 Training loss: 0.0
2025-12-09 10:24:38.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 6025 LR: 0.00034760562924401704 Training loss: 0.0
2025-12-09 10:24:38.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 6026 LR: 0.0003474545199690963 Training loss: 0.0
2025-12-09 10:24:38.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 6027 LR: 0.00034730342605550135 Training loss: 0.0
2025-12-09 10:24:38.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 6028 LR: 0.0003471523475184472 Training loss: 0.0
2025-12-09 10:24:38.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 6029 LR: 0.0003470012843731476 Training loss: 0.0
2025-12-09 10:24:38.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 6030 LR: 0.0003468502366348142 Training loss: 0.0
2025-12-09 10:24:38.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 6031 LR: 0.000346699204318658 Training loss: 0.0
2025-12-09 10:24:38.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 6032 LR: 0.00034654818743988763 Training loss: 0.0
2025-12-09 10:24:38.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 6033 LR: 0.00034639718601371075 Training loss: 0.0
2025-12-09 10:24:38.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 6034 LR: 0.0003462462000553327 Training loss: 0.0
2025-12-09 10:24:38.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 6035 LR: 0.00034609522957995844 Training loss: 0.0
2025-12-09 10:24:38.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 6036 LR: 0.00034594427460279015 Training loss: 0.0
2025-12-09 10:24:38.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 6037 LR: 0.0003457933351390293 Training loss: 0.0
2025-12-09 10:24:38.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 6038 LR: 0.00034564241120387527 Training loss: 0.0
2025-12-09 10:24:38.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 6039 LR: 0.00034549150281252633 Training loss: 0.0
2025-12-09 10:24:38.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 6040 LR: 0.00034534060998017875 Training loss: 0.0
2025-12-09 10:24:38.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 6041 LR: 0.00034518973272202756 Training loss: 0.0
2025-12-09 10:24:38.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 6042 LR: 0.0003450388710532659 Training loss: 0.0
2025-12-09 10:24:38.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 6043 LR: 0.00034488802498908595 Training loss: 0.0
2025-12-09 10:24:38.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 6044 LR: 0.0003447371945446774 Training loss: 0.0
2025-12-09 10:24:38.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 6045 LR: 0.00034458637973522934 Training loss: 0.0
2025-12-09 10:24:38.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 6046 LR: 0.0003444355805759284 Training loss: 0.0
2025-12-09 10:24:38.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 6047 LR: 0.00034428479708196037 Training loss: 0.0
2025-12-09 10:24:38.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 6048 LR: 0.0003441340292685089 Training loss: 0.0
2025-12-09 10:24:38.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 6049 LR: 0.0003439832771507565 Training loss: 0.0
2025-12-09 10:24:38.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 6050 LR: 0.0003438325407438837 Training loss: 0.0
2025-12-09 10:24:38.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 6051 LR: 0.00034368182006307005 Training loss: 0.0
2025-12-09 10:24:38.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 6052 LR: 0.00034353111512349245 Training loss: 0.0
2025-12-09 10:24:38.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 6053 LR: 0.0003433804259403276 Training loss: 0.0
2025-12-09 10:24:38.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 6054 LR: 0.00034322975252874946 Training loss: 0.0
2025-12-09 10:24:38.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 6055 LR: 0.00034307909490393095 Training loss: 0.0
2025-12-09 10:24:38.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 6056 LR: 0.00034292845308104316 Training loss: 0.0
2025-12-09 10:24:38.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 6057 LR: 0.00034277782707525605 Training loss: 0.0
2025-12-09 10:24:38.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 6058 LR: 0.00034262721690173737 Training loss: 0.0
2025-12-09 10:24:38.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 6059 LR: 0.0003424766225756537 Training loss: 0.0
2025-12-09 10:24:38.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 6060 LR: 0.0003423260441121696 Training loss: 0.0
2025-12-09 10:24:38.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 6061 LR: 0.0003421754815264488 Training loss: 0.0
2025-12-09 10:24:38.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 6062 LR: 0.0003420249348336526 Training loss: 0.0
2025-12-09 10:24:38.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 6063 LR: 0.0003418744040489412 Training loss: 0.0
2025-12-09 10:24:38.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 6064 LR: 0.0003417238891874728 Training loss: 0.0
2025-12-09 10:24:38.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 6065 LR: 0.0003415733902644046 Training loss: 0.0
2025-12-09 10:24:38.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 6066 LR: 0.00034142290729489164 Training loss: 0.0
2025-12-09 10:24:38.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 6067 LR: 0.0003412724402940876 Training loss: 0.0
2025-12-09 10:24:38.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 6068 LR: 0.0003411219892771443 Training loss: 0.0
2025-12-09 10:24:38.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 6069 LR: 0.00034097155425921255 Training loss: 0.0
2025-12-09 10:24:38.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 6070 LR: 0.00034082113525544085 Training loss: 0.0
2025-12-09 10:24:38.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 6071 LR: 0.0003406707322809766 Training loss: 0.0
2025-12-09 10:24:38.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 6072 LR: 0.000340520345350965 Training loss: 0.0
2025-12-09 10:24:38.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 6073 LR: 0.0003403699744805504 Training loss: 0.0
2025-12-09 10:24:38.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 6074 LR: 0.0003402196196848751 Training loss: 0.0
2025-12-09 10:24:38.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 6075 LR: 0.0003400692809790796 Training loss: 0.0
2025-12-09 10:24:38.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 6076 LR: 0.00033991895837830324 Training loss: 0.0
2025-12-09 10:24:38.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 6077 LR: 0.00033976865189768314 Training loss: 0.0
2025-12-09 10:24:38.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 6078 LR: 0.00033961836155235557 Training loss: 0.0
2025-12-09 10:24:38.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 6079 LR: 0.0003394680873574546 Training loss: 0.0
2025-12-09 10:24:38.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 6080 LR: 0.00033931782932811297 Training loss: 0.0
2025-12-09 10:24:38.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 6081 LR: 0.00033916758747946126 Training loss: 0.0
2025-12-09 10:24:38.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 6082 LR: 0.0003390173618266294 Training loss: 0.0
2025-12-09 10:24:38.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 6083 LR: 0.00033886715238474455 Training loss: 0.0
2025-12-09 10:24:38.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 6084 LR: 0.00033871695916893316 Training loss: 0.0
2025-12-09 10:24:38.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 6085 LR: 0.00033856678219431946 Training loss: 0.0
2025-12-09 10:24:38.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 6086 LR: 0.0003384166214760266 Training loss: 0.0
2025-12-09 10:24:38.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 6087 LR: 0.0003382664770291752 Training loss: 0.0
2025-12-09 10:24:38.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 6088 LR: 0.0003381163488688854 Training loss: 0.0
2025-12-09 10:24:38.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 6089 LR: 0.0003379662370102747 Training loss: 0.0
2025-12-09 10:24:38.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 6090 LR: 0.00033781614146845973 Training loss: 0.0
2025-12-09 10:24:38.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 6091 LR: 0.00033766606225855457 Training loss: 0.0
2025-12-09 10:24:38.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 6092 LR: 0.0003375159993956727 Training loss: 0.0
2025-12-09 10:24:38.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 6093 LR: 0.00033736595289492514 Training loss: 0.0
2025-12-09 10:24:38.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 6094 LR: 0.00033721592277142175 Training loss: 0.0
2025-12-09 10:24:38.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 6095 LR: 0.00033706590904027036 Training loss: 0.0
2025-12-09 10:24:38.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 6096 LR: 0.00033691591171657764 Training loss: 0.0
2025-12-09 10:24:38.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 6097 LR: 0.00033676593081544804 Training loss: 0.0
2025-12-09 10:24:38.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 6098 LR: 0.0003366159663519849 Training loss: 0.0
2025-12-09 10:24:38.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 6099 LR: 0.0003364660183412892 Training loss: 0.0
2025-12-09 10:24:39.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 6100 LR: 0.00033631608679846113 Training loss: 0.0
2025-12-09 10:24:39.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 6101 LR: 0.00033616617173859865 Training loss: 0.0
2025-12-09 10:24:39.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 6102 LR: 0.00033601627317679826 Training loss: 0.0
2025-12-09 10:24:39.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 6103 LR: 0.0003358663911281544 Training loss: 0.0
2025-12-09 10:24:39.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 6104 LR: 0.0003357165256077608 Training loss: 0.0
2025-12-09 10:24:39.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 6105 LR: 0.00033556667663070836 Training loss: 0.0
2025-12-09 10:24:39.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 6106 LR: 0.0003354168442120873 Training loss: 0.0
2025-12-09 10:24:39.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 6107 LR: 0.0003352670283669852 Training loss: 0.0
2025-12-09 10:24:39.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 6108 LR: 0.00033511722911048916 Training loss: 0.0
2025-12-09 10:24:39.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 6109 LR: 0.0003349674464576834 Training loss: 0.0
2025-12-09 10:24:39.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 6110 LR: 0.00033481768042365145 Training loss: 0.0
2025-12-09 10:24:39.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 6111 LR: 0.0003346679310234744 Training loss: 0.0
2025-12-09 10:24:39.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 6112 LR: 0.0003345181982722323 Training loss: 0.0
2025-12-09 10:24:39.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 6113 LR: 0.00033436848218500306 Training loss: 0.0
2025-12-09 10:24:39.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 6114 LR: 0.00033421878277686314 Training loss: 0.0
2025-12-09 10:24:39.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 6115 LR: 0.00033406910006288716 Training loss: 0.0
2025-12-09 10:24:39.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 6116 LR: 0.0003339194340581485 Training loss: 0.0
2025-12-09 10:24:39.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 6117 LR: 0.00033376978477771794 Training loss: 0.0
2025-12-09 10:24:39.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 6118 LR: 0.0003336201522366658 Training loss: 0.0
2025-12-09 10:24:39.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 6119 LR: 0.00033347053645005966 Training loss: 0.0
2025-12-09 10:24:39.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 6120 LR: 0.00033332093743296606 Training loss: 0.0
2025-12-09 10:24:39.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 6121 LR: 0.00033317135520044924 Training loss: 0.0
2025-12-09 10:24:39.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 6122 LR: 0.0003330217897675726 Training loss: 0.0
2025-12-09 10:24:39.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 6123 LR: 0.00033287224114939706 Training loss: 0.0
2025-12-09 10:24:39.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 6124 LR: 0.0003327227093609824 Training loss: 0.0
2025-12-09 10:24:39.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 6125 LR: 0.00033257319441738607 Training loss: 0.0
2025-12-09 10:24:39.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 6126 LR: 0.00033242369633366476 Training loss: 0.0
2025-12-09 10:24:39.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 6127 LR: 0.00033227421512487253 Training loss: 0.0
2025-12-09 10:24:39.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 6128 LR: 0.0003321247508060623 Training loss: 0.0
2025-12-09 10:24:39.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 6129 LR: 0.00033197530339228485 Training loss: 0.0
2025-12-09 10:24:39.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 6130 LR: 0.00033182587289859005 Training loss: 0.0
2025-12-09 10:24:39.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 6131 LR: 0.0003316764593400251 Training loss: 0.0
2025-12-09 10:24:39.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 6132 LR: 0.0003315270627316362 Training loss: 0.0
2025-12-09 10:24:39.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 6133 LR: 0.00033137768308846724 Training loss: 0.0
2025-12-09 10:24:39.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 6134 LR: 0.0003312283204255612 Training loss: 0.0
2025-12-09 10:24:39.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 6135 LR: 0.00033107897475795854 Training loss: 0.0
2025-12-09 10:24:39.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 6136 LR: 0.00033092964610069865 Training loss: 0.0
2025-12-09 10:24:39.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 6137 LR: 0.0003307803344688185 Training loss: 0.0
2025-12-09 10:24:39.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 6138 LR: 0.0003306310398773543 Training loss: 0.0
2025-12-09 10:24:39.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 6139 LR: 0.00033048176234133967 Training loss: 0.0
2025-12-09 10:24:39.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 6140 LR: 0.000330332501875807 Training loss: 0.0
2025-12-09 10:24:39.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 6141 LR: 0.0003301832584957866 Training loss: 0.0
2025-12-09 10:24:39.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 6142 LR: 0.0003300340322163076 Training loss: 0.0
2025-12-09 10:24:39.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 6143 LR: 0.0003298848230523967 Training loss: 0.0
2025-12-09 10:24:39.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 6144 LR: 0.00032973563101907965 Training loss: 0.0
2025-12-09 10:24:39.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 6145 LR: 0.0003295864561313797 Training loss: 0.0
2025-12-09 10:24:39.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 6146 LR: 0.00032943729840431924 Training loss: 0.0
2025-12-09 10:24:39.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 6147 LR: 0.00032928815785291787 Training loss: 0.0
2025-12-09 10:24:39.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 6148 LR: 0.0003291390344921945 Training loss: 0.0
2025-12-09 10:24:39.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 6149 LR: 0.0003289899283371657 Training loss: 0.0
2025-12-09 10:24:39.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 6150 LR: 0.0003288408394028464 Training loss: 0.0
2025-12-09 10:24:39.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 6151 LR: 0.00032869176770424977 Training loss: 0.0
2025-12-09 10:24:39.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 6152 LR: 0.0003285427132563876 Training loss: 0.0
2025-12-09 10:24:39.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 6153 LR: 0.0003283936760742694 Training loss: 0.0
2025-12-09 10:24:39.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 6154 LR: 0.00032824465617290344 Training loss: 0.0
2025-12-09 10:24:39.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 6155 LR: 0.00032809565356729575 Training loss: 0.0
2025-12-09 10:24:39.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 6156 LR: 0.00032794666827245123 Training loss: 0.0
2025-12-09 10:24:39.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 6157 LR: 0.00032779770030337237 Training loss: 0.0
2025-12-09 10:24:39.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 6158 LR: 0.0003276487496750605 Training loss: 0.0
2025-12-09 10:24:39.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 6159 LR: 0.0003274998164025148 Training loss: 0.0
2025-12-09 10:24:39.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 6160 LR: 0.0003273509005007327 Training loss: 0.0
2025-12-09 10:24:39.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 6161 LR: 0.00032720200198471037 Training loss: 0.0
2025-12-09 10:24:39.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 6162 LR: 0.0003270531208694416 Training loss: 0.0
2025-12-09 10:24:39.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 6163 LR: 0.000326904257169919 Training loss: 0.0
2025-12-09 10:24:39.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 6164 LR: 0.0003267554109011327 Training loss: 0.0
2025-12-09 10:24:39.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 6165 LR: 0.00032660658207807206 Training loss: 0.0
2025-12-09 10:24:39.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 6166 LR: 0.00032645777071572366 Training loss: 0.0
2025-12-09 10:24:39.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 6167 LR: 0.0003263089768290731 Training loss: 0.0
2025-12-09 10:24:39.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 6168 LR: 0.0003261602004331037 Training loss: 0.0
2025-12-09 10:24:39.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 6169 LR: 0.0003260114415427975 Training loss: 0.0
2025-12-09 10:24:39.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 6170 LR: 0.0003258627001731343 Training loss: 0.0
2025-12-09 10:24:39.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 6171 LR: 0.0003257139763390925 Training loss: 0.0
2025-12-09 10:24:39.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 6172 LR: 0.00032556527005564835 Training loss: 0.0
2025-12-09 10:24:39.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 6173 LR: 0.0003254165813377769 Training loss: 0.0
2025-12-09 10:24:39.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 6174 LR: 0.0003252679102004509 Training loss: 0.0
2025-12-09 10:24:39.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 6175 LR: 0.0003251192566586416 Training loss: 0.0
2025-12-09 10:24:39.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 6176 LR: 0.0003249706207273181 Training loss: 0.0
2025-12-09 10:24:39.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 6177 LR: 0.0003248220024214488 Training loss: 0.0
2025-12-09 10:24:39.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 6178 LR: 0.00032467340175599857 Training loss: 0.0
2025-12-09 10:24:39.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 6179 LR: 0.0003245248187459323 Training loss: 0.0
2025-12-09 10:24:39.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 6180 LR: 0.00032437625340621184 Training loss: 0.0
2025-12-09 10:24:39.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 6181 LR: 0.00032422770575179794 Training loss: 0.0
2025-12-09 10:24:39.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 6182 LR: 0.00032407917579764913 Training loss: 0.0
2025-12-09 10:24:39.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 6183 LR: 0.0003239306635587226 Training loss: 0.0
2025-12-09 10:24:39.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 6184 LR: 0.00032378216904997345 Training loss: 0.0
2025-12-09 10:24:39.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 6185 LR: 0.00032363369228635507 Training loss: 0.0
2025-12-09 10:24:39.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 6186 LR: 0.0003234852332828189 Training loss: 0.0
2025-12-09 10:24:39.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 6187 LR: 0.0003233367920543151 Training loss: 0.0
2025-12-09 10:24:39.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 6188 LR: 0.0003231883686157914 Training loss: 0.0
2025-12-09 10:24:39.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 6189 LR: 0.00032303996298219416 Training loss: 0.0
2025-12-09 10:24:39.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 6190 LR: 0.00032289157516846766 Training loss: 0.0
2025-12-09 10:24:39.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 6191 LR: 0.00032274320518955497 Training loss: 0.0
2025-12-09 10:24:39.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 6192 LR: 0.0003225948530603965 Training loss: 0.0
2025-12-09 10:24:39.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 6193 LR: 0.00032244651879593156 Training loss: 0.0
2025-12-09 10:24:39.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 6194 LR: 0.0003222982024110972 Training loss: 0.0
2025-12-09 10:24:39.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 6195 LR: 0.0003221499039208291 Training loss: 0.0
2025-12-09 10:24:39.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 6196 LR: 0.00032200162334006076 Training loss: 0.0
2025-12-09 10:24:39.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 6197 LR: 0.0003218533606837242 Training loss: 0.0
2025-12-09 10:24:39.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 6198 LR: 0.00032170511596674905 Training loss: 0.0
2025-12-09 10:24:39.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 6199 LR: 0.00032155688920406414 Training loss: 0.0
2025-12-09 10:24:39.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 6200 LR: 0.00032140868041059546 Training loss: 0.0
2025-12-09 10:24:39.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 6201 LR: 0.00032126048960126786 Training loss: 0.0
2025-12-09 10:24:39.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 6202 LR: 0.00032111231679100394 Training loss: 0.0
2025-12-09 10:24:39.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 6203 LR: 0.00032096416199472495 Training loss: 0.0
2025-12-09 10:24:39.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 6204 LR: 0.00032081602522734986 Training loss: 0.0
2025-12-09 10:24:39.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 6205 LR: 0.0003206679065037963 Training loss: 0.0
2025-12-09 10:24:39.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 6206 LR: 0.0003205198058389793 Training loss: 0.0
2025-12-09 10:24:39.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 6207 LR: 0.00032037172324781327 Training loss: 0.0
2025-12-09 10:24:39.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 6208 LR: 0.00032022365874520965 Training loss: 0.0
2025-12-09 10:24:39.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 6209 LR: 0.0003200756123460788 Training loss: 0.0
2025-12-09 10:24:39.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 6210 LR: 0.0003199275840653287 Training loss: 0.0
2025-12-09 10:24:39.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 6211 LR: 0.00031977957391786616 Training loss: 0.0
2025-12-09 10:24:39.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 6212 LR: 0.0003196315819185953 Training loss: 0.0
2025-12-09 10:24:39.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 6213 LR: 0.00031948360808241945 Training loss: 0.0
2025-12-09 10:24:39.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 6214 LR: 0.0003193356524242392 Training loss: 0.0
2025-12-09 10:24:39.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 6215 LR: 0.00031918771495895393 Training loss: 0.0
2025-12-09 10:24:39.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 6216 LR: 0.00031903979570146063 Training loss: 0.0
2025-12-09 10:24:39.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 6217 LR: 0.0003188918946666551 Training loss: 0.0
2025-12-09 10:24:39.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 6218 LR: 0.0003187440118694308 Training loss: 0.0
2025-12-09 10:24:39.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 6219 LR: 0.00031859614732467957 Training loss: 0.0
2025-12-09 10:24:39.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 6220 LR: 0.0003184483010472912 Training loss: 0.0
2025-12-09 10:24:39.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 6221 LR: 0.00031830047305215413 Training loss: 0.0
2025-12-09 10:24:39.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 6222 LR: 0.0003181526633541543 Training loss: 0.0
2025-12-09 10:24:39.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 6223 LR: 0.00031800487196817647 Training loss: 0.0
2025-12-09 10:24:39.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 6224 LR: 0.0003178570989091028 Training loss: 0.0
2025-12-09 10:24:39.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 6225 LR: 0.00031770934419181454 Training loss: 0.0
2025-12-09 10:24:39.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 6226 LR: 0.00031756160783119017 Training loss: 0.0
2025-12-09 10:24:39.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 6227 LR: 0.00031741388984210707 Training loss: 0.0
2025-12-09 10:24:39.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 6228 LR: 0.00031726619023944 Training loss: 0.0
2025-12-09 10:24:39.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 6229 LR: 0.00031711850903806275 Training loss: 0.0
2025-12-09 10:24:39.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 6230 LR: 0.00031697084625284663 Training loss: 0.0
2025-12-09 10:24:39.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 6231 LR: 0.0003168232018986613 Training loss: 0.0
2025-12-09 10:24:39.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 6232 LR: 0.00031667557599037436 Training loss: 0.0
2025-12-09 10:24:39.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 6233 LR: 0.00031652796854285214 Training loss: 0.0
2025-12-09 10:24:39.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 6234 LR: 0.0003163803795709583 Training loss: 0.0
2025-12-09 10:24:39.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 6235 LR: 0.0003162328090895554 Training loss: 0.0
2025-12-09 10:24:39.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 6236 LR: 0.0003160852571135033 Training loss: 0.0
2025-12-09 10:24:39.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 6237 LR: 0.00031593772365766105 Training loss: 0.0
2025-12-09 10:24:39.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 6238 LR: 0.0003157902087368848 Training loss: 0.0
2025-12-09 10:24:39.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 6239 LR: 0.0003156427123660297 Training loss: 0.0
2025-12-09 10:24:39.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 6240 LR: 0.0003154952345599481 Training loss: 0.0
2025-12-09 10:24:39.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 6241 LR: 0.0003153477753334918 Training loss: 0.0
2025-12-09 10:24:39.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 6242 LR: 0.000315200334701509 Training loss: 0.0
2025-12-09 10:24:39.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 6243 LR: 0.0003150529126788477 Training loss: 0.0
2025-12-09 10:24:39.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 6244 LR: 0.0003149055092803531 Training loss: 0.0
2025-12-09 10:24:39.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 6245 LR: 0.0003147581245208685 Training loss: 0.0
2025-12-09 10:24:39.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 6246 LR: 0.0003146107584152358 Training loss: 0.0
2025-12-09 10:24:39.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 6247 LR: 0.00031446341097829443 Training loss: 0.0
2025-12-09 10:24:39.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 6248 LR: 0.00031431608222488275 Training loss: 0.0
2025-12-09 10:24:39.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 6249 LR: 0.0003141687721698363 Training loss: 0.0
2025-12-09 10:24:39.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 6250 LR: 0.0003140214808279896 Training loss: 0.0
2025-12-09 10:24:39.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 6251 LR: 0.00031387420821417443 Training loss: 0.0
2025-12-09 10:24:39.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 6252 LR: 0.0003137269543432217 Training loss: 0.0
2025-12-09 10:24:39.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 6253 LR: 0.00031357971922995936 Training loss: 0.0
2025-12-09 10:24:39.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 6254 LR: 0.00031343250288921436 Training loss: 0.0
2025-12-09 10:24:39.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 6255 LR: 0.000313285305335811 Training loss: 0.0
2025-12-09 10:24:39.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 6256 LR: 0.00031313812658457255 Training loss: 0.0
2025-12-09 10:24:39.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 6257 LR: 0.0003129909666503194 Training loss: 0.0
2025-12-09 10:24:39.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 6258 LR: 0.00031284382554787094 Training loss: 0.0
2025-12-09 10:24:39.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 6259 LR: 0.00031269670329204396 Training loss: 0.0
2025-12-09 10:24:39.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 6260 LR: 0.0003125495998976541 Training loss: 0.0
2025-12-09 10:24:39.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 6261 LR: 0.00031240251537951417 Training loss: 0.0
2025-12-09 10:24:39.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 6262 LR: 0.000312255449752436 Training loss: 0.0
2025-12-09 10:24:39.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 6263 LR: 0.00031210840303122863 Training loss: 0.0
2025-12-09 10:24:39.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 6264 LR: 0.00031196137523070017 Training loss: 0.0
2025-12-09 10:24:39.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 6265 LR: 0.00031181436636565596 Training loss: 0.0
2025-12-09 10:24:39.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 6266 LR: 0.00031166737645090003 Training loss: 0.0
2025-12-09 10:24:39.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 6267 LR: 0.00031152040550123396 Training loss: 0.0
2025-12-09 10:24:39.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 6268 LR: 0.0003113734535314581 Training loss: 0.0
2025-12-09 10:24:39.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 6269 LR: 0.00031122652055637015 Training loss: 0.0
2025-12-09 10:24:39.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 6270 LR: 0.0003110796065907665 Training loss: 0.0
2025-12-09 10:24:39.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 6271 LR: 0.00031093271164944113 Training loss: 0.0
2025-12-09 10:24:39.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 6272 LR: 0.0003107858357471869 Training loss: 0.0
2025-12-09 10:24:39.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 6273 LR: 0.0003106389788987934 Training loss: 0.0
2025-12-09 10:24:39.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 6274 LR: 0.00031049214111904987 Training loss: 0.0
2025-12-09 10:24:39.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 6275 LR: 0.0003103453224227424 Training loss: 0.0
2025-12-09 10:24:39.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 6276 LR: 0.0003101985228246559 Training loss: 0.0
2025-12-09 10:24:39.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 6277 LR: 0.00031005174233957267 Training loss: 0.0
2025-12-09 10:24:39.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 6278 LR: 0.00030990498098227404 Training loss: 0.0
2025-12-09 10:24:39.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 6279 LR: 0.0003097582387675385 Training loss: 0.0
2025-12-09 10:24:39.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 6280 LR: 0.0003096115157101432 Training loss: 0.0
2025-12-09 10:24:39.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 6281 LR: 0.000309464811824863 Training loss: 0.0
2025-12-09 10:24:39.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 6282 LR: 0.0003093181271264711 Training loss: 0.0
2025-12-09 10:24:39.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 6283 LR: 0.00030917146162973846 Training loss: 0.0
2025-12-09 10:24:39.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 6284 LR: 0.0003090248153494346 Training loss: 0.0
2025-12-09 10:24:39.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 6285 LR: 0.00030887818830032635 Training loss: 0.0
2025-12-09 10:24:39.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 6286 LR: 0.00030873158049717954 Training loss: 0.0
2025-12-09 10:24:39.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 6287 LR: 0.0003085849919547572 Training loss: 0.0
2025-12-09 10:24:39.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 6288 LR: 0.00030843842268782107 Training loss: 0.0
2025-12-09 10:24:39.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 6289 LR: 0.00030829187271113034 Training loss: 0.0
2025-12-09 10:24:39.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 6290 LR: 0.00030814534203944295 Training loss: 0.0
2025-12-09 10:24:39.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 6291 LR: 0.00030799883068751435 Training loss: 0.0
2025-12-09 10:24:39.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 6292 LR: 0.0003078523386700982 Training loss: 0.0
2025-12-09 10:24:39.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 6293 LR: 0.0003077058660019462 Training loss: 0.0
2025-12-09 10:24:39.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 6294 LR: 0.0003075594126978084 Training loss: 0.0
2025-12-09 10:24:39.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 6295 LR: 0.00030741297877243237 Training loss: 0.0
2025-12-09 10:24:39.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 6296 LR: 0.0003072665642405642 Training loss: 0.0
2025-12-09 10:24:39.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 6297 LR: 0.0003071201691169476 Training loss: 0.0
2025-12-09 10:24:39.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 6298 LR: 0.0003069737934163248 Training loss: 0.0
2025-12-09 10:24:39.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 6299 LR: 0.00030682743715343565 Training loss: 0.0
2025-12-09 10:24:39.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 6300 LR: 0.00030668110034301845 Training loss: 0.0
2025-12-09 10:24:39.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 6301 LR: 0.00030653478299980894 Training loss: 0.0
2025-12-09 10:24:39.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 6302 LR: 0.00030638848513854175 Training loss: 0.0
2025-12-09 10:24:39.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 6303 LR: 0.0003062422067739485 Training loss: 0.0
2025-12-09 10:24:39.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 6304 LR: 0.00030609594792075994 Training loss: 0.0
2025-12-09 10:24:39.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 6305 LR: 0.0003059497085937041 Training loss: 0.0
2025-12-09 10:24:39.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 6306 LR: 0.00030580348880750733 Training loss: 0.0
2025-12-09 10:24:39.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 6307 LR: 0.0003056572885768937 Training loss: 0.0
2025-12-09 10:24:39.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 6308 LR: 0.000305511107916586 Training loss: 0.0
2025-12-09 10:24:39.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 6309 LR: 0.0003053649468413043 Training loss: 0.0
2025-12-09 10:24:39.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 6310 LR: 0.00030521880536576724 Training loss: 0.0
2025-12-09 10:24:39.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 6311 LR: 0.000305072683504691 Training loss: 0.0
2025-12-09 10:24:39.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 6312 LR: 0.0003049265812727903 Training loss: 0.0
2025-12-09 10:24:39.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 6313 LR: 0.0003047804986847775 Training loss: 0.0
2025-12-09 10:24:39.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 6314 LR: 0.0003046344357553632 Training loss: 0.0
2025-12-09 10:24:39.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 6315 LR: 0.0003044883924992557 Training loss: 0.0
2025-12-09 10:24:39.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 6316 LR: 0.00030434236893116197 Training loss: 0.0
2025-12-09 10:24:39.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 6317 LR: 0.0003041963650657862 Training loss: 0.0
2025-12-09 10:24:39.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 6318 LR: 0.0003040503809178312 Training loss: 0.0
2025-12-09 10:24:39.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 6319 LR: 0.00030390441650199725 Training loss: 0.0
2025-12-09 10:24:39.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 6320 LR: 0.00030375847183298344 Training loss: 0.0
2025-12-09 10:24:39.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 6321 LR: 0.000303612546925486 Training loss: 0.0
2025-12-09 10:24:39.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 6322 LR: 0.00030346664179419983 Training loss: 0.0
2025-12-09 10:24:39.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 6323 LR: 0.00030332075645381727 Training loss: 0.0
2025-12-09 10:24:39.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 6324 LR: 0.00030317489091902933 Training loss: 0.0
2025-12-09 10:24:39.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 6325 LR: 0.00030302904520452444 Training loss: 0.0
2025-12-09 10:24:39.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 6326 LR: 0.00030288321932498937 Training loss: 0.0
2025-12-09 10:24:39.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 6327 LR: 0.0003027374132951085 Training loss: 0.0
2025-12-09 10:24:39.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 6328 LR: 0.00030259162712956497 Training loss: 0.0
2025-12-09 10:24:39.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 6329 LR: 0.00030244586084303903 Training loss: 0.0
2025-12-09 10:24:39.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 6330 LR: 0.00030230011445020965 Training loss: 0.0
2025-12-09 10:24:39.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 6331 LR: 0.0003021543879657533 Training loss: 0.0
2025-12-09 10:24:39.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 6332 LR: 0.00030200868140434445 Training loss: 0.0
2025-12-09 10:24:39.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 6333 LR: 0.0003018629947806563 Training loss: 0.0
2025-12-09 10:24:39.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 6334 LR: 0.00030171732810935887 Training loss: 0.0
2025-12-09 10:24:39.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 6335 LR: 0.0003015716814051213 Training loss: 0.0
2025-12-09 10:24:39.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 6336 LR: 0.00030142605468260977 Training loss: 0.0
2025-12-09 10:24:39.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 6337 LR: 0.00030128044795648925 Training loss: 0.0
2025-12-09 10:24:39.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 6338 LR: 0.000301134861241422 Training loss: 0.0
2025-12-09 10:24:39.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 6339 LR: 0.00030098929455206903 Training loss: 0.0
2025-12-09 10:24:39.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 6340 LR: 0.00030084374790308844 Training loss: 0.0
2025-12-09 10:24:39.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 6341 LR: 0.00030069822130913715 Training loss: 0.0
2025-12-09 10:24:39.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 6342 LR: 0.00030055271478486936 Training loss: 0.0
2025-12-09 10:24:39.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 6343 LR: 0.0003004072283449379 Training loss: 0.0
2025-12-09 10:24:39.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 6344 LR: 0.00030026176200399296 Training loss: 0.0
2025-12-09 10:24:39.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 6345 LR: 0.00030011631577668324 Training loss: 0.0
2025-12-09 10:24:39.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 6346 LR: 0.00029997088967765483 Training loss: 0.0
2025-12-09 10:24:39.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 6347 LR: 0.0002998254837215526 Training loss: 0.0
2025-12-09 10:24:39.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 6348 LR: 0.0002996800979230185 Training loss: 0.0
2025-12-09 10:24:39.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 6349 LR: 0.00029953473229669324 Training loss: 0.0
2025-12-09 10:24:39.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 6350 LR: 0.0002993893868572148 Training loss: 0.0
2025-12-09 10:24:39.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 6351 LR: 0.0002992440616192197 Training loss: 0.0
2025-12-09 10:24:39.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 6352 LR: 0.0002990987565973421 Training loss: 0.0
2025-12-09 10:24:39.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 6353 LR: 0.00029895347180621424 Training loss: 0.0
2025-12-09 10:24:39.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 6354 LR: 0.0002988082072604661 Training loss: 0.0
2025-12-09 10:24:39.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 6355 LR: 0.00029866296297472616 Training loss: 0.0
2025-12-09 10:24:39.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 6356 LR: 0.0002985177389636202 Training loss: 0.0
2025-12-09 10:24:39.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 6357 LR: 0.0002983725352417726 Training loss: 0.0
2025-12-09 10:24:39.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 6358 LR: 0.00029822735182380493 Training loss: 0.0
2025-12-09 10:24:39.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 6359 LR: 0.00029808218872433767 Training loss: 0.0
2025-12-09 10:24:39.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 6360 LR: 0.0002979370459579883 Training loss: 0.0
2025-12-09 10:24:39.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 6361 LR: 0.000297791923539373 Training loss: 0.0
2025-12-09 10:24:39.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 6362 LR: 0.00029764682148310527 Training loss: 0.0
2025-12-09 10:24:39.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 6363 LR: 0.00029750173980379736 Training loss: 0.0
2025-12-09 10:24:39.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 6364 LR: 0.00029735667851605853 Training loss: 0.0
2025-12-09 10:24:39.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 6365 LR: 0.00029721163763449677 Training loss: 0.0
2025-12-09 10:24:39.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 6366 LR: 0.0002970666171737174 Training loss: 0.0
2025-12-09 10:24:39.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 6367 LR: 0.0002969216171483242 Training loss: 0.0
2025-12-09 10:24:39.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 6368 LR: 0.0002967766375729185 Training loss: 0.0
2025-12-09 10:24:39.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 6369 LR: 0.0002966316784621 Training loss: 0.0
2025-12-09 10:24:39.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 6370 LR: 0.00029648673983046576 Training loss: 0.0
2025-12-09 10:24:39.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 6371 LR: 0.00029634182169261135 Training loss: 0.0
2025-12-09 10:24:39.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 6372 LR: 0.0002961969240631298 Training loss: 0.0
2025-12-09 10:24:39.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 6373 LR: 0.0002960520469566126 Training loss: 0.0
2025-12-09 10:24:39.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 6374 LR: 0.00029590719038764856 Training loss: 0.0
2025-12-09 10:24:39.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 6375 LR: 0.000295762354370825 Training loss: 0.0
2025-12-09 10:24:39.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 6376 LR: 0.00029561753892072654 Training loss: 0.0
2025-12-09 10:24:39.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 6377 LR: 0.00029547274405193646 Training loss: 0.0
2025-12-09 10:24:39.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 6378 LR: 0.0002953279697790354 Training loss: 0.0
2025-12-09 10:24:39.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 6379 LR: 0.0002951832161166024 Training loss: 0.0
2025-12-09 10:24:39.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 6380 LR: 0.0002950384830792136 Training loss: 0.0
2025-12-09 10:24:39.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 6381 LR: 0.0002948937706814442 Training loss: 0.0
2025-12-09 10:24:39.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 6382 LR: 0.00029474907893786635 Training loss: 0.0
2025-12-09 10:24:39.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 6383 LR: 0.00029460440786305075 Training loss: 0.0
2025-12-09 10:24:39.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 6384 LR: 0.00029445975747156546 Training loss: 0.0
2025-12-09 10:24:39.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 6385 LR: 0.0002943151277779771 Training loss: 0.0
2025-12-09 10:24:39.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 6386 LR: 0.00029417051879684973 Training loss: 0.0
2025-12-09 10:24:39.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 6387 LR: 0.00029402593054274557 Training loss: 0.0
2025-12-09 10:24:39.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 6388 LR: 0.0002938813630302244 Training loss: 0.0
2025-12-09 10:24:39.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 6389 LR: 0.0002937368162738445 Training loss: 0.0
2025-12-09 10:24:39.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 6390 LR: 0.0002935922902881614 Training loss: 0.0
2025-12-09 10:24:39.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 6391 LR: 0.00029344778508772916 Training loss: 0.0
2025-12-09 10:24:39.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 6392 LR: 0.00029330330068709916 Training loss: 0.0
2025-12-09 10:24:39.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 6393 LR: 0.00029315883710082124 Training loss: 0.0
2025-12-09 10:24:39.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 6394 LR: 0.00029301439434344274 Training loss: 0.0
2025-12-09 10:24:39.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 6395 LR: 0.0002928699724295091 Training loss: 0.0
2025-12-09 10:24:39.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 6396 LR: 0.0002927255713735635 Training loss: 0.0
2025-12-09 10:24:39.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 6397 LR: 0.00029258119119014736 Training loss: 0.0
2025-12-09 10:24:39.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 6398 LR: 0.0002924368318937993 Training loss: 0.0
2025-12-09 10:24:39.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 6399 LR: 0.0002922924934990568 Training loss: 0.0
2025-12-09 10:24:39.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 6400 LR: 0.0002921481760204545 Training loss: 0.0
2025-12-09 10:24:39.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 6401 LR: 0.00029200387947252523 Training loss: 0.0
2025-12-09 10:24:39.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 6402 LR: 0.0002918596038697995 Training loss: 0.0
2025-12-09 10:24:39.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 6403 LR: 0.00029171534922680596 Training loss: 0.0
2025-12-09 10:24:39.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 6404 LR: 0.00029157111555807105 Training loss: 0.0
2025-12-09 10:24:39.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 6405 LR: 0.0002914269028781191 Training loss: 0.0
2025-12-09 10:24:39.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 6406 LR: 0.0002912827112014723 Training loss: 0.0
2025-12-09 10:24:39.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 6407 LR: 0.0002911385405426511 Training loss: 0.0
2025-12-09 10:24:39.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 6408 LR: 0.00029099439091617263 Training loss: 0.0
2025-12-09 10:24:39.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 6409 LR: 0.0002908502623365536 Training loss: 0.0
2025-12-09 10:24:39.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 6410 LR: 0.00029070615481830743 Training loss: 0.0
2025-12-09 10:24:39.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 6411 LR: 0.00029056206837594565 Training loss: 0.0
2025-12-09 10:24:39.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 6412 LR: 0.00029041800302397785 Training loss: 0.0
2025-12-09 10:24:39.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 6413 LR: 0.00029027395877691145 Training loss: 0.0
2025-12-09 10:24:39.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 6414 LR: 0.0002901299356492516 Training loss: 0.0
2025-12-09 10:24:39.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 6415 LR: 0.00028998593365550174 Training loss: 0.0
2025-12-09 10:24:39.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 6416 LR: 0.00028984195281016236 Training loss: 0.0
2025-12-09 10:24:39.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 6417 LR: 0.0002896979931277326 Training loss: 0.0
2025-12-09 10:24:39.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 6418 LR: 0.0002895540546227092 Training loss: 0.0
2025-12-09 10:24:39.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 6419 LR: 0.0002894101373095867 Training loss: 0.0
2025-12-09 10:24:39.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 6420 LR: 0.0002892662412028578 Training loss: 0.0
2025-12-09 10:24:39.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 6421 LR: 0.0002891223663170123 Training loss: 0.0
2025-12-09 10:24:39.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 6422 LR: 0.00028897851266653917 Training loss: 0.0
2025-12-09 10:24:39.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 6423 LR: 0.0002888346802659238 Training loss: 0.0
2025-12-09 10:24:39.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 6424 LR: 0.0002886908691296504 Training loss: 0.0
2025-12-09 10:24:39.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 6425 LR: 0.00028854707927220057 Training loss: 0.0
2025-12-09 10:24:39.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 6426 LR: 0.00028840331070805435 Training loss: 0.0
2025-12-09 10:24:39.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 6427 LR: 0.0002882595634516886 Training loss: 0.0
2025-12-09 10:24:39.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 6428 LR: 0.0002881158375175793 Training loss: 0.0
2025-12-09 10:24:39.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 6429 LR: 0.00028797213292019926 Training loss: 0.0
2025-12-09 10:24:39.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 6430 LR: 0.00028782844967401955 Training loss: 0.0
2025-12-09 10:24:39.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 6431 LR: 0.00028768478779350927 Training loss: 0.0
2025-12-09 10:24:39.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 6432 LR: 0.000287541147293135 Training loss: 0.0
2025-12-09 10:24:39.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 6433 LR: 0.0002873975281873613 Training loss: 0.0
2025-12-09 10:24:39.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 6434 LR: 0.00028725393049065096 Training loss: 0.0
2025-12-09 10:24:39.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 6435 LR: 0.00028711035421746366 Training loss: 0.0
2025-12-09 10:24:39.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 6436 LR: 0.0002869667993822582 Training loss: 0.0
2025-12-09 10:24:39.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 6437 LR: 0.00028682326599949 Training loss: 0.0
2025-12-09 10:24:39.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 6438 LR: 0.0002866797540836131 Training loss: 0.0
2025-12-09 10:24:39.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 6439 LR: 0.0002865362636490791 Training loss: 0.0
2025-12-09 10:24:39.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 6440 LR: 0.0002863927947103376 Training loss: 0.0
2025-12-09 10:24:39.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 6441 LR: 0.0002862493472818357 Training loss: 0.0
2025-12-09 10:24:39.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 6442 LR: 0.00028610592137801895 Training loss: 0.0
2025-12-09 10:24:39.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 6443 LR: 0.00028596251701332973 Training loss: 0.0
2025-12-09 10:24:39.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 6444 LR: 0.0002858191342022095 Training loss: 0.0
2025-12-09 10:24:39.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 6445 LR: 0.0002856757729590964 Training loss: 0.0
2025-12-09 10:24:39.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 6446 LR: 0.00028553243329842716 Training loss: 0.0
2025-12-09 10:24:39.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 6447 LR: 0.00028538911523463595 Training loss: 0.0
2025-12-09 10:24:39.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 6448 LR: 0.0002852458187821549 Training loss: 0.0
2025-12-09 10:24:39.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 6449 LR: 0.0002851025439554142 Training loss: 0.0
2025-12-09 10:24:39.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 6450 LR: 0.0002849592907688415 Training loss: 0.0
2025-12-09 10:24:39.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 6451 LR: 0.00028481605923686207 Training loss: 0.0
2025-12-09 10:24:39.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 6452 LR: 0.0002846728493738998 Training loss: 0.0
2025-12-09 10:24:39.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 6453 LR: 0.0002845296611943756 Training loss: 0.0
2025-12-09 10:24:39.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 6454 LR: 0.0002843864947127087 Training loss: 0.0
2025-12-09 10:24:39.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 6455 LR: 0.0002842433499433158 Training loss: 0.0
2025-12-09 10:24:39.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 6456 LR: 0.00028410022690061166 Training loss: 0.0
2025-12-09 10:24:39.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 6457 LR: 0.0002839571255990088 Training loss: 0.0
2025-12-09 10:24:39.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 6458 LR: 0.0002838140460529177 Training loss: 0.0
2025-12-09 10:24:39.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 6459 LR: 0.00028367098827674573 Training loss: 0.0
2025-12-09 10:24:39.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 6460 LR: 0.0002835279522848998 Training loss: 0.0
2025-12-09 10:24:39.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 6461 LR: 0.000283384938091783 Training loss: 0.0
2025-12-09 10:24:39.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 6462 LR: 0.00028324194571179695 Training loss: 0.0
2025-12-09 10:24:39.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 6463 LR: 0.00028309897515934105 Training loss: 0.0
2025-12-09 10:24:39.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 6464 LR: 0.0002829560264488126 Training loss: 0.0
2025-12-09 10:24:39.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 6465 LR: 0.000282813099594606 Training loss: 0.0
2025-12-09 10:24:39.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 6466 LR: 0.00028267019461111466 Training loss: 0.0
2025-12-09 10:24:39.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 6467 LR: 0.0002825273115127286 Training loss: 0.0
2025-12-09 10:24:39.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 6468 LR: 0.0002823844503138363 Training loss: 0.0
2025-12-09 10:24:39.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 6469 LR: 0.00028224161102882397 Training loss: 0.0
2025-12-09 10:24:39.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 6470 LR: 0.0002820987936720754 Training loss: 0.0
2025-12-09 10:24:39.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 6471 LR: 0.0002819559982579723 Training loss: 0.0
2025-12-09 10:24:39.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 6472 LR: 0.00028181322480089443 Training loss: 0.0
2025-12-09 10:24:39.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 6473 LR: 0.0002816704733152185 Training loss: 0.0
2025-12-09 10:24:39.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 6474 LR: 0.0002815277438153203 Training loss: 0.0
2025-12-09 10:24:39.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 6475 LR: 0.0002813850363155722 Training loss: 0.0
2025-12-09 10:24:39.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 6476 LR: 0.0002812423508303449 Training loss: 0.0
2025-12-09 10:24:39.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 6477 LR: 0.0002810996873740068 Training loss: 0.0
2025-12-09 10:24:39.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 6478 LR: 0.00028095704596092433 Training loss: 0.0
2025-12-09 10:24:39.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 6479 LR: 0.00028081442660546124 Training loss: 0.0
2025-12-09 10:24:39.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 6480 LR: 0.00028067182932197966 Training loss: 0.0
2025-12-09 10:24:39.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 6481 LR: 0.0002805292541248384 Training loss: 0.0
2025-12-09 10:24:39.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 6482 LR: 0.0002803867010283957 Training loss: 0.0
2025-12-09 10:24:39.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 6483 LR: 0.00028024417004700596 Training loss: 0.0
2025-12-09 10:24:39.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 6484 LR: 0.00028010166119502234 Training loss: 0.0
2025-12-09 10:24:39.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 6485 LR: 0.0002799591744867954 Training loss: 0.0
2025-12-09 10:24:39.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 6486 LR: 0.00027981670993667353 Training loss: 0.0
2025-12-09 10:24:39.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 6487 LR: 0.00027967426755900294 Training loss: 0.0
2025-12-09 10:24:39.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 6488 LR: 0.0002795318473681279 Training loss: 0.0
2025-12-09 10:24:39.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 6489 LR: 0.0002793894493783892 Training loss: 0.0
2025-12-09 10:24:39.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 6490 LR: 0.00027924707360412745 Training loss: 0.0
2025-12-09 10:24:39.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 6491 LR: 0.0002791047200596791 Training loss: 0.0
2025-12-09 10:24:39.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 6492 LR: 0.0002789623887593794 Training loss: 0.0
2025-12-09 10:24:39.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 6493 LR: 0.0002788200797175611 Training loss: 0.0
2025-12-09 10:24:39.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 6494 LR: 0.000278677792948555 Training loss: 0.0
2025-12-09 10:24:39.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 6495 LR: 0.0002785355284666886 Training loss: 0.0
2025-12-09 10:24:39.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 6496 LR: 0.0002783932862862888 Training loss: 0.0
2025-12-09 10:24:39.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 6497 LR: 0.0002782510664216789 Training loss: 0.0
2025-12-09 10:24:39.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 6498 LR: 0.0002781088688871805 Training loss: 0.0
2025-12-09 10:24:39.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 6499 LR: 0.0002779666936971129 Training loss: 0.0
2025-12-09 10:24:39.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 6500 LR: 0.0002778245408657932 Training loss: 0.0
2025-12-09 10:24:39.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 6501 LR: 0.00027768241040753637 Training loss: 0.0
2025-12-09 10:24:39.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 6502 LR: 0.0002775403023366546 Training loss: 0.0
2025-12-09 10:24:39.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 6503 LR: 0.00027739821666745816 Training loss: 0.0
2025-12-09 10:24:39.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 6504 LR: 0.00027725615341425523 Training loss: 0.0
2025-12-09 10:24:39.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 6505 LR: 0.0002771141125913517 Training loss: 0.0
2025-12-09 10:24:39.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 6506 LR: 0.00027697209421305083 Training loss: 0.0
2025-12-09 10:24:39.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 6507 LR: 0.00027683009829365413 Training loss: 0.0
2025-12-09 10:24:39.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 6508 LR: 0.00027668812484746004 Training loss: 0.0
2025-12-09 10:24:39.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 6509 LR: 0.00027654617388876614 Training loss: 0.0
2025-12-09 10:24:39.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 6510 LR: 0.00027640424543186613 Training loss: 0.0
2025-12-09 10:24:39.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 6511 LR: 0.0002762623394910525 Training loss: 0.0
2025-12-09 10:24:39.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 6512 LR: 0.0002761204560806152 Training loss: 0.0
2025-12-09 10:24:39.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 6513 LR: 0.0002759785952148418 Training loss: 0.0
2025-12-09 10:24:39.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 6514 LR: 0.00027583675690801777 Training loss: 0.0
2025-12-09 10:24:39.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 6515 LR: 0.0002756949411744264 Training loss: 0.0
2025-12-09 10:24:39.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 6516 LR: 0.0002755531480283479 Training loss: 0.0
2025-12-09 10:24:39.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 6517 LR: 0.0002754113774840616 Training loss: 0.0
2025-12-09 10:24:39.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 6518 LR: 0.00027526962955584335 Training loss: 0.0
2025-12-09 10:24:39.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 6519 LR: 0.0002751279042579672 Training loss: 0.0
2025-12-09 10:24:39.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 6520 LR: 0.0002749862016047049 Training loss: 0.0
2025-12-09 10:24:39.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 6521 LR: 0.00027484452161032617 Training loss: 0.0
2025-12-09 10:24:39.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 6522 LR: 0.0002747028642890976 Training loss: 0.0
2025-12-09 10:24:39.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 6523 LR: 0.00027456122965528474 Training loss: 0.0
2025-12-09 10:24:39.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 6524 LR: 0.0002744196177231498 Training loss: 0.0
2025-12-09 10:24:39.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 6525 LR: 0.00027427802850695307 Training loss: 0.0
2025-12-09 10:24:39.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 6526 LR: 0.00027413646202095277 Training loss: 0.0
2025-12-09 10:24:39.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 6527 LR: 0.0002739949182794045 Training loss: 0.0
2025-12-09 10:24:39.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 6528 LR: 0.0002738533972965618 Training loss: 0.0
2025-12-09 10:24:39.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 6529 LR: 0.00027371189908667604 Training loss: 0.0
2025-12-09 10:24:39.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 6530 LR: 0.00027357042366399543 Training loss: 0.0
2025-12-09 10:24:39.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 6531 LR: 0.00027342897104276734 Training loss: 0.0
2025-12-09 10:24:39.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 6532 LR: 0.0002732875412372355 Training loss: 0.0
2025-12-09 10:24:39.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 6533 LR: 0.00027314613426164205 Training loss: 0.0
2025-12-09 10:24:39.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 6534 LR: 0.00027300475013022663 Training loss: 0.0
2025-12-09 10:24:39.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 6535 LR: 0.0002728633888572267 Training loss: 0.0
2025-12-09 10:24:39.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 6536 LR: 0.00027272205045687726 Training loss: 0.0
2025-12-09 10:24:39.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 6537 LR: 0.0002725807349434114 Training loss: 0.0
2025-12-09 10:24:39.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 6538 LR: 0.0002724394423310589 Training loss: 0.0
2025-12-09 10:24:39.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 6539 LR: 0.00027229817263404863 Training loss: 0.0
2025-12-09 10:24:39.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 6540 LR: 0.000272156925866606 Training loss: 0.0
2025-12-09 10:24:39.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 6541 LR: 0.00027201570204295466 Training loss: 0.0
2025-12-09 10:24:39.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 6542 LR: 0.000271874501177316 Training loss: 0.0
2025-12-09 10:24:39.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 6543 LR: 0.0002717333232839088 Training loss: 0.0
2025-12-09 10:24:39.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 6544 LR: 0.0002715921683769496 Training loss: 0.0
2025-12-09 10:24:39.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 6545 LR: 0.0002714510364706531 Training loss: 0.0
2025-12-09 10:24:39.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 6546 LR: 0.00027130992757923045 Training loss: 0.0
2025-12-09 10:24:39.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 6547 LR: 0.0002711688417168924 Training loss: 0.0
2025-12-09 10:24:39.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 6548 LR: 0.00027102777889784533 Training loss: 0.0
2025-12-09 10:24:39.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 6549 LR: 0.0002708867391362948 Training loss: 0.0
2025-12-09 10:24:39.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 6550 LR: 0.00027074572244644335 Training loss: 0.0
2025-12-09 10:24:39.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 6551 LR: 0.00027060472884249143 Training loss: 0.0
2025-12-09 10:24:39.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 6552 LR: 0.0002704637583386369 Training loss: 0.0
2025-12-09 10:24:39.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 6553 LR: 0.00027032281094907594 Training loss: 0.0
2025-12-09 10:24:39.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 6554 LR: 0.0002701818866880012 Training loss: 0.0
2025-12-09 10:24:39.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 6555 LR: 0.00027004098556960453 Training loss: 0.0
2025-12-09 10:24:39.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 6556 LR: 0.0002699001076080742 Training loss: 0.0
2025-12-09 10:24:39.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 6557 LR: 0.0002697592528175967 Training loss: 0.0
2025-12-09 10:24:39.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 6558 LR: 0.0002696184212123561 Training loss: 0.0
2025-12-09 10:24:39.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 6559 LR: 0.0002694776128065345 Training loss: 0.0
2025-12-09 10:24:39.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 6560 LR: 0.0002693368276143105 Training loss: 0.0
2025-12-09 10:24:39.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 6561 LR: 0.0002691960656498621 Training loss: 0.0
2025-12-09 10:24:39.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 6562 LR: 0.0002690553269273633 Training loss: 0.0
2025-12-09 10:24:39.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 6563 LR: 0.0002689146114609868 Training loss: 0.0
2025-12-09 10:24:39.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 6564 LR: 0.00026877391926490257 Training loss: 0.0
2025-12-09 10:24:39.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 6565 LR: 0.00026863325035327837 Training loss: 0.0
2025-12-09 10:24:39.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 6566 LR: 0.00026849260474027956 Training loss: 0.0
2025-12-09 10:24:39.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 6567 LR: 0.00026835198244006924 Training loss: 0.0
2025-12-09 10:24:39.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 6568 LR: 0.00026821138346680765 Training loss: 0.0
2025-12-09 10:24:39.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 6569 LR: 0.00026807080783465374 Training loss: 0.0
2025-12-09 10:24:39.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 6570 LR: 0.000267930255557763 Training loss: 0.0
2025-12-09 10:24:39.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 6571 LR: 0.00026778972665028903 Training loss: 0.0
2025-12-09 10:24:39.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 6572 LR: 0.00026764922112638333 Training loss: 0.0
2025-12-09 10:24:39.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 6573 LR: 0.00026750873900019466 Training loss: 0.0
2025-12-09 10:24:39.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 6574 LR: 0.0002673682802858697 Training loss: 0.0
2025-12-09 10:24:39.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 6575 LR: 0.0002672278449975527 Training loss: 0.0
2025-12-09 10:24:39.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 6576 LR: 0.00026708743314938496 Training loss: 0.0
2025-12-09 10:24:39.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 6577 LR: 0.00026694704475550666 Training loss: 0.0
2025-12-09 10:24:39.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 6578 LR: 0.00026680667983005447 Training loss: 0.0
2025-12-09 10:24:39.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 6579 LR: 0.00026666633838716316 Training loss: 0.0
2025-12-09 10:24:39.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 6580 LR: 0.00026652602044096517 Training loss: 0.0
2025-12-09 10:24:39.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 6581 LR: 0.0002663857260055906 Training loss: 0.0
2025-12-09 10:24:39.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 6582 LR: 0.0002662454550951671 Training loss: 0.0
2025-12-09 10:24:39.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 6583 LR: 0.00026610520772381996 Training loss: 0.0
2025-12-09 10:24:39.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 6584 LR: 0.0002659649839056716 Training loss: 0.0
2025-12-09 10:24:39.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 6585 LR: 0.0002658247836548434 Training loss: 0.0
2025-12-09 10:24:39.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 6586 LR: 0.00026568460698545303 Training loss: 0.0
2025-12-09 10:24:39.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 6587 LR: 0.000265544453911616 Training loss: 0.0
2025-12-09 10:24:39.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 6588 LR: 0.00026540432444744646 Training loss: 0.0
2025-12-09 10:24:39.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 6589 LR: 0.00026526421860705474 Training loss: 0.0
2025-12-09 10:24:39.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 6590 LR: 0.0002651241364045498 Training loss: 0.0
2025-12-09 10:24:39.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 6591 LR: 0.00026498407785403795 Training loss: 0.0
2025-12-09 10:24:39.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 6592 LR: 0.000264844042969623 Training loss: 0.0
2025-12-09 10:24:39.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 6593 LR: 0.0002647040317654065 Training loss: 0.0
2025-12-09 10:24:39.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 6594 LR: 0.00026456404425548774 Training loss: 0.0
2025-12-09 10:24:39.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 6595 LR: 0.0002644240804539629 Training loss: 0.0
2025-12-09 10:24:39.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 6596 LR: 0.0002642841403749271 Training loss: 0.0
2025-12-09 10:24:39.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 6597 LR: 0.00026414422403247173 Training loss: 0.0
2025-12-09 10:24:39.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 6598 LR: 0.0002640043314406865 Training loss: 0.0
2025-12-09 10:24:39.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 6599 LR: 0.0002638644626136587 Training loss: 0.0
2025-12-09 10:24:39.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 6600 LR: 0.00026372461756547306 Training loss: 0.0
2025-12-09 10:24:39.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 6601 LR: 0.0002635847963102119 Training loss: 0.0
2025-12-09 10:24:39.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 6602 LR: 0.0002634449988619555 Training loss: 0.0
2025-12-09 10:24:39.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 6603 LR: 0.00026330522523478083 Training loss: 0.0
2025-12-09 10:24:39.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 6604 LR: 0.000263165475442764 Training loss: 0.0
2025-12-09 10:24:39.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 6605 LR: 0.00026302574949997707 Training loss: 0.0
2025-12-09 10:24:39.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 6606 LR: 0.0002628860474204906 Training loss: 0.0
2025-12-09 10:24:39.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 6607 LR: 0.0002627463692183727 Training loss: 0.0
2025-12-09 10:24:39.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 6608 LR: 0.00026260671490768896 Training loss: 0.0
2025-12-09 10:24:39.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 6609 LR: 0.00026246708450250255 Training loss: 0.0
2025-12-09 10:24:39.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 6610 LR: 0.0002623274780168744 Training loss: 0.0
2025-12-09 10:24:39.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 6611 LR: 0.00026218789546486235 Training loss: 0.0
2025-12-09 10:24:39.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 6612 LR: 0.00026204833686052306 Training loss: 0.0
2025-12-09 10:24:39.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 6613 LR: 0.0002619088022179096 Training loss: 0.0
2025-12-09 10:24:39.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 6614 LR: 0.0002617692915510731 Training loss: 0.0
2025-12-09 10:24:39.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 6615 LR: 0.00026162980487406257 Training loss: 0.0
2025-12-09 10:24:39.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 6616 LR: 0.0002614903422009243 Training loss: 0.0
2025-12-09 10:24:39.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 6617 LR: 0.0002613509035457017 Training loss: 0.0
2025-12-09 10:24:39.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 6618 LR: 0.00026121148892243695 Training loss: 0.0
2025-12-09 10:24:39.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 6619 LR: 0.00026107209834516854 Training loss: 0.0
2025-12-09 10:24:39.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 6620 LR: 0.00026093273182793334 Training loss: 0.0
2025-12-09 10:24:39.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 6621 LR: 0.00026079338938476537 Training loss: 0.0
2025-12-09 10:24:39.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 6622 LR: 0.00026065407102969664 Training loss: 0.0
2025-12-09 10:24:39.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 6623 LR: 0.0002605147767767564 Training loss: 0.0
2025-12-09 10:24:39.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 6624 LR: 0.00026037550663997176 Training loss: 0.0
2025-12-09 10:24:39.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 6625 LR: 0.0002602362606333667 Training loss: 0.0
2025-12-09 10:24:39.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 6626 LR: 0.0002600970387709639 Training loss: 0.0
2025-12-09 10:24:39.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 6627 LR: 0.0002599578410667827 Training loss: 0.0
2025-12-09 10:24:39.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 6628 LR: 0.0002598186675348402 Training loss: 0.0
2025-12-09 10:24:39.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 6629 LR: 0.0002596795181891514 Training loss: 0.0
2025-12-09 10:24:39.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 6630 LR: 0.00025954039304372853 Training loss: 0.0
2025-12-09 10:24:39.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 6631 LR: 0.00025940129211258144 Training loss: 0.0
2025-12-09 10:24:39.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 6632 LR: 0.0002592622154097179 Training loss: 0.0
2025-12-09 10:24:39.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 6633 LR: 0.0002591231629491423 Training loss: 0.0
2025-12-09 10:24:39.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 6634 LR: 0.00025898413474485793 Training loss: 0.0
2025-12-09 10:24:39.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 6635 LR: 0.0002588451308108645 Training loss: 0.0
2025-12-09 10:24:39.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 6636 LR: 0.0002587061511611597 Training loss: 0.0
2025-12-09 10:24:39.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 6637 LR: 0.00025856719580973894 Training loss: 0.0
2025-12-09 10:24:39.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 6638 LR: 0.0002584282647705949 Training loss: 0.0
2025-12-09 10:24:39.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 6639 LR: 0.000258289358057718 Training loss: 0.0
2025-12-09 10:24:39.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 6640 LR: 0.0002581504756850964 Training loss: 0.0
2025-12-09 10:24:39.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 6641 LR: 0.0002580116176667148 Training loss: 0.0
2025-12-09 10:24:39.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 6642 LR: 0.0002578727840165571 Training loss: 0.0
2025-12-09 10:24:39.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 6643 LR: 0.0002577339747486033 Training loss: 0.0
2025-12-09 10:24:39.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 6644 LR: 0.0002575951898768315 Training loss: 0.0
2025-12-09 10:24:39.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 6645 LR: 0.0002574564294152175 Training loss: 0.0
2025-12-09 10:24:39.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 6646 LR: 0.0002573176933777344 Training loss: 0.0
2025-12-09 10:24:39.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 6647 LR: 0.00025717898177835295 Training loss: 0.0
2025-12-09 10:24:39.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 6648 LR: 0.0002570402946310416 Training loss: 0.0
2025-12-09 10:24:39.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 6649 LR: 0.0002569016319497657 Training loss: 0.0
2025-12-09 10:24:39.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 6650 LR: 0.0002567629937484889 Training loss: 0.0
2025-12-09 10:24:39.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 6651 LR: 0.0002566243800411719 Training loss: 0.0
2025-12-09 10:24:39.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 6652 LR: 0.0002564857908417731 Training loss: 0.0
2025-12-09 10:24:39.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 6653 LR: 0.00025634722616424866 Training loss: 0.0
2025-12-09 10:24:39.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 6654 LR: 0.000256208686022552 Training loss: 0.0
2025-12-09 10:24:39.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 6655 LR: 0.0002560701704306336 Training loss: 0.0
2025-12-09 10:24:39.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 6656 LR: 0.0002559316794024427 Training loss: 0.0
2025-12-09 10:24:39.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 6657 LR: 0.0002557932129519249 Training loss: 0.0
2025-12-09 10:24:39.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 6658 LR: 0.0002556547710930238 Training loss: 0.0
2025-12-09 10:24:39.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 6659 LR: 0.00025551635383968066 Training loss: 0.0
2025-12-09 10:24:39.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 6660 LR: 0.0002553779612058339 Training loss: 0.0
2025-12-09 10:24:39.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 6661 LR: 0.0002552395932054198 Training loss: 0.0
2025-12-09 10:24:39.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 6662 LR: 0.00025510124985237217 Training loss: 0.0
2025-12-09 10:24:39.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 6663 LR: 0.0002549629311606215 Training loss: 0.0
2025-12-09 10:24:39.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 6664 LR: 0.0002548246371440974 Training loss: 0.0
2025-12-09 10:24:39.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 6665 LR: 0.0002546863678167255 Training loss: 0.0
2025-12-09 10:24:39.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 6666 LR: 0.00025454812319242957 Training loss: 0.0
2025-12-09 10:24:39.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 6667 LR: 0.000254409903285131 Training loss: 0.0
2025-12-09 10:24:39.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 6668 LR: 0.0002542717081087484 Training loss: 0.0
2025-12-09 10:24:39.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 6669 LR: 0.00025413353767719804 Training loss: 0.0
2025-12-09 10:24:39.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 6670 LR: 0.0002539953920043939 Training loss: 0.0
2025-12-09 10:24:39.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 6671 LR: 0.0002538572711042469 Training loss: 0.0
2025-12-09 10:24:39.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 6672 LR: 0.000253719174990666 Training loss: 0.0
2025-12-09 10:24:39.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 6673 LR: 0.0002535811036775574 Training loss: 0.0
2025-12-09 10:24:39.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 6674 LR: 0.0002534430571788249 Training loss: 0.0
2025-12-09 10:24:39.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 6675 LR: 0.00025330503550837 Training loss: 0.0
2025-12-09 10:24:39.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 6676 LR: 0.00025316703868009087 Training loss: 0.0
2025-12-09 10:24:39.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 6677 LR: 0.0002530290667078846 Training loss: 0.0
2025-12-09 10:24:39.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 6678 LR: 0.0002528911196056444 Training loss: 0.0
2025-12-09 10:24:39.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 6679 LR: 0.0002527531973872617 Training loss: 0.0
2025-12-09 10:24:39.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 6680 LR: 0.0002526153000666251 Training loss: 0.0
2025-12-09 10:24:39.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 6681 LR: 0.00025247742765762137 Training loss: 0.0
2025-12-09 10:24:39.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 6682 LR: 0.0002523395801741335 Training loss: 0.0
2025-12-09 10:24:39.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 6683 LR: 0.0002522017576300434 Training loss: 0.0
2025-12-09 10:24:39.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 6684 LR: 0.0002520639600392295 Training loss: 0.0
2025-12-09 10:24:39.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 6685 LR: 0.00025192618741556796 Training loss: 0.0
2025-12-09 10:24:39.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 6686 LR: 0.00025178843977293256 Training loss: 0.0
2025-12-09 10:24:39.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 6687 LR: 0.0002516507171251944 Training loss: 0.0
2025-12-09 10:24:39.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 6688 LR: 0.00025151301948622234 Training loss: 0.0
2025-12-09 10:24:39.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 6689 LR: 0.0002513753468698826 Training loss: 0.0
2025-12-09 10:24:39.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 6690 LR: 0.0002512376992900382 Training loss: 0.0
2025-12-09 10:24:39.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 6691 LR: 0.00025110007676055107 Training loss: 0.0
2025-12-09 10:24:39.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 6692 LR: 0.0002509624792952793 Training loss: 0.0
2025-12-09 10:24:39.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 6693 LR: 0.00025082490690807893 Training loss: 0.0
2025-12-09 10:24:39.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 6694 LR: 0.00025068735961280365 Training loss: 0.0
2025-12-09 10:24:39.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 6695 LR: 0.0002505498374233044 Training loss: 0.0
2025-12-09 10:24:39.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 6696 LR: 0.0002504123403534297 Training loss: 0.0
2025-12-09 10:24:39.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 6697 LR: 0.00025027486841702577 Training loss: 0.0
2025-12-09 10:24:39.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 6698 LR: 0.00025013742162793536 Training loss: 0.0
2025-12-09 10:24:39.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 6699 LR: 0.0002500000000000001 Training loss: 0.0
2025-12-09 10:24:39.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 6700 LR: 0.0002498626035470578 Training loss: 0.0
2025-12-09 10:24:39.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 6701 LR: 0.0002497252322829445 Training loss: 0.0
2025-12-09 10:24:39.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 6702 LR: 0.0002495878862214935 Training loss: 0.0
2025-12-09 10:24:39.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 6703 LR: 0.00024945056537653543 Training loss: 0.0
2025-12-09 10:24:39.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 6704 LR: 0.0002493132697618986 Training loss: 0.0
2025-12-09 10:24:39.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 6705 LR: 0.00024917599939140885 Training loss: 0.0
2025-12-09 10:24:39.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 6706 LR: 0.00024903875427888873 Training loss: 0.0
2025-12-09 10:24:39.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 6707 LR: 0.0002489015344381596 Training loss: 0.0
2025-12-09 10:24:39.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 6708 LR: 0.00024876433988303877 Training loss: 0.0
2025-12-09 10:24:39.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 6709 LR: 0.0002486271706273421 Training loss: 0.0
2025-12-09 10:24:39.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 6710 LR: 0.00024849002668488247 Training loss: 0.0
2025-12-09 10:24:39.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 6711 LR: 0.0002483529080694705 Training loss: 0.0
2025-12-09 10:24:39.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 6712 LR: 0.0002482158147949134 Training loss: 0.0
2025-12-09 10:24:39.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 6713 LR: 0.0002480787468750172 Training loss: 0.0
2025-12-09 10:24:39.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 6714 LR: 0.00024794170432358416 Training loss: 0.0
2025-12-09 10:24:39.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 6715 LR: 0.00024780468715441455 Training loss: 0.0
2025-12-09 10:24:39.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 6716 LR: 0.00024766769538130606 Training loss: 0.0
2025-12-09 10:24:39.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 6717 LR: 0.0002475307290180538 Training loss: 0.0
2025-12-09 10:24:39.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 6718 LR: 0.00024739378807845015 Training loss: 0.0
2025-12-09 10:24:39.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 6719 LR: 0.0002472568725762853 Training loss: 0.0
2025-12-09 10:24:39.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 6720 LR: 0.00024711998252534615 Training loss: 0.0
2025-12-09 10:24:39.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 6721 LR: 0.0002469831179394182 Training loss: 0.0
2025-12-09 10:24:39.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 6722 LR: 0.00024684627883228316 Training loss: 0.0
2025-12-09 10:24:39.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 6723 LR: 0.0002467094652177209 Training loss: 0.0
2025-12-09 10:24:39.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 6724 LR: 0.00024657267710950857 Training loss: 0.0
2025-12-09 10:24:39.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 6725 LR: 0.0002464359145214207 Training loss: 0.0
2025-12-09 10:24:39.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 6726 LR: 0.00024629917746722934 Training loss: 0.0
2025-12-09 10:24:39.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 6727 LR: 0.000246162465960704 Training loss: 0.0
2025-12-09 10:24:39.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 6728 LR: 0.0002460257800156111 Training loss: 0.0
2025-12-09 10:24:39.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 6729 LR: 0.00024588911964571554 Training loss: 0.0
2025-12-09 10:24:39.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 6730 LR: 0.0002457524848647785 Training loss: 0.0
2025-12-09 10:24:39.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 6731 LR: 0.00024561587568655926 Training loss: 0.0
2025-12-09 10:24:39.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 6732 LR: 0.00024547929212481435 Training loss: 0.0
2025-12-09 10:24:39.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 6733 LR: 0.0002453427341932978 Training loss: 0.0
2025-12-09 10:24:39.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 6734 LR: 0.0002452062019057609 Training loss: 0.0
2025-12-09 10:24:39.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 6735 LR: 0.00024506969527595275 Training loss: 0.0
2025-12-09 10:24:39.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 6736 LR: 0.0002449332143176189 Training loss: 0.0
2025-12-09 10:24:39.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 6737 LR: 0.00024479675904450377 Training loss: 0.0
2025-12-09 10:24:39.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 6738 LR: 0.0002446603294703478 Training loss: 0.0
2025-12-09 10:24:39.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 6739 LR: 0.00024452392560888974 Training loss: 0.0
2025-12-09 10:24:39.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 6740 LR: 0.00024438754747386533 Training loss: 0.0
2025-12-09 10:24:39.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 6741 LR: 0.00024425119507900814 Training loss: 0.0
2025-12-09 10:24:39.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 6742 LR: 0.00024411486843804815 Training loss: 0.0
2025-12-09 10:24:39.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 6743 LR: 0.0002439785675647143 Training loss: 0.0
2025-12-09 10:24:39.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 6744 LR: 0.00024384229247273155 Training loss: 0.0
2025-12-09 10:24:39.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 6745 LR: 0.0002437060431758229 Training loss: 0.0
2025-12-09 10:24:39.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 6746 LR: 0.0002435698196877087 Training loss: 0.0
2025-12-09 10:24:39.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 6747 LR: 0.00024343362202210666 Training loss: 0.0
2025-12-09 10:24:39.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 6748 LR: 0.00024329745019273187 Training loss: 0.0
2025-12-09 10:24:39.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 6749 LR: 0.00024316130421329695 Training loss: 0.0
2025-12-09 10:24:39.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 6750 LR: 0.00024302518409751134 Training loss: 0.0
2025-12-09 10:24:39.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 6751 LR: 0.00024288908985908302 Training loss: 0.0
2025-12-09 10:24:39.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 6752 LR: 0.00024275302151171614 Training loss: 0.0
2025-12-09 10:24:39.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 6753 LR: 0.0002426169790691129 Training loss: 0.0
2025-12-09 10:24:39.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 6754 LR: 0.00024248096254497287 Training loss: 0.0
2025-12-09 10:24:39.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 6755 LR: 0.00024234497195299288 Training loss: 0.0
2025-12-09 10:24:39.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 6756 LR: 0.00024220900730686734 Training loss: 0.0
2025-12-09 10:24:39.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 6757 LR: 0.00024207306862028755 Training loss: 0.0
2025-12-09 10:24:39.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 6758 LR: 0.00024193715590694264 Training loss: 0.0
2025-12-09 10:24:39.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 6759 LR: 0.00024180126918051909 Training loss: 0.0
2025-12-09 10:24:39.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 6760 LR: 0.0002416654084547007 Training loss: 0.0
2025-12-09 10:24:39.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 6761 LR: 0.00024152957374316857 Training loss: 0.0
2025-12-09 10:24:39.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 6762 LR: 0.00024139376505960148 Training loss: 0.0
2025-12-09 10:24:39.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 6763 LR: 0.00024125798241767484 Training loss: 0.0
2025-12-09 10:24:39.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 6764 LR: 0.0002411222258310626 Training loss: 0.0
2025-12-09 10:24:39.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 6765 LR: 0.00024098649531343496 Training loss: 0.0
2025-12-09 10:24:39.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 6766 LR: 0.0002408507908784602 Training loss: 0.0
2025-12-09 10:24:39.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 6767 LR: 0.00024071511253980366 Training loss: 0.0
2025-12-09 10:24:39.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 6768 LR: 0.00024057946031112826 Training loss: 0.0
2025-12-09 10:24:39.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 6769 LR: 0.00024044383420609406 Training loss: 0.0
2025-12-09 10:24:39.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 6770 LR: 0.00024030823423835886 Training loss: 0.0
2025-12-09 10:24:39.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 6771 LR: 0.000240172660421577 Training loss: 0.0
2025-12-09 10:24:39.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 6772 LR: 0.00024003711276940142 Training loss: 0.0
2025-12-09 10:24:39.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 6773 LR: 0.00023990159129548135 Training loss: 0.0
2025-12-09 10:24:39.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 6774 LR: 0.00023976609601346395 Training loss: 0.0
2025-12-09 10:24:39.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 6775 LR: 0.0002396306269369935 Training loss: 0.0
2025-12-09 10:24:39.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 6776 LR: 0.000239495184079712 Training loss: 0.0
2025-12-09 10:24:39.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 6777 LR: 0.00023935976745525795 Training loss: 0.0
2025-12-09 10:24:39.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 6778 LR: 0.00023922437707726856 Training loss: 0.0
2025-12-09 10:24:39.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 6779 LR: 0.00023908901295937712 Training loss: 0.0
2025-12-09 10:24:39.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 6780 LR: 0.00023895367511521493 Training loss: 0.0
2025-12-09 10:24:39.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 6781 LR: 0.00023881836355841047 Training loss: 0.0
2025-12-09 10:24:39.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 6782 LR: 0.00023868307830258968 Training loss: 0.0
2025-12-09 10:24:39.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 6783 LR: 0.00023854781936137576 Training loss: 0.0
2025-12-09 10:24:39.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 6784 LR: 0.00023841258674838945 Training loss: 0.0
2025-12-09 10:24:39.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 6785 LR: 0.0002382773804772481 Training loss: 0.0
2025-12-09 10:24:39.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 6786 LR: 0.00023814220056156776 Training loss: 0.0
2025-12-09 10:24:39.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 6787 LR: 0.00023800704701496051 Training loss: 0.0
2025-12-09 10:24:39.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 6788 LR: 0.00023787191985103645 Training loss: 0.0
2025-12-09 10:24:39.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 6789 LR: 0.00023773681908340283 Training loss: 0.0
2025-12-09 10:24:39.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 6790 LR: 0.00023760174472566443 Training loss: 0.0
2025-12-09 10:24:39.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 6791 LR: 0.00023746669679142312 Training loss: 0.0
2025-12-09 10:24:39.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 6792 LR: 0.00023733167529427847 Training loss: 0.0
2025-12-09 10:24:39.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 6793 LR: 0.00023719668024782648 Training loss: 0.0
2025-12-09 10:24:39.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 6794 LR: 0.00023706171166566203 Training loss: 0.0
2025-12-09 10:24:39.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 6795 LR: 0.00023692676956137582 Training loss: 0.0
2025-12-09 10:24:39.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 6796 LR: 0.00023679185394855673 Training loss: 0.0
2025-12-09 10:24:39.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 6797 LR: 0.00023665696484079075 Training loss: 0.0
2025-12-09 10:24:39.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 6798 LR: 0.0002365221022516612 Training loss: 0.0
2025-12-09 10:24:39.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 6799 LR: 0.00023638726619474876 Training loss: 0.0
2025-12-09 10:24:39.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 6800 LR: 0.00023625245668363153 Training loss: 0.0
2025-12-09 10:24:39.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 6801 LR: 0.00023611767373188443 Training loss: 0.0
2025-12-09 10:24:39.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 6802 LR: 0.00023598291735308063 Training loss: 0.0
2025-12-09 10:24:39.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 6803 LR: 0.0002358481875607897 Training loss: 0.0
2025-12-09 10:24:39.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 6804 LR: 0.00023571348436857904 Training loss: 0.0
2025-12-09 10:24:39.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 6805 LR: 0.00023557880779001322 Training loss: 0.0
2025-12-09 10:24:39.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 6806 LR: 0.00023544415783865446 Training loss: 0.0
2025-12-09 10:24:39.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 6807 LR: 0.00023530953452806141 Training loss: 0.0
2025-12-09 10:24:39.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 6808 LR: 0.00023517493787179135 Training loss: 0.0
2025-12-09 10:24:39.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 6809 LR: 0.0002350403678833976 Training loss: 0.0
2025-12-09 10:24:39.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 6810 LR: 0.00023490582457643156 Training loss: 0.0
2025-12-09 10:24:39.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 6811 LR: 0.00023477130796444173 Training loss: 0.0
2025-12-09 10:24:39.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 6812 LR: 0.00023463681806097392 Training loss: 0.0
2025-12-09 10:24:39.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 6813 LR: 0.00023450235487957133 Training loss: 0.0
2025-12-09 10:24:39.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 6814 LR: 0.00023436791843377448 Training loss: 0.0
2025-12-09 10:24:39.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 6815 LR: 0.00023423350873712058 Training loss: 0.0
2025-12-09 10:24:39.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 6816 LR: 0.00023409912580314547 Training loss: 0.0
2025-12-09 10:24:39.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 6817 LR: 0.00023396476964538093 Training loss: 0.0
2025-12-09 10:24:39.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 6818 LR: 0.00023383044027735684 Training loss: 0.0
2025-12-09 10:24:39.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 6819 LR: 0.00023369613771260007 Training loss: 0.0
2025-12-09 10:24:39.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 6820 LR: 0.00023356186196463497 Training loss: 0.0
2025-12-09 10:24:39.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 6821 LR: 0.00023342761304698313 Training loss: 0.0
2025-12-09 10:24:39.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 6822 LR: 0.0002332933909731635 Training loss: 0.0
2025-12-09 10:24:39.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 6823 LR: 0.0002331591957566917 Training loss: 0.0
2025-12-09 10:24:39.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 6824 LR: 0.000233025027411082 Training loss: 0.0
2025-12-09 10:24:39.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 6825 LR: 0.00023289088594984452 Training loss: 0.0
2025-12-09 10:24:39.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 6826 LR: 0.0002327567713864876 Training loss: 0.0
2025-12-09 10:24:39.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 6827 LR: 0.0002326226837345164 Training loss: 0.0
2025-12-09 10:24:39.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 6828 LR: 0.0002324886230074337 Training loss: 0.0
2025-12-09 10:24:39.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 6829 LR: 0.00023235458921873925 Training loss: 0.0
2025-12-09 10:24:39.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 6830 LR: 0.0002322205823819306 Training loss: 0.0
2025-12-09 10:24:39.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 6831 LR: 0.00023208660251050156 Training loss: 0.0
2025-12-09 10:24:39.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 6832 LR: 0.0002319526496179447 Training loss: 0.0
2025-12-09 10:24:39.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 6833 LR: 0.00023181872371774853 Training loss: 0.0
2025-12-09 10:24:39.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 6834 LR: 0.00023168482482339954 Training loss: 0.0
2025-12-09 10:24:39.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 6835 LR: 0.00023155095294838136 Training loss: 0.0
2025-12-09 10:24:39.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 6836 LR: 0.00023141710810617506 Training loss: 0.0
2025-12-09 10:24:39.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 6837 LR: 0.0002312832903102582 Training loss: 0.0
2025-12-09 10:24:39.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 6838 LR: 0.0002311494995741071 Training loss: 0.0
2025-12-09 10:24:39.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 6839 LR: 0.0002310157359111938 Training loss: 0.0
2025-12-09 10:24:39.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 6840 LR: 0.00023088199933498854 Training loss: 0.0
2025-12-09 10:24:39.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 6841 LR: 0.00023074828985895858 Training loss: 0.0
2025-12-09 10:24:39.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 6842 LR: 0.00023061460749656843 Training loss: 0.0
2025-12-09 10:24:39.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 6843 LR: 0.0002304809522612802 Training loss: 0.0
2025-12-09 10:24:39.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 6844 LR: 0.00023034732416655246 Training loss: 0.0
2025-12-09 10:24:39.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 6845 LR: 0.00023021372322584184 Training loss: 0.0
2025-12-09 10:24:39.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 6846 LR: 0.00023008014945260187 Training loss: 0.0
2025-12-09 10:24:39.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 6847 LR: 0.00022994660286028347 Training loss: 0.0
2025-12-09 10:24:39.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 6848 LR: 0.00022981308346233477 Training loss: 0.0
2025-12-09 10:24:39.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 6849 LR: 0.0002296795912722014 Training loss: 0.0
2025-12-09 10:24:39.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 6850 LR: 0.0002295461263033254 Training loss: 0.0
2025-12-09 10:24:39.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 6851 LR: 0.00022941268856914744 Training loss: 0.0
2025-12-09 10:24:39.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 6852 LR: 0.0002292792780831041 Training loss: 0.0
2025-12-09 10:24:39.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 6853 LR: 0.00022914589485863014 Training loss: 0.0
2025-12-09 10:24:39.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 6854 LR: 0.00022901253890915714 Training loss: 0.0
2025-12-09 10:24:39.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 6855 LR: 0.00022887921024811403 Training loss: 0.0
2025-12-09 10:24:39.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 6856 LR: 0.00022874590888892704 Training loss: 0.0
2025-12-09 10:24:39.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 6857 LR: 0.00022861263484501976 Training loss: 0.0
2025-12-09 10:24:39.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 6858 LR: 0.00022847938812981238 Training loss: 0.0
2025-12-09 10:24:39.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 6859 LR: 0.0002283461687567236 Training loss: 0.0
2025-12-09 10:24:39.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 6860 LR: 0.00022821297673916797 Training loss: 0.0
2025-12-09 10:24:39.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 6861 LR: 0.0002280798120905581 Training loss: 0.0
2025-12-09 10:24:39.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 6862 LR: 0.00022794667482430375 Training loss: 0.0
2025-12-09 10:24:39.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 6863 LR: 0.00022781356495381184 Training loss: 0.0
2025-12-09 10:24:39.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 6864 LR: 0.00022768048249248646 Training loss: 0.0
2025-12-09 10:24:39.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 6865 LR: 0.0002275474274537292 Training loss: 0.0
2025-12-09 10:24:39.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 6866 LR: 0.0002274143998509382 Training loss: 0.0
2025-12-09 10:24:39.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 6867 LR: 0.00022728139969751006 Training loss: 0.0
2025-12-09 10:24:39.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 6868 LR: 0.0002271484270068373 Training loss: 0.0
2025-12-09 10:24:39.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 6869 LR: 0.00022701548179231045 Training loss: 0.0
2025-12-09 10:24:39.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 6870 LR: 0.00022688256406731716 Training loss: 0.0
2025-12-09 10:24:39.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 6871 LR: 0.00022674967384524238 Training loss: 0.0
2025-12-09 10:24:39.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 6872 LR: 0.0002266168111394676 Training loss: 0.0
2025-12-09 10:24:39.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 6873 LR: 0.0002264839759633728 Training loss: 0.0
2025-12-09 10:24:39.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 6874 LR: 0.00022635116833033393 Training loss: 0.0
2025-12-09 10:24:39.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 6875 LR: 0.00022621838825372491 Training loss: 0.0
2025-12-09 10:24:39.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 6876 LR: 0.00022608563574691675 Training loss: 0.0
2025-12-09 10:24:39.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 6877 LR: 0.00022595291082327763 Training loss: 0.0
2025-12-09 10:24:39.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 6878 LR: 0.0002258202134961728 Training loss: 0.0
2025-12-09 10:24:39.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 6879 LR: 0.00022568754377896516 Training loss: 0.0
2025-12-09 10:24:39.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 6880 LR: 0.00022555490168501402 Training loss: 0.0
2025-12-09 10:24:39.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 6881 LR: 0.00022542228722767716 Training loss: 0.0
2025-12-09 10:24:39.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 6882 LR: 0.00022528970042030822 Training loss: 0.0
2025-12-09 10:24:39.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 6883 LR: 0.00022515714127625897 Training loss: 0.0
2025-12-09 10:24:39.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 6884 LR: 0.00022502460980887806 Training loss: 0.0
2025-12-09 10:24:39.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 6885 LR: 0.00022489210603151145 Training loss: 0.0
2025-12-09 10:24:39.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 6886 LR: 0.0002247596299575022 Training loss: 0.0
2025-12-09 10:24:39.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 6887 LR: 0.00022462718160019086 Training loss: 0.0
2025-12-09 10:24:39.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 6888 LR: 0.00022449476097291442 Training loss: 0.0
2025-12-09 10:24:39.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 6889 LR: 0.00022436236808900844 Training loss: 0.0
2025-12-09 10:24:39.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 6890 LR: 0.00022423000296180424 Training loss: 0.0
2025-12-09 10:24:39.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 6891 LR: 0.00022409766560463118 Training loss: 0.0
2025-12-09 10:24:39.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 6892 LR: 0.00022396535603081563 Training loss: 0.0
2025-12-09 10:24:39.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 6893 LR: 0.00022383307425368122 Training loss: 0.0
2025-12-09 10:24:39.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 6894 LR: 0.00022370082028654864 Training loss: 0.0
2025-12-09 10:24:39.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 6895 LR: 0.00022356859414273612 Training loss: 0.0
2025-12-09 10:24:39.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 6896 LR: 0.00022343639583555819 Training loss: 0.0
2025-12-09 10:24:39.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 6897 LR: 0.000223304225378328 Training loss: 0.0
2025-12-09 10:24:39.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 6898 LR: 0.0002231720827843546 Training loss: 0.0
2025-12-09 10:24:39.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 6899 LR: 0.00022303996806694487 Training loss: 0.0
2025-12-09 10:24:39.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 6900 LR: 0.00022290788123940282 Training loss: 0.0
2025-12-09 10:24:39.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 6901 LR: 0.00022277582231502963 Training loss: 0.0
2025-12-09 10:24:39.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 6902 LR: 0.00022264379130712325 Training loss: 0.0
2025-12-09 10:24:39.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 6903 LR: 0.0002225117882289799 Training loss: 0.0
2025-12-09 10:24:39.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 6904 LR: 0.0002223798130938916 Training loss: 0.0
2025-12-09 10:24:39.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 6905 LR: 0.00022224786591514863 Training loss: 0.0
2025-12-09 10:24:39.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 6906 LR: 0.00022211594670603791 Training loss: 0.0
2025-12-09 10:24:39.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 6907 LR: 0.00022198405547984375 Training loss: 0.0
2025-12-09 10:24:39.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 6908 LR: 0.00022185219224984758 Training loss: 0.0
2025-12-09 10:24:39.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 6909 LR: 0.00022172035702932823 Training loss: 0.0
2025-12-09 10:24:39.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 6910 LR: 0.00022158854983156097 Training loss: 0.0
2025-12-09 10:24:39.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 6911 LR: 0.00022145677066981944 Training loss: 0.0
2025-12-09 10:24:39.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 6912 LR: 0.00022132501955737338 Training loss: 0.0
2025-12-09 10:24:39.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 6913 LR: 0.0002211932965074902 Training loss: 0.0
2025-12-09 10:24:39.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 6914 LR: 0.0002210616015334344 Training loss: 0.0
2025-12-09 10:24:39.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 6915 LR: 0.00022092993464846772 Training loss: 0.0
2025-12-09 10:24:39.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 6916 LR: 0.000220798295865849 Training loss: 0.0
2025-12-09 10:24:39.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 6917 LR: 0.00022066668519883436 Training loss: 0.0
2025-12-09 10:24:39.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 6918 LR: 0.00022053510266067657 Training loss: 0.0
2025-12-09 10:24:39.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 6919 LR: 0.00022040354826462666 Training loss: 0.0
2025-12-09 10:24:39.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 6920 LR: 0.0002202720220239316 Training loss: 0.0
2025-12-09 10:24:39.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 6921 LR: 0.00022014052395183625 Training loss: 0.0
2025-12-09 10:24:39.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 6922 LR: 0.0002200090540615825 Training loss: 0.0
2025-12-09 10:24:39.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 6923 LR: 0.00021987761236640934 Training loss: 0.0
2025-12-09 10:24:39.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 6924 LR: 0.00021974619887955293 Training loss: 0.0
2025-12-09 10:24:39.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 6925 LR: 0.00021961481361424683 Training loss: 0.0
2025-12-09 10:24:39.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 6926 LR: 0.00021948345658372092 Training loss: 0.0
2025-12-09 10:24:39.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 6927 LR: 0.00021935212780120367 Training loss: 0.0
2025-12-09 10:24:39.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 6928 LR: 0.0002192208272799195 Training loss: 0.0
2025-12-09 10:24:39.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 6929 LR: 0.0002190895550330899 Training loss: 0.0
2025-12-09 10:24:39.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 6930 LR: 0.0002189583110739348 Training loss: 0.0
2025-12-09 10:24:39.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 6931 LR: 0.00021882709541566996 Training loss: 0.0
2025-12-09 10:24:39.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 6932 LR: 0.00021869590807150892 Training loss: 0.0
2025-12-09 10:24:39.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 6933 LR: 0.00021856474905466216 Training loss: 0.0
2025-12-09 10:24:39.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 6934 LR: 0.00021843361837833752 Training loss: 0.0
2025-12-09 10:24:39.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 6935 LR: 0.0002183025160557398 Training loss: 0.0
2025-12-09 10:24:39.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 6936 LR: 0.00021817144210007123 Training loss: 0.0
2025-12-09 10:24:39.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 6937 LR: 0.00021804039652453027 Training loss: 0.0
2025-12-09 10:24:39.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 6938 LR: 0.0002179093793423141 Training loss: 0.0
2025-12-09 10:24:39.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 6939 LR: 0.00021777839056661552 Training loss: 0.0
2025-12-09 10:24:39.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 6940 LR: 0.00021764743021062527 Training loss: 0.0
2025-12-09 10:24:39.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 6941 LR: 0.00021751649828753106 Training loss: 0.0
2025-12-09 10:24:39.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 6942 LR: 0.0002173855948105178 Training loss: 0.0
2025-12-09 10:24:39.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 6943 LR: 0.00021725471979276733 Training loss: 0.0
2025-12-09 10:24:39.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 6944 LR: 0.00021712387324745907 Training loss: 0.0
2025-12-09 10:24:39.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 6945 LR: 0.00021699305518776868 Training loss: 0.0
2025-12-09 10:24:39.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 6946 LR: 0.00021686226562687023 Training loss: 0.0
2025-12-09 10:24:39.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 6947 LR: 0.00021673150457793373 Training loss: 0.0
2025-12-09 10:24:39.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 6948 LR: 0.00021660077205412693 Training loss: 0.0
2025-12-09 10:24:39.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 6949 LR: 0.0002164700680686147 Training loss: 0.0
2025-12-09 10:24:39.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 6950 LR: 0.00021633939263455875 Training loss: 0.0
2025-12-09 10:24:39.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 6951 LR: 0.0002162087457651183 Training loss: 0.0
2025-12-09 10:24:39.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 6952 LR: 0.00021607812747344952 Training loss: 0.0
2025-12-09 10:24:39.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 6953 LR: 0.00021594753777270516 Training loss: 0.0
2025-12-09 10:24:39.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 6954 LR: 0.00021581697667603635 Training loss: 0.0
2025-12-09 10:24:39.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 6955 LR: 0.00021568644419659005 Training loss: 0.0
2025-12-09 10:24:39.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 6956 LR: 0.00021555594034751102 Training loss: 0.0
2025-12-09 10:24:39.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 6957 LR: 0.00021542546514194101 Training loss: 0.0
2025-12-09 10:24:39.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 6958 LR: 0.00021529501859301887 Training loss: 0.0
2025-12-09 10:24:39.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 6959 LR: 0.0002151646007138806 Training loss: 0.0
2025-12-09 10:24:39.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 6960 LR: 0.0002150342115176594 Training loss: 0.0
2025-12-09 10:24:39.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 6961 LR: 0.00021490385101748517 Training loss: 0.0
2025-12-09 10:24:39.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 6962 LR: 0.00021477351922648524 Training loss: 0.0
2025-12-09 10:24:39.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 6963 LR: 0.0002146432161577842 Training loss: 0.0
2025-12-09 10:24:39.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 6964 LR: 0.0002145129418245035 Training loss: 0.0
2025-12-09 10:24:39.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 6965 LR: 0.0002143826962397617 Training loss: 0.0
2025-12-09 10:24:39.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 6966 LR: 0.00021425247941667474 Training loss: 0.0
2025-12-09 10:24:39.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 6967 LR: 0.00021412229136835497 Training loss: 0.0
2025-12-09 10:24:39.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 6968 LR: 0.00021399213210791297 Training loss: 0.0
2025-12-09 10:24:39.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 6969 LR: 0.00021386200164845526 Training loss: 0.0
2025-12-09 10:24:39.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 6970 LR: 0.00021373190000308618 Training loss: 0.0
2025-12-09 10:24:39.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 6971 LR: 0.0002136018271849069 Training loss: 0.0
2025-12-09 10:24:39.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 6972 LR: 0.00021347178320701583 Training loss: 0.0
2025-12-09 10:24:39.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 6973 LR: 0.00021334176808250832 Training loss: 0.0
2025-12-09 10:24:39.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 6974 LR: 0.00021321178182447708 Training loss: 0.0
2025-12-09 10:24:39.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 6975 LR: 0.00021308182444601127 Training loss: 0.0
2025-12-09 10:24:39.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 6976 LR: 0.0002129518959601982 Training loss: 0.0
2025-12-09 10:24:39.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 6977 LR: 0.00021282199638012118 Training loss: 0.0
2025-12-09 10:24:39.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 6978 LR: 0.00021269212571886127 Training loss: 0.0
2025-12-09 10:24:39.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 6979 LR: 0.0002125622839894964 Training loss: 0.0
2025-12-09 10:24:39.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 6980 LR: 0.00021243247120510174 Training loss: 0.0
2025-12-09 10:24:39.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 6981 LR: 0.0002123026873787493 Training loss: 0.0
2025-12-09 10:24:39.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 6982 LR: 0.00021217293252350855 Training loss: 0.0
2025-12-09 10:24:39.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 6983 LR: 0.00021204320665244532 Training loss: 0.0
2025-12-09 10:24:39.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 6984 LR: 0.00021191350977862363 Training loss: 0.0
2025-12-09 10:24:39.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 6985 LR: 0.00021178384191510342 Training loss: 0.0
2025-12-09 10:24:39.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 6986 LR: 0.0002116542030749425 Training loss: 0.0
2025-12-09 10:24:39.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 6987 LR: 0.0002115245932711954 Training loss: 0.0
2025-12-09 10:24:39.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 6988 LR: 0.00021139501251691385 Training loss: 0.0
2025-12-09 10:24:39.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 6989 LR: 0.00021126546082514663 Training loss: 0.0
2025-12-09 10:24:39.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 6990 LR: 0.00021113593820893984 Training loss: 0.0
2025-12-09 10:24:39.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 6991 LR: 0.00021100644468133572 Training loss: 0.0
2025-12-09 10:24:39.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 6992 LR: 0.00021087698025537517 Training loss: 0.0
2025-12-09 10:24:39.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 6993 LR: 0.0002107475449440946 Training loss: 0.0
2025-12-09 10:24:39.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 6994 LR: 0.00021061813876052833 Training loss: 0.0
2025-12-09 10:24:39.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 6995 LR: 0.00021048876171770754 Training loss: 0.0
2025-12-09 10:24:39.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 6996 LR: 0.0002103594138286607 Training loss: 0.0
2025-12-09 10:24:39.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 6997 LR: 0.00021023009510641268 Training loss: 0.0
2025-12-09 10:24:39.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 6998 LR: 0.00021010080556398643 Training loss: 0.0
2025-12-09 10:24:39.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 6999 LR: 0.00020997154521440098 Training loss: 0.0
2025-12-09 10:24:39.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 7000 LR: 0.000209842314070673 Training loss: 0.0
2025-12-09 10:24:39.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 7001 LR: 0.000209713112145816 Training loss: 0.0
2025-12-09 10:24:39.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 7002 LR: 0.00020958393945284072 Training loss: 0.0
2025-12-09 10:24:39.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 7003 LR: 0.00020945479600475482 Training loss: 0.0
2025-12-09 10:24:39.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 7004 LR: 0.00020932568181456312 Training loss: 0.0
2025-12-09 10:24:39.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 7005 LR: 0.000209196596895267 Training loss: 0.0
2025-12-09 10:24:39.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 7006 LR: 0.00020906754125986593 Training loss: 0.0
2025-12-09 10:24:39.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 7007 LR: 0.00020893851492135535 Training loss: 0.0
2025-12-09 10:24:39.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 7008 LR: 0.00020880951789272834 Training loss: 0.0
2025-12-09 10:24:39.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 7009 LR: 0.0002086805501869749 Training loss: 0.0
2025-12-09 10:24:39.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 7010 LR: 0.0002085516118170821 Training loss: 0.0
2025-12-09 10:24:39.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 7011 LR: 0.00020842270279603403 Training loss: 0.0
2025-12-09 10:24:39.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 7012 LR: 0.00020829382313681193 Training loss: 0.0
2025-12-09 10:24:39.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 7013 LR: 0.00020816497285239372 Training loss: 0.0
2025-12-09 10:24:39.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 7014 LR: 0.00020803615195575477 Training loss: 0.0
2025-12-09 10:24:39.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 7015 LR: 0.00020790736045986734 Training loss: 0.0
2025-12-09 10:24:39.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 7016 LR: 0.00020777859837770068 Training loss: 0.0
2025-12-09 10:24:39.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 7017 LR: 0.00020764986572222139 Training loss: 0.0
2025-12-09 10:24:39.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 7018 LR: 0.00020752116250639225 Training loss: 0.0
2025-12-09 10:24:39.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 7019 LR: 0.0002073924887431744 Training loss: 0.0
2025-12-09 10:24:39.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 7020 LR: 0.00020726384444552472 Training loss: 0.0
2025-12-09 10:24:39.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 7021 LR: 0.00020713522962639792 Training loss: 0.0
2025-12-09 10:24:39.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 7022 LR: 0.0002070066442987455 Training loss: 0.0
2025-12-09 10:24:39.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 7023 LR: 0.00020687808847551608 Training loss: 0.0
2025-12-09 10:24:39.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 7024 LR: 0.00020674956216965484 Training loss: 0.0
2025-12-09 10:24:39.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 7025 LR: 0.00020662106539410502 Training loss: 0.0
2025-12-09 10:24:39.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 7026 LR: 0.00020649259816180572 Training loss: 0.0
2025-12-09 10:24:39.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 7027 LR: 0.00020636416048569372 Training loss: 0.0
2025-12-09 10:24:39.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 7028 LR: 0.00020623575237870272 Training loss: 0.0
2025-12-09 10:24:39.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 7029 LR: 0.00020610737385376348 Training loss: 0.0
2025-12-09 10:24:39.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 7030 LR: 0.0002059790249238036 Training loss: 0.0
2025-12-09 10:24:39.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 7031 LR: 0.00020585070560174808 Training loss: 0.0
2025-12-09 10:24:39.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 7032 LR: 0.00020572241590051805 Training loss: 0.0
2025-12-09 10:24:39.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 7033 LR: 0.00020559415583303308 Training loss: 0.0
2025-12-09 10:24:39.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 7034 LR: 0.00020546592541220837 Training loss: 0.0
2025-12-09 10:24:39.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 7035 LR: 0.0002053377246509569 Training loss: 0.0
2025-12-09 10:24:39.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 7036 LR: 0.0002052095535621885 Training loss: 0.0
2025-12-09 10:24:39.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 7037 LR: 0.00020508141215881004 Training loss: 0.0
2025-12-09 10:24:39.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 7038 LR: 0.00020495330045372523 Training loss: 0.0
2025-12-09 10:24:39.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 7039 LR: 0.00020482521845983521 Training loss: 0.0
2025-12-09 10:24:39.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 7040 LR: 0.00020469716619003726 Training loss: 0.0
2025-12-09 10:24:39.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 7041 LR: 0.00020456914365722694 Training loss: 0.0
2025-12-09 10:24:39.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 7042 LR: 0.0002044411508742956 Training loss: 0.0
2025-12-09 10:24:39.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 7043 LR: 0.00020431318785413228 Training loss: 0.0
2025-12-09 10:24:39.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 7044 LR: 0.00020418525460962284 Training loss: 0.0
2025-12-09 10:24:39.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 7045 LR: 0.0002040573511536502 Training loss: 0.0
2025-12-09 10:24:39.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 7046 LR: 0.00020392947749909418 Training loss: 0.0
2025-12-09 10:24:39.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 7047 LR: 0.00020380163365883188 Training loss: 0.0
2025-12-09 10:24:39.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 7048 LR: 0.00020367381964573656 Training loss: 0.0
2025-12-09 10:24:39.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 7049 LR: 0.00020354603547267987 Training loss: 0.0
2025-12-09 10:24:39.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 7050 LR: 0.00020341828115252907 Training loss: 0.0
2025-12-09 10:24:39.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 7051 LR: 0.00020329055669814934 Training loss: 0.0
2025-12-09 10:24:39.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 7052 LR: 0.00020316286212240236 Training loss: 0.0
2025-12-09 10:24:39.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 7053 LR: 0.00020303519743814725 Training loss: 0.0
2025-12-09 10:24:39.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 7054 LR: 0.00020290756265823928 Training loss: 0.0
2025-12-09 10:24:39.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 7055 LR: 0.00020277995779553192 Training loss: 0.0
2025-12-09 10:24:39.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 7056 LR: 0.00020265238286287457 Training loss: 0.0
2025-12-09 10:24:39.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 7057 LR: 0.00020252483787311409 Training loss: 0.0
2025-12-09 10:24:39.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 7058 LR: 0.00020239732283909435 Training loss: 0.0
2025-12-09 10:24:39.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 7059 LR: 0.00020226983777365604 Training loss: 0.0
2025-12-09 10:24:39.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 7060 LR: 0.00020214238268963686 Training loss: 0.0
2025-12-09 10:24:39.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 7061 LR: 0.00020201495759987183 Training loss: 0.0
2025-12-09 10:24:39.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 7062 LR: 0.00020188756251719205 Training loss: 0.0
2025-12-09 10:24:39.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 7063 LR: 0.0002017601974544269 Training loss: 0.0
2025-12-09 10:24:39.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 7064 LR: 0.00020163286242440154 Training loss: 0.0
2025-12-09 10:24:39.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 7065 LR: 0.00020150555743993876 Training loss: 0.0
2025-12-09 10:24:39.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 7066 LR: 0.0002013782825138582 Training loss: 0.0
2025-12-09 10:24:39.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 7067 LR: 0.0002012510376589764 Training loss: 0.0
2025-12-09 10:24:39.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 7068 LR: 0.00020112382288810698 Training loss: 0.0
2025-12-09 10:24:39.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 7069 LR: 0.00020099663821406056 Training loss: 0.0
2025-12-09 10:24:39.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 7070 LR: 0.00020086948364964413 Training loss: 0.0
2025-12-09 10:24:39.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 7071 LR: 0.00020074235920766287 Training loss: 0.0
2025-12-09 10:24:39.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 7072 LR: 0.0002006152649009177 Training loss: 0.0
2025-12-09 10:24:39.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 7073 LR: 0.00020048820074220714 Training loss: 0.0
2025-12-09 10:24:39.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 7074 LR: 0.00020036116674432652 Training loss: 0.0
2025-12-09 10:24:39.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 7075 LR: 0.00020023416292006829 Training loss: 0.0
2025-12-09 10:24:39.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 7076 LR: 0.0002001071892822216 Training loss: 0.0
2025-12-09 10:24:39.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 7077 LR: 0.00019998024584357295 Training loss: 0.0
2025-12-09 10:24:39.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 7078 LR: 0.00019985333261690497 Training loss: 0.0
2025-12-09 10:24:39.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 7079 LR: 0.00019972644961499853 Training loss: 0.0
2025-12-09 10:24:39.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 7080 LR: 0.00019959959685063024 Training loss: 0.0
2025-12-09 10:24:39.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 7081 LR: 0.0001994727743365743 Training loss: 0.0
2025-12-09 10:24:39.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 7082 LR: 0.00019934598208560178 Training loss: 0.0
2025-12-09 10:24:39.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 7083 LR: 0.00019921922011048067 Training loss: 0.0
2025-12-09 10:24:39.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 7084 LR: 0.00019909248842397582 Training loss: 0.0
2025-12-09 10:24:39.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 7085 LR: 0.00019896578703884932 Training loss: 0.0
2025-12-09 10:24:39.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 7086 LR: 0.00019883911596785947 Training loss: 0.0
2025-12-09 10:24:39.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 7087 LR: 0.0001987124752237628 Training loss: 0.0
2025-12-09 10:24:39.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 7088 LR: 0.00019858586481931147 Training loss: 0.0
2025-12-09 10:24:39.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 7089 LR: 0.00019845928476725522 Training loss: 0.0
2025-12-09 10:24:39.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 7090 LR: 0.00019833273508034082 Training loss: 0.0
2025-12-09 10:24:39.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 7091 LR: 0.00019820621577131188 Training loss: 0.0
2025-12-09 10:24:39.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 7092 LR: 0.0001980797268529084 Training loss: 0.0
2025-12-09 10:24:39.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 7093 LR: 0.00019795326833786853 Training loss: 0.0
2025-12-09 10:24:39.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 7094 LR: 0.0001978268402389261 Training loss: 0.0
2025-12-09 10:24:39.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 7095 LR: 0.00019770044256881258 Training loss: 0.0
2025-12-09 10:24:39.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 7096 LR: 0.00019757407534025623 Training loss: 0.0
2025-12-09 10:24:39.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 7097 LR: 0.00019744773856598225 Training loss: 0.0
2025-12-09 10:24:39.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 7098 LR: 0.00019732143225871285 Training loss: 0.0
2025-12-09 10:24:39.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 7099 LR: 0.00019719515643116677 Training loss: 0.0
2025-12-09 10:24:39.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 7100 LR: 0.00019706891109606017 Training loss: 0.0
2025-12-09 10:24:39.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 7101 LR: 0.00019694269626610589 Training loss: 0.0
2025-12-09 10:24:39.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 7102 LR: 0.00019681651195401384 Training loss: 0.0
2025-12-09 10:24:39.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 7103 LR: 0.00019669035817249076 Training loss: 0.0
2025-12-09 10:24:39.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 7104 LR: 0.00019656423493424048 Training loss: 0.0
2025-12-09 10:24:39.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 7105 LR: 0.00019643814225196304 Training loss: 0.0
2025-12-09 10:24:39.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 7106 LR: 0.00019631208013835678 Training loss: 0.0
2025-12-09 10:24:39.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 7107 LR: 0.00019618604860611555 Training loss: 0.0
2025-12-09 10:24:39.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 7108 LR: 0.0001960600476679309 Training loss: 0.0
2025-12-09 10:24:39.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 7109 LR: 0.0001959340773364911 Training loss: 0.0
2025-12-09 10:24:39.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 7110 LR: 0.00019580813762448145 Training loss: 0.0
2025-12-09 10:24:39.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 7111 LR: 0.000195682228544584 Training loss: 0.0
2025-12-09 10:24:39.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 7112 LR: 0.00019555635010947797 Training loss: 0.0
2025-12-09 10:24:39.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 7113 LR: 0.0001954305023318388 Training loss: 0.0
2025-12-09 10:24:39.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 7114 LR: 0.0001953046852243401 Training loss: 0.0
2025-12-09 10:24:39.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 7115 LR: 0.00019517889879965106 Training loss: 0.0
2025-12-09 10:24:39.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 7116 LR: 0.00019505314307043854 Training loss: 0.0
2025-12-09 10:24:39.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 7117 LR: 0.00019492741804936621 Training loss: 0.0
2025-12-09 10:24:39.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 7118 LR: 0.0001948017237490947 Training loss: 0.0
2025-12-09 10:24:39.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 7119 LR: 0.0001946760601822809 Training loss: 0.0
2025-12-09 10:24:39.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 7120 LR: 0.00019455042736157984 Training loss: 0.0
2025-12-09 10:24:39.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 7121 LR: 0.00019442482529964222 Training loss: 0.0
2025-12-09 10:24:39.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 7122 LR: 0.00019429925400911636 Training loss: 0.0
2025-12-09 10:24:39.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 7123 LR: 0.00019417371350264717 Training loss: 0.0
2025-12-09 10:24:39.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 7124 LR: 0.00019404820379287675 Training loss: 0.0
2025-12-09 10:24:39.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 7125 LR: 0.00019392272489244378 Training loss: 0.0
2025-12-09 10:24:39.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 7126 LR: 0.00019379727681398423 Training loss: 0.0
2025-12-09 10:24:39.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 7127 LR: 0.00019367185957013024 Training loss: 0.0
2025-12-09 10:24:39.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 7128 LR: 0.00019354647317351188 Training loss: 0.0
2025-12-09 10:24:39.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 7129 LR: 0.00019342111763675512 Training loss: 0.0
2025-12-09 10:24:39.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 7130 LR: 0.00019329579297248345 Training loss: 0.0
2025-12-09 10:24:39.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 7131 LR: 0.00019317049919331702 Training loss: 0.0
2025-12-09 10:24:39.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 7132 LR: 0.00019304523631187293 Training loss: 0.0
2025-12-09 10:24:39.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 7133 LR: 0.00019292000434076512 Training loss: 0.0
2025-12-09 10:24:39.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 7134 LR: 0.00019279480329260467 Training loss: 0.0
2025-12-09 10:24:39.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 7135 LR: 0.0001926696331799988 Training loss: 0.0
2025-12-09 10:24:39.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 7136 LR: 0.00019254449401555273 Training loss: 0.0
2025-12-09 10:24:39.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 7137 LR: 0.00019241938581186763 Training loss: 0.0
2025-12-09 10:24:39.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 7138 LR: 0.0001922943085815419 Training loss: 0.0
2025-12-09 10:24:39.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 7139 LR: 0.00019216926233717085 Training loss: 0.0
2025-12-09 10:24:39.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 7140 LR: 0.00019204424709134673 Training loss: 0.0
2025-12-09 10:24:39.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 7141 LR: 0.00019191926285665845 Training loss: 0.0
2025-12-09 10:24:39.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 7142 LR: 0.00019179430964569216 Training loss: 0.0
2025-12-09 10:24:39.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 7143 LR: 0.00019166938747103014 Training loss: 0.0
2025-12-09 10:24:39.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 7144 LR: 0.00019154449634525267 Training loss: 0.0
2025-12-09 10:24:39.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 7145 LR: 0.00019141963628093584 Training loss: 0.0
2025-12-09 10:24:39.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 7146 LR: 0.00019129480729065314 Training loss: 0.0
2025-12-09 10:24:39.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 7147 LR: 0.00019117000938697492 Training loss: 0.0
2025-12-09 10:24:39.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 7148 LR: 0.00019104524258246853 Training loss: 0.0
2025-12-09 10:24:39.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 7149 LR: 0.00019092050688969737 Training loss: 0.0
2025-12-09 10:24:39.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 7150 LR: 0.000190795802321223 Training loss: 0.0
2025-12-09 10:24:39.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 7151 LR: 0.0001906711288896028 Training loss: 0.0
2025-12-09 10:24:39.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 7152 LR: 0.00019054648660739144 Training loss: 0.0
2025-12-09 10:24:39.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 7153 LR: 0.00019042187548714036 Training loss: 0.0
2025-12-09 10:24:39.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 7154 LR: 0.00019029729554139797 Training loss: 0.0
2025-12-09 10:24:39.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 7155 LR: 0.00019017274678270946 Training loss: 0.0
2025-12-09 10:24:39.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 7156 LR: 0.00019004822922361704 Training loss: 0.0
2025-12-09 10:24:39.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 7157 LR: 0.00018992374287665908 Training loss: 0.0
2025-12-09 10:24:39.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 7158 LR: 0.0001897992877543721 Training loss: 0.0
2025-12-09 10:24:39.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 7159 LR: 0.00018967486386928817 Training loss: 0.0
2025-12-09 10:24:39.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 7160 LR: 0.000189550471233937 Training loss: 0.0
2025-12-09 10:24:39.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 7161 LR: 0.00018942610986084484 Training loss: 0.0
2025-12-09 10:24:39.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 7162 LR: 0.00018930177976253493 Training loss: 0.0
2025-12-09 10:24:39.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 7163 LR: 0.0001891774809515273 Training loss: 0.0
2025-12-09 10:24:39.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 7164 LR: 0.00018905321344033898 Training loss: 0.0
2025-12-09 10:24:39.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 7165 LR: 0.00018892897724148323 Training loss: 0.0
2025-12-09 10:24:39.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 7166 LR: 0.00018880477236747135 Training loss: 0.0
2025-12-09 10:24:39.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 7167 LR: 0.00018868059883081012 Training loss: 0.0
2025-12-09 10:24:39.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 7168 LR: 0.00018855645664400412 Training loss: 0.0
2025-12-09 10:24:39.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 7169 LR: 0.00018843234581955443 Training loss: 0.0
2025-12-09 10:24:39.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 7170 LR: 0.00018830826636995895 Training loss: 0.0
2025-12-09 10:24:39.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 7171 LR: 0.00018818421830771255 Training loss: 0.0
2025-12-09 10:24:39.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 7172 LR: 0.00018806020164530702 Training loss: 0.0
2025-12-09 10:24:39.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 7173 LR: 0.00018793621639523028 Training loss: 0.0
2025-12-09 10:24:39.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 7174 LR: 0.00018781226256996836 Training loss: 0.0
2025-12-09 10:24:39.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 7175 LR: 0.00018768834018200288 Training loss: 0.0
2025-12-09 10:24:39.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 7176 LR: 0.000187564449243813 Training loss: 0.0
2025-12-09 10:24:39.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 7177 LR: 0.00018744058976787455 Training loss: 0.0
2025-12-09 10:24:39.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 7178 LR: 0.00018731676176666012 Training loss: 0.0
2025-12-09 10:24:39.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 7179 LR: 0.00018719296525263924 Training loss: 0.0
2025-12-09 10:24:39.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 7180 LR: 0.00018706920023827834 Training loss: 0.0
2025-12-09 10:24:39.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 7181 LR: 0.00018694546673604014 Training loss: 0.0
2025-12-09 10:24:39.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 7182 LR: 0.0001868217647583852 Training loss: 0.0
2025-12-09 10:24:39.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 7183 LR: 0.0001866980943177699 Training loss: 0.0
2025-12-09 10:24:39.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 7184 LR: 0.00018657445542664768 Training loss: 0.0
2025-12-09 10:24:39.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 7185 LR: 0.00018645084809746954 Training loss: 0.0
2025-12-09 10:24:39.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 7186 LR: 0.00018632727234268225 Training loss: 0.0
2025-12-09 10:24:39.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 7187 LR: 0.00018620372817473003 Training loss: 0.0
2025-12-09 10:24:39.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 7188 LR: 0.00018608021560605382 Training loss: 0.0
2025-12-09 10:24:39.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 7189 LR: 0.0001859567346490913 Training loss: 0.0
2025-12-09 10:24:39.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 7190 LR: 0.00018583328531627697 Training loss: 0.0
2025-12-09 10:24:39.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 7191 LR: 0.00018570986762004243 Training loss: 0.0
2025-12-09 10:24:39.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 7192 LR: 0.00018558648157281527 Training loss: 0.0
2025-12-09 10:24:39.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 7193 LR: 0.0001854631271870212 Training loss: 0.0
2025-12-09 10:24:39.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 7194 LR: 0.00018533980447508135 Training loss: 0.0
2025-12-09 10:24:39.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 7195 LR: 0.00018521651344941464 Training loss: 0.0
2025-12-09 10:24:39.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 7196 LR: 0.0001850932541224364 Training loss: 0.0
2025-12-09 10:24:39.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 7197 LR: 0.00018497002650655887 Training loss: 0.0
2025-12-09 10:24:39.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 7198 LR: 0.00018484683061419105 Training loss: 0.0
2025-12-09 10:24:39.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 7199 LR: 0.0001847236664577389 Training loss: 0.0
2025-12-09 10:24:39.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 7200 LR: 0.00018460053404960458 Training loss: 0.0
2025-12-09 10:24:39.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 7201 LR: 0.0001844774334021882 Training loss: 0.0
2025-12-09 10:24:39.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 7202 LR: 0.00018435436452788551 Training loss: 0.0
2025-12-09 10:24:39.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 7203 LR: 0.0001842313274390896 Training loss: 0.0
2025-12-09 10:24:39.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 7204 LR: 0.00018410832214819047 Training loss: 0.0
2025-12-09 10:24:39.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 7205 LR: 0.00018398534866757456 Training loss: 0.0
2025-12-09 10:24:39.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 7206 LR: 0.0001838624070096255 Training loss: 0.0
2025-12-09 10:24:39.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 7207 LR: 0.00018373949718672344 Training loss: 0.0
2025-12-09 10:24:39.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 7208 LR: 0.00018361661921124513 Training loss: 0.0
2025-12-09 10:24:39.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 7209 LR: 0.00018349377309556487 Training loss: 0.0
2025-12-09 10:24:39.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 7210 LR: 0.0001833709588520529 Training loss: 0.0
2025-12-09 10:24:39.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 7211 LR: 0.00018324817649307667 Training loss: 0.0
2025-12-09 10:24:39.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 7212 LR: 0.0001831254260310004 Training loss: 0.0
2025-12-09 10:24:39.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 7213 LR: 0.00018300270747818526 Training loss: 0.0
2025-12-09 10:24:39.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 7214 LR: 0.0001828800208469884 Training loss: 0.0
2025-12-09 10:24:39.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 7215 LR: 0.00018275736614976518 Training loss: 0.0
2025-12-09 10:24:39.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 7216 LR: 0.00018263474339886627 Training loss: 0.0
2025-12-09 10:24:39.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 7217 LR: 0.00018251215260664007 Training loss: 0.0
2025-12-09 10:24:39.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 7218 LR: 0.00018238959378543142 Training loss: 0.0
2025-12-09 10:24:39.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 7219 LR: 0.00018226706694758193 Training loss: 0.0
2025-12-09 10:24:39.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 7220 LR: 0.0001821445721054301 Training loss: 0.0
2025-12-09 10:24:39.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 7221 LR: 0.0001820221092713114 Training loss: 0.0
2025-12-09 10:24:39.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 7222 LR: 0.00018189967845755724 Training loss: 0.0
2025-12-09 10:24:39.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 7223 LR: 0.00018177727967649704 Training loss: 0.0
2025-12-09 10:24:39.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 7224 LR: 0.00018165491294045593 Training loss: 0.0
2025-12-09 10:24:39.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 7225 LR: 0.0001815325782617564 Training loss: 0.0
2025-12-09 10:24:39.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 7226 LR: 0.00018141027565271752 Training loss: 0.0
2025-12-09 10:24:39.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 7227 LR: 0.00018128800512565513 Training loss: 0.0
2025-12-09 10:24:39.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 7228 LR: 0.00018116576669288193 Training loss: 0.0
2025-12-09 10:24:39.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 7229 LR: 0.0001810435603667075 Training loss: 0.0
2025-12-09 10:24:39.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 7230 LR: 0.00018092138615943742 Training loss: 0.0
2025-12-09 10:24:39.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 7231 LR: 0.00018079924408337538 Training loss: 0.0
2025-12-09 10:24:39.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 7232 LR: 0.00018067713415082054 Training loss: 0.0
2025-12-09 10:24:39.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 7233 LR: 0.0001805550563740696 Training loss: 0.0
2025-12-09 10:24:39.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 7234 LR: 0.00018043301076541574 Training loss: 0.0
2025-12-09 10:24:39.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 7235 LR: 0.0001803109973371489 Training loss: 0.0
2025-12-09 10:24:39.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 7236 LR: 0.0001801890161015559 Training loss: 0.0
2025-12-09 10:24:39.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 7237 LR: 0.00018006706707092041 Training loss: 0.0
2025-12-09 10:24:39.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 7238 LR: 0.00017994515025752218 Training loss: 0.0
2025-12-09 10:24:39.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 7239 LR: 0.0001798232656736389 Training loss: 0.0
2025-12-09 10:24:39.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 7240 LR: 0.00017970141333154382 Training loss: 0.0
2025-12-09 10:24:39.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 7241 LR: 0.00017957959324350765 Training loss: 0.0
2025-12-09 10:24:39.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 7242 LR: 0.00017945780542179767 Training loss: 0.0
2025-12-09 10:24:39.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 7243 LR: 0.00017933604987867814 Training loss: 0.0
2025-12-09 10:24:39.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 7244 LR: 0.00017921432662640918 Training loss: 0.0
2025-12-09 10:24:39.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 7245 LR: 0.00017909263567724915 Training loss: 0.0
2025-12-09 10:24:39.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 7246 LR: 0.0001789709770434518 Training loss: 0.0
2025-12-09 10:24:39.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 7247 LR: 0.00017884935073726822 Training loss: 0.0
2025-12-09 10:24:39.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 7248 LR: 0.00017872775677094623 Training loss: 0.0
2025-12-09 10:24:39.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 7249 LR: 0.0001786061951567303 Training loss: 0.0
2025-12-09 10:24:39.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 7250 LR: 0.0001784846659068618 Training loss: 0.0
2025-12-09 10:24:39.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 7251 LR: 0.0001783631690335788 Training loss: 0.0
2025-12-09 10:24:39.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 7252 LR: 0.00017824170454911554 Training loss: 0.0
2025-12-09 10:24:39.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 7253 LR: 0.00017812027246570417 Training loss: 0.0
2025-12-09 10:24:39.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 7254 LR: 0.00017799887279557237 Training loss: 0.0
2025-12-09 10:24:39.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 7255 LR: 0.0001778775055509453 Training loss: 0.0
2025-12-09 10:24:39.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 7256 LR: 0.00017775617074404455 Training loss: 0.0
2025-12-09 10:24:39.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 7257 LR: 0.00017763486838708858 Training loss: 0.0
2025-12-09 10:24:39.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 7258 LR: 0.00017751359849229258 Training loss: 0.0
2025-12-09 10:24:39.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 7259 LR: 0.00017739236107186857 Training loss: 0.0
2025-12-09 10:24:39.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 7260 LR: 0.00017727115613802463 Training loss: 0.0
2025-12-09 10:24:39.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 7261 LR: 0.00017714998370296675 Training loss: 0.0
2025-12-09 10:24:39.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 7262 LR: 0.00017702884377889655 Training loss: 0.0
2025-12-09 10:24:39.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 7263 LR: 0.00017690773637801295 Training loss: 0.0
2025-12-09 10:24:39.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 7264 LR: 0.0001767866615125114 Training loss: 0.0
2025-12-09 10:24:39.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 7265 LR: 0.00017666561919458423 Training loss: 0.0
2025-12-09 10:24:39.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 7266 LR: 0.00017654460943642032 Training loss: 0.0
2025-12-09 10:24:39.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 7267 LR: 0.00017642363225020557 Training loss: 0.0
2025-12-09 10:24:39.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 7268 LR: 0.00017630268764812207 Training loss: 0.0
2025-12-09 10:24:39.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 7269 LR: 0.00017618177564234904 Training loss: 0.0
2025-12-09 10:24:39.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 7270 LR: 0.0001760608962450624 Training loss: 0.0
2025-12-09 10:24:39.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 7271 LR: 0.00017594004946843456 Training loss: 0.0
2025-12-09 10:24:39.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 7272 LR: 0.00017581923532463507 Training loss: 0.0
2025-12-09 10:24:39.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 7273 LR: 0.00017569845382582938 Training loss: 0.0
2025-12-09 10:24:39.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 7274 LR: 0.00017557770498418084 Training loss: 0.0
2025-12-09 10:24:39.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 7275 LR: 0.00017545698881184834 Training loss: 0.0
2025-12-09 10:24:39.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 7276 LR: 0.00017533630532098828 Training loss: 0.0
2025-12-09 10:24:39.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 7277 LR: 0.00017521565452375333 Training loss: 0.0
2025-12-09 10:24:39.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 7278 LR: 0.00017509503643229325 Training loss: 0.0
2025-12-09 10:24:39.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 7279 LR: 0.00017497445105875377 Training loss: 0.0
2025-12-09 10:24:39.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 7280 LR: 0.0001748538984152785 Training loss: 0.0
2025-12-09 10:24:39.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 7281 LR: 0.00017473337851400662 Training loss: 0.0
2025-12-09 10:24:39.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 7282 LR: 0.0001746128913670746 Training loss: 0.0
2025-12-09 10:24:39.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 7283 LR: 0.00017449243698661554 Training loss: 0.0
2025-12-09 10:24:39.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 7284 LR: 0.00017437201538475917 Training loss: 0.0
2025-12-09 10:24:39.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 7285 LR: 0.00017425162657363192 Training loss: 0.0
2025-12-09 10:24:39.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 7286 LR: 0.00017413127056535715 Training loss: 0.0
2025-12-09 10:24:39.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 7287 LR: 0.00017401094737205415 Training loss: 0.0
2025-12-09 10:24:39.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 7288 LR: 0.00017389065700584023 Training loss: 0.0
2025-12-09 10:24:39.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 7289 LR: 0.000173770399478828 Training loss: 0.0
2025-12-09 10:24:39.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 7290 LR: 0.0001736501748031276 Training loss: 0.0
2025-12-09 10:24:39.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 7291 LR: 0.00017352998299084572 Training loss: 0.0
2025-12-09 10:24:39.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 7292 LR: 0.00017340982405408562 Training loss: 0.0
2025-12-09 10:24:39.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 7293 LR: 0.00017328969800494727 Training loss: 0.0
2025-12-09 10:24:39.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 7294 LR: 0.00017316960485552757 Training loss: 0.0
2025-12-09 10:24:39.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 7295 LR: 0.00017304954461791938 Training loss: 0.0
2025-12-09 10:24:39.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 7296 LR: 0.00017292951730421346 Training loss: 0.0
2025-12-09 10:24:39.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 7297 LR: 0.000172809522926496 Training loss: 0.0
2025-12-09 10:24:39.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 7298 LR: 0.00017268956149685066 Training loss: 0.0
2025-12-09 10:24:39.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 7299 LR: 0.0001725696330273575 Training loss: 0.0
2025-12-09 10:24:39.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 7300 LR: 0.00017244973753009334 Training loss: 0.0
2025-12-09 10:24:39.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 7301 LR: 0.00017232987501713165 Training loss: 0.0
2025-12-09 10:24:39.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 7302 LR: 0.0001722100455005427 Training loss: 0.0
2025-12-09 10:24:39.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 7303 LR: 0.00017209024899239296 Training loss: 0.0
2025-12-09 10:24:39.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 7304 LR: 0.00017197048550474643 Training loss: 0.0
2025-12-09 10:24:39.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 7305 LR: 0.0001718507550496629 Training loss: 0.0
2025-12-09 10:24:39.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 7306 LR: 0.00017173105763919932 Training loss: 0.0
2025-12-09 10:24:39.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 7307 LR: 0.00017161139328540932 Training loss: 0.0
2025-12-09 10:24:39.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 7308 LR: 0.00017149176200034316 Training loss: 0.0
2025-12-09 10:24:39.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 7309 LR: 0.00017137216379604724 Training loss: 0.0
2025-12-09 10:24:39.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 7310 LR: 0.00017125259868456578 Training loss: 0.0
2025-12-09 10:24:39.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 7311 LR: 0.0001711330666779385 Training loss: 0.0
2025-12-09 10:24:39.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 7312 LR: 0.00017101356778820233 Training loss: 0.0
2025-12-09 10:24:39.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 7313 LR: 0.00017089410202739092 Training loss: 0.0
2025-12-09 10:24:39.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 7314 LR: 0.00017077466940753445 Training loss: 0.0
2025-12-09 10:24:39.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 7315 LR: 0.00017065526994065972 Training loss: 0.0
2025-12-09 10:24:39.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 7316 LR: 0.0001705359036387905 Training loss: 0.0
2025-12-09 10:24:39.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 7317 LR: 0.00017041657051394644 Training loss: 0.0
2025-12-09 10:24:39.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 7318 LR: 0.00017029727057814504 Training loss: 0.0
2025-12-09 10:24:39.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 7319 LR: 0.00017017800384339925 Training loss: 0.0
2025-12-09 10:24:39.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 7320 LR: 0.0001700587703217195 Training loss: 0.0
2025-12-09 10:24:39.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 7321 LR: 0.00016993957002511256 Training loss: 0.0
2025-12-09 10:24:39.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 7322 LR: 0.00016982040296558188 Training loss: 0.0
2025-12-09 10:24:39.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 7323 LR: 0.00016970126915512757 Training loss: 0.0
2025-12-09 10:24:39.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 7324 LR: 0.0001695821686057466 Training loss: 0.0
2025-12-09 10:24:39.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 7325 LR: 0.0001694631013294319 Training loss: 0.0
2025-12-09 10:24:39.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 7326 LR: 0.00016934406733817414 Training loss: 0.0
2025-12-09 10:24:39.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 7327 LR: 0.0001692250666439596 Training loss: 0.0
2025-12-09 10:24:39.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 7328 LR: 0.0001691060992587718 Training loss: 0.0
2025-12-09 10:24:39.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 7329 LR: 0.00016898716519459073 Training loss: 0.0
2025-12-09 10:24:39.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 7330 LR: 0.0001688682644633931 Training loss: 0.0
2025-12-09 10:24:39.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 7331 LR: 0.00016874939707715216 Training loss: 0.0
2025-12-09 10:24:39.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 7332 LR: 0.00016863056304783803 Training loss: 0.0
2025-12-09 10:24:39.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 7333 LR: 0.00016851176238741683 Training loss: 0.0
2025-12-09 10:24:39.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 7334 LR: 0.00016839299510785238 Training loss: 0.0
2025-12-09 10:24:39.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 7335 LR: 0.00016827426122110412 Training loss: 0.0
2025-12-09 10:24:39.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 7336 LR: 0.00016815556073912868 Training loss: 0.0
2025-12-09 10:24:39.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 7337 LR: 0.0001680368936738792 Training loss: 0.0
2025-12-09 10:24:39.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 7338 LR: 0.0001679182600373056 Training loss: 0.0
2025-12-09 10:24:39.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 7339 LR: 0.00016779965984135375 Training loss: 0.0
2025-12-09 10:24:39.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 7340 LR: 0.00016768109309796747 Training loss: 0.0
2025-12-09 10:24:39.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 7341 LR: 0.00016756255981908582 Training loss: 0.0
2025-12-09 10:24:39.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 7342 LR: 0.00016744406001664524 Training loss: 0.0
2025-12-09 10:24:39.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 7343 LR: 0.00016732559370257881 Training loss: 0.0
2025-12-09 10:24:39.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 7344 LR: 0.00016720716088881594 Training loss: 0.0
2025-12-09 10:24:39.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 7345 LR: 0.00016708876158728293 Training loss: 0.0
2025-12-09 10:24:39.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 7346 LR: 0.00016697039580990258 Training loss: 0.0
2025-12-09 10:24:39.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 7347 LR: 0.00016685206356859401 Training loss: 0.0
2025-12-09 10:24:39.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 7348 LR: 0.0001667337648752738 Training loss: 0.0
2025-12-09 10:24:39.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 7349 LR: 0.00016661549974185424 Training loss: 0.0
2025-12-09 10:24:39.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 7350 LR: 0.00016649726818024468 Training loss: 0.0
2025-12-09 10:24:39.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 7351 LR: 0.00016637907020235115 Training loss: 0.0
2025-12-09 10:24:39.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 7352 LR: 0.0001662609058200761 Training loss: 0.0
2025-12-09 10:24:39.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 7353 LR: 0.00016614277504531865 Training loss: 0.0
2025-12-09 10:24:39.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 7354 LR: 0.00016602467788997483 Training loss: 0.0
2025-12-09 10:24:39.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 7355 LR: 0.00016590661436593663 Training loss: 0.0
2025-12-09 10:24:39.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 7356 LR: 0.0001657885844850932 Training loss: 0.0
2025-12-09 10:24:39.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 7357 LR: 0.00016567058825933022 Training loss: 0.0
2025-12-09 10:24:39.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 7358 LR: 0.00016555262570052982 Training loss: 0.0
2025-12-09 10:24:39.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 7359 LR: 0.00016543469682057105 Training loss: 0.0
2025-12-09 10:24:39.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 7360 LR: 0.0001653168016313288 Training loss: 0.0
2025-12-09 10:24:39.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 7361 LR: 0.00016519894014467579 Training loss: 0.0
2025-12-09 10:24:39.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 7362 LR: 0.0001650811123724802 Training loss: 0.0
2025-12-09 10:24:39.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 7363 LR: 0.00016496331832660744 Training loss: 0.0
2025-12-09 10:24:39.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 7364 LR: 0.00016484555801891937 Training loss: 0.0
2025-12-09 10:24:39.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 7365 LR: 0.0001647278314612744 Training loss: 0.0
2025-12-09 10:24:39.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 7366 LR: 0.00016461013866552767 Training loss: 0.0
2025-12-09 10:24:39.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 7367 LR: 0.00016449247964353092 Training loss: 0.0
2025-12-09 10:24:39.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 7368 LR: 0.00016437485440713213 Training loss: 0.0
2025-12-09 10:24:39.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 7369 LR: 0.00016425726296817632 Training loss: 0.0
2025-12-09 10:24:39.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 7370 LR: 0.00016413970533850496 Training loss: 0.0
2025-12-09 10:24:39.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 7371 LR: 0.00016402218152995607 Training loss: 0.0
2025-12-09 10:24:39.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 7372 LR: 0.00016390469155436432 Training loss: 0.0
2025-12-09 10:24:39.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 7373 LR: 0.0001637872354235611 Training loss: 0.0
2025-12-09 10:24:39.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 7374 LR: 0.00016366981314937373 Training loss: 0.0
2025-12-09 10:24:39.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 7375 LR: 0.0001635524247436273 Training loss: 0.0
2025-12-09 10:24:39.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 7376 LR: 0.00016343507021814236 Training loss: 0.0
2025-12-09 10:24:39.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 7377 LR: 0.0001633177495847366 Training loss: 0.0
2025-12-09 10:24:39.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 7378 LR: 0.00016320046285522426 Training loss: 0.0
2025-12-09 10:24:39.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 7379 LR: 0.00016308321004141607 Training loss: 0.0
2025-12-09 10:24:39.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 7380 LR: 0.00016296599115511945 Training loss: 0.0
2025-12-09 10:24:39.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 7381 LR: 0.00016284880620813847 Training loss: 0.0
2025-12-09 10:24:39.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 7382 LR: 0.00016273165521227313 Training loss: 0.0
2025-12-09 10:24:39.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 7383 LR: 0.0001626145381793212 Training loss: 0.0
2025-12-09 10:24:39.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 7384 LR: 0.0001624974551210759 Training loss: 0.0
2025-12-09 10:24:39.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 7385 LR: 0.00016238040604932757 Training loss: 0.0
2025-12-09 10:24:39.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 7386 LR: 0.00016226339097586318 Training loss: 0.0
2025-12-09 10:24:39.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 7387 LR: 0.0001621464099124661 Training loss: 0.0
2025-12-09 10:24:39.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 7388 LR: 0.00016202946287091624 Training loss: 0.0
2025-12-09 10:24:39.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 7389 LR: 0.00016191254986299043 Training loss: 0.0
2025-12-09 10:24:39.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 7390 LR: 0.00016179567090046122 Training loss: 0.0
2025-12-09 10:24:39.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 7391 LR: 0.00016167882599509904 Training loss: 0.0
2025-12-09 10:24:39.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 7392 LR: 0.0001615620151586697 Training loss: 0.0
2025-12-09 10:24:39.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 7393 LR: 0.00016144523840293612 Training loss: 0.0
2025-12-09 10:24:39.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 7394 LR: 0.0001613284957396578 Training loss: 0.0
2025-12-09 10:24:39.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 7395 LR: 0.0001612117871805907 Training loss: 0.0
2025-12-09 10:24:39.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 7396 LR: 0.00016109511273748733 Training loss: 0.0
2025-12-09 10:24:39.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 7397 LR: 0.000160978472422097 Training loss: 0.0
2025-12-09 10:24:39.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 7398 LR: 0.00016086186624616496 Training loss: 0.0
2025-12-09 10:24:39.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 7399 LR: 0.00016074529422143398 Training loss: 0.0
2025-12-09 10:24:39.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 7400 LR: 0.0001606287563596424 Training loss: 0.0
2025-12-09 10:24:39.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 7401 LR: 0.00016051225267252583 Training loss: 0.0
2025-12-09 10:24:39.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 7402 LR: 0.00016039578317181608 Training loss: 0.0
2025-12-09 10:24:39.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 7403 LR: 0.00016027934786924186 Training loss: 0.0
2025-12-09 10:24:39.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 7404 LR: 0.00016016294677652772 Training loss: 0.0
2025-12-09 10:24:39.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 7405 LR: 0.0001600465799053958 Training loss: 0.0
2025-12-09 10:24:39.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 7406 LR: 0.00015993024726756384 Training loss: 0.0
2025-12-09 10:24:40.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 7407 LR: 0.0001598139488747467 Training loss: 0.0
2025-12-09 10:24:40.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 7408 LR: 0.0001596976847386556 Training loss: 0.0
2025-12-09 10:24:40.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 7409 LR: 0.0001595814548709983 Training loss: 0.0
2025-12-09 10:24:40.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 7410 LR: 0.0001594652592834792 Training loss: 0.0
2025-12-09 10:24:40.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 7411 LR: 0.00015934909798779933 Training loss: 0.0
2025-12-09 10:24:40.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 7412 LR: 0.00015923297099565563 Training loss: 0.0
2025-12-09 10:24:40.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 7413 LR: 0.00015911687831874277 Training loss: 0.0
2025-12-09 10:24:40.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 7414 LR: 0.00015900081996875082 Training loss: 0.0
2025-12-09 10:24:40.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 7415 LR: 0.00015888479595736694 Training loss: 0.0
2025-12-09 10:24:40.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 7416 LR: 0.00015876880629627472 Training loss: 0.0
2025-12-09 10:24:40.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 7417 LR: 0.00015865285099715443 Training loss: 0.0
2025-12-09 10:24:40.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 7418 LR: 0.00015853693007168268 Training loss: 0.0
2025-12-09 10:24:40.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 7419 LR: 0.00015842104353153285 Training loss: 0.0
2025-12-09 10:24:40.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 7420 LR: 0.00015830519138837436 Training loss: 0.0
2025-12-09 10:24:40.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 7421 LR: 0.00015818937365387397 Training loss: 0.0
2025-12-09 10:24:40.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 7422 LR: 0.0001580735903396942 Training loss: 0.0
2025-12-09 10:24:40.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 7423 LR: 0.00015795784145749452 Training loss: 0.0
2025-12-09 10:24:40.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 7424 LR: 0.00015784212701893085 Training loss: 0.0
2025-12-09 10:24:40.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 7425 LR: 0.00015772644703565563 Training loss: 0.0
2025-12-09 10:24:40.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 7426 LR: 0.00015761080151931783 Training loss: 0.0
2025-12-09 10:24:40.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 7427 LR: 0.00015749519048156307 Training loss: 0.0
2025-12-09 10:24:40.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 7428 LR: 0.000157379613934033 Training loss: 0.0
2025-12-09 10:24:40.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 7429 LR: 0.0001572640718883667 Training loss: 0.0
2025-12-09 10:24:40.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 7430 LR: 0.00015714856435619884 Training loss: 0.0
2025-12-09 10:24:40.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 7431 LR: 0.00015703309134916117 Training loss: 0.0
2025-12-09 10:24:40.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 7432 LR: 0.00015691765287888183 Training loss: 0.0
2025-12-09 10:24:40.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 7433 LR: 0.00015680224895698558 Training loss: 0.0
2025-12-09 10:24:40.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 7434 LR: 0.0001566868795950932 Training loss: 0.0
2025-12-09 10:24:40.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 7435 LR: 0.00015657154480482293 Training loss: 0.0
2025-12-09 10:24:40.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 7436 LR: 0.00015645624459778858 Training loss: 0.0
2025-12-09 10:24:40.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 7437 LR: 0.00015634097898560096 Training loss: 0.0
2025-12-09 10:24:40.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 7438 LR: 0.00015622574797986732 Training loss: 0.0
2025-12-09 10:24:40.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 7439 LR: 0.0001561105515921915 Training loss: 0.0
2025-12-09 10:24:40.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 7440 LR: 0.00015599538983417395 Training loss: 0.0
2025-12-09 10:24:40.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 7441 LR: 0.00015588026271741095 Training loss: 0.0
2025-12-09 10:24:40.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 7442 LR: 0.00015576517025349613 Training loss: 0.0
2025-12-09 10:24:40.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 7443 LR: 0.00015565011245401928 Training loss: 0.0
2025-12-09 10:24:40.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 7444 LR: 0.00015553508933056665 Training loss: 0.0
2025-12-09 10:24:40.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 7445 LR: 0.00015542010089472107 Training loss: 0.0
2025-12-09 10:24:40.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 7446 LR: 0.0001553051471580621 Training loss: 0.0
2025-12-09 10:24:40.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 7447 LR: 0.0001551902281321651 Training loss: 0.0
2025-12-09 10:24:40.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 7448 LR: 0.00015507534382860295 Training loss: 0.0
2025-12-09 10:24:40.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 7449 LR: 0.0001549604942589441 Training loss: 0.0
2025-12-09 10:24:40.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 7450 LR: 0.00015484567943475404 Training loss: 0.0
2025-12-09 10:24:40.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 7451 LR: 0.0001547308993675946 Training loss: 0.0
2025-12-09 10:24:40.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 7452 LR: 0.00015461615406902414 Training loss: 0.0
2025-12-09 10:24:40.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 7453 LR: 0.00015450144355059754 Training loss: 0.0
2025-12-09 10:24:40.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 7454 LR: 0.0001543867678238663 Training loss: 0.0
2025-12-09 10:24:40.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 7455 LR: 0.00015427212690037774 Training loss: 0.0
2025-12-09 10:24:40.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 7456 LR: 0.00015415752079167683 Training loss: 0.0
2025-12-09 10:24:40.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 7457 LR: 0.000154042949509304 Training loss: 0.0
2025-12-09 10:24:40.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 7458 LR: 0.00015392841306479665 Training loss: 0.0
2025-12-09 10:24:40.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 7459 LR: 0.00015381391146968864 Training loss: 0.0
2025-12-09 10:24:40.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 7460 LR: 0.00015369944473551044 Training loss: 0.0
2025-12-09 10:24:40.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 7461 LR: 0.0001535850128737884 Training loss: 0.0
2025-12-09 10:24:40.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 7462 LR: 0.00015347061589604633 Training loss: 0.0
2025-12-09 10:24:40.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 7463 LR: 0.00015335625381380363 Training loss: 0.0
2025-12-09 10:24:40.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 7464 LR: 0.00015324192663857672 Training loss: 0.0
2025-12-09 10:24:40.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 7465 LR: 0.00015312763438187827 Training loss: 0.0
2025-12-09 10:24:40.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 7466 LR: 0.00015301337705521755 Training loss: 0.0
2025-12-09 10:24:40.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 7467 LR: 0.00015289915467010028 Training loss: 0.0
2025-12-09 10:24:40.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 7468 LR: 0.0001527849672380288 Training loss: 0.0
2025-12-09 10:24:40.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 7469 LR: 0.00015267081477050133 Training loss: 0.0
2025-12-09 10:24:40.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 7470 LR: 0.00015255669727901362 Training loss: 0.0
2025-12-09 10:24:40.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 7471 LR: 0.00015244261477505676 Training loss: 0.0
2025-12-09 10:24:40.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 7472 LR: 0.0001523285672701191 Training loss: 0.0
2025-12-09 10:24:40.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 7473 LR: 0.00015221455477568523 Training loss: 0.0
2025-12-09 10:24:40.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 7474 LR: 0.00015210057730323618 Training loss: 0.0
2025-12-09 10:24:40.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 7475 LR: 0.00015198663486424947 Training loss: 0.0
2025-12-09 10:24:40.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 7476 LR: 0.00015187272747019926 Training loss: 0.0
2025-12-09 10:24:40.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 7477 LR: 0.0001517588551325556 Training loss: 0.0
2025-12-09 10:24:40.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 7478 LR: 0.00015164501786278596 Training loss: 0.0
2025-12-09 10:24:40.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 7479 LR: 0.00015153121567235335 Training loss: 0.0
2025-12-09 10:24:40.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 7480 LR: 0.00015141744857271778 Training loss: 0.0
2025-12-09 10:24:40.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 7481 LR: 0.0001513037165753356 Training loss: 0.0
2025-12-09 10:24:40.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 7482 LR: 0.00015119001969165962 Training loss: 0.0
2025-12-09 10:24:40.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 7483 LR: 0.00015107635793313912 Training loss: 0.0
2025-12-09 10:24:40.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 7484 LR: 0.00015096273131121995 Training loss: 0.0
2025-12-09 10:24:40.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 7485 LR: 0.00015084913983734395 Training loss: 0.0
2025-12-09 10:24:40.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 7486 LR: 0.00015073558352295024 Training loss: 0.0
2025-12-09 10:24:40.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 7487 LR: 0.00015062206237947363 Training loss: 0.0
2025-12-09 10:24:40.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 7488 LR: 0.00015050857641834574 Training loss: 0.0
2025-12-09 10:24:40.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 7489 LR: 0.00015039512565099468 Training loss: 0.0
2025-12-09 10:24:40.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 7490 LR: 0.00015028171008884484 Training loss: 0.0
2025-12-09 10:24:40.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 7491 LR: 0.00015016832974331724 Training loss: 0.0
2025-12-09 10:24:40.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 7492 LR: 0.00015005498462582946 Training loss: 0.0
2025-12-09 10:24:40.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 7493 LR: 0.0001499416747477948 Training loss: 0.0
2025-12-09 10:24:40.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 7494 LR: 0.00014982840012062426 Training loss: 0.0
2025-12-09 10:24:40.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 7495 LR: 0.00014971516075572405 Training loss: 0.0
2025-12-09 10:24:40.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 7496 LR: 0.0001496019566644976 Training loss: 0.0
2025-12-09 10:24:40.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 7497 LR: 0.0001494887878583445 Training loss: 0.0
2025-12-09 10:24:40.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 7498 LR: 0.00014937565434866107 Training loss: 0.0
2025-12-09 10:24:40.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 7499 LR: 0.00014926255614683932 Training loss: 0.0
2025-12-09 10:24:40.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 7500 LR: 0.00014914949326426884 Training loss: 0.0
2025-12-09 10:24:40.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 7501 LR: 0.0001490364657123347 Training loss: 0.0
2025-12-09 10:24:40.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 7502 LR: 0.0001489234735024188 Training loss: 0.0
2025-12-09 10:24:40.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 7503 LR: 0.00014881051664589957 Training loss: 0.0
2025-12-09 10:24:40.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 7504 LR: 0.00014869759515415165 Training loss: 0.0
2025-12-09 10:24:40.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 7505 LR: 0.00014858470903854633 Training loss: 0.0
2025-12-09 10:24:40.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 7506 LR: 0.00014847185831045134 Training loss: 0.0
2025-12-09 10:24:40.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 7507 LR: 0.00014835904298123026 Training loss: 0.0
2025-12-09 10:24:40.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 7508 LR: 0.00014824626306224431 Training loss: 0.0
2025-12-09 10:24:40.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 7509 LR: 0.0001481335185648498 Training loss: 0.0
2025-12-09 10:24:40.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 7510 LR: 0.00014802080950040042 Training loss: 0.0
2025-12-09 10:24:40.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 7511 LR: 0.0001479081358802458 Training loss: 0.0
2025-12-09 10:24:40.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 7512 LR: 0.00014779549771573236 Training loss: 0.0
2025-12-09 10:24:40.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 7513 LR: 0.00014768289501820264 Training loss: 0.0
2025-12-09 10:24:40.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 7514 LR: 0.00014757032779899587 Training loss: 0.0
2025-12-09 10:24:40.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 7515 LR: 0.00014745779606944716 Training loss: 0.0
2025-12-09 10:24:40.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 7516 LR: 0.00014734529984088908 Training loss: 0.0
2025-12-09 10:24:40.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 7517 LR: 0.00014723283912464942 Training loss: 0.0
2025-12-09 10:24:40.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 7518 LR: 0.00014712041393205328 Training loss: 0.0
2025-12-09 10:24:40.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 7519 LR: 0.0001470080242744218 Training loss: 0.0
2025-12-09 10:24:40.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 7520 LR: 0.00014689567016307255 Training loss: 0.0
2025-12-09 10:24:40.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 7521 LR: 0.00014678335160931972 Training loss: 0.0
2025-12-09 10:24:40.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 7522 LR: 0.00014667106862447383 Training loss: 0.0
2025-12-09 10:24:40.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 7523 LR: 0.00014655882121984137 Training loss: 0.0
2025-12-09 10:24:40.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 7524 LR: 0.00014644660940672628 Training loss: 0.0
2025-12-09 10:24:40.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 7525 LR: 0.00014633443319642792 Training loss: 0.0
2025-12-09 10:24:40.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 7526 LR: 0.00014622229260024216 Training loss: 0.0
2025-12-09 10:24:40.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 7527 LR: 0.00014611018762946215 Training loss: 0.0
2025-12-09 10:24:40.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 7528 LR: 0.0001459981182953764 Training loss: 0.0
2025-12-09 10:24:40.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 7529 LR: 0.0001458860846092705 Training loss: 0.0
2025-12-09 10:24:40.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 7530 LR: 0.00014577408658242614 Training loss: 0.0
2025-12-09 10:24:40.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 7531 LR: 0.00014566212422612157 Training loss: 0.0
2025-12-09 10:24:40.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 7532 LR: 0.00014555019755163145 Training loss: 0.0
2025-12-09 10:24:40.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 7533 LR: 0.00014543830657022682 Training loss: 0.0
2025-12-09 10:24:40.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 7534 LR: 0.0001453264512931748 Training loss: 0.0
2025-12-09 10:24:40.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 7535 LR: 0.00014521463173173966 Training loss: 0.0
2025-12-09 10:24:40.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 7536 LR: 0.00014510284789718127 Training loss: 0.0
2025-12-09 10:24:40.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 7537 LR: 0.00014499109980075636 Training loss: 0.0
2025-12-09 10:24:40.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 7538 LR: 0.00014487938745371803 Training loss: 0.0
2025-12-09 10:24:40.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 7539 LR: 0.00014476771086731566 Training loss: 0.0
2025-12-09 10:24:40.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 7540 LR: 0.00014465607005279503 Training loss: 0.0
2025-12-09 10:24:40.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 7541 LR: 0.00014454446502139862 Training loss: 0.0
2025-12-09 10:24:40.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 7542 LR: 0.00014443289578436457 Training loss: 0.0
2025-12-09 10:24:40.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 7543 LR: 0.00014432136235292847 Training loss: 0.0
2025-12-09 10:24:40.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 7544 LR: 0.00014420986473832127 Training loss: 0.0
2025-12-09 10:24:40.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 7545 LR: 0.00014409840295177102 Training loss: 0.0
2025-12-09 10:24:40.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 7546 LR: 0.0001439869770045018 Training loss: 0.0
2025-12-09 10:24:40.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 7547 LR: 0.00014387558690773429 Training loss: 0.0
2025-12-09 10:24:40.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 7548 LR: 0.0001437642326726854 Training loss: 0.0
2025-12-09 10:24:40.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 7549 LR: 0.00014365291431056872 Training loss: 0.0
2025-12-09 10:24:40.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 7550 LR: 0.00014354163183259345 Training loss: 0.0
2025-12-09 10:24:40.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 7551 LR: 0.00014343038524996642 Training loss: 0.0
2025-12-09 10:24:40.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 7552 LR: 0.00014331917457388976 Training loss: 0.0
2025-12-09 10:24:40.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 7553 LR: 0.00014320799981556244 Training loss: 0.0
2025-12-09 10:24:40.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 7554 LR: 0.00014309686098617973 Training loss: 0.0
2025-12-09 10:24:40.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 7555 LR: 0.00014298575809693355 Training loss: 0.0
2025-12-09 10:24:40.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 7556 LR: 0.00014287469115901143 Training loss: 0.0
2025-12-09 10:24:40.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 7557 LR: 0.00014276366018359842 Training loss: 0.0
2025-12-09 10:24:40.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 7558 LR: 0.00014265266518187492 Training loss: 0.0
2025-12-09 10:24:40.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 7559 LR: 0.00014254170616501827 Training loss: 0.0
2025-12-09 10:24:40.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 7560 LR: 0.00014243078314420205 Training loss: 0.0
2025-12-09 10:24:40.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 7561 LR: 0.00014231989613059615 Training loss: 0.0
2025-12-09 10:24:40.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 7562 LR: 0.00014220904513536693 Training loss: 0.0
2025-12-09 10:24:40.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 7563 LR: 0.00014209823016967722 Training loss: 0.0
2025-12-09 10:24:40.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 7564 LR: 0.00014198745124468565 Training loss: 0.0
2025-12-09 10:24:40.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 7565 LR: 0.00014187670837154825 Training loss: 0.0
2025-12-09 10:24:40.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 7566 LR: 0.0001417660015614164 Training loss: 0.0
2025-12-09 10:24:40.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 7567 LR: 0.0001416553308254383 Training loss: 0.0
2025-12-09 10:24:40.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 7568 LR: 0.00014154469617475861 Training loss: 0.0
2025-12-09 10:24:40.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 7569 LR: 0.0001414340976205183 Training loss: 0.0
2025-12-09 10:24:40.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 7570 LR: 0.00014132353517385443 Training loss: 0.0
2025-12-09 10:24:40.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 7571 LR: 0.00014121300884590099 Training loss: 0.0
2025-12-09 10:24:40.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 7572 LR: 0.0001411025186477874 Training loss: 0.0
2025-12-09 10:24:40.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 7573 LR: 0.0001409920645906406 Training loss: 0.0
2025-12-09 10:24:40.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 7574 LR: 0.00014088164668558302 Training loss: 0.0
2025-12-09 10:24:40.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 7575 LR: 0.00014077126494373377 Training loss: 0.0
2025-12-09 10:24:40.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 7576 LR: 0.00014066091937620827 Training loss: 0.0
2025-12-09 10:24:40.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 7577 LR: 0.0001405506099941184 Training loss: 0.0
2025-12-09 10:24:40.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 7578 LR: 0.00014044033680857227 Training loss: 0.0
2025-12-09 10:24:40.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 7579 LR: 0.00014033009983067452 Training loss: 0.0
2025-12-09 10:24:40.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 7580 LR: 0.0001402198990715256 Training loss: 0.0
2025-12-09 10:24:40.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 7581 LR: 0.00014010973454222327 Training loss: 0.0
2025-12-09 10:24:40.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 7582 LR: 0.00013999960625386064 Training loss: 0.0
2025-12-09 10:24:40.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 7583 LR: 0.00013988951421752788 Training loss: 0.0
2025-12-09 10:24:40.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 7584 LR: 0.00013977945844431116 Training loss: 0.0
2025-12-09 10:24:40.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 7585 LR: 0.0001396694389452931 Training loss: 0.0
2025-12-09 10:24:40.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 7586 LR: 0.0001395594557315527 Training loss: 0.0
2025-12-09 10:24:40.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 7587 LR: 0.0001394495088141654 Training loss: 0.0
2025-12-09 10:24:40.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 7588 LR: 0.0001393395982042024 Training loss: 0.0
2025-12-09 10:24:40.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 7589 LR: 0.00013922972391273224 Training loss: 0.0
2025-12-09 10:24:40.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 7590 LR: 0.0001391198859508189 Training loss: 0.0
2025-12-09 10:24:40.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 7591 LR: 0.00013901008432952322 Training loss: 0.0
2025-12-09 10:24:40.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 7592 LR: 0.00013890031905990208 Training loss: 0.0
2025-12-09 10:24:40.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 7593 LR: 0.00013879059015300916 Training loss: 0.0
2025-12-09 10:24:40.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 7594 LR: 0.00013868089761989356 Training loss: 0.0
2025-12-09 10:24:40.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 7595 LR: 0.00013857124147160206 Training loss: 0.0
2025-12-09 10:24:40.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 7596 LR: 0.00013846162171917643 Training loss: 0.0
2025-12-09 10:24:40.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 7597 LR: 0.00013835203837365563 Training loss: 0.0
2025-12-09 10:24:40.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 7598 LR: 0.00013824249144607465 Training loss: 0.0
2025-12-09 10:24:40.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 7599 LR: 0.0001381329809474649 Training loss: 0.0
2025-12-09 10:24:40.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 7600 LR: 0.00013802350688885405 Training loss: 0.0
2025-12-09 10:24:40.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 7601 LR: 0.00013791406928126637 Training loss: 0.0
2025-12-09 10:24:40.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 7602 LR: 0.00013780466813572163 Training loss: 0.0
2025-12-09 10:24:40.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 7603 LR: 0.00013769530346323722 Training loss: 0.0
2025-12-09 10:24:40.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 7604 LR: 0.00013758597527482568 Training loss: 0.0
2025-12-09 10:24:40.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 7605 LR: 0.00013747668358149657 Training loss: 0.0
2025-12-09 10:24:40.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 7606 LR: 0.00013736742839425543 Training loss: 0.0
2025-12-09 10:24:40.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 7607 LR: 0.00013725820972410437 Training loss: 0.0
2025-12-09 10:24:40.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 7608 LR: 0.00013714902758204167 Training loss: 0.0
2025-12-09 10:24:40.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 7609 LR: 0.0001370398819790621 Training loss: 0.0
2025-12-09 10:24:40.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 7610 LR: 0.0001369307729261563 Training loss: 0.0
2025-12-09 10:24:40.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 7611 LR: 0.00013682170043431176 Training loss: 0.0
2025-12-09 10:24:40.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 7612 LR: 0.0001367126645145121 Training loss: 0.0
2025-12-09 10:24:40.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 7613 LR: 0.0001366036651777371 Training loss: 0.0
2025-12-09 10:24:40.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 7614 LR: 0.00013649470243496325 Training loss: 0.0
2025-12-09 10:24:40.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 7615 LR: 0.00013638577629716264 Training loss: 0.0
2025-12-09 10:24:40.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 7616 LR: 0.0001362768867753047 Training loss: 0.0
2025-12-09 10:24:40.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 7617 LR: 0.00013616803388035416 Training loss: 0.0
2025-12-09 10:24:40.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 7618 LR: 0.00013605921762327268 Training loss: 0.0
2025-12-09 10:24:40.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 7619 LR: 0.00013595043801501794 Training loss: 0.0
2025-12-09 10:24:40.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 7620 LR: 0.00013584169506654438 Training loss: 0.0
2025-12-09 10:24:40.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 7621 LR: 0.0001357329887888018 Training loss: 0.0
2025-12-09 10:24:40.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 7622 LR: 0.0001356243191927376 Training loss: 0.0
2025-12-09 10:24:40.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 7623 LR: 0.00013551568628929433 Training loss: 0.0
2025-12-09 10:24:40.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 7624 LR: 0.00013540709008941148 Training loss: 0.0
2025-12-09 10:24:40.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 7625 LR: 0.0001352985306040247 Training loss: 0.0
2025-12-09 10:24:40.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 7626 LR: 0.00013519000784406588 Training loss: 0.0
2025-12-09 10:24:40.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 7627 LR: 0.00013508152182046336 Training loss: 0.0
2025-12-09 10:24:40.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 7628 LR: 0.00013497307254414166 Training loss: 0.0
2025-12-09 10:24:40.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 7629 LR: 0.00013486466002602133 Training loss: 0.0
2025-12-09 10:24:40.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 7630 LR: 0.00013475628427702004 Training loss: 0.0
2025-12-09 10:24:40.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 7631 LR: 0.00013464794530805075 Training loss: 0.0
2025-12-09 10:24:40.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 7632 LR: 0.00013453964313002337 Training loss: 0.0
2025-12-09 10:24:40.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 7633 LR: 0.00013443137775384395 Training loss: 0.0
2025-12-09 10:24:40.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 7634 LR: 0.00013432314919041476 Training loss: 0.0
2025-12-09 10:24:40.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 7635 LR: 0.0001342149574506345 Training loss: 0.0
2025-12-09 10:24:40.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 7636 LR: 0.00013410680254539808 Training loss: 0.0
2025-12-09 10:24:40.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 7637 LR: 0.00013399868448559638 Training loss: 0.0
2025-12-09 10:24:40.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 7638 LR: 0.00013389060328211744 Training loss: 0.0
2025-12-09 10:24:40.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 7639 LR: 0.00013378255894584462 Training loss: 0.0
2025-12-09 10:24:40.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 7640 LR: 0.00013367455148765805 Training loss: 0.0
2025-12-09 10:24:40.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 7641 LR: 0.0001335665809184341 Training loss: 0.0
2025-12-09 10:24:40.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 7642 LR: 0.00013345864724904544 Training loss: 0.0
2025-12-09 10:24:40.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 7643 LR: 0.000133350750490361 Training loss: 0.0
2025-12-09 10:24:40.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 7644 LR: 0.00013324289065324608 Training loss: 0.0
2025-12-09 10:24:40.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 7645 LR: 0.00013313506774856177 Training loss: 0.0
2025-12-09 10:24:40.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 7646 LR: 0.00013302728178716633 Training loss: 0.0
2025-12-09 10:24:40.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 7647 LR: 0.00013291953277991348 Training loss: 0.0
2025-12-09 10:24:40.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 7648 LR: 0.00013281182073765363 Training loss: 0.0
2025-12-09 10:24:40.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 7649 LR: 0.0001327041456712334 Training loss: 0.0
2025-12-09 10:24:40.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 7650 LR: 0.00013259650759149576 Training loss: 0.0
2025-12-09 10:24:40.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 7651 LR: 0.00013248890650927948 Training loss: 0.0
2025-12-09 10:24:40.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 7652 LR: 0.00013238134243542056 Training loss: 0.0
2025-12-09 10:24:40.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 7653 LR: 0.00013227381538075022 Training loss: 0.0
2025-12-09 10:24:40.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 7654 LR: 0.00013216632535609663 Training loss: 0.0
2025-12-09 10:24:40.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 7655 LR: 0.00013205887237228398 Training loss: 0.0
2025-12-09 10:24:40.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 7656 LR: 0.00013195145644013284 Training loss: 0.0
2025-12-09 10:24:40.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 7657 LR: 0.00013184407757045998 Training loss: 0.0
2025-12-09 10:24:40.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 7658 LR: 0.00013173673577407857 Training loss: 0.0
2025-12-09 10:24:40.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 7659 LR: 0.00013162943106179747 Training loss: 0.0
2025-12-09 10:24:40.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 7660 LR: 0.00013152216344442292 Training loss: 0.0
2025-12-09 10:24:40.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 7661 LR: 0.0001314149329327563 Training loss: 0.0
2025-12-09 10:24:40.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 7662 LR: 0.0001313077395375958 Training loss: 0.0
2025-12-09 10:24:40.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 7663 LR: 0.00013120058326973583 Training loss: 0.0
2025-12-09 10:24:40.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 7664 LR: 0.0001310934641399671 Training loss: 0.0
2025-12-09 10:24:40.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 7665 LR: 0.00013098638215907637 Training loss: 0.0
2025-12-09 10:24:40.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 7666 LR: 0.000130879337337847 Training loss: 0.0
2025-12-09 10:24:40.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 7667 LR: 0.00013077232968705804 Training loss: 0.0
2025-12-09 10:24:40.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 7668 LR: 0.00013066535921748561 Training loss: 0.0
2025-12-09 10:24:40.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 7669 LR: 0.00013055842593990132 Training loss: 0.0
2025-12-09 10:24:40.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 7670 LR: 0.00013045152986507336 Training loss: 0.0
2025-12-09 10:24:40.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 7671 LR: 0.00013034467100376623 Training loss: 0.0
2025-12-09 10:24:40.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 7672 LR: 0.00013023784936674066 Training loss: 0.0
2025-12-09 10:24:40.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 7673 LR: 0.0001301310649647535 Training loss: 0.0
2025-12-09 10:24:40.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 7674 LR: 0.00013002431780855816 Training loss: 0.0
2025-12-09 10:24:40.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 7675 LR: 0.00012991760790890362 Training loss: 0.0
2025-12-09 10:24:40.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 7676 LR: 0.0001298109352765361 Training loss: 0.0
2025-12-09 10:24:40.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 7677 LR: 0.00012970429992219712 Training loss: 0.0
2025-12-09 10:24:40.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 7678 LR: 0.000129597701856625 Training loss: 0.0
2025-12-09 10:24:40.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 7679 LR: 0.00012949114109055414 Training loss: 0.0
2025-12-09 10:24:40.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 7680 LR: 0.00012938461763471526 Training loss: 0.0
2025-12-09 10:24:40.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 7681 LR: 0.00012927813149983525 Training loss: 0.0
2025-12-09 10:24:40.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 7682 LR: 0.00012917168269663742 Training loss: 0.0
2025-12-09 10:24:40.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 7683 LR: 0.00012906527123584082 Training loss: 0.0
2025-12-09 10:24:40.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 7684 LR: 0.0001289588971281613 Training loss: 0.0
2025-12-09 10:24:40.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 7685 LR: 0.00012885256038431064 Training loss: 0.0
2025-12-09 10:24:40.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 7686 LR: 0.00012874626101499703 Training loss: 0.0
2025-12-09 10:24:40.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 7687 LR: 0.00012863999903092472 Training loss: 0.0
2025-12-09 10:24:40.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 7688 LR: 0.00012853377444279457 Training loss: 0.0
2025-12-09 10:24:40.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 7689 LR: 0.00012842758726130281 Training loss: 0.0
2025-12-09 10:24:40.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 7690 LR: 0.0001283214374971432 Training loss: 0.0
2025-12-09 10:24:40.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 7691 LR: 0.00012821532516100448 Training loss: 0.0
2025-12-09 10:24:40.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 7692 LR: 0.00012810925026357235 Training loss: 0.0
2025-12-09 10:24:40.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 7693 LR: 0.0001280032128155285 Training loss: 0.0
2025-12-09 10:24:40.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 7694 LR: 0.00012789721282755102 Training loss: 0.0
2025-12-09 10:24:40.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 7695 LR: 0.00012779125031031413 Training loss: 0.0
2025-12-09 10:24:40.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 7696 LR: 0.000127685325274488 Training loss: 0.0
2025-12-09 10:24:40.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 7697 LR: 0.00012757943773073944 Training loss: 0.0
2025-12-09 10:24:40.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 7698 LR: 0.00012747358768973126 Training loss: 0.0
2025-12-09 10:24:40.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 7699 LR: 0.00012736777516212267 Training loss: 0.0
2025-12-09 10:24:40.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 7700 LR: 0.00012726200015856893 Training loss: 0.0
2025-12-09 10:24:40.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 7701 LR: 0.0001271562626897217 Training loss: 0.0
2025-12-09 10:24:40.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 7702 LR: 0.00012705056276622828 Training loss: 0.0
2025-12-09 10:24:40.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 7703 LR: 0.00012694490039873337 Training loss: 0.0
2025-12-09 10:24:40.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 7704 LR: 0.00012683927559787656 Training loss: 0.0
2025-12-09 10:24:40.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 7705 LR: 0.0001267336883742945 Training loss: 0.0
2025-12-09 10:24:40.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 7706 LR: 0.00012662813873861984 Training loss: 0.0
2025-12-09 10:24:40.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 7707 LR: 0.00012652262670148135 Training loss: 0.0
2025-12-09 10:24:40.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 7708 LR: 0.00012641715227350414 Training loss: 0.0
2025-12-09 10:24:40.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 7709 LR: 0.00012631171546530968 Training loss: 0.0
2025-12-09 10:24:40.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 7710 LR: 0.0001262063162875149 Training loss: 0.0
2025-12-09 10:24:40.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 7711 LR: 0.00012610095475073412 Training loss: 0.0
2025-12-09 10:24:40.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 7712 LR: 0.00012599563086557685 Training loss: 0.0
2025-12-09 10:24:40.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 7713 LR: 0.0001258903446426493 Training loss: 0.0
2025-12-09 10:24:40.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 7714 LR: 0.00012578509609255384 Training loss: 0.0
2025-12-09 10:24:40.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 7715 LR: 0.00012567988522588908 Training loss: 0.0
2025-12-09 10:24:40.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 7716 LR: 0.00012557471205324939 Training loss: 0.0
2025-12-09 10:24:40.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 7717 LR: 0.00012546957658522617 Training loss: 0.0
2025-12-09 10:24:40.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 7718 LR: 0.00012536447883240625 Training loss: 0.0
2025-12-09 10:24:40.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 7719 LR: 0.00012525941880537307 Training loss: 0.0
2025-12-09 10:24:40.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 7720 LR: 0.00012515439651470612 Training loss: 0.0
2025-12-09 10:24:40.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 7721 LR: 0.0001250494119709812 Training loss: 0.0
2025-12-09 10:24:40.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 7722 LR: 0.0001249444651847702 Training loss: 0.0
2025-12-09 10:24:40.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 7723 LR: 0.0001248395561666415 Training loss: 0.0
2025-12-09 10:24:40.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 7724 LR: 0.00012473468492715895 Training loss: 0.0
2025-12-09 10:24:40.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 7725 LR: 0.0001246298514768836 Training loss: 0.0
2025-12-09 10:24:40.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 7726 LR: 0.0001245250558263718 Training loss: 0.0
2025-12-09 10:24:40.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 7727 LR: 0.0001244202979861766 Training loss: 0.0
2025-12-09 10:24:40.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 7728 LR: 0.0001243155779668471 Training loss: 0.0
2025-12-09 10:24:40.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 7729 LR: 0.00012421089577892869 Training loss: 0.0
2025-12-09 10:24:40.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 7730 LR: 0.00012410625143296271 Training loss: 0.0
2025-12-09 10:24:40.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 7731 LR: 0.00012400164493948712 Training loss: 0.0
2025-12-09 10:24:40.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 7732 LR: 0.0001238970763090353 Training loss: 0.0
2025-12-09 10:24:40.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 7733 LR: 0.00012379254555213787 Training loss: 0.0
2025-12-09 10:24:40.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 7734 LR: 0.0001236880526793207 Training loss: 0.0
2025-12-09 10:24:40.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 7735 LR: 0.00012358359770110633 Training loss: 0.0
2025-12-09 10:24:40.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 7736 LR: 0.00012347918062801332 Training loss: 0.0
2025-12-09 10:24:40.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 7737 LR: 0.00012337480147055658 Training loss: 0.0
2025-12-09 10:24:40.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 7738 LR: 0.00012327046023924697 Training loss: 0.0
2025-12-09 10:24:40.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 7739 LR: 0.0001231661569445919 Training loss: 0.0
2025-12-09 10:24:40.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 7740 LR: 0.0001230618915970942 Training loss: 0.0
2025-12-09 10:24:40.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 7741 LR: 0.000122957664207254 Training loss: 0.0
2025-12-09 10:24:40.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 7742 LR: 0.00012285347478556652 Training loss: 0.0
2025-12-09 10:24:40.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 7743 LR: 0.00012274932334252386 Training loss: 0.0
2025-12-09 10:24:40.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 7744 LR: 0.000122645209888614 Training loss: 0.0
2025-12-09 10:24:40.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 7745 LR: 0.0001225411344343213 Training loss: 0.0
2025-12-09 10:24:40.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 7746 LR: 0.0001224370969901258 Training loss: 0.0
2025-12-09 10:24:40.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 7747 LR: 0.00012233309756650457 Training loss: 0.0
2025-12-09 10:24:40.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 7748 LR: 0.0001222291361739299 Training loss: 0.0
2025-12-09 10:24:40.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 7749 LR: 0.00012212521282287093 Training loss: 0.0
2025-12-09 10:24:40.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 7750 LR: 0.00012202132752379264 Training loss: 0.0
2025-12-09 10:24:40.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 7751 LR: 0.00012191748028715632 Training loss: 0.0
2025-12-09 10:24:40.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 7752 LR: 0.00012181367112341946 Training loss: 0.0
2025-12-09 10:24:40.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 7753 LR: 0.00012170990004303568 Training loss: 0.0
2025-12-09 10:24:40.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 7754 LR: 0.00012160616705645434 Training loss: 0.0
2025-12-09 10:24:40.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 7755 LR: 0.00012150247217412185 Training loss: 0.0
2025-12-09 10:24:40.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 7756 LR: 0.00012139881540647996 Training loss: 0.0
2025-12-09 10:24:40.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 7757 LR: 0.000121295196763967 Training loss: 0.0
2025-12-09 10:24:40.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 7758 LR: 0.00012119161625701735 Training loss: 0.0
2025-12-09 10:24:40.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 7759 LR: 0.00012108807389606158 Training loss: 0.0
2025-12-09 10:24:40.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 7760 LR: 0.00012098456969152643 Training loss: 0.0
2025-12-09 10:24:40.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 7761 LR: 0.00012088110365383486 Training loss: 0.0
2025-12-09 10:24:40.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 7762 LR: 0.00012077767579340549 Training loss: 0.0
2025-12-09 10:24:40.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 7763 LR: 0.00012067428612065407 Training loss: 0.0
2025-12-09 10:24:40.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 7764 LR: 0.00012057093464599156 Training loss: 0.0
2025-12-09 10:24:40.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 7765 LR: 0.00012046762137982548 Training loss: 0.0
2025-12-09 10:24:40.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 7766 LR: 0.00012036434633255961 Training loss: 0.0
2025-12-09 10:24:40.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 7767 LR: 0.00012026110951459362 Training loss: 0.0
2025-12-09 10:24:40.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 7768 LR: 0.00012015791093632356 Training loss: 0.0
2025-12-09 10:24:40.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 7769 LR: 0.00012005475060814159 Training loss: 0.0
2025-12-09 10:24:40.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 7770 LR: 0.00011995162854043556 Training loss: 0.0
2025-12-09 10:24:40.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 7771 LR: 0.00011984854474359041 Training loss: 0.0
2025-12-09 10:24:40.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 7772 LR: 0.00011974549922798627 Training loss: 0.0
2025-12-09 10:24:40.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 7773 LR: 0.00011964249200399996 Training loss: 0.0
2025-12-09 10:24:40.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 7774 LR: 0.00011953952308200427 Training loss: 0.0
2025-12-09 10:24:40.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 7775 LR: 0.00011943659247236838 Training loss: 0.0
2025-12-09 10:24:40.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 7776 LR: 0.00011933370018545691 Training loss: 0.0
2025-12-09 10:24:40.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 7777 LR: 0.00011923084623163172 Training loss: 0.0
2025-12-09 10:24:40.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 7778 LR: 0.00011912803062124972 Training loss: 0.0
2025-12-09 10:24:40.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 7779 LR: 0.00011902525336466464 Training loss: 0.0
2025-12-09 10:24:40.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 7780 LR: 0.00011892251447222608 Training loss: 0.0
2025-12-09 10:24:40.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 7781 LR: 0.00011881981395427993 Training loss: 0.0
2025-12-09 10:24:40.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 7782 LR: 0.00011871715182116821 Training loss: 0.0
2025-12-09 10:24:40.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 7783 LR: 0.00011861452808322876 Training loss: 0.0
2025-12-09 10:24:40.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 7784 LR: 0.00011851194275079585 Training loss: 0.0
2025-12-09 10:24:40.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 7785 LR: 0.00011840939583419985 Training loss: 0.0
2025-12-09 10:24:40.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 7786 LR: 0.00011830688734376733 Training loss: 0.0
2025-12-09 10:24:40.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 7787 LR: 0.00011820441728982073 Training loss: 0.0
2025-12-09 10:24:40.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 7788 LR: 0.00011810198568267905 Training loss: 0.0
2025-12-09 10:24:40.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 7789 LR: 0.00011799959253265668 Training loss: 0.0
2025-12-09 10:24:40.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 7790 LR: 0.00011789723785006512 Training loss: 0.0
2025-12-09 10:24:40.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 7791 LR: 0.00011779492164521116 Training loss: 0.0
2025-12-09 10:24:40.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 7792 LR: 0.00011769264392839812 Training loss: 0.0
2025-12-09 10:24:40.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 7793 LR: 0.00011759040470992538 Training loss: 0.0
2025-12-09 10:24:40.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 7794 LR: 0.00011748820400008841 Training loss: 0.0
2025-12-09 10:24:40.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 7795 LR: 0.00011738604180917889 Training loss: 0.0
2025-12-09 10:24:40.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 7796 LR: 0.00011728391814748456 Training loss: 0.0
2025-12-09 10:24:40.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 7797 LR: 0.00011718183302528896 Training loss: 0.0
2025-12-09 10:24:40.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 7798 LR: 0.00011707978645287253 Training loss: 0.0
2025-12-09 10:24:40.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 7799 LR: 0.00011697777844051105 Training loss: 0.0
2025-12-09 10:24:40.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 7800 LR: 0.00011687580899847678 Training loss: 0.0
2025-12-09 10:24:40.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 7801 LR: 0.00011677387813703805 Training loss: 0.0
2025-12-09 10:24:40.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 7802 LR: 0.00011667198586645928 Training loss: 0.0
2025-12-09 10:24:40.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 7803 LR: 0.00011657013219700107 Training loss: 0.0
2025-12-09 10:24:40.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 7804 LR: 0.0001164683171389202 Training loss: 0.0
2025-12-09 10:24:40.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 7805 LR: 0.00011636654070246905 Training loss: 0.0
2025-12-09 10:24:40.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 7806 LR: 0.00011626480289789698 Training loss: 0.0
2025-12-09 10:24:40.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 7807 LR: 0.00011616310373544864 Training loss: 0.0
2025-12-09 10:24:40.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 7808 LR: 0.00011606144322536528 Training loss: 0.0
2025-12-09 10:24:40.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 7809 LR: 0.00011595982137788402 Training loss: 0.0
2025-12-09 10:24:40.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 7810 LR: 0.00011585823820323843 Training loss: 0.0
2025-12-09 10:24:40.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 7811 LR: 0.00011575669371165748 Training loss: 0.0
2025-12-09 10:24:40.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 7812 LR: 0.00011565518791336722 Training loss: 0.0
2025-12-09 10:24:40.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 7813 LR: 0.00011555372081858884 Training loss: 0.0
2025-12-09 10:24:40.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 7814 LR: 0.0001154522924375403 Training loss: 0.0
2025-12-09 10:24:40.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 7815 LR: 0.00011535090278043537 Training loss: 0.0
2025-12-09 10:24:40.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 7816 LR: 0.00011524955185748398 Training loss: 0.0
2025-12-09 10:24:40.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 7817 LR: 0.00011514823967889221 Training loss: 0.0
2025-12-09 10:24:40.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 7818 LR: 0.00011504696625486233 Training loss: 0.0
2025-12-09 10:24:40.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 7819 LR: 0.00011494573159559212 Training loss: 0.0
2025-12-09 10:24:40.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 7820 LR: 0.00011484453571127651 Training loss: 0.0
2025-12-09 10:24:40.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 7821 LR: 0.00011474337861210544 Training loss: 0.0
2025-12-09 10:24:40.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 7822 LR: 0.00011464226030826563 Training loss: 0.0
2025-12-09 10:24:40.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 7823 LR: 0.00011454118080993964 Training loss: 0.0
2025-12-09 10:24:40.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 7824 LR: 0.0001144401401273062 Training loss: 0.0
2025-12-09 10:24:40.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 7825 LR: 0.0001143391382705401 Training loss: 0.0
2025-12-09 10:24:40.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 7826 LR: 0.0001142381752498124 Training loss: 0.0
2025-12-09 10:24:40.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 7827 LR: 0.00011413725107528956 Training loss: 0.0
2025-12-09 10:24:40.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 7828 LR: 0.00011403636575713528 Training loss: 0.0
2025-12-09 10:24:40.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 7829 LR: 0.00011393551930550828 Training loss: 0.0
2025-12-09 10:24:40.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 7830 LR: 0.00011383471173056392 Training loss: 0.0
2025-12-09 10:24:40.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 7831 LR: 0.0001137339430424535 Training loss: 0.0
2025-12-09 10:24:40.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 7832 LR: 0.00011363321325132448 Training loss: 0.0
2025-12-09 10:24:40.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 7833 LR: 0.00011353252236732031 Training loss: 0.0
2025-12-09 10:24:40.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 7834 LR: 0.00011343187040058068 Training loss: 0.0
2025-12-09 10:24:40.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 7835 LR: 0.00011333125736124084 Training loss: 0.0
2025-12-09 10:24:40.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 7836 LR: 0.0001132306832594331 Training loss: 0.0
2025-12-09 10:24:40.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 7837 LR: 0.00011313014810528483 Training loss: 0.0
2025-12-09 10:24:40.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 7838 LR: 0.00011302965190892007 Training loss: 0.0
2025-12-09 10:24:40.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 7839 LR: 0.00011292919468045875 Training loss: 0.0
2025-12-09 10:24:40.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 7840 LR: 0.00011282877643001709 Training loss: 0.0
2025-12-09 10:24:40.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 7841 LR: 0.00011272839716770677 Training loss: 0.0
2025-12-09 10:24:40.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 7842 LR: 0.00011262805690363653 Training loss: 0.0
2025-12-09 10:24:40.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 7843 LR: 0.00011252775564791024 Training loss: 0.0
2025-12-09 10:24:40.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 7844 LR: 0.00011242749341062835 Training loss: 0.0
2025-12-09 10:24:40.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 7845 LR: 0.00011232727020188727 Training loss: 0.0
2025-12-09 10:24:40.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 7846 LR: 0.0001122270860317795 Training loss: 0.0
2025-12-09 10:24:40.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 7847 LR: 0.0001121269409103935 Training loss: 0.0
2025-12-09 10:24:40.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 7848 LR: 0.00011202683484781412 Training loss: 0.0
2025-12-09 10:24:40.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 7849 LR: 0.00011192676785412154 Training loss: 0.0
2025-12-09 10:24:40.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 7850 LR: 0.00011182673993939313 Training loss: 0.0
2025-12-09 10:24:40.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 7851 LR: 0.00011172675111370123 Training loss: 0.0
2025-12-09 10:24:40.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 7852 LR: 0.00011162680138711484 Training loss: 0.0
2025-12-09 10:24:40.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 7853 LR: 0.00011152689076969896 Training loss: 0.0
2025-12-09 10:24:40.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 7854 LR: 0.00011142701927151455 Training loss: 0.0
2025-12-09 10:24:40.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 7855 LR: 0.00011132718690261867 Training loss: 0.0
2025-12-09 10:24:40.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 7856 LR: 0.00011122739367306456 Training loss: 0.0
2025-12-09 10:24:40.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 7857 LR: 0.000111127639592901 Training loss: 0.0
2025-12-09 10:24:40.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 7858 LR: 0.00011102792467217377 Training loss: 0.0
2025-12-09 10:24:40.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 7859 LR: 0.00011092824892092374 Training loss: 0.0
2025-12-09 10:24:40.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 7860 LR: 0.0001108286123491884 Training loss: 0.0
2025-12-09 10:24:40.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 7861 LR: 0.00011072901496700111 Training loss: 0.0
2025-12-09 10:24:40.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 7862 LR: 0.0001106294567843914 Training loss: 0.0
2025-12-09 10:24:40.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 7863 LR: 0.00011052993781138477 Training loss: 0.0
2025-12-09 10:24:40.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 7864 LR: 0.00011043045805800284 Training loss: 0.0
2025-12-09 10:24:40.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 7865 LR: 0.00011033101753426283 Training loss: 0.0
2025-12-09 10:24:40.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 7866 LR: 0.00011023161625017903 Training loss: 0.0
2025-12-09 10:24:40.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 7867 LR: 0.00011013225421576078 Training loss: 0.0
2025-12-09 10:24:40.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 7868 LR: 0.00011003293144101356 Training loss: 0.0
2025-12-09 10:24:40.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 7869 LR: 0.0001099336479359398 Training loss: 0.0
2025-12-09 10:24:40.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 7870 LR: 0.00010983440371053682 Training loss: 0.0
2025-12-09 10:24:40.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 7871 LR: 0.00010973519877479876 Training loss: 0.0
2025-12-09 10:24:40.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 7872 LR: 0.0001096360331387155 Training loss: 0.0
2025-12-09 10:24:40.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 7873 LR: 0.00010953690681227302 Training loss: 0.0
2025-12-09 10:24:40.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 7874 LR: 0.00010943781980545332 Training loss: 0.0
2025-12-09 10:24:40.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 7875 LR: 0.00010933877212823462 Training loss: 0.0
2025-12-09 10:24:40.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 7876 LR: 0.00010923976379059059 Training loss: 0.0
2025-12-09 10:24:40.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 7877 LR: 0.00010914079480249194 Training loss: 0.0
2025-12-09 10:24:40.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 7878 LR: 0.00010904186517390446 Training loss: 0.0
2025-12-09 10:24:40.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 7879 LR: 0.00010894297491479043 Training loss: 0.0
2025-12-09 10:24:40.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 7880 LR: 0.00010884412403510813 Training loss: 0.0
2025-12-09 10:24:40.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 7881 LR: 0.00010874531254481185 Training loss: 0.0
2025-12-09 10:24:40.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 7882 LR: 0.00010864654045385185 Training loss: 0.0
2025-12-09 10:24:40.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 7883 LR: 0.00010854780777217466 Training loss: 0.0
2025-12-09 10:24:40.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 7884 LR: 0.00010844911450972228 Training loss: 0.0
2025-12-09 10:24:40.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 7885 LR: 0.00010835046067643361 Training loss: 0.0
2025-12-09 10:24:40.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 7886 LR: 0.00010825184628224272 Training loss: 0.0
2025-12-09 10:24:40.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 7887 LR: 0.00010815327133708014 Training loss: 0.0
2025-12-09 10:24:40.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 7888 LR: 0.00010805473585087244 Training loss: 0.0
2025-12-09 10:24:40.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 7889 LR: 0.00010795623983354214 Training loss: 0.0
2025-12-09 10:24:40.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 7890 LR: 0.00010785778329500772 Training loss: 0.0
2025-12-09 10:24:40.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 7891 LR: 0.00010775936624518396 Training loss: 0.0
2025-12-09 10:24:40.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 7892 LR: 0.000107660988693981 Training loss: 0.0
2025-12-09 10:24:40.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 7893 LR: 0.00010756265065130605 Training loss: 0.0
2025-12-09 10:24:40.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 7894 LR: 0.00010746435212706123 Training loss: 0.0
2025-12-09 10:24:40.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 7895 LR: 0.00010736609313114548 Training loss: 0.0
2025-12-09 10:24:40.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 7896 LR: 0.00010726787367345337 Training loss: 0.0
2025-12-09 10:24:40.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 7897 LR: 0.00010716969376387564 Training loss: 0.0
2025-12-09 10:24:40.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 7898 LR: 0.00010707155341229901 Training loss: 0.0
2025-12-09 10:24:40.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 7899 LR: 0.00010697345262860636 Training loss: 0.0
2025-12-09 10:24:40.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 7900 LR: 0.00010687539142267599 Training loss: 0.0
2025-12-09 10:24:40.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 7901 LR: 0.00010677736980438319 Training loss: 0.0
2025-12-09 10:24:40.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 7902 LR: 0.00010667938778359836 Training loss: 0.0
2025-12-09 10:24:40.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 7903 LR: 0.00010658144537018843 Training loss: 0.0
2025-12-09 10:24:40.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 7904 LR: 0.00010648354257401621 Training loss: 0.0
2025-12-09 10:24:40.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 7905 LR: 0.0001063856794049406 Training loss: 0.0
2025-12-09 10:24:40.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 7906 LR: 0.00010628785587281603 Training loss: 0.0
2025-12-09 10:24:40.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 7907 LR: 0.00010619007198749386 Training loss: 0.0
2025-12-09 10:24:40.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 7908 LR: 0.00010609232775882055 Training loss: 0.0
2025-12-09 10:24:40.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 7909 LR: 0.00010599462319663906 Training loss: 0.0
2025-12-09 10:24:40.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 7910 LR: 0.00010589695831078822 Training loss: 0.0
2025-12-09 10:24:40.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 7911 LR: 0.0001057993331111029 Training loss: 0.0
2025-12-09 10:24:40.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 7912 LR: 0.00010570174760741397 Training loss: 0.0
2025-12-09 10:24:40.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 7913 LR: 0.00010560420180954839 Training loss: 0.0
2025-12-09 10:24:40.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 7914 LR: 0.00010550669572732863 Training loss: 0.0
2025-12-09 10:24:40.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 7915 LR: 0.00010540922937057407 Training loss: 0.0
2025-12-09 10:24:40.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 7916 LR: 0.00010531180274909919 Training loss: 0.0
2025-12-09 10:24:40.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 7917 LR: 0.00010521441587271497 Training loss: 0.0
2025-12-09 10:24:40.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 7918 LR: 0.00010511706875122822 Training loss: 0.0
2025-12-09 10:24:40.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 7919 LR: 0.00010501976139444191 Training loss: 0.0
2025-12-09 10:24:40.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 7920 LR: 0.00010492249381215479 Training loss: 0.0
2025-12-09 10:24:40.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 7921 LR: 0.00010482526601416187 Training loss: 0.0
2025-12-09 10:24:40.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 7922 LR: 0.00010472807801025358 Training loss: 0.0
2025-12-09 10:24:40.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 7923 LR: 0.00010463092981021732 Training loss: 0.0
2025-12-09 10:24:40.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 7924 LR: 0.00010453382142383544 Training loss: 0.0
2025-12-09 10:24:40.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 7925 LR: 0.00010443675286088694 Training loss: 0.0
2025-12-09 10:24:40.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 7926 LR: 0.00010433972413114663 Training loss: 0.0
2025-12-09 10:24:40.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 7927 LR: 0.00010424273524438521 Training loss: 0.0
2025-12-09 10:24:40.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 7928 LR: 0.00010414578621036958 Training loss: 0.0
2025-12-09 10:24:40.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 7929 LR: 0.0001040488770388625 Training loss: 0.0
2025-12-09 10:24:40.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 7930 LR: 0.00010395200773962248 Training loss: 0.0
2025-12-09 10:24:40.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 7931 LR: 0.00010385517832240471 Training loss: 0.0
2025-12-09 10:24:40.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 7932 LR: 0.00010375838879695948 Training loss: 0.0
2025-12-09 10:24:40.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 7933 LR: 0.00010366163917303367 Training loss: 0.0
2025-12-09 10:24:40.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 7934 LR: 0.00010356492946036994 Training loss: 0.0
2025-12-09 10:24:40.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 7935 LR: 0.0001034682596687071 Training loss: 0.0
2025-12-09 10:24:40.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 7936 LR: 0.00010337162980777937 Training loss: 0.0
2025-12-09 10:24:40.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 7937 LR: 0.00010327503988731795 Training loss: 0.0
2025-12-09 10:24:40.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 7938 LR: 0.00010317848991704909 Training loss: 0.0
2025-12-09 10:24:40.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 7939 LR: 0.00010308197990669538 Training loss: 0.0
2025-12-09 10:24:40.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 7940 LR: 0.00010298550986597544 Training loss: 0.0
2025-12-09 10:24:40.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 7941 LR: 0.00010288907980460377 Training loss: 0.0
2025-12-09 10:24:40.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 7942 LR: 0.0001027926897322909 Training loss: 0.0
2025-12-09 10:24:40.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 7943 LR: 0.00010269633965874348 Training loss: 0.0
2025-12-09 10:24:40.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 7944 LR: 0.00010260002959366348 Training loss: 0.0
2025-12-09 10:24:40.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 7945 LR: 0.0001025037595467499 Training loss: 0.0
2025-12-09 10:24:40.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 7946 LR: 0.00010240752952769678 Training loss: 0.0
2025-12-09 10:24:40.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 7947 LR: 0.00010231133954619448 Training loss: 0.0
2025-12-09 10:24:40.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 7948 LR: 0.00010221518961192944 Training loss: 0.0
2025-12-09 10:24:40.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 7949 LR: 0.0001021190797345839 Training loss: 0.0
2025-12-09 10:24:40.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 7950 LR: 0.00010202300992383618 Training loss: 0.0
2025-12-09 10:24:40.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 7951 LR: 0.00010192698018936059 Training loss: 0.0
2025-12-09 10:24:40.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 7952 LR: 0.00010183099054082706 Training loss: 0.0
2025-12-09 10:24:40.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 7953 LR: 0.00010173504098790188 Training loss: 0.0
2025-12-09 10:24:40.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 7954 LR: 0.00010163913154024723 Training loss: 0.0
2025-12-09 10:24:40.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 7955 LR: 0.00010154326220752108 Training loss: 0.0
2025-12-09 10:24:40.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 7956 LR: 0.00010144743299937764 Training loss: 0.0
2025-12-09 10:24:40.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 7957 LR: 0.00010135164392546659 Training loss: 0.0
2025-12-09 10:24:40.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 7958 LR: 0.00010125589499543431 Training loss: 0.0
2025-12-09 10:24:40.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 7959 LR: 0.00010116018621892236 Training loss: 0.0
2025-12-09 10:24:40.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 7960 LR: 0.00010106451760556878 Training loss: 0.0
2025-12-09 10:24:40.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 7961 LR: 0.00010096888916500736 Training loss: 0.0
2025-12-09 10:24:40.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 7962 LR: 0.00010087330090686797 Training loss: 0.0
2025-12-09 10:24:40.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 7963 LR: 0.00010077775284077601 Training loss: 0.0
2025-12-09 10:24:40.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 7964 LR: 0.00010068224497635369 Training loss: 0.0
2025-12-09 10:24:40.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 7965 LR: 0.00010058677732321825 Training loss: 0.0
2025-12-09 10:24:40.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 7966 LR: 0.00010049134989098336 Training loss: 0.0
2025-12-09 10:24:40.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 7967 LR: 0.00010039596268925866 Training loss: 0.0
2025-12-09 10:24:40.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 7968 LR: 0.00010030061572764953 Training loss: 0.0
2025-12-09 10:24:40.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 7969 LR: 0.00010020530901575753 Training loss: 0.0
2025-12-09 10:24:40.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 7970 LR: 0.00010011004256318007 Training loss: 0.0
2025-12-09 10:24:40.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 7971 LR: 0.0001000148163795101 Training loss: 0.0
2025-12-09 10:24:40.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 7972 LR: 9.991963047433744e-05 Training loss: 0.0
2025-12-09 10:24:40.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 7973 LR: 9.982448485724693e-05 Training loss: 0.0
2025-12-09 10:24:40.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 7974 LR: 9.972937953781985e-05 Training loss: 0.0
2025-12-09 10:24:40.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 7975 LR: 9.963431452563332e-05 Training loss: 0.0
2025-12-09 10:24:40.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 7976 LR: 9.953928983026028e-05 Training loss: 0.0
2025-12-09 10:24:40.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 7977 LR: 9.944430546126986e-05 Training loss: 0.0
2025-12-09 10:24:40.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 7978 LR: 9.934936142822704e-05 Training loss: 0.0
2025-12-09 10:24:40.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 7979 LR: 9.925445774069231e-05 Training loss: 0.0
2025-12-09 10:24:40.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 7980 LR: 9.915959440822298e-05 Training loss: 0.0
2025-12-09 10:24:40.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 7981 LR: 9.906477144037141e-05 Training loss: 0.0
2025-12-09 10:24:40.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 7982 LR: 9.896998884668634e-05 Training loss: 0.0
2025-12-09 10:24:40.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 7983 LR: 9.887524663671244e-05 Training loss: 0.0
2025-12-09 10:24:40.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 7984 LR: 9.878054481999027e-05 Training loss: 0.0
2025-12-09 10:24:40.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 7985 LR: 9.868588340605621e-05 Training loss: 0.0
2025-12-09 10:24:40.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 7986 LR: 9.859126240444282e-05 Training loss: 0.0
2025-12-09 10:24:40.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 7987 LR: 9.849668182467808e-05 Training loss: 0.0
2025-12-09 10:24:40.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 7988 LR: 9.84021416762868e-05 Training loss: 0.0
2025-12-09 10:24:40.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 7989 LR: 9.830764196878872e-05 Training loss: 0.0
2025-12-09 10:24:40.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 7990 LR: 9.821318271170005e-05 Training loss: 0.0
2025-12-09 10:24:40.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 7991 LR: 9.811876391453295e-05 Training loss: 0.0
2025-12-09 10:24:40.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 7992 LR: 9.802438558679528e-05 Training loss: 0.0
2025-12-09 10:24:40.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 7993 LR: 9.793004773799103e-05 Training loss: 0.0
2025-12-09 10:24:40.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 7994 LR: 9.783575037762005e-05 Training loss: 0.0
2025-12-09 10:24:40.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 7995 LR: 9.774149351517775e-05 Training loss: 0.0
2025-12-09 10:24:40.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 7996 LR: 9.764727716015637e-05 Training loss: 0.0
2025-12-09 10:24:40.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 7997 LR: 9.755310132204298e-05 Training loss: 0.0
2025-12-09 10:24:40.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 7998 LR: 9.745896601032128e-05 Training loss: 0.0
2025-12-09 10:24:40.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 7999 LR: 9.736487123447069e-05 Training loss: 0.0
2025-12-09 10:24:40.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 8000 LR: 9.727081700396667e-05 Training loss: 0.0
2025-12-09 10:24:40.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 8001 LR: 9.717680332828016e-05 Training loss: 0.0
2025-12-09 10:24:40.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 8002 LR: 9.708283021687875e-05 Training loss: 0.0
2025-12-09 10:24:40.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 8003 LR: 9.698889767922514e-05 Training loss: 0.0
2025-12-09 10:24:40.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 8004 LR: 9.689500572477855e-05 Training loss: 0.0
2025-12-09 10:24:40.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 8005 LR: 9.680115436299386e-05 Training loss: 0.0
2025-12-09 10:24:40.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 8006 LR: 9.67073436033219e-05 Training loss: 0.0
2025-12-09 10:24:40.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 8007 LR: 9.661357345520938e-05 Training loss: 0.0
2025-12-09 10:24:40.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 8008 LR: 9.651984392809914e-05 Training loss: 0.0
2025-12-09 10:24:40.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 8009 LR: 9.642615503142926e-05 Training loss: 0.0
2025-12-09 10:24:40.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 8010 LR: 9.633250677463484e-05 Training loss: 0.0
2025-12-09 10:24:40.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 8011 LR: 9.623889916714579e-05 Training loss: 0.0
2025-12-09 10:24:40.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 8012 LR: 9.614533221838856e-05 Training loss: 0.0
2025-12-09 10:24:40.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 8013 LR: 9.605180593778529e-05 Training loss: 0.0
2025-12-09 10:24:40.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 8014 LR: 9.595832033475416e-05 Training loss: 0.0
2025-12-09 10:24:40.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 8015 LR: 9.586487541870908e-05 Training loss: 0.0
2025-12-09 10:24:40.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 8016 LR: 9.57714711990601e-05 Training loss: 0.0
2025-12-09 10:24:40.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 8017 LR: 9.567810768521268e-05 Training loss: 0.0
2025-12-09 10:24:40.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 8018 LR: 9.558478488656903e-05 Training loss: 0.0
2025-12-09 10:24:40.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 8019 LR: 9.549150281252633e-05 Training loss: 0.0
2025-12-09 10:24:40.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 8020 LR: 9.539826147247821e-05 Training loss: 0.0
2025-12-09 10:24:40.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 8021 LR: 9.530506087581408e-05 Training loss: 0.0
2025-12-09 10:24:40.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 8022 LR: 9.521190103191929e-05 Training loss: 0.0
2025-12-09 10:24:40.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 8023 LR: 9.511878195017499e-05 Training loss: 0.0
2025-12-09 10:24:40.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 8024 LR: 9.502570363995838e-05 Training loss: 0.0
2025-12-09 10:24:40.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 8025 LR: 9.493266611064205e-05 Training loss: 0.0
2025-12-09 10:24:40.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 8026 LR: 9.483966937159544e-05 Training loss: 0.0
2025-12-09 10:24:40.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 8027 LR: 9.474671343218294e-05 Training loss: 0.0
2025-12-09 10:24:40.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 8028 LR: 9.465379830176523e-05 Training loss: 0.0
2025-12-09 10:24:40.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 8029 LR: 9.4560923989699e-05 Training loss: 0.0
2025-12-09 10:24:40.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 8030 LR: 9.446809050533678e-05 Training loss: 0.0
2025-12-09 10:24:40.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 8031 LR: 9.437529785802646e-05 Training loss: 0.0
2025-12-09 10:24:40.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 8032 LR: 9.428254605711278e-05 Training loss: 0.0
2025-12-09 10:24:40.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 8033 LR: 9.418983511193551e-05 Training loss: 0.0
2025-12-09 10:24:40.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 8034 LR: 9.409716503183075e-05 Training loss: 0.0
2025-12-09 10:24:40.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 8035 LR: 9.400453582613034e-05 Training loss: 0.0
2025-12-09 10:24:40.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 8036 LR: 9.39119475041621e-05 Training loss: 0.0
2025-12-09 10:24:40.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 8037 LR: 9.381940007524975e-05 Training loss: 0.0
2025-12-09 10:24:40.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 8038 LR: 9.372689354871255e-05 Training loss: 0.0
2025-12-09 10:24:40.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 8039 LR: 9.363442793386607e-05 Training loss: 0.0
2025-12-09 10:24:40.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 8040 LR: 9.354200324002154e-05 Training loss: 0.0
2025-12-09 10:24:40.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 8041 LR: 9.344961947648623e-05 Training loss: 0.0
2025-12-09 10:24:40.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 8042 LR: 9.335727665256305e-05 Training loss: 0.0
2025-12-09 10:24:40.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 8043 LR: 9.326497477755114e-05 Training loss: 0.0
2025-12-09 10:24:40.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 8044 LR: 9.317271386074488e-05 Training loss: 0.0
2025-12-09 10:24:40.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 8045 LR: 9.308049391143547e-05 Training loss: 0.0
2025-12-09 10:24:40.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 8046 LR: 9.298831493890908e-05 Training loss: 0.0
2025-12-09 10:24:40.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 8047 LR: 9.289617695244818e-05 Training loss: 0.0
2025-12-09 10:24:40.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 8048 LR: 9.280407996133116e-05 Training loss: 0.0
2025-12-09 10:24:40.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 8049 LR: 9.271202397483213e-05 Training loss: 0.0
2025-12-09 10:24:40.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 8050 LR: 9.262000900222117e-05 Training loss: 0.0
2025-12-09 10:24:40.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 8051 LR: 9.25280350527643e-05 Training loss: 0.0
2025-12-09 10:24:40.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 8052 LR: 9.243610213572285e-05 Training loss: 0.0
2025-12-09 10:24:40.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 8053 LR: 9.234421026035506e-05 Training loss: 0.0
2025-12-09 10:24:40.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 8054 LR: 9.225235943591399e-05 Training loss: 0.0
2025-12-09 10:24:40.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 8055 LR: 9.216054967164917e-05 Training loss: 0.0
2025-12-09 10:24:40.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 8056 LR: 9.206878097680582e-05 Training loss: 0.0
2025-12-09 10:24:40.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 8057 LR: 9.197705336062517e-05 Training loss: 0.0
2025-12-09 10:24:40.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 8058 LR: 9.188536683234388e-05 Training loss: 0.0
2025-12-09 10:24:40.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 8059 LR: 9.179372140119524e-05 Training loss: 0.0
2025-12-09 10:24:40.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 8060 LR: 9.170211707640753e-05 Training loss: 0.0
2025-12-09 10:24:40.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 8061 LR: 9.161055386720546e-05 Training loss: 0.0
2025-12-09 10:24:40.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 8062 LR: 9.151903178280946e-05 Training loss: 0.0
2025-12-09 10:24:40.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 8063 LR: 9.142755083243575e-05 Training loss: 0.0
2025-12-09 10:24:40.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 8064 LR: 9.133611102529655e-05 Training loss: 0.0
2025-12-09 10:24:40.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 8065 LR: 9.12447123705999e-05 Training loss: 0.0
2025-12-09 10:24:40.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 8066 LR: 9.115335487754922e-05 Training loss: 0.0
2025-12-09 10:24:40.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 8067 LR: 9.106203855534478e-05 Training loss: 0.0
2025-12-09 10:24:40.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 8068 LR: 9.097076341318178e-05 Training loss: 0.0
2025-12-09 10:24:40.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 8069 LR: 9.087952946025175e-05 Training loss: 0.0
2025-12-09 10:24:40.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 8070 LR: 9.078833670574182e-05 Training loss: 0.0
2025-12-09 10:24:40.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 8071 LR: 9.069718515883523e-05 Training loss: 0.0
2025-12-09 10:24:40.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 8072 LR: 9.060607482871092e-05 Training loss: 0.0
2025-12-09 10:24:40.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 8073 LR: 9.051500572454375e-05 Training loss: 0.0
2025-12-09 10:24:40.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 8074 LR: 9.042397785550405e-05 Training loss: 0.0
2025-12-09 10:24:40.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 8075 LR: 9.033299123075884e-05 Training loss: 0.0
2025-12-09 10:24:40.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 8076 LR: 9.02420458594701e-05 Training loss: 0.0
2025-12-09 10:24:40.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 8077 LR: 9.015114175079614e-05 Training loss: 0.0
2025-12-09 10:24:40.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 8078 LR: 9.006027891389095e-05 Training loss: 0.0
2025-12-09 10:24:40.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 8079 LR: 8.996945735790446e-05 Training loss: 0.0
2025-12-09 10:24:40.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 8080 LR: 8.987867709198239e-05 Training loss: 0.0
2025-12-09 10:24:40.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 8081 LR: 8.978793812526647e-05 Training loss: 0.0
2025-12-09 10:24:40.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 8082 LR: 8.96972404668937e-05 Training loss: 0.0
2025-12-09 10:24:40.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 8083 LR: 8.960658412599781e-05 Training loss: 0.0
2025-12-09 10:24:40.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 8084 LR: 8.951596911170756e-05 Training loss: 0.0
2025-12-09 10:24:40.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 8085 LR: 8.942539543314798e-05 Training loss: 0.0
2025-12-09 10:24:40.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 8086 LR: 8.93348630994399e-05 Training loss: 0.0
2025-12-09 10:24:40.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 8087 LR: 8.924437211969983e-05 Training loss: 0.0
2025-12-09 10:24:40.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 8088 LR: 8.915392250304022e-05 Training loss: 0.0
2025-12-09 10:24:40.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 8089 LR: 8.906351425856951e-05 Training loss: 0.0
2025-12-09 10:24:40.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 8090 LR: 8.897314739539159e-05 Training loss: 0.0
2025-12-09 10:24:40.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 8091 LR: 8.888282192260644e-05 Training loss: 0.0
2025-12-09 10:24:40.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 8092 LR: 8.87925378493099e-05 Training loss: 0.0
2025-12-09 10:24:40.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 8093 LR: 8.870229518459349e-05 Training loss: 0.0
2025-12-09 10:24:40.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 8094 LR: 8.861209393754477e-05 Training loss: 0.0
2025-12-09 10:24:40.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 8095 LR: 8.852193411724702e-05 Training loss: 0.0
2025-12-09 10:24:40.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 8096 LR: 8.843181573277903e-05 Training loss: 0.0
2025-12-09 10:24:40.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 8097 LR: 8.834173879321617e-05 Training loss: 0.0
2025-12-09 10:24:40.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 8098 LR: 8.825170330762878e-05 Training loss: 0.0
2025-12-09 10:24:40.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 8099 LR: 8.816170928508365e-05 Training loss: 0.0
2025-12-09 10:24:40.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 8100 LR: 8.807175673464313e-05 Training loss: 0.0
2025-12-09 10:24:40.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 8101 LR: 8.798184566536538e-05 Training loss: 0.0
2025-12-09 10:24:40.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 8102 LR: 8.789197608630456e-05 Training loss: 0.0
2025-12-09 10:24:40.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 8103 LR: 8.78021480065106e-05 Training loss: 0.0
2025-12-09 10:24:40.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 8104 LR: 8.771236143502876e-05 Training loss: 0.0
2025-12-09 10:24:40.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 8105 LR: 8.762261638090114e-05 Training loss: 0.0
2025-12-09 10:24:40.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 8106 LR: 8.753291285316456e-05 Training loss: 0.0
2025-12-09 10:24:40.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 8107 LR: 8.744325086085247e-05 Training loss: 0.0
2025-12-09 10:24:40.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 8108 LR: 8.735363041299366e-05 Training loss: 0.0
2025-12-09 10:24:40.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 8109 LR: 8.7264051518613e-05 Training loss: 0.0
2025-12-09 10:24:40.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 8110 LR: 8.717451418673105e-05 Training loss: 0.0
2025-12-09 10:24:40.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 8111 LR: 8.708501842636441e-05 Training loss: 0.0
2025-12-09 10:24:40.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 8112 LR: 8.699556424652478e-05 Training loss: 0.0
2025-12-09 10:24:40.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 8113 LR: 8.690615165622085e-05 Training loss: 0.0
2025-12-09 10:24:40.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 8114 LR: 8.681678066445598e-05 Training loss: 0.0
2025-12-09 10:24:40.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 8115 LR: 8.672745128022997e-05 Training loss: 0.0
2025-12-09 10:24:40.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 8116 LR: 8.663816351253834e-05 Training loss: 0.0
2025-12-09 10:24:40.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 8117 LR: 8.654891737037235e-05 Training loss: 0.0
2025-12-09 10:24:40.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 8118 LR: 8.645971286271903e-05 Training loss: 0.0
2025-12-09 10:24:40.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 8119 LR: 8.637054999856148e-05 Training loss: 0.0
2025-12-09 10:24:40.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 8120 LR: 8.628142878687795e-05 Training loss: 0.0
2025-12-09 10:24:40.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 8121 LR: 8.619234923664349e-05 Training loss: 0.0
2025-12-09 10:24:40.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 8122 LR: 8.610331135682808e-05 Training loss: 0.0
2025-12-09 10:24:40.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 8123 LR: 8.601431515639768e-05 Training loss: 0.0
2025-12-09 10:24:40.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 8124 LR: 8.592536064431467e-05 Training loss: 0.0
2025-12-09 10:24:40.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 8125 LR: 8.583644782953643e-05 Training loss: 0.0
2025-12-09 10:24:40.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 8126 LR: 8.574757672101651e-05 Training loss: 0.0
2025-12-09 10:24:40.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 8127 LR: 8.565874732770429e-05 Training loss: 0.0
2025-12-09 10:24:40.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 8128 LR: 8.556995965854486e-05 Training loss: 0.0
2025-12-09 10:24:40.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 8129 LR: 8.548121372247918e-05 Training loss: 0.0
2025-12-09 10:24:40.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 8130 LR: 8.539250952844401e-05 Training loss: 0.0
2025-12-09 10:24:40.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 8131 LR: 8.53038470853716e-05 Training loss: 0.0
2025-12-09 10:24:40.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 8132 LR: 8.521522640219065e-05 Training loss: 0.0
2025-12-09 10:24:40.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 8133 LR: 8.512664748782495e-05 Training loss: 0.0
2025-12-09 10:24:40.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 8134 LR: 8.503811035119453e-05 Training loss: 0.0
2025-12-09 10:24:40.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 8135 LR: 8.494961500121501e-05 Training loss: 0.0
2025-12-09 10:24:40.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 8136 LR: 8.486116144679789e-05 Training loss: 0.0
2025-12-09 10:24:40.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 8137 LR: 8.477274969685045e-05 Training loss: 0.0
2025-12-09 10:24:40.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 8138 LR: 8.468437976027587e-05 Training loss: 0.0
2025-12-09 10:24:40.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 8139 LR: 8.459605164597267e-05 Training loss: 0.0
2025-12-09 10:24:40.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 8140 LR: 8.450776536283594e-05 Training loss: 0.0
2025-12-09 10:24:40.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 8141 LR: 8.441952091975574e-05 Training loss: 0.0
2025-12-09 10:24:40.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 8142 LR: 8.433131832561842e-05 Training loss: 0.0
2025-12-09 10:24:40.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 8143 LR: 8.424315758930596e-05 Training loss: 0.0
2025-12-09 10:24:40.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 8144 LR: 8.415503871969615e-05 Training loss: 0.0
2025-12-09 10:24:40.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 8145 LR: 8.406696172566259e-05 Training loss: 0.0
2025-12-09 10:24:40.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 8146 LR: 8.39789266160747e-05 Training loss: 0.0
2025-12-09 10:24:40.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 8147 LR: 8.389093339979726e-05 Training loss: 0.0
2025-12-09 10:24:40.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 8148 LR: 8.380298208569171e-05 Training loss: 0.0
2025-12-09 10:24:40.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 8149 LR: 8.371507268261436e-05 Training loss: 0.0
2025-12-09 10:24:40.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 8150 LR: 8.36272051994178e-05 Training loss: 0.0
2025-12-09 10:24:40.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 8151 LR: 8.353937964495028e-05 Training loss: 0.0
2025-12-09 10:24:40.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 8152 LR: 8.345159602805597e-05 Training loss: 0.0
2025-12-09 10:24:40.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 8153 LR: 8.336385435757426e-05 Training loss: 0.0
2025-12-09 10:24:40.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 8154 LR: 8.327615464234128e-05 Training loss: 0.0
2025-12-09 10:24:40.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 8155 LR: 8.318849689118802e-05 Training loss: 0.0
2025-12-09 10:24:40.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 8156 LR: 8.310088111294167e-05 Training loss: 0.0
2025-12-09 10:24:40.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 8157 LR: 8.30133073164252e-05 Training loss: 0.0
2025-12-09 10:24:40.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 8158 LR: 8.292577551045732e-05 Training loss: 0.0
2025-12-09 10:24:40.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 8159 LR: 8.283828570385238e-05 Training loss: 0.0
2025-12-09 10:24:40.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 8160 LR: 8.275083790542082e-05 Training loss: 0.0
2025-12-09 10:24:40.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 8161 LR: 8.26634321239682e-05 Training loss: 0.0
2025-12-09 10:24:40.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 8162 LR: 8.257606836829679e-05 Training loss: 0.0
2025-12-09 10:24:40.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 8163 LR: 8.248874664720374e-05 Training loss: 0.0
2025-12-09 10:24:40.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 8164 LR: 8.240146696948253e-05 Training loss: 0.0
2025-12-09 10:24:40.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 8165 LR: 8.231422934392213e-05 Training loss: 0.0
2025-12-09 10:24:40.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 8166 LR: 8.22270337793074e-05 Training loss: 0.0
2025-12-09 10:24:40.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 8167 LR: 8.213988028441893e-05 Training loss: 0.0
2025-12-09 10:24:40.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 8168 LR: 8.205276886803325e-05 Training loss: 0.0
2025-12-09 10:24:40.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 8169 LR: 8.196569953892202e-05 Training loss: 0.0
2025-12-09 10:24:40.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 8170 LR: 8.187867230585367e-05 Training loss: 0.0
2025-12-09 10:24:40.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 8171 LR: 8.179168717759144e-05 Training loss: 0.0
2025-12-09 10:24:40.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 8172 LR: 8.170474416289492e-05 Training loss: 0.0
2025-12-09 10:24:40.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 8173 LR: 8.161784327051918e-05 Training loss: 0.0
2025-12-09 10:24:40.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 8174 LR: 8.153098450921515e-05 Training loss: 0.0
2025-12-09 10:24:40.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 8175 LR: 8.144416788772957e-05 Training loss: 0.0
2025-12-09 10:24:40.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 8176 LR: 8.135739341480497e-05 Training loss: 0.0
2025-12-09 10:24:40.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 8177 LR: 8.127066109917908e-05 Training loss: 0.0
2025-12-09 10:24:40.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 8178 LR: 8.118397094958646e-05 Training loss: 0.0
2025-12-09 10:24:40.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 8179 LR: 8.109732297475635e-05 Training loss: 0.0
2025-12-09 10:24:40.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 8180 LR: 8.101071718341441e-05 Training loss: 0.0
2025-12-09 10:24:40.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 8181 LR: 8.092415358428174e-05 Training loss: 0.0
2025-12-09 10:24:40.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 8182 LR: 8.083763218607549e-05 Training loss: 0.0
2025-12-09 10:24:40.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 8183 LR: 8.075115299750796e-05 Training loss: 0.0
2025-12-09 10:24:40.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 8184 LR: 8.066471602728804e-05 Training loss: 0.0
2025-12-09 10:24:40.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 8185 LR: 8.057832128411968e-05 Training loss: 0.0
2025-12-09 10:24:40.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 8186 LR: 8.04919687767029e-05 Training loss: 0.0
2025-12-09 10:24:40.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 8187 LR: 8.040565851373333e-05 Training loss: 0.0
2025-12-09 10:24:40.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 8188 LR: 8.031939050390252e-05 Training loss: 0.0
2025-12-09 10:24:40.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 8189 LR: 8.023316475589754e-05 Training loss: 0.0
2025-12-09 10:24:40.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 8190 LR: 8.014698127840153e-05 Training loss: 0.0
2025-12-09 10:24:40.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 8191 LR: 8.006084008009284e-05 Training loss: 0.0
2025-12-09 10:24:40.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 8192 LR: 7.997474116964626e-05 Training loss: 0.0
2025-12-09 10:24:40.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 8193 LR: 7.988868455573162e-05 Training loss: 0.0
2025-12-09 10:24:40.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 8194 LR: 7.980267024701493e-05 Training loss: 0.0
2025-12-09 10:24:40.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 8195 LR: 7.971669825215788e-05 Training loss: 0.0
2025-12-09 10:24:40.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 8196 LR: 7.963076857981783e-05 Training loss: 0.0
2025-12-09 10:24:40.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 8197 LR: 7.954488123864783e-05 Training loss: 0.0
2025-12-09 10:24:40.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 8198 LR: 7.945903623729695e-05 Training loss: 0.0
2025-12-09 10:24:40.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 8199 LR: 7.937323358440934e-05 Training loss: 0.0
2025-12-09 10:24:40.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 8200 LR: 7.92874732886259e-05 Training loss: 0.0
2025-12-09 10:24:40.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 8201 LR: 7.92017553585822e-05 Training loss: 0.0
2025-12-09 10:24:40.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 8202 LR: 7.911607980291024e-05 Training loss: 0.0
2025-12-09 10:24:40.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 8203 LR: 7.903044663023756e-05 Training loss: 0.0
2025-12-09 10:24:40.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 8204 LR: 7.894485584918737e-05 Training loss: 0.0
2025-12-09 10:24:40.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 8205 LR: 7.885930746837866e-05 Training loss: 0.0
2025-12-09 10:24:40.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 8206 LR: 7.877380149642626e-05 Training loss: 0.0
2025-12-09 10:24:40.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 8207 LR: 7.868833794194047e-05 Training loss: 0.0
2025-12-09 10:24:40.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 8208 LR: 7.86029168135275e-05 Training loss: 0.0
2025-12-09 10:24:40.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 8209 LR: 7.851753811978923e-05 Training loss: 0.0
2025-12-09 10:24:40.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 8210 LR: 7.843220186932338e-05 Training loss: 0.0
2025-12-09 10:24:40.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 8211 LR: 7.834690807072342e-05 Training loss: 0.0
2025-12-09 10:24:40.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 8212 LR: 7.826165673257796e-05 Training loss: 0.0
2025-12-09 10:24:40.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 8213 LR: 7.817644786347244e-05 Training loss: 0.0
2025-12-09 10:24:40.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 8214 LR: 7.809128147198691e-05 Training loss: 0.0
2025-12-09 10:24:40.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 8215 LR: 7.800615756669782e-05 Training loss: 0.0
2025-12-09 10:24:40.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 8216 LR: 7.792107615617711e-05 Training loss: 0.0
2025-12-09 10:24:40.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 8217 LR: 7.783603724899258e-05 Training loss: 0.0
2025-12-09 10:24:40.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 8218 LR: 7.775104085370732e-05 Training loss: 0.0
2025-12-09 10:24:40.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 8219 LR: 7.766608697888095e-05 Training loss: 0.0
2025-12-09 10:24:40.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 8220 LR: 7.758117563306793e-05 Training loss: 0.0
2025-12-09 10:24:40.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 8221 LR: 7.749630682481895e-05 Training loss: 0.0
2025-12-09 10:24:40.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 8222 LR: 7.741148056268033e-05 Training loss: 0.0
2025-12-09 10:24:40.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 8223 LR: 7.732669685519406e-05 Training loss: 0.0
2025-12-09 10:24:40.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 8224 LR: 7.724195571089787e-05 Training loss: 0.0
2025-12-09 10:24:40.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 8225 LR: 7.715725713832527e-05 Training loss: 0.0
2025-12-09 10:24:40.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 8226 LR: 7.707260114600506e-05 Training loss: 0.0
2025-12-09 10:24:40.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 8227 LR: 7.698798774246257e-05 Training loss: 0.0
2025-12-09 10:24:40.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 8228 LR: 7.690341693621805e-05 Training loss: 0.0
2025-12-09 10:24:40.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 8229 LR: 7.681888873578785e-05 Training loss: 0.0
2025-12-09 10:24:40.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 8230 LR: 7.673440314968399e-05 Training loss: 0.0
2025-12-09 10:24:40.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 8231 LR: 7.664996018641412e-05 Training loss: 0.0
2025-12-09 10:24:40.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 8232 LR: 7.656555985448171e-05 Training loss: 0.0
2025-12-09 10:24:40.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 8233 LR: 7.648120216238597e-05 Training loss: 0.0
2025-12-09 10:24:40.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 8234 LR: 7.639688711862131e-05 Training loss: 0.0
2025-12-09 10:24:40.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 8235 LR: 7.631261473167878e-05 Training loss: 0.0
2025-12-09 10:24:40.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 8236 LR: 7.62283850100442e-05 Training loss: 0.0
2025-12-09 10:24:40.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 8237 LR: 7.614419796219974e-05 Training loss: 0.0
2025-12-09 10:24:40.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 8238 LR: 7.606005359662288e-05 Training loss: 0.0
2025-12-09 10:24:40.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 8239 LR: 7.597595192178702e-05 Training loss: 0.0
2025-12-09 10:24:40.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 8240 LR: 7.589189294616122e-05 Training loss: 0.0
2025-12-09 10:24:40.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 8241 LR: 7.580787667821032e-05 Training loss: 0.0
2025-12-09 10:24:40.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 8242 LR: 7.572390312639438e-05 Training loss: 0.0
2025-12-09 10:24:40.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 8243 LR: 7.563997229917002e-05 Training loss: 0.0
2025-12-09 10:24:40.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 8244 LR: 7.555608420498872e-05 Training loss: 0.0
2025-12-09 10:24:40.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 8245 LR: 7.547223885229814e-05 Training loss: 0.0
2025-12-09 10:24:40.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 8246 LR: 7.53884362495415e-05 Training loss: 0.0
2025-12-09 10:24:40.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 8247 LR: 7.530467640515782e-05 Training loss: 0.0
2025-12-09 10:24:40.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 8248 LR: 7.522095932758132e-05 Training loss: 0.0
2025-12-09 10:24:40.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 8249 LR: 7.513728502524286e-05 Training loss: 0.0
2025-12-09 10:24:40.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 8250 LR: 7.505365350656812e-05 Training loss: 0.0
2025-12-09 10:24:40.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 8251 LR: 7.497006477997875e-05 Training loss: 0.0
2025-12-09 10:24:40.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 8252 LR: 7.48865188538923e-05 Training loss: 0.0
2025-12-09 10:24:40.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 8253 LR: 7.480301573672171e-05 Training loss: 0.0
2025-12-09 10:24:40.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 8254 LR: 7.471955543687587e-05 Training loss: 0.0
2025-12-09 10:24:40.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 8255 LR: 7.46361379627592e-05 Training loss: 0.0
2025-12-09 10:24:40.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 8256 LR: 7.455276332277161e-05 Training loss: 0.0
2025-12-09 10:24:40.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 8257 LR: 7.446943152530932e-05 Training loss: 0.0
2025-12-09 10:24:40.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 8258 LR: 7.438614257876358e-05 Training loss: 0.0
2025-12-09 10:24:40.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 8259 LR: 7.430289649152156e-05 Training loss: 0.0
2025-12-09 10:24:40.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 8260 LR: 7.421969327196626e-05 Training loss: 0.0
2025-12-09 10:24:40.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 8261 LR: 7.413653292847617e-05 Training loss: 0.0
2025-12-09 10:24:40.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 8262 LR: 7.405341546942562e-05 Training loss: 0.0
2025-12-09 10:24:40.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 8263 LR: 7.397034090318456e-05 Training loss: 0.0
2025-12-09 10:24:40.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 8264 LR: 7.388730923811826e-05 Training loss: 0.0
2025-12-09 10:24:40.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 8265 LR: 7.38043204825885e-05 Training loss: 0.0
2025-12-09 10:24:40.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 8266 LR: 7.372137464495188e-05 Training loss: 0.0
2025-12-09 10:24:40.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 8267 LR: 7.363847173356119e-05 Training loss: 0.0
2025-12-09 10:24:40.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 8268 LR: 7.355561175676474e-05 Training loss: 0.0
2025-12-09 10:24:40.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 8269 LR: 7.347279472290646e-05 Training loss: 0.0
2025-12-09 10:24:40.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 8270 LR: 7.339002064032613e-05 Training loss: 0.0
2025-12-09 10:24:40.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 8271 LR: 7.330728951735915e-05 Training loss: 0.0
2025-12-09 10:24:40.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 8272 LR: 7.322460136233622e-05 Training loss: 0.0
2025-12-09 10:24:40.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 8273 LR: 7.31419561835845e-05 Training loss: 0.0
2025-12-09 10:24:40.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 8274 LR: 7.305935398942598e-05 Training loss: 0.0
2025-12-09 10:24:40.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 8275 LR: 7.297679478817881e-05 Training loss: 0.0
2025-12-09 10:24:40.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 8276 LR: 7.289427858815679e-05 Training loss: 0.0
2025-12-09 10:24:40.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 8277 LR: 7.281180539766924e-05 Training loss: 0.0
2025-12-09 10:24:40.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 8278 LR: 7.272937522502105e-05 Training loss: 0.0
2025-12-09 10:24:40.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 8279 LR: 7.264698807851328e-05 Training loss: 0.0
2025-12-09 10:24:40.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 8280 LR: 7.256464396644203e-05 Training loss: 0.0
2025-12-09 10:24:40.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 8281 LR: 7.248234289709943e-05 Training loss: 0.0
2025-12-09 10:24:40.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 8282 LR: 7.240008487877314e-05 Training loss: 0.0
2025-12-09 10:24:40.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 8283 LR: 7.23178699197467e-05 Training loss: 0.0
2025-12-09 10:24:40.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 8284 LR: 7.2235698028299e-05 Training loss: 0.0
2025-12-09 10:24:40.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 8285 LR: 7.215356921270494e-05 Training loss: 0.0
2025-12-09 10:24:40.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 8286 LR: 7.20714834812345e-05 Training loss: 0.0
2025-12-09 10:24:40.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 8287 LR: 7.19894408421542e-05 Training loss: 0.0
2025-12-09 10:24:40.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 8288 LR: 7.19074413037254e-05 Training loss: 0.0
2025-12-09 10:24:40.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 8289 LR: 7.182548487420554e-05 Training loss: 0.0
2025-12-09 10:24:40.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 8290 LR: 7.174357156184764e-05 Training loss: 0.0
2025-12-09 10:24:40.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 8291 LR: 7.166170137490035e-05 Training loss: 0.0
2025-12-09 10:24:40.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 8292 LR: 7.1579874321608e-05 Training loss: 0.0
2025-12-09 10:24:40.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 8293 LR: 7.149809041021072e-05 Training loss: 0.0
2025-12-09 10:24:40.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 8294 LR: 7.14163496489439e-05 Training loss: 0.0
2025-12-09 10:24:40.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 8295 LR: 7.133465204603895e-05 Training loss: 0.0
2025-12-09 10:24:40.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 8296 LR: 7.125299760972282e-05 Training loss: 0.0
2025-12-09 10:24:40.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 8297 LR: 7.117138634821807e-05 Training loss: 0.0
2025-12-09 10:24:40.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 8298 LR: 7.108981826974308e-05 Training loss: 0.0
2025-12-09 10:24:40.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 8299 LR: 7.100829338251146e-05 Training loss: 0.0
2025-12-09 10:24:40.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 8300 LR: 7.09268116947332e-05 Training loss: 0.0
2025-12-09 10:24:40.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 8301 LR: 7.08453732146131e-05 Training loss: 0.0
2025-12-09 10:24:40.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 8302 LR: 7.076397795035222e-05 Training loss: 0.0
2025-12-09 10:24:40.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 8303 LR: 7.068262591014695e-05 Training loss: 0.0
2025-12-09 10:24:40.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 8304 LR: 7.060131710218958e-05 Training loss: 0.0
2025-12-09 10:24:40.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 8305 LR: 7.052005153466778e-05 Training loss: 0.0
2025-12-09 10:24:40.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 8306 LR: 7.043882921576516e-05 Training loss: 0.0
2025-12-09 10:24:40.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 8307 LR: 7.035765015366047e-05 Training loss: 0.0
2025-12-09 10:24:40.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 8308 LR: 7.027651435652888e-05 Training loss: 0.0
2025-12-09 10:24:40.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 8309 LR: 7.019542183254046e-05 Training loss: 0.0
2025-12-09 10:24:40.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 8310 LR: 7.011437258986125e-05 Training loss: 0.0
2025-12-09 10:24:40.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 8311 LR: 7.003336663665293e-05 Training loss: 0.0
2025-12-09 10:24:40.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 8312 LR: 6.9952403981073e-05 Training loss: 0.0
2025-12-09 10:24:40.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 8313 LR: 6.987148463127396e-05 Training loss: 0.0
2025-12-09 10:24:40.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 8314 LR: 6.979060859540493e-05 Training loss: 0.0
2025-12-09 10:24:40.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 8315 LR: 6.970977588160964e-05 Training loss: 0.0
2025-12-09 10:24:40.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 8316 LR: 6.962898649802824e-05 Training loss: 0.0
2025-12-09 10:24:40.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 8317 LR: 6.954824045279607e-05 Training loss: 0.0
2025-12-09 10:24:40.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 8318 LR: 6.94675377540443e-05 Training loss: 0.0
2025-12-09 10:24:40.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 8319 LR: 6.938687840989971e-05 Training loss: 0.0
2025-12-09 10:24:40.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 8320 LR: 6.930626242848482e-05 Training loss: 0.0
2025-12-09 10:24:40.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 8321 LR: 6.922568981791727e-05 Training loss: 0.0
2025-12-09 10:24:40.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 8322 LR: 6.91451605863112e-05 Training loss: 0.0
2025-12-09 10:24:40.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 8323 LR: 6.906467474177558e-05 Training loss: 0.0
2025-12-09 10:24:40.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 8324 LR: 6.898423229241535e-05 Training loss: 0.0
2025-12-09 10:24:40.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 8325 LR: 6.89038332463312e-05 Training loss: 0.0
2025-12-09 10:24:40.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 8326 LR: 6.882347761161923e-05 Training loss: 0.0
2025-12-09 10:24:40.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 8327 LR: 6.874316539637127e-05 Training loss: 0.0
2025-12-09 10:24:40.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 8328 LR: 6.866289660867487e-05 Training loss: 0.0
2025-12-09 10:24:40.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 8329 LR: 6.858267125661271e-05 Training loss: 0.0
2025-12-09 10:24:40.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 8330 LR: 6.850248934826403e-05 Training loss: 0.0
2025-12-09 10:24:40.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 8331 LR: 6.842235089170273e-05 Training loss: 0.0
2025-12-09 10:24:40.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 8332 LR: 6.834225589499887e-05 Training loss: 0.0
2025-12-09 10:24:40.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 8333 LR: 6.82622043662181e-05 Training loss: 0.0
2025-12-09 10:24:40.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 8334 LR: 6.818219631342148e-05 Training loss: 0.0
2025-12-09 10:24:40.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 8335 LR: 6.81022317446659e-05 Training loss: 0.0
2025-12-09 10:24:40.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 8336 LR: 6.802231066800385e-05 Training loss: 0.0
2025-12-09 10:24:40.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 8337 LR: 6.794243309148307e-05 Training loss: 0.0
2025-12-09 10:24:40.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 8338 LR: 6.786259902314768e-05 Training loss: 0.0
2025-12-09 10:24:40.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 8339 LR: 6.778280847103668e-05 Training loss: 0.0
2025-12-09 10:24:40.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 8340 LR: 6.7703061443185e-05 Training loss: 0.0
2025-12-09 10:24:40.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 8341 LR: 6.76233579476232e-05 Training loss: 0.0
2025-12-09 10:24:40.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 8342 LR: 6.754369799237753e-05 Training loss: 0.0
2025-12-09 10:24:40.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 8343 LR: 6.746408158546946e-05 Training loss: 0.0
2025-12-09 10:24:40.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 8344 LR: 6.738450873491675e-05 Training loss: 0.0
2025-12-09 10:24:40.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 8345 LR: 6.730497944873204e-05 Training loss: 0.0
2025-12-09 10:24:40.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 8346 LR: 6.722549373492403e-05 Training loss: 0.0
2025-12-09 10:24:40.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 8347 LR: 6.7146051601497e-05 Training loss: 0.0
2025-12-09 10:24:40.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 8348 LR: 6.706665305645077e-05 Training loss: 0.0
2025-12-09 10:24:40.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 8349 LR: 6.698729810778065e-05 Training loss: 0.0
2025-12-09 10:24:40.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 8350 LR: 6.690798676347792e-05 Training loss: 0.0
2025-12-09 10:24:40.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 8351 LR: 6.682871903152887e-05 Training loss: 0.0
2025-12-09 10:24:40.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 8352 LR: 6.674949491991616e-05 Training loss: 0.0
2025-12-09 10:24:40.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 8353 LR: 6.667031443661731e-05 Training loss: 0.0
2025-12-09 10:24:40.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 8354 LR: 6.659117758960598e-05 Training loss: 0.0
2025-12-09 10:24:40.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 8355 LR: 6.651208438685119e-05 Training loss: 0.0
2025-12-09 10:24:40.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 8356 LR: 6.643303483631769e-05 Training loss: 0.0
2025-12-09 10:24:40.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 8357 LR: 6.635402894596566e-05 Training loss: 0.0
2025-12-09 10:24:40.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 8358 LR: 6.627506672375117e-05 Training loss: 0.0
2025-12-09 10:24:40.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 8359 LR: 6.619614817762538e-05 Training loss: 0.0
2025-12-09 10:24:40.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 8360 LR: 6.611727331553586e-05 Training loss: 0.0
2025-12-09 10:24:40.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 8361 LR: 6.603844214542487e-05 Training loss: 0.0
2025-12-09 10:24:40.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 8362 LR: 6.595965467523091e-05 Training loss: 0.0
2025-12-09 10:24:40.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 8363 LR: 6.588091091288784e-05 Training loss: 0.0
2025-12-09 10:24:40.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 8364 LR: 6.580221086632515e-05 Training loss: 0.0
2025-12-09 10:24:40.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 8365 LR: 6.572355454346801e-05 Training loss: 0.0
2025-12-09 10:24:40.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 8366 LR: 6.564494195223709e-05 Training loss: 0.0
2025-12-09 10:24:40.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 8367 LR: 6.556637310054841e-05 Training loss: 0.0
2025-12-09 10:24:40.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 8368 LR: 6.548784799631435e-05 Training loss: 0.0
2025-12-09 10:24:40.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 8369 LR: 6.540936664744196e-05 Training loss: 0.0
2025-12-09 10:24:40.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 8370 LR: 6.533092906183441e-05 Training loss: 0.0
2025-12-09 10:24:40.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 8371 LR: 6.52525352473905e-05 Training loss: 0.0
2025-12-09 10:24:40.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 8372 LR: 6.517418521200446e-05 Training loss: 0.0
2025-12-09 10:24:40.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 8373 LR: 6.509587896356583e-05 Training loss: 0.0
2025-12-09 10:24:40.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 8374 LR: 6.501761650996052e-05 Training loss: 0.0
2025-12-09 10:24:40.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 8375 LR: 6.493939785906927e-05 Training loss: 0.0
2025-12-09 10:24:40.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 8376 LR: 6.486122301876868e-05 Training loss: 0.0
2025-12-09 10:24:40.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 8377 LR: 6.478309199693105e-05 Training loss: 0.0
2025-12-09 10:24:40.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 8378 LR: 6.470500480142416e-05 Training loss: 0.0
2025-12-09 10:24:40.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 8379 LR: 6.462696144011149e-05 Training loss: 0.0
2025-12-09 10:24:40.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 8380 LR: 6.454896192085175e-05 Training loss: 0.0
2025-12-09 10:24:40.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 8381 LR: 6.447100625149966e-05 Training loss: 0.0
2025-12-09 10:24:40.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 8382 LR: 6.439309443990532e-05 Training loss: 0.0
2025-12-09 10:24:40.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 8383 LR: 6.431522649391447e-05 Training loss: 0.0
2025-12-09 10:24:40.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 8384 LR: 6.423740242136832e-05 Training loss: 0.0
2025-12-09 10:24:40.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 8385 LR: 6.415962223010402e-05 Training loss: 0.0
2025-12-09 10:24:40.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 8386 LR: 6.408188592795355e-05 Training loss: 0.0
2025-12-09 10:24:40.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 8387 LR: 6.40041935227455e-05 Training loss: 0.0
2025-12-09 10:24:40.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 8388 LR: 6.392654502230311e-05 Training loss: 0.0
2025-12-09 10:24:40.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 8389 LR: 6.384894043444567e-05 Training loss: 0.0
2025-12-09 10:24:40.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 8390 LR: 6.377137976698805e-05 Training loss: 0.0
2025-12-09 10:24:40.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 8391 LR: 6.36938630277405e-05 Training loss: 0.0
2025-12-09 10:24:40.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 8392 LR: 6.361639022450905e-05 Training loss: 0.0
2025-12-09 10:24:40.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 8393 LR: 6.353896136509524e-05 Training loss: 0.0
2025-12-09 10:24:40.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 8394 LR: 6.346157645729589e-05 Training loss: 0.0
2025-12-09 10:24:40.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 8395 LR: 6.338423550890405e-05 Training loss: 0.0
2025-12-09 10:24:40.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 8396 LR: 6.330693852770764e-05 Training loss: 0.0
2025-12-09 10:24:40.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 8397 LR: 6.322968552149055e-05 Training loss: 0.0
2025-12-09 10:24:40.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 8398 LR: 6.315247649803224e-05 Training loss: 0.0
2025-12-09 10:24:40.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 8399 LR: 6.307531146510753e-05 Training loss: 0.0
2025-12-09 10:24:40.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 8400 LR: 6.2998190430487e-05 Training loss: 0.0
2025-12-09 10:24:40.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 8401 LR: 6.29211134019369e-05 Training loss: 0.0
2025-12-09 10:24:40.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 8402 LR: 6.284408038721857e-05 Training loss: 0.0
2025-12-09 10:24:40.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 8403 LR: 6.276709139408938e-05 Training loss: 0.0
2025-12-09 10:24:40.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 8404 LR: 6.269014643030213e-05 Training loss: 0.0
2025-12-09 10:24:40.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 8405 LR: 6.26132455036052e-05 Training loss: 0.0
2025-12-09 10:24:40.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 8406 LR: 6.253638862174244e-05 Training loss: 0.0
2025-12-09 10:24:40.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 8407 LR: 6.245957579245348e-05 Training loss: 0.0
2025-12-09 10:24:40.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 8408 LR: 6.23828070234731e-05 Training loss: 0.0
2025-12-09 10:24:40.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 8409 LR: 6.230608232253226e-05 Training loss: 0.0
2025-12-09 10:24:40.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 8410 LR: 6.222940169735686e-05 Training loss: 0.0
2025-12-09 10:24:40.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 8411 LR: 6.21527651556687e-05 Training loss: 0.0
2025-12-09 10:24:40.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 8412 LR: 6.207617270518512e-05 Training loss: 0.0
2025-12-09 10:24:40.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 8413 LR: 6.1999624353619e-05 Training loss: 0.0
2025-12-09 10:24:40.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 8414 LR: 6.192312010867868e-05 Training loss: 0.0
2025-12-09 10:24:40.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 8415 LR: 6.184665997806832e-05 Training loss: 0.0
2025-12-09 10:24:40.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 8416 LR: 6.177024396948705e-05 Training loss: 0.0
2025-12-09 10:24:40.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 8417 LR: 6.169387209063048e-05 Training loss: 0.0
2025-12-09 10:24:40.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 8418 LR: 6.161754434918887e-05 Training loss: 0.0
2025-12-09 10:24:40.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 8419 LR: 6.154126075284855e-05 Training loss: 0.0
2025-12-09 10:24:40.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 8420 LR: 6.146502130929127e-05 Training loss: 0.0
2025-12-09 10:24:40.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 8421 LR: 6.138882602619439e-05 Training loss: 0.0
2025-12-09 10:24:40.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 8422 LR: 6.131267491123066e-05 Training loss: 0.0
2025-12-09 10:24:40.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 8423 LR: 6.123656797206872e-05 Training loss: 0.0
2025-12-09 10:24:40.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 8424 LR: 6.116050521637217e-05 Training loss: 0.0
2025-12-09 10:24:40.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 8425 LR: 6.108448665180089e-05 Training loss: 0.0
2025-12-09 10:24:40.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 8426 LR: 6.100851228600973e-05 Training loss: 0.0
2025-12-09 10:24:40.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 8427 LR: 6.093258212664937e-05 Training loss: 0.0
2025-12-09 10:24:40.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 8428 LR: 6.085669618136602e-05 Training loss: 0.0
2025-12-09 10:24:40.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 8429 LR: 6.078085445780129e-05 Training loss: 0.0
2025-12-09 10:24:40.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 8430 LR: 6.070505696359252e-05 Training loss: 0.0
2025-12-09 10:24:40.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 8431 LR: 6.06293037063726e-05 Training loss: 0.0
2025-12-09 10:24:40.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 8432 LR: 6.055359469376953e-05 Training loss: 0.0
2025-12-09 10:24:40.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 8433 LR: 6.0477929933407674e-05 Training loss: 0.0
2025-12-09 10:24:40.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 8434 LR: 6.04023094329062e-05 Training loss: 0.0
2025-12-09 10:24:40.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 8435 LR: 6.032673319988008e-05 Training loss: 0.0
2025-12-09 10:24:40.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 8436 LR: 6.025120124193989e-05 Training loss: 0.0
2025-12-09 10:24:40.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 8437 LR: 6.0175713566691824e-05 Training loss: 0.0
2025-12-09 10:24:40.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 8438 LR: 6.0100270181737196e-05 Training loss: 0.0
2025-12-09 10:24:40.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 8439 LR: 6.002487109467347e-05 Training loss: 0.0
2025-12-09 10:24:40.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 8440 LR: 5.994951631309314e-05 Training loss: 0.0
2025-12-09 10:24:40.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 8441 LR: 5.9874205844584416e-05 Training loss: 0.0
2025-12-09 10:24:40.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 8442 LR: 5.979893969673117e-05 Training loss: 0.0
2025-12-09 10:24:40.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 8443 LR: 5.972371787711262e-05 Training loss: 0.0
2025-12-09 10:24:40.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 8444 LR: 5.964854039330364e-05 Training loss: 0.0
2025-12-09 10:24:40.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 8445 LR: 5.957340725287475e-05 Training loss: 0.0
2025-12-09 10:24:40.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 8446 LR: 5.949831846339143e-05 Training loss: 0.0
2025-12-09 10:24:40.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 8447 LR: 5.94232740324156e-05 Training loss: 0.0
2025-12-09 10:24:40.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 8448 LR: 5.934827396750392e-05 Training loss: 0.0
2025-12-09 10:24:40.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 8449 LR: 5.927331827620902e-05 Training loss: 0.0
2025-12-09 10:24:40.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 8450 LR: 5.919840696607886e-05 Training loss: 0.0
2025-12-09 10:24:40.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 8451 LR: 5.912354004465709e-05 Training loss: 0.0
2025-12-09 10:24:40.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 8452 LR: 5.904871751948276e-05 Training loss: 0.0
2025-12-09 10:24:40.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 8453 LR: 5.8973939398090647e-05 Training loss: 0.0
2025-12-09 10:24:40.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 8454 LR: 5.889920568801055e-05 Training loss: 0.0
2025-12-09 10:24:40.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 8455 LR: 5.882451639676856e-05 Training loss: 0.0
2025-12-09 10:24:40.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 8456 LR: 5.87498715318856e-05 Training loss: 0.0
2025-12-09 10:24:40.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 8457 LR: 5.867527110087856e-05 Training loss: 0.0
2025-12-09 10:24:40.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 8458 LR: 5.8600715111259584e-05 Training loss: 0.0
2025-12-09 10:24:40.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 8459 LR: 5.852620357053651e-05 Training loss: 0.0
2025-12-09 10:24:40.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 8460 LR: 5.845173648621266e-05 Training loss: 0.0
2025-12-09 10:24:40.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 8461 LR: 5.8377313865786985e-05 Training loss: 0.0
2025-12-09 10:24:40.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 8462 LR: 5.830293571675355e-05 Training loss: 0.0
2025-12-09 10:24:40.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 8463 LR: 5.822860204660252e-05 Training loss: 0.0
2025-12-09 10:24:40.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 8464 LR: 5.815431286281925e-05 Training loss: 0.0
2025-12-09 10:24:40.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 8465 LR: 5.8080068172884357e-05 Training loss: 0.0
2025-12-09 10:24:40.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 8466 LR: 5.800586798427471e-05 Training loss: 0.0
2025-12-09 10:24:40.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 8467 LR: 5.793171230446198e-05 Training loss: 0.0
2025-12-09 10:24:40.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 8468 LR: 5.7857601140913705e-05 Training loss: 0.0
2025-12-09 10:24:40.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 8469 LR: 5.778353450109286e-05 Training loss: 0.0
2025-12-09 10:24:40.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 8470 LR: 5.770951239245803e-05 Training loss: 0.0
2025-12-09 10:24:40.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 8471 LR: 5.76355348224632e-05 Training loss: 0.0
2025-12-09 10:24:40.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 8472 LR: 5.7561601798558015e-05 Training loss: 0.0
2025-12-09 10:24:40.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 8473 LR: 5.748771332818725e-05 Training loss: 0.0
2025-12-09 10:24:40.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 8474 LR: 5.741386941879179e-05 Training loss: 0.0
2025-12-09 10:24:40.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 8475 LR: 5.7340070077807506e-05 Training loss: 0.0
2025-12-09 10:24:40.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 8476 LR: 5.7266315312666016e-05 Training loss: 0.0
2025-12-09 10:24:40.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 8477 LR: 5.7192605130794497e-05 Training loss: 0.0
2025-12-09 10:24:40.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 8478 LR: 5.71189395396155e-05 Training loss: 0.0
2025-12-09 10:24:40.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 8479 LR: 5.7045318546547206e-05 Training loss: 0.0
2025-12-09 10:24:40.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 8480 LR: 5.69717421590033e-05 Training loss: 0.0
2025-12-09 10:24:40.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 8481 LR: 5.6898210384392636e-05 Training loss: 0.0
2025-12-09 10:24:40.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 8482 LR: 5.6824723230120225e-05 Training loss: 0.0
2025-12-09 10:24:40.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 8483 LR: 5.6751280703585985e-05 Training loss: 0.0
2025-12-09 10:24:40.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 8484 LR: 5.6677882812185665e-05 Training loss: 0.0
2025-12-09 10:24:40.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 8485 LR: 5.6604529563310414e-05 Training loss: 0.0
2025-12-09 10:24:40.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 8486 LR: 5.653122096434693e-05 Training loss: 0.0
2025-12-09 10:24:40.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 8487 LR: 5.645795702267731e-05 Training loss: 0.0
2025-12-09 10:24:40.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 8488 LR: 5.6384737745679374e-05 Training loss: 0.0
2025-12-09 10:24:40.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 8489 LR: 5.631156314072605e-05 Training loss: 0.0
2025-12-09 10:24:40.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 8490 LR: 5.6238433215186346e-05 Training loss: 0.0
2025-12-09 10:24:40.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 8491 LR: 5.61653479764242e-05 Training loss: 0.0
2025-12-09 10:24:40.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 8492 LR: 5.609230743179938e-05 Training loss: 0.0
2025-12-09 10:24:40.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 8493 LR: 5.601931158866702e-05 Training loss: 0.0
2025-12-09 10:24:40.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 8494 LR: 5.594636045437795e-05 Training loss: 0.0
2025-12-09 10:24:40.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 8495 LR: 5.587345403627803e-05 Training loss: 0.0
2025-12-09 10:24:40.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 8496 LR: 5.5800592341709314e-05 Training loss: 0.0
2025-12-09 10:24:40.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 8497 LR: 5.572777537800872e-05 Training loss: 0.0
2025-12-09 10:24:40.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 8498 LR: 5.565500315250899e-05 Training loss: 0.0
2025-12-09 10:24:40.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 8499 LR: 5.5582275672538315e-05 Training loss: 0.0
2025-12-09 10:24:40.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 8500 LR: 5.5509592945420296e-05 Training loss: 0.0
2025-12-09 10:24:40.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 8501 LR: 5.543695497847406e-05 Training loss: 0.0
2025-12-09 10:24:40.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 8502 LR: 5.536436177901444e-05 Training loss: 0.0
2025-12-09 10:24:40.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 8503 LR: 5.529181335435124e-05 Training loss: 0.0
2025-12-09 10:24:40.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 8504 LR: 5.52193097117904e-05 Training loss: 0.0
2025-12-09 10:24:40.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 8505 LR: 5.5146850858632855e-05 Training loss: 0.0
2025-12-09 10:24:40.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 8506 LR: 5.507443680217522e-05 Training loss: 0.0
2025-12-09 10:24:40.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 8507 LR: 5.5002067549709654e-05 Training loss: 0.0
2025-12-09 10:24:40.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 8508 LR: 5.492974310852372e-05 Training loss: 0.0
2025-12-09 10:24:40.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 8509 LR: 5.4857463485900484e-05 Training loss: 0.0
2025-12-09 10:24:40.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 8510 LR: 5.478522868911856e-05 Training loss: 0.0
2025-12-09 10:24:40.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 8511 LR: 5.471303872545175e-05 Training loss: 0.0
2025-12-09 10:24:40.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 8512 LR: 5.464089360216995e-05 Training loss: 0.0
2025-12-09 10:24:40.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 8513 LR: 5.4568793326537855e-05 Training loss: 0.0
2025-12-09 10:24:40.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 8514 LR: 5.449673790581611e-05 Training loss: 0.0
2025-12-09 10:24:40.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 8515 LR: 5.442472734726062e-05 Training loss: 0.0
2025-12-09 10:24:40.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 8516 LR: 5.4352761658122976e-05 Training loss: 0.0
2025-12-09 10:24:40.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 8517 LR: 5.428084084564999e-05 Training loss: 0.0
2025-12-09 10:24:40.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 8518 LR: 5.4208964917084216e-05 Training loss: 0.0
2025-12-09 10:24:40.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 8519 LR: 5.413713387966329e-05 Training loss: 0.0
2025-12-09 10:24:40.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 8520 LR: 5.406534774062105e-05 Training loss: 0.0
2025-12-09 10:24:40.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 8521 LR: 5.3993606507185935e-05 Training loss: 0.0
2025-12-09 10:24:40.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 8522 LR: 5.3921910186582436e-05 Training loss: 0.0
2025-12-09 10:24:40.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 8523 LR: 5.3850258786030394e-05 Training loss: 0.0
2025-12-09 10:24:40.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 8524 LR: 5.377865231274504e-05 Training loss: 0.0
2025-12-09 10:24:40.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 8525 LR: 5.370709077393721e-05 Training loss: 0.0
2025-12-09 10:24:40.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 8526 LR: 5.363557417681325e-05 Training loss: 0.0
2025-12-09 10:24:40.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 8527 LR: 5.3564102528574576e-05 Training loss: 0.0
2025-12-09 10:24:40.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 8528 LR: 5.3492675836418705e-05 Training loss: 0.0
2025-12-09 10:24:40.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 8529 LR: 5.34212941075381e-05 Training loss: 0.0
2025-12-09 10:24:40.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 8530 LR: 5.334995734912096e-05 Training loss: 0.0
2025-12-09 10:24:40.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 8531 LR: 5.327866556835087e-05 Training loss: 0.0
2025-12-09 10:24:40.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 8532 LR: 5.320741877240703e-05 Training loss: 0.0
2025-12-09 10:24:40.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 8533 LR: 5.313621696846371e-05 Training loss: 0.0
2025-12-09 10:24:40.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 8534 LR: 5.306506016369134e-05 Training loss: 0.0
2025-12-09 10:24:40.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 8535 LR: 5.299394836525506e-05 Training loss: 0.0
2025-12-09 10:24:40.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 8536 LR: 5.292288158031594e-05 Training loss: 0.0
2025-12-09 10:24:40.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 8537 LR: 5.285185981603041e-05 Training loss: 0.0
2025-12-09 10:24:40.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 8538 LR: 5.278088307955037e-05 Training loss: 0.0
2025-12-09 10:24:40.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 8539 LR: 5.270995137802315e-05 Training loss: 0.0
2025-12-09 10:24:40.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 8540 LR: 5.26390647185917e-05 Training loss: 0.0
2025-12-09 10:24:40.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 8541 LR: 5.256822310839404e-05 Training loss: 0.0
2025-12-09 10:24:40.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 8542 LR: 5.249742655456419e-05 Training loss: 0.0
2025-12-09 10:24:40.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 8543 LR: 5.242667506423121e-05 Training loss: 0.0
2025-12-09 10:24:40.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 8544 LR: 5.235596864451975e-05 Training loss: 0.0
2025-12-09 10:24:40.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 8545 LR: 5.228530730255004e-05 Training loss: 0.0
2025-12-09 10:24:40.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 8546 LR: 5.221469104543758e-05 Training loss: 0.0
2025-12-09 10:24:40.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 8547 LR: 5.214411988029355e-05 Training loss: 0.0
2025-12-09 10:24:40.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 8548 LR: 5.207359381422444e-05 Training loss: 0.0
2025-12-09 10:24:40.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 8549 LR: 5.2003112854332125e-05 Training loss: 0.0
2025-12-09 10:24:40.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 8550 LR: 5.193267700771403e-05 Training loss: 0.0
2025-12-09 10:24:40.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 8551 LR: 5.186228628146317e-05 Training loss: 0.0
2025-12-09 10:24:40.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 8552 LR: 5.179194068266774e-05 Training loss: 0.0
2025-12-09 10:24:40.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 8553 LR: 5.172164021841175e-05 Training loss: 0.0
2025-12-09 10:24:40.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 8554 LR: 5.1651384895774145e-05 Training loss: 0.0
2025-12-09 10:24:40.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 8555 LR: 5.1581174721829994e-05 Training loss: 0.0
2025-12-09 10:24:40.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 8556 LR: 5.1511009703649195e-05 Training loss: 0.0
2025-12-09 10:24:40.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 8557 LR: 5.1440889848297426e-05 Training loss: 0.0
2025-12-09 10:24:40.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 8558 LR: 5.137081516283582e-05 Training loss: 0.0
2025-12-09 10:24:40.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 8559 LR: 5.130078565432089e-05 Training loss: 0.0
2025-12-09 10:24:40.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 8560 LR: 5.12308013298044e-05 Training loss: 0.0
2025-12-09 10:24:40.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 8561 LR: 5.116086219633415e-05 Training loss: 0.0
2025-12-09 10:24:40.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 8562 LR: 5.1090968260952665e-05 Training loss: 0.0
2025-12-09 10:24:40.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 8563 LR: 5.1021119530698434e-05 Training loss: 0.0
2025-12-09 10:24:40.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 8564 LR: 5.095131601260516e-05 Training loss: 0.0
2025-12-09 10:24:40.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 8565 LR: 5.088155771370207e-05 Training loss: 0.0
2025-12-09 10:24:40.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 8566 LR: 5.081184464101379e-05 Training loss: 0.0
2025-12-09 10:24:40.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 8567 LR: 5.0742176801560625e-05 Training loss: 0.0
2025-12-09 10:24:40.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 8568 LR: 5.067255420235778e-05 Training loss: 0.0
2025-12-09 10:24:40.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 8569 LR: 5.060297685041659e-05 Training loss: 0.0
2025-12-09 10:24:40.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 8570 LR: 5.053344475274324e-05 Training loss: 0.0
2025-12-09 10:24:40.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 8571 LR: 5.0463957916339676e-05 Training loss: 0.0
2025-12-09 10:24:40.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 8572 LR: 5.03945163482033e-05 Training loss: 0.0
2025-12-09 10:24:40.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 8573 LR: 5.03251200553268e-05 Training loss: 0.0
2025-12-09 10:24:40.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 8574 LR: 5.025576904469842e-05 Training loss: 0.0
2025-12-09 10:24:40.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 8575 LR: 5.01864633233019e-05 Training loss: 0.0
2025-12-09 10:24:40.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 8576 LR: 5.0117202898116e-05 Training loss: 0.0
2025-12-09 10:24:40.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 8577 LR: 5.004798777611563e-05 Training loss: 0.0
2025-12-09 10:24:40.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 8578 LR: 4.997881796427051e-05 Training loss: 0.0
2025-12-09 10:24:40.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 8579 LR: 4.99096934695461e-05 Training loss: 0.0
2025-12-09 10:24:40.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 8580 LR: 4.984061429890324e-05 Training loss: 0.0
2025-12-09 10:24:40.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 8581 LR: 4.977158045929825e-05 Training loss: 0.0
2025-12-09 10:24:40.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 8582 LR: 4.970259195768273e-05 Training loss: 0.0
2025-12-09 10:24:40.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 8583 LR: 4.9633648801004015e-05 Training loss: 0.0
2025-12-09 10:24:40.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 8584 LR: 4.956475099620433e-05 Training loss: 0.0
2025-12-09 10:24:40.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 8585 LR: 4.9495898550222075e-05 Training loss: 0.0
2025-12-09 10:24:40.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 8586 LR: 4.9427091469990415e-05 Training loss: 0.0
2025-12-09 10:24:40.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 8587 LR: 4.9358329762438314e-05 Training loss: 0.0
2025-12-09 10:24:40.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 8588 LR: 4.928961343449012e-05 Training loss: 0.0
2025-12-09 10:24:40.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 8589 LR: 4.922094249306558e-05 Training loss: 0.0
2025-12-09 10:24:40.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 8590 LR: 4.9152316945079604e-05 Training loss: 0.0
2025-12-09 10:24:40.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 8591 LR: 4.908373679744316e-05 Training loss: 0.0
2025-12-09 10:24:40.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 8592 LR: 4.9015202057062004e-05 Training loss: 0.0
2025-12-09 10:24:40.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 8593 LR: 4.8946712730837675e-05 Training loss: 0.0
2025-12-09 10:24:40.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 8594 LR: 4.887826882566698e-05 Training loss: 0.0
2025-12-09 10:24:40.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 8595 LR: 4.880987034844231e-05 Training loss: 0.0
2025-12-09 10:24:40.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 8596 LR: 4.874151730605136e-05 Training loss: 0.0
2025-12-09 10:24:40.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 8597 LR: 4.8673209705377364e-05 Training loss: 0.0
2025-12-09 10:24:40.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 8598 LR: 4.8604947553298585e-05 Training loss: 0.0
2025-12-09 10:24:40.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 8599 LR: 4.853673085668947e-05 Training loss: 0.0
2025-12-09 10:24:40.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 8600 LR: 4.846855962241908e-05 Training loss: 0.0
2025-12-09 10:24:40.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 8601 LR: 4.840043385735238e-05 Training loss: 0.0
2025-12-09 10:24:40.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 8602 LR: 4.833235356834958e-05 Training loss: 0.0
2025-12-09 10:24:40.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 8603 LR: 4.82643187622665e-05 Training loss: 0.0
2025-12-09 10:24:40.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 8604 LR: 4.819632944595414e-05 Training loss: 0.0
2025-12-09 10:24:40.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 8605 LR: 4.812838562625915e-05 Training loss: 0.0
2025-12-09 10:24:40.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 8606 LR: 4.80604873100231e-05 Training loss: 0.0
2025-12-09 10:24:40.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 8607 LR: 4.799263450408387e-05 Training loss: 0.0
2025-12-09 10:24:40.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 8608 LR: 4.792482721527386e-05 Training loss: 0.0
2025-12-09 10:24:40.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 8609 LR: 4.78570654504214e-05 Training loss: 0.0
2025-12-09 10:24:40.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 8610 LR: 4.7789349216350084e-05 Training loss: 0.0
2025-12-09 10:24:40.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 8611 LR: 4.7721678519878906e-05 Training loss: 0.0
2025-12-09 10:24:40.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 8612 LR: 4.76540533678223e-05 Training loss: 0.0
2025-12-09 10:24:40.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 8613 LR: 4.758647376699032e-05 Training loss: 0.0
2025-12-09 10:24:40.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 8614 LR: 4.75189397241878e-05 Training loss: 0.0
2025-12-09 10:24:40.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 8615 LR: 4.745145124621586e-05 Training loss: 0.0
2025-12-09 10:24:40.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 8616 LR: 4.738400833987033e-05 Training loss: 0.0
2025-12-09 10:24:40.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 8617 LR: 4.7316611011942735e-05 Training loss: 0.0
2025-12-09 10:24:40.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 8618 LR: 4.7249259269220027e-05 Training loss: 0.0
2025-12-09 10:24:40.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 8619 LR: 4.7181953118484556e-05 Training loss: 0.0
2025-12-09 10:24:40.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 8620 LR: 4.7114692566514015e-05 Training loss: 0.0
2025-12-09 10:24:40.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 8621 LR: 4.70474776200816e-05 Training loss: 0.0
2025-12-09 10:24:40.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 8622 LR: 4.698030828595568e-05 Training loss: 0.0
2025-12-09 10:24:40.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 8623 LR: 4.6913184570900436e-05 Training loss: 0.0
2025-12-09 10:24:40.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 8624 LR: 4.684610648167503e-05 Training loss: 0.0
2025-12-09 10:24:40.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 8625 LR: 4.6779074025034285e-05 Training loss: 0.0
2025-12-09 10:24:40.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 8626 LR: 4.671208720772846e-05 Training loss: 0.0
2025-12-09 10:24:40.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 8627 LR: 4.664514603650305e-05 Training loss: 0.0
2025-12-09 10:24:40.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 8628 LR: 4.657825051809889e-05 Training loss: 0.0
2025-12-09 10:24:40.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 8629 LR: 4.651140065925269e-05 Training loss: 0.0
2025-12-09 10:24:40.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 8630 LR: 4.644459646669591e-05 Training loss: 0.0
2025-12-09 10:24:40.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 8631 LR: 4.637783794715589e-05 Training loss: 0.0
2025-12-09 10:24:40.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 8632 LR: 4.631112510735519e-05 Training loss: 0.0
2025-12-09 10:24:40.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 8633 LR: 4.624445795401172e-05 Training loss: 0.0
2025-12-09 10:24:40.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 8634 LR: 4.6177836493839055e-05 Training loss: 0.0
2025-12-09 10:24:40.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 8635 LR: 4.6111260733545715e-05 Training loss: 0.0
2025-12-09 10:24:40.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 8636 LR: 4.6044730679836055e-05 Training loss: 0.0
2025-12-09 10:24:40.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 8637 LR: 4.597824633940956e-05 Training loss: 0.0
2025-12-09 10:24:40.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 8638 LR: 4.5911807718961195e-05 Training loss: 0.0
2025-12-09 10:24:40.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 8639 LR: 4.58454148251814e-05 Training loss: 0.0
2025-12-09 10:24:40.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 8640 LR: 4.577906766475604e-05 Training loss: 0.0
2025-12-09 10:24:40.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 8641 LR: 4.5712766244365875e-05 Training loss: 0.0
2025-12-09 10:24:40.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 8642 LR: 4.564651057068797e-05 Training loss: 0.0
2025-12-09 10:24:40.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 8643 LR: 4.558030065039387e-05 Training loss: 0.0
2025-12-09 10:24:40.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 8644 LR: 4.551413649015112e-05 Training loss: 0.0
2025-12-09 10:24:40.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 8645 LR: 4.5448018096622355e-05 Training loss: 0.0
2025-12-09 10:24:40.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 8646 LR: 4.538194547646573e-05 Training loss: 0.0
2025-12-09 10:24:40.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 8647 LR: 4.5315918636334776e-05 Training loss: 0.0
2025-12-09 10:24:40.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 8648 LR: 4.524993758287843e-05 Training loss: 0.0
2025-12-09 10:24:40.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 8649 LR: 4.518400232274078e-05 Training loss: 0.0
2025-12-09 10:24:40.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 8650 LR: 4.511811286256184e-05 Training loss: 0.0
2025-12-09 10:24:40.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 8651 LR: 4.505226920897637e-05 Training loss: 0.0
2025-12-09 10:24:40.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 8652 LR: 4.498647136861494e-05 Training loss: 0.0
2025-12-09 10:24:40.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 8653 LR: 4.492071934810343e-05 Training loss: 0.0
2025-12-09 10:24:40.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 8654 LR: 4.4855013154063095e-05 Training loss: 0.0
2025-12-09 10:24:40.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 8655 LR: 4.4789352793110305e-05 Training loss: 0.0
2025-12-09 10:24:40.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 8656 LR: 4.472373827185738e-05 Training loss: 0.0
2025-12-09 10:24:40.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 8657 LR: 4.465816959691149e-05 Training loss: 0.0
2025-12-09 10:24:40.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 8658 LR: 4.4592646774875454e-05 Training loss: 0.0
2025-12-09 10:24:40.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 8659 LR: 4.452716981234745e-05 Training loss: 0.0
2025-12-09 10:24:40.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 8660 LR: 4.446173871592096e-05 Training loss: 0.0
2025-12-09 10:24:40.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 8661 LR: 4.439635349218496e-05 Training loss: 0.0
2025-12-09 10:24:40.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 8662 LR: 4.433101414772372e-05 Training loss: 0.0
2025-12-09 10:24:40.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 8663 LR: 4.426572068911677e-05 Training loss: 0.0
2025-12-09 10:24:40.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 8664 LR: 4.420047312293946e-05 Training loss: 0.0
2025-12-09 10:24:40.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 8665 LR: 4.4135271455761905e-05 Training loss: 0.0
2025-12-09 10:24:40.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 8666 LR: 4.407011569415004e-05 Training loss: 0.0
2025-12-09 10:24:40.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 8667 LR: 4.4005005844665046e-05 Training loss: 0.0
2025-12-09 10:24:40.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 8668 LR: 4.393994191386352e-05 Training loss: 0.0
2025-12-09 10:24:40.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 8669 LR: 4.3874923908297335e-05 Training loss: 0.0
2025-12-09 10:24:40.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 8670 LR: 4.380995183451392e-05 Training loss: 0.0
2025-12-09 10:24:40.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 8671 LR: 4.37450256990557e-05 Training loss: 0.0
2025-12-09 10:24:40.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 8672 LR: 4.368014550846111e-05 Training loss: 0.0
2025-12-09 10:24:40.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 8673 LR: 4.361531126926327e-05 Training loss: 0.0
2025-12-09 10:24:40.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 8674 LR: 4.355052298799112e-05 Training loss: 0.0
2025-12-09 10:24:40.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 8675 LR: 4.348578067116882e-05 Training loss: 0.0
2025-12-09 10:24:40.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 8676 LR: 4.3421084325315885e-05 Training loss: 0.0
2025-12-09 10:24:40.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 8677 LR: 4.335643395694727e-05 Training loss: 0.0
2025-12-09 10:24:40.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 8678 LR: 4.3291829572573324e-05 Training loss: 0.0
2025-12-09 10:24:40.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 8679 LR: 4.322727117869951e-05 Training loss: 0.0
2025-12-09 10:24:40.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 8680 LR: 4.316275878182718e-05 Training loss: 0.0
2025-12-09 10:24:40.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 8681 LR: 4.309829238845242e-05 Training loss: 0.0
2025-12-09 10:24:40.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 8682 LR: 4.3033872005067085e-05 Training loss: 0.0
2025-12-09 10:24:40.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 8683 LR: 4.2969497638158384e-05 Training loss: 0.0
2025-12-09 10:24:40.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 8684 LR: 4.290516929420884e-05 Training loss: 0.0
2025-12-09 10:24:40.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 8685 LR: 4.284088697969607e-05 Training loss: 0.0
2025-12-09 10:24:40.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 8686 LR: 4.277665070109365e-05 Training loss: 0.0
2025-12-09 10:24:40.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 8687 LR: 4.271246046486993e-05 Training loss: 0.0
2025-12-09 10:24:40.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 8688 LR: 4.264831627748889e-05 Training loss: 0.0
2025-12-09 10:24:40.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 8689 LR: 4.2584218145409916e-05 Training loss: 0.0
2025-12-09 10:24:40.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 8690 LR: 4.252016607508763e-05 Training loss: 0.0
2025-12-09 10:24:40.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 8691 LR: 4.24561600729721e-05 Training loss: 0.0
2025-12-09 10:24:40.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 8692 LR: 4.239220014550882e-05 Training loss: 0.0
2025-12-09 10:24:40.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 8693 LR: 4.232828629913832e-05 Training loss: 0.0
2025-12-09 10:24:40.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 8694 LR: 4.2264418540297e-05 Training loss: 0.0
2025-12-09 10:24:40.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 8695 LR: 4.220059687541617e-05 Training loss: 0.0
2025-12-09 10:24:40.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 8696 LR: 4.213682131092267e-05 Training loss: 0.0
2025-12-09 10:24:40.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 8697 LR: 4.207309185323876e-05 Training loss: 0.0
2025-12-09 10:24:40.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 8698 LR: 4.2009408508781934e-05 Training loss: 0.0
2025-12-09 10:24:40.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 8699 LR: 4.194577128396521e-05 Training loss: 0.0
2025-12-09 10:24:40.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 8700 LR: 4.18821801851968e-05 Training loss: 0.0
2025-12-09 10:24:40.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 8701 LR: 4.181863521888019e-05 Training loss: 0.0
2025-12-09 10:24:40.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 8702 LR: 4.17551363914146e-05 Training loss: 0.0
2025-12-09 10:24:40.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 8703 LR: 4.1691683709194184e-05 Training loss: 0.0
2025-12-09 10:24:40.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 8704 LR: 4.1628277178608674e-05 Training loss: 0.0
2025-12-09 10:24:40.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 8705 LR: 4.1564916806043074e-05 Training loss: 0.0
2025-12-09 10:24:40.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 8706 LR: 4.150160259787783e-05 Training loss: 0.0
2025-12-09 10:24:40.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 8707 LR: 4.143833456048868e-05 Training loss: 0.0
2025-12-09 10:24:40.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 8708 LR: 4.1375112700246795e-05 Training loss: 0.0
2025-12-09 10:24:40.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 8709 LR: 4.1311937023518264e-05 Training loss: 0.0
2025-12-09 10:24:40.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 8710 LR: 4.124880753666538e-05 Training loss: 0.0
2025-12-09 10:24:40.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 8711 LR: 4.1185724246044884e-05 Training loss: 0.0
2025-12-09 10:24:40.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 8712 LR: 4.112268715800943e-05 Training loss: 0.0
2025-12-09 10:24:41.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 8713 LR: 4.105969627890682e-05 Training loss: 0.0
2025-12-09 10:24:41.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 8714 LR: 4.0996751615080204e-05 Training loss: 0.0
2025-12-09 10:24:41.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 8715 LR: 4.0933853172868185e-05 Training loss: 0.0
2025-12-09 10:24:41.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 8716 LR: 4.0871000958604685e-05 Training loss: 0.0
2025-12-09 10:24:41.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 8717 LR: 4.0808194978618706e-05 Training loss: 0.0
2025-12-09 10:24:41.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 8718 LR: 4.074543523923491e-05 Training loss: 0.0
2025-12-09 10:24:41.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 8719 LR: 4.0682721746773344e-05 Training loss: 0.0
2025-12-09 10:24:41.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 8720 LR: 4.062005450754897e-05 Training loss: 0.0
2025-12-09 10:24:41.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 8721 LR: 4.055743352787267e-05 Training loss: 0.0
2025-12-09 10:24:41.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 8722 LR: 4.0494858814050185e-05 Training loss: 0.0
2025-12-09 10:24:41.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 8723 LR: 4.043233037238281e-05 Training loss: 0.0
2025-12-09 10:24:41.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 8724 LR: 4.036984820916722e-05 Training loss: 0.0
2025-12-09 10:24:41.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 8725 LR: 4.030741233069535e-05 Training loss: 0.0
2025-12-09 10:24:41.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 8726 LR: 4.0245022743254476e-05 Training loss: 0.0
2025-12-09 10:24:41.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 8727 LR: 4.0182679453127316e-05 Training loss: 0.0
2025-12-09 10:24:41.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 8728 LR: 4.0120382466591555e-05 Training loss: 0.0
2025-12-09 10:24:41.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 8729 LR: 4.0058131789920904e-05 Training loss: 0.0
2025-12-09 10:24:41.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 8730 LR: 3.999592742938368e-05 Training loss: 0.0
2025-12-09 10:24:41.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 8731 LR: 3.993376939124399e-05 Training loss: 0.0
2025-12-09 10:24:41.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 8732 LR: 3.98716576817611e-05 Training loss: 0.0
2025-12-09 10:24:41.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 8733 LR: 3.980959230718972e-05 Training loss: 0.0
2025-12-09 10:24:41.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 8734 LR: 3.974757327377981e-05 Training loss: 0.0
2025-12-09 10:24:41.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 8735 LR: 3.9685600587776814e-05 Training loss: 0.0
2025-12-09 10:24:41.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 8736 LR: 3.962367425542102e-05 Training loss: 0.0
2025-12-09 10:24:41.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 8737 LR: 3.956179428294876e-05 Training loss: 0.0
2025-12-09 10:24:41.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 8738 LR: 3.949996067659117e-05 Training loss: 0.0
2025-12-09 10:24:41.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 8739 LR: 3.9438173442575e-05 Training loss: 0.0
2025-12-09 10:24:41.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 8740 LR: 3.937643258712209e-05 Training loss: 0.0
2025-12-09 10:24:41.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 8741 LR: 3.9314738116449814e-05 Training loss: 0.0
2025-12-09 10:24:41.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 8742 LR: 3.925309003677086e-05 Training loss: 0.0
2025-12-09 10:24:41.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 8743 LR: 3.9191488354293146e-05 Training loss: 0.0
2025-12-09 10:24:41.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 8744 LR: 3.9129933075219836e-05 Training loss: 0.0
2025-12-09 10:24:41.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 8745 LR: 3.90684242057498e-05 Training loss: 0.0
2025-12-09 10:24:41.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 8746 LR: 3.900696175207674e-05 Training loss: 0.0
2025-12-09 10:24:41.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 8747 LR: 3.894554572038999e-05 Training loss: 0.0
2025-12-09 10:24:41.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 8748 LR: 3.8884176116874227e-05 Training loss: 0.0
2025-12-09 10:24:41.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 8749 LR: 3.882285294770937e-05 Training loss: 0.0
2025-12-09 10:24:41.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 8750 LR: 3.876157621907045e-05 Training loss: 0.0
2025-12-09 10:24:41.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 8751 LR: 3.870034593712835e-05 Training loss: 0.0
2025-12-09 10:24:41.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 8752 LR: 3.8639162108048685e-05 Training loss: 0.0
2025-12-09 10:24:41.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 8753 LR: 3.8578024737992825e-05 Training loss: 0.0
2025-12-09 10:24:41.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 8754 LR: 3.851693383311722e-05 Training loss: 0.0
2025-12-09 10:24:41.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 8755 LR: 3.845588939957373e-05 Training loss: 0.0
2025-12-09 10:24:41.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 8756 LR: 3.839489144350955e-05 Training loss: 0.0
2025-12-09 10:24:41.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 8757 LR: 3.8333939971067264e-05 Training loss: 0.0
2025-12-09 10:24:41.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 8758 LR: 3.8273034988384414e-05 Training loss: 0.0
2025-12-09 10:24:41.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 8759 LR: 3.821217650159453e-05 Training loss: 0.0
2025-12-09 10:24:41.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 8760 LR: 3.815136451682566e-05 Training loss: 0.0
2025-12-09 10:24:41.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 8761 LR: 3.8090599040201845e-05 Training loss: 0.0
2025-12-09 10:24:41.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 8762 LR: 3.8029880077841974e-05 Training loss: 0.0
2025-12-09 10:24:41.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 8763 LR: 3.7969207635860594e-05 Training loss: 0.0
2025-12-09 10:24:41.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 8764 LR: 3.7908581720367376e-05 Training loss: 0.0
2025-12-09 10:24:41.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 8765 LR: 3.784800233746738e-05 Training loss: 0.0
2025-12-09 10:24:41.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 8766 LR: 3.7787469493260786e-05 Training loss: 0.0
2025-12-09 10:24:41.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 8767 LR: 3.772698319384349e-05 Training loss: 0.0
2025-12-09 10:24:41.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 8768 LR: 3.7666543445306234e-05 Training loss: 0.0
2025-12-09 10:24:41.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 8769 LR: 3.760615025373543e-05 Training loss: 0.0
2025-12-09 10:24:41.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 8770 LR: 3.754580362521265e-05 Training loss: 0.0
2025-12-09 10:24:41.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 8771 LR: 3.748550356581482e-05 Training loss: 0.0
2025-12-09 10:24:41.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 8772 LR: 3.742525008161407e-05 Training loss: 0.0
2025-12-09 10:24:41.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 8773 LR: 3.7365043178678114e-05 Training loss: 0.0
2025-12-09 10:24:41.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 8774 LR: 3.7304882863069436e-05 Training loss: 0.0
2025-12-09 10:24:41.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 8775 LR: 3.724476914084657e-05 Training loss: 0.0
2025-12-09 10:24:41.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 8776 LR: 3.7184702018062736e-05 Training loss: 0.0
2025-12-09 10:24:41.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 8777 LR: 3.71246815007667e-05 Training loss: 0.0
2025-12-09 10:24:41.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 8778 LR: 3.7064707595002634e-05 Training loss: 0.0
2025-12-09 10:24:41.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 8779 LR: 3.700478030680987e-05 Training loss: 0.0
2025-12-09 10:24:41.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 8780 LR: 3.694489964222292e-05 Training loss: 0.0
2025-12-09 10:24:41.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 8781 LR: 3.688506560727206e-05 Training loss: 0.0
2025-12-09 10:24:41.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 8782 LR: 3.682527820798237e-05 Training loss: 0.0
2025-12-09 10:24:41.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 8783 LR: 3.676553745037447e-05 Training loss: 0.0
2025-12-09 10:24:41.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 8784 LR: 3.6705843340464284e-05 Training loss: 0.0
2025-12-09 10:24:41.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 8785 LR: 3.664619588426299e-05 Training loss: 0.0
2025-12-09 10:24:41.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 8786 LR: 3.658659508777706e-05 Training loss: 0.0
2025-12-09 10:24:41.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 8787 LR: 3.652704095700849e-05 Training loss: 0.0
2025-12-09 10:24:41.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 8788 LR: 3.646753349795395e-05 Training loss: 0.0
2025-12-09 10:24:41.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 8789 LR: 3.6408072716606344e-05 Training loss: 0.0
2025-12-09 10:24:41.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 8790 LR: 3.6348658618953034e-05 Training loss: 0.0
2025-12-09 10:24:41.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 8791 LR: 3.628929121097707e-05 Training loss: 0.0
2025-12-09 10:24:41.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 8792 LR: 3.6229970498656836e-05 Training loss: 0.0
2025-12-09 10:24:41.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 8793 LR: 3.6170696487965894e-05 Training loss: 0.0
2025-12-09 10:24:41.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 8794 LR: 3.611146918487307e-05 Training loss: 0.0
2025-12-09 10:24:41.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 8795 LR: 3.6052288595342705e-05 Training loss: 0.0
2025-12-09 10:24:41.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 8796 LR: 3.5993154725334046e-05 Training loss: 0.0
2025-12-09 10:24:41.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 8797 LR: 3.59340675808022e-05 Training loss: 0.0
2025-12-09 10:24:41.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 8798 LR: 3.5875027167696916e-05 Training loss: 0.0
2025-12-09 10:24:41.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 8799 LR: 3.5816033491963716e-05 Training loss: 0.0
2025-12-09 10:24:41.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 8800 LR: 3.575708655954324e-05 Training loss: 0.0
2025-12-09 10:24:41.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 8801 LR: 3.569818637637146e-05 Training loss: 0.0
2025-12-09 10:24:41.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 8802 LR: 3.563933294837957e-05 Training loss: 0.0
2025-12-09 10:24:41.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 8803 LR: 3.5580526281494216e-05 Training loss: 0.0
2025-12-09 10:24:41.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 8804 LR: 3.552176638163707e-05 Training loss: 0.0
2025-12-09 10:24:41.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 8805 LR: 3.546305325472543e-05 Training loss: 0.0
2025-12-09 10:24:41.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 8806 LR: 3.540438690667158e-05 Training loss: 0.0
2025-12-09 10:24:41.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 8807 LR: 3.534576734338324e-05 Training loss: 0.0
2025-12-09 10:24:41.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 8808 LR: 3.5287194570763516e-05 Training loss: 0.0
2025-12-09 10:24:41.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 8809 LR: 3.522866859471047e-05 Training loss: 0.0
2025-12-09 10:24:41.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 8810 LR: 3.5170189421117826e-05 Training loss: 0.0
2025-12-09 10:24:41.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 8811 LR: 3.5111757055874326e-05 Training loss: 0.0
2025-12-09 10:24:41.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 8812 LR: 3.505337150486421e-05 Training loss: 0.0
2025-12-09 10:24:41.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 8813 LR: 3.4995032773966876e-05 Training loss: 0.0
2025-12-09 10:24:41.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 8814 LR: 3.4936740869057074e-05 Training loss: 0.0
2025-12-09 10:24:41.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 8815 LR: 3.487849579600455e-05 Training loss: 0.0
2025-12-09 10:24:41.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 8816 LR: 3.482029756067501e-05 Training loss: 0.0
2025-12-09 10:24:41.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 8817 LR: 3.476214616892864e-05 Training loss: 0.0
2025-12-09 10:24:41.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 8818 LR: 3.470404162662144e-05 Training loss: 0.0
2025-12-09 10:24:41.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 8819 LR: 3.46459839396045e-05 Training loss: 0.0
2025-12-09 10:24:41.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 8820 LR: 3.4587973113724244e-05 Training loss: 0.0
2025-12-09 10:24:41.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 8821 LR: 3.4530009154822404e-05 Training loss: 0.0
2025-12-09 10:24:41.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 8822 LR: 3.4472092068735914e-05 Training loss: 0.0
2025-12-09 10:24:41.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 8823 LR: 3.441422186129689e-05 Training loss: 0.0
2025-12-09 10:24:41.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 8824 LR: 3.435639853833317e-05 Training loss: 0.0
2025-12-09 10:24:41.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 8825 LR: 3.429862210566731e-05 Training loss: 0.0
2025-12-09 10:24:41.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 8826 LR: 3.424089256911739e-05 Training loss: 0.0
2025-12-09 10:24:41.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 8827 LR: 3.418320993449692e-05 Training loss: 0.0
2025-12-09 10:24:41.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 8828 LR: 3.4125574207614416e-05 Training loss: 0.0
2025-12-09 10:24:41.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 8829 LR: 3.406798539427386e-05 Training loss: 0.0
2025-12-09 10:24:41.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 8830 LR: 3.401044350027449e-05 Training loss: 0.0
2025-12-09 10:24:41.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 8831 LR: 3.3952948531410564e-05 Training loss: 0.0
2025-12-09 10:24:41.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 8832 LR: 3.389550049347212e-05 Training loss: 0.0
2025-12-09 10:24:41.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 8833 LR: 3.383809939224392e-05 Training loss: 0.0
2025-12-09 10:24:41.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 8834 LR: 3.378074523350638e-05 Training loss: 0.0
2025-12-09 10:24:41.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 8835 LR: 3.372343802303507e-05 Training loss: 0.0
2025-12-09 10:24:41.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 8836 LR: 3.366617776660075e-05 Training loss: 0.0
2025-12-09 10:24:41.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 8837 LR: 3.360896446996958e-05 Training loss: 0.0
2025-12-09 10:24:41.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 8838 LR: 3.355179813890302e-05 Training loss: 0.0
2025-12-09 10:24:41.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 8839 LR: 3.349467877915746e-05 Training loss: 0.0
2025-12-09 10:24:41.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 8840 LR: 3.3437606396485134e-05 Training loss: 0.0
2025-12-09 10:24:41.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 8841 LR: 3.3380580996632995e-05 Training loss: 0.0
2025-12-09 10:24:41.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 8842 LR: 3.3323602585343615e-05 Training loss: 0.0
2025-12-09 10:24:41.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 8843 LR: 3.3266671168354634e-05 Training loss: 0.0
2025-12-09 10:24:41.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 8844 LR: 3.3209786751399184e-05 Training loss: 0.0
2025-12-09 10:24:41.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 8845 LR: 3.3152949340205294e-05 Training loss: 0.0
2025-12-09 10:24:41.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 8846 LR: 3.309615894049678e-05 Training loss: 0.0
2025-12-09 10:24:41.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 8847 LR: 3.3039415557992226e-05 Training loss: 0.0
2025-12-09 10:24:41.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 8848 LR: 3.298271919840573e-05 Training loss: 0.0
2025-12-09 10:24:41.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 8849 LR: 3.292606986744667e-05 Training loss: 0.0
2025-12-09 10:24:41.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 8850 LR: 3.2869467570819546e-05 Training loss: 0.0
2025-12-09 10:24:41.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 8851 LR: 3.2812912314224285e-05 Training loss: 0.0
2025-12-09 10:24:41.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 8852 LR: 3.2756404103356005e-05 Training loss: 0.0
2025-12-09 10:24:41.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 8853 LR: 3.269994294390494e-05 Training loss: 0.0
2025-12-09 10:24:41.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 8854 LR: 3.264352884155697e-05 Training loss: 0.0
2025-12-09 10:24:41.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 8855 LR: 3.258716180199278e-05 Training loss: 0.0
2025-12-09 10:24:41.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 8856 LR: 3.253084183088861e-05 Training loss: 0.0
2025-12-09 10:24:41.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 8857 LR: 3.2474568933915924e-05 Training loss: 0.0
2025-12-09 10:24:41.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 8858 LR: 3.24183431167413e-05 Training loss: 0.0
2025-12-09 10:24:41.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 8859 LR: 3.23621643850267e-05 Training loss: 0.0
2025-12-09 10:24:41.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 8860 LR: 3.23060327444295e-05 Training loss: 0.0
2025-12-09 10:24:41.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 8861 LR: 3.224994820060184e-05 Training loss: 0.0
2025-12-09 10:24:41.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 8862 LR: 3.2193910759191705e-05 Training loss: 0.0
2025-12-09 10:24:41.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 8863 LR: 3.21379204258419e-05 Training loss: 0.0
2025-12-09 10:24:41.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 8864 LR: 3.2081977206190716e-05 Training loss: 0.0
2025-12-09 10:24:41.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 8865 LR: 3.202608110587163e-05 Training loss: 0.0
2025-12-09 10:24:41.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 8866 LR: 3.1970232130513366e-05 Training loss: 0.0
2025-12-09 10:24:41.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 8867 LR: 3.191443028573993e-05 Training loss: 0.0
2025-12-09 10:24:41.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 8868 LR: 3.1858675577170594e-05 Training loss: 0.0
2025-12-09 10:24:41.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 8869 LR: 3.180296801041971e-05 Training loss: 0.0
2025-12-09 10:24:41.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 8870 LR: 3.174730759109723e-05 Training loss: 0.0
2025-12-09 10:24:41.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 8871 LR: 3.169169432480806e-05 Training loss: 0.0
2025-12-09 10:24:41.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 8872 LR: 3.163612821715239e-05 Training loss: 0.0
2025-12-09 10:24:41.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 8873 LR: 3.158060927372586e-05 Training loss: 0.0
2025-12-09 10:24:41.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 8874 LR: 3.152513750011921e-05 Training loss: 0.0
2025-12-09 10:24:41.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 8875 LR: 3.1469712901918244e-05 Training loss: 0.0
2025-12-09 10:24:41.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 8876 LR: 3.141433548470451e-05 Training loss: 0.0
2025-12-09 10:24:41.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 8877 LR: 3.1359005254054274e-05 Training loss: 0.0
2025-12-09 10:24:41.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 8878 LR: 3.1303722215539395e-05 Training loss: 0.0
2025-12-09 10:24:41.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 8879 LR: 3.124848637472688e-05 Training loss: 0.0
2025-12-09 10:24:41.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 8880 LR: 3.119329773717899e-05 Training loss: 0.0
2025-12-09 10:24:41.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 8881 LR: 3.113815630845318e-05 Training loss: 0.0
2025-12-09 10:24:41.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 8882 LR: 3.108306209410222e-05 Training loss: 0.0
2025-12-09 10:24:41.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 8883 LR: 3.1028015099673954e-05 Training loss: 0.0
2025-12-09 10:24:41.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 8884 LR: 3.0973015330711896e-05 Training loss: 0.0
2025-12-09 10:24:41.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 8885 LR: 3.091806279275433e-05 Training loss: 0.0
2025-12-09 10:24:41.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 8886 LR: 3.086315749133495e-05 Training loss: 0.0
2025-12-09 10:24:41.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 8887 LR: 3.080829943198277e-05 Training loss: 0.0
2025-12-09 10:24:41.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 8888 LR: 3.075348862022204e-05 Training loss: 0.0
2025-12-09 10:24:41.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 8889 LR: 3.069872506157212e-05 Training loss: 0.0
2025-12-09 10:24:41.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 8890 LR: 3.064400876154782e-05 Training loss: 0.0
2025-12-09 10:24:41.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 8891 LR: 3.058933972565897e-05 Training loss: 0.0
2025-12-09 10:24:41.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 8892 LR: 3.0534717959410764e-05 Training loss: 0.0
2025-12-09 10:24:41.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 8893 LR: 3.048014346830358e-05 Training loss: 0.0
2025-12-09 10:24:41.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 8894 LR: 3.0425616257833078e-05 Training loss: 0.0
2025-12-09 10:24:41.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 8895 LR: 3.0371136333490312e-05 Training loss: 0.0
2025-12-09 10:24:41.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 8896 LR: 3.0316703700761063e-05 Training loss: 0.0
2025-12-09 10:24:41.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 8897 LR: 3.026231836512705e-05 Training loss: 0.0
2025-12-09 10:24:41.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 8898 LR: 3.0207980332064676e-05 Training loss: 0.0
2025-12-09 10:24:41.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 8899 LR: 3.0153689607045842e-05 Training loss: 0.0
2025-12-09 10:24:41.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 8900 LR: 3.009944619553756e-05 Training loss: 0.0
2025-12-09 10:24:41.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 8901 LR: 3.0045250103002298e-05 Training loss: 0.0
2025-12-09 10:24:41.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 8902 LR: 2.9991101334897353e-05 Training loss: 0.0
2025-12-09 10:24:41.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 8903 LR: 2.9936999896675755e-05 Training loss: 0.0
2025-12-09 10:24:41.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 8904 LR: 2.9882945793785364e-05 Training loss: 0.0
2025-12-09 10:24:41.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 8905 LR: 2.9828939031669446e-05 Training loss: 0.0
2025-12-09 10:24:41.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 8906 LR: 2.977497961576653e-05 Training loss: 0.0
2025-12-09 10:24:41.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 8907 LR: 2.9721067551510273e-05 Training loss: 0.0
2025-12-09 10:24:41.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 8908 LR: 2.9667202844329667e-05 Training loss: 0.0
2025-12-09 10:24:41.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 8909 LR: 2.9613385499648926e-05 Training loss: 0.0
2025-12-09 10:24:41.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 8910 LR: 2.9559615522887274e-05 Training loss: 0.0
2025-12-09 10:24:41.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 8911 LR: 2.9505892919459543e-05 Training loss: 0.0
2025-12-09 10:24:41.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 8912 LR: 2.9452217694775518e-05 Training loss: 0.0
2025-12-09 10:24:41.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 8913 LR: 2.9398589854240266e-05 Training loss: 0.0
2025-12-09 10:24:41.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 8914 LR: 2.934500940325413e-05 Training loss: 0.0
2025-12-09 10:24:41.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 8915 LR: 2.9291476347212686e-05 Training loss: 0.0
2025-12-09 10:24:41.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 8916 LR: 2.9237990691506734e-05 Training loss: 0.0
2025-12-09 10:24:41.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 8917 LR: 2.918455244152224e-05 Training loss: 0.0
2025-12-09 10:24:41.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 8918 LR: 2.9131161602640343e-05 Training loss: 0.0
2025-12-09 10:24:41.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 8919 LR: 2.9077818180237692e-05 Training loss: 0.0
2025-12-09 10:24:41.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 8920 LR: 2.902452217968582e-05 Training loss: 0.0
2025-12-09 10:24:41.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 8921 LR: 2.8971273606351657e-05 Training loss: 0.0
2025-12-09 10:24:41.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 8922 LR: 2.8918072465597355e-05 Training loss: 0.0
2025-12-09 10:24:41.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 8923 LR: 2.8864918762780302e-05 Training loss: 0.0
2025-12-09 10:24:41.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 8924 LR: 2.8811812503252988e-05 Training loss: 0.0
2025-12-09 10:24:41.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 8925 LR: 2.875875369236336e-05 Training loss: 0.0
2025-12-09 10:24:41.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 8926 LR: 2.87057423354542e-05 Training loss: 0.0
2025-12-09 10:24:41.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 8927 LR: 2.8652778437864013e-05 Training loss: 0.0
2025-12-09 10:24:41.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 8928 LR: 2.8599862004926093e-05 Training loss: 0.0
2025-12-09 10:24:41.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 8929 LR: 2.8546993041969172e-05 Training loss: 0.0
2025-12-09 10:24:41.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 8930 LR: 2.849417155431716e-05 Training loss: 0.0
2025-12-09 10:24:41.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 8931 LR: 2.844139754728914e-05 Training loss: 0.0
2025-12-09 10:24:41.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 8932 LR: 2.838867102619952e-05 Training loss: 0.0
2025-12-09 10:24:41.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 8933 LR: 2.8335991996357835e-05 Training loss: 0.0
2025-12-09 10:24:41.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 8934 LR: 2.8283360463068787e-05 Training loss: 0.0
2025-12-09 10:24:41.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 8935 LR: 2.823077643163252e-05 Training loss: 0.0
2025-12-09 10:24:41.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 8936 LR: 2.8178239907344082e-05 Training loss: 0.0
2025-12-09 10:24:41.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 8937 LR: 2.8125750895494017e-05 Training loss: 0.0
2025-12-09 10:24:41.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 8938 LR: 2.8073309401367876e-05 Training loss: 0.0
2025-12-09 10:24:41.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 8939 LR: 2.802091543024671e-05 Training loss: 0.0
2025-12-09 10:24:41.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 8940 LR: 2.796856898740624e-05 Training loss: 0.0
2025-12-09 10:24:41.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 8941 LR: 2.7916270078118088e-05 Training loss: 0.0
2025-12-09 10:24:41.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 8942 LR: 2.7864018707648596e-05 Training loss: 0.0
2025-12-09 10:24:41.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 8943 LR: 2.78118148812595e-05 Training loss: 0.0
2025-12-09 10:24:41.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 8944 LR: 2.7759658604207703e-05 Training loss: 0.0
2025-12-09 10:24:41.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 8945 LR: 2.7707549881745397e-05 Training loss: 0.0
2025-12-09 10:24:41.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 8946 LR: 2.7655488719119826e-05 Training loss: 0.0
2025-12-09 10:24:41.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 8947 LR: 2.760347512157374e-05 Training loss: 0.0
2025-12-09 10:24:41.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 8948 LR: 2.7551509094344674e-05 Training loss: 0.0
2025-12-09 10:24:41.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 8949 LR: 2.7499590642665774e-05 Training loss: 0.0
2025-12-09 10:24:41.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 8950 LR: 2.7447719771765136e-05 Training loss: 0.0
2025-12-09 10:24:41.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 8951 LR: 2.739589648686619e-05 Training loss: 0.0
2025-12-09 10:24:41.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 8952 LR: 2.7344120793187543e-05 Training loss: 0.0
2025-12-09 10:24:41.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 8953 LR: 2.7292392695943023e-05 Training loss: 0.0
2025-12-09 10:24:41.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 8954 LR: 2.724071220034158e-05 Training loss: 0.0
2025-12-09 10:24:41.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 8955 LR: 2.7189079311587595e-05 Training loss: 0.0
2025-12-09 10:24:41.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 8956 LR: 2.7137494034880196e-05 Training loss: 0.0
2025-12-09 10:24:41.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 8957 LR: 2.7085956375414388e-05 Training loss: 0.0
2025-12-09 10:24:41.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 8958 LR: 2.703446633837975e-05 Training loss: 0.0
2025-12-09 10:24:41.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 8959 LR: 2.6983023928961405e-05 Training loss: 0.0
2025-12-09 10:24:41.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 8960 LR: 2.6931629152339598e-05 Training loss: 0.0
2025-12-09 10:24:41.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 8961 LR: 2.6880282013689806e-05 Training loss: 0.0
2025-12-09 10:24:41.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 8962 LR: 2.6828982518182666e-05 Training loss: 0.0
2025-12-09 10:24:41.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 8963 LR: 2.6777730670984103e-05 Training loss: 0.0
2025-12-09 10:24:41.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 8964 LR: 2.6726526477254985e-05 Training loss: 0.0
2025-12-09 10:24:41.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 8965 LR: 2.667536994215186e-05 Training loss: 0.0
2025-12-09 10:24:41.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 8966 LR: 2.662426107082594e-05 Training loss: 0.0
2025-12-09 10:24:41.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 8967 LR: 2.6573199868423937e-05 Training loss: 0.0
2025-12-09 10:24:41.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 8968 LR: 2.6522186340087794e-05 Training loss: 0.0
2025-12-09 10:24:41.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 8969 LR: 2.6471220490954628e-05 Training loss: 0.0
2025-12-09 10:24:41.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 8970 LR: 2.6420302326156444e-05 Training loss: 0.0
2025-12-09 10:24:41.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 8971 LR: 2.636943185082097e-05 Training loss: 0.0
2025-12-09 10:24:41.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 8972 LR: 2.631860907007072e-05 Training loss: 0.0
2025-12-09 10:24:41.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 8973 LR: 2.626783398902355e-05 Training loss: 0.0
2025-12-09 10:24:41.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 8974 LR: 2.6217106612792528e-05 Training loss: 0.0
2025-12-09 10:24:41.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 8975 LR: 2.616642694648591e-05 Training loss: 0.0
2025-12-09 10:24:41.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 8976 LR: 2.611579499520722e-05 Training loss: 0.0
2025-12-09 10:24:41.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 8977 LR: 2.6065210764054936e-05 Training loss: 0.0
2025-12-09 10:24:41.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 8978 LR: 2.601467425812293e-05 Training loss: 0.0
2025-12-09 10:24:41.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 8979 LR: 2.596418548250029e-05 Training loss: 0.0
2025-12-09 10:24:41.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 8980 LR: 2.591374444227118e-05 Training loss: 0.0
2025-12-09 10:24:41.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 8981 LR: 2.5863351142515035e-05 Training loss: 0.0
2025-12-09 10:24:41.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 8982 LR: 2.581300558830657e-05 Training loss: 0.0
2025-12-09 10:24:41.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 8983 LR: 2.576270778471529e-05 Training loss: 0.0
2025-12-09 10:24:41.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 8984 LR: 2.571245773680647e-05 Training loss: 0.0
2025-12-09 10:24:41.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 8985 LR: 2.5662255449640125e-05 Training loss: 0.0
2025-12-09 10:24:41.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 8986 LR: 2.561210092827171e-05 Training loss: 0.0
2025-12-09 10:24:41.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 8987 LR: 2.5561994177751735e-05 Training loss: 0.0
2025-12-09 10:24:41.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 8988 LR: 2.5511935203126003e-05 Training loss: 0.0
2025-12-09 10:24:41.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 8989 LR: 2.5461924009435368e-05 Training loss: 0.0
2025-12-09 10:24:41.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 8990 LR: 2.541196060171608e-05 Training loss: 0.0
2025-12-09 10:24:41.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 8991 LR: 2.536204498499922e-05 Training loss: 0.0
2025-12-09 10:24:41.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 8992 LR: 2.531217716431161e-05 Training loss: 0.0
2025-12-09 10:24:41.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 8993 LR: 2.5262357144674674e-05 Training loss: 0.0
2025-12-09 10:24:41.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 8994 LR: 2.52125849311054e-05 Training loss: 0.0
2025-12-09 10:24:41.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 8995 LR: 2.5162860528615827e-05 Training loss: 0.0
2025-12-09 10:24:41.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 8996 LR: 2.511318394221329e-05 Training loss: 0.0
2025-12-09 10:24:41.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 8997 LR: 2.5063555176899953e-05 Training loss: 0.0
2025-12-09 10:24:41.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 8998 LR: 2.501397423767382e-05 Training loss: 0.0
2025-12-09 10:24:41.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 8999 LR: 2.4964441129527336e-05 Training loss: 0.0
2025-12-09 10:24:41.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 9000 LR: 2.4914955857448686e-05 Training loss: 0.0
2025-12-09 10:24:41.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 9001 LR: 2.4865518426420987e-05 Training loss: 0.0
2025-12-09 10:24:41.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 9002 LR: 2.4816128841422538e-05 Training loss: 0.0
2025-12-09 10:24:41.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 9003 LR: 2.476678710742697e-05 Training loss: 0.0
2025-12-09 10:24:41.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 9004 LR: 2.4717493229402976e-05 Training loss: 0.0
2025-12-09 10:24:41.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 9005 LR: 2.4668247212314254e-05 Training loss: 0.0
2025-12-09 10:24:41.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 9006 LR: 2.4619049061120224e-05 Training loss: 0.0
2025-12-09 10:24:41.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 9007 LR: 2.4569898780774813e-05 Training loss: 0.0
2025-12-09 10:24:41.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 9008 LR: 2.4520796376227617e-05 Training loss: 0.0
2025-12-09 10:24:41.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 9009 LR: 2.4471741852423235e-05 Training loss: 0.0
2025-12-09 10:24:41.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 9010 LR: 2.4422735214301438e-05 Training loss: 0.0
2025-12-09 10:24:41.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 9011 LR: 2.4373776466797172e-05 Training loss: 0.0
2025-12-09 10:24:41.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 9012 LR: 2.4324865614840653e-05 Training loss: 0.0
2025-12-09 10:24:41.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 9013 LR: 2.4276002663357e-05 Training loss: 0.0
2025-12-09 10:24:41.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 9014 LR: 2.4227187617267056e-05 Training loss: 0.0
2025-12-09 10:24:41.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 9015 LR: 2.417842048148622e-05 Training loss: 0.0
2025-12-09 10:24:41.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 9016 LR: 2.4129701260925396e-05 Training loss: 0.0
2025-12-09 10:24:41.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 9017 LR: 2.4081029960490664e-05 Training loss: 0.0
2025-12-09 10:24:41.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 9018 LR: 2.4032406585083157e-05 Training loss: 0.0
2025-12-09 10:24:41.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 9019 LR: 2.3983831139599287e-05 Training loss: 0.0
2025-12-09 10:24:41.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 9020 LR: 2.3935303628930704e-05 Training loss: 0.0
2025-12-09 10:24:41.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 9021 LR: 2.388682405796383e-05 Training loss: 0.0
2025-12-09 10:24:41.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 9022 LR: 2.3838392431580925e-05 Training loss: 0.0
2025-12-09 10:24:41.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 9023 LR: 2.379000875465881e-05 Training loss: 0.0
2025-12-09 10:24:41.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 9024 LR: 2.3741673032069754e-05 Training loss: 0.0
2025-12-09 10:24:41.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 9025 LR: 2.36933852686812e-05 Training loss: 0.0
2025-12-09 10:24:41.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 9026 LR: 2.3645145469355757e-05 Training loss: 0.0
2025-12-09 10:24:41.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 9027 LR: 2.359695363895109e-05 Training loss: 0.0
2025-12-09 10:24:41.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 9028 LR: 2.354880978232021e-05 Training loss: 0.0
2025-12-09 10:24:41.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 9029 LR: 2.3500713904311022e-05 Training loss: 0.0
2025-12-09 10:24:41.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 9030 LR: 2.3452666009767032e-05 Training loss: 0.0
2025-12-09 10:24:41.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 9031 LR: 2.340466610352654e-05 Training loss: 0.0
2025-12-09 10:24:41.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 9032 LR: 2.3356714190423067e-05 Training loss: 0.0
2025-12-09 10:24:41.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 9033 LR: 2.330881027528542e-05 Training loss: 0.0
2025-12-09 10:24:41.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 9034 LR: 2.3260954362937626e-05 Training loss: 0.0
2025-12-09 10:24:41.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 9035 LR: 2.321314645819855e-05 Training loss: 0.0
2025-12-09 10:24:41.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 9036 LR: 2.316538656588274e-05 Training loss: 0.0
2025-12-09 10:24:41.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 9037 LR: 2.311767469079934e-05 Training loss: 0.0
2025-12-09 10:24:41.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 9038 LR: 2.3070010837753063e-05 Training loss: 0.0
2025-12-09 10:24:41.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 9039 LR: 2.3022395011543685e-05 Training loss: 0.0
2025-12-09 10:24:41.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 9040 LR: 2.2974827216966032e-05 Training loss: 0.0
2025-12-09 10:24:41.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 9041 LR: 2.292730745881022e-05 Training loss: 0.0
2025-12-09 10:24:41.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 9042 LR: 2.287983574186159e-05 Training loss: 0.0
2025-12-09 10:24:41.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 9043 LR: 2.283241207090031e-05 Training loss: 0.0
2025-12-09 10:24:41.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 9044 LR: 2.2785036450702235e-05 Training loss: 0.0
2025-12-09 10:24:41.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 9045 LR: 2.273770888603782e-05 Training loss: 0.0
2025-12-09 10:24:41.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 9046 LR: 2.2690429381673095e-05 Training loss: 0.0
2025-12-09 10:24:41.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 9047 LR: 2.264319794236902e-05 Training loss: 0.0
2025-12-09 10:24:41.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 9048 LR: 2.2596014572881908e-05 Training loss: 0.0
2025-12-09 10:24:41.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 9049 LR: 2.2548879277963063e-05 Training loss: 0.0
2025-12-09 10:24:41.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 9050 LR: 2.2501792062359026e-05 Training loss: 0.0
2025-12-09 10:24:41.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 9051 LR: 2.2454752930811396e-05 Training loss: 0.0
2025-12-09 10:24:41.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 9052 LR: 2.2407761888057154e-05 Training loss: 0.0
2025-12-09 10:24:41.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 9053 LR: 2.236081893882819e-05 Training loss: 0.0
2025-12-09 10:24:41.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 9054 LR: 2.2313924087851657e-05 Training loss: 0.0
2025-12-09 10:24:41.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 9055 LR: 2.226707733984995e-05 Training loss: 0.0
2025-12-09 10:24:41.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 9056 LR: 2.222027869954041e-05 Training loss: 0.0
2025-12-09 10:24:41.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 9057 LR: 2.2173528171635814e-05 Training loss: 0.0
2025-12-09 10:24:41.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 9058 LR: 2.212682576084385e-05 Training loss: 0.0
2025-12-09 10:24:41.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 9059 LR: 2.208017147186736e-05 Training loss: 0.0
2025-12-09 10:24:41.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 9060 LR: 2.2033565309404703e-05 Training loss: 0.0
2025-12-09 10:24:41.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 9061 LR: 2.198700727814884e-05 Training loss: 0.0
2025-12-09 10:24:41.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 9062 LR: 2.1940497382788195e-05 Training loss: 0.0
2025-12-09 10:24:41.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 9063 LR: 2.1894035628006514e-05 Training loss: 0.0
2025-12-09 10:24:41.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 9064 LR: 2.1847622018482283e-05 Training loss: 0.0
2025-12-09 10:24:41.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 9065 LR: 2.1801256558889483e-05 Training loss: 0.0
2025-12-09 10:24:41.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 9066 LR: 2.1754939253896988e-05 Training loss: 0.0
2025-12-09 10:24:41.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 9067 LR: 2.170867010816907e-05 Training loss: 0.0
2025-12-09 10:24:41.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 9068 LR: 2.1662449126364948e-05 Training loss: 0.0
2025-12-09 10:24:41.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 9069 LR: 2.1616276313139227e-05 Training loss: 0.0
2025-12-09 10:24:41.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 9070 LR: 2.157015167314125e-05 Training loss: 0.0
2025-12-09 10:24:41.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 9071 LR: 2.1524075211016013e-05 Training loss: 0.0
2025-12-09 10:24:41.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 9072 LR: 2.1478046931403262e-05 Training loss: 0.0
2025-12-09 10:24:41.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 9073 LR: 2.1432066838938058e-05 Training loss: 0.0
2025-12-09 10:24:41.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 9074 LR: 2.1386134938250645e-05 Training loss: 0.0
2025-12-09 10:24:41.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 9075 LR: 2.134025123396638e-05 Training loss: 0.0
2025-12-09 10:24:41.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 9076 LR: 2.1294415730705676e-05 Training loss: 0.0
2025-12-09 10:24:41.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 9077 LR: 2.124862843308434e-05 Training loss: 0.0
2025-12-09 10:24:41.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 9078 LR: 2.120288934571285e-05 Training loss: 0.0
2025-12-09 10:24:41.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 9079 LR: 2.1157198473197415e-05 Training loss: 0.0
2025-12-09 10:24:41.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 9080 LR: 2.1111555820138906e-05 Training loss: 0.0
2025-12-09 10:24:41.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 9081 LR: 2.1065961391133704e-05 Training loss: 0.0
2025-12-09 10:24:41.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 9082 LR: 2.1020415190773023e-05 Training loss: 0.0
2025-12-09 10:24:41.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 9083 LR: 2.0974917223643418e-05 Training loss: 0.0
2025-12-09 10:24:41.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 9084 LR: 2.0929467494326615e-05 Training loss: 0.0
2025-12-09 10:24:41.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 9085 LR: 2.0884066007399337e-05 Training loss: 0.0
2025-12-09 10:24:41.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 9086 LR: 2.0838712767433375e-05 Training loss: 0.0
2025-12-09 10:24:41.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 9087 LR: 2.079340777899602e-05 Training loss: 0.0
2025-12-09 10:24:41.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 9088 LR: 2.07481510466494e-05 Training loss: 0.0
2025-12-09 10:24:41.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 9089 LR: 2.0702942574950812e-05 Training loss: 0.0
2025-12-09 10:24:41.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 9090 LR: 2.065778236845278e-05 Training loss: 0.0
2025-12-09 10:24:41.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 9091 LR: 2.0612670431703062e-05 Training loss: 0.0
2025-12-09 10:24:41.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 9092 LR: 2.056760676924413e-05 Training loss: 0.0
2025-12-09 10:24:41.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 9093 LR: 2.052259138561424e-05 Training loss: 0.0
2025-12-09 10:24:41.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 9094 LR: 2.047762428534622e-05 Training loss: 0.0
2025-12-09 10:24:41.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 9095 LR: 2.0432705472968326e-05 Training loss: 0.0
2025-12-09 10:24:41.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 9096 LR: 2.0387834953003838e-05 Training loss: 0.0
2025-12-09 10:24:41.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 9097 LR: 2.0343012729971243e-05 Training loss: 0.0
2025-12-09 10:24:41.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 9098 LR: 2.029823880838416e-05 Training loss: 0.0
2025-12-09 10:24:41.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 9099 LR: 2.025351319275137e-05 Training loss: 0.0
2025-12-09 10:24:41.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 9100 LR: 2.020883588757655e-05 Training loss: 0.0
2025-12-09 10:24:41.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 9101 LR: 2.0164206897358928e-05 Training loss: 0.0
2025-12-09 10:24:41.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 9102 LR: 2.0119626226592468e-05 Training loss: 0.0
2025-12-09 10:24:41.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 9103 LR: 2.007509387976658e-05 Training loss: 0.0
2025-12-09 10:24:41.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 9104 LR: 2.0030609861365567e-05 Training loss: 0.0
2025-12-09 10:24:41.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 9105 LR: 1.998617417586901e-05 Training loss: 0.0
2025-12-09 10:24:41.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 9106 LR: 1.994178682775155e-05 Training loss: 0.0
2025-12-09 10:24:41.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 9107 LR: 1.9897447821483115e-05 Training loss: 0.0
2025-12-09 10:24:41.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 9108 LR: 1.985315716152847e-05 Training loss: 0.0
2025-12-09 10:24:41.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 9109 LR: 1.9808914852347816e-05 Training loss: 0.0
2025-12-09 10:24:41.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 9110 LR: 1.976472089839626e-05 Training loss: 0.0
2025-12-09 10:24:41.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 9111 LR: 1.9720575304124134e-05 Training loss: 0.0
2025-12-09 10:24:41.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 9112 LR: 1.9676478073976988e-05 Training loss: 0.0
2025-12-09 10:24:41.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 9113 LR: 1.9632429212395332e-05 Training loss: 0.0
2025-12-09 10:24:41.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 9114 LR: 1.9588428723814943e-05 Training loss: 0.0
2025-12-09 10:24:41.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 9115 LR: 1.9544476612666673e-05 Training loss: 0.0
2025-12-09 10:24:41.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 9116 LR: 1.950057288337631e-05 Training loss: 0.0
2025-12-09 10:24:41.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 9117 LR: 1.9456717540365264e-05 Training loss: 0.0
2025-12-09 10:24:41.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 9118 LR: 1.941291058804956e-05 Training loss: 0.0
2025-12-09 10:24:41.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 9119 LR: 1.9369152030840554e-05 Training loss: 0.0
2025-12-09 10:24:41.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 9120 LR: 1.9325441873144834e-05 Training loss: 0.0
2025-12-09 10:24:41.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 9121 LR: 1.928178011936399e-05 Training loss: 0.0
2025-12-09 10:24:41.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 9122 LR: 1.9238166773894673e-05 Training loss: 0.0
2025-12-09 10:24:41.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 9123 LR: 1.919460184112892e-05 Training loss: 0.0
2025-12-09 10:24:41.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 9124 LR: 1.915108532545351e-05 Training loss: 0.0
2025-12-09 10:24:41.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 9125 LR: 1.9107617231250708e-05 Training loss: 0.0
2025-12-09 10:24:41.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 9126 LR: 1.9064197562897623e-05 Training loss: 0.0
2025-12-09 10:24:41.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 9127 LR: 1.9020826324766703e-05 Training loss: 0.0
2025-12-09 10:24:41.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 9128 LR: 1.897750352122546e-05 Training loss: 0.0
2025-12-09 10:24:41.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 9129 LR: 1.893422915663645e-05 Training loss: 0.0
2025-12-09 10:24:41.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 9130 LR: 1.8891003235357307e-05 Training loss: 0.0
2025-12-09 10:24:41.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 9131 LR: 1.88478257617411e-05 Training loss: 0.0
2025-12-09 10:24:41.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 9132 LR: 1.8804696740135575e-05 Training loss: 0.0
2025-12-09 10:24:41.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 9133 LR: 1.8761616174883976e-05 Training loss: 0.0
2025-12-09 10:24:41.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 9134 LR: 1.871858407032445e-05 Training loss: 0.0
2025-12-09 10:24:41.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 9135 LR: 1.8675600430790306e-05 Training loss: 0.0
2025-12-09 10:24:41.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 9136 LR: 1.8632665260610028e-05 Training loss: 0.0
2025-12-09 10:24:41.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 9137 LR: 1.8589778564107262e-05 Training loss: 0.0
2025-12-09 10:24:41.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 9138 LR: 1.8546940345600504e-05 Training loss: 0.0
2025-12-09 10:24:41.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 9139 LR: 1.850415060940386e-05 Training loss: 0.0
2025-12-09 10:24:41.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 9140 LR: 1.8461409359825932e-05 Training loss: 0.0
2025-12-09 10:24:41.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 9141 LR: 1.841871660117095e-05 Training loss: 0.0
2025-12-09 10:24:41.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 9142 LR: 1.837607233773797e-05 Training loss: 0.0
2025-12-09 10:24:41.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 9143 LR: 1.8333476573821394e-05 Training loss: 0.0
2025-12-09 10:24:41.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 9144 LR: 1.8290929313710515e-05 Training loss: 0.0
2025-12-09 10:24:41.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 9145 LR: 1.8248430561689955e-05 Training loss: 0.0
2025-12-09 10:24:41.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 9146 LR: 1.8205980322039182e-05 Training loss: 0.0
2025-12-09 10:24:41.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 9147 LR: 1.8163578599033003e-05 Training loss: 0.0
2025-12-09 10:24:41.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 9148 LR: 1.8121225396941276e-05 Training loss: 0.0
2025-12-09 10:24:41.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 9149 LR: 1.8078920720028978e-05 Training loss: 0.0
2025-12-09 10:24:41.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 9150 LR: 1.8036664572556204e-05 Training loss: 0.0
2025-12-09 10:24:41.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 9151 LR: 1.7994456958778048e-05 Training loss: 0.0
2025-12-09 10:24:41.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 9152 LR: 1.7952297882945002e-05 Training loss: 0.0
2025-12-09 10:24:41.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 9153 LR: 1.7910187349302277e-05 Training loss: 0.0
2025-12-09 10:24:41.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 9154 LR: 1.7868125362090482e-05 Training loss: 0.0
2025-12-09 10:24:41.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 9155 LR: 1.782611192554534e-05 Training loss: 0.0
2025-12-09 10:24:41.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 9156 LR: 1.7784147043897526e-05 Training loss: 0.0
2025-12-09 10:24:41.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 9157 LR: 1.774223072137282e-05 Training loss: 0.0
2025-12-09 10:24:41.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 9158 LR: 1.7700362962192406e-05 Training loss: 0.0
2025-12-09 10:24:41.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 9159 LR: 1.765854377057219e-05 Training loss: 0.0
2025-12-09 10:24:41.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 9160 LR: 1.7616773150723407e-05 Training loss: 0.0
2025-12-09 10:24:41.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 9161 LR: 1.757505110685237e-05 Training loss: 0.0
2025-12-09 10:24:41.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 9162 LR: 1.7533377643160487e-05 Training loss: 0.0
2025-12-09 10:24:41.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 9163 LR: 1.7491752763844293e-05 Training loss: 0.0
2025-12-09 10:24:41.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 9164 LR: 1.7450176473095435e-05 Training loss: 0.0
2025-12-09 10:24:41.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 9165 LR: 1.7408648775100456e-05 Training loss: 0.0
2025-12-09 10:24:41.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 9166 LR: 1.7367169674041505e-05 Training loss: 0.0
2025-12-09 10:24:41.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 9167 LR: 1.7325739174095302e-05 Training loss: 0.0
2025-12-09 10:24:41.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 9168 LR: 1.728435727943395e-05 Training loss: 0.0
2025-12-09 10:24:41.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 9169 LR: 1.724302399422456e-05 Training loss: 0.0
2025-12-09 10:24:41.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 9170 LR: 1.720173932262953e-05 Training loss: 0.0
2025-12-09 10:24:41.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 9171 LR: 1.7160503268806083e-05 Training loss: 0.0
2025-12-09 10:24:41.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 9172 LR: 1.7119315836906792e-05 Training loss: 0.0
2025-12-09 10:24:41.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 9173 LR: 1.707817703107911e-05 Training loss: 0.0
2025-12-09 10:24:41.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 9174 LR: 1.70370868554659e-05 Training loss: 0.0
2025-12-09 10:24:41.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 9175 LR: 1.6996045314204735e-05 Training loss: 0.0
2025-12-09 10:24:41.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 9176 LR: 1.695505241142864e-05 Training loss: 0.0
2025-12-09 10:24:41.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 9177 LR: 1.691410815126554e-05 Training loss: 0.0
2025-12-09 10:24:41.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 9178 LR: 1.6873212537838467e-05 Training loss: 0.0
2025-12-09 10:24:41.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 9179 LR: 1.683236557526574e-05 Training loss: 0.0
2025-12-09 10:24:41.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 9180 LR: 1.6791567267660622e-05 Training loss: 0.0
2025-12-09 10:24:41.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 9181 LR: 1.6750817619131332e-05 Training loss: 0.0
2025-12-09 10:24:41.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 9182 LR: 1.6710116633781637e-05 Training loss: 0.0
2025-12-09 10:24:41.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 9183 LR: 1.666946431570987e-05 Training loss: 0.0
2025-12-09 10:24:41.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 9184 LR: 1.6628860669009817e-05 Training loss: 0.0
2025-12-09 10:24:41.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 9185 LR: 1.658830569777031e-05 Training loss: 0.0
2025-12-09 10:24:41.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 9186 LR: 1.6547799406075203e-05 Training loss: 0.0
2025-12-09 10:24:41.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 9187 LR: 1.6507341798003396e-05 Training loss: 0.0
2025-12-09 10:24:41.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 9188 LR: 1.6466932877629127e-05 Training loss: 0.0
2025-12-09 10:24:41.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 9189 LR: 1.6426572649021475e-05 Training loss: 0.0
2025-12-09 10:24:41.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 9190 LR: 1.6386261116244694e-05 Training loss: 0.0
2025-12-09 10:24:41.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 9191 LR: 1.6345998283358142e-05 Training loss: 0.0
2025-12-09 10:24:41.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 9192 LR: 1.6305784154416416e-05 Training loss: 0.0
2025-12-09 10:24:41.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 9193 LR: 1.6265618733468934e-05 Training loss: 0.0
2025-12-09 10:24:41.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 9194 LR: 1.6225502024560467e-05 Training loss: 0.0
2025-12-09 10:24:41.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 9195 LR: 1.6185434031730615e-05 Training loss: 0.0
2025-12-09 10:24:41.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 9196 LR: 1.614541475901443e-05 Training loss: 0.0
2025-12-09 10:24:41.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 9197 LR: 1.6105444210441687e-05 Training loss: 0.0
2025-12-09 10:24:41.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 9198 LR: 1.6065522390037446e-05 Training loss: 0.0
2025-12-09 10:24:41.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 9199 LR: 1.6025649301821876e-05 Training loss: 0.0
2025-12-09 10:24:41.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 9200 LR: 1.5985824949810157e-05 Training loss: 0.0
2025-12-09 10:24:41.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 9201 LR: 1.5946049338012635e-05 Training loss: 0.0
2025-12-09 10:24:41.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 9202 LR: 1.5906322470434774e-05 Training loss: 0.0
2025-12-09 10:24:41.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 9203 LR: 1.5866644351076876e-05 Training loss: 0.0
2025-12-09 10:24:41.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 9204 LR: 1.582701498393474e-05 Training loss: 0.0
2025-12-09 10:24:41.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 9205 LR: 1.5787434372998955e-05 Training loss: 0.0
2025-12-09 10:24:41.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 9206 LR: 1.574790252225522e-05 Training loss: 0.0
2025-12-09 10:24:41.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 9207 LR: 1.5708419435684463e-05 Training loss: 0.0
2025-12-09 10:24:41.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 9208 LR: 1.5668985117262612e-05 Training loss: 0.0
2025-12-09 10:24:41.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 9209 LR: 1.5629599570960716e-05 Training loss: 0.0
2025-12-09 10:24:41.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 9210 LR: 1.5590262800744936e-05 Training loss: 0.0
2025-12-09 10:24:41.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 9211 LR: 1.5550974810576323e-05 Training loss: 0.0
2025-12-09 10:24:41.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 9212 LR: 1.5511735604411383e-05 Training loss: 0.0
2025-12-09 10:24:41.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 9213 LR: 1.5472545186201394e-05 Training loss: 0.0
2025-12-09 10:24:41.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 9214 LR: 1.5433403559892866e-05 Training loss: 0.0
2025-12-09 10:24:41.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 9215 LR: 1.5394310729427264e-05 Training loss: 0.0
2025-12-09 10:24:41.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 9216 LR: 1.535526669874143e-05 Training loss: 0.0
2025-12-09 10:24:41.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 9217 LR: 1.531627147176684e-05 Training loss: 0.0
2025-12-09 10:24:41.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 9218 LR: 1.527732505243057e-05 Training loss: 0.0
2025-12-09 10:24:41.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 9219 LR: 1.5238427444654367e-05 Training loss: 0.0
2025-12-09 10:24:41.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 9220 LR: 1.5199578652355273e-05 Training loss: 0.0
2025-12-09 10:24:41.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 9221 LR: 1.5160778679445263e-05 Training loss: 0.0
2025-12-09 10:24:41.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 9222 LR: 1.512202752983166e-05 Training loss: 0.0
2025-12-09 10:24:41.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 9223 LR: 1.5083325207416565e-05 Training loss: 0.0
2025-12-09 10:24:41.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 9224 LR: 1.5044671716097413e-05 Training loss: 0.0
2025-12-09 10:24:41.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 9225 LR: 1.5006067059766482e-05 Training loss: 0.0
2025-12-09 10:24:41.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 9226 LR: 1.4967511242311383e-05 Training loss: 0.0
2025-12-09 10:24:41.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 9227 LR: 1.4929004267614622e-05 Training loss: 0.0
2025-12-09 10:24:41.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 9228 LR: 1.4890546139553818e-05 Training loss: 0.0
2025-12-09 10:24:41.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 9229 LR: 1.4852136862001764e-05 Training loss: 0.0
2025-12-09 10:24:41.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 9230 LR: 1.4813776438826253e-05 Training loss: 0.0
2025-12-09 10:24:41.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 9231 LR: 1.4775464873890254e-05 Training loss: 0.0
2025-12-09 10:24:41.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 9232 LR: 1.4737202171051567e-05 Training loss: 0.0
2025-12-09 10:24:41.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 9233 LR: 1.4698988334163388e-05 Training loss: 0.0
2025-12-09 10:24:41.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 9234 LR: 1.466082336707375e-05 Training loss: 0.0
2025-12-09 10:24:41.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 9235 LR: 1.4622707273625968e-05 Training loss: 0.0
2025-12-09 10:24:41.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 9236 LR: 1.458464005765825e-05 Training loss: 0.0
2025-12-09 10:24:41.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 9237 LR: 1.4546621723004083e-05 Training loss: 0.0
2025-12-09 10:24:41.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 9238 LR: 1.4508652273491685e-05 Training loss: 0.0
2025-12-09 10:24:41.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 9239 LR: 1.4470731712944884e-05 Training loss: 0.0
2025-12-09 10:24:41.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 9240 LR: 1.4432860045182017e-05 Training loss: 0.0
2025-12-09 10:24:41.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 9241 LR: 1.4395037274016864e-05 Training loss: 0.0
2025-12-09 10:24:41.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 9242 LR: 1.4357263403258159e-05 Training loss: 0.0
2025-12-09 10:24:41.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 9243 LR: 1.4319538436709745e-05 Training loss: 0.0
2025-12-09 10:24:41.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 9244 LR: 1.428186237817053e-05 Training loss: 0.0
2025-12-09 10:24:41.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 9245 LR: 1.4244235231434532e-05 Training loss: 0.0
2025-12-09 10:24:41.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 9246 LR: 1.4206657000290668e-05 Training loss: 0.0
2025-12-09 10:24:41.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 9247 LR: 1.4169127688523186e-05 Training loss: 0.0
2025-12-09 10:24:41.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 9248 LR: 1.4131647299911287e-05 Training loss: 0.0
2025-12-09 10:24:41.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 9249 LR: 1.4094215838229174e-05 Training loss: 0.0
2025-12-09 10:24:41.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 9250 LR: 1.405683330724622e-05 Training loss: 0.0
2025-12-09 10:24:41.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 9251 LR: 1.4019499710726914e-05 Training loss: 0.0
2025-12-09 10:24:41.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 9252 LR: 1.3982215052430635e-05 Training loss: 0.0
2025-12-09 10:24:41.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 9253 LR: 1.3944979336112052e-05 Training loss: 0.0
2025-12-09 10:24:41.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 9254 LR: 1.3907792565520716e-05 Training loss: 0.0
2025-12-09 10:24:41.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 9255 LR: 1.3870654744401357e-05 Training loss: 0.0
2025-12-09 10:24:41.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 9256 LR: 1.383356587649376e-05 Training loss: 0.0
2025-12-09 10:24:41.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 9257 LR: 1.379652596553277e-05 Training loss: 0.0
2025-12-09 10:24:41.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 9258 LR: 1.3759535015248348e-05 Training loss: 0.0
2025-12-09 10:24:41.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 9259 LR: 1.372259302936546e-05 Training loss: 0.0
2025-12-09 10:24:41.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 9260 LR: 1.3685700011604074e-05 Training loss: 0.0
2025-12-09 10:24:41.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 9261 LR: 1.3648855965679496e-05 Training loss: 0.0
2025-12-09 10:24:41.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 9262 LR: 1.3612060895301759e-05 Training loss: 0.0
2025-12-09 10:24:41.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 9263 LR: 1.3575314804176175e-05 Training loss: 0.0
2025-12-09 10:24:41.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 9264 LR: 1.3538617696003064e-05 Training loss: 0.0
2025-12-09 10:24:41.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 9265 LR: 1.3501969574477857e-05 Training loss: 0.0
2025-12-09 10:24:41.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 9266 LR: 1.3465370443290993e-05 Training loss: 0.0
2025-12-09 10:24:41.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 9267 LR: 1.3428820306128075e-05 Training loss: 0.0
2025-12-09 10:24:41.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 9268 LR: 1.3392319166669552e-05 Training loss: 0.0
2025-12-09 10:24:41.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 9269 LR: 1.3355867028591206e-05 Training loss: 0.0
2025-12-09 10:24:41.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 9270 LR: 1.3319463895563767e-05 Training loss: 0.0
2025-12-09 10:24:41.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 9271 LR: 1.3283109771252966e-05 Training loss: 0.0
2025-12-09 10:24:41.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 9272 LR: 1.3246804659319712e-05 Training loss: 0.0
2025-12-09 10:24:41.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 9273 LR: 1.3210548563419855e-05 Training loss: 0.0
2025-12-09 10:24:41.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 9274 LR: 1.3174341487204477e-05 Training loss: 0.0
2025-12-09 10:24:41.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 9275 LR: 1.3138183434319661e-05 Training loss: 0.0
2025-12-09 10:24:41.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 9276 LR: 1.3102074408406327e-05 Training loss: 0.0
2025-12-09 10:24:41.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 9277 LR: 1.3066014413100846e-05 Training loss: 0.0
2025-12-09 10:24:41.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 9278 LR: 1.3030003452034422e-05 Training loss: 0.0
2025-12-09 10:24:41.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 9279 LR: 1.2994041528833267e-05 Training loss: 0.0
2025-12-09 10:24:41.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 9280 LR: 1.2958128647118817e-05 Training loss: 0.0
2025-12-09 10:24:41.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 9281 LR: 1.292226481050751e-05 Training loss: 0.0
2025-12-09 10:24:41.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 9282 LR: 1.288645002261074e-05 Training loss: 0.0
2025-12-09 10:24:41.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 9283 LR: 1.285068428703523e-05 Training loss: 0.0
2025-12-09 10:24:41.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 9284 LR: 1.2814967607382432e-05 Training loss: 0.0
2025-12-09 10:24:41.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 9285 LR: 1.2779299987249027e-05 Training loss: 0.0
2025-12-09 10:24:41.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 9286 LR: 1.2743681430226805e-05 Training loss: 0.0
2025-12-09 10:24:41.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 9287 LR: 1.2708111939902568e-05 Training loss: 0.0
2025-12-09 10:24:41.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 9288 LR: 1.2672591519858057e-05 Training loss: 0.0
2025-12-09 10:24:41.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 9289 LR: 1.2637120173670358e-05 Training loss: 0.0
2025-12-09 10:24:41.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 9290 LR: 1.260169790491117e-05 Training loss: 0.0
2025-12-09 10:24:41.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 9291 LR: 1.2566324717147803e-05 Training loss: 0.0
2025-12-09 10:24:41.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 9292 LR: 1.2531000613942134e-05 Training loss: 0.0
2025-12-09 10:24:41.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 9293 LR: 1.249572559885137e-05 Training loss: 0.0
2025-12-09 10:24:41.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 9294 LR: 1.2460499675427727e-05 Training loss: 0.0
2025-12-09 10:24:41.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 9295 LR: 1.2425322847218367e-05 Training loss: 0.0
2025-12-09 10:24:41.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 9296 LR: 1.239019511776568e-05 Training loss: 0.0
2025-12-09 10:24:41.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 9297 LR: 1.235511649060711e-05 Training loss: 0.0
2025-12-09 10:24:41.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 9298 LR: 1.232008696927478e-05 Training loss: 0.0
2025-12-09 10:24:41.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 9299 LR: 1.2285106557296478e-05 Training loss: 0.0
2025-12-09 10:24:41.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 9300 LR: 1.2250175258194551e-05 Training loss: 0.0
2025-12-09 10:24:41.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 9301 LR: 1.221529307548669e-05 Training loss: 0.0
2025-12-09 10:24:41.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 9302 LR: 1.2180460012685413e-05 Training loss: 0.0
2025-12-09 10:24:41.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 9303 LR: 1.2145676073298473e-05 Training loss: 0.0
2025-12-09 10:24:41.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 9304 LR: 1.2110941260828568e-05 Training loss: 0.0
2025-12-09 10:24:41.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 9305 LR: 1.207625557877362e-05 Training loss: 0.0
2025-12-09 10:24:41.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 9306 LR: 1.2041619030626282e-05 Training loss: 0.0
2025-12-09 10:24:41.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 9307 LR: 1.2007031619874654e-05 Training loss: 0.0
2025-12-09 10:24:41.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 9308 LR: 1.1972493350001502e-05 Training loss: 0.0
2025-12-09 10:24:41.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 9309 LR: 1.1938004224484989e-05 Training loss: 0.0
2025-12-09 10:24:41.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 9310 LR: 1.1903564246798059e-05 Training loss: 0.0
2025-12-09 10:24:41.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 9311 LR: 1.1869173420408885e-05 Training loss: 0.0
2025-12-09 10:24:41.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 9312 LR: 1.1834831748780527e-05 Training loss: 0.0
2025-12-09 10:24:41.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 9313 LR: 1.1800539235371333e-05 Training loss: 0.0
2025-12-09 10:24:41.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 9314 LR: 1.1766295883634426e-05 Training loss: 0.0
2025-12-09 10:24:41.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 9315 LR: 1.173210169701816e-05 Training loss: 0.0
2025-12-09 10:24:41.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 9316 LR: 1.1697956678965893e-05 Training loss: 0.0
2025-12-09 10:24:41.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 9317 LR: 1.166386083291604e-05 Training loss: 0.0
2025-12-09 10:24:41.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 9318 LR: 1.1629814162302077e-05 Training loss: 0.0
2025-12-09 10:24:41.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 9319 LR: 1.1595816670552429e-05 Training loss: 0.0
2025-12-09 10:24:41.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 9320 LR: 1.1561868361090689e-05 Training loss: 0.0
2025-12-09 10:24:41.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 9321 LR: 1.1527969237335456e-05 Training loss: 0.0
2025-12-09 10:24:41.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 9322 LR: 1.1494119302700279e-05 Training loss: 0.0
2025-12-09 10:24:41.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 9323 LR: 1.1460318560593986e-05 Training loss: 0.0
2025-12-09 10:24:41.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 9324 LR: 1.1426567014420297e-05 Training loss: 0.0
2025-12-09 10:24:41.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 9325 LR: 1.1392864667577829e-05 Training loss: 0.0
2025-12-09 10:24:41.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 9326 LR: 1.135921152346059e-05 Training loss: 0.0
2025-12-09 10:24:41.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 9327 LR: 1.1325607585457365e-05 Training loss: 0.0
2025-12-09 10:24:41.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 9328 LR: 1.1292052856952062e-05 Training loss: 0.0
2025-12-09 10:24:41.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 9329 LR: 1.1258547341323699e-05 Training loss: 0.0
2025-12-09 10:24:41.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 9330 LR: 1.1225091041946245e-05 Training loss: 0.0
2025-12-09 10:24:41.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 9331 LR: 1.1191683962188725e-05 Training loss: 0.0
2025-12-09 10:24:41.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 9332 LR: 1.1158326105415284e-05 Training loss: 0.0
2025-12-09 10:24:41.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 9333 LR: 1.1125017474984956e-05 Training loss: 0.0
2025-12-09 10:24:41.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 9334 LR: 1.1091758074252112e-05 Training loss: 0.0
2025-12-09 10:24:41.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 9335 LR: 1.1058547906565741e-05 Training loss: 0.0
2025-12-09 10:24:41.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 9336 LR: 1.1025386975270279e-05 Training loss: 0.0
2025-12-09 10:24:41.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 9337 LR: 1.0992275283704944e-05 Training loss: 0.0
2025-12-09 10:24:41.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 9338 LR: 1.0959212835204125e-05 Training loss: 0.0
2025-12-09 10:24:41.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 9339 LR: 1.0926199633097156e-05 Training loss: 0.0
2025-12-09 10:24:41.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 9340 LR: 1.0893235680708602e-05 Training loss: 0.0
2025-12-09 10:24:41.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 9341 LR: 1.0860320981357697e-05 Training loss: 0.0
2025-12-09 10:24:41.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 9342 LR: 1.0827455538359177e-05 Training loss: 0.0
2025-12-09 10:24:41.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 9343 LR: 1.0794639355022506e-05 Training loss: 0.0
2025-12-09 10:24:41.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 9344 LR: 1.0761872434652209e-05 Training loss: 0.0
2025-12-09 10:24:41.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 9345 LR: 1.0729154780547979e-05 Training loss: 0.0
2025-12-09 10:24:41.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 9346 LR: 1.0696486396004511e-05 Training loss: 0.0
2025-12-09 10:24:41.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 9347 LR: 1.0663867284311457e-05 Training loss: 0.0
2025-12-09 10:24:41.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 9348 LR: 1.0631297448753574e-05 Training loss: 0.0
2025-12-09 10:24:41.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 9349 LR: 1.0598776892610684e-05 Training loss: 0.0
2025-12-09 10:24:41.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 9350 LR: 1.05663056191575e-05 Training loss: 0.0
2025-12-09 10:24:41.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 9351 LR: 1.0533883631663966e-05 Training loss: 0.0
2025-12-09 10:24:41.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 9352 LR: 1.050151093339502e-05 Training loss: 0.0
2025-12-09 10:24:41.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 9353 LR: 1.0469187527610447e-05 Training loss: 0.0
2025-12-09 10:24:41.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 9354 LR: 1.0436913417565363e-05 Training loss: 0.0
2025-12-09 10:24:41.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 9355 LR: 1.0404688606509617e-05 Training loss: 0.0
2025-12-09 10:24:41.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 9356 LR: 1.037251309768844e-05 Training loss: 0.0
2025-12-09 10:24:41.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 9357 LR: 1.0340386894341747e-05 Training loss: 0.0
2025-12-09 10:24:41.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 9358 LR: 1.0308309999704668e-05 Training loss: 0.0
2025-12-09 10:24:41.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 9359 LR: 1.0276282417007399e-05 Training loss: 0.0
2025-12-09 10:24:41.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 9360 LR: 1.0244304149475081e-05 Training loss: 0.0
2025-12-09 10:24:41.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 9361 LR: 1.0212375200327972e-05 Training loss: 0.0
2025-12-09 10:24:41.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 9362 LR: 1.0180495572781278e-05 Training loss: 0.0
2025-12-09 10:24:41.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 9363 LR: 1.0148665270045209e-05 Training loss: 0.0
2025-12-09 10:24:41.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 9364 LR: 1.0116884295325202e-05 Training loss: 0.0
2025-12-09 10:24:41.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 9365 LR: 1.0085152651821528e-05 Training loss: 0.0
2025-12-09 10:24:41.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 9366 LR: 1.0053470342729575e-05 Training loss: 0.0
2025-12-09 10:24:41.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 9367 LR: 1.0021837371239739e-05 Training loss: 0.0
2025-12-09 10:24:41.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 9368 LR: 9.990253740537526e-06 Training loss: 0.0
2025-12-09 10:24:41.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 9369 LR: 9.958719453803277e-06 Training loss: 0.0
2025-12-09 10:24:41.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 9370 LR: 9.927234514212679e-06 Training loss: 0.0
2025-12-09 10:24:41.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 9371 LR: 9.895798924936028e-06 Training loss: 0.0
2025-12-09 10:24:41.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 9372 LR: 9.864412689139124e-06 Training loss: 0.0
2025-12-09 10:24:41.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 9373 LR: 9.833075809982383e-06 Training loss: 0.0
2025-12-09 10:24:41.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 9374 LR: 9.801788290621506e-06 Training loss: 0.0
2025-12-09 10:24:41.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 9375 LR: 9.770550134207135e-06 Training loss: 0.0
2025-12-09 10:24:41.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 9376 LR: 9.739361343884979e-06 Training loss: 0.0
2025-12-09 10:24:41.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 9377 LR: 9.708221922795691e-06 Training loss: 0.0
2025-12-09 10:24:41.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 9378 LR: 9.67713187407504e-06 Training loss: 0.0
2025-12-09 10:24:41.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 9379 LR: 9.646091200853802e-06 Training loss: 0.0
2025-12-09 10:24:41.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 9380 LR: 9.615099906257807e-06 Training loss: 0.0
2025-12-09 10:24:41.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 9381 LR: 9.584157993407782e-06 Training loss: 0.0
2025-12-09 10:24:41.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 9382 LR: 9.553265465419625e-06 Training loss: 0.0
2025-12-09 10:24:41.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 9383 LR: 9.522422325404235e-06 Training loss: 0.0
2025-12-09 10:24:41.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 9384 LR: 9.491628576467514e-06 Training loss: 0.0
2025-12-09 10:24:41.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 9385 LR: 9.460884221710265e-06 Training loss: 0.0
2025-12-09 10:24:41.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 9386 LR: 9.430189264228728e-06 Training loss: 0.0
2025-12-09 10:24:41.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 9387 LR: 9.3995437071136e-06 Training loss: 0.0
2025-12-09 10:24:41.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 9388 LR: 9.368947553451024e-06 Training loss: 0.0
2025-12-09 10:24:41.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 9389 LR: 9.338400806321978e-06 Training loss: 0.0
2025-12-09 10:24:41.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 9390 LR: 9.30790346880256e-06 Training loss: 0.0
2025-12-09 10:24:41.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 9391 LR: 9.277455543963809e-06 Training loss: 0.0
2025-12-09 10:24:41.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 9392 LR: 9.247057034871942e-06 Training loss: 0.0
2025-12-09 10:24:41.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 9393 LR: 9.216707944587899e-06 Training loss: 0.0
2025-12-09 10:24:41.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 9394 LR: 9.186408276168012e-06 Training loss: 0.0
2025-12-09 10:24:41.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 9395 LR: 9.156158032663397e-06 Training loss: 0.0
2025-12-09 10:24:41.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 9396 LR: 9.125957217120173e-06 Training loss: 0.0
2025-12-09 10:24:41.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 9397 LR: 9.095805832579684e-06 Training loss: 0.0
2025-12-09 10:24:41.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 9398 LR: 9.065703882078058e-06 Training loss: 0.0
2025-12-09 10:24:41.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 9399 LR: 9.035651368646646e-06 Training loss: 0.0
2025-12-09 10:24:41.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 9400 LR: 9.005648295311752e-06 Training loss: 0.0
2025-12-09 10:24:41.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 9401 LR: 8.975694665094514e-06 Training loss: 0.0
2025-12-09 10:24:41.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 9402 LR: 8.945790481011518e-06 Training loss: 0.0
2025-12-09 10:24:41.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 9403 LR: 8.915935746073967e-06 Training loss: 0.0
2025-12-09 10:24:41.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 9404 LR: 8.886130463288177e-06 Training loss: 0.0
2025-12-09 10:24:41.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 9405 LR: 8.856374635655695e-06 Training loss: 0.0
2025-12-09 10:24:41.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 9406 LR: 8.826668266172788e-06 Training loss: 0.0
2025-12-09 10:24:41.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 9407 LR: 8.797011357830953e-06 Training loss: 0.0
2025-12-09 10:24:41.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 9408 LR: 8.76740391361669e-06 Training loss: 0.0
2025-12-09 10:24:41.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 9409 LR: 8.737845936511335e-06 Training loss: 0.0
2025-12-09 10:24:41.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 9410 LR: 8.708337429491509e-06 Training loss: 0.0
2025-12-09 10:24:41.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 9411 LR: 8.678878395528666e-06 Training loss: 0.0
2025-12-09 10:24:41.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 9412 LR: 8.649468837589214e-06 Training loss: 0.0
2025-12-09 10:24:41.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 9413 LR: 8.620108758634948e-06 Training loss: 0.0
2025-12-09 10:24:41.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 9414 LR: 8.590798161622227e-06 Training loss: 0.0
2025-12-09 10:24:41.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 9415 LR: 8.561537049502688e-06 Training loss: 0.0
2025-12-09 10:24:41.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 9416 LR: 8.53232542522292e-06 Training loss: 0.0
2025-12-09 10:24:41.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 9417 LR: 8.503163291724514e-06 Training loss: 0.0
2025-12-09 10:24:41.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 9418 LR: 8.474050651944121e-06 Training loss: 0.0
2025-12-09 10:24:41.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 9419 LR: 8.444987508813451e-06 Training loss: 0.0
2025-12-09 10:24:41.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 9420 LR: 8.415973865258941e-06 Training loss: 0.0
2025-12-09 10:24:41.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 9421 LR: 8.387009724202532e-06 Training loss: 0.0
2025-12-09 10:24:41.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 9422 LR: 8.35809508856078e-06 Training loss: 0.0
2025-12-09 10:24:41.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 9423 LR: 8.329229961245354e-06 Training loss: 0.0
2025-12-09 10:24:41.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 9424 LR: 8.300414345163044e-06 Training loss: 0.0
2025-12-09 10:24:41.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 9425 LR: 8.271648243215579e-06 Training loss: 0.0
2025-12-09 10:24:41.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 9426 LR: 8.242931658299646e-06 Training loss: 0.0
2025-12-09 10:24:41.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 9427 LR: 8.214264593307098e-06 Training loss: 0.0
2025-12-09 10:24:41.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 9428 LR: 8.185647051124568e-06 Training loss: 0.0
2025-12-09 10:24:41.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 9429 LR: 8.157079034633974e-06 Training loss: 0.0
2025-12-09 10:24:41.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 9430 LR: 8.128560546712016e-06 Training loss: 0.0
2025-12-09 10:24:41.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 9431 LR: 8.100091590230619e-06 Training loss: 0.0
2025-12-09 10:24:41.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 9432 LR: 8.071672168056488e-06 Training loss: 0.0
2025-12-09 10:24:41.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 9433 LR: 8.043302283051501e-06 Training loss: 0.0
2025-12-09 10:24:41.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 9434 LR: 8.014981938072541e-06 Training loss: 0.0
2025-12-09 10:24:41.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 9435 LR: 7.986711135971491e-06 Training loss: 0.0
2025-12-09 10:24:41.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 9436 LR: 7.958489879595132e-06 Training loss: 0.0
2025-12-09 10:24:41.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 9437 LR: 7.930318171785356e-06 Training loss: 0.0
2025-12-09 10:24:41.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 9438 LR: 7.90219601537906e-06 Training loss: 0.0
2025-12-09 10:24:41.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 9439 LR: 7.874123413208145e-06 Training loss: 0.0
2025-12-09 10:24:41.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 9440 LR: 7.846100368099573e-06 Training loss: 0.0
2025-12-09 10:24:41.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 9441 LR: 7.818126882875253e-06 Training loss: 0.0
2025-12-09 10:24:41.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 9442 LR: 7.790202960352045e-06 Training loss: 0.0
2025-12-09 10:24:41.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 9443 LR: 7.762328603341973e-06 Training loss: 0.0
2025-12-09 10:24:41.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 9444 LR: 7.734503814651906e-06 Training loss: 0.0
2025-12-09 10:24:41.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 9445 LR: 7.706728597083879e-06 Training loss: 0.0
2025-12-09 10:24:41.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 9446 LR: 7.679002953434766e-06 Training loss: 0.0
2025-12-09 10:24:41.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 9447 LR: 7.651326886496612e-06 Training loss: 0.0
2025-12-09 10:24:41.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 9448 LR: 7.6237003990562996e-06 Training loss: 0.0
2025-12-09 10:24:41.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 9449 LR: 7.59612349389599e-06 Training loss: 0.0
2025-12-09 10:24:41.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 9450 LR: 7.568596173792519e-06 Training loss: 0.0
2025-12-09 10:24:41.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 9451 LR: 7.541118441517947e-06 Training loss: 0.0
2025-12-09 10:24:41.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 9452 LR: 7.513690299839282e-06 Training loss: 0.0
2025-12-09 10:24:41.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 9453 LR: 7.486311751518482e-06 Training loss: 0.0
2025-12-09 10:24:41.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 9454 LR: 7.458982799312675e-06 Training loss: 0.0
2025-12-09 10:24:41.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 9455 LR: 7.4317034459737694e-06 Training loss: 0.0
2025-12-09 10:24:41.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 9456 LR: 7.404473694248904e-06 Training loss: 0.0
2025-12-09 10:24:41.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 9457 LR: 7.377293546880048e-06 Training loss: 0.0
2025-12-09 10:24:41.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 9458 LR: 7.350163006604183e-06 Training loss: 0.0
2025-12-09 10:24:41.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 9459 LR: 7.323082076153509e-06 Training loss: 0.0
2025-12-09 10:24:41.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 9460 LR: 7.2960507582549576e-06 Training loss: 0.0
2025-12-09 10:24:41.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 9461 LR: 7.269069055630628e-06 Training loss: 0.0
2025-12-09 10:24:41.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 9462 LR: 7.242136970997515e-06 Training loss: 0.0
2025-12-09 10:24:41.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 9463 LR: 7.215254507067781e-06 Training loss: 0.0
2025-12-09 10:24:41.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 9464 LR: 7.188421666548373e-06 Training loss: 0.0
2025-12-09 10:24:41.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 9465 LR: 7.161638452141517e-06 Training loss: 0.0
2025-12-09 10:24:41.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 9466 LR: 7.134904866544057e-06 Training loss: 0.0
2025-12-09 10:24:41.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 9467 LR: 7.1082209124482825e-06 Training loss: 0.0
2025-12-09 10:24:41.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 9468 LR: 7.081586592541156e-06 Training loss: 0.0
2025-12-09 10:24:41.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 9469 LR: 7.055001909504755e-06 Training loss: 0.0
2025-12-09 10:24:41.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 9470 LR: 7.028466866016214e-06 Training loss: 0.0
2025-12-09 10:24:41.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 9471 LR: 7.001981464747565e-06 Training loss: 0.0
2025-12-09 10:24:41.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 9472 LR: 6.975545708365838e-06 Training loss: 0.0
2025-12-09 10:24:41.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 9473 LR: 6.949159599533239e-06 Training loss: 0.0
2025-12-09 10:24:41.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 9474 LR: 6.9228231409067535e-06 Training loss: 0.0
2025-12-09 10:24:41.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 9475 LR: 6.896536335138426e-06 Training loss: 0.0
2025-12-09 10:24:41.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 9476 LR: 6.870299184875473e-06 Training loss: 0.0
2025-12-09 10:24:41.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 9477 LR: 6.844111692759836e-06 Training loss: 0.0
2025-12-09 10:24:41.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 9478 LR: 6.817973861428683e-06 Training loss: 0.0
2025-12-09 10:24:41.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 9479 LR: 6.791885693514133e-06 Training loss: 0.0
2025-12-09 10:24:41.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 9480 LR: 6.765847191643082e-06 Training loss: 0.0
2025-12-09 10:24:41.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 9481 LR: 6.739858358437822e-06 Training loss: 0.0
2025-12-09 10:24:41.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 9482 LR: 6.713919196515317e-06 Training loss: 0.0
2025-12-09 10:24:41.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 9483 LR: 6.688029708487586e-06 Training loss: 0.0
2025-12-09 10:24:41.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 9484 LR: 6.662189896961823e-06 Training loss: 0.0
2025-12-09 10:24:41.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 9485 LR: 6.636399764540002e-06 Training loss: 0.0
2025-12-09 10:24:41.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 9486 LR: 6.610659313819267e-06 Training loss: 0.0
2025-12-09 10:24:41.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 9487 LR: 6.584968547391656e-06 Training loss: 0.0
2025-12-09 10:24:41.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 9488 LR: 6.559327467844156e-06 Training loss: 0.0
2025-12-09 10:24:41.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 9489 LR: 6.533736077758867e-06 Training loss: 0.0
2025-12-09 10:24:41.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 9490 LR: 6.508194379712895e-06 Training loss: 0.0
2025-12-09 10:24:41.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 9491 LR: 6.4827023762782375e-06 Training loss: 0.0
2025-12-09 10:24:41.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 9492 LR: 6.457260070021953e-06 Training loss: 0.0
2025-12-09 10:24:41.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 9493 LR: 6.431867463506047e-06 Training loss: 0.0
2025-12-09 10:24:41.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 9494 LR: 6.406524559287641e-06 Training loss: 0.0
2025-12-09 10:24:41.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 9495 LR: 6.381231359918638e-06 Training loss: 0.0
2025-12-09 10:24:41.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 9496 LR: 6.355987867946167e-06 Training loss: 0.0
2025-12-09 10:24:41.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 9497 LR: 6.330794085912195e-06 Training loss: 0.0
2025-12-09 10:24:41.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 9498 LR: 6.305650016353748e-06 Training loss: 0.0
2025-12-09 10:24:41.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 9499 LR: 6.2805556618028556e-06 Training loss: 0.0
2025-12-09 10:24:41.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 9500 LR: 6.255511024786498e-06 Training loss: 0.0
2025-12-09 10:24:41.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 9501 LR: 6.230516107826656e-06 Training loss: 0.0
2025-12-09 10:24:41.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 9502 LR: 6.205570913440317e-06 Training loss: 0.0
2025-12-09 10:24:41.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 9503 LR: 6.180675444139528e-06 Training loss: 0.0
2025-12-09 10:24:41.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 9504 LR: 6.15582970243117e-06 Training loss: 0.0
2025-12-09 10:24:41.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 9505 LR: 6.131033690817245e-06 Training loss: 0.0
2025-12-09 10:24:41.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 9506 LR: 6.106287411794753e-06 Training loss: 0.0
2025-12-09 10:24:41.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 9507 LR: 6.081590867855535e-06 Training loss: 0.0
2025-12-09 10:24:41.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 9508 LR: 6.056944061486658e-06 Training loss: 0.0
2025-12-09 10:24:41.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 9509 LR: 6.032346995169968e-06 Training loss: 0.0
2025-12-09 10:24:41.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 9510 LR: 6.00779967138243e-06 Training loss: 0.0
2025-12-09 10:24:41.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 9511 LR: 5.983302092595955e-06 Training loss: 0.0
2025-12-09 10:24:41.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 9512 LR: 5.958854261277457e-06 Training loss: 0.0
2025-12-09 10:24:41.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 9513 LR: 5.934456179888803e-06 Training loss: 0.0
2025-12-09 10:24:41.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 9514 LR: 5.9101078508869145e-06 Training loss: 0.0
2025-12-09 10:24:41.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 9515 LR: 5.885809276723608e-06 Training loss: 0.0
2025-12-09 10:24:41.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 9516 LR: 5.861560459845816e-06 Training loss: 0.0
2025-12-09 10:24:41.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 9517 LR: 5.837361402695362e-06 Training loss: 0.0
2025-12-09 10:24:41.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 9518 LR: 5.813212107709076e-06 Training loss: 0.0
2025-12-09 10:24:41.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 9519 LR: 5.789112577318789e-06 Training loss: 0.0
2025-12-09 10:24:41.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 9520 LR: 5.765062813951394e-06 Training loss: 0.0
2025-12-09 10:24:41.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 9521 LR: 5.74106282002862e-06 Training loss: 0.0
2025-12-09 10:24:41.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 9522 LR: 5.717112597967311e-06 Training loss: 0.0
2025-12-09 10:24:41.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 9523 LR: 5.693212150179205e-06 Training loss: 0.0
2025-12-09 10:24:41.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 9524 LR: 5.669361479071156e-06 Training loss: 0.0
2025-12-09 10:24:41.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 9525 LR: 5.645560587044851e-06 Training loss: 0.0
2025-12-09 10:24:41.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 9526 LR: 5.6218094764970976e-06 Training loss: 0.0
2025-12-09 10:24:41.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 9527 LR: 5.598108149819536e-06 Training loss: 0.0
2025-12-09 10:24:41.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 9528 LR: 5.5744566093990366e-06 Training loss: 0.0
2025-12-09 10:24:41.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 9529 LR: 5.550854857617194e-06 Training loss: 0.0
2025-12-09 10:24:41.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 9530 LR: 5.5273028968507725e-06 Training loss: 0.0
2025-12-09 10:24:41.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 9531 LR: 5.503800729471376e-06 Training loss: 0.0
2025-12-09 10:24:41.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 9532 LR: 5.4803483578457216e-06 Training loss: 0.0
2025-12-09 10:24:41.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 9533 LR: 5.456945784335421e-06 Training loss: 0.0
2025-12-09 10:24:41.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 9534 LR: 5.4335930112972e-06 Training loss: 0.0
2025-12-09 10:24:41.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 9535 LR: 5.410290041082622e-06 Training loss: 0.0
2025-12-09 10:24:41.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 9536 LR: 5.387036876038309e-06 Training loss: 0.0
2025-12-09 10:24:41.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 9537 LR: 5.363833518505834e-06 Training loss: 0.0
2025-12-09 10:24:41.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 9538 LR: 5.3406799708218265e-06 Training loss: 0.0
2025-12-09 10:24:41.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 9539 LR: 5.317576235317756e-06 Training loss: 0.0
2025-12-09 10:24:41.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 9540 LR: 5.29452231432026e-06 Training loss: 0.0
2025-12-09 10:24:41.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 9541 LR: 5.271518210150816e-06 Training loss: 0.0
2025-12-09 10:24:41.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 9542 LR: 5.24856392512596e-06 Training loss: 0.0
2025-12-09 10:24:41.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 9543 LR: 5.225659461557175e-06 Training loss: 0.0
2025-12-09 10:24:41.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 9544 LR: 5.202804821750951e-06 Training loss: 0.0
2025-12-09 10:24:41.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 9545 LR: 5.180000008008723e-06 Training loss: 0.0
2025-12-09 10:24:41.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 9546 LR: 5.157245022626989e-06 Training loss: 0.0
2025-12-09 10:24:41.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 9547 LR: 5.134539867897081e-06 Training loss: 0.0
2025-12-09 10:24:41.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 9548 LR: 5.111884546105505e-06 Training loss: 0.0
2025-12-09 10:24:41.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 9549 LR: 5.089279059533658e-06 Training loss: 0.0
2025-12-09 10:24:41.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 9550 LR: 5.066723410457774e-06 Training loss: 0.0
2025-12-09 10:24:41.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 9551 LR: 5.04421760114937e-06 Training loss: 0.0
2025-12-09 10:24:41.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 9552 LR: 5.0217616338747445e-06 Training loss: 0.0
2025-12-09 10:24:41.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 9553 LR: 4.999355510895087e-06 Training loss: 0.0
2025-12-09 10:24:41.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 9554 LR: 4.976999234466817e-06 Training loss: 0.0
2025-12-09 10:24:41.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 9555 LR: 4.954692806841188e-06 Training loss: 0.0
2025-12-09 10:24:41.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 9556 LR: 4.932436230264459e-06 Training loss: 0.0
2025-12-09 10:24:41.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 9557 LR: 4.910229506977837e-06 Training loss: 0.0
2025-12-09 10:24:41.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 9558 LR: 4.888072639217589e-06 Training loss: 0.0
2025-12-09 10:24:41.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 9559 LR: 4.865965629214819e-06 Training loss: 0.0
2025-12-09 10:24:41.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 9560 LR: 4.843908479195858e-06 Training loss: 0.0
2025-12-09 10:24:41.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 9561 LR: 4.82190119138165e-06 Training loss: 0.0
2025-12-09 10:24:41.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 9562 LR: 4.799943767988535e-06 Training loss: 0.0
2025-12-09 10:24:41.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 9563 LR: 4.778036211227466e-06 Training loss: 0.0
2025-12-09 10:24:41.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 9564 LR: 4.7561785233046214e-06 Training loss: 0.0
2025-12-09 10:24:41.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 9565 LR: 4.734370706421076e-06 Training loss: 0.0
2025-12-09 10:24:41.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 9566 LR: 4.71261276277285e-06 Training loss: 0.0
2025-12-09 10:24:41.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 9567 LR: 4.6909046945509125e-06 Training loss: 0.0
2025-12-09 10:24:41.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 9568 LR: 4.669246503941404e-06 Training loss: 0.0
2025-12-09 10:24:41.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 9569 LR: 4.6476381931251366e-06 Training loss: 0.0
2025-12-09 10:24:41.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 9570 LR: 4.6260797642782015e-06 Training loss: 0.0
2025-12-09 10:24:41.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 9571 LR: 4.604571219571474e-06 Training loss: 0.0
2025-12-09 10:24:41.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 9572 LR: 4.5831125611708325e-06 Training loss: 0.0
2025-12-09 10:24:41.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 9573 LR: 4.561703791237271e-06 Training loss: 0.0
2025-12-09 10:24:41.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 9574 LR: 4.540344911926509e-06 Training loss: 0.0
2025-12-09 10:24:41.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 9575 LR: 4.519035925389492e-06 Training loss: 0.0
2025-12-09 10:24:41.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 9576 LR: 4.497776833772005e-06 Training loss: 0.0
2025-12-09 10:24:41.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 9577 LR: 4.476567639214779e-06 Training loss: 0.0
2025-12-09 10:24:41.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 9578 LR: 4.455408343853718e-06 Training loss: 0.0
2025-12-09 10:24:41.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 9579 LR: 4.434298949819449e-06 Training loss: 0.0
2025-12-09 10:24:41.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 9580 LR: 4.413239459237661e-06 Training loss: 0.0
2025-12-09 10:24:41.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 9581 LR: 4.392229874229159e-06 Training loss: 0.0
2025-12-09 10:24:41.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 9582 LR: 4.371270196909527e-06 Training loss: 0.0
2025-12-09 10:24:41.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 9583 LR: 4.350360429389411e-06 Training loss: 0.0
2025-12-09 10:24:41.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 9584 LR: 4.329500573774458e-06 Training loss: 0.0
2025-12-09 10:24:41.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 9585 LR: 4.308690632165213e-06 Training loss: 0.0
2025-12-09 10:24:41.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 9586 LR: 4.287930606657275e-06 Training loss: 0.0
2025-12-09 10:24:41.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 9587 LR: 4.267220499341195e-06 Training loss: 0.0
2025-12-09 10:24:41.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 9588 LR: 4.246560312302416e-06 Training loss: 0.0
2025-12-09 10:24:41.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 9589 LR: 4.2259500476214406e-06 Training loss: 0.0
2025-12-09 10:24:41.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 9590 LR: 4.205389707373719e-06 Training loss: 0.0
2025-12-09 10:24:41.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 9591 LR: 4.184879293629707e-06 Training loss: 0.0
2025-12-09 10:24:41.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 9592 LR: 4.164418808454807e-06 Training loss: 0.0
2025-12-09 10:24:41.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 9593 LR: 4.14400825390937e-06 Training loss: 0.0
2025-12-09 10:24:41.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 9594 LR: 4.123647632048644e-06 Training loss: 0.0
2025-12-09 10:24:41.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 9595 LR: 4.103336944923153e-06 Training loss: 0.0
2025-12-09 10:24:41.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 9596 LR: 4.083076194577984e-06 Training loss: 0.0
2025-12-09 10:24:41.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 9597 LR: 4.0628653830535045e-06 Training loss: 0.0
2025-12-09 10:24:41.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 9598 LR: 4.042704512384865e-06 Training loss: 0.0
2025-12-09 10:24:41.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 9599 LR: 4.02259358460233e-06 Training loss: 0.0
2025-12-09 10:24:41.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 9600 LR: 4.0025326017311125e-06 Training loss: 0.0
2025-12-09 10:24:41.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 9601 LR: 3.982521565791264e-06 Training loss: 0.0
2025-12-09 10:24:41.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 9602 LR: 3.962560478797839e-06 Training loss: 0.0
2025-12-09 10:24:41.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 9603 LR: 3.942649342761117e-06 Training loss: 0.0
2025-12-09 10:24:41.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 9604 LR: 3.9227881596859416e-06 Training loss: 0.0
2025-12-09 10:24:41.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 9605 LR: 3.902976931572488e-06 Training loss: 0.0
2025-12-09 10:24:41.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 9606 LR: 3.883215660415662e-06 Training loss: 0.0
2025-12-09 10:24:41.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 9607 LR: 3.863504348205426e-06 Training loss: 0.0
2025-12-09 10:24:41.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 9608 LR: 3.84384299692675e-06 Training loss: 0.0
2025-12-09 10:24:41.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 9609 LR: 3.8242316085594916e-06 Training loss: 0.0
2025-12-09 10:24:41.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 9610 LR: 3.804670185078518e-06 Training loss: 0.0
2025-12-09 10:24:41.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 9611 LR: 3.7851587284537526e-06 Training loss: 0.0
2025-12-09 10:24:41.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 9612 LR: 3.7656972406498457e-06 Training loss: 0.0
2025-12-09 10:24:41.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 9613 LR: 3.74628572362673e-06 Training loss: 0.0
2025-12-09 10:24:41.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 9614 LR: 3.7269241793390084e-06 Training loss: 0.0
2025-12-09 10:24:41.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 9615 LR: 3.707612609736399e-06 Training loss: 0.0
2025-12-09 10:24:41.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 9616 LR: 3.68835101676368e-06 Training loss: 0.0
2025-12-09 10:24:41.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 9617 LR: 3.6691394023604665e-06 Training loss: 0.0
2025-12-09 10:24:41.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 9618 LR: 3.649977768461266e-06 Training loss: 0.0
2025-12-09 10:24:41.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 9619 LR: 3.630866116995757e-06 Training loss: 0.0
2025-12-09 10:24:41.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 9620 LR: 3.611804449888456e-06 Training loss: 0.0
2025-12-09 10:24:41.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 9621 LR: 3.592792769058828e-06 Training loss: 0.0
2025-12-09 10:24:41.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 9622 LR: 3.5738310764213964e-06 Training loss: 0.0
2025-12-09 10:24:41.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 9623 LR: 3.5549193738856343e-06 Training loss: 0.0
2025-12-09 10:24:41.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 9624 LR: 3.536057663355852e-06 Training loss: 0.0
2025-12-09 10:24:41.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 9625 LR: 3.5172459467315286e-06 Training loss: 0.0
2025-12-09 10:24:41.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 9626 LR: 3.4984842259069282e-06 Training loss: 0.0
2025-12-09 10:24:41.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 9627 LR: 3.4797725027713723e-06 Training loss: 0.0
2025-12-09 10:24:41.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 9628 LR: 3.461110779209131e-06 Training loss: 0.0
2025-12-09 10:24:41.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 9629 LR: 3.4424990570994797e-06 Training loss: 0.0
2025-12-09 10:24:41.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 9630 LR: 3.423937338316585e-06 Training loss: 0.0
2025-12-09 10:24:41.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 9631 LR: 3.4054256247296188e-06 Training loss: 0.0
2025-12-09 10:24:41.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 9632 LR: 3.3869639182026456e-06 Training loss: 0.0
2025-12-09 10:24:41.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 9633 LR: 3.3685522205949006e-06 Training loss: 0.0
2025-12-09 10:24:41.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 9634 LR: 3.350190533760289e-06 Training loss: 0.0
2025-12-09 10:24:41.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 9635 LR: 3.3318788595479434e-06 Training loss: 0.0
2025-12-09 10:24:41.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 9636 LR: 3.3136171998017774e-06 Training loss: 0.0
2025-12-09 10:24:41.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 9637 LR: 3.29540555636082e-06 Training loss: 0.0
2025-12-09 10:24:41.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 9638 LR: 3.277243931058882e-06 Training loss: 0.0
2025-12-09 10:24:41.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 9639 LR: 3.2591323257248896e-06 Training loss: 0.0
2025-12-09 10:24:41.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 9640 LR: 3.241070742182717e-06 Training loss: 0.0
2025-12-09 10:24:41.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 9641 LR: 3.223059182251076e-06 Training loss: 0.0
2025-12-09 10:24:41.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 9642 LR: 3.2050976477438487e-06 Training loss: 0.0
2025-12-09 10:24:41.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 9643 LR: 3.1871861404696445e-06 Training loss: 0.0
2025-12-09 10:24:41.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 9644 LR: 3.169324662232187e-06 Training loss: 0.0
2025-12-09 10:24:41.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 9645 LR: 3.1515132148302038e-06 Training loss: 0.0
2025-12-09 10:24:41.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 9646 LR: 3.1337518000572052e-06 Training loss: 0.0
2025-12-09 10:24:41.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 9647 LR: 3.1160404197018156e-06 Training loss: 0.0
2025-12-09 10:24:41.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 9648 LR: 3.098379075547553e-06 Training loss: 0.0
2025-12-09 10:24:41.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 9649 LR: 3.0807677693729385e-06 Training loss: 0.0
2025-12-09 10:24:41.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 9650 LR: 3.0632065029513877e-06 Training loss: 0.0
2025-12-09 10:24:41.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 9651 LR: 3.0456952780513746e-06 Training loss: 0.0
2025-12-09 10:24:41.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 9652 LR: 3.028234096436211e-06 Training loss: 0.0
2025-12-09 10:24:41.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 9653 LR: 3.0108229598643234e-06 Training loss: 0.0
2025-12-09 10:24:41.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 9654 LR: 2.9934618700889204e-06 Training loss: 0.0
2025-12-09 10:24:41.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 9655 LR: 2.976150828858326e-06 Training loss: 0.0
2025-12-09 10:24:41.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 9656 LR: 2.9588898379157015e-06 Training loss: 0.0
2025-12-09 10:24:41.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 9657 LR: 2.9416788989993782e-06 Training loss: 0.0
2025-12-09 10:24:41.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 9658 LR: 2.9245180138423033e-06 Training loss: 0.0
2025-12-09 10:24:41.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 9659 LR: 2.9074071841727055e-06 Training loss: 0.0
2025-12-09 10:24:41.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 9660 LR: 2.8903464117135956e-06 Training loss: 0.0
2025-12-09 10:24:41.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 9661 LR: 2.8733356981829885e-06 Training loss: 0.0
2025-12-09 10:24:41.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 9662 LR: 2.856375045293846e-06 Training loss: 0.0
2025-12-09 10:24:41.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 9663 LR: 2.8394644547541373e-06 Training loss: 0.0
2025-12-09 10:24:41.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 9664 LR: 2.8226039282667757e-06 Training loss: 0.0
2025-12-09 10:24:41.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 9665 LR: 2.805793467529627e-06 Training loss: 0.0
2025-12-09 10:24:41.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 9666 LR: 2.7890330742354474e-06 Training loss: 0.0
2025-12-09 10:24:41.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 9667 LR: 2.7723227500719985e-06 Training loss: 0.0
2025-12-09 10:24:41.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 9668 LR: 2.7556624967221e-06 Training loss: 0.0
2025-12-09 10:24:41.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 9669 LR: 2.739052315863355e-06 Training loss: 0.0
2025-12-09 10:24:41.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 9670 LR: 2.7224922091684255e-06 Training loss: 0.0
2025-12-09 10:24:41.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 9671 LR: 2.705982178304922e-06 Training loss: 0.0
2025-12-09 10:24:41.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 9672 LR: 2.6895222249354035e-06 Training loss: 0.0
2025-12-09 10:24:41.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 9673 LR: 2.6731123507174327e-06 Training loss: 0.0
2025-12-09 10:24:41.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 9674 LR: 2.65675255730341e-06 Training loss: 0.0
2025-12-09 10:24:41.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 9675 LR: 2.640442846340796e-06 Training loss: 0.0
2025-12-09 10:24:41.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 9676 LR: 2.6241832194719985e-06 Training loss: 0.0
2025-12-09 10:24:41.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 9677 LR: 2.6079736783343187e-06 Training loss: 0.0
2025-12-09 10:24:41.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 9678 LR: 2.5918142245600627e-06 Training loss: 0.0
2025-12-09 10:24:41.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 9679 LR: 2.5757048597765396e-06 Training loss: 0.0
2025-12-09 10:24:41.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 9680 LR: 2.5596455856058963e-06 Training loss: 0.0
2025-12-09 10:24:41.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 9681 LR: 2.5436364036653394e-06 Training loss: 0.0
2025-12-09 10:24:41.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 9682 LR: 2.527677315567023e-06 Training loss: 0.0
2025-12-09 10:24:41.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 9683 LR: 2.51176832291794e-06 Training loss: 0.0
2025-12-09 10:24:41.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 9684 LR: 2.4959094273201976e-06 Training loss: 0.0
2025-12-09 10:24:41.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 9685 LR: 2.4801006303707964e-06 Training loss: 0.0
2025-12-09 10:24:41.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 9686 LR: 2.4643419336615736e-06 Training loss: 0.0
2025-12-09 10:24:41.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 9687 LR: 2.448633338779593e-06 Training loss: 0.0
2025-12-09 10:24:41.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 9688 LR: 2.4329748473065905e-06 Training loss: 0.0
2025-12-09 10:24:41.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 9689 LR: 2.417366460819359e-06 Training loss: 0.0
2025-12-09 10:24:41.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 9690 LR: 2.401808180889753e-06 Training loss: 0.0
2025-12-09 10:24:41.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 9691 LR: 2.386300009084408e-06 Training loss: 0.0
2025-12-09 10:24:41.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 9692 LR: 2.3708419469650743e-06 Training loss: 0.0
2025-12-09 10:24:41.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 9693 LR: 2.355433996088341e-06 Training loss: 0.0
2025-12-09 10:24:41.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 9694 LR: 2.340076158005744e-06 Training loss: 0.0
2025-12-09 10:24:41.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 9695 LR: 2.3247684342639353e-06 Training loss: 0.0
2025-12-09 10:24:41.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 9696 LR: 2.309510826404293e-06 Training loss: 0.0
2025-12-09 10:24:41.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 9697 LR: 2.294303335963255e-06 Training loss: 0.0
2025-12-09 10:24:41.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 9698 LR: 2.2791459644723176e-06 Training loss: 0.0
2025-12-09 10:24:41.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 9699 LR: 2.2640387134577057e-06 Training loss: 0.0
2025-12-09 10:24:41.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 9700 LR: 2.2489815844408126e-06 Training loss: 0.0
2025-12-09 10:24:41.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 9701 LR: 2.233974578937814e-06 Training loss: 0.0
2025-12-09 10:24:41.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 9702 LR: 2.219017698460002e-06 Training loss: 0.0
2025-12-09 10:24:41.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 9703 LR: 2.204110944513449e-06 Training loss: 0.0
2025-12-09 10:24:41.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 9704 LR: 2.189254318599343e-06 Training loss: 0.0
2025-12-09 10:24:41.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 9705 LR: 2.1744478222136542e-06 Training loss: 0.0
2025-12-09 10:24:41.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 9706 LR: 2.1596914568475236e-06 Training loss: 0.0
2025-12-09 10:24:41.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 9707 LR: 2.144985223986817e-06 Training loss: 0.0
2025-12-09 10:24:41.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 9708 LR: 2.130329125112407e-06 Training loss: 0.0
2025-12-09 10:24:41.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 9709 LR: 2.115723161700278e-06 Training loss: 0.0
2025-12-09 10:24:41.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 9710 LR: 2.1011673352212544e-06 Training loss: 0.0
2025-12-09 10:24:41.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 9711 LR: 2.0866616471409973e-06 Training loss: 0.0
2025-12-09 10:24:41.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 9712 LR: 2.072206098920282e-06 Training loss: 0.0
2025-12-09 10:24:41.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 9713 LR: 2.057800692014833e-06 Training loss: 0.0
2025-12-09 10:24:41.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 9714 LR: 2.0434454278752124e-06 Training loss: 0.0
2025-12-09 10:24:41.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 9715 LR: 2.029140307946986e-06 Training loss: 0.0
2025-12-09 10:24:41.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 9716 LR: 2.014885333670724e-06 Training loss: 0.0
2025-12-09 10:24:41.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 9717 LR: 2.000680506481889e-06 Training loss: 0.0
2025-12-09 10:24:41.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 9718 LR: 1.9865258278108923e-06 Training loss: 0.0
2025-12-09 10:24:41.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 9719 LR: 1.9724212990830937e-06 Training loss: 0.0
2025-12-09 10:24:41.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 9720 LR: 1.958366921718913e-06 Training loss: 0.0
2025-12-09 10:24:41.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 9721 LR: 1.944362697133495e-06 Training loss: 0.0
2025-12-09 10:24:41.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 9722 LR: 1.9304086267371566e-06 Training loss: 0.0
2025-12-09 10:24:41.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 9723 LR: 1.9165047119349965e-06 Training loss: 0.0
2025-12-09 10:24:41.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 9724 LR: 1.9026509541272275e-06 Training loss: 0.0
2025-12-09 10:24:41.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 9725 LR: 1.8888473547088447e-06 Training loss: 0.0
2025-12-09 10:24:41.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 9726 LR: 1.8750939150699587e-06 Training loss: 0.0
2025-12-09 10:24:41.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 9727 LR: 1.8613906365954614e-06 Training loss: 0.0
2025-12-09 10:24:41.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 9728 LR: 1.8477375206653046e-06 Training loss: 0.0
2025-12-09 10:24:41.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 9729 LR: 1.8341345686543331e-06 Training loss: 0.0
2025-12-09 10:24:41.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 9730 LR: 1.82058178193234e-06 Training loss: 0.0
2025-12-09 10:24:41.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 9731 LR: 1.8070791618641779e-06 Training loss: 0.0
2025-12-09 10:24:41.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 9732 LR: 1.7936267098095372e-06 Training loss: 0.0
2025-12-09 10:24:41.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 9733 LR: 1.7802244271230005e-06 Training loss: 0.0
2025-12-09 10:24:41.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 9734 LR: 1.7668723151542665e-06 Training loss: 0.0
2025-12-09 10:24:41.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 9735 LR: 1.753570375247815e-06 Training loss: 0.0
2025-12-09 10:24:41.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 9736 LR: 1.740318608743241e-06 Training loss: 0.0
2025-12-09 10:24:41.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 9737 LR: 1.7271170169749218e-06 Training loss: 0.0
2025-12-09 10:24:41.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 9738 LR: 1.7139656012722936e-06 Training loss: 0.0
2025-12-09 10:24:41.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 9739 LR: 1.7008643629596864e-06 Training loss: 0.0
2025-12-09 10:24:41.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 9740 LR: 1.6878133033564336e-06 Training loss: 0.0
2025-12-09 10:24:41.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 9741 LR: 1.674812423776706e-06 Training loss: 0.0
2025-12-09 10:24:41.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 9742 LR: 1.6618617255297896e-06 Training loss: 0.0
2025-12-09 10:24:41.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 9743 LR: 1.6489612099197526e-06 Training loss: 0.0
2025-12-09 10:24:41.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 9744 LR: 1.6361108782456114e-06 Training loss: 0.0
2025-12-09 10:24:41.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 9745 LR: 1.6233107318015528e-06 Training loss: 0.0
2025-12-09 10:24:41.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 9746 LR: 1.6105607718764347e-06 Training loss: 0.0
2025-12-09 10:24:41.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 9747 LR: 1.5978609997542304e-06 Training loss: 0.0
2025-12-09 10:24:41.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 9748 LR: 1.5852114167136945e-06 Training loss: 0.0
2025-12-09 10:24:41.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 9749 LR: 1.5726120240288633e-06 Training loss: 0.0
2025-12-09 10:24:41.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 9750 LR: 1.5600628229682778e-06 Training loss: 0.0
2025-12-09 10:24:41.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 9751 LR: 1.5475638147957604e-06 Training loss: 0.0
2025-12-09 10:24:41.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 9752 LR: 1.5351150007699156e-06 Training loss: 0.0
2025-12-09 10:24:41.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 9753 LR: 1.5227163821443513e-06 Training loss: 0.0
2025-12-09 10:24:41.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 9754 LR: 1.510367960167569e-06 Training loss: 0.0
2025-12-09 10:24:41.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 9755 LR: 1.4980697360831852e-06 Training loss: 0.0
2025-12-09 10:24:41.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 9756 LR: 1.4858217111294869e-06 Training loss: 0.0
2025-12-09 10:24:41.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 9757 LR: 1.4736238865398766e-06 Training loss: 0.0
2025-12-09 10:24:41.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 9758 LR: 1.4614762635427604e-06 Training loss: 0.0
2025-12-09 10:24:41.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 9759 LR: 1.4493788433612708e-06 Training loss: 0.0
2025-12-09 10:24:41.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 9760 LR: 1.437331627213767e-06 Training loss: 0.0
2025-12-09 10:24:41.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 9761 LR: 1.4253346163132785e-06 Training loss: 0.0
2025-12-09 10:24:41.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 9762 LR: 1.41338781186795e-06 Training loss: 0.0
2025-12-09 10:24:41.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 9763 LR: 1.4014912150808745e-06 Training loss: 0.0
2025-12-09 10:24:41.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 9764 LR: 1.3896448271499272e-06 Training loss: 0.0
2025-12-09 10:24:41.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 9765 LR: 1.377848649268154e-06 Training loss: 0.0
2025-12-09 10:24:41.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 9766 LR: 1.366102682623327e-06 Training loss: 0.0
2025-12-09 10:24:41.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 9767 LR: 1.354406928398333e-06 Training loss: 0.0
2025-12-09 10:24:41.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 9768 LR: 1.3427613877709521e-06 Training loss: 0.0
2025-12-09 10:24:41.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 9769 LR: 1.3311660619138578e-06 Training loss: 0.0
2025-12-09 10:24:41.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 9770 LR: 1.3196209519946156e-06 Training loss: 0.0
2025-12-09 10:24:41.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 9771 LR: 1.308126059176018e-06 Training loss: 0.0
2025-12-09 10:24:41.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 9772 LR: 1.296681384615417e-06 Training loss: 0.0
2025-12-09 10:24:41.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 9773 LR: 1.2852869294653346e-06 Training loss: 0.0
2025-12-09 10:24:41.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 9774 LR: 1.2739426948732423e-06 Training loss: 0.0
2025-12-09 10:24:41.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 9775 LR: 1.2626486819814487e-06 Training loss: 0.0
2025-12-09 10:24:41.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 9776 LR: 1.2514048919273214e-06 Training loss: 0.0
2025-12-09 10:24:41.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 9777 LR: 1.2402113258430658e-06 Training loss: 0.0
2025-12-09 10:24:41.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 9778 LR: 1.229067984855836e-06 Training loss: 0.0
2025-12-09 10:24:41.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 9779 LR: 1.2179748700879012e-06 Training loss: 0.0
2025-12-09 10:24:41.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 9780 LR: 1.2069319826562009e-06 Training loss: 0.0
2025-12-09 10:24:41.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 9781 LR: 1.19593932367279e-06 Training loss: 0.0
2025-12-09 10:24:41.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 9782 LR: 1.1849968942446166e-06 Training loss: 0.0
2025-12-09 10:24:41.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 9783 LR: 1.1741046954736878e-06 Training loss: 0.0
2025-12-09 10:24:41.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 9784 LR: 1.163262728456682e-06 Training loss: 0.0
2025-12-09 10:24:41.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 9785 LR: 1.1524709942855594e-06 Training loss: 0.0
2025-12-09 10:24:41.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 9786 LR: 1.1417294940468948e-06 Training loss: 0.0
2025-12-09 10:24:41.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 9787 LR: 1.131038228822434e-06 Training loss: 0.0
2025-12-09 10:24:41.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 9788 LR: 1.1203971996887608e-06 Training loss: 0.0
2025-12-09 10:24:41.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 9789 LR: 1.1098064077174619e-06 Training loss: 0.0
2025-12-09 10:24:41.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 9790 LR: 1.0992658539750178e-06 Training loss: 0.0
2025-12-09 10:24:41.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 9791 LR: 1.0887755395228016e-06 Training loss: 0.0
2025-12-09 10:24:41.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 9792 LR: 1.0783354654173017e-06 Training loss: 0.0
2025-12-09 10:24:41.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 9793 LR: 1.0679456327097326e-06 Training loss: 0.0
2025-12-09 10:24:41.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 9794 LR: 1.0576060424463685e-06 Training loss: 0.0
2025-12-09 10:24:41.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 9795 LR: 1.047316695668432e-06 Training loss: 0.0
2025-12-09 10:24:41.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 9796 LR: 1.0370775934120946e-06 Training loss: 0.0
2025-12-09 10:24:41.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 9797 LR: 1.0268887367083646e-06 Training loss: 0.0
2025-12-09 10:24:41.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 9798 LR: 1.0167501265832547e-06 Training loss: 0.0
2025-12-09 10:24:41.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 9799 LR: 1.006661764057837e-06 Training loss: 0.0
2025-12-09 10:24:41.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 9800 LR: 9.966236501478542e-07 Training loss: 0.0
2025-12-09 10:24:41.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 9801 LR: 9.866357858642206e-07 Training loss: 0.0
2025-12-09 10:24:41.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 9802 LR: 9.766981722127421e-07 Training loss: 0.0
2025-12-09 10:24:41.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 9803 LR: 9.668108101940631e-07 Training loss: 0.0
2025-12-09 10:24:41.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 9804 LR: 9.56973700803887e-07 Training loss: 0.0
2025-12-09 10:24:41.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 9805 LR: 9.471868450328103e-07 Training loss: 0.0
2025-12-09 10:24:41.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 9806 LR: 9.374502438663779e-07 Training loss: 0.0
2025-12-09 10:24:41.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 9807 LR: 9.277638982850834e-07 Training loss: 0.0
2025-12-09 10:24:41.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 9808 LR: 9.181278092642576e-07 Training loss: 0.0
2025-12-09 10:24:41.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 9809 LR: 9.085419777743465e-07 Training loss: 0.0
2025-12-09 10:24:41.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 9810 LR: 8.990064047805225e-07 Training loss: 0.0
2025-12-09 10:24:41.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 9811 LR: 8.895210912431839e-07 Training loss: 0.0
2025-12-09 10:24:41.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 9812 LR: 8.800860381173448e-07 Training loss: 0.0
2025-12-09 10:24:41.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 9813 LR: 8.707012463532449e-07 Training loss: 0.0
2025-12-09 10:24:41.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 9814 LR: 8.613667168958505e-07 Training loss: 0.0
2025-12-09 10:24:41.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 9815 LR: 8.520824506851876e-07 Training loss: 0.0
2025-12-09 10:24:41.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 9816 LR: 8.428484486561194e-07 Training loss: 0.0
2025-12-09 10:24:41.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 9817 LR: 8.336647117385687e-07 Training loss: 0.0
2025-12-09 10:24:41.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 9818 LR: 8.245312408573513e-07 Training loss: 0.0
2025-12-09 10:24:41.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 9819 LR: 8.15448036932176e-07 Training loss: 0.0
2025-12-09 10:24:41.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 9820 LR: 8.064151008776998e-07 Training loss: 0.0
2025-12-09 10:24:41.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 9821 LR: 7.974324336035843e-07 Training loss: 0.0
2025-12-09 10:24:41.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 9822 LR: 7.88500036014328e-07 Training loss: 0.0
2025-12-09 10:24:41.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 9823 LR: 7.796179090094891e-07 Training loss: 0.0
2025-12-09 10:24:41.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 9824 LR: 7.707860534834632e-07 Training loss: 0.0
2025-12-09 10:24:41.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 9825 LR: 7.620044703256502e-07 Training loss: 0.0
2025-12-09 10:24:41.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 9826 LR: 7.532731604202869e-07 Training loss: 0.0
2025-12-09 10:24:41.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 9827 LR: 7.445921246466702e-07 Training loss: 0.0
2025-12-09 10:24:41.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 9828 LR: 7.359613638789342e-07 Training loss: 0.0
2025-12-09 10:24:41.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 9829 LR: 7.273808789862724e-07 Training loss: 0.0
2025-12-09 10:24:41.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 9830 LR: 7.188506708327159e-07 Training loss: 0.0
2025-12-09 10:24:41.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 9831 LR: 7.103707402771886e-07 Training loss: 0.0
2025-12-09 10:24:41.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 9832 LR: 7.019410881736743e-07 Training loss: 0.0
2025-12-09 10:24:41.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 9833 LR: 6.935617153710494e-07 Training loss: 0.0
2025-12-09 10:24:41.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 9834 LR: 6.852326227130834e-07 Training loss: 0.0
2025-12-09 10:24:41.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 9835 LR: 6.769538110384943e-07 Training loss: 0.0
2025-12-09 10:24:41.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 9836 LR: 6.687252811810596e-07 Training loss: 0.0
2025-12-09 10:24:41.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 9837 LR: 6.605470339692832e-07 Training loss: 0.0
2025-12-09 10:24:41.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 9838 LR: 6.52419070226784e-07 Training loss: 0.0
2025-12-09 10:24:41.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 9839 LR: 6.443413907720186e-07 Training loss: 0.0
2025-12-09 10:24:41.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 9840 LR: 6.363139964183917e-07 Training loss: 0.0
2025-12-09 10:24:41.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 9841 LR: 6.283368879742568e-07 Training loss: 0.0
2025-12-09 10:24:41.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 9842 LR: 6.204100662429712e-07 Training loss: 0.0
2025-12-09 10:24:41.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 9843 LR: 6.125335320227299e-07 Training loss: 0.0
2025-12-09 10:24:41.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 9844 LR: 6.047072861067315e-07 Training loss: 0.0
2025-12-09 10:24:41.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 9845 LR: 5.969313292830125e-07 Training loss: 0.0
2025-12-09 10:24:41.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 9846 LR: 5.892056623346132e-07 Training loss: 0.0
2025-12-09 10:24:41.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 9847 LR: 5.815302860395777e-07 Training loss: 0.0
2025-12-09 10:24:41.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 9848 LR: 5.739052011707325e-07 Training loss: 0.0
2025-12-09 10:24:41.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 9849 LR: 5.663304084960185e-07 Training loss: 0.0
2025-12-09 10:24:41.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 9850 LR: 5.588059087781594e-07 Training loss: 0.0
2025-12-09 10:24:41.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 9851 LR: 5.513317027748821e-07 Training loss: 0.0
2025-12-09 10:24:41.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 9852 LR: 5.439077912388068e-07 Training loss: 0.0
2025-12-09 10:24:41.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 9853 LR: 5.365341749175578e-07 Training loss: 0.0
2025-12-09 10:24:41.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 9854 LR: 5.292108545536522e-07 Training loss: 0.0
2025-12-09 10:24:41.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 9855 LR: 5.219378308845557e-07 Training loss: 0.0
2025-12-09 10:24:41.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 9856 LR: 5.147151046426823e-07 Training loss: 0.0
2025-12-09 10:24:41.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 9857 LR: 5.075426765552837e-07 Training loss: 0.0
2025-12-09 10:24:41.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 9858 LR: 5.00420547344671e-07 Training loss: 0.0
2025-12-09 10:24:41.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 9859 LR: 4.933487177280482e-07 Training loss: 0.0
2025-12-09 10:24:41.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 9860 LR: 4.863271884175679e-07 Training loss: 0.0
2025-12-09 10:24:41.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 9861 LR: 4.793559601202757e-07 Training loss: 0.0
2025-12-09 10:24:41.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 9862 LR: 4.7243503353811e-07 Training loss: 0.0
2025-12-09 10:24:41.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 9863 LR: 4.655644093681244e-07 Training loss: 0.0
2025-12-09 10:24:41.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 9864 LR: 4.5874408830215433e-07 Training loss: 0.0
2025-12-09 10:24:41.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 9865 LR: 4.519740710269282e-07 Training loss: 0.0
2025-12-09 10:24:41.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 9866 LR: 4.4525435822428964e-07 Training loss: 0.0
2025-12-09 10:24:41.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 9867 LR: 4.3858495057080837e-07 Training loss: 0.0
2025-12-09 10:24:41.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 9868 LR: 4.31965848738225e-07 Training loss: 0.0
2025-12-09 10:24:41.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 9869 LR: 4.2539705339295075e-07 Training loss: 0.0
2025-12-09 10:24:41.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 9870 LR: 4.1887856519656764e-07 Training loss: 0.0
2025-12-09 10:24:41.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 9871 LR: 4.124103848054395e-07 Training loss: 0.0
2025-12-09 10:24:41.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 9872 LR: 4.0599251287087857e-07 Training loss: 0.0
2025-12-09 10:24:41.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 9873 LR: 3.996249500392568e-07 Training loss: 0.0
2025-12-09 10:24:41.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 9874 LR: 3.9330769695167246e-07 Training loss: 0.0
2025-12-09 10:24:41.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 9875 LR: 3.8704075424439435e-07 Training loss: 0.0
2025-12-09 10:24:41.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 9876 LR: 3.808241225484177e-07 Training loss: 0.0
2025-12-09 10:24:41.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 9877 LR: 3.746578024897418e-07 Training loss: 0.0
2025-12-09 10:24:41.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 9878 LR: 3.685417946894254e-07 Training loss: 0.0
2025-12-09 10:24:41.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 9879 LR: 3.6247609976319816e-07 Training loss: 0.0
2025-12-09 10:24:41.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 9880 LR: 3.564607183220159e-07 Training loss: 0.0
2025-12-09 10:24:41.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 9881 LR: 3.504956509715607e-07 Training loss: 0.0
2025-12-09 10:24:41.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 9882 LR: 3.445808983125187e-07 Training loss: 0.0
2025-12-09 10:24:41.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 9883 LR: 3.3871646094052466e-07 Training loss: 0.0
2025-12-09 10:24:41.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 9884 LR: 3.3290233944605066e-07 Training loss: 0.0
2025-12-09 10:24:41.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 9885 LR: 3.2713853441468375e-07 Training loss: 0.0
2025-12-09 10:24:41.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 9886 LR: 3.2142504642679313e-07 Training loss: 0.0
2025-12-09 10:24:41.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 9887 LR: 3.1576187605775186e-07 Training loss: 0.0
2025-12-09 10:24:41.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 9888 LR: 3.1014902387777046e-07 Training loss: 0.0
2025-12-09 10:24:41.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 9889 LR: 3.0458649045211895e-07 Training loss: 0.0
2025-12-09 10:24:41.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 9890 LR: 2.990742763409604e-07 Training loss: 0.0
2025-12-09 10:24:41.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 9891 LR: 2.9361238209935083e-07 Training loss: 0.0
2025-12-09 10:24:41.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 9892 LR: 2.882008082772947e-07 Training loss: 0.0
2025-12-09 10:24:41.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 9893 LR: 2.828395554196894e-07 Training loss: 0.0
2025-12-09 10:24:41.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 9894 LR: 2.775286240665476e-07 Training loss: 0.0
2025-12-09 10:24:41.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 9895 LR: 2.722680147525525e-07 Training loss: 0.0
2025-12-09 10:24:41.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 9896 LR: 2.670577280075026e-07 Training loss: 0.0
2025-12-09 10:24:41.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 9897 LR: 2.6189776435608934e-07 Training loss: 0.0
2025-12-09 10:24:41.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 9898 LR: 2.567881243178971e-07 Training loss: 0.0
2025-12-09 10:24:41.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 9899 LR: 2.517288084074587e-07 Training loss: 0.0
2025-12-09 10:24:41.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 9900 LR: 2.467198171342e-07 Training loss: 0.0
2025-12-09 10:24:41.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 9901 LR: 2.417611510026618e-07 Training loss: 0.0
2025-12-09 10:24:41.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 9902 LR: 2.36852810512056e-07 Training loss: 0.0
2025-12-09 10:24:41.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 9903 LR: 2.3199479615670926e-07 Training loss: 0.0
2025-12-09 10:24:41.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 9904 LR: 2.2718710842584145e-07 Training loss: 0.0
2025-12-09 10:24:41.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 9905 LR: 2.2242974780350977e-07 Training loss: 0.0
2025-12-09 10:24:41.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 9906 LR: 2.17722714768831e-07 Training loss: 0.0
2025-12-09 10:24:41.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 9907 LR: 2.1306600979581481e-07 Training loss: 0.0
2025-12-09 10:24:41.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 9908 LR: 2.0845963335336393e-07 Training loss: 0.0
2025-12-09 10:24:41.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 9909 LR: 2.0390358590538505e-07 Training loss: 0.0
2025-12-09 10:24:41.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 9910 LR: 1.9939786791062232e-07 Training loss: 0.0
2025-12-09 10:24:41.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 9911 LR: 1.9494247982282386e-07 Training loss: 0.0
2025-12-09 10:24:41.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 9912 LR: 1.9053742209063086e-07 Training loss: 0.0
2025-12-09 10:24:41.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 9913 LR: 1.8618269515763286e-07 Training loss: 0.0
2025-12-09 10:24:41.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 9914 LR: 1.81878299462368e-07 Training loss: 0.0
2025-12-09 10:24:41.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 9915 LR: 1.7762423543832286e-07 Training loss: 0.0
2025-12-09 10:24:41.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 9916 LR: 1.7342050351382143e-07 Training loss: 0.0
2025-12-09 10:24:41.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 9917 LR: 1.6926710411219183e-07 Training loss: 0.0
2025-12-09 10:24:41.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 9918 LR: 1.65164037651655e-07 Training loss: 0.0
2025-12-09 10:24:41.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 9919 LR: 1.61111304545436e-07 Training loss: 0.0
2025-12-09 10:24:41.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 9920 LR: 1.5710890520165277e-07 Training loss: 0.0
2025-12-09 10:24:41.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 9921 LR: 1.531568400233163e-07 Training loss: 0.0
2025-12-09 10:24:41.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 9922 LR: 1.4925510940844156e-07 Training loss: 0.0
2025-12-09 10:24:41.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 9923 LR: 1.4540371374988093e-07 Training loss: 0.0
2025-12-09 10:24:41.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 9924 LR: 1.4160265343549083e-07 Training loss: 0.0
2025-12-09 10:24:41.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 9925 LR: 1.3785192884802068e-07 Training loss: 0.0
2025-12-09 10:24:41.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 9926 LR: 1.341515403651683e-07 Training loss: 0.0
2025-12-09 10:24:41.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 9927 LR: 1.3050148835958008e-07 Training loss: 0.0
2025-12-09 10:24:41.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 9928 LR: 1.269017731988509e-07 Training loss: 0.0
2025-12-09 10:24:41.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 9929 LR: 1.2335239524541298e-07 Training loss: 0.0
2025-12-09 10:24:41.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 9930 LR: 1.1985335485675818e-07 Training loss: 0.0
2025-12-09 10:24:41.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 9931 LR: 1.1640465238516029e-07 Training loss: 0.0
2025-12-09 10:24:41.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 9932 LR: 1.1300628817789705e-07 Training loss: 0.0
2025-12-09 10:24:41.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 9933 LR: 1.096582625772502e-07 Training loss: 0.0
2025-12-09 10:24:41.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 9934 LR: 1.0636057592033899e-07 Training loss: 0.0
2025-12-09 10:24:41.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 9935 LR: 1.0311322853928662e-07 Training loss: 0.0
2025-12-09 10:24:41.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 9936 LR: 9.991622076099827e-08 Training loss: 0.0
2025-12-09 10:24:41.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 9937 LR: 9.676955290749412e-08 Training loss: 0.0
2025-12-09 10:24:41.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 9938 LR: 9.367322529557632e-08 Training loss: 0.0
2025-12-09 10:24:41.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 9939 LR: 9.06272382371065e-08 Training loss: 0.0
2025-12-09 10:24:41.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 9940 LR: 8.763159203883931e-08 Training loss: 0.0
2025-12-09 10:24:41.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 9941 LR: 8.468628700231129e-08 Training loss: 0.0
2025-12-09 10:24:41.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 9942 LR: 8.179132342428508e-08 Training loss: 0.0
2025-12-09 10:24:41.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 9943 LR: 7.89467015961387e-08 Training loss: 0.0
2025-12-09 10:24:41.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 9944 LR: 7.615242180436521e-08 Training loss: 0.0
2025-12-09 10:24:41.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 9945 LR: 7.340848433040614e-08 Training loss: 0.0
2025-12-09 10:24:41.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 9946 LR: 7.071488945054049e-08 Training loss: 0.0
2025-12-09 10:24:41.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 9947 LR: 6.807163743594025e-08 Training loss: 0.0
2025-12-09 10:24:41.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 9948 LR: 6.547872855289238e-08 Training loss: 0.0
2025-12-09 10:24:41.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 9949 LR: 6.293616306246586e-08 Training loss: 0.0
2025-12-09 10:24:41.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 9950 LR: 6.04439412206781e-08 Training loss: 0.0
2025-12-09 10:24:41.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 9951 LR: 5.800206327855051e-08 Training loss: 0.0
2025-12-09 10:24:41.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 9952 LR: 5.561052948188649e-08 Training loss: 0.0
2025-12-09 10:24:41.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 9953 LR: 5.3269340071548934e-08 Training loss: 0.0
2025-12-09 10:24:41.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 9954 LR: 5.0978495283349194e-08 Training loss: 0.0
2025-12-09 10:24:41.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 9955 LR: 4.873799534788059e-08 Training loss: 0.0
2025-12-09 10:24:41.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 9956 LR: 4.654784049085148e-08 Training loss: 0.0
2025-12-09 10:24:41.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 9957 LR: 4.440803093280765e-08 Training loss: 0.0
2025-12-09 10:24:41.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 9958 LR: 4.231856688913238e-08 Training loss: 0.0
2025-12-09 10:24:41.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 9959 LR: 4.027944857032395e-08 Training loss: 0.0
2025-12-09 10:24:41.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 9960 LR: 3.829067618171811e-08 Training loss: 0.0
2025-12-09 10:24:41.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 9961 LR: 3.635224992354358e-08 Training loss: 0.0
2025-12-09 10:24:41.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 9962 LR: 3.4464169991033076e-08 Training loss: 0.0
2025-12-09 10:24:41.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 9963 LR: 3.262643657425679e-08 Training loss: 0.0
2025-12-09 10:24:41.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 9964 LR: 3.0839049858344405e-08 Training loss: 0.0
2025-12-09 10:24:41.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 9965 LR: 2.910201002326307e-08 Training loss: 0.0
2025-12-09 10:24:41.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 9966 LR: 2.741531724392843e-08 Training loss: 0.0
2025-12-09 10:24:41.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 9967 LR: 2.57789716902046e-08 Training loss: 0.0
2025-12-09 10:24:41.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 9968 LR: 2.419297352684868e-08 Training loss: 0.0
2025-12-09 10:24:41.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 9969 LR: 2.265732291356626e-08 Training loss: 0.0
2025-12-09 10:24:41.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 9970 LR: 2.1172020005011393e-08 Training loss: 0.0
2025-12-09 10:24:41.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 9971 LR: 1.9737064950786642e-08 Training loss: 0.0
2025-12-09 10:24:41.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 9972 LR: 1.835245789533202e-08 Training loss: 0.0
2025-12-09 10:24:41.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 9973 LR: 1.7018198978091537e-08 Training loss: 0.0
2025-12-09 10:24:41.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 9974 LR: 1.573428833345769e-08 Training loss: 0.0
2025-12-09 10:24:41.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 9975 LR: 1.4500726090715954e-08 Training loss: 0.0
2025-12-09 10:24:41.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 9976 LR: 1.3317512374044772e-08 Training loss: 0.0
2025-12-09 10:24:41.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 9977 LR: 1.2184647302626584e-08 Training loss: 0.0
2025-12-09 10:24:41.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 9978 LR: 1.1102130990536807e-08 Training loss: 0.0
2025-12-09 10:24:41.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 9979 LR: 1.0069963546743833e-08 Training loss: 0.0
2025-12-09 10:24:41.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 9980 LR: 9.088145075275555e-09 Training loss: 0.0
2025-12-09 10:24:41.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 9981 LR: 8.156675674941826e-09 Training loss: 0.0
2025-12-09 10:24:41.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 9982 LR: 7.27555543950098e-09 Training loss: 0.0
2025-12-09 10:24:41.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 9983 LR: 6.444784457770858e-09 Training loss: 0.0
2025-12-09 10:24:41.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 9984 LR: 5.664362813406765e-09 Training loss: 0.0
2025-12-09 10:24:41.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 9985 LR: 4.934290584901469e-09 Training loss: 0.0
2025-12-09 10:24:41.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 9986 LR: 4.2545678458627555e-09 Training loss: 0.0
2025-12-09 10:24:41.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 9987 LR: 3.625194664735876e-09 Training loss: 0.0
2025-12-09 10:24:41.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 9988 LR: 3.046171104803541e-09 Training loss: 0.0
2025-12-09 10:24:41.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 9989 LR: 2.517497224463483e-09 Training loss: 0.0
2025-12-09 10:24:41.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 9990 LR: 2.0391730769508954e-09 Training loss: 0.0
2025-12-09 10:24:41.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 9991 LR: 1.6111987103939462e-09 Training loss: 0.0
2025-12-09 10:24:41.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 9992 LR: 1.2335741679248002e-09 Training loss: 0.0
2025-12-09 10:24:41.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 9993 LR: 9.062994875685959e-10 Training loss: 0.0
2025-12-09 10:24:41.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 9994 LR: 6.29374702243446e-10 Training loss: 0.0
2025-12-09 10:24:41.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 9995 LR: 4.027998398714594e-10 Training loss: 0.0
2025-12-09 10:24:41.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 9996 LR: 2.265749232122083e-10 Training loss: 0.0
2025-12-09 10:24:41.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 9997 LR: 1.0069997008477216e-10 Training loss: 0.0
2025-12-09 10:24:41.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 9998 LR: 2.517499314569349e-11 Training loss: 0.0
2025-12-09 10:24:41.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 9999 LR: 0.0 Training loss: 0.0
