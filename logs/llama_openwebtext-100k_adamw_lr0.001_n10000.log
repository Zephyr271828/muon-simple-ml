2025-12-09 11:57:45.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.163034439086914
2025-12-09 11:57:45.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.192876815795898
2025-12-09 11:57:46.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.115283012390137
2025-12-09 11:57:46.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 12.006651878356934
2025-12-09 11:57:46.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 11.896477699279785
2025-12-09 11:57:47.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 11.848509788513184
2025-12-09 11:57:47.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 11.625916481018066
2025-12-09 11:57:48.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 10.940481185913086
2025-12-09 11:57:48.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 10.654305458068848
2025-12-09 11:57:48.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 10.120201110839844
2025-12-09 11:57:49.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 10.105287551879883
2025-12-09 11:57:49.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 10.0431489944458
2025-12-09 11:57:50.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 9.925274848937988
2025-12-09 11:57:50.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 9.616560935974121
2025-12-09 11:57:50.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 9.630809783935547
2025-12-09 11:57:51.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 9.524812698364258
2025-12-09 11:57:51.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 9.505146980285645
2025-12-09 11:57:51.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 9.479969024658203
2025-12-09 11:57:52.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 9.4948091506958
2025-12-09 11:57:52.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 9.019283294677734
2025-12-09 11:57:53.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 8.642292976379395
2025-12-09 11:57:53.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 8.313167572021484
2025-12-09 11:57:53.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 8.410198211669922
2025-12-09 11:57:54.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 9.24057674407959
2025-12-09 11:57:54.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 8.439962387084961
2025-12-09 11:57:55.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 8.341361045837402
2025-12-09 11:57:55.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 8.373710632324219
2025-12-09 11:57:55.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 8.285319328308105
2025-12-09 11:57:56.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 8.289020538330078
2025-12-09 11:57:56.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 8.648266792297363
2025-12-09 11:57:56.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 8.23114013671875
2025-12-09 11:57:57.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 8.380739212036133
2025-12-09 11:57:57.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 8.346726417541504
2025-12-09 11:57:58.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 8.669692039489746
2025-12-09 11:57:58.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 8.451268196105957
2025-12-09 11:57:58.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 8.5569429397583
2025-12-09 11:57:59.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 9.469520568847656
2025-12-09 11:57:59.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 8.565106391906738
2025-12-09 11:58:00.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 9.349461555480957
2025-12-09 11:58:00.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 9.467888832092285
2025-12-09 11:58:00.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 8.263838768005371
2025-12-09 11:58:01.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 8.597699165344238
2025-12-09 11:58:01.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 8.544163703918457
2025-12-09 11:58:01.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 8.28820514678955
2025-12-09 11:58:02.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 8.36696720123291
2025-12-09 11:58:02.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 8.537219047546387
2025-12-09 11:58:03.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 8.30577564239502
2025-12-09 11:58:03.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 8.20102310180664
2025-12-09 11:58:03.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 8.299720764160156
2025-12-09 11:58:04.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 8.156744956970215
2025-12-09 11:58:04.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 8.90001392364502
2025-12-09 11:58:05.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 8.046710014343262
2025-12-09 11:58:05.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 8.279866218566895
2025-12-09 11:58:05.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 8.356385231018066
2025-12-09 11:58:06.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 8.702637672424316
2025-12-09 11:58:06.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 8.164571762084961
2025-12-09 11:58:06.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 8.10025405883789
2025-12-09 11:58:07.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 8.21685791015625
2025-12-09 11:58:07.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 8.049637794494629
2025-12-09 11:58:08.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 8.016632080078125
2025-12-09 11:58:08.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 8.2543363571167
2025-12-09 11:58:08.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 8.327221870422363
2025-12-09 11:58:09.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 8.154609680175781
2025-12-09 11:58:09.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 8.338589668273926
2025-12-09 11:58:10.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 8.063992500305176
2025-12-09 11:58:10.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 8.108779907226562
2025-12-09 11:58:10.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 8.495901107788086
2025-12-09 11:58:11.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 8.354949951171875
2025-12-09 11:58:11.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 8.161706924438477
2025-12-09 11:58:11.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 8.251791954040527
2025-12-09 11:58:12.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 8.161210060119629
2025-12-09 11:58:12.734 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 8.312765121459961
2025-12-09 11:58:13.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 8.131490707397461
2025-12-09 11:58:13.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 8.185748100280762
2025-12-09 11:58:13.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 8.133986473083496
2025-12-09 11:58:14.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 8.101377487182617
2025-12-09 11:58:14.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 8.3768949508667
2025-12-09 11:58:15.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 8.370002746582031
2025-12-09 11:58:15.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 7.904540061950684
2025-12-09 11:58:15.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 7.847740173339844
2025-12-09 11:58:16.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 8.1318359375
2025-12-09 11:58:16.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 7.850449562072754
2025-12-09 11:58:16.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 8.310515403747559
2025-12-09 11:58:17.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 8.275249481201172
2025-12-09 11:58:17.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 8.10615062713623
2025-12-09 11:58:18.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 8.242816925048828
2025-12-09 11:58:18.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 8.471940040588379
2025-12-09 11:58:18.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 8.261445999145508
2025-12-09 11:58:19.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 8.055402755737305
2025-12-09 11:58:19.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 7.751707077026367
2025-12-09 11:58:20.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 8.502073287963867
2025-12-09 11:58:20.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 7.941368103027344
2025-12-09 11:58:20.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 8.875041961669922
2025-12-09 11:58:21.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 7.858638763427734
2025-12-09 11:58:21.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 8.494112014770508
2025-12-09 11:58:21.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 8.347163200378418
2025-12-09 11:58:22.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 8.320319175720215
2025-12-09 11:58:22.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 7.937711238861084
2025-12-09 11:58:23.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 8.316486358642578
2025-12-09 11:58:23.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 7.849207401275635
2025-12-09 11:58:23.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0009999999029798809 Training loss: 7.753601551055908
2025-12-09 11:58:24.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.000999999611919561 Training loss: 8.444405555725098
2025-12-09 11:58:24.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0009999991268191536 Training loss: 8.232436180114746
2025-12-09 11:58:25.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0009999984476788465 Training loss: 8.237497329711914
2025-12-09 11:58:25.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0009999975744989036 Training loss: 7.78886079788208
2025-12-09 11:58:25.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0009999965072796635 Training loss: 8.559237480163574
2025-12-09 11:58:26.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0009999952460215409 Training loss: 7.953524112701416
2025-12-09 11:58:26.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0009999937907250245 Training loss: 8.032050132751465
2025-12-09 11:58:27.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0009999921413906799 Training loss: 7.724843502044678
2025-12-09 11:58:27.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.0009999902980191463 Training loss: 8.04150104522705
2025-12-09 11:58:27.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.00099998826061114 Training loss: 8.024497985839844
2025-12-09 11:58:28.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0009999860291674508 Training loss: 7.766926288604736
2025-12-09 11:58:28.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0009999836036889453 Training loss: 7.75118350982666
2025-12-09 11:58:28.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0009999809841765644 Training loss: 7.9802632331848145
2025-12-09 11:58:29.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.000999978170631325 Training loss: 7.821259021759033
2025-12-09 11:58:29.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0009999751630543187 Training loss: 8.05175495147705
2025-12-09 11:58:30.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.000999971961446713 Training loss: 7.599653720855713
2025-12-09 11:58:30.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.0009999685658097501 Training loss: 7.7950334548950195
2025-12-09 11:58:30.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0009999649761447478 Training loss: 7.887042045593262
2025-12-09 11:58:31.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.0009999611924530994 Training loss: 7.714775562286377
2025-12-09 11:58:31.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.000999957214736273 Training loss: 8.02319049835205
2025-12-09 11:58:32.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.0009999530429958125 Training loss: 7.516730785369873
2025-12-09 11:58:32.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.0009999486772333365 Training loss: 7.27385950088501
2025-12-09 11:58:32.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.00099994411745054 Training loss: 7.796440601348877
2025-12-09 11:58:33.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0009999393636491917 Training loss: 7.917876720428467
2025-12-09 11:58:33.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.000999934415831137 Training loss: 8.071786880493164
2025-12-09 11:58:33.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.000999929273998296 Training loss: 7.588228225708008
2025-12-09 11:58:34.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.0009999239381526638 Training loss: 7.84539270401001
2025-12-09 11:58:34.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0009999184082963117 Training loss: 7.82369327545166
2025-12-09 11:58:35.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.0009999126844313852 Training loss: 7.635559558868408
2025-12-09 11:58:35.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.000999906766560106 Training loss: 7.905280590057373
2025-12-09 11:58:35.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.0009999006546847706 Training loss: 7.9369401931762695
2025-12-09 11:58:36.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0009998943488077508 Training loss: 7.861617565155029
2025-12-09 11:58:36.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.0009998878489314938 Training loss: 7.7497992515563965
2025-12-09 11:58:37.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.000999881155058522 Training loss: 7.809140682220459
2025-12-09 11:58:37.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0009998742671914335 Training loss: 8.016775131225586
2025-12-09 11:58:37.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.000999867185332901 Training loss: 7.390947341918945
2025-12-09 11:58:38.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.000999859909485673 Training loss: 7.819207668304443
2025-12-09 11:58:38.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.000999852439652573 Training loss: 7.26800537109375
2025-12-09 11:58:39.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0009998447758365 Training loss: 9.05301570892334
2025-12-09 11:58:39.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0009998369180404282 Training loss: 7.5699896812438965
2025-12-09 11:58:39.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.000999828866267407 Training loss: 7.682825565338135
2025-12-09 11:58:40.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0009998206205205612 Training loss: 8.364670753479004
2025-12-09 11:58:40.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.0009998121808030905 Training loss: 7.608509540557861
2025-12-09 11:58:40.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0009998035471182707 Training loss: 8.624787330627441
2025-12-09 11:58:41.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.000999794719469452 Training loss: 7.566892623901367
2025-12-09 11:58:41.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0009997856978600603 Training loss: 7.4581990242004395
2025-12-09 11:58:42.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0009997764822935967 Training loss: 7.883506774902344
2025-12-09 11:58:42.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.000999767072773638 Training loss: 7.897951126098633
2025-12-09 11:58:42.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0009997574693038351 Training loss: 7.483532428741455
2025-12-09 11:58:43.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0009997476718879154 Training loss: 7.793302536010742
2025-12-09 11:58:43.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.000999737680529681 Training loss: 7.882689476013184
2025-12-09 11:58:44.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0009997274952330093 Training loss: 8.05925178527832
2025-12-09 11:58:44.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.000999717116001853 Training loss: 7.769495487213135
2025-12-09 11:58:44.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.0009997065428402404 Training loss: 8.038328170776367
2025-12-09 11:58:45.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0009996957757522741 Training loss: 7.924686908721924
2025-12-09 11:58:45.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.0009996848147421334 Training loss: 8.05998420715332
2025-12-09 11:58:45.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0009996736598140714 Training loss: 8.372714042663574
2025-12-09 11:58:46.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.0009996623109724174 Training loss: 7.215878963470459
2025-12-09 11:58:46.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0009996507682215755 Training loss: 7.742047309875488
2025-12-09 11:58:47.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.0009996390315660253 Training loss: 7.463719844818115
2025-12-09 11:58:47.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.0009996271010103215 Training loss: 7.225977420806885
2025-12-09 11:58:47.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.0009996149765590945 Training loss: 7.520662307739258
2025-12-09 11:58:48.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.000999602658217049 Training loss: 7.788507461547852
2025-12-09 11:58:48.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0009995901459889658 Training loss: 7.923064231872559
2025-12-09 11:58:49.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.0009995774398797008 Training loss: 7.398204803466797
2025-12-09 11:58:49.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.0009995645398941846 Training loss: 7.521371841430664
2025-12-09 11:58:49.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0009995514460374238 Training loss: 7.733614921569824
2025-12-09 11:58:50.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.0009995381583144996 Training loss: 7.3826584815979
2025-12-09 11:58:50.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.0009995246767305688 Training loss: 7.6645331382751465
2025-12-09 11:58:51.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0009995110012908633 Training loss: 7.416742324829102
2025-12-09 11:58:51.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.0009994971320006906 Training loss: 7.5225934982299805
2025-12-09 11:58:51.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0009994830688654327 Training loss: 7.380815029144287
2025-12-09 11:58:52.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.000999468811890547 Training loss: 8.220470428466797
2025-12-09 11:58:52.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.000999454361081567 Training loss: 8.058857917785645
2025-12-09 11:58:52.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.0009994397164441006 Training loss: 7.23861026763916
2025-12-09 11:58:53.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.000999424877983831 Training loss: 7.4743971824646
2025-12-09 11:58:53.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0009994098457065167 Training loss: 9.13571834564209
2025-12-09 11:58:54.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.0009993946196179913 Training loss: 7.412985801696777
2025-12-09 11:58:54.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.000999379199724164 Training loss: 7.318389892578125
2025-12-09 11:58:54.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0009993635860310187 Training loss: 7.8754353523254395
2025-12-09 11:58:55.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.000999347778544615 Training loss: 7.420847415924072
2025-12-09 11:58:55.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.0009993317772710873 Training loss: 7.981661319732666
2025-12-09 11:58:56.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.0009993155822166457 Training loss: 7.364670276641846
2025-12-09 11:58:56.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.0009992991933875748 Training loss: 7.386404037475586
2025-12-09 11:58:56.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0009992826107902348 Training loss: 7.53912878036499
2025-12-09 11:58:57.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.0009992658344310614 Training loss: 7.806736469268799
2025-12-09 11:58:57.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.000999248864316565 Training loss: 7.477468013763428
2025-12-09 11:58:57.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0009992317004533314 Training loss: 7.438858509063721
2025-12-09 11:58:58.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.0009992143428480215 Training loss: 7.536301612854004
2025-12-09 11:58:58.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0009991967915073715 Training loss: 7.82763147354126
2025-12-09 11:58:59.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0009991790464381925 Training loss: 7.181128978729248
2025-12-09 11:58:59.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.0009991611076473714 Training loss: 7.682668209075928
2025-12-09 11:58:59.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.0009991429751418698 Training loss: 7.601749420166016
2025-12-09 11:59:00.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.0009991246489287244 Training loss: 7.780276298522949
2025-12-09 11:59:00.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0009991061290150474 Training loss: 7.524214267730713
2025-12-09 11:59:01.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0009990874154080258 Training loss: 7.517573833465576
2025-12-09 11:59:01.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.0009990685081149222 Training loss: 7.239368438720703
2025-12-09 11:59:01.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0009990494071430741 Training loss: 7.946127414703369
2025-12-09 11:59:02.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0009990301124998943 Training loss: 7.380575180053711
2025-12-09 11:59:02.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0009990106241928704 Training loss: 7.094995498657227
2025-12-09 11:59:03.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0009989909422295658 Training loss: 7.573654651641846
2025-12-09 11:59:03.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0009989710666176185 Training loss: 7.790853500366211
2025-12-09 11:59:03.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0009989509973647418 Training loss: 7.1911211013793945
2025-12-09 11:59:04.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0009989307344787242 Training loss: 7.020416736602783
2025-12-09 11:59:04.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0009989102779674292 Training loss: 7.548094272613525
2025-12-09 11:59:04.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.000998889627838796 Training loss: 7.545131206512451
2025-12-09 11:59:05.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.000998868784100838 Training loss: 8.026115417480469
2025-12-09 11:59:05.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.0009988477467616447 Training loss: 7.722711086273193
2025-12-09 11:59:06.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0009988265158293798 Training loss: 7.825374126434326
2025-12-09 11:59:06.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.000998805091312283 Training loss: 7.288910865783691
2025-12-09 11:59:06.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.0009987834732186687 Training loss: 7.170194149017334
2025-12-09 11:59:07.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0009987616615569263 Training loss: 7.62982177734375
2025-12-09 11:59:07.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.0009987396563355204 Training loss: 7.361668109893799
2025-12-09 11:59:08.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.000998717457562991 Training loss: 7.611928939819336
2025-12-09 11:59:08.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.0009986950652479533 Training loss: 7.295044422149658
2025-12-09 11:59:08.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0009986724793990967 Training loss: 7.363790512084961
2025-12-09 11:59:09.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.0009986497000251866 Training loss: 7.04460334777832
2025-12-09 11:59:09.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.0009986267271350634 Training loss: 7.254483222961426
2025-12-09 11:59:10.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0009986035607376421 Training loss: 7.720302581787109
2025-12-09 11:59:10.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.0009985802008419132 Training loss: 7.4596381187438965
2025-12-09 11:59:10.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0009985566474569425 Training loss: 7.347620487213135
2025-12-09 11:59:11.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0009985329005918703 Training loss: 7.676898002624512
2025-12-09 11:59:11.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0009985089602559125 Training loss: 7.891622066497803
2025-12-09 11:59:11.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0009984848264583597 Training loss: 7.235136032104492
2025-12-09 11:59:12.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.000998460499208578 Training loss: 7.283065319061279
2025-12-09 11:59:12.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.000998435978516008 Training loss: 7.417981147766113
2025-12-09 11:59:13.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.0009984112643901658 Training loss: 7.706059455871582
2025-12-09 11:59:13.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0009983863568406427 Training loss: 7.255741119384766
2025-12-09 11:59:13.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0009983612558771048 Training loss: 6.638543128967285
2025-12-09 11:59:14.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0009983359615092931 Training loss: 7.247200965881348
2025-12-09 11:59:14.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.000998310473747024 Training loss: 7.739259243011475
2025-12-09 11:59:15.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0009982847926001885 Training loss: 7.439174175262451
2025-12-09 11:59:15.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0009982589180787533 Training loss: 6.943292140960693
2025-12-09 11:59:15.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.0009982328501927599 Training loss: 7.6303253173828125
2025-12-09 11:59:16.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0009982065889523242 Training loss: 7.287990093231201
2025-12-09 11:59:16.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.000998180134367638 Training loss: 7.565235614776611
2025-12-09 11:59:16.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0009981534864489678 Training loss: 7.509146213531494
2025-12-09 11:59:17.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.0009981266452066553 Training loss: 7.788050651550293
2025-12-09 11:59:17.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0009980996106511168 Training loss: 7.547353267669678
2025-12-09 11:59:18.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.000998072382792844 Training loss: 7.3979034423828125
2025-12-09 11:59:18.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.0009980449616424037 Training loss: 7.114386081695557
2025-12-09 11:59:18.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.000998017347210437 Training loss: 7.291896820068359
2025-12-09 11:59:19.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.000997989539507661 Training loss: 7.138538837432861
2025-12-09 11:59:19.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.000997961538544867 Training loss: 8.311306953430176
2025-12-09 11:59:20.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0009979333443329217 Training loss: 7.507253170013428
2025-12-09 11:59:20.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.000997904956882767 Training loss: 7.302073001861572
2025-12-09 11:59:20.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0009978763762054192 Training loss: 7.215590000152588
2025-12-09 11:59:21.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.00099784760231197 Training loss: 7.553249359130859
2025-12-09 11:59:21.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.000997818635213586 Training loss: 7.653748512268066
2025-12-09 11:59:22.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0009977894749215088 Training loss: 7.066263198852539
2025-12-09 11:59:22.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.000997760121447055 Training loss: 7.475822925567627
2025-12-09 11:59:22.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0009977305748016159 Training loss: 7.294275760650635
2025-12-09 11:59:23.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.000997700834996658 Training loss: 7.7484002113342285
2025-12-09 11:59:23.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.000997670902043723 Training loss: 7.082922458648682
2025-12-09 11:59:23.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.000997640775954427 Training loss: 7.153512954711914
2025-12-09 11:59:24.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.0009976104567404615 Training loss: 7.431005954742432
2025-12-09 11:59:24.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0009975799444135929 Training loss: 6.960775852203369
2025-12-09 11:59:25.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.0009975492389856621 Training loss: 7.041862487792969
2025-12-09 11:59:25.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.0009975183404685856 Training loss: 7.192813396453857
2025-12-09 11:59:25.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0009974872488743543 Training loss: 7.382180690765381
2025-12-09 11:59:26.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0009974559642150344 Training loss: 7.2810211181640625
2025-12-09 11:59:26.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.000997424486502767 Training loss: 7.699681282043457
2025-12-09 11:59:27.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0009973928157497674 Training loss: 7.002138614654541
2025-12-09 11:59:27.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.000997360951968327 Training loss: 7.654074192047119
2025-12-09 11:59:27.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.0009973288951708112 Training loss: 7.332629203796387
2025-12-09 11:59:28.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0009972966453696609 Training loss: 7.802114486694336
2025-12-09 11:59:28.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.0009972642025773912 Training loss: 7.3677239418029785
2025-12-09 11:59:29.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.0009972315668065929 Training loss: 7.3008928298950195
2025-12-09 11:59:29.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.000997198738069931 Training loss: 7.337677955627441
2025-12-09 11:59:29.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.000997165716380146 Training loss: 7.52299690246582
2025-12-09 11:59:30.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0009971325017500525 Training loss: 7.15311861038208
2025-12-09 11:59:30.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.0009970990941925411 Training loss: 6.942046165466309
2025-12-09 11:59:30.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.0009970654937205762 Training loss: 7.427358150482178
2025-12-09 11:59:31.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0009970317003471976 Training loss: 7.423610210418701
2025-12-09 11:59:31.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.0009969977140855198 Training loss: 7.419850826263428
2025-12-09 11:59:32.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0009969635349487322 Training loss: 7.275195598602295
2025-12-09 11:59:32.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.000996929162950099 Training loss: 7.1010236740112305
2025-12-09 11:59:32.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0009968945981029596 Training loss: 7.342330455780029
2025-12-09 11:59:33.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0009968598404207275 Training loss: 7.4640631675720215
2025-12-09 11:59:33.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0009968248899168918 Training loss: 7.682768821716309
2025-12-09 11:59:34.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.000996789746605016 Training loss: 8.277417182922363
2025-12-09 11:59:34.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0009967544104987386 Training loss: 7.126711368560791
2025-12-09 11:59:34.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0009967188816117727 Training loss: 7.016894817352295
2025-12-09 11:59:35.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0009966831599579067 Training loss: 7.3811564445495605
2025-12-09 11:59:35.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.000996647245551003 Training loss: 7.549909591674805
2025-12-09 11:59:36.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0009966111384049996 Training loss: 7.5264434814453125
2025-12-09 11:59:36.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0009965748385339088 Training loss: 7.177248954772949
2025-12-09 11:59:36.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0009965383459518181 Training loss: 6.799937725067139
2025-12-09 11:59:37.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0009965016606728893 Training loss: 7.231451511383057
2025-12-09 11:59:37.547 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0009964647827113596 Training loss: 7.112030506134033
2025-12-09 11:59:37.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.0009964277120815403 Training loss: 7.670905590057373
2025-12-09 11:59:38.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.0009963904487978177 Training loss: 7.452422618865967
2025-12-09 11:59:38.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0009963529928746534 Training loss: 8.010001182556152
2025-12-09 11:59:39.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0009963153443265829 Training loss: 6.833184242248535
2025-12-09 11:59:39.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.0009962775031682168 Training loss: 7.185210704803467
2025-12-09 11:59:39.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.0009962394694142409 Training loss: 7.383999824523926
2025-12-09 11:59:40.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.0009962012430794153 Training loss: 7.348850250244141
2025-12-09 11:59:40.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.0009961628241785747 Training loss: 7.350939750671387
2025-12-09 11:59:41.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0009961242127266288 Training loss: 7.746349811553955
2025-12-09 11:59:41.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0009960854087385617 Training loss: 7.540901184082031
2025-12-09 11:59:41.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.000996046412229433 Training loss: 7.237720489501953
2025-12-09 11:59:42.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0009960072232143762 Training loss: 7.315936088562012
2025-12-09 11:59:42.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.0009959678417085997 Training loss: 7.554211616516113
2025-12-09 11:59:42.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0009959282677273868 Training loss: 6.745067119598389
2025-12-09 11:59:43.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0009958885012860954 Training loss: 9.16088581085205
2025-12-09 11:59:43.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.0009958485424001581 Training loss: 7.062124252319336
2025-12-09 11:59:44.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0009958083910850822 Training loss: 7.218323230743408
2025-12-09 11:59:44.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0009957680473564494 Training loss: 6.831634998321533
2025-12-09 11:59:44.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.0009957275112299165 Training loss: 7.180285930633545
2025-12-09 11:59:45.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0009956867827212148 Training loss: 7.314449310302734
2025-12-09 11:59:45.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.00099564586184615 Training loss: 7.625958442687988
2025-12-09 11:59:46.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0009956047486206032 Training loss: 7.350064277648926
2025-12-09 11:59:46.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0009955634430605291 Training loss: 7.018315315246582
2025-12-09 11:59:46.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.000995521945181958 Training loss: 7.666355609893799
2025-12-09 11:59:47.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0009954802550009943 Training loss: 7.419686794281006
2025-12-09 11:59:47.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.0009954383725338167 Training loss: 7.380845069885254
2025-12-09 11:59:48.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.0009953962977966794 Training loss: 7.10598611831665
2025-12-09 11:59:48.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.000995354030805911 Training loss: 7.823146820068359
2025-12-09 11:59:48.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0009953115715779141 Training loss: 7.237271785736084
2025-12-09 11:59:49.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.0009952689201291663 Training loss: 7.436704158782959
2025-12-09 11:59:49.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.00099522607647622 Training loss: 7.380693435668945
2025-12-09 11:59:49.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.0009951830406357018 Training loss: 6.993168830871582
2025-12-09 11:59:50.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.0009951398126243135 Training loss: 7.320809364318848
2025-12-09 11:59:50.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.0009950963924588304 Training loss: 6.998902797698975
2025-12-09 11:59:51.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.0009950527801561033 Training loss: 7.027320384979248
2025-12-09 11:59:51.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0009950089757330574 Training loss: 7.433650970458984
2025-12-09 11:59:51.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0009949649792066922 Training loss: 7.151974201202393
2025-12-09 11:59:52.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.000994920790594082 Training loss: 7.655622482299805
2025-12-09 11:59:52.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.0009948764099123755 Training loss: 8.255760192871094
2025-12-09 11:59:53.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.000994831837178796 Training loss: 7.303532123565674
2025-12-09 11:59:53.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.000994787072410641 Training loss: 7.289849281311035
2025-12-09 11:59:53.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0009947421156252835 Training loss: 6.972695350646973
2025-12-09 11:59:54.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.0009946969668401698 Training loss: 7.394505023956299
2025-12-09 11:59:54.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.0009946516260728212 Training loss: 7.32027006149292
2025-12-09 11:59:55.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.000994606093340834 Training loss: 7.156782150268555
2025-12-09 11:59:55.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.0009945603686618784 Training loss: 7.21410608291626
2025-12-09 11:59:55.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.000994514452053699 Training loss: 7.798482418060303
2025-12-09 11:59:56.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.0009944683435341155 Training loss: 6.861510753631592
2025-12-09 11:59:56.556 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.0009944220431210215 Training loss: 7.836240768432617
2025-12-09 11:59:56.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.0009943755508323854 Training loss: 7.229801177978516
2025-12-09 11:59:57.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.0009943288666862497 Training loss: 7.560859203338623
2025-12-09 11:59:57.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.000994281990700732 Training loss: 7.680565357208252
2025-12-09 11:59:58.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.0009942349228940237 Training loss: 7.067097187042236
2025-12-09 11:59:58.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.0009941876632843908 Training loss: 7.155828475952148
2025-12-09 11:59:58.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.0009941402118901744 Training loss: 7.082911968231201
2025-12-09 11:59:59.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0009940925687297885 Training loss: 7.640539169311523
2025-12-09 11:59:59.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0009940447338217234 Training loss: 6.95618200302124
2025-12-09 12:00:00.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0009939967071845423 Training loss: 7.002398490905762
2025-12-09 12:00:00.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.0009939484888368837 Training loss: 7.048412322998047
2025-12-09 12:00:00.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.0009939000787974601 Training loss: 6.910360813140869
2025-12-09 12:00:01.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.0009938514770850585 Training loss: 7.272913932800293
2025-12-09 12:00:01.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.0009938026837185403 Training loss: 7.191866397857666
2025-12-09 12:00:01.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.0009937536987168413 Training loss: 7.0006256103515625
2025-12-09 12:00:02.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0009937045220989715 Training loss: 7.324591636657715
2025-12-09 12:00:02.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0009936551538840153 Training loss: 6.961051940917969
2025-12-09 12:00:03.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.000993605594091132 Training loss: 6.8459978103637695
2025-12-09 12:00:03.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.000993555842739554 Training loss: 7.205642223358154
2025-12-09 12:00:03.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0009935058998485897 Training loss: 7.320609092712402
2025-12-09 12:00:04.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.0009934557654376205 Training loss: 7.515509128570557
2025-12-09 12:00:04.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.0009934054395261025 Training loss: 7.694757461547852
2025-12-09 12:00:05.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.0009933549221335664 Training loss: 7.244123458862305
2025-12-09 12:00:05.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.000993304213279617 Training loss: 7.22634744644165
2025-12-09 12:00:05.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0009932533129839334 Training loss: 7.409102916717529
2025-12-09 12:00:06.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.000993202221266269 Training loss: 6.894642353057861
2025-12-09 12:00:06.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.0009931509381464515 Training loss: 7.4337592124938965
2025-12-09 12:00:07.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.0009930994636443828 Training loss: 7.00593900680542
2025-12-09 12:00:07.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.0009930477977800392 Training loss: 6.900500297546387
2025-12-09 12:00:07.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.000992995940573471 Training loss: 7.10638427734375
2025-12-09 12:00:08.207 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.0009929438920448037 Training loss: 7.113773345947266
2025-12-09 12:00:08.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.0009928916522142356 Training loss: 6.996668815612793
2025-12-09 12:00:08.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.00099283922110204 Training loss: 6.936768531799316
2025-12-09 12:00:09.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.0009927865987285648 Training loss: 7.068575382232666
2025-12-09 12:00:09.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.0009927337851142314 Training loss: 7.274648666381836
2025-12-09 12:00:10.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.000992680780279536 Training loss: 7.096066474914551
2025-12-09 12:00:10.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.0009926275842450482 Training loss: 7.098959922790527
2025-12-09 12:00:10.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.0009925741970314129 Training loss: 7.039676666259766
2025-12-09 12:00:11.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.0009925206186593484 Training loss: 7.350255012512207
2025-12-09 12:00:11.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.0009924668491496473 Training loss: 7.162681579589844
2025-12-09 12:00:12.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.000992412888523177 Training loss: 7.813267230987549
2025-12-09 12:00:12.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.000992358736800878 Training loss: 7.218216896057129
2025-12-09 12:00:12.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.0009923043940037657 Training loss: 6.977889537811279
2025-12-09 12:00:13.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.0009922498601529295 Training loss: 6.923476696014404
2025-12-09 12:00:13.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.000992195135269533 Training loss: 6.98903226852417
2025-12-09 12:00:14.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0009921402193748137 Training loss: 6.633384704589844
2025-12-09 12:00:14.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.0009920851124900836 Training loss: 7.040977954864502
2025-12-09 12:00:14.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.0009920298146367287 Training loss: 7.090988636016846
2025-12-09 12:00:15.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.0009919743258362086 Training loss: 7.515102863311768
2025-12-09 12:00:15.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0009919186461100577 Training loss: 6.893669605255127
2025-12-09 12:00:15.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.000991862775479884 Training loss: 7.4726080894470215
2025-12-09 12:00:16.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.00099180671396737 Training loss: 6.749088287353516
2025-12-09 12:00:16.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.0009917504615942721 Training loss: 7.269937992095947
2025-12-09 12:00:17.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.0009916940183824206 Training loss: 7.365699768066406
2025-12-09 12:00:17.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.0009916373843537201 Training loss: 7.038516044616699
2025-12-09 12:00:17.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.0009915805595301491 Training loss: 7.183223247528076
2025-12-09 12:00:18.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.0009915235439337602 Training loss: 7.7750396728515625
2025-12-09 12:00:18.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.0009914663375866803 Training loss: 7.272334098815918
2025-12-09 12:00:19.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.0009914089405111098 Training loss: 7.291191101074219
2025-12-09 12:00:19.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.0009913513527293235 Training loss: 7.472557067871094
2025-12-09 12:00:19.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0009912935742636697 Training loss: 7.436251640319824
2025-12-09 12:00:20.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.0009912356051365717 Training loss: 6.88408899307251
2025-12-09 12:00:20.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.0009911774453705258 Training loss: 7.3224945068359375
2025-12-09 12:00:21.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.0009911190949881028 Training loss: 6.550334930419922
2025-12-09 12:00:21.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.0009910605540119474 Training loss: 7.256500244140625
2025-12-09 12:00:21.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.0009910018224647782 Training loss: 6.791090965270996
2025-12-09 12:00:22.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.0009909429003693876 Training loss: 7.1515960693359375
2025-12-09 12:00:22.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.0009908837877486423 Training loss: 7.38965368270874
2025-12-09 12:00:22.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.0009908244846254825 Training loss: 6.869956016540527
2025-12-09 12:00:23.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.000990764991022923 Training loss: 6.8617095947265625
2025-12-09 12:00:23.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.0009907053069640515 Training loss: 7.148702144622803
2025-12-09 12:00:24.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.000990645432472031 Training loss: 6.970191478729248
2025-12-09 12:00:24.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.000990585367570097 Training loss: 7.064856052398682
2025-12-09 12:00:24.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.0009905251122815596 Training loss: 7.4463419914245605
2025-12-09 12:00:25.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.000990464666629803 Training loss: 7.1266303062438965
2025-12-09 12:00:25.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.0009904040306382847 Training loss: 7.483878135681152
2025-12-09 12:00:26.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0009903432043305365 Training loss: 7.075639724731445
2025-12-09 12:00:26.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.0009902821877301638 Training loss: 7.363073825836182
2025-12-09 12:00:26.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.000990220980860846 Training loss: 7.344825744628906
2025-12-09 12:00:27.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.0009901595837463362 Training loss: 7.2913594245910645
2025-12-09 12:00:27.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.0009900979964104616 Training loss: 6.97576379776001
2025-12-09 12:00:27.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.000990036218877123 Training loss: 7.092408657073975
2025-12-09 12:00:28.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.000989974251170295 Training loss: 6.814452648162842
2025-12-09 12:00:28.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.000989912093314026 Training loss: 7.228304386138916
2025-12-09 12:00:29.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.0009898497453324385 Training loss: 7.372936248779297
2025-12-09 12:00:29.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.000989787207249728 Training loss: 7.430624008178711
2025-12-09 12:00:29.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.0009897244790901649 Training loss: 6.971487998962402
2025-12-09 12:00:30.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.0009896615608780924 Training loss: 7.721053123474121
2025-12-09 12:00:30.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.000989598452637928 Training loss: 7.277741432189941
2025-12-09 12:00:31.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.0009895351543941628 Training loss: 7.0581536293029785
2025-12-09 12:00:31.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0009894716661713616 Training loss: 6.651464939117432
2025-12-09 12:00:31.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0009894079879941627 Training loss: 7.964301109313965
2025-12-09 12:00:32.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.0009893441198872788 Training loss: 6.87536096572876
2025-12-09 12:00:32.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.0009892800618754953 Training loss: 7.185734748840332
2025-12-09 12:00:33.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.0009892158139836725 Training loss: 7.20966100692749
2025-12-09 12:00:33.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0009891513762367431 Training loss: 7.4270501136779785
2025-12-09 12:00:33.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.0009890867486597146 Training loss: 7.040834426879883
2025-12-09 12:00:34.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.0009890219312776677 Training loss: 7.737486839294434
2025-12-09 12:00:34.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.0009889569241157564 Training loss: 6.838325023651123
2025-12-09 12:00:34.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.000988891727199209 Training loss: 6.997594356536865
2025-12-09 12:00:35.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.000988826340553327 Training loss: 6.187948226928711
2025-12-09 12:00:35.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.0009887607642034859 Training loss: 7.795039176940918
2025-12-09 12:00:36.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.0009886949981751346 Training loss: 6.588823318481445
2025-12-09 12:00:36.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.0009886290424937951 Training loss: 7.040180206298828
2025-12-09 12:00:36.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0009885628971850642 Training loss: 6.942149639129639
2025-12-09 12:00:37.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.0009884965622746112 Training loss: 7.128566741943359
2025-12-09 12:00:37.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.0009884300377881795 Training loss: 7.176023006439209
2025-12-09 12:00:38.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.0009883633237515858 Training loss: 6.969916820526123
2025-12-09 12:00:38.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.0009882964201907208 Training loss: 7.137135028839111
2025-12-09 12:00:38.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0009882293271315482 Training loss: 6.9552154541015625
2025-12-09 12:00:39.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.0009881620446001056 Training loss: 7.525629997253418
2025-12-09 12:00:39.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.000988094572622504 Training loss: 7.420582294464111
2025-12-09 12:00:40.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.0009880269112249281 Training loss: 7.744894504547119
2025-12-09 12:00:40.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.000987959060433636 Training loss: 6.758722305297852
2025-12-09 12:00:40.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.0009878910202749589 Training loss: 7.098827362060547
2025-12-09 12:00:41.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.0009878227907753022 Training loss: 6.900410175323486
2025-12-09 12:00:41.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.0009877543719611444 Training loss: 6.896575927734375
2025-12-09 12:00:41.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.0009876857638590373 Training loss: 7.248706817626953
2025-12-09 12:00:42.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.0009876169664956068 Training loss: 6.99046516418457
2025-12-09 12:00:42.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.0009875479798975512 Training loss: 7.125633239746094
2025-12-09 12:00:43.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.0009874788040916433 Training loss: 7.234933376312256
2025-12-09 12:00:43.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.0009874094391047288 Training loss: 7.0180768966674805
2025-12-09 12:00:43.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.0009873398849637267 Training loss: 6.750127792358398
2025-12-09 12:00:44.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.00098727014169563 Training loss: 7.281252384185791
2025-12-09 12:00:44.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.0009872002093275043 Training loss: 7.365250110626221
2025-12-09 12:00:45.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.000987130087886489 Training loss: 6.879098892211914
2025-12-09 12:00:45.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.000987059777399797 Training loss: 7.098609924316406
2025-12-09 12:00:45.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.0009869892778947148 Training loss: 8.070328712463379
2025-12-09 12:00:46.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.0009869185893986011 Training loss: 7.370302677154541
2025-12-09 12:00:46.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.0009868477119388895 Training loss: 7.289418697357178
2025-12-09 12:00:47.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.0009867766455430858 Training loss: 6.8578667640686035
2025-12-09 12:00:47.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.0009867053902387693 Training loss: 7.15665340423584
2025-12-09 12:00:47.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.0009866339460535929 Training loss: 7.144228935241699
2025-12-09 12:00:48.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.0009865623130152828 Training loss: 6.896724224090576
2025-12-09 12:00:48.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.0009864904911516383 Training loss: 7.371510982513428
2025-12-09 12:00:48.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.0009864184804905323 Training loss: 7.324470043182373
2025-12-09 12:00:49.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.0009863462810599105 Training loss: 6.9808549880981445
2025-12-09 12:00:49.734 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.000986273892887792 Training loss: 7.886877059936523
2025-12-09 12:00:50.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.0009862013160022696 Training loss: 7.036606311798096
2025-12-09 12:00:50.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.0009861285504315085 Training loss: 7.489642143249512
2025-12-09 12:00:50.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.0009860555962037478 Training loss: 7.3589582443237305
2025-12-09 12:00:51.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.0009859824533472999 Training loss: 7.16518497467041
2025-12-09 12:00:51.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.0009859091218905498 Training loss: 6.9221510887146
2025-12-09 12:00:52.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.000985835601861956 Training loss: 7.727482795715332
2025-12-09 12:00:52.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.0009857618932900504 Training loss: 6.989415645599365
2025-12-09 12:00:52.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0009856879962034375 Training loss: 7.072854042053223
2025-12-09 12:00:53.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0009856139106307956 Training loss: 6.928814888000488
2025-12-09 12:00:53.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.0009855396366008756 Training loss: 7.376487731933594
2025-12-09 12:00:54.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.0009854651741425023 Training loss: 8.121116638183594
2025-12-09 12:00:54.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.0009853905232845728 Training loss: 7.06154203414917
2025-12-09 12:00:54.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0009853156840560575 Training loss: 6.945557594299316
2025-12-09 12:00:55.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.0009852406564860004 Training loss: 6.937526226043701
2025-12-09 12:00:55.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.000985165440603518 Training loss: 7.1234235763549805
2025-12-09 12:00:55.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.0009850900364378 Training loss: 6.96568489074707
2025-12-09 12:00:56.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.0009850144440181096 Training loss: 7.875219821929932
2025-12-09 12:00:56.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.0009849386633737824 Training loss: 6.983744144439697
2025-12-09 12:00:57.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.0009848626945342278 Training loss: 7.2204766273498535
2025-12-09 12:00:57.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.0009847865375289275 Training loss: 7.324361801147461
2025-12-09 12:00:57.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.0009847101923874367 Training loss: 7.168854713439941
2025-12-09 12:00:58.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.0009846336591393832 Training loss: 7.137368202209473
2025-12-09 12:00:58.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.0009845569378144686 Training loss: 6.971034526824951
2025-12-09 12:00:59.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.0009844800284424663 Training loss: 6.750809192657471
2025-12-09 12:00:59.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0009844029310532238 Training loss: 7.145030975341797
2025-12-09 12:00:59.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.0009843256456766609 Training loss: 6.949342727661133
2025-12-09 12:01:00.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.0009842481723427705 Training loss: 6.664475440979004
2025-12-09 12:01:00.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.0009841705110816186 Training loss: 7.1126275062561035
2025-12-09 12:01:00.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.000984092661923344 Training loss: 6.597280025482178
2025-12-09 12:01:01.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.0009840146248981585 Training loss: 7.15090799331665
2025-12-09 12:01:01.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.0009839364000363466 Training loss: 6.865684986114502
2025-12-09 12:01:02.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.000983857987368266 Training loss: 6.840259075164795
2025-12-09 12:01:02.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.0009837793869243467 Training loss: 7.082773208618164
2025-12-09 12:01:02.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.0009837005987350927 Training loss: 6.90855598449707
2025-12-09 12:01:03.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.0009836216228310797 Training loss: 7.685556411743164
2025-12-09 12:01:03.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.0009835424592429566 Training loss: 7.978285789489746
2025-12-09 12:01:04.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.0009834631080014456 Training loss: 7.333579063415527
2025-12-09 12:01:04.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.0009833835691373412 Training loss: 7.283302307128906
2025-12-09 12:01:04.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.000983303842681511 Training loss: 7.231754302978516
2025-12-09 12:01:05.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.000983223928664895 Training loss: 7.185320854187012
2025-12-09 12:01:05.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.0009831438271185064 Training loss: 6.503413200378418
2025-12-09 12:01:06.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.0009830635380734312 Training loss: 6.908692359924316
2025-12-09 12:01:06.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.000982983061560828 Training loss: 7.226515293121338
2025-12-09 12:01:06.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0009829023976119279 Training loss: 7.076889514923096
2025-12-09 12:01:07.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0009828215462580352 Training loss: 6.844151496887207
2025-12-09 12:01:07.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.0009827405075305267 Training loss: 6.9417548179626465
2025-12-09 12:01:07.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.000982659281460852 Training loss: 7.472141265869141
2025-12-09 12:01:08.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.0009825778680805331 Training loss: 7.042254447937012
2025-12-09 12:01:08.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.0009824962674211653 Training loss: 6.87209415435791
2025-12-09 12:01:09.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.0009824144795144158 Training loss: 6.945627689361572
2025-12-09 12:01:09.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.0009823325043920256 Training loss: 6.633835315704346
2025-12-09 12:01:09.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.0009822503420858068 Training loss: 7.266514301300049
2025-12-09 12:01:10.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.0009821679926276456 Training loss: 7.132686138153076
2025-12-09 12:01:10.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.0009820854560494998 Training loss: 7.290655136108398
2025-12-09 12:01:11.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.0009820027323834007 Training loss: 7.116331100463867
2025-12-09 12:01:11.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.0009819198216614513 Training loss: 6.6910552978515625
2025-12-09 12:01:11.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.0009818367239158277 Training loss: 7.328753471374512
2025-12-09 12:01:12.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.0009817534391787788 Training loss: 6.809731960296631
2025-12-09 12:01:12.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0009816699674826256 Training loss: 7.105456352233887
2025-12-09 12:01:13.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.0009815863088597618 Training loss: 6.885411739349365
2025-12-09 12:01:13.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.0009815024633426537 Training loss: 6.988394737243652
2025-12-09 12:01:13.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.00098141843096384 Training loss: 7.0749125480651855
2025-12-09 12:01:14.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.0009813342117559324 Training loss: 6.919492244720459
2025-12-09 12:01:14.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.0009812498057516143 Training loss: 7.156891822814941
2025-12-09 12:01:14.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.0009811652129836422 Training loss: 7.329735279083252
2025-12-09 12:01:15.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.0009810804334848449 Training loss: 6.455320835113525
2025-12-09 12:01:15.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.0009809954672881237 Training loss: 7.52678108215332
2025-12-09 12:01:16.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.0009809103144264523 Training loss: 6.89572286605835
2025-12-09 12:01:16.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.0009808249749328768 Training loss: 7.019077301025391
2025-12-09 12:01:16.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.000980739448840516 Training loss: 7.239087104797363
2025-12-09 12:01:17.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.0009806537361825606 Training loss: 7.232363224029541
2025-12-09 12:01:17.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.0009805678369922742 Training loss: 7.244472026824951
2025-12-09 12:01:18.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.0009804817513029928 Training loss: 6.9605584144592285
2025-12-09 12:01:18.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.000980395479148124 Training loss: 6.969308376312256
2025-12-09 12:01:18.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.0009803090205611487 Training loss: 7.30450439453125
2025-12-09 12:01:19.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.0009802223755756199 Training loss: 7.050876140594482
2025-12-09 12:01:19.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0009801355442251626 Training loss: 7.195952415466309
2025-12-09 12:01:20.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.0009800485265434745 Training loss: 7.055855751037598
2025-12-09 12:01:20.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.0009799613225643252 Training loss: 7.0311360359191895
2025-12-09 12:01:20.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.0009798739323215572 Training loss: 7.0095391273498535
2025-12-09 12:01:21.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.0009797863558490849 Training loss: 7.212560653686523
2025-12-09 12:01:21.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.000979698593180895 Training loss: 8.2991304397583
2025-12-09 12:01:21.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.0009796106443510462 Training loss: 6.8370819091796875
2025-12-09 12:01:22.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.00097952250939367 Training loss: 7.3613996505737305
2025-12-09 12:01:22.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.0009794341883429699 Training loss: 7.2772088050842285
2025-12-09 12:01:23.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.0009793456812332215 Training loss: 7.103468894958496
2025-12-09 12:01:23.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.0009792569880987725 Training loss: 6.745631694793701
2025-12-09 12:01:23.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.0009791681089740432 Training loss: 6.981790065765381
2025-12-09 12:01:24.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.0009790790438935256 Training loss: 6.991612434387207
2025-12-09 12:01:24.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.0009789897928917846 Training loss: 7.0652546882629395
2025-12-09 12:01:25.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.000978900356003456 Training loss: 6.940522193908691
2025-12-09 12:01:25.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.0009788107332632495 Training loss: 7.073658466339111
2025-12-09 12:01:25.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.0009787209247059453 Training loss: 7.064385414123535
2025-12-09 12:01:26.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.0009786309303663962 Training loss: 7.652308464050293
2025-12-09 12:01:26.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.0009785407502795277 Training loss: 7.05230188369751
2025-12-09 12:01:27.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.0009784503844803367 Training loss: 6.800323009490967
2025-12-09 12:01:27.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.0009783598330038925 Training loss: 7.291532516479492
2025-12-09 12:01:27.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.0009782690958853363 Training loss: 7.258736610412598
2025-12-09 12:01:28.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.0009781781731598813 Training loss: 6.846775531768799
2025-12-09 12:01:28.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.000978087064862813 Training loss: 7.431147575378418
2025-12-09 12:01:28.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.0009779957710294885 Training loss: 6.948266983032227
2025-12-09 12:01:29.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.0009779042916953375 Training loss: 7.012070655822754
2025-12-09 12:01:29.734 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.0009778126268958612 Training loss: 7.227962970733643
2025-12-09 12:01:30.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.000977720776666633 Training loss: 6.643306255340576
2025-12-09 12:01:30.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.000977628741043298 Training loss: 7.046093463897705
2025-12-09 12:01:30.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.0009775365200615734 Training loss: 6.764304161071777
2025-12-09 12:01:31.290 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.0009774441137572487 Training loss: 6.9599995613098145
2025-12-09 12:01:31.677 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.0009773515221661846 Training loss: 6.991168022155762
2025-12-09 12:01:32.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.0009772587453243141 Training loss: 7.240253925323486
2025-12-09 12:01:32.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.0009771657832676427 Training loss: 6.730522632598877
2025-12-09 12:01:32.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.0009770726360322465 Training loss: 6.937039852142334
2025-12-09 12:01:33.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.000976979303654274 Training loss: 7.542394161224365
2025-12-09 12:01:33.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.0009768857861699462 Training loss: 6.676952838897705
2025-12-09 12:01:34.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.0009767920836155552 Training loss: 6.81767463684082
2025-12-09 12:01:34.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.0009766981960274653 Training loss: 6.74185848236084
2025-12-09 12:01:34.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.000976604123442112 Training loss: 7.465503215789795
2025-12-09 12:01:35.175 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.0009765098658960035 Training loss: 6.692911624908447
2025-12-09 12:01:35.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.0009764154234257191 Training loss: 6.8784098625183105
2025-12-09 12:01:35.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.00097632079606791 Training loss: 7.180807590484619
2025-12-09 12:01:36.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.0009762259838592994 Training loss: 7.050564765930176
2025-12-09 12:01:36.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.0009761309868366819 Training loss: 7.313096046447754
2025-12-09 12:01:37.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0009760358050369243 Training loss: 6.838676929473877
2025-12-09 12:01:37.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.0009759404384969643 Training loss: 6.948596000671387
2025-12-09 12:01:37.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.0009758448872538121 Training loss: 6.8691086769104
2025-12-09 12:01:38.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.0009757491513445493 Training loss: 6.880108833312988
2025-12-09 12:01:38.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.0009756532308063293 Training loss: 7.222430229187012
2025-12-09 12:01:39.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.0009755571256763765 Training loss: 6.901295185089111
2025-12-09 12:01:39.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.0009754608359919879 Training loss: 7.180896759033203
2025-12-09 12:01:39.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.0009753643617905312 Training loss: 7.1715545654296875
2025-12-09 12:01:40.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.0009752677031094466 Training loss: 6.590025424957275
2025-12-09 12:01:40.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0009751708599862451 Training loss: 6.752316474914551
2025-12-09 12:01:40.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.0009750738324585098 Training loss: 6.7444329261779785
2025-12-09 12:01:41.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.0009749766205638952 Training loss: 7.822662353515625
2025-12-09 12:01:41.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.0009748792243401273 Training loss: 7.005153656005859
2025-12-09 12:01:42.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.0009747816438250037 Training loss: 7.184478282928467
2025-12-09 12:01:42.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.0009746838790563935 Training loss: 7.12422513961792
2025-12-09 12:01:42.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.000974585930072237 Training loss: 6.999091625213623
2025-12-09 12:01:43.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.0009744877969105468 Training loss: 6.7892069816589355
2025-12-09 12:01:43.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.0009743894796094062 Training loss: 7.163353443145752
2025-12-09 12:01:44.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.0009742909782069701 Training loss: 6.972917079925537
2025-12-09 12:01:44.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.0009741922927414651 Training loss: 7.169806480407715
2025-12-09 12:01:44.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.0009740934232511893 Training loss: 6.991377830505371
2025-12-09 12:01:45.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.0009739943697745117 Training loss: 6.731271266937256
2025-12-09 12:01:45.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0009738951323498732 Training loss: 7.369096279144287
2025-12-09 12:01:46.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0009737957110157858 Training loss: 6.808143615722656
2025-12-09 12:01:46.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.0009736961058108331 Training loss: 7.792073726654053
2025-12-09 12:01:46.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.0009735963167736698 Training loss: 7.203647136688232
2025-12-09 12:01:47.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.0009734963439430222 Training loss: 6.86553430557251
2025-12-09 12:01:47.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.0009733961873576877 Training loss: 6.59531307220459
2025-12-09 12:01:47.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0009732958470565352 Training loss: 6.700313568115234
2025-12-09 12:01:48.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.0009731953230785049 Training loss: 6.996798515319824
2025-12-09 12:01:48.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.0009730946154626079 Training loss: 7.446941375732422
2025-12-09 12:01:49.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.000972993724247927 Training loss: 7.21003532409668
2025-12-09 12:01:49.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.0009728926494736163 Training loss: 6.767492771148682
2025-12-09 12:01:49.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.0009727913911789008 Training loss: 7.021949291229248
2025-12-09 12:01:50.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.0009726899494030768 Training loss: 7.030025005340576
2025-12-09 12:01:50.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.0009725883241855118 Training loss: 7.205124855041504
2025-12-09 12:01:51.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.0009724865155656448 Training loss: 7.5990190505981445
2025-12-09 12:01:51.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.0009723845235829856 Training loss: 7.254859447479248
2025-12-09 12:01:51.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.0009722823482771155 Training loss: 6.989003658294678
2025-12-09 12:01:52.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.0009721799896876864 Training loss: 6.755059719085693
2025-12-09 12:01:52.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.0009720774478544219 Training loss: 7.709157943725586
2025-12-09 12:01:53.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.0009719747228171163 Training loss: 6.866214275360107
2025-12-09 12:01:53.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.0009718718146156355 Training loss: 7.214068412780762
2025-12-09 12:01:53.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0009717687232899158 Training loss: 7.0659308433532715
2025-12-09 12:01:54.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0009716654488799652 Training loss: 7.096471309661865
2025-12-09 12:01:54.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.0009715619914258623 Training loss: 6.842726707458496
2025-12-09 12:01:54.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.000971458350967757 Training loss: 6.961872100830078
2025-12-09 12:01:55.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.0009713545275458703 Training loss: 7.184791564941406
2025-12-09 12:01:55.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.0009712505212004937 Training loss: 6.8991570472717285
2025-12-09 12:01:56.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.0009711463319719904 Training loss: 7.100872039794922
2025-12-09 12:01:56.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0009710419599007938 Training loss: 6.693134307861328
2025-12-09 12:01:56.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.0009709374050274089 Training loss: 7.292740345001221
2025-12-09 12:01:57.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.0009708326673924114 Training loss: 7.193123817443848
2025-12-09 12:01:57.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0009707277470364482 Training loss: 6.777451992034912
2025-12-09 12:01:58.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.0009706226440002363 Training loss: 7.426961421966553
2025-12-09 12:01:58.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.0009705173583245644 Training loss: 6.705275535583496
2025-12-09 12:01:58.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.0009704118900502918 Training loss: 7.0695600509643555
2025-12-09 12:01:59.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.0009703062392183488 Training loss: 6.947417736053467
2025-12-09 12:01:59.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.0009702004058697362 Training loss: 6.59307861328125
2025-12-09 12:02:00.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0009700943900455262 Training loss: 7.171966075897217
2025-12-09 12:02:00.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.0009699881917868609 Training loss: 7.217903137207031
2025-12-09 12:02:00.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.0009698818111349544 Training loss: 6.7108893394470215
2025-12-09 12:02:01.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.0009697752481310904 Training loss: 6.992037296295166
2025-12-09 12:02:01.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.0009696685028166244 Training loss: 6.880644798278809
2025-12-09 12:02:01.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.000969561575232982 Training loss: 6.998692512512207
2025-12-09 12:02:02.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0009694544654216595 Training loss: 6.927560329437256
2025-12-09 12:02:02.745 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.0009693471734242243 Training loss: 6.726859092712402
2025-12-09 12:02:03.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0009692396992823144 Training loss: 7.38444185256958
2025-12-09 12:02:03.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.0009691320430376385 Training loss: 6.681159019470215
2025-12-09 12:02:03.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.0009690242047319755 Training loss: 6.802889823913574
2025-12-09 12:02:04.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.0009689161844071756 Training loss: 7.2704668045043945
2025-12-09 12:02:04.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.0009688079821051594 Training loss: 6.648741722106934
2025-12-09 12:02:05.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.0009686995978679181 Training loss: 6.502857208251953
2025-12-09 12:02:05.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.0009685910317375133 Training loss: 6.9080305099487305
2025-12-09 12:02:05.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.0009684822837560776 Training loss: 7.173154354095459
2025-12-09 12:02:06.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.0009683733539658139 Training loss: 6.9802045822143555
2025-12-09 12:02:06.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.0009682642424089958 Training loss: 7.405025959014893
2025-12-09 12:02:07.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.0009681549491279673 Training loss: 7.415944576263428
2025-12-09 12:02:07.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.000968045474165143 Training loss: 7.042191982269287
2025-12-09 12:02:07.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0009679358175630081 Training loss: 7.11625337600708
2025-12-09 12:02:08.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.000967825979364118 Training loss: 6.093024730682373
2025-12-09 12:02:08.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.0009677159596110987 Training loss: 6.850123405456543
2025-12-09 12:02:08.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.000967605758346647 Training loss: 7.003256320953369
2025-12-09 12:02:09.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.0009674953756135297 Training loss: 6.875373363494873
2025-12-09 12:02:09.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.0009673848114545843 Training loss: 7.018247127532959
2025-12-09 12:02:10.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.0009672740659127184 Training loss: 7.981795310974121
2025-12-09 12:02:10.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.0009671631390309102 Training loss: 7.9251017570495605
2025-12-09 12:02:10.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.0009670520308522084 Training loss: 7.019673824310303
2025-12-09 12:02:11.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.0009669407414197318 Training loss: 7.003682613372803
2025-12-09 12:02:11.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.0009668292707766699 Training loss: 6.900816917419434
