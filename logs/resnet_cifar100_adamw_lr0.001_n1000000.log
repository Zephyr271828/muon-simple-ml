2025-12-09 12:07:31.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 4.902071952819824
2025-12-09 12:07:31.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 4.799776077270508
2025-12-09 12:07:31.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 4.992262840270996
2025-12-09 12:07:31.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 5.050384044647217
2025-12-09 12:07:31.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 4.758328437805176
2025-12-09 12:07:31.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 4.82920503616333
2025-12-09 12:07:31.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 4.878856658935547
2025-12-09 12:07:31.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 4.86288595199585
2025-12-09 12:07:31.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 4.855072021484375
2025-12-09 12:07:31.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 4.8631062507629395
2025-12-09 12:07:31.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 4.797866344451904
2025-12-09 12:07:31.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 4.8048882484436035
2025-12-09 12:07:31.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 4.836832046508789
2025-12-09 12:07:31.745 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 4.742440700531006
2025-12-09 12:07:31.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 4.65506649017334
2025-12-09 12:07:31.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 4.698196887969971
2025-12-09 12:07:31.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 4.635758399963379
2025-12-09 12:07:31.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 4.68140172958374
2025-12-09 12:07:31.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 4.605752468109131
2025-12-09 12:07:31.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 4.508063316345215
2025-12-09 12:07:31.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 4.665602684020996
2025-12-09 12:07:31.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 4.571895599365234
2025-12-09 12:07:31.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 4.519351005554199
2025-12-09 12:07:31.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 4.673489093780518
2025-12-09 12:07:31.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 4.424766540527344
2025-12-09 12:07:31.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 4.508998394012451
2025-12-09 12:07:31.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 4.507012367248535
2025-12-09 12:07:31.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 4.533949851989746
2025-12-09 12:07:31.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 4.470733165740967
2025-12-09 12:07:31.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 4.5855393409729
2025-12-09 12:07:31.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 4.443317890167236
2025-12-09 12:07:31.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 4.479922294616699
2025-12-09 12:07:31.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 4.300083637237549
2025-12-09 12:07:31.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 4.3665452003479
2025-12-09 12:07:31.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 4.39802885055542
2025-12-09 12:07:31.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 4.41067361831665
2025-12-09 12:07:31.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 4.424589157104492
2025-12-09 12:07:31.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 4.439002513885498
2025-12-09 12:07:31.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 4.2829084396362305
2025-12-09 12:07:31.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 4.3343915939331055
2025-12-09 12:07:31.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 4.1714348793029785
2025-12-09 12:07:31.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 4.34212064743042
2025-12-09 12:07:32.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 4.290355682373047
2025-12-09 12:07:32.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 4.406133651733398
2025-12-09 12:07:32.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 4.218841552734375
2025-12-09 12:07:32.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 4.251500129699707
2025-12-09 12:07:32.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 4.151042461395264
2025-12-09 12:07:32.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 4.186878681182861
2025-12-09 12:07:32.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 4.232626914978027
2025-12-09 12:07:32.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 4.214980125427246
2025-12-09 12:07:32.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 4.12679386138916
2025-12-09 12:07:32.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 4.156745910644531
2025-12-09 12:07:32.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 4.166407108306885
2025-12-09 12:07:32.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 4.251073360443115
2025-12-09 12:07:32.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 4.151442050933838
2025-12-09 12:07:32.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 4.050533771514893
2025-12-09 12:07:32.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 4.069966793060303
2025-12-09 12:07:32.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 4.084425449371338
2025-12-09 12:07:32.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 3.9431278705596924
2025-12-09 12:07:32.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 4.016781806945801
2025-12-09 12:07:32.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 4.15385627746582
2025-12-09 12:07:32.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 4.068385601043701
2025-12-09 12:07:32.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 4.188042163848877
2025-12-09 12:07:32.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 4.020360469818115
2025-12-09 12:07:32.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 4.270858287811279
2025-12-09 12:07:32.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 3.9194998741149902
2025-12-09 12:07:32.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 4.005044937133789
2025-12-09 12:07:32.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 4.121378421783447
2025-12-09 12:07:32.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 3.8430192470550537
2025-12-09 12:07:32.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 3.8720884323120117
2025-12-09 12:07:32.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 4.068196773529053
2025-12-09 12:07:32.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 3.9437224864959717
2025-12-09 12:07:32.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 3.8922417163848877
2025-12-09 12:07:32.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 4.019424915313721
2025-12-09 12:07:32.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 3.8553712368011475
2025-12-09 12:07:32.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 3.9048686027526855
2025-12-09 12:07:32.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 3.9831953048706055
2025-12-09 12:07:32.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 3.9678516387939453
2025-12-09 12:07:32.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 3.9253125190734863
2025-12-09 12:07:32.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 4.031107425689697
2025-12-09 12:07:32.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 4.0098557472229
2025-12-09 12:07:32.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 3.8629631996154785
2025-12-09 12:07:32.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 3.915043592453003
2025-12-09 12:07:32.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 3.8765454292297363
2025-12-09 12:07:32.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 3.653426170349121
2025-12-09 12:07:32.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 3.839121103286743
2025-12-09 12:07:32.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 3.8970108032226562
2025-12-09 12:07:32.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 3.821587324142456
2025-12-09 12:07:32.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 3.9726500511169434
2025-12-09 12:07:32.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 3.8340916633605957
2025-12-09 12:07:32.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 3.8894848823547363
2025-12-09 12:07:32.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 3.879199743270874
2025-12-09 12:07:32.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 3.767333984375
2025-12-09 12:07:32.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 3.7901198863983154
2025-12-09 12:07:32.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 3.7636473178863525
2025-12-09 12:07:32.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 3.8814499378204346
2025-12-09 12:07:32.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 3.861192226409912
2025-12-09 12:07:32.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 3.784872055053711
2025-12-09 12:07:32.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 3.7253994941711426
2025-12-09 12:07:32.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 3.7716281414031982
2025-12-09 12:07:32.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0009999708626830617 Training loss: 3.741147041320801
2025-12-09 12:07:32.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.0009998834541281797 Training loss: 3.9739911556243896
2025-12-09 12:07:32.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0009997377845227576 Training loss: 3.6909263134002686
2025-12-09 12:07:32.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0009995338708444802 Training loss: 3.8639328479766846
2025-12-09 12:07:32.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0009992717368593384 Training loss: 3.897185802459717
2025-12-09 12:07:32.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0009989514131188558 Training loss: 3.6808369159698486
2025-12-09 12:07:32.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0009985729369565298 Training loss: 3.7451817989349365
2025-12-09 12:07:32.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.00099813635248348 Training loss: 3.9761056900024414
2025-12-09 12:07:32.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0009976417105833069 Training loss: 3.8694984912872314
2025-12-09 12:07:32.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.000997089068906162 Training loss: 3.8875248432159424
2025-12-09 12:07:32.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.0009964784918620282 Training loss: 3.9154176712036133
2025-12-09 12:07:32.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0009958100506132126 Training loss: 3.5804011821746826
2025-12-09 12:07:32.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0009950838230660534 Training loss: 3.7718183994293213
2025-12-09 12:07:32.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0009942998938618393 Training loss: 3.785996675491333
2025-12-09 12:07:32.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.0009934583543669453 Training loss: 3.6971018314361572
2025-12-09 12:07:32.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0009925593026621834 Training loss: 3.8506393432617188
2025-12-09 12:07:32.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.000991602843531371 Training loss: 3.7200770378112793
2025-12-09 12:07:32.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.0009905890884491196 Training loss: 3.5929131507873535
2025-12-09 12:07:32.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0009895181555678418 Training loss: 3.6624624729156494
2025-12-09 12:07:32.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.0009883901697039807 Training loss: 3.5289690494537354
2025-12-09 12:07:32.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.000987205262323463 Training loss: 3.9420175552368164
2025-12-09 12:07:32.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.000985963571526376 Training loss: 3.739933967590332
2025-12-09 12:07:32.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.0009846652420308728 Training loss: 3.7938551902770996
2025-12-09 12:07:32.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.0009833104251563056 Training loss: 3.7096595764160156
2025-12-09 12:07:32.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.000981899278805589 Training loss: 3.8643407821655273
2025-12-09 12:07:32.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.0009804319674467969 Training loss: 3.9117846488952637
2025-12-09 12:07:32.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.0009789086620939935 Training loss: 3.689323663711548
2025-12-09 12:07:32.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.0009773295402873026 Training loss: 3.6356115341186523
2025-12-09 12:07:32.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0009756947860722143 Training loss: 3.6520941257476807
2025-12-09 12:07:32.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.0009740045899781352 Training loss: 4.030992031097412
2025-12-09 12:07:32.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.0009722591489961827 Training loss: 3.717789649963379
2025-12-09 12:07:32.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.0009704586665562249 Training loss: 3.891408920288086
2025-12-09 12:07:32.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0009686033525031719 Training loss: 3.779996871948242
2025-12-09 12:07:32.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.0009666934230725179 Training loss: 3.6771955490112305
2025-12-09 12:07:32.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.0009647291008651398 Training loss: 3.6876509189605713
2025-12-09 12:07:32.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0009627106148213521 Training loss: 3.826122283935547
2025-12-09 12:07:32.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0009606382001942255 Training loss: 3.8568434715270996
2025-12-09 12:07:32.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.0009585120985221671 Training loss: 3.6136832237243652
2025-12-09 12:07:32.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.0009563325576007701 Training loss: 3.8320746421813965
2025-12-09 12:07:32.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0009540998314539327 Training loss: 3.6768171787261963
2025-12-09 12:07:32.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0009518141803042527 Training loss: 3.713090419769287
2025-12-09 12:07:32.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.0009494758705426977 Training loss: 3.8929762840270996
2025-12-09 12:07:32.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0009470851746975581 Training loss: 3.8304991722106934
2025-12-09 12:07:32.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.0009446423714026846 Training loss: 3.806478261947632
2025-12-09 12:07:32.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0009421477453650118 Training loss: 3.9078328609466553
2025-12-09 12:07:32.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.0009396015873313782 Training loss: 3.637789726257324
2025-12-09 12:07:32.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0009370041940546379 Training loss: 3.913346767425537
2025-12-09 12:07:32.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0009343558682590756 Training loss: 3.68160080909729
2025-12-09 12:07:32.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.0009316569186051234 Training loss: 3.6968154907226562
2025-12-09 12:07:32.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0009289076596533872 Training loss: 3.626406192779541
2025-12-09 12:07:32.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0009261084118279846 Training loss: 3.6404247283935547
2025-12-09 12:07:32.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.0009232595013792003 Training loss: 3.551931619644165
2025-12-09 12:07:32.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0009203612603454604 Training loss: 3.6788413524627686
2025-12-09 12:07:33.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.0009174140265146356 Training loss: 3.3855578899383545
2025-12-09 12:07:33.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.0009144181433846706 Training loss: 3.3127150535583496
2025-12-09 12:07:33.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0009113739601235507 Training loss: 3.7886428833007812
2025-12-09 12:07:33.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.0009082818315286055 Training loss: 3.611888885498047
2025-12-09 12:07:33.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0009051421179851588 Training loss: 3.609332323074341
2025-12-09 12:07:33.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.000901955185424525 Training loss: 3.460726022720337
2025-12-09 12:07:33.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0008987214052813603 Training loss: 3.6199934482574463
2025-12-09 12:07:33.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.0008954411544503729 Training loss: 3.5334365367889404
2025-12-09 12:07:33.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.0008921148152423946 Training loss: 3.396487236022949
2025-12-09 12:07:33.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.0008887427753398248 Training loss: 3.5967626571655273
2025-12-09 12:07:33.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.0008853254277514447 Training loss: 3.669004201889038
2025-12-09 12:07:33.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0008818631707666135 Training loss: 3.774049997329712
2025-12-09 12:07:33.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.0008783564079088476 Training loss: 3.629426956176758
2025-12-09 12:07:33.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.0008748055478887904 Training loss: 3.642237901687622
2025-12-09 12:07:33.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0008712110045565768 Training loss: 3.5818307399749756
2025-12-09 12:07:33.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.0008675731968536002 Training loss: 3.5439229011535645
2025-12-09 12:07:33.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.0008638925487636848 Training loss: 3.3817718029022217
2025-12-09 12:07:33.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.00086016948926367 Training loss: 3.6006405353546143
2025-12-09 12:07:33.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.0008564044522734146 Training loss: 3.5886988639831543
2025-12-09 12:07:33.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.000852597876605223 Training loss: 3.5199687480926514
2025-12-09 12:07:33.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.0008487502059127015 Training loss: 3.5125889778137207
2025-12-09 12:07:33.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.0008448618886390522 Training loss: 3.5646400451660156
2025-12-09 12:07:33.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.0008409333779648059 Training loss: 3.669891595840454
2025-12-09 12:07:33.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0008369651317550054 Training loss: 3.3731887340545654
2025-12-09 12:07:33.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0008329576125058406 Training loss: 3.3741512298583984
2025-12-09 12:07:33.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.0008289112872907454 Training loss: 3.670724630355835
2025-12-09 12:07:33.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.0008248266277059606 Training loss: 3.4812803268432617
2025-12-09 12:07:33.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.00082070410981557 Training loss: 3.3980023860931396
2025-12-09 12:07:33.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.000816544214096015 Training loss: 3.5198159217834473
2025-12-09 12:07:33.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.0008123474253800957 Training loss: 3.5558996200561523
2025-12-09 12:07:33.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.0008081142328004637 Training loss: 3.546647548675537
2025-12-09 12:07:33.295 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.0008038451297326145 Training loss: 3.597137689590454
2025-12-09 12:07:33.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0007995406137373846 Training loss: 3.5242116451263428
2025-12-09 12:07:33.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.0007952011865029613 Training loss: 3.5761287212371826
2025-12-09 12:07:33.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.0007908273537864113 Training loss: 3.492710590362549
2025-12-09 12:07:33.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0007864196253547349 Training loss: 3.2370169162750244
2025-12-09 12:07:33.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.0007819785149254532 Training loss: 3.472161054611206
2025-12-09 12:07:33.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.000777504540106735 Training loss: 3.4965596199035645
2025-12-09 12:07:33.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0007729982223370691 Training loss: 3.6133346557617188
2025-12-09 12:07:33.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.0007684600868244919 Training loss: 3.3403992652893066
2025-12-09 12:07:33.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.0007638906624853743 Training loss: 3.4745049476623535
2025-12-09 12:07:33.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.0007592904818827774 Training loss: 3.4480197429656982
2025-12-09 12:07:33.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0007546600811643815 Training loss: 3.3990774154663086
2025-12-09 12:07:33.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.00075 Training loss: 3.5228612422943115
2025-12-09 12:07:33.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.0007453107815186803 Training loss: 3.4305927753448486
2025-12-09 12:07:33.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0007405929722454026 Training loss: 3.531097650527954
2025-12-09 12:07:33.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0007358471220373831 Training loss: 3.501842498779297
2025-12-09 12:07:33.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0007310737840199885 Training loss: 3.4230289459228516
2025-12-09 12:07:33.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0007262735145222696 Training loss: 3.1712467670440674
2025-12-09 12:07:33.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0007214468730121209 Training loss: 3.1885764598846436
2025-12-09 12:07:33.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0007165944220310766 Training loss: 3.451148271560669
2025-12-09 12:07:33.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0007117167271287453 Training loss: 3.336209535598755
2025-12-09 12:07:33.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0007068143567968958 Training loss: 3.4033565521240234
2025-12-09 12:07:33.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.0007018878824032009 Training loss: 3.348346710205078
2025-12-09 12:07:33.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.0006969378781246436 Training loss: 3.6716818809509277
2025-12-09 12:07:33.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.0006919649208805981 Training loss: 3.289508819580078
2025-12-09 12:07:33.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0006869695902655897 Training loss: 3.453125
2025-12-09 12:07:33.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.0006819524684817438 Training loss: 3.4916670322418213
2025-12-09 12:07:33.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.0006769141402709304 Training loss: 3.2673158645629883
2025-12-09 12:07:33.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0006718551928466132 Training loss: 3.3703558444976807
2025-12-09 12:07:33.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.0006667762158254104 Training loss: 3.3901009559631348
2025-12-09 12:07:33.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.0006616778011583743 Training loss: 3.451183795928955
2025-12-09 12:07:33.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.0006565605430620013 Training loss: 3.481969118118286
2025-12-09 12:07:33.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0006514250379489753 Training loss: 3.3176989555358887
2025-12-09 12:07:33.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.0006462718843586572 Training loss: 3.5554301738739014
2025-12-09 12:07:33.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.0006411016828873239 Training loss: 3.3925886154174805
2025-12-09 12:07:33.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0006359150361181715 Training loss: 3.2628703117370605
2025-12-09 12:07:33.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.0006307125485510829 Training loss: 3.4819705486297607
2025-12-09 12:07:33.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0006254948265321744 Training loss: 3.523745536804199
2025-12-09 12:07:33.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0006202624781831269 Training loss: 3.459033250808716
2025-12-09 12:07:33.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0006150161133303088 Training loss: 3.4526259899139404
2025-12-09 12:07:33.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0006097563434337025 Training loss: 3.4287848472595215
2025-12-09 12:07:33.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.0006044837815156376 Training loss: 3.3711233139038086
2025-12-09 12:07:33.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.0005991990420893449 Training loss: 3.200705051422119
2025-12-09 12:07:33.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.0005939027410873352 Training loss: 3.39522123336792
2025-12-09 12:07:33.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0005885954957896114 Training loss: 3.4457316398620605
2025-12-09 12:07:33.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0005832779247517272 Training loss: 3.2448132038116455
2025-12-09 12:07:33.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0005779506477326933 Training loss: 3.4456839561462402
2025-12-09 12:07:33.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.0005726142856227452 Training loss: 3.2389883995056152
2025-12-09 12:07:33.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0005672694603709794 Training loss: 3.6066248416900635
2025-12-09 12:07:33.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0005619167949128652 Training loss: 3.3394088745117188
2025-12-09 12:07:33.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.0005565569130976422 Training loss: 3.249512195587158
2025-12-09 12:07:33.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0005511904396156113 Training loss: 3.2793779373168945
2025-12-09 12:07:33.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.0005458179999253274 Training loss: 3.440136432647705
2025-12-09 12:07:33.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0005404402201807021 Training loss: 3.2955827713012695
2025-12-09 12:07:33.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.0005350577271580271 Training loss: 3.3218133449554443
2025-12-09 12:07:33.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0005296711481829226 Training loss: 3.3483831882476807
2025-12-09 12:07:33.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.0005242811110572242 Training loss: 3.511014699935913
2025-12-09 12:07:33.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.0005188882439858117 Training loss: 3.1974544525146484
2025-12-09 12:07:33.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.0005134931755033936 Training loss: 3.3339221477508545
2025-12-09 12:07:33.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.0005080965344012508 Training loss: 2.998211145401001
2025-12-09 12:07:33.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.0005026989496539523 Training loss: 3.3404312133789062
2025-12-09 12:07:33.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0004973010503460479 Training loss: 3.243499755859375
2025-12-09 12:07:33.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.0004919034655987492 Training loss: 3.2867629528045654
2025-12-09 12:07:33.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0004865068244966066 Training loss: 3.2134716510772705
2025-12-09 12:07:33.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0004811117560141884 Training loss: 3.1450016498565674
2025-12-09 12:07:33.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.000475718888942776 Training loss: 3.2863786220550537
2025-12-09 12:07:33.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0004703288518170774 Training loss: 3.3414361476898193
2025-12-09 12:07:33.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.00046494227284197295 Training loss: 3.089836835861206
2025-12-09 12:07:33.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.00045955977981929796 Training loss: 3.1444413661956787
2025-12-09 12:07:33.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.0004541820000746727 Training loss: 3.278970956802368
2025-12-09 12:07:33.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.00044880956038438873 Training loss: 3.408684253692627
2025-12-09 12:07:33.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.0004434430869023579 Training loss: 3.313790798187256
2025-12-09 12:07:33.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.000438083205087135 Training loss: 3.121086597442627
2025-12-09 12:07:33.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.00043273053962902076 Training loss: 3.0750513076782227
2025-12-09 12:07:33.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.000427385714377255 Training loss: 3.093784809112549
2025-12-09 12:07:33.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.0004220493522673067 Training loss: 3.134849786758423
2025-12-09 12:07:33.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0004167220752482728 Training loss: 3.134831666946411
2025-12-09 12:07:33.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.00041140450421038864 Training loss: 3.408961772918701
2025-12-09 12:07:33.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.000406097258912665 Training loss: 3.1583919525146484
2025-12-09 12:07:34.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0004008009579106551 Training loss: 3.1101458072662354
2025-12-09 12:07:34.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.0003955162184843625 Training loss: 3.233851432800293
2025-12-09 12:07:34.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.00039024365656629766 Training loss: 3.276808261871338
2025-12-09 12:07:34.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0003849838866696913 Training loss: 3.0939323902130127
2025-12-09 12:07:34.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.00037973752181687335 Training loss: 3.0543413162231445
2025-12-09 12:07:34.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.00037450517346782563 Training loss: 3.1654882431030273
2025-12-09 12:07:34.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0003692874514489173 Training loss: 3.0670859813690186
2025-12-09 12:07:34.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.00036408496388182855 Training loss: 2.98134446144104
2025-12-09 12:07:34.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0003588983171126762 Training loss: 3.377030611038208
2025-12-09 12:07:34.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.000353728115641343 Training loss: 3.0019333362579346
2025-12-09 12:07:34.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.0003485749620510247 Training loss: 3.0327394008636475
2025-12-09 12:07:34.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.00034343945693799885 Training loss: 2.9816861152648926
2025-12-09 12:07:34.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.00033832219884162584 Training loss: 3.2179388999938965
2025-12-09 12:07:34.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0003332237841745898 Training loss: 3.239443778991699
2025-12-09 12:07:34.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.00032814480715338666 Training loss: 3.265049457550049
2025-12-09 12:07:34.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0003230858597290697 Training loss: 2.9570541381835938
2025-12-09 12:07:34.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0003180475315182563 Training loss: 2.983248233795166
2025-12-09 12:07:34.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0003130304097344103 Training loss: 3.1104633808135986
2025-12-09 12:07:34.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.0003080350791194019 Training loss: 3.022446870803833
2025-12-09 12:07:34.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.00030306212187535653 Training loss: 3.060664415359497
2025-12-09 12:07:34.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0002981121175967992 Training loss: 2.8824377059936523
2025-12-09 12:07:34.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.00029318564320310444 Training loss: 3.129668951034546
2025-12-09 12:07:34.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.0002882832728712551 Training loss: 2.8682472705841064
2025-12-09 12:07:34.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0002834055779689235 Training loss: 2.85302472114563
2025-12-09 12:07:34.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.00027855312698787905 Training loss: 3.3352460861206055
2025-12-09 12:07:34.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0002737264854777306 Training loss: 2.9033279418945312
2025-12-09 12:07:34.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.00026892621598001155 Training loss: 3.2355682849884033
2025-12-09 12:07:34.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0002641528779626171 Training loss: 3.3294472694396973
2025-12-09 12:07:34.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.00025940702775459747 Training loss: 3.1424753665924072
2025-12-09 12:07:34.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.00025468921848131984 Training loss: 3.0940208435058594
2025-12-09 12:07:34.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0002500000000000001 Training loss: 3.155986785888672
2025-12-09 12:07:34.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.00024533991883561866 Training loss: 2.9337189197540283
2025-12-09 12:07:34.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.00024070951811722268 Training loss: 3.17521595954895
2025-12-09 12:07:34.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.00023610933751462554 Training loss: 2.80256986618042
2025-12-09 12:07:34.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.0002315399131755081 Training loss: 2.9599521160125732
2025-12-09 12:07:34.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.00022700177766293096 Training loss: 3.1635944843292236
2025-12-09 12:07:34.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.00022249545989326514 Training loss: 3.039517402648926
2025-12-09 12:07:34.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0002180214850745467 Training loss: 2.929443359375
2025-12-09 12:07:34.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.00021358037464526514 Training loss: 3.0686919689178467
2025-12-09 12:07:34.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.00020917264621358878 Training loss: 2.8090250492095947
2025-12-09 12:07:34.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.00020479881349703882 Training loss: 2.9899306297302246
2025-12-09 12:07:34.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.00020045938626261545 Training loss: 3.2260749340057373
2025-12-09 12:07:34.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.00019615487026738542 Training loss: 3.170473098754883
2025-12-09 12:07:34.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.00019188576719953633 Training loss: 3.0923209190368652
2025-12-09 12:07:34.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.00018765257461990443 Training loss: 2.988070011138916
2025-12-09 12:07:34.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0001834557859039851 Training loss: 2.8492422103881836
2025-12-09 12:07:34.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.00017929589018443015 Training loss: 3.1352341175079346
2025-12-09 12:07:34.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.00017517337229403947 Training loss: 2.9785664081573486
2025-12-09 12:07:34.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.0001710887127092548 Training loss: 3.055682420730591
2025-12-09 12:07:34.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.00016704238749415957 Training loss: 3.1732125282287598
2025-12-09 12:07:34.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0001630348682449946 Training loss: 2.9174740314483643
2025-12-09 12:07:34.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.00015906662203519413 Training loss: 2.8585493564605713
2025-12-09 12:07:34.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.00015513811136094787 Training loss: 3.115839958190918
2025-12-09 12:07:34.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.0001512497940872986 Training loss: 3.167027711868286
2025-12-09 12:07:34.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.0001474021233947772 Training loss: 3.155799150466919
2025-12-09 12:07:34.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.00014359554772658552 Training loss: 2.4998586177825928
2025-12-09 12:07:34.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.00013983051073632996 Training loss: 3.2807888984680176
2025-12-09 12:07:34.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.00013610745123631535 Training loss: 2.785172462463379
2025-12-09 12:07:34.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.00013242680314639994 Training loss: 3.02824068069458
2025-12-09 12:07:34.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.00012878899544342326 Training loss: 2.956393241882324
2025-12-09 12:07:34.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.00012519445211120977 Training loss: 2.731273889541626
2025-12-09 12:07:34.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.00012164359209115234 Training loss: 3.0263757705688477
2025-12-09 12:07:34.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.00011813682923338653 Training loss: 2.9982717037200928
2025-12-09 12:07:34.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.00011467457224855543 Training loss: 3.1267337799072266
2025-12-09 12:07:34.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.00011125722466017545 Training loss: 3.0102462768554688
2025-12-09 12:07:34.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.00010788518475760544 Training loss: 2.774111032485962
2025-12-09 12:07:34.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.00010455884554962725 Training loss: 3.014448404312134
2025-12-09 12:07:34.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.0001012785947186397 Training loss: 3.043984889984131
2025-12-09 12:07:34.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 9.804481457547498e-05 Training loss: 3.147935628890991
2025-12-09 12:07:34.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 9.485788201484124e-05 Training loss: 3.1863808631896973
2025-12-09 12:07:34.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 9.171816847139447e-05 Training loss: 2.8953685760498047
2025-12-09 12:07:34.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 8.862603987644941e-05 Training loss: 3.129934072494507
2025-12-09 12:07:34.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 8.558185661532942e-05 Training loss: 2.962118148803711
2025-12-09 12:07:34.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 8.258597348536451e-05 Training loss: 3.126514434814453
2025-12-09 12:07:34.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 7.96387396545396e-05 Training loss: 3.1222076416015625
2025-12-09 12:07:34.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 7.674049862079991e-05 Training loss: 3.0825443267822266
2025-12-09 12:07:34.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 7.38915881720154e-05 Training loss: 2.931342363357544
2025-12-09 12:07:34.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 7.109234034661289e-05 Training loss: 2.919646978378296
2025-12-09 12:07:34.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 6.834308139487671e-05 Training loss: 2.9157845973968506
2025-12-09 12:07:34.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 6.564413174092443e-05 Training loss: 2.805983304977417
2025-12-09 12:07:34.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 6.299580594536214e-05 Training loss: 2.9649887084960938
2025-12-09 12:07:34.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 6.0398412668621897e-05 Training loss: 2.9350969791412354
2025-12-09 12:07:34.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 5.785225463498828e-05 Training loss: 2.889084577560425
2025-12-09 12:07:34.745 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 5.535762859731547e-05 Training loss: 3.14776611328125
2025-12-09 12:07:34.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 5.291482530244179e-05 Training loss: 2.9472665786743164
2025-12-09 12:07:34.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 5.0524129457302394e-05 Training loss: 2.9735045433044434
2025-12-09 12:07:34.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 4.818581969574742e-05 Training loss: 3.002448320388794
2025-12-09 12:07:34.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 4.5900168546067264e-05 Training loss: 2.919330596923828
2025-12-09 12:07:34.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 4.366744239922998e-05 Training loss: 2.817737579345703
2025-12-09 12:07:34.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 4.148790147783288e-05 Training loss: 2.9035611152648926
2025-12-09 12:07:34.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 3.936179980577453e-05 Training loss: 3.0014572143554688
2025-12-09 12:07:34.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 3.728938517864794e-05 Training loss: 2.9297688007354736
2025-12-09 12:07:34.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 3.527089913486037e-05 Training loss: 2.922882318496704
2025-12-09 12:07:34.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 3.330657692748212e-05 Training loss: 2.637202024459839
2025-12-09 12:07:34.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 3.1396647496828245e-05 Training loss: 2.9470982551574707
2025-12-09 12:07:34.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 2.9541333443775243e-05 Training loss: 2.9105961322784424
2025-12-09 12:07:34.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 2.7740851003817347e-05 Training loss: 2.7872514724731445
2025-12-09 12:07:34.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 2.5995410021864786e-05 Training loss: 2.690641403198242
2025-12-09 12:07:34.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 2.430521392778573e-05 Training loss: 2.900927782058716
2025-12-09 12:07:34.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 2.2670459712697378e-05 Training loss: 2.949101686477661
2025-12-09 12:07:34.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 2.109133790600648e-05 Training loss: 3.001410722732544
2025-12-09 12:07:34.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 1.956803255320322e-05 Training loss: 2.884272336959839
2025-12-09 12:07:34.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 1.810072119441103e-05 Training loss: 3.1464240550994873
2025-12-09 12:07:34.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 1.6689574843694434e-05 Training loss: 2.938363790512085
2025-12-09 12:07:34.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 1.53347579691272e-05 Training loss: 3.122175931930542
2025-12-09 12:07:34.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 1.4036428473624019e-05 Training loss: 2.916015625
2025-12-09 12:07:34.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 1.2794737676536993e-05 Training loss: 2.803297519683838
2025-12-09 12:07:34.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 1.1609830296019142e-05 Training loss: 2.8586740493774414
2025-12-09 12:07:34.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 1.048184443215816e-05 Training loss: 3.139516592025757
2025-12-09 12:07:34.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.410911550880474e-06 Training loss: 3.0074973106384277
2025-12-09 12:07:34.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 8.397156468629207e-06 Training loss: 2.8618204593658447
2025-12-09 12:07:34.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 7.440697337816771e-06 Training loss: 2.9199278354644775
2025-12-09 12:07:35.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 6.541645633054649e-06 Training loss: 3.118321657180786
2025-12-09 12:07:35.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 5.700106138160688e-06 Training loss: 2.811218738555908
2025-12-09 12:07:35.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 4.916176933946692e-06 Training loss: 2.9558186531066895
2025-12-09 12:07:35.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 4.189949386787462e-06 Training loss: 2.941944122314453
2025-12-09 12:07:35.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 3.521508137971807e-06 Training loss: 2.940264940261841
2025-12-09 12:07:35.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 2.9109310938378875e-06 Training loss: 2.810718297958374
2025-12-09 12:07:35.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 2.3582894166930268e-06 Training loss: 3.0499019622802734
2025-12-09 12:07:35.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 1.8636475165200173e-06 Training loss: 3.021050214767456
2025-12-09 12:07:35.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 1.4270630434701782e-06 Training loss: 2.9467933177948
2025-12-09 12:07:35.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 1.0485868811441758e-06 Training loss: 2.797092914581299
2025-12-09 12:07:35.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 7.282631406615448e-07 Training loss: 3.004603147506714
2025-12-09 12:07:35.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 4.6612915551963455e-07 Training loss: 2.764779806137085
2025-12-09 12:07:35.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 2.6221547724253336e-07 Training loss: 2.968517541885376
2025-12-09 12:07:35.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 1.1654587182013953e-07 Training loss: 2.9317970275878906
2025-12-09 12:07:35.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 2.9137316938265823e-08 Training loss: 2.877230644226074
2025-12-09 12:07:35.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0 Training loss: 3.0553176403045654
