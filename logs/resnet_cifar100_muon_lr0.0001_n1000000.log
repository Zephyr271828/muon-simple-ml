2025-12-09 12:08:23.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 4.807416915893555
2025-12-09 12:08:23.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 4.884763240814209
2025-12-09 12:08:23.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 4.891476154327393
2025-12-09 12:08:23.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 4.913439750671387
2025-12-09 12:08:23.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 4.7699294090271
2025-12-09 12:08:23.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 4.898793697357178
2025-12-09 12:08:23.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 4.819169521331787
2025-12-09 12:08:23.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 4.967755317687988
2025-12-09 12:08:23.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 4.811676502227783
2025-12-09 12:08:23.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 4.901790142059326
2025-12-09 12:08:23.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 4.706619739532471
2025-12-09 12:08:23.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 4.777202129364014
2025-12-09 12:08:23.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 4.894384384155273
2025-12-09 12:08:23.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 4.827633857727051
2025-12-09 12:08:23.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 4.795583724975586
2025-12-09 12:08:23.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 4.842196941375732
2025-12-09 12:08:23.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 4.92041540145874
2025-12-09 12:08:23.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 4.933459758758545
2025-12-09 12:08:23.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 4.806779384613037
2025-12-09 12:08:23.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 4.900381565093994
2025-12-09 12:08:23.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 4.919936656951904
2025-12-09 12:08:23.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 4.956502914428711
2025-12-09 12:08:23.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 4.77970552444458
2025-12-09 12:08:23.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 4.825094699859619
2025-12-09 12:08:23.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 4.897058010101318
2025-12-09 12:08:23.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 4.80316162109375
2025-12-09 12:08:23.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 4.983546733856201
2025-12-09 12:08:23.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 4.871586322784424
2025-12-09 12:08:23.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 4.913790702819824
2025-12-09 12:08:23.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 4.749074459075928
2025-12-09 12:08:23.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 4.6440348625183105
2025-12-09 12:08:23.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 4.9014973640441895
2025-12-09 12:08:23.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 4.864341735839844
2025-12-09 12:08:23.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 4.7923970222473145
2025-12-09 12:08:23.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 4.745015621185303
2025-12-09 12:08:24.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 4.854106903076172
2025-12-09 12:08:24.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 4.845688819885254
2025-12-09 12:08:24.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 4.8679094314575195
2025-12-09 12:08:24.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 4.877035617828369
2025-12-09 12:08:24.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 4.94230842590332
2025-12-09 12:08:24.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 5.0008063316345215
2025-12-09 12:08:24.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 4.858883857727051
2025-12-09 12:08:24.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 4.813955307006836
2025-12-09 12:08:24.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 4.745957374572754
2025-12-09 12:08:24.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 4.959157943725586
2025-12-09 12:08:24.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 4.75170373916626
2025-12-09 12:08:24.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 4.942490577697754
2025-12-09 12:08:24.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 4.9015583992004395
2025-12-09 12:08:24.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 4.889211177825928
2025-12-09 12:08:24.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 4.773494243621826
2025-12-09 12:08:24.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 4.716901779174805
2025-12-09 12:08:24.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 4.764179706573486
2025-12-09 12:08:24.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 4.733688831329346
2025-12-09 12:08:24.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 4.903561115264893
2025-12-09 12:08:24.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 4.808925151824951
2025-12-09 12:08:24.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 4.716157913208008
2025-12-09 12:08:24.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 4.88922119140625
2025-12-09 12:08:24.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 4.776815414428711
2025-12-09 12:08:24.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 4.769846439361572
2025-12-09 12:08:24.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 4.919809818267822
2025-12-09 12:08:24.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 4.708305835723877
2025-12-09 12:08:24.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 4.734050750732422
2025-12-09 12:08:24.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 4.764756202697754
2025-12-09 12:08:24.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 4.811374664306641
2025-12-09 12:08:24.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 4.700167179107666
2025-12-09 12:08:24.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 4.849527835845947
2025-12-09 12:08:24.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 4.830898284912109
2025-12-09 12:08:24.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 4.87635612487793
2025-12-09 12:08:24.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 4.749935150146484
2025-12-09 12:08:24.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 4.781463623046875
2025-12-09 12:08:24.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 4.916378974914551
2025-12-09 12:08:25.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 4.785304069519043
2025-12-09 12:08:25.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 4.820451736450195
2025-12-09 12:08:25.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 4.859490871429443
2025-12-09 12:08:25.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 4.9258270263671875
2025-12-09 12:08:25.113 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 4.858382701873779
2025-12-09 12:08:25.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 4.712160587310791
2025-12-09 12:08:25.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 4.798151016235352
2025-12-09 12:08:25.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 4.771055221557617
2025-12-09 12:08:25.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 4.701242446899414
2025-12-09 12:08:25.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 4.6314520835876465
2025-12-09 12:08:25.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 4.759357452392578
2025-12-09 12:08:25.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 4.82227087020874
2025-12-09 12:08:25.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 4.871768951416016
2025-12-09 12:08:25.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 4.796668529510498
2025-12-09 12:08:25.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 4.790532112121582
2025-12-09 12:08:25.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 4.781465530395508
2025-12-09 12:08:25.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 4.8421525955200195
2025-12-09 12:08:25.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 4.805006504058838
2025-12-09 12:08:25.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 4.7216362953186035
2025-12-09 12:08:25.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 4.704891681671143
2025-12-09 12:08:25.547 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 4.808255195617676
2025-12-09 12:08:25.574 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 4.7424516677856445
2025-12-09 12:08:25.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 4.705361366271973
2025-12-09 12:08:25.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 4.726911544799805
2025-12-09 12:08:25.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 4.6797661781311035
2025-12-09 12:08:25.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 4.738581657409668
2025-12-09 12:08:25.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 4.670316219329834
2025-12-09 12:08:25.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 4.78372859954834
2025-12-09 12:08:25.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 4.686532497406006
2025-12-09 12:08:25.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.999708626830618e-05 Training loss: 4.746339797973633
2025-12-09 12:08:25.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 9.998834541281798e-05 Training loss: 4.714141845703125
2025-12-09 12:08:25.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 9.997377845227576e-05 Training loss: 4.6724853515625
2025-12-09 12:08:25.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 9.995338708444804e-05 Training loss: 4.709565162658691
2025-12-09 12:08:25.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 9.992717368593385e-05 Training loss: 4.715757369995117
2025-12-09 12:08:25.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 9.989514131188559e-05 Training loss: 4.64192533493042
2025-12-09 12:08:25.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 9.985729369565299e-05 Training loss: 4.679233551025391
2025-12-09 12:08:25.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 9.9813635248348e-05 Training loss: 4.670106410980225
2025-12-09 12:08:26.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 9.97641710583307e-05 Training loss: 4.658885955810547
2025-12-09 12:08:26.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 9.970890689061622e-05 Training loss: 4.606276988983154
2025-12-09 12:08:26.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 9.964784918620282e-05 Training loss: 4.737740993499756
2025-12-09 12:08:26.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 9.958100506132127e-05 Training loss: 4.566539287567139
2025-12-09 12:08:26.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 9.950838230660534e-05 Training loss: 4.6801652908325195
2025-12-09 12:08:26.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 9.942998938618394e-05 Training loss: 4.560304641723633
2025-12-09 12:08:26.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 9.934583543669453e-05 Training loss: 4.595900535583496
2025-12-09 12:08:26.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 9.925593026621833e-05 Training loss: 4.5907135009765625
2025-12-09 12:08:26.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 9.916028435313708e-05 Training loss: 4.586472988128662
2025-12-09 12:08:26.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 9.905890884491195e-05 Training loss: 4.54141092300415
2025-12-09 12:08:26.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 9.895181555678418e-05 Training loss: 4.518231391906738
2025-12-09 12:08:26.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 9.883901697039808e-05 Training loss: 4.574387550354004
2025-12-09 12:08:26.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 9.872052623234632e-05 Training loss: 4.55807638168335
2025-12-09 12:08:26.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 9.85963571526376e-05 Training loss: 4.612545013427734
2025-12-09 12:08:26.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 9.846652420308728e-05 Training loss: 4.56686544418335
2025-12-09 12:08:26.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 9.833104251563056e-05 Training loss: 4.591782569885254
2025-12-09 12:08:26.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 9.818992788055889e-05 Training loss: 4.505134105682373
2025-12-09 12:08:26.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 9.80431967446797e-05 Training loss: 4.648963451385498
2025-12-09 12:08:26.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 9.789086620939936e-05 Training loss: 4.637988090515137
2025-12-09 12:08:26.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 9.773295402873026e-05 Training loss: 4.534299373626709
2025-12-09 12:08:26.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 9.756947860722143e-05 Training loss: 4.6846160888671875
2025-12-09 12:08:26.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 9.740045899781352e-05 Training loss: 4.59594202041626
2025-12-09 12:08:26.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 9.722591489961827e-05 Training loss: 4.57163143157959
2025-12-09 12:08:26.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 9.70458666556225e-05 Training loss: 4.581573963165283
2025-12-09 12:08:26.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 9.686033525031719e-05 Training loss: 4.5798749923706055
2025-12-09 12:08:26.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 9.66693423072518e-05 Training loss: 4.689960479736328
2025-12-09 12:08:26.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 9.647291008651398e-05 Training loss: 4.535506248474121
2025-12-09 12:08:26.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 9.627106148213522e-05 Training loss: 4.509089469909668
2025-12-09 12:08:26.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 9.606382001942255e-05 Training loss: 4.651177883148193
2025-12-09 12:08:26.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 9.585120985221671e-05 Training loss: 4.665130615234375
2025-12-09 12:08:26.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 9.563325576007701e-05 Training loss: 4.48229455947876
2025-12-09 12:08:26.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 9.540998314539328e-05 Training loss: 4.656438827514648
2025-12-09 12:08:26.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 9.518141803042527e-05 Training loss: 4.657026290893555
2025-12-09 12:08:26.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 9.494758705426978e-05 Training loss: 4.551095485687256
2025-12-09 12:08:26.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 9.470851746975582e-05 Training loss: 4.5218281745910645
2025-12-09 12:08:26.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 9.446423714026846e-05 Training loss: 4.5097975730896
2025-12-09 12:08:26.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 9.421477453650118e-05 Training loss: 4.709960460662842
2025-12-09 12:08:27.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 9.396015873313781e-05 Training loss: 4.47311544418335
2025-12-09 12:08:27.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 9.37004194054638e-05 Training loss: 4.543660640716553
2025-12-09 12:08:27.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 9.343558682590756e-05 Training loss: 4.459718227386475
2025-12-09 12:08:27.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 9.316569186051234e-05 Training loss: 4.596447467803955
2025-12-09 12:08:27.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 9.289076596533872e-05 Training loss: 4.550669193267822
2025-12-09 12:08:27.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 9.261084118279847e-05 Training loss: 4.472076416015625
2025-12-09 12:08:27.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 9.232595013792002e-05 Training loss: 4.4716410636901855
2025-12-09 12:08:27.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 9.203612603454604e-05 Training loss: 4.491650104522705
2025-12-09 12:08:27.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 9.174140265146356e-05 Training loss: 4.59637975692749
2025-12-09 12:08:27.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 9.144181433846707e-05 Training loss: 4.499828815460205
2025-12-09 12:08:27.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 9.113739601235507e-05 Training loss: 4.4388651847839355
2025-12-09 12:08:27.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 9.082818315286055e-05 Training loss: 4.493859767913818
2025-12-09 12:08:27.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 9.051421179851588e-05 Training loss: 4.41414213180542
2025-12-09 12:08:27.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 9.01955185424525e-05 Training loss: 4.602511882781982
2025-12-09 12:08:27.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 8.987214052813604e-05 Training loss: 4.541841506958008
2025-12-09 12:08:27.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 8.954411544503729e-05 Training loss: 4.5359673500061035
2025-12-09 12:08:27.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 8.921148152423946e-05 Training loss: 4.432968616485596
2025-12-09 12:08:27.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 8.887427753398248e-05 Training loss: 4.482220649719238
2025-12-09 12:08:27.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 8.853254277514446e-05 Training loss: 4.388469696044922
2025-12-09 12:08:27.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 8.818631707666135e-05 Training loss: 4.650068283081055
2025-12-09 12:08:27.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 8.783564079088477e-05 Training loss: 4.488872051239014
2025-12-09 12:08:27.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 8.748055478887904e-05 Training loss: 4.524272918701172
2025-12-09 12:08:27.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 8.712110045565768e-05 Training loss: 4.434693336486816
2025-12-09 12:08:27.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 8.675731968536002e-05 Training loss: 4.540933609008789
2025-12-09 12:08:27.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 8.638925487636848e-05 Training loss: 4.466912269592285
2025-12-09 12:08:27.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 8.6016948926367e-05 Training loss: 4.328950881958008
2025-12-09 12:08:27.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 8.564044522734147e-05 Training loss: 4.3315839767456055
2025-12-09 12:08:27.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 8.52597876605223e-05 Training loss: 4.499574661254883
2025-12-09 12:08:27.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 8.487502059127015e-05 Training loss: 4.451755046844482
2025-12-09 12:08:27.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 8.448618886390522e-05 Training loss: 4.643527030944824
2025-12-09 12:08:27.831 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 8.40933377964806e-05 Training loss: 4.406239986419678
2025-12-09 12:08:27.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 8.369651317550054e-05 Training loss: 4.522305011749268
2025-12-09 12:08:27.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 8.329576125058406e-05 Training loss: 4.469662189483643
2025-12-09 12:08:27.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 8.289112872907454e-05 Training loss: 4.477057456970215
2025-12-09 12:08:27.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 8.248266277059607e-05 Training loss: 4.428930282592773
2025-12-09 12:08:27.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 8.2070410981557e-05 Training loss: 4.585470199584961
2025-12-09 12:08:27.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 8.16544214096015e-05 Training loss: 4.374366283416748
2025-12-09 12:08:28.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 8.123474253800957e-05 Training loss: 4.5215301513671875
2025-12-09 12:08:28.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 8.081142328004637e-05 Training loss: 4.453728199005127
2025-12-09 12:08:28.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 8.038451297326145e-05 Training loss: 4.306363582611084
2025-12-09 12:08:28.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 7.995406137373846e-05 Training loss: 4.580838680267334
2025-12-09 12:08:28.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 7.952011865029614e-05 Training loss: 4.458127498626709
2025-12-09 12:08:28.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 7.908273537864113e-05 Training loss: 4.460531711578369
2025-12-09 12:08:28.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 7.86419625354735e-05 Training loss: 4.401713848114014
2025-12-09 12:08:28.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 7.819785149254532e-05 Training loss: 4.441482067108154
2025-12-09 12:08:28.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 7.77504540106735e-05 Training loss: 4.472036361694336
2025-12-09 12:08:28.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 7.729982223370691e-05 Training loss: 4.37354850769043
2025-12-09 12:08:28.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 7.68460086824492e-05 Training loss: 4.4514241218566895
2025-12-09 12:08:28.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 7.638906624853743e-05 Training loss: 4.333474636077881
2025-12-09 12:08:28.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 7.592904818827775e-05 Training loss: 4.4419732093811035
2025-12-09 12:08:28.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 7.546600811643816e-05 Training loss: 4.469165802001953
2025-12-09 12:08:28.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 7.500000000000001e-05 Training loss: 4.481315612792969
2025-12-09 12:08:28.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 7.453107815186803e-05 Training loss: 4.29518461227417
2025-12-09 12:08:28.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 7.405929722454026e-05 Training loss: 4.473886489868164
2025-12-09 12:08:28.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 7.358471220373832e-05 Training loss: 4.429542064666748
2025-12-09 12:08:28.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 7.310737840199885e-05 Training loss: 4.350740909576416
2025-12-09 12:08:28.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 7.262735145222696e-05 Training loss: 4.34218692779541
2025-12-09 12:08:28.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 7.214468730121208e-05 Training loss: 4.453068733215332
2025-12-09 12:08:28.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 7.165944220310767e-05 Training loss: 4.399875164031982
2025-12-09 12:08:28.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 7.117167271287453e-05 Training loss: 4.334104537963867
2025-12-09 12:08:28.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 7.068143567968957e-05 Training loss: 4.385180473327637
2025-12-09 12:08:28.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 7.018878824032009e-05 Training loss: 4.437130451202393
2025-12-09 12:08:28.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 6.969378781246436e-05 Training loss: 4.483096122741699
2025-12-09 12:08:28.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 6.919649208805981e-05 Training loss: 4.3670244216918945
2025-12-09 12:08:28.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 6.869695902655897e-05 Training loss: 4.26228666305542
2025-12-09 12:08:28.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 6.819524684817438e-05 Training loss: 4.286706447601318
2025-12-09 12:08:28.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 6.769141402709305e-05 Training loss: 4.402121543884277
2025-12-09 12:08:28.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 6.718551928466132e-05 Training loss: 4.350619792938232
2025-12-09 12:08:28.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 6.667762158254104e-05 Training loss: 4.474886417388916
2025-12-09 12:08:28.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 6.616778011583743e-05 Training loss: 4.416744232177734
2025-12-09 12:08:28.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 6.565605430620013e-05 Training loss: 4.247434616088867
2025-12-09 12:08:28.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 6.514250379489753e-05 Training loss: 4.432190895080566
2025-12-09 12:08:28.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 6.462718843586571e-05 Training loss: 4.261624813079834
2025-12-09 12:08:29.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 6.411016828873239e-05 Training loss: 4.41459321975708
2025-12-09 12:08:29.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 6.359150361181715e-05 Training loss: 4.299952507019043
2025-12-09 12:08:29.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 6.307125485510828e-05 Training loss: 4.44692325592041
2025-12-09 12:08:29.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 6.254948265321744e-05 Training loss: 4.428693771362305
2025-12-09 12:08:29.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 6.202624781831268e-05 Training loss: 4.375356197357178
2025-12-09 12:08:29.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 6.150161133303089e-05 Training loss: 4.3486433029174805
2025-12-09 12:08:29.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 6.0975634343370256e-05 Training loss: 4.400364398956299
2025-12-09 12:08:29.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 6.044837815156377e-05 Training loss: 4.418776035308838
2025-12-09 12:08:29.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 5.99199042089345e-05 Training loss: 4.318648338317871
2025-12-09 12:08:29.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 5.939027410873351e-05 Training loss: 4.306934833526611
2025-12-09 12:08:29.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 5.885954957896115e-05 Training loss: 4.432824611663818
2025-12-09 12:08:29.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 5.832779247517273e-05 Training loss: 4.416925430297852
2025-12-09 12:08:29.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 5.779506477326933e-05 Training loss: 4.366994380950928
2025-12-09 12:08:29.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 5.726142856227452e-05 Training loss: 4.374678611755371
2025-12-09 12:08:29.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 5.672694603709794e-05 Training loss: 4.2907280921936035
2025-12-09 12:08:29.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 5.619167949128652e-05 Training loss: 4.450795650482178
2025-12-09 12:08:29.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 5.565569130976422e-05 Training loss: 4.431904315948486
2025-12-09 12:08:29.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 5.5119043961561136e-05 Training loss: 4.277616024017334
2025-12-09 12:08:29.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 5.458179999253275e-05 Training loss: 4.299601078033447
2025-12-09 12:08:29.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 5.4044022018070214e-05 Training loss: 4.381418228149414
2025-12-09 12:08:29.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 5.3505772715802704e-05 Training loss: 4.29187536239624
2025-12-09 12:08:29.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 5.296711481829226e-05 Training loss: 4.458838939666748
2025-12-09 12:08:29.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 5.242811110572242e-05 Training loss: 4.306499004364014
2025-12-09 12:08:29.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 5.188882439858117e-05 Training loss: 4.407374382019043
2025-12-09 12:08:29.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 5.134931755033936e-05 Training loss: 4.243475437164307
2025-12-09 12:08:29.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 5.080965344012508e-05 Training loss: 4.219301700592041
2025-12-09 12:08:29.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 5.0269894965395225e-05 Training loss: 4.247928619384766
2025-12-09 12:08:29.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 4.973010503460479e-05 Training loss: 4.170760631561279
2025-12-09 12:08:29.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 4.919034655987493e-05 Training loss: 4.181494235992432
2025-12-09 12:08:29.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 4.865068244966066e-05 Training loss: 4.244619846343994
2025-12-09 12:08:29.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 4.8111175601418844e-05 Training loss: 4.455161094665527
2025-12-09 12:08:29.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 4.7571888894277604e-05 Training loss: 4.388850688934326
2025-12-09 12:08:29.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 4.703288518170774e-05 Training loss: 4.250951766967773
2025-12-09 12:08:29.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 4.6494227284197294e-05 Training loss: 4.306222438812256
2025-12-09 12:08:29.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 4.59559779819298e-05 Training loss: 4.372572898864746
2025-12-09 12:08:29.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 4.541820000746727e-05 Training loss: 4.270666122436523
2025-12-09 12:08:29.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 4.4880956038438876e-05 Training loss: 4.4165778160095215
2025-12-09 12:08:30.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 4.434430869023579e-05 Training loss: 4.197596549987793
2025-12-09 12:08:30.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 4.38083205087135e-05 Training loss: 4.240001201629639
2025-12-09 12:08:30.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 4.3273053962902076e-05 Training loss: 4.12797737121582
2025-12-09 12:08:30.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 4.27385714377255e-05 Training loss: 4.398800849914551
2025-12-09 12:08:30.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 4.220493522673067e-05 Training loss: 4.210813999176025
2025-12-09 12:08:30.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 4.1672207524827275e-05 Training loss: 4.399049758911133
2025-12-09 12:08:30.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 4.114045042103887e-05 Training loss: 4.282647132873535
2025-12-09 12:08:30.207 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 4.06097258912665e-05 Training loss: 4.365235805511475
2025-12-09 12:08:30.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 4.0080095791065505e-05 Training loss: 4.251132965087891
2025-12-09 12:08:30.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 3.955162184843625e-05 Training loss: 4.192480087280273
2025-12-09 12:08:30.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 3.902436565662977e-05 Training loss: 4.237423896789551
2025-12-09 12:08:30.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 3.849838866696913e-05 Training loss: 4.458807468414307
2025-12-09 12:08:30.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 3.7973752181687335e-05 Training loss: 4.2835869789123535
2025-12-09 12:08:30.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 3.745051734678256e-05 Training loss: 4.367833614349365
2025-12-09 12:08:30.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 3.692874514489173e-05 Training loss: 4.288788318634033
2025-12-09 12:08:30.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 3.640849638818286e-05 Training loss: 4.369898319244385
2025-12-09 12:08:30.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 3.588983171126762e-05 Training loss: 4.283475875854492
2025-12-09 12:08:30.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 3.53728115641343e-05 Training loss: 4.277584552764893
2025-12-09 12:08:30.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 3.4857496205102474e-05 Training loss: 4.278965473175049
2025-12-09 12:08:30.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 3.434394569379988e-05 Training loss: 4.288785457611084
2025-12-09 12:08:30.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 3.3832219884162585e-05 Training loss: 4.435842514038086
2025-12-09 12:08:30.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 3.332237841745898e-05 Training loss: 4.3075785636901855
2025-12-09 12:08:30.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 3.281448071533867e-05 Training loss: 4.215269565582275
2025-12-09 12:08:30.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 3.2308585972906966e-05 Training loss: 4.170616149902344
2025-12-09 12:08:30.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 3.180475315182563e-05 Training loss: 4.301338195800781
2025-12-09 12:08:30.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 3.130304097344103e-05 Training loss: 4.179366588592529
2025-12-09 12:08:30.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 3.080350791194019e-05 Training loss: 4.391659736633301
2025-12-09 12:08:30.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 3.0306212187535653e-05 Training loss: 4.330071449279785
2025-12-09 12:08:30.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 2.9811211759679924e-05 Training loss: 4.250441074371338
2025-12-09 12:08:30.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 2.9318564320310444e-05 Training loss: 4.315998077392578
2025-12-09 12:08:30.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 2.882832728712551e-05 Training loss: 4.303674697875977
2025-12-09 12:08:30.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 2.8340557796892354e-05 Training loss: 4.170159339904785
2025-12-09 12:08:30.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 2.7855312698787904e-05 Training loss: 4.36315393447876
2025-12-09 12:08:30.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 2.737264854777306e-05 Training loss: 4.362024307250977
2025-12-09 12:08:30.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 2.6892621598001156e-05 Training loss: 4.256870269775391
2025-12-09 12:08:30.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 2.6415287796261706e-05 Training loss: 4.355503559112549
2025-12-09 12:08:31.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 2.5940702775459747e-05 Training loss: 4.371674537658691
2025-12-09 12:08:31.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 2.5468921848131983e-05 Training loss: 4.289384841918945
2025-12-09 12:08:31.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 2.500000000000001e-05 Training loss: 4.291182518005371
2025-12-09 12:08:31.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 2.4533991883561868e-05 Training loss: 4.293264389038086
2025-12-09 12:08:31.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 2.407095181172227e-05 Training loss: 4.11835241317749
2025-12-09 12:08:31.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 2.3610933751462553e-05 Training loss: 4.303590774536133
2025-12-09 12:08:31.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 2.315399131755081e-05 Training loss: 4.277817726135254
2025-12-09 12:08:31.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 2.2700177766293096e-05 Training loss: 4.378958702087402
2025-12-09 12:08:31.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 2.2249545989326514e-05 Training loss: 4.370800018310547
2025-12-09 12:08:31.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 2.180214850745467e-05 Training loss: 4.209883689880371
2025-12-09 12:08:31.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 2.1358037464526515e-05 Training loss: 4.3177595138549805
2025-12-09 12:08:31.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 2.091726462135888e-05 Training loss: 4.307745456695557
2025-12-09 12:08:31.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 2.0479881349703883e-05 Training loss: 4.14977502822876
2025-12-09 12:08:31.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 2.0045938626261546e-05 Training loss: 4.1724371910095215
2025-12-09 12:08:31.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 1.9615487026738543e-05 Training loss: 4.219072341918945
2025-12-09 12:08:31.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 1.9188576719953633e-05 Training loss: 4.310133934020996
2025-12-09 12:08:31.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 1.8765257461990442e-05 Training loss: 4.301385879516602
2025-12-09 12:08:31.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 1.834557859039851e-05 Training loss: 4.276269435882568
2025-12-09 12:08:31.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 1.7929589018443016e-05 Training loss: 4.2066497802734375
2025-12-09 12:08:31.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 1.7517337229403946e-05 Training loss: 4.223169803619385
2025-12-09 12:08:31.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 1.710887127092548e-05 Training loss: 4.204423427581787
2025-12-09 12:08:31.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 1.6704238749415957e-05 Training loss: 4.246867656707764
2025-12-09 12:08:31.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 1.6303486824499458e-05 Training loss: 4.20657205581665
2025-12-09 12:08:31.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 1.5906662203519412e-05 Training loss: 4.356269836425781
2025-12-09 12:08:31.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 1.5513811136094787e-05 Training loss: 4.248010635375977
2025-12-09 12:08:31.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 1.5124979408729861e-05 Training loss: 4.33681058883667
2025-12-09 12:08:31.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 1.4740212339477721e-05 Training loss: 4.208827972412109
2025-12-09 12:08:31.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 1.4359554772658552e-05 Training loss: 4.248037815093994
2025-12-09 12:08:31.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 1.3983051073632997e-05 Training loss: 4.142782211303711
2025-12-09 12:08:31.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 1.3610745123631535e-05 Training loss: 4.133360385894775
2025-12-09 12:08:31.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 1.3242680314639993e-05 Training loss: 4.395676136016846
2025-12-09 12:08:31.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 1.2878899544342327e-05 Training loss: 4.203537940979004
2025-12-09 12:08:31.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 1.2519445211120979e-05 Training loss: 4.255921840667725
2025-12-09 12:08:31.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 1.2164359209115234e-05 Training loss: 4.277631759643555
2025-12-09 12:08:31.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 1.1813682923338653e-05 Training loss: 4.28942346572876
2025-12-09 12:08:32.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 1.1467457224855544e-05 Training loss: 4.322581768035889
2025-12-09 12:08:32.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 1.1125722466017547e-05 Training loss: 4.174400329589844
2025-12-09 12:08:32.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 1.0788518475760545e-05 Training loss: 4.291229248046875
2025-12-09 12:08:32.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 1.0455884554962725e-05 Training loss: 4.175118446350098
2025-12-09 12:08:32.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 1.012785947186397e-05 Training loss: 4.286608695983887
2025-12-09 12:08:32.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 9.804481457547498e-06 Training loss: 4.324318885803223
2025-12-09 12:08:32.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 9.485788201484126e-06 Training loss: 4.256133079528809
2025-12-09 12:08:32.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 9.171816847139448e-06 Training loss: 4.233741760253906
2025-12-09 12:08:32.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 8.86260398764494e-06 Training loss: 4.280683994293213
2025-12-09 12:08:32.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 8.558185661532941e-06 Training loss: 4.337381362915039
2025-12-09 12:08:32.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 8.25859734853645e-06 Training loss: 4.304214954376221
2025-12-09 12:08:32.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 7.96387396545396e-06 Training loss: 4.333521842956543
2025-12-09 12:08:32.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 7.67404986207999e-06 Training loss: 4.1822967529296875
2025-12-09 12:08:32.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 7.389158817201542e-06 Training loss: 4.398521900177002
2025-12-09 12:08:32.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 7.109234034661289e-06 Training loss: 4.171009540557861
2025-12-09 12:08:32.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 6.8343081394876715e-06 Training loss: 4.3329644203186035
2025-12-09 12:08:32.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 6.564413174092443e-06 Training loss: 4.3712286949157715
2025-12-09 12:08:32.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 6.299580594536214e-06 Training loss: 4.166014194488525
2025-12-09 12:08:32.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 6.0398412668621895e-06 Training loss: 4.298115253448486
2025-12-09 12:08:32.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 5.785225463498828e-06 Training loss: 4.302985668182373
2025-12-09 12:08:32.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 5.535762859731547e-06 Training loss: 4.109285354614258
2025-12-09 12:08:32.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 5.291482530244179e-06 Training loss: 4.1128740310668945
2025-12-09 12:08:32.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 5.05241294573024e-06 Training loss: 4.284399032592773
2025-12-09 12:08:32.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 4.818581969574742e-06 Training loss: 4.124522686004639
2025-12-09 12:08:32.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 4.590016854606727e-06 Training loss: 4.21868371963501
2025-12-09 12:08:32.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 4.366744239922998e-06 Training loss: 4.32699728012085
2025-12-09 12:08:32.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 4.148790147783288e-06 Training loss: 4.147897243499756
2025-12-09 12:08:32.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 3.936179980577453e-06 Training loss: 4.269458770751953
2025-12-09 12:08:32.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 3.728938517864794e-06 Training loss: 4.156815528869629
2025-12-09 12:08:32.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 3.527089913486037e-06 Training loss: 4.073634147644043
2025-12-09 12:08:32.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 3.3306576927482126e-06 Training loss: 4.178506374359131
2025-12-09 12:08:32.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 3.1396647496828247e-06 Training loss: 4.256709098815918
2025-12-09 12:08:32.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 2.9541333443775243e-06 Training loss: 4.278628826141357
2025-12-09 12:08:32.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 2.774085100381735e-06 Training loss: 4.175690174102783
2025-12-09 12:08:32.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 2.5995410021864787e-06 Training loss: 4.122504234313965
2025-12-09 12:08:32.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 2.430521392778573e-06 Training loss: 4.1902875900268555
2025-12-09 12:08:33.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 2.2670459712697377e-06 Training loss: 4.17415189743042
2025-12-09 12:08:33.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 2.1091337906006482e-06 Training loss: 4.1553449630737305
2025-12-09 12:08:33.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 1.956803255320322e-06 Training loss: 4.198418140411377
2025-12-09 12:08:33.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 1.810072119441103e-06 Training loss: 4.349740028381348
2025-12-09 12:08:33.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 1.6689574843694433e-06 Training loss: 4.196045875549316
2025-12-09 12:08:33.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 1.53347579691272e-06 Training loss: 4.235924243927002
2025-12-09 12:08:33.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 1.4036428473624019e-06 Training loss: 4.196152210235596
2025-12-09 12:08:33.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 1.2794737676536994e-06 Training loss: 4.136143684387207
2025-12-09 12:08:33.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 1.1609830296019143e-06 Training loss: 4.2739081382751465
2025-12-09 12:08:33.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 1.0481844432158161e-06 Training loss: 4.224211692810059
2025-12-09 12:08:33.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.410911550880475e-07 Training loss: 4.104203224182129
2025-12-09 12:08:33.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 8.397156468629208e-07 Training loss: 4.204704761505127
2025-12-09 12:08:33.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 7.44069733781677e-07 Training loss: 4.219138145446777
2025-12-09 12:08:33.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 6.54164563305465e-07 Training loss: 4.364266872406006
2025-12-09 12:08:33.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 5.700106138160688e-07 Training loss: 4.356906414031982
2025-12-09 12:08:33.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 4.916176933946693e-07 Training loss: 4.101128101348877
2025-12-09 12:08:33.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 4.189949386787462e-07 Training loss: 4.292298793792725
2025-12-09 12:08:33.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 3.5215081379718074e-07 Training loss: 4.27244758605957
2025-12-09 12:08:33.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 2.9109310938378877e-07 Training loss: 4.191623210906982
2025-12-09 12:08:33.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 2.3582894166930268e-07 Training loss: 4.150076389312744
2025-12-09 12:08:33.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 1.8636475165200174e-07 Training loss: 4.297043800354004
2025-12-09 12:08:33.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 1.427063043470178e-07 Training loss: 4.18207311630249
2025-12-09 12:08:33.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 1.0485868811441757e-07 Training loss: 4.243820667266846
2025-12-09 12:08:33.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 7.282631406615447e-08 Training loss: 4.379822254180908
2025-12-09 12:08:33.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 4.661291555196345e-08 Training loss: 4.247375965118408
2025-12-09 12:08:33.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 2.6221547724253337e-08 Training loss: 4.351202011108398
2025-12-09 12:08:33.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 1.1654587182013953e-08 Training loss: 4.295895576477051
2025-12-09 12:08:33.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 2.9137316938265825e-09 Training loss: 4.30062198638916
2025-12-09 12:08:33.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0 Training loss: 4.13051176071167
