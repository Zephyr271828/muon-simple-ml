2025-12-09 12:03:10.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 9.209024429321289
2025-12-09 12:03:10.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 9.209566116333008
2025-12-09 12:03:10.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 9.209246635437012
2025-12-09 12:03:10.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 9.20930004119873
2025-12-09 12:03:10.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 9.210488319396973
2025-12-09 12:03:10.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 9.209168434143066
2025-12-09 12:03:10.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 9.209073066711426
2025-12-09 12:03:10.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 9.208855628967285
2025-12-09 12:03:10.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 9.208351135253906
2025-12-09 12:03:10.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 9.20811939239502
2025-12-09 12:03:10.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 9.20893383026123
2025-12-09 12:03:10.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 9.207524299621582
2025-12-09 12:03:11.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 9.207283020019531
2025-12-09 12:03:11.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 9.207274436950684
2025-12-09 12:03:11.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 9.206236839294434
2025-12-09 12:03:11.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 9.206640243530273
2025-12-09 12:03:11.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 9.205229759216309
2025-12-09 12:03:11.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 9.205496788024902
2025-12-09 12:03:11.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 9.204668998718262
2025-12-09 12:03:11.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 9.20315170288086
2025-12-09 12:03:11.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 9.202880859375
2025-12-09 12:03:11.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 9.201762199401855
2025-12-09 12:03:11.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 9.20173168182373
2025-12-09 12:03:11.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 9.200715065002441
2025-12-09 12:03:11.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 9.199572563171387
2025-12-09 12:03:11.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 9.199329376220703
2025-12-09 12:03:11.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 9.198172569274902
2025-12-09 12:03:11.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 9.196495056152344
2025-12-09 12:03:11.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 9.195527076721191
2025-12-09 12:03:11.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 9.195600509643555
2025-12-09 12:03:11.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 9.195064544677734
2025-12-09 12:03:11.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 9.19383430480957
2025-12-09 12:03:11.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 9.191217422485352
2025-12-09 12:03:11.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 9.186532020568848
2025-12-09 12:03:11.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 9.187793731689453
2025-12-09 12:03:11.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 9.188499450683594
2025-12-09 12:03:11.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 9.187067031860352
2025-12-09 12:03:11.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 9.183317184448242
2025-12-09 12:03:11.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 9.1834135055542
2025-12-09 12:03:11.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 9.180062294006348
2025-12-09 12:03:11.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 9.177169799804688
2025-12-09 12:03:11.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 9.176996231079102
2025-12-09 12:03:11.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 9.171857833862305
2025-12-09 12:03:11.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 9.172595977783203
2025-12-09 12:03:11.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 9.16873836517334
2025-12-09 12:03:11.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 9.160918235778809
2025-12-09 12:03:11.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 9.160917282104492
2025-12-09 12:03:11.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 9.158665657043457
2025-12-09 12:03:11.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 9.154533386230469
2025-12-09 12:03:11.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 9.152827262878418
2025-12-09 12:03:11.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 9.14614486694336
2025-12-09 12:03:11.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 9.14345932006836
2025-12-09 12:03:11.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 9.139439582824707
2025-12-09 12:03:11.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 9.135503768920898
2025-12-09 12:03:11.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 9.1261568069458
2025-12-09 12:03:11.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 9.118470191955566
2025-12-09 12:03:11.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 9.109370231628418
2025-12-09 12:03:11.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 9.096487045288086
2025-12-09 12:03:11.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 9.089252471923828
2025-12-09 12:03:11.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 9.055608749389648
2025-12-09 12:03:11.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 9.048818588256836
2025-12-09 12:03:11.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 9.042821884155273
2025-12-09 12:03:11.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 9.013386726379395
2025-12-09 12:03:11.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 8.993734359741211
2025-12-09 12:03:11.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 8.981754302978516
2025-12-09 12:03:11.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 8.9314603805542
2025-12-09 12:03:11.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 8.889989852905273
2025-12-09 12:03:11.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 8.833755493164062
2025-12-09 12:03:11.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 8.782258987426758
2025-12-09 12:03:11.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 8.69974422454834
2025-12-09 12:03:11.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 8.676621437072754
2025-12-09 12:03:11.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 8.597393989562988
2025-12-09 12:03:11.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 8.433536529541016
2025-12-09 12:03:11.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 8.402475357055664
2025-12-09 12:03:11.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 8.294014930725098
2025-12-09 12:03:12.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 8.235062599182129
2025-12-09 12:03:12.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 8.12389087677002
2025-12-09 12:03:12.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 8.055445671081543
2025-12-09 12:03:12.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 7.967375755310059
2025-12-09 12:03:12.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 7.882314682006836
2025-12-09 12:03:12.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 7.803153991699219
2025-12-09 12:03:12.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 7.746076583862305
2025-12-09 12:03:12.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 7.633280277252197
2025-12-09 12:03:12.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 7.593998908996582
2025-12-09 12:03:12.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 7.538854122161865
2025-12-09 12:03:12.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 7.461554527282715
2025-12-09 12:03:12.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 7.364379405975342
2025-12-09 12:03:12.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 7.399495601654053
2025-12-09 12:03:12.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 7.31929349899292
2025-12-09 12:03:12.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 7.257993221282959
2025-12-09 12:03:12.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 7.280298709869385
2025-12-09 12:03:12.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 7.212914943695068
2025-12-09 12:03:12.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 7.143744945526123
2025-12-09 12:03:12.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 7.169068336486816
2025-12-09 12:03:12.295 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 7.079456806182861
2025-12-09 12:03:12.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 7.08006477355957
2025-12-09 12:03:12.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 7.021658420562744
2025-12-09 12:03:12.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 7.015956401824951
2025-12-09 12:03:12.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 6.952155113220215
2025-12-09 12:03:12.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 6.956890106201172
2025-12-09 12:03:12.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.698463103929542e-05 Training loss: 6.95953369140625
2025-12-09 12:03:12.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 8.83022221559489e-05 Training loss: 6.933084011077881
2025-12-09 12:03:12.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 7.500000000000001e-05 Training loss: 6.908402919769287
2025-12-09 12:03:12.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 5.868240888334653e-05 Training loss: 6.955794334411621
2025-12-09 12:03:12.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 4.131759111665349e-05 Training loss: 6.827764511108398
2025-12-09 12:03:12.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 2.500000000000001e-05 Training loss: 6.91732120513916
2025-12-09 12:03:12.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 1.1697777844051105e-05 Training loss: 6.860717296600342
2025-12-09 12:03:12.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 3.0153689607045845e-06 Training loss: 6.893388748168945
2025-12-09 12:03:12.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0 Training loss: 6.77175760269165
