2025-12-09 09:44:58.978 | INFO     | __main__:train:20 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.02794075012207
2025-12-09 09:44:59.226 | INFO     | __main__:train:20 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.014616012573242
2025-12-09 09:44:59.466 | INFO     | __main__:train:20 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.013604164123535
2025-12-09 09:44:59.705 | INFO     | __main__:train:20 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 12.026618003845215
2025-12-09 09:44:59.945 | INFO     | __main__:train:20 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 12.030435562133789
2025-12-09 09:45:00.185 | INFO     | __main__:train:20 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 12.014780044555664
2025-12-09 09:45:00.426 | INFO     | __main__:train:20 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 12.017641067504883
2025-12-09 09:45:00.667 | INFO     | __main__:train:20 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 12.027512550354004
2025-12-09 09:45:00.908 | INFO     | __main__:train:20 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 12.037276268005371
2025-12-09 09:45:01.148 | INFO     | __main__:train:20 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 12.000923156738281
2025-12-09 09:45:01.389 | INFO     | __main__:train:20 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 12.01872730255127
2025-12-09 09:45:01.630 | INFO     | __main__:train:20 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 12.013433456420898
2025-12-09 09:45:01.870 | INFO     | __main__:train:20 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 12.00814151763916
2025-12-09 09:45:02.110 | INFO     | __main__:train:20 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 12.028107643127441
2025-12-09 09:45:02.352 | INFO     | __main__:train:20 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 12.018831253051758
2025-12-09 09:45:02.594 | INFO     | __main__:train:20 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 12.006763458251953
2025-12-09 09:45:02.835 | INFO     | __main__:train:20 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 12.010709762573242
2025-12-09 09:45:03.076 | INFO     | __main__:train:20 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 12.018917083740234
2025-12-09 09:45:03.319 | INFO     | __main__:train:20 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 12.00931167602539
2025-12-09 09:45:03.563 | INFO     | __main__:train:20 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 11.993416786193848
2025-12-09 09:45:03.806 | INFO     | __main__:train:20 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 11.985626220703125
2025-12-09 09:45:04.048 | INFO     | __main__:train:20 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 12.004792213439941
2025-12-09 09:45:04.290 | INFO     | __main__:train:20 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 11.98165512084961
2025-12-09 09:45:04.532 | INFO     | __main__:train:20 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 11.961620330810547
2025-12-09 09:45:04.774 | INFO     | __main__:train:20 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 11.983362197875977
2025-12-09 09:45:05.017 | INFO     | __main__:train:20 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 11.980844497680664
2025-12-09 09:45:05.259 | INFO     | __main__:train:20 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 11.970645904541016
2025-12-09 09:45:05.500 | INFO     | __main__:train:20 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 11.958568572998047
2025-12-09 09:45:05.743 | INFO     | __main__:train:20 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 11.938972473144531
2025-12-09 09:45:05.984 | INFO     | __main__:train:20 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 11.955068588256836
2025-12-09 09:45:06.225 | INFO     | __main__:train:20 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 11.921982765197754
2025-12-09 09:45:06.467 | INFO     | __main__:train:20 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 11.928089141845703
2025-12-09 09:45:06.709 | INFO     | __main__:train:20 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 11.917946815490723
2025-12-09 09:45:06.952 | INFO     | __main__:train:20 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 11.92427921295166
2025-12-09 09:45:07.194 | INFO     | __main__:train:20 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 11.927412033081055
2025-12-09 09:45:07.436 | INFO     | __main__:train:20 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 11.877516746520996
2025-12-09 09:45:07.676 | INFO     | __main__:train:20 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 11.894444465637207
2025-12-09 09:45:07.919 | INFO     | __main__:train:20 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 11.843326568603516
2025-12-09 09:45:08.161 | INFO     | __main__:train:20 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 11.877495765686035
2025-12-09 09:45:08.403 | INFO     | __main__:train:20 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 11.839622497558594
2025-12-09 09:45:08.645 | INFO     | __main__:train:20 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 11.796979904174805
2025-12-09 09:45:08.887 | INFO     | __main__:train:20 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 11.825655937194824
2025-12-09 09:45:09.129 | INFO     | __main__:train:20 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 11.835723876953125
2025-12-09 09:45:09.372 | INFO     | __main__:train:20 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 11.817005157470703
2025-12-09 09:45:09.614 | INFO     | __main__:train:20 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 11.787270545959473
2025-12-09 09:45:09.856 | INFO     | __main__:train:20 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 11.751460075378418
2025-12-09 09:45:10.098 | INFO     | __main__:train:20 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 11.701913833618164
2025-12-09 09:45:10.339 | INFO     | __main__:train:20 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 11.722996711730957
2025-12-09 09:45:10.581 | INFO     | __main__:train:20 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 11.715152740478516
2025-12-09 09:45:10.823 | INFO     | __main__:train:20 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 11.628507614135742
2025-12-09 09:45:11.064 | INFO     | __main__:train:20 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 11.656670570373535
2025-12-09 09:45:11.306 | INFO     | __main__:train:20 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 11.637391090393066
2025-12-09 09:45:11.548 | INFO     | __main__:train:20 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 11.605191230773926
2025-12-09 09:45:11.789 | INFO     | __main__:train:20 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 11.61406421661377
2025-12-09 09:45:12.031 | INFO     | __main__:train:20 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 11.528764724731445
2025-12-09 09:45:12.273 | INFO     | __main__:train:20 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 11.508578300476074
2025-12-09 09:45:12.515 | INFO     | __main__:train:20 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 11.465746879577637
2025-12-09 09:45:12.756 | INFO     | __main__:train:20 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 11.50588321685791
2025-12-09 09:45:12.999 | INFO     | __main__:train:20 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 11.43044662475586
2025-12-09 09:45:13.240 | INFO     | __main__:train:20 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 11.378363609313965
2025-12-09 09:45:13.483 | INFO     | __main__:train:20 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 11.432872772216797
2025-12-09 09:45:13.725 | INFO     | __main__:train:20 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 11.383200645446777
2025-12-09 09:45:13.967 | INFO     | __main__:train:20 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 11.363897323608398
2025-12-09 09:45:14.209 | INFO     | __main__:train:20 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 11.273201942443848
2025-12-09 09:45:14.451 | INFO     | __main__:train:20 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 11.305115699768066
2025-12-09 09:45:14.693 | INFO     | __main__:train:20 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 11.2705078125
2025-12-09 09:45:14.935 | INFO     | __main__:train:20 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 11.225560188293457
2025-12-09 09:45:15.176 | INFO     | __main__:train:20 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 11.16572093963623
2025-12-09 09:45:15.418 | INFO     | __main__:train:20 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 11.166461944580078
2025-12-09 09:45:15.660 | INFO     | __main__:train:20 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 11.146879196166992
2025-12-09 09:45:15.901 | INFO     | __main__:train:20 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 11.130253791809082
2025-12-09 09:45:16.142 | INFO     | __main__:train:20 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 11.057134628295898
2025-12-09 09:45:16.383 | INFO     | __main__:train:20 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 11.112546920776367
2025-12-09 09:45:16.625 | INFO     | __main__:train:20 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 11.040069580078125
2025-12-09 09:45:16.866 | INFO     | __main__:train:20 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 11.01755142211914
2025-12-09 09:45:17.108 | INFO     | __main__:train:20 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 11.01066780090332
2025-12-09 09:45:17.350 | INFO     | __main__:train:20 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 10.966510772705078
2025-12-09 09:45:17.592 | INFO     | __main__:train:20 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 10.909757614135742
2025-12-09 09:45:17.834 | INFO     | __main__:train:20 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 10.902948379516602
2025-12-09 09:45:18.076 | INFO     | __main__:train:20 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 10.941258430480957
2025-12-09 09:45:18.318 | INFO     | __main__:train:20 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 10.871702194213867
2025-12-09 09:45:18.559 | INFO     | __main__:train:20 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 10.847274780273438
2025-12-09 09:45:18.801 | INFO     | __main__:train:20 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 10.884182929992676
2025-12-09 09:45:19.043 | INFO     | __main__:train:20 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 10.796850204467773
2025-12-09 09:45:19.284 | INFO     | __main__:train:20 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 10.742159843444824
2025-12-09 09:45:19.525 | INFO     | __main__:train:20 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 10.802244186401367
2025-12-09 09:45:19.766 | INFO     | __main__:train:20 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 10.724225997924805
2025-12-09 09:45:20.008 | INFO     | __main__:train:20 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 10.689436912536621
2025-12-09 09:45:20.249 | INFO     | __main__:train:20 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 10.76109504699707
2025-12-09 09:45:20.490 | INFO     | __main__:train:20 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 10.6966552734375
2025-12-09 09:45:20.733 | INFO     | __main__:train:20 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 10.71577262878418
2025-12-09 09:45:20.974 | INFO     | __main__:train:20 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 10.642037391662598
2025-12-09 09:45:21.215 | INFO     | __main__:train:20 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 10.556187629699707
2025-12-09 09:45:21.457 | INFO     | __main__:train:20 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 10.508187294006348
2025-12-09 09:45:21.699 | INFO     | __main__:train:20 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 10.63825511932373
2025-12-09 09:45:21.940 | INFO     | __main__:train:20 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 10.477030754089355
2025-12-09 09:45:22.180 | INFO     | __main__:train:20 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 10.55614185333252
2025-12-09 09:45:22.422 | INFO     | __main__:train:20 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 10.520975112915039
2025-12-09 09:45:22.663 | INFO     | __main__:train:20 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 10.52652359008789
2025-12-09 09:45:22.905 | INFO     | __main__:train:20 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 10.54840087890625
2025-12-09 09:45:23.146 | INFO     | __main__:train:20 - Epoch: 0 Step: 100 LR: 0.0009977359612865424 Training loss: 10.738433837890625
2025-12-09 09:45:23.388 | INFO     | __main__:train:20 - Epoch: 0 Step: 101 LR: 0.0009909643486313534 Training loss: 10.445591926574707
2025-12-09 09:45:23.629 | INFO     | __main__:train:20 - Epoch: 0 Step: 102 LR: 0.0009797464868072487 Training loss: 10.430203437805176
2025-12-09 09:45:23.870 | INFO     | __main__:train:20 - Epoch: 0 Step: 103 LR: 0.0009641839665080363 Training loss: 10.470603942871094
2025-12-09 09:45:24.113 | INFO     | __main__:train:20 - Epoch: 0 Step: 104 LR: 0.0009444177243274617 Training loss: 10.397150039672852
2025-12-09 09:45:24.355 | INFO     | __main__:train:20 - Epoch: 0 Step: 105 LR: 0.0009206267664155906 Training loss: 10.505353927612305
2025-12-09 09:45:24.597 | INFO     | __main__:train:20 - Epoch: 0 Step: 106 LR: 0.0008930265473713938 Training loss: 10.284651756286621
2025-12-09 09:45:24.838 | INFO     | __main__:train:20 - Epoch: 0 Step: 107 LR: 0.000861867019052535 Training loss: 10.439136505126953
2025-12-09 09:45:25.080 | INFO     | __main__:train:20 - Epoch: 0 Step: 108 LR: 0.0008274303669726426 Training loss: 10.386134147644043
2025-12-09 09:45:25.321 | INFO     | __main__:train:20 - Epoch: 0 Step: 109 LR: 0.0007900284547855992 Training loss: 10.382081985473633
2025-12-09 09:45:25.562 | INFO     | __main__:train:20 - Epoch: 0 Step: 110 LR: 0.00075 Training loss: 10.381235122680664
2025-12-09 09:45:25.802 | INFO     | __main__:train:20 - Epoch: 0 Step: 111 LR: 0.0007077075065009433 Training loss: 10.289785385131836
2025-12-09 09:45:26.044 | INFO     | __main__:train:20 - Epoch: 0 Step: 112 LR: 0.0006635339816587109 Training loss: 10.349892616271973
2025-12-09 09:45:26.286 | INFO     | __main__:train:20 - Epoch: 0 Step: 113 LR: 0.0006178794677547138 Training loss: 10.446232795715332
2025-12-09 09:45:26.526 | INFO     | __main__:train:20 - Epoch: 0 Step: 114 LR: 0.0005711574191366427 Training loss: 10.361533164978027
2025-12-09 09:45:26.767 | INFO     | __main__:train:20 - Epoch: 0 Step: 115 LR: 0.0005237909579118712 Training loss: 10.35205364227295
2025-12-09 09:45:27.009 | INFO     | __main__:train:20 - Epoch: 0 Step: 116 LR: 0.0004762090420881289 Training loss: 10.260618209838867
2025-12-09 09:45:27.250 | INFO     | __main__:train:20 - Epoch: 0 Step: 117 LR: 0.0004288425808633575 Training loss: 10.359268188476562
2025-12-09 09:45:27.492 | INFO     | __main__:train:20 - Epoch: 0 Step: 118 LR: 0.0003821205322452863 Training loss: 10.359148025512695
2025-12-09 09:45:27.735 | INFO     | __main__:train:20 - Epoch: 0 Step: 119 LR: 0.0003364660183412892 Training loss: 10.386510848999023
2025-12-09 09:45:27.976 | INFO     | __main__:train:20 - Epoch: 0 Step: 120 LR: 0.0002922924934990568 Training loss: 10.317763328552246
2025-12-09 09:45:28.218 | INFO     | __main__:train:20 - Epoch: 0 Step: 121 LR: 0.0002500000000000001 Training loss: 10.293746948242188
2025-12-09 09:45:28.459 | INFO     | __main__:train:20 - Epoch: 0 Step: 122 LR: 0.00020997154521440098 Training loss: 10.187711715698242
2025-12-09 09:45:28.700 | INFO     | __main__:train:20 - Epoch: 0 Step: 123 LR: 0.0001725696330273575 Training loss: 10.289572715759277
2025-12-09 09:45:28.941 | INFO     | __main__:train:20 - Epoch: 0 Step: 124 LR: 0.0001381329809474649 Training loss: 10.220911979675293
2025-12-09 09:45:29.182 | INFO     | __main__:train:20 - Epoch: 0 Step: 125 LR: 0.00010697345262860636 Training loss: 10.415426254272461
2025-12-09 09:45:29.424 | INFO     | __main__:train:20 - Epoch: 0 Step: 126 LR: 7.937323358440934e-05 Training loss: 10.294270515441895
2025-12-09 09:45:29.664 | INFO     | __main__:train:20 - Epoch: 0 Step: 127 LR: 5.5582275672538315e-05 Training loss: 10.21622371673584
2025-12-09 09:45:29.906 | INFO     | __main__:train:20 - Epoch: 0 Step: 128 LR: 3.5816033491963716e-05 Training loss: 10.242570877075195
2025-12-09 09:45:30.147 | INFO     | __main__:train:20 - Epoch: 0 Step: 129 LR: 2.025351319275137e-05 Training loss: 10.278555870056152
2025-12-09 09:45:30.389 | INFO     | __main__:train:20 - Epoch: 0 Step: 130 LR: 9.035651368646646e-06 Training loss: 10.229397773742676
2025-12-09 09:45:30.630 | INFO     | __main__:train:20 - Epoch: 0 Step: 131 LR: 2.2640387134577057e-06 Training loss: 10.233512878417969
2025-12-09 09:45:30.779 | INFO     | __main__:train:20 - Epoch: 0 Step: 132 LR: 0.0 Training loss: 10.172471046447754
