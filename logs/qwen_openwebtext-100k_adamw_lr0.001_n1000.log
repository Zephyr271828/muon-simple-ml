2025-12-09 11:23:01.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.011871337890625
2025-12-09 11:23:01.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.063874244689941
2025-12-09 11:23:01.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.043976783752441
2025-12-09 11:23:01.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 11.984064102172852
2025-12-09 11:23:01.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 11.838266372680664
2025-12-09 11:23:01.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 11.766844749450684
2025-12-09 11:23:01.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 11.899165153503418
2025-12-09 11:23:01.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 11.805736541748047
2025-12-09 11:23:01.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 11.808732032775879
2025-12-09 11:23:02.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 11.618257522583008
2025-12-09 11:23:02.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 11.405991554260254
2025-12-09 11:23:02.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 11.389955520629883
2025-12-09 11:23:02.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 11.250168800354004
2025-12-09 11:23:02.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 11.276381492614746
2025-12-09 11:23:02.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 11.108343124389648
2025-12-09 11:23:02.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 11.013111114501953
2025-12-09 11:23:02.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 11.017556190490723
2025-12-09 11:23:02.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 10.992149353027344
2025-12-09 11:23:02.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 10.822657585144043
2025-12-09 11:23:02.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 10.832563400268555
2025-12-09 11:23:02.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 10.530593872070312
2025-12-09 11:23:03.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 10.595780372619629
2025-12-09 11:23:03.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 10.484597206115723
2025-12-09 11:23:03.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 10.291356086730957
2025-12-09 11:23:03.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 10.207487106323242
2025-12-09 11:23:03.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 10.083830833435059
2025-12-09 11:23:03.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 10.01059341430664
2025-12-09 11:23:03.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 9.845787048339844
2025-12-09 11:23:03.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 9.86734390258789
2025-12-09 11:23:03.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 9.770709991455078
2025-12-09 11:23:03.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 9.576380729675293
2025-12-09 11:23:03.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 9.345137596130371
2025-12-09 11:23:03.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 9.26835823059082
2025-12-09 11:23:03.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 9.049795150756836
2025-12-09 11:23:04.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 9.203766822814941
2025-12-09 11:23:04.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 8.972868919372559
2025-12-09 11:23:04.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 8.783666610717773
2025-12-09 11:23:04.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 8.424395561218262
2025-12-09 11:23:04.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 8.592761039733887
2025-12-09 11:23:04.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 8.754590034484863
2025-12-09 11:23:04.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 8.196718215942383
2025-12-09 11:23:04.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 8.397433280944824
2025-12-09 11:23:04.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 7.998248100280762
2025-12-09 11:23:04.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 8.143061637878418
2025-12-09 11:23:04.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 8.324009895324707
2025-12-09 11:23:04.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 8.121919631958008
2025-12-09 11:23:05.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 7.9883012771606445
2025-12-09 11:23:05.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 8.29737663269043
2025-12-09 11:23:05.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 8.026978492736816
2025-12-09 11:23:05.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 7.749413967132568
2025-12-09 11:23:05.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 8.050375938415527
2025-12-09 11:23:05.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 8.11960220336914
2025-12-09 11:23:05.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 7.828721046447754
2025-12-09 11:23:05.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 8.656049728393555
2025-12-09 11:23:05.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 8.024876594543457
2025-12-09 11:23:05.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 7.810828685760498
2025-12-09 11:23:05.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 8.062681198120117
2025-12-09 11:23:06.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 8.269262313842773
2025-12-09 11:23:06.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 8.755758285522461
2025-12-09 11:23:06.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 7.727964401245117
2025-12-09 11:23:06.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 7.830817699432373
2025-12-09 11:23:06.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 7.924960136413574
2025-12-09 11:23:06.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 7.913268566131592
2025-12-09 11:23:06.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 7.762399673461914
2025-12-09 11:23:06.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 7.736903667449951
2025-12-09 11:23:06.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 7.867471218109131
2025-12-09 11:23:06.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 8.157472610473633
2025-12-09 11:23:06.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 7.710661888122559
2025-12-09 11:23:06.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 7.7509331703186035
2025-12-09 11:23:06.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 8.03754711151123
2025-12-09 11:23:07.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 7.998584747314453
2025-12-09 11:23:07.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 7.789994716644287
2025-12-09 11:23:07.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 7.9294915199279785
2025-12-09 11:23:07.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 7.995638370513916
2025-12-09 11:23:07.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 7.993552207946777
2025-12-09 11:23:07.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 7.852838516235352
2025-12-09 11:23:07.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 7.8262128829956055
2025-12-09 11:23:07.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 7.976247787475586
2025-12-09 11:23:07.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 8.04315185546875
2025-12-09 11:23:07.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 8.394307136535645
2025-12-09 11:23:07.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 7.946252822875977
2025-12-09 11:23:07.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 7.7009053230285645
2025-12-09 11:23:08.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 7.791889667510986
2025-12-09 11:23:08.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 7.761691093444824
2025-12-09 11:23:08.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 7.738017559051514
2025-12-09 11:23:08.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 7.8631415367126465
2025-12-09 11:23:08.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 7.7144904136657715
2025-12-09 11:23:08.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 7.79520320892334
2025-12-09 11:23:08.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 7.690086364746094
2025-12-09 11:23:08.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 8.006461143493652
2025-12-09 11:23:08.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 7.625690460205078
2025-12-09 11:23:08.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 7.845182418823242
2025-12-09 11:23:08.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 7.917845249176025
2025-12-09 11:23:08.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 7.585602283477783
2025-12-09 11:23:09.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 7.626070499420166
2025-12-09 11:23:09.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 7.705488204956055
2025-12-09 11:23:09.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 7.809467315673828
2025-12-09 11:23:09.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 8.841462135314941
2025-12-09 11:23:09.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 7.673986434936523
2025-12-09 11:23:09.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 7.84870719909668
2025-12-09 11:23:09.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 100 LR: 0.0009999867173939862 Training loss: 7.669098854064941
2025-12-09 11:23:09.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 101 LR: 0.0009999468702816552 Training loss: 7.746130466461182
2025-12-09 11:23:09.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 102 LR: 0.0009998804607801008 Training loss: 8.865127563476562
2025-12-09 11:23:09.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 103 LR: 0.0009997874924176885 Training loss: 7.943967342376709
2025-12-09 11:23:09.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 104 LR: 0.0009996679701338661 Training loss: 8.020747184753418
2025-12-09 11:23:09.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 105 LR: 0.0009995219002789037 Training loss: 7.901909351348877
2025-12-09 11:23:09.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 106 LR: 0.0009993492906135546 Training loss: 7.820194721221924
2025-12-09 11:23:10.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 107 LR: 0.0009991501503086434 Training loss: 7.613742351531982
2025-12-09 11:23:10.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 108 LR: 0.0009989244899445793 Training loss: 7.586395740509033
2025-12-09 11:23:10.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 109 LR: 0.0009986723215107925 Training loss: 7.818367004394531
2025-12-09 11:23:10.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 110 LR: 0.0009983936584050993 Training loss: 7.572717189788818
2025-12-09 11:23:10.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 111 LR: 0.0009980885154329882 Training loss: 7.215537071228027
2025-12-09 11:23:10.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 112 LR: 0.0009977569088068354 Training loss: 7.556257724761963
2025-12-09 11:23:10.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 113 LR: 0.0009973988561450412 Training loss: 7.460836887359619
2025-12-09 11:23:10.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 114 LR: 0.000997014376471095 Training loss: 7.4348835945129395
2025-12-09 11:23:10.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 115 LR: 0.0009966034902125656 Training loss: 7.90631103515625
2025-12-09 11:23:10.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 116 LR: 0.0009961662192000138 Training loss: 7.54292106628418
2025-12-09 11:23:10.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 117 LR: 0.0009957025866658338 Training loss: 7.574390888214111
2025-12-09 11:23:10.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 118 LR: 0.000995212617243019 Training loss: 7.708459854125977
2025-12-09 11:23:10.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 119 LR: 0.0009946963369638524 Training loss: 7.529989242553711
2025-12-09 11:23:11.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 120 LR: 0.0009941537732585245 Training loss: 7.843486785888672
2025-12-09 11:23:11.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 121 LR: 0.0009935849549536746 Training loss: 7.509313106536865
2025-12-09 11:23:11.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 122 LR: 0.0009929899122708607 Training loss: 7.565339088439941
2025-12-09 11:23:11.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 123 LR: 0.0009923686768249528 Training loss: 6.750374794006348
2025-12-09 11:23:11.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 124 LR: 0.0009917212816224538 Training loss: 7.266131401062012
2025-12-09 11:23:11.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 125 LR: 0.0009910477610597448 Training loss: 7.545147895812988
2025-12-09 11:23:11.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 126 LR: 0.0009903481509212595 Training loss: 7.7118000984191895
2025-12-09 11:23:11.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 127 LR: 0.0009896224883775811 Training loss: 7.603121280670166
2025-12-09 11:23:11.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 128 LR: 0.0009888708119834679 Training loss: 7.741968154907227
2025-12-09 11:23:11.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 129 LR: 0.0009880931616758058 Training loss: 7.553615093231201
2025-12-09 11:23:11.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 130 LR: 0.0009872895787714853 Training loss: 7.297248363494873
2025-12-09 11:23:11.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 131 LR: 0.0009864601059652069 Training loss: 7.303332805633545
2025-12-09 11:23:12.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 132 LR: 0.0009856047873272127 Training loss: 7.286035537719727
2025-12-09 11:23:12.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 133 LR: 0.0009847236683009444 Training loss: 7.4981794357299805
2025-12-09 11:23:12.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 134 LR: 0.0009838167957006295 Training loss: 7.296297550201416
2025-12-09 11:23:12.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 135 LR: 0.000982884217708794 Training loss: 7.44314432144165
2025-12-09 11:23:12.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 136 LR: 0.000981925983873702 Training loss: 7.438162803649902
2025-12-09 11:23:12.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 137 LR: 0.0009809421451067234 Training loss: 7.39261531829834
2025-12-09 11:23:12.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 138 LR: 0.000979932753679629 Training loss: 7.771538734436035
2025-12-09 11:23:12.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 139 LR: 0.000978897863221814 Training loss: 8.591291427612305
2025-12-09 11:23:12.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 140 LR: 0.0009778375287174464 Training loss: 7.651359558105469
2025-12-09 11:23:12.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 141 LR: 0.0009767518065025487 Training loss: 7.518265247344971
2025-12-09 11:23:12.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 142 LR: 0.0009756407542620023 Training loss: 7.3043365478515625
2025-12-09 11:23:12.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 143 LR: 0.0009745044310264839 Training loss: 7.633028030395508
2025-12-09 11:23:12.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 144 LR: 0.000973342897169329 Training loss: 7.415378093719482
2025-12-09 11:23:13.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 145 LR: 0.0009721562144033238 Training loss: 7.5819854736328125
2025-12-09 11:23:13.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 146 LR: 0.000970944445777427 Training loss: 7.610455513000488
2025-12-09 11:23:13.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 147 LR: 0.0009697076556734194 Training loss: 7.499914169311523
2025-12-09 11:23:13.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 148 LR: 0.0009684459098024841 Training loss: 7.415499210357666
2025-12-09 11:23:13.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 149 LR: 0.0009671592752017137 Training loss: 7.669327735900879
2025-12-09 11:23:13.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 150 LR: 0.0009658478202305505 Training loss: 7.3542609214782715
2025-12-09 11:23:13.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 151 LR: 0.0009645116145671533 Training loss: 7.872863292694092
2025-12-09 11:23:13.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 152 LR: 0.0009631507292046955 Training loss: 7.416768550872803
2025-12-09 11:23:13.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 153 LR: 0.0009617652364475933 Training loss: 7.444173812866211
2025-12-09 11:23:13.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 154 LR: 0.0009603552099076648 Training loss: 7.453213214874268
2025-12-09 11:23:13.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 155 LR: 0.0009589207245002177 Training loss: 7.298367500305176
2025-12-09 11:23:13.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 156 LR: 0.0009574618564400701 Training loss: 7.368563652038574
2025-12-09 11:23:13.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 157 LR: 0.0009559786832375008 Training loss: 7.44244909286499
2025-12-09 11:23:14.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 158 LR: 0.0009544712836941307 Training loss: 8.266708374023438
2025-12-09 11:23:14.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 159 LR: 0.000952939737898737 Training loss: 7.39432954788208
2025-12-09 11:23:14.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 160 LR: 0.0009513841272229973 Training loss: 7.401886463165283
2025-12-09 11:23:14.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 161 LR: 0.0009498045343171664 Training loss: 7.52096700668335
2025-12-09 11:23:14.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 162 LR: 0.000948201043105685 Training loss: 7.631976127624512
2025-12-09 11:23:14.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 163 LR: 0.0009465737387827214 Training loss: 7.706600666046143
2025-12-09 11:23:14.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 164 LR: 0.0009449227078076444 Training loss: 7.58638334274292
2025-12-09 11:23:14.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 165 LR: 0.0009432480379004296 Training loss: 7.085669994354248
2025-12-09 11:23:14.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 166 LR: 0.0009415498180369994 Training loss: 7.196706771850586
2025-12-09 11:23:14.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 167 LR: 0.0009398281384444955 Training loss: 7.522193431854248
2025-12-09 11:23:14.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 168 LR: 0.0009380830905964843 Training loss: 7.732982158660889
2025-12-09 11:23:14.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 169 LR: 0.0009363147672080985 Training loss: 7.401552677154541
2025-12-09 11:23:14.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 170 LR: 0.0009345232622311092 Training loss: 7.95512056350708
2025-12-09 11:23:15.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 171 LR: 0.0009327086708489356 Training loss: 7.37492036819458
2025-12-09 11:23:15.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 172 LR: 0.0009308710894715873 Training loss: 7.4344258308410645
2025-12-09 11:23:15.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 173 LR: 0.0009290106157305423 Training loss: 7.420007228851318
2025-12-09 11:23:15.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 174 LR: 0.0009271273484735592 Training loss: 7.266089916229248
2025-12-09 11:23:15.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 175 LR: 0.000925221387759426 Training loss: 7.041550636291504
2025-12-09 11:23:15.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 176 LR: 0.000923292834852644 Training loss: 7.234187602996826
2025-12-09 11:23:15.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 177 LR: 0.0009213417922180464 Training loss: 7.010738849639893
2025-12-09 11:23:15.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 178 LR: 0.000919368363515356 Training loss: 7.562369346618652
2025-12-09 11:23:15.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 179 LR: 0.0009173726535936768 Training loss: 7.1673264503479
2025-12-09 11:23:15.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 180 LR: 0.0009153547684859229 Training loss: 6.940759181976318
2025-12-09 11:23:15.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 181 LR: 0.0009133148154031859 Training loss: 7.736659526824951
2025-12-09 11:23:15.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 182 LR: 0.0009112529027290382 Training loss: 7.319201469421387
2025-12-09 11:23:15.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 183 LR: 0.0009091691400137745 Training loss: 7.316929817199707
2025-12-09 11:23:16.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 184 LR: 0.0009070636379685915 Training loss: 7.55074405670166
2025-12-09 11:23:16.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 185 LR: 0.0009049365084597057 Training loss: 7.0222883224487305
2025-12-09 11:23:16.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 186 LR: 0.00090278786450241 Training loss: 7.496299743652344
2025-12-09 11:23:16.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 187 LR: 0.0009006178202550689 Training loss: 7.482462406158447
2025-12-09 11:23:16.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 188 LR: 0.0008984264910130535 Training loss: 7.482877731323242
2025-12-09 11:23:16.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 189 LR: 0.0008962139932026156 Training loss: 7.290844917297363
2025-12-09 11:23:16.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 190 LR: 0.0008939804443747022 Training loss: 7.514702796936035
2025-12-09 11:23:16.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 191 LR: 0.0008917259631987098 Training loss: 7.237260818481445
2025-12-09 11:23:16.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 192 LR: 0.000889450669456179 Training loss: 7.336963176727295
2025-12-09 11:23:16.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 193 LR: 0.0008871546840344313 Training loss: 7.0641255378723145
2025-12-09 11:23:16.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 194 LR: 0.0008848381289201459 Training loss: 7.071653842926025
2025-12-09 11:23:16.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 195 LR: 0.0008825011271928785 Training loss: 7.136176586151123
2025-12-09 11:23:17.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 196 LR: 0.0008801438030185214 Training loss: 7.317030906677246
2025-12-09 11:23:17.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 197 LR: 0.0008777662816427078 Training loss: 7.344244956970215
2025-12-09 11:23:17.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 198 LR: 0.000875368689384157 Training loss: 7.088496685028076
2025-12-09 11:23:17.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 199 LR: 0.000872951153627962 Training loss: 7.193630218505859
2025-12-09 11:23:17.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 200 LR: 0.0008705138028188228 Training loss: 7.272645950317383
2025-12-09 11:23:17.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 201 LR: 0.0008680567664542214 Training loss: 8.085562705993652
2025-12-09 11:23:17.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 202 LR: 0.0008655801750775418 Training loss: 7.247067451477051
2025-12-09 11:23:17.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 203 LR: 0.0008630841602711343 Training loss: 7.30755615234375
2025-12-09 11:23:17.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 204 LR: 0.0008605688546493238 Training loss: 7.150115489959717
2025-12-09 11:23:17.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 205 LR: 0.0008580343918513644 Training loss: 7.030981540679932
2025-12-09 11:23:17.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 206 LR: 0.0008554809065343396 Training loss: 7.268960475921631
2025-12-09 11:23:17.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 207 LR: 0.0008529085343660072 Training loss: 7.079758644104004
2025-12-09 11:23:18.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 208 LR: 0.0008503174120175909 Training loss: 7.487596035003662
2025-12-09 11:23:18.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 209 LR: 0.0008477076771565203 Training loss: 6.995940208435059
2025-12-09 11:23:18.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 210 LR: 0.0008450794684391151 Training loss: 7.286248207092285
2025-12-09 11:23:18.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 211 LR: 0.0008424329255032188 Training loss: 7.465862274169922
2025-12-09 11:23:18.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 212 LR: 0.00083976818896078 Training loss: 7.745307922363281
2025-12-09 11:23:18.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 213 LR: 0.0008370854003903813 Training loss: 7.368463039398193
2025-12-09 11:23:18.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 214 LR: 0.0008343847023297169 Training loss: 7.818581581115723
2025-12-09 11:23:18.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 215 LR: 0.0008316662382680202 Training loss: 7.03179407119751
2025-12-09 11:23:18.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 216 LR: 0.0008289301526384393 Training loss: 7.134493827819824
2025-12-09 11:23:18.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 217 LR: 0.0008261765908103643 Training loss: 7.299971580505371
2025-12-09 11:23:18.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 218 LR: 0.0008234056990817025 Training loss: 7.255918025970459
2025-12-09 11:23:18.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 219 LR: 0.0008206176246711066 Training loss: 7.190973281860352
2025-12-09 11:23:19.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 220 LR: 0.0008178125157101521 Training loss: 6.40303373336792
2025-12-09 11:23:19.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 221 LR: 0.000814990521235468 Training loss: 7.112150192260742
2025-12-09 11:23:19.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 222 LR: 0.0008121517911808173 Training loss: 6.9738545417785645
2025-12-09 11:23:19.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 223 LR: 0.0008092964763691314 Training loss: 6.893483638763428
2025-12-09 11:23:19.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 224 LR: 0.0008064247285044972 Training loss: 7.027251720428467
2025-12-09 11:23:19.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 225 LR: 0.0008035367001640964 Training loss: 7.438170909881592
2025-12-09 11:23:19.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 226 LR: 0.0008006325447900998 Training loss: 7.628764629364014
2025-12-09 11:23:19.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 227 LR: 0.0007977124166815133 Training loss: 7.460910797119141
