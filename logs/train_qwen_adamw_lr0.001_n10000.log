2025-12-09 06:10:06.806 | INFO     | __main__:<module>:359 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.127805709838867
2025-12-09 06:10:07.282 | INFO     | __main__:<module>:359 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.15256404876709
2025-12-09 06:10:07.745 | INFO     | __main__:<module>:359 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.094893455505371
2025-12-09 06:10:08.208 | INFO     | __main__:<module>:359 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 11.960448265075684
2025-12-09 06:10:08.671 | INFO     | __main__:<module>:359 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 11.821746826171875
2025-12-09 06:10:09.134 | INFO     | __main__:<module>:359 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 11.563643455505371
2025-12-09 06:17:54.500 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.144083976745605
2025-12-09 06:17:54.964 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.115209579467773
2025-12-09 06:17:55.425 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.086054801940918
2025-12-09 06:17:55.889 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 11.979866981506348
2025-12-09 06:17:56.351 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 11.809732437133789
2025-12-09 06:17:56.813 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 11.66931438446045
2025-12-09 06:17:57.275 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 11.29494571685791
2025-12-09 06:17:57.739 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 11.048238754272461
2025-12-09 06:17:58.199 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 10.689297676086426
2025-12-09 06:17:58.660 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 10.5571870803833
2025-12-09 06:17:59.123 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 10.46126937866211
2025-12-09 06:17:59.585 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 10.397744178771973
2025-12-09 06:18:00.045 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 10.369585990905762
2025-12-09 06:18:00.506 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 10.24973201751709
2025-12-09 06:18:00.966 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 10.07225513458252
2025-12-09 06:18:01.428 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 9.880852699279785
2025-12-09 06:18:01.888 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 9.703659057617188
2025-12-09 06:18:02.349 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 9.610466957092285
2025-12-09 06:18:02.809 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 9.499723434448242
2025-12-09 06:18:03.271 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 9.435247421264648
2025-12-09 06:18:03.731 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 9.166848182678223
2025-12-09 06:18:04.192 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 8.967368125915527
2025-12-09 06:18:04.653 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 8.837044715881348
2025-12-09 06:18:05.113 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 8.795344352722168
2025-12-09 06:18:05.575 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 8.648298263549805
2025-12-09 06:18:06.035 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 8.484686851501465
2025-12-09 06:18:06.497 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 8.310685157775879
2025-12-09 06:18:06.959 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 8.297019004821777
2025-12-09 06:18:07.419 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 8.236312866210938
2025-12-09 06:18:07.880 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 7.971818447113037
2025-12-09 06:18:08.340 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 7.913660526275635
2025-12-09 06:18:08.800 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 7.824951171875
2025-12-09 06:18:09.260 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 7.885519981384277
2025-12-09 06:18:09.721 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 7.89362096786499
2025-12-09 06:18:10.181 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 8.18751335144043
2025-12-09 06:18:10.641 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 7.821181297302246
2025-12-09 06:18:11.103 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 8.266495704650879
2025-12-09 06:18:11.564 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 7.739558696746826
2025-12-09 06:18:12.024 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 7.786712169647217
2025-12-09 06:18:12.484 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 7.9902262687683105
2025-12-09 06:18:12.945 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 7.952709197998047
2025-12-09 06:18:13.406 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 7.990299701690674
2025-12-09 06:18:13.867 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 8.030835151672363
2025-12-09 06:18:14.327 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 7.826642036437988
2025-12-09 06:18:14.789 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 7.83192777633667
2025-12-09 06:18:15.250 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 7.851109981536865
2025-12-09 06:18:15.710 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 8.02087688446045
2025-12-09 06:18:16.172 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 7.893890380859375
2025-12-09 06:18:16.633 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 8.075593948364258
2025-12-09 06:18:17.094 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 7.865667819976807
2025-12-09 06:18:17.555 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 7.811479568481445
2025-12-09 06:18:18.016 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 7.922068119049072
2025-12-09 06:18:18.477 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 7.880640506744385
2025-12-09 06:18:18.939 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 7.791440486907959
2025-12-09 06:18:19.400 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 7.818027973175049
2025-12-09 06:18:19.862 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 7.765536785125732
2025-12-09 06:18:20.324 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 7.738839626312256
2025-12-09 06:18:20.785 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 7.894217491149902
2025-12-09 06:18:21.247 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 7.807816028594971
2025-12-09 06:18:21.708 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 7.721136093139648
2025-12-09 06:18:22.170 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 7.667706489562988
2025-12-09 06:18:22.632 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 7.909162521362305
2025-12-09 06:18:23.094 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 7.650217056274414
2025-12-09 06:18:23.557 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 7.776555061340332
2025-12-09 06:18:24.020 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 7.746321201324463
2025-12-09 06:18:24.483 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 7.736086368560791
2025-12-09 06:18:24.945 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 7.653933525085449
2025-12-09 06:18:25.407 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 7.412154197692871
2025-12-09 06:18:25.871 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 7.918598175048828
2025-12-09 06:18:26.334 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 7.748519420623779
2025-12-09 06:18:26.797 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 7.726073265075684
2025-12-09 06:18:27.261 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 7.435537338256836
2025-12-09 06:18:27.723 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 7.874489784240723
2025-12-09 06:18:28.187 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 7.611508369445801
2025-12-09 06:18:28.649 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 7.6687235832214355
2025-12-09 06:18:29.113 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 7.476490497589111
2025-12-09 06:18:29.576 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 7.791960716247559
2025-12-09 06:18:30.040 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 7.645686149597168
2025-12-09 06:18:30.503 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 7.6692214012146
2025-12-09 06:18:30.967 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 7.628603458404541
2025-12-09 06:18:31.430 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 7.761521339416504
2025-12-09 06:18:31.894 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 7.494723320007324
2025-12-09 06:18:32.358 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 7.739351272583008
2025-12-09 06:18:32.821 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 7.649904251098633
2025-12-09 06:18:33.285 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 7.445559501647949
2025-12-09 06:18:33.748 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 7.429413318634033
2025-12-09 06:18:34.213 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 7.683132171630859
2025-12-09 06:18:34.677 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 7.349419116973877
2025-12-09 06:18:35.141 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 7.673696041107178
2025-12-09 06:18:35.604 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 7.53405237197876
2025-12-09 06:18:36.069 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 7.2724504470825195
2025-12-09 06:18:36.535 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 7.386366367340088
2025-12-09 06:18:36.999 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 7.483569622039795
2025-12-09 06:18:37.463 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 7.284578800201416
2025-12-09 06:18:37.927 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 7.180388927459717
2025-12-09 06:18:38.392 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 7.943809509277344
2025-12-09 06:18:38.857 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 7.341403961181641
2025-12-09 06:18:39.320 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 7.639496803283691
2025-12-09 06:18:39.784 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 7.450406551361084
2025-12-09 06:18:40.247 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 7.370380878448486
2025-12-09 06:18:40.713 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 100 LR: 0.0009999983285747596 Training loss: 7.374074935913086
2025-12-09 06:18:41.178 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 101 LR: 0.0009999933143102129 Training loss: 7.424652099609375
2025-12-09 06:18:41.643 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 102 LR: 0.000999984957239884 Training loss: 7.306385040283203
2025-12-09 06:18:42.107 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 103 LR: 0.0009999732574196452 Training loss: 7.000627517700195
2025-12-09 06:18:42.573 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 104 LR: 0.0009999582149277186 Training loss: 7.462045192718506
2025-12-09 06:18:43.037 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 105 LR: 0.0009999398298646738 Training loss: 7.32696008682251
2025-12-09 06:18:43.501 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 106 LR: 0.0009999181023534274 Training loss: 7.292097091674805
2025-12-09 06:18:43.965 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 107 LR: 0.0009998930325392434 Training loss: 7.289747714996338
2025-12-09 06:18:44.429 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 108 LR: 0.000999864620589731 Training loss: 7.251802444458008
2025-12-09 06:18:44.894 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 109 LR: 0.0009998328666948437 Training loss: 7.219763278961182
2025-12-09 06:18:45.358 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 110 LR: 0.0009997977710668792 Training loss: 7.2933807373046875
2025-12-09 06:18:45.823 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 111 LR: 0.0009997593339404756 Training loss: 7.175277233123779
2025-12-09 06:18:46.288 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 112 LR: 0.0009997175555726127 Training loss: 7.431323528289795
2025-12-09 06:18:46.752 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 113 LR: 0.0009996724362426074 Training loss: 7.229297637939453
2025-12-09 06:18:47.217 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 114 LR: 0.000999623976252115 Training loss: 7.249647617340088
2025-12-09 06:18:47.682 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 115 LR: 0.0009995721759251239 Training loss: 7.246492385864258
2025-12-09 06:18:48.147 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 116 LR: 0.0009995170356079557 Training loss: 7.105974197387695
2025-12-09 06:18:48.612 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 117 LR: 0.0009994585556692623 Training loss: 7.407994747161865
2025-12-09 06:18:49.078 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 118 LR: 0.0009993967365000227 Training loss: 7.0978264808654785
2025-12-09 06:18:49.543 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 119 LR: 0.0009993315785135415 Training loss: 7.28500509262085
2025-12-09 06:18:50.008 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 120 LR: 0.0009992630821454458 Training loss: 7.19965124130249
2025-12-09 06:18:50.473 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 121 LR: 0.0009991912478536816 Training loss: 7.465033531188965
2025-12-09 06:18:50.938 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 122 LR: 0.0009991160761185114 Training loss: 6.810675621032715
2025-12-09 06:18:51.401 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 123 LR: 0.0009990375674425109 Training loss: 7.0258307456970215
2025-12-09 06:18:51.866 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 124 LR: 0.000998955722350566 Training loss: 7.312132835388184
2025-12-09 06:18:52.332 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 125 LR: 0.0009988705413898683 Training loss: 7.418149948120117
2025-12-09 06:18:52.796 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 126 LR: 0.0009987820251299122 Training loss: 7.107263565063477
2025-12-09 06:18:53.260 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 127 LR: 0.0009986901741624908 Training loss: 7.106011867523193
2025-12-09 06:18:53.725 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 128 LR: 0.0009985949891016925 Training loss: 7.183544635772705
2025-12-09 06:18:54.190 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 129 LR: 0.000998496470583896 Training loss: 6.941934108734131
2025-12-09 06:18:54.655 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 130 LR: 0.0009983946192677667 Training loss: 6.956031799316406
2025-12-09 06:18:55.120 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 131 LR: 0.000998289435834252 Training loss: 7.142816543579102
2025-12-09 06:18:55.585 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 132 LR: 0.000998180920986577 Training loss: 6.90041446685791
2025-12-09 06:18:56.051 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 133 LR: 0.0009980690754502392 Training loss: 7.08634090423584
2025-12-09 06:18:56.516 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 134 LR: 0.0009979538999730047 Training loss: 7.331157207489014
2025-12-09 06:18:56.981 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 135 LR: 0.0009978353953249022 Training loss: 7.1458892822265625
2025-12-09 06:18:57.446 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 136 LR: 0.0009977135622982185 Training loss: 7.21198034286499
2025-12-09 06:18:57.911 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 137 LR: 0.0009975884017074926 Training loss: 7.03187894821167
2025-12-09 06:18:58.376 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 138 LR: 0.0009974599143895107 Training loss: 6.883896350860596
2025-12-09 06:18:58.841 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 139 LR: 0.0009973281012033007 Training loss: 7.201373100280762
2025-12-09 06:18:59.307 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 140 LR: 0.0009971929630301264 Training loss: 6.987429618835449
2025-12-09 06:18:59.772 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 141 LR: 0.0009970545007734807 Training loss: 6.756161212921143
2025-12-09 06:19:00.237 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 142 LR: 0.0009969127153590812 Training loss: 6.821210861206055
2025-12-09 06:19:00.702 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 143 LR: 0.0009967676077348628 Training loss: 7.1707682609558105
2025-12-09 06:19:01.166 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 144 LR: 0.0009966191788709714 Training loss: 7.201067924499512
2025-12-09 06:19:01.632 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 145 LR: 0.0009964674297597584 Training loss: 7.028117656707764
2025-12-09 06:19:02.097 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 146 LR: 0.0009963123614157728 Training loss: 7.234981536865234
2025-12-09 06:19:02.564 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 147 LR: 0.0009961539748757548 Training loss: 6.748935222625732
2025-12-09 06:19:03.029 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 148 LR: 0.00099599227119863 Training loss: 6.800657749176025
2025-12-09 06:19:03.494 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 149 LR: 0.0009958272514655007 Training loss: 7.049232482910156
2025-12-09 06:19:03.961 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 150 LR: 0.0009956589167796391 Training loss: 6.83914852142334
2025-12-09 06:19:04.426 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 151 LR: 0.000995487268266481 Training loss: 7.010040760040283
2025-12-09 06:19:04.892 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 152 LR: 0.000995312307073617 Training loss: 6.981129169464111
2025-12-09 06:19:05.357 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 153 LR: 0.0009951340343707852 Training loss: 6.907287120819092
2025-12-09 06:19:05.823 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 154 LR: 0.0009949524513498636 Training loss: 6.907320499420166
2025-12-09 06:19:06.288 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 155 LR: 0.0009947675592248619 Training loss: 6.725998878479004
2025-12-09 06:19:06.754 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 156 LR: 0.0009945793592319135 Training loss: 7.130700588226318
2025-12-09 06:19:07.221 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 157 LR: 0.0009943878526292675 Training loss: 6.910610198974609
2025-12-09 06:19:07.687 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 158 LR: 0.0009941930406972797 Training loss: 6.729463577270508
2025-12-09 06:19:08.152 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 159 LR: 0.0009939949247384046 Training loss: 6.8993659019470215
2025-12-09 06:19:08.618 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 160 LR: 0.0009937935060771858 Training loss: 6.863109588623047
2025-12-09 06:19:09.083 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 161 LR: 0.0009935887860602487 Training loss: 6.66193962097168
2025-12-09 06:19:09.549 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 162 LR: 0.0009933807660562897 Training loss: 6.822219371795654
2025-12-09 06:19:10.014 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 163 LR: 0.0009931694474560684 Training loss: 6.590452194213867
2025-12-09 06:19:10.480 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 164 LR: 0.0009929548316723982 Training loss: 6.94432258605957
2025-12-09 06:19:10.946 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 165 LR: 0.0009927369201401357 Training loss: 6.829695224761963
2025-12-09 06:19:11.409 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 166 LR: 0.0009925157143161724 Training loss: 6.853383541107178
2025-12-09 06:19:11.874 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 167 LR: 0.0009922912156794242 Training loss: 6.789942741394043
2025-12-09 06:19:12.340 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 168 LR: 0.0009920634257308217 Training loss: 7.000233173370361
2025-12-09 06:19:12.804 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 169 LR: 0.0009918323459933004 Training loss: 6.673954963684082
2025-12-09 06:19:13.270 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 170 LR: 0.0009915979780117908 Training loss: 6.532578945159912
2025-12-09 06:19:13.734 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 171 LR: 0.0009913603233532068 Training loss: 6.842102527618408
2025-12-09 06:19:14.199 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 172 LR: 0.000991119383606436 Training loss: 6.849630355834961
2025-12-09 06:19:14.664 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 173 LR: 0.0009908751603823302 Training loss: 6.7189483642578125
2025-12-09 06:19:15.129 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 174 LR: 0.0009906276553136924 Training loss: 6.655501842498779
2025-12-09 06:19:15.594 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 175 LR: 0.0009903768700552675 Training loss: 6.770179271697998
2025-12-09 06:19:16.059 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 176 LR: 0.000990122806283731 Training loss: 6.7546706199646
2025-12-09 06:19:16.525 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 177 LR: 0.000989865465697677 Training loss: 6.821495056152344
2025-12-09 06:19:16.990 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 178 LR: 0.000989604850017608 Training loss: 6.853172779083252
2025-12-09 06:19:17.457 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 179 LR: 0.0009893409609859221 Training loss: 6.6634368896484375
2025-12-09 06:19:17.924 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 180 LR: 0.0009890738003669028 Training loss: 6.6030354499816895
2025-12-09 06:19:18.390 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 181 LR: 0.000988803369946706 Training loss: 6.885098934173584
2025-12-09 06:19:18.856 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 182 LR: 0.0009885296715333488 Training loss: 6.7876763343811035
2025-12-09 06:19:19.322 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 183 LR: 0.0009882527069566965 Training loss: 6.795912265777588
2025-12-09 06:19:19.789 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 184 LR: 0.0009879724780684517 Training loss: 7.158975601196289
2025-12-09 06:19:20.255 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 185 LR: 0.0009876889867421411 Training loss: 6.721831798553467
2025-12-09 06:19:20.721 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 186 LR: 0.0009874022348731028 Training loss: 6.902676105499268
2025-12-09 06:19:21.187 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 187 LR: 0.000987112224378474 Training loss: 6.837739944458008
2025-12-09 06:19:21.653 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 188 LR: 0.0009868189571971783 Training loss: 6.677855968475342
2025-12-09 06:19:22.119 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 189 LR: 0.0009865224352899118 Training loss: 6.615323066711426
2025-12-09 06:19:22.585 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 190 LR: 0.0009862226606391323 Training loss: 6.49968957901001
2025-12-09 06:19:23.050 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 191 LR: 0.0009859196352490424 Training loss: 6.6713480949401855
2025-12-09 06:19:23.516 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 192 LR: 0.0009856133611455802 Training loss: 6.429480075836182
2025-12-09 06:19:23.983 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 193 LR: 0.000985303840376402 Training loss: 6.812419891357422
2025-12-09 06:19:24.449 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 194 LR: 0.0009849910750108718 Training loss: 6.895503044128418
2025-12-09 06:19:24.916 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 195 LR: 0.0009846750671400446 Training loss: 6.868448734283447
2025-12-09 06:19:25.381 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 196 LR: 0.000984355818876655 Training loss: 6.597975254058838
2025-12-09 06:19:25.847 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 197 LR: 0.0009840333323551014 Training loss: 6.601480484008789
2025-12-09 06:19:26.313 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 198 LR: 0.000983707609731432 Training loss: 6.869301795959473
2025-12-09 06:19:26.778 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 199 LR: 0.000983378653183331 Training loss: 6.810558319091797
2025-12-09 06:19:27.243 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 200 LR: 0.0009830464649101035 Training loss: 6.6662726402282715
2025-12-09 06:19:27.709 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 201 LR: 0.000982711047132661 Training loss: 6.670092582702637
2025-12-09 06:19:28.174 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 202 LR: 0.0009823724020935065 Training loss: 6.583805084228516
2025-12-09 06:19:28.639 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 203 LR: 0.000982030532056719 Training loss: 6.431250095367432
2025-12-09 06:19:29.104 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 204 LR: 0.0009816854393079402 Training loss: 6.6271443367004395
2025-12-09 06:19:29.570 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 205 LR: 0.0009813371261543564 Training loss: 6.761280059814453
2025-12-09 06:19:30.036 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 206 LR: 0.0009809855949246852 Training loss: 6.474431991577148
2025-12-09 06:19:30.504 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 207 LR: 0.0009806308479691594 Training loss: 6.64478874206543
2025-12-09 06:19:30.969 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 208 LR: 0.0009802728876595111 Training loss: 6.275836944580078
2025-12-09 06:19:31.435 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 209 LR: 0.000979911716388956 Training loss: 6.851048946380615
2025-12-09 06:19:31.901 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 210 LR: 0.000979547336572177 Training loss: 6.583871841430664
2025-12-09 06:19:32.367 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 211 LR: 0.0009791797506453084 Training loss: 6.885447025299072
2025-12-09 06:19:32.833 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 212 LR: 0.0009788089610659203 Training loss: 6.838728427886963
2025-12-09 06:19:33.300 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 213 LR: 0.0009784349703130008 Training loss: 6.501067638397217
2025-12-09 06:19:33.765 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 214 LR: 0.0009780577808869398 Training loss: 6.668071746826172
2025-12-09 06:19:34.232 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 215 LR: 0.0009776773953095136 Training loss: 6.80872106552124
2025-12-09 06:19:34.697 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 216 LR: 0.000977293816123866 Training loss: 6.534455299377441
2025-12-09 06:19:35.163 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 217 LR: 0.0009769070458944928 Training loss: 6.550492286682129
2025-12-09 06:19:35.629 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 218 LR: 0.0009765170872072244 Training loss: 6.682994842529297
2025-12-09 06:19:36.094 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 219 LR: 0.0009761239426692076 Training loss: 6.600232124328613
2025-12-09 06:19:36.561 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 220 LR: 0.0009757276149088896 Training loss: 6.4758076667785645
2025-12-09 06:19:37.027 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 221 LR: 0.0009753281065759988 Training loss: 6.512087821960449
2025-12-09 06:19:37.493 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 222 LR: 0.0009749254203415288 Training loss: 6.324365139007568
2025-12-09 06:19:37.960 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 223 LR: 0.0009745195588977192 Training loss: 6.497088432312012
2025-12-09 06:19:38.427 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 224 LR: 0.0009741105249580382 Training loss: 6.508318901062012
2025-12-09 06:19:38.893 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 225 LR: 0.0009736983212571646 Training loss: 6.662809371948242
2025-12-09 06:19:39.360 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 226 LR: 0.000973282950550969 Training loss: 6.310478687286377
2025-12-09 06:19:39.826 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 227 LR: 0.0009728644156164958 Training loss: 6.8058085441589355
2025-12-09 06:19:40.291 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 228 LR: 0.000972442719251944 Training loss: 6.406848430633545
2025-12-09 06:19:40.757 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 229 LR: 0.00097201786427665 Training loss: 6.582744121551514
2025-12-09 06:19:41.223 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 230 LR: 0.0009715898535310668 Training loss: 6.665187358856201
2025-12-09 06:19:41.690 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 231 LR: 0.0009711586898767462 Training loss: 6.521701812744141
2025-12-09 06:19:42.156 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 232 LR: 0.0009707243761963195 Training loss: 6.689792633056641
2025-12-09 06:19:42.622 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 233 LR: 0.0009702869153934781 Training loss: 6.716709613800049
2025-12-09 06:19:43.088 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 234 LR: 0.0009698463103929542 Training loss: 6.518563747406006
2025-12-09 06:19:43.555 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 235 LR: 0.0009694025641405011 Training loss: 6.71755838394165
2025-12-09 06:19:44.021 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 236 LR: 0.0009689556796028733 Training loss: 6.49306058883667
2025-12-09 06:19:44.486 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 237 LR: 0.0009685056597678075 Training loss: 6.4493327140808105
2025-12-09 06:19:44.951 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 238 LR: 0.0009680525076440014 Training loss: 6.718421936035156
2025-12-09 06:19:45.416 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 239 LR: 0.0009675962262610949 Training loss: 6.716429710388184
2025-12-09 06:19:45.883 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 240 LR: 0.0009671368186696487 Training loss: 6.698691368103027
2025-12-09 06:19:46.349 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 241 LR: 0.0009666742879411247 Training loss: 6.427755832672119
2025-12-09 06:19:46.816 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 242 LR: 0.0009662086371678649 Training loss: 6.494609355926514
2025-12-09 06:19:47.281 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 243 LR: 0.0009657398694630713 Training loss: 6.680841445922852
2025-12-09 06:19:47.748 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 244 LR: 0.0009652679879607843 Training loss: 6.79547119140625
2025-12-09 06:19:48.215 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 245 LR: 0.0009647929958158627 Training loss: 6.513388156890869
2025-12-09 06:19:48.681 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 246 LR: 0.0009643148962039621 Training loss: 6.591485023498535
2025-12-09 06:19:49.149 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 247 LR: 0.0009638336923215134 Training loss: 6.753680229187012
2025-12-09 06:19:49.616 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 248 LR: 0.0009633493873857018 Training loss: 6.542154312133789
2025-12-09 06:19:50.082 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 249 LR: 0.0009628619846344453 Training loss: 6.6992340087890625
2025-12-09 06:19:50.548 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 250 LR: 0.0009623714873263729 Training loss: 6.727650165557861
2025-12-09 06:19:51.015 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 251 LR: 0.000961877898740803 Training loss: 6.574027061462402
2025-12-09 06:19:51.482 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 252 LR: 0.0009613812221777212 Training loss: 6.781872749328613
2025-12-09 06:19:51.949 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 253 LR: 0.0009608814609577585 Training loss: 6.748242378234863
2025-12-09 06:19:52.416 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 254 LR: 0.0009603786184221692 Training loss: 6.796421527862549
2025-12-09 06:19:52.882 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 255 LR: 0.0009598726979328079 Training loss: 6.502639293670654
2025-12-09 06:19:53.348 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 256 LR: 0.0009593637028721076 Training loss: 6.530092716217041
2025-12-09 06:19:53.814 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 257 LR: 0.0009588516366430573 Training loss: 6.531146049499512
2025-12-09 06:19:54.280 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 258 LR: 0.0009583365026691784 Training loss: 6.218863010406494
2025-12-09 06:19:54.747 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 259 LR: 0.000957818304394503 Training loss: 6.593141078948975
2025-12-09 06:19:55.212 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 260 LR: 0.0009572970452835494 Training loss: 6.379354000091553
2025-12-09 06:19:55.680 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 261 LR: 0.0009567727288213005 Training loss: 6.817396640777588
2025-12-09 06:19:56.145 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 262 LR: 0.0009562453585131791 Training loss: 6.541067600250244
2025-12-09 06:19:56.611 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 263 LR: 0.0009557149378850254 Training loss: 6.688055515289307
2025-12-09 06:19:57.077 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 264 LR: 0.0009551814704830733 Training loss: 6.667454719543457
2025-12-09 06:19:57.542 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 265 LR: 0.0009546449598739262 Training loss: 6.524491786956787
2025-12-09 06:19:58.008 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 266 LR: 0.0009541054096445336 Training loss: 6.5572686195373535
2025-12-09 06:19:58.475 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 267 LR: 0.0009535628234021669 Training loss: 6.478846073150635
2025-12-09 06:19:58.941 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 268 LR: 0.0009530172047743957 Training loss: 6.42263650894165
2025-12-09 06:19:59.408 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 269 LR: 0.0009524685574090626 Training loss: 6.462478160858154
2025-12-09 06:19:59.874 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 270 LR: 0.0009519168849742603 Training loss: 6.593641757965088
2025-12-09 06:20:00.341 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 271 LR: 0.0009513621911583053 Training loss: 6.567675590515137
2025-12-09 06:20:00.807 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 272 LR: 0.0009508044796697148 Training loss: 6.62876033782959
2025-12-09 06:20:01.274 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 273 LR: 0.0009502437542371811 Training loss: 6.517432689666748
2025-12-09 06:20:01.741 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 274 LR: 0.0009496800186095466 Training loss: 6.721051216125488
2025-12-09 06:20:02.206 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 275 LR: 0.0009491132765557791 Training loss: 6.517075061798096
2025-12-09 06:20:02.672 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 276 LR: 0.0009485435318649467 Training loss: 6.296546459197998
2025-12-09 06:20:03.139 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 277 LR: 0.0009479707883461918 Training loss: 6.576088905334473
2025-12-09 06:20:03.607 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 278 LR: 0.0009473950498287066 Training loss: 6.30772590637207
2025-12-09 06:20:04.072 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 279 LR: 0.0009468163201617061 Training loss: 6.490312099456787
2025-12-09 06:20:04.539 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 280 LR: 0.0009462346032144044 Training loss: 6.634509563446045
2025-12-09 06:20:05.005 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 281 LR: 0.0009456499028759868 Training loss: 6.806659698486328
2025-12-09 06:20:05.472 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 282 LR: 0.0009450622230555847 Training loss: 6.519150257110596
2025-12-09 06:20:05.939 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 283 LR: 0.0009444715676822502 Training loss: 6.382368087768555
2025-12-09 06:20:06.406 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 284 LR: 0.0009438779407049281 Training loss: 6.246201515197754
2025-12-09 06:20:06.872 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 285 LR: 0.0009432813460924307 Training loss: 6.475840091705322
2025-12-09 06:20:07.338 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 286 LR: 0.0009426817878334115 Training loss: 6.560649394989014
2025-12-09 06:20:07.805 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 287 LR: 0.0009420792699363377 Training loss: 6.555284023284912
2025-12-09 06:20:08.271 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 288 LR: 0.0009414737964294635 Training loss: 6.718075275421143
2025-12-09 06:20:08.737 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 289 LR: 0.000940865371360804 Training loss: 6.498297214508057
2025-12-09 06:20:09.203 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 290 LR: 0.0009402539987981071 Training loss: 6.737325191497803
2025-12-09 06:20:09.670 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 291 LR: 0.0009396396828288272 Training loss: 6.8402862548828125
2025-12-09 06:20:10.135 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 292 LR: 0.0009390224275600969 Training loss: 6.577523231506348
2025-12-09 06:20:10.602 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 293 LR: 0.0009384022371187003 Training loss: 6.2064080238342285
2025-12-09 06:20:11.069 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 294 LR: 0.0009377791156510454 Training loss: 6.60673189163208
2025-12-09 06:20:11.535 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 295 LR: 0.000937153067323136 Training loss: 6.47604513168335
2025-12-09 06:20:12.002 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 296 LR: 0.0009365240963205439 Training loss: 6.511516571044922
2025-12-09 06:20:12.468 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 297 LR: 0.0009358922068483812 Training loss: 6.6433892250061035
2025-12-09 06:20:12.934 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 298 LR: 0.000935257403131272 Training loss: 6.386826038360596
2025-12-09 06:20:13.400 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 299 LR: 0.0009346196894133239 Training loss: 6.333555221557617
2025-12-09 06:20:13.867 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 300 LR: 0.0009339790699581003 Training loss: 6.542905807495117
2025-12-09 06:20:14.333 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 301 LR: 0.0009333355490485915 Training loss: 6.551274299621582
2025-12-09 06:20:14.799 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 302 LR: 0.0009326891309871854 Training loss: 6.291600227355957
2025-12-09 06:20:15.265 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 303 LR: 0.0009320398200956402 Training loss: 6.44265079498291
2025-12-09 06:20:15.732 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 304 LR: 0.0009313876207150542 Training loss: 6.199668884277344
2025-12-09 06:20:16.199 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 305 LR: 0.0009307325372058377 Training loss: 6.396121978759766
2025-12-09 06:20:16.666 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 306 LR: 0.0009300745739476828 Training loss: 6.306034564971924
2025-12-09 06:20:17.133 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 307 LR: 0.0009294137353395351 Training loss: 6.324970722198486
2025-12-09 06:20:17.599 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 308 LR: 0.000928750025799564 Training loss: 6.405823230743408
2025-12-09 06:20:18.065 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 309 LR: 0.0009280834497651332 Training loss: 6.575307369232178
2025-12-09 06:20:18.532 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 310 LR: 0.0009274140116927706 Training loss: 6.630419731140137
2025-12-09 06:20:18.998 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 311 LR: 0.0009267417160581388 Training loss: 6.265880584716797
2025-12-09 06:20:19.463 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 312 LR: 0.0009260665673560057 Training loss: 6.519974231719971
2025-12-09 06:20:19.930 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 313 LR: 0.0009253885701002134 Training loss: 6.103250503540039
2025-12-09 06:20:20.396 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 314 LR: 0.0009247077288236488 Training loss: 7.007988452911377
2025-12-09 06:20:20.862 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 315 LR: 0.0009240240480782129 Training loss: 6.47698450088501
2025-12-09 06:20:21.329 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 316 LR: 0.0009233375324347912 Training loss: 6.567717552185059
2025-12-09 06:20:21.796 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 317 LR: 0.0009226481864832216 Training loss: 6.499432563781738
2025-12-09 06:20:22.262 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 318 LR: 0.0009219560148322654 Training loss: 6.310819625854492
2025-12-09 06:20:22.728 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 319 LR: 0.0009212610221095747 Training loss: 6.357890605926514
2025-12-09 06:20:23.195 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 320 LR: 0.0009205632129616635 Training loss: 6.136929988861084
2025-12-09 06:20:23.661 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 321 LR: 0.0009198625920538749 Training loss: 6.451791286468506
2025-12-09 06:20:24.127 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 322 LR: 0.0009191591640703507 Training loss: 6.49559211730957
2025-12-09 06:20:24.592 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 323 LR: 0.0009184529337140002 Training loss: 6.622584342956543
2025-12-09 06:20:25.057 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 324 LR: 0.0009177439057064682 Training loss: 6.162290096282959
2025-12-09 06:20:25.524 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 325 LR: 0.0009170320847881042 Training loss: 6.432693004608154
2025-12-09 06:20:25.990 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 326 LR: 0.0009163174757179297 Training loss: 6.507302761077881
2025-12-09 06:20:26.456 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 327 LR: 0.0009156000832736073 Training loss: 6.315875053405762
2025-12-09 06:20:26.922 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 328 LR: 0.0009148799122514087 Training loss: 6.351590156555176
2025-12-09 06:20:27.389 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 329 LR: 0.0009141569674661816 Training loss: 6.352120399475098
2025-12-09 06:20:27.856 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 330 LR: 0.0009134312537513187 Training loss: 6.561171531677246
2025-12-09 06:20:28.321 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 331 LR: 0.000912702775958725 Training loss: 6.380094051361084
2025-12-09 06:20:28.788 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 332 LR: 0.0009119715389587853 Training loss: 6.08152961730957
2025-12-09 06:20:29.256 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 333 LR: 0.0009112375476403312 Training loss: 6.131806373596191
2025-12-09 06:20:29.723 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 334 LR: 0.0009105008069106094 Training loss: 6.081863880157471
2025-12-09 06:20:30.189 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 335 LR: 0.0009097613216952478 Training loss: 6.478745937347412
2025-12-09 06:20:30.656 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 336 LR: 0.0009090190969382239 Training loss: 6.153054237365723
2025-12-09 06:20:31.123 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 337 LR: 0.00090827413760183 Training loss: 6.46912956237793
2025-12-09 06:20:31.590 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 338 LR: 0.0009075264486666419 Training loss: 6.401040077209473
2025-12-09 06:20:32.057 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 339 LR: 0.0009067760351314837 Training loss: 6.333269119262695
2025-12-09 06:20:32.523 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 340 LR: 0.0009060229020133965 Training loss: 6.464041233062744
2025-12-09 06:20:32.989 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 341 LR: 0.0009052670543476026 Training loss: 6.244146347045898
2025-12-09 06:20:33.457 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 342 LR: 0.0009045084971874737 Training loss: 6.248075485229492
2025-12-09 06:20:33.924 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 343 LR: 0.0009037472356044962 Training loss: 6.251558780670166
2025-12-09 06:20:34.390 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 344 LR: 0.0009029832746882371 Training loss: 6.598482131958008
2025-12-09 06:20:34.856 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 345 LR: 0.000902216619546311 Training loss: 6.385437965393066
2025-12-09 06:20:35.324 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 346 LR: 0.0009014472753043447 Training loss: 6.404670238494873
2025-12-09 06:20:35.790 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 347 LR: 0.0009006752471059439 Training loss: 6.172214508056641
2025-12-09 06:20:36.255 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 348 LR: 0.000899900540112658 Training loss: 5.988315105438232
2025-12-09 06:20:36.722 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 349 LR: 0.0008991231595039464 Training loss: 6.467217445373535
2025-12-09 06:20:37.187 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 350 LR: 0.0008983431104771436 Training loss: 6.350070476531982
2025-12-09 06:20:37.653 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 351 LR: 0.0008975603982474239 Training loss: 6.555225849151611
2025-12-09 06:20:38.120 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 352 LR: 0.0008967750280477673 Training loss: 6.6485090255737305
2025-12-09 06:20:38.586 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 353 LR: 0.0008959870051289241 Training loss: 6.180239677429199
2025-12-09 06:20:39.053 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 354 LR: 0.0008951963347593796 Training loss: 6.441574573516846
2025-12-09 06:20:39.520 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 355 LR: 0.00089440302222532 Training loss: 6.595419406890869
2025-12-09 06:20:39.986 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 356 LR: 0.0008936070728305952 Training loss: 6.009420394897461
2025-12-09 06:20:40.453 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 357 LR: 0.000892808491896685 Training loss: 6.4601969718933105
2025-12-09 06:20:40.919 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 358 LR: 0.0008920072847626629 Training loss: 6.386193752288818
2025-12-09 06:20:41.385 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 359 LR: 0.0008912034567851599 Training loss: 6.234272480010986
2025-12-09 06:20:41.852 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 360 LR: 0.0008903970133383297 Training loss: 6.246845245361328
2025-12-09 06:20:42.318 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 361 LR: 0.0008895879598138119 Training loss: 6.168770790100098
2025-12-09 06:20:42.785 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 362 LR: 0.0008887763016206965 Training loss: 6.290290355682373
2025-12-09 06:20:43.252 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 363 LR: 0.0008879620441854873 Training loss: 6.207202911376953
2025-12-09 06:20:43.719 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 364 LR: 0.0008871451929520662 Training loss: 6.4252519607543945
2025-12-09 06:20:44.186 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 365 LR: 0.0008863257533816562 Training loss: 6.407425403594971
2025-12-09 06:20:44.653 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 366 LR: 0.0008855037309527853 Training loss: 6.346802711486816
2025-12-09 06:20:45.121 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 367 LR: 0.0008846791311612497 Training loss: 6.357115268707275
2025-12-09 06:20:45.587 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 368 LR: 0.000883851959520077 Training loss: 6.141971588134766
2025-12-09 06:20:46.055 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 369 LR: 0.000883022221559489 Training loss: 6.273010730743408
2025-12-09 06:20:46.521 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 370 LR: 0.0008821899228268662 Training loss: 6.125938415527344
2025-12-09 06:20:46.988 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 371 LR: 0.0008813550688867087 Training loss: 6.270872116088867
2025-12-09 06:20:47.455 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 372 LR: 0.0008805176653206003 Training loss: 6.542510509490967
2025-12-09 06:20:47.922 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 373 LR: 0.0008796777177271708 Training loss: 6.375239372253418
2025-12-09 06:20:48.388 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 374 LR: 0.000878835231722059 Training loss: 6.163445472717285
2025-12-09 06:20:48.857 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 375 LR: 0.000877990212937874 Training loss: 6.287261486053467
2025-12-09 06:20:49.324 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 376 LR: 0.0008771426670241587 Training loss: 6.379241466522217
2025-12-09 06:20:49.791 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 377 LR: 0.0008762925996473518 Training loss: 6.16050386428833
2025-12-09 06:20:50.258 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 378 LR: 0.0008754400164907496 Training loss: 6.342939376831055
2025-12-09 06:20:50.725 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 379 LR: 0.0008745849232544681 Training loss: 6.36724328994751
2025-12-09 06:20:51.190 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 380 LR: 0.0008737273256554048 Training loss: 6.275936603546143
2025-12-09 06:20:51.657 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 381 LR: 0.0008728672294272009 Training loss: 6.500179767608643
2025-12-09 06:20:52.124 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 382 LR: 0.0008720046403202027 Training loss: 6.129827499389648
2025-12-09 06:20:52.588 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 383 LR: 0.0008711395641014228 Training loss: 6.173158168792725
2025-12-09 06:20:53.055 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 384 LR: 0.0008702720065545023 Training loss: 6.153473377227783
2025-12-09 06:20:53.522 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 385 LR: 0.0008694019734796714 Training loss: 6.168806552886963
2025-12-09 06:20:53.988 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 386 LR: 0.0008685294706937113 Training loss: 6.204996109008789
2025-12-09 06:20:54.455 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 387 LR: 0.0008676545040299144 Training loss: 6.228785514831543
2025-12-09 06:20:54.921 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 388 LR: 0.0008667770793380463 Training loss: 6.079884052276611
2025-12-09 06:20:55.386 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 389 LR: 0.0008658972024843061 Training loss: 6.257730484008789
2025-12-09 06:20:55.854 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 390 LR: 0.0008650148793512873 Training loss: 6.213314533233643
2025-12-09 06:20:56.321 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 391 LR: 0.0008641301158379387 Training loss: 6.142784595489502
2025-12-09 06:20:56.787 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 392 LR: 0.0008632429178595242 Training loss: 6.271406650543213
2025-12-09 06:20:57.255 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 393 LR: 0.0008623532913475847 Training loss: 6.431122779846191
2025-12-09 06:20:57.721 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 394 LR: 0.0008614612422498965 Training loss: 6.194883346557617
2025-12-09 06:20:58.188 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 395 LR: 0.0008605667765304334 Training loss: 6.249392509460449
2025-12-09 06:20:58.656 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 396 LR: 0.0008596699001693256 Training loss: 6.266635417938232
2025-12-09 06:20:59.125 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 397 LR: 0.0008587706191628204 Training loss: 6.233150959014893
2025-12-09 06:20:59.592 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 398 LR: 0.0008578689395232416 Training loss: 6.206753730773926
2025-12-09 06:21:00.059 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 399 LR: 0.0008569648672789496 Training loss: 6.229661464691162
2025-12-09 06:21:00.527 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 400 LR: 0.0008560584084743011 Training loss: 6.209376811981201
2025-12-09 06:21:00.994 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 401 LR: 0.0008551495691696085 Training loss: 6.2506937980651855
2025-12-09 06:21:01.462 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 402 LR: 0.0008542383554411 Training loss: 6.4217143058776855
2025-12-09 06:21:01.929 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 403 LR: 0.0008533247733808776 Training loss: 6.183902263641357
2025-12-09 06:21:02.397 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 404 LR: 0.0008524088290968781 Training loss: 6.247923374176025
2025-12-09 06:21:02.863 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 405 LR: 0.000851490528712831 Training loss: 6.3068108558654785
2025-12-09 06:21:03.330 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 406 LR: 0.0008505698783682179 Training loss: 6.5494771003723145
2025-12-09 06:21:03.797 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 407 LR: 0.0008496468842182317 Training loss: 6.2486138343811035
2025-12-09 06:21:04.265 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 408 LR: 0.0008487215524337357 Training loss: 6.0425310134887695
2025-12-09 06:21:04.732 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 409 LR: 0.0008477938892012209 Training loss: 6.161240577697754
2025-12-09 06:21:05.199 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 410 LR: 0.0008468639007227668 Training loss: 6.347732067108154
2025-12-09 06:21:05.666 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 411 LR: 0.0008459315932159979 Training loss: 6.227643966674805
2025-12-09 06:21:06.133 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 412 LR: 0.0008449969729140437 Training loss: 6.481549263000488
2025-12-09 06:21:06.599 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 413 LR: 0.0008440600460654957 Training loss: 6.297256946563721
2025-12-09 06:21:07.067 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 414 LR: 0.0008431208189343669 Training loss: 6.20458984375
2025-12-09 06:21:07.535 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 415 LR: 0.0008421792978000489 Training loss: 6.348241329193115
2025-12-09 06:21:08.001 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 416 LR: 0.0008412354889572705 Training loss: 6.213452339172363
2025-12-09 06:21:08.467 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 417 LR: 0.0008402893987160552 Training loss: 6.373502731323242
2025-12-09 06:21:08.933 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 418 LR: 0.0008393410334016798 Training loss: 6.151304721832275
2025-12-09 06:21:09.399 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 419 LR: 0.000838390399354631 Training loss: 6.334400653839111
2025-12-09 06:21:09.867 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 420 LR: 0.0008374375029305639 Training loss: 6.270210266113281
2025-12-09 06:21:10.334 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 421 LR: 0.0008364823505002586 Training loss: 6.013847351074219
2025-12-09 06:21:10.801 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 422 LR: 0.0008355249484495791 Training loss: 6.061013221740723
2025-12-09 06:21:11.267 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 423 LR: 0.0008345653031794292 Training loss: 6.128716945648193
2025-12-09 06:21:11.733 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 424 LR: 0.0008336034211057098 Training loss: 6.46520471572876
2025-12-09 06:21:12.202 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 425 LR: 0.0008326393086592772 Training loss: 6.188959121704102
2025-12-09 06:21:12.670 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 426 LR: 0.0008316729722858987 Training loss: 6.326810359954834
2025-12-09 06:21:13.138 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 427 LR: 0.0008307044184462104 Training loss: 6.312751770019531
2025-12-09 06:21:13.606 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 428 LR: 0.0008297336536156738 Training loss: 6.418445587158203
2025-12-09 06:21:14.072 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 429 LR: 0.0008287606842845319 Training loss: 6.22913122177124
2025-12-09 06:21:14.540 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 430 LR: 0.0008277855169577668 Training loss: 6.160021781921387
2025-12-09 06:21:15.008 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 431 LR: 0.000826808158155056 Training loss: 5.99622917175293
2025-12-09 06:21:15.475 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 432 LR: 0.0008258286144107276 Training loss: 6.012800216674805
2025-12-09 06:21:15.942 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 433 LR: 0.0008248468922737186 Training loss: 6.348350524902344
2025-12-09 06:21:16.408 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 434 LR: 0.0008238629983075294 Training loss: 6.097114086151123
2025-12-09 06:21:16.876 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 435 LR: 0.0008228769390901811 Training loss: 5.83588171005249
2025-12-09 06:21:17.342 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 436 LR: 0.0008218887212141705 Training loss: 6.218348026275635
2025-12-09 06:21:17.810 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 437 LR: 0.0008208983512864268 Training loss: 6.192276477813721
2025-12-09 06:21:18.276 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 438 LR: 0.0008199058359282674 Training loss: 6.246119022369385
2025-12-09 06:21:18.743 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 439 LR: 0.000818911181775353 Training loss: 6.305091857910156
2025-12-09 06:21:19.211 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 440 LR: 0.0008179143954776439 Training loss: 6.128269672393799
2025-12-09 06:21:19.678 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 441 LR: 0.0008169154836993551 Training loss: 6.063394069671631
2025-12-09 06:21:20.145 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 442 LR: 0.0008159144531189122 Training loss: 6.305853843688965
2025-12-09 06:21:20.613 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 443 LR: 0.0008149113104289063 Training loss: 6.337045192718506
2025-12-09 06:21:21.080 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 444 LR: 0.0008139060623360494 Training loss: 6.146538734436035
2025-12-09 06:21:21.547 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 445 LR: 0.0008128987155611295 Training loss: 5.897891044616699
2025-12-09 06:21:22.015 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 446 LR: 0.000811889276838966 Training loss: 6.173603057861328
2025-12-09 06:21:22.481 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 447 LR: 0.0008108777529183644 Training loss: 6.339434623718262
2025-12-09 06:21:22.949 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 448 LR: 0.0008098641505620711 Training loss: 5.915322780609131
2025-12-09 06:21:23.417 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 449 LR: 0.0008088484765467285 Training loss: 6.026721954345703
2025-12-09 06:21:23.884 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 450 LR: 0.0008078307376628291 Training loss: 6.135566711425781
2025-12-09 06:21:24.350 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 451 LR: 0.000806810940714671 Training loss: 6.237552642822266
2025-12-09 06:21:24.816 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 452 LR: 0.0008057890925203113 Training loss: 6.236329078674316
2025-12-09 06:21:25.283 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 453 LR: 0.0008047651999115216 Training loss: 6.299668788909912
2025-12-09 06:21:25.750 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 454 LR: 0.0008037392697337418 Training loss: 6.292201995849609
2025-12-09 06:21:26.217 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 455 LR: 0.0008027113088460343 Training loss: 6.170931339263916
2025-12-09 06:21:26.684 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 456 LR: 0.0008016813241210379 Training loss: 6.205148696899414
2025-12-09 06:21:27.152 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 457 LR: 0.0008006493224449228 Training loss: 6.033891677856445
2025-12-09 06:21:27.619 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 458 LR: 0.0007996153107173435 Training loss: 6.127396583557129
2025-12-09 06:21:28.086 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 459 LR: 0.0007985792958513931 Training loss: 6.105281352996826
2025-12-09 06:21:28.554 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 460 LR: 0.0007975412847735573 Training loss: 6.154908657073975
2025-12-09 06:21:29.021 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 461 LR: 0.0007965012844236677 Training loss: 6.1453094482421875
2025-12-09 06:21:29.489 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 462 LR: 0.0007954593017548556 Training loss: 6.078529357910156
2025-12-09 06:21:29.956 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 463 LR: 0.0007944153437335057 Training loss: 6.4536871910095215
2025-12-09 06:21:30.424 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 464 LR: 0.000793369417339209 Training loss: 5.965181827545166
2025-12-09 06:21:30.891 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 465 LR: 0.0007923215295647166 Training loss: 6.038404941558838
2025-12-09 06:21:31.358 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 466 LR: 0.0007912716874158928 Training loss: 5.954602241516113
2025-12-09 06:21:31.826 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 467 LR: 0.0007902198979116684 Training loss: 6.101198196411133
2025-12-09 06:21:32.294 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 468 LR: 0.0007891661680839932 Training loss: 6.2221455574035645
2025-12-09 06:21:32.760 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 469 LR: 0.0007881105049777901 Training loss: 6.28850793838501
2025-12-09 06:21:33.227 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 470 LR: 0.0007870529156509068 Training loss: 6.158895492553711
2025-12-09 06:21:33.695 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 471 LR: 0.0007859934071740692 Training loss: 5.861974239349365
2025-12-09 06:21:34.162 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 472 LR: 0.0007849319866308342 Training loss: 6.270565509796143
2025-12-09 06:21:34.630 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 473 LR: 0.0007838686611175421 Training loss: 6.113309860229492
2025-12-09 06:21:35.096 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 474 LR: 0.0007828034377432694 Training loss: 6.238149166107178
2025-12-09 06:21:35.563 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 475 LR: 0.0007817363236297808 Training loss: 5.792449951171875
2025-12-09 06:21:36.031 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 476 LR: 0.0007806673259114826 Training loss: 6.092442512512207
2025-12-09 06:21:36.497 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 477 LR: 0.0007795964517353734 Training loss: 5.9748148918151855
2025-12-09 06:21:36.965 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 478 LR: 0.0007785237082609981 Training loss: 6.253527641296387
2025-12-09 06:21:37.432 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 479 LR: 0.0007774491026603985 Training loss: 5.994882106781006
2025-12-09 06:21:37.899 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 480 LR: 0.0007763726421180664 Training loss: 6.1190361976623535
2025-12-09 06:21:38.365 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 481 LR: 0.000775294333830895 Training loss: 6.233896255493164
2025-12-09 06:21:38.832 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 482 LR: 0.0007742141850081313 Training loss: 6.094111919403076
2025-12-09 06:21:39.298 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 483 LR: 0.000773132202871327 Training loss: 5.948858261108398
2025-12-09 06:21:39.766 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 484 LR: 0.0007720483946542913 Training loss: 6.411797523498535
2025-12-09 06:21:40.234 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 485 LR: 0.0007709627676030419 Training loss: 6.212763786315918
2025-12-09 06:21:40.701 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 486 LR: 0.0007698753289757565 Training loss: 6.0345540046691895
2025-12-09 06:21:41.167 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 487 LR: 0.0007687860860427245 Training loss: 6.212796211242676
2025-12-09 06:21:41.634 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 488 LR: 0.0007676950460862986 Training loss: 6.094280242919922
2025-12-09 06:21:42.101 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 489 LR: 0.0007666022164008457 Training loss: 5.992491722106934
2025-12-09 06:21:42.568 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 490 LR: 0.000765507604292698 Training loss: 5.87640380859375
2025-12-09 06:21:43.036 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 491 LR: 0.000764411217080105 Training loss: 6.011484146118164
2025-12-09 06:21:43.503 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 492 LR: 0.0007633130620931837 Training loss: 5.916069507598877
2025-12-09 06:21:43.970 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 493 LR: 0.00076221314667387 Training loss: 6.57110595703125
2025-12-09 06:21:44.438 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 494 LR: 0.0007611114781758692 Training loss: 6.041118621826172
2025-12-09 06:21:44.905 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 495 LR: 0.0007600080639646077 Training loss: 6.289586067199707
2025-12-09 06:21:45.371 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 496 LR: 0.000758902911417183 Training loss: 5.885494232177734
2025-12-09 06:21:45.838 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 497 LR: 0.0007577960279223142 Training loss: 6.054006099700928
2025-12-09 06:21:46.304 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 498 LR: 0.0007566874208802939 Training loss: 6.086918354034424
2025-12-09 06:21:46.771 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 499 LR: 0.0007555770977029366 Training loss: 6.358570575714111
2025-12-09 06:21:47.239 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 500 LR: 0.0007544650658135314 Training loss: 6.515212535858154
2025-12-09 06:21:47.707 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 501 LR: 0.0007533513326467912 Training loss: 6.217456817626953
2025-12-09 06:21:48.173 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 502 LR: 0.0007522359056488024 Training loss: 5.835427761077881
2025-12-09 06:21:48.640 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 503 LR: 0.0007511187922769767 Training loss: 6.3198771476745605
2025-12-09 06:21:49.108 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 504 LR: 0.00075 Training loss: 6.014217376708984
2025-12-09 06:21:49.574 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 505 LR: 0.0007488795362977829 Training loss: 6.204493522644043
2025-12-09 06:21:50.042 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 506 LR: 0.0007477574086614104 Training loss: 6.201176643371582
2025-12-09 06:21:50.508 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 507 LR: 0.0007466336245930927 Training loss: 6.13448429107666
2025-12-09 06:21:50.975 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 508 LR: 0.0007455081916061139 Training loss: 6.420290470123291
2025-12-09 06:21:51.443 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 509 LR: 0.0007443811172247821 Training loss: 5.9279351234436035
2025-12-09 06:21:51.910 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 510 LR: 0.0007432524089843799 Training loss: 6.054317474365234
2025-12-09 06:21:52.377 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 511 LR: 0.0007421220744311132 Training loss: 6.2419233322143555
2025-12-09 06:21:52.845 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 512 LR: 0.0007409901211220605 Training loss: 5.992185115814209
2025-12-09 06:21:53.311 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 513 LR: 0.0007398565566251232 Training loss: 6.294266223907471
2025-12-09 06:21:53.778 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 514 LR: 0.0007387213885189745 Training loss: 6.1831955909729
2025-12-09 06:21:54.246 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 515 LR: 0.0007375846243930091 Training loss: 6.167561054229736
2025-12-09 06:21:54.713 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 516 LR: 0.0007364462718472918 Training loss: 6.112473964691162
2025-12-09 06:21:55.180 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 517 LR: 0.0007353063384925075 Training loss: 5.900045394897461
2025-12-09 06:21:55.647 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 518 LR: 0.0007341648319499096 Training loss: 6.059234142303467
2025-12-09 06:21:56.115 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 519 LR: 0.0007330217598512695 Training loss: 5.935640811920166
2025-12-09 06:21:56.581 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 520 LR: 0.0007318771298388254 Training loss: 6.366966247558594
2025-12-09 06:21:57.049 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 521 LR: 0.0007307309495652312 Training loss: 6.07673454284668
2025-12-09 06:21:57.516 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 522 LR: 0.0007295832266935059 Training loss: 6.136507511138916
2025-12-09 06:21:57.983 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 523 LR: 0.0007284339688969809 Training loss: 6.105169296264648
2025-12-09 06:21:58.451 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 524 LR: 0.0007272831838592503 Training loss: 6.005711078643799
2025-12-09 06:21:58.919 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 525 LR: 0.0007261308792741188 Training loss: 6.018955707550049
2025-12-09 06:21:59.387 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 526 LR: 0.0007249770628455503 Training loss: 6.194779396057129
2025-12-09 06:21:59.853 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 527 LR: 0.0007238217422876163 Training loss: 6.12343692779541
2025-12-09 06:22:00.320 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 528 LR: 0.0007226649253244447 Training loss: 5.855400562286377
2025-12-09 06:22:00.787 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 529 LR: 0.0007215066196901676 Training loss: 6.029047966003418
2025-12-09 06:22:01.255 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 530 LR: 0.0007203468331288703 Training loss: 5.937533855438232
2025-12-09 06:22:01.723 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 531 LR: 0.0007191855733945387 Training loss: 6.281572341918945
2025-12-09 06:22:02.190 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 532 LR: 0.0007180228482510084 Training loss: 6.386157512664795
2025-12-09 06:22:02.657 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 533 LR: 0.0007168586654719117 Training loss: 6.112133979797363
2025-12-09 06:22:03.124 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 534 LR: 0.0007156930328406268 Training loss: 6.344298362731934
2025-12-09 06:22:03.591 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 535 LR: 0.0007145259581502247 Training loss: 6.070544719696045
2025-12-09 06:22:04.058 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 536 LR: 0.0007133574492034179 Training loss: 6.155156135559082
2025-12-09 06:22:04.526 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 537 LR: 0.0007121875138125077 Training loss: 6.207874298095703
2025-12-09 06:22:04.991 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 538 LR: 0.0007110161597993325 Training loss: 6.153662204742432
2025-12-09 06:22:05.457 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 539 LR: 0.0007098433949952145 Training loss: 5.846356391906738
2025-12-09 06:22:05.924 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 540 LR: 0.000708669227240909 Training loss: 6.059216499328613
2025-12-09 06:22:06.391 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 541 LR: 0.0007074936643865501 Training loss: 6.046385765075684
2025-12-09 06:22:06.859 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 542 LR: 0.0007063167142915998 Training loss: 6.184225082397461
2025-12-09 06:22:07.326 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 543 LR: 0.0007051383848247942 Training loss: 6.009905815124512
2025-12-09 06:22:07.794 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 544 LR: 0.0007039586838640917 Training loss: 5.861295223236084
2025-12-09 06:22:08.260 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 545 LR: 0.0007027776192966206 Training loss: 6.039827346801758
2025-12-09 06:22:08.729 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 546 LR: 0.0007015951990186251 Training loss: 5.971735954284668
2025-12-09 06:22:09.196 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 547 LR: 0.0007004114309354136 Training loss: 6.3943657875061035
2025-12-09 06:22:09.664 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 548 LR: 0.0006992263229613054 Training loss: 6.15619421005249
2025-12-09 06:22:10.132 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 549 LR: 0.0006980398830195785 Training loss: 6.292499542236328
2025-12-09 06:22:10.599 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 550 LR: 0.000696852119042415 Training loss: 6.226047992706299
2025-12-09 06:22:11.065 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 551 LR: 0.0006956630389708499 Training loss: 6.105137348175049
2025-12-09 06:22:11.531 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 552 LR: 0.0006944726507547168 Training loss: 6.037280082702637
2025-12-09 06:22:11.998 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 553 LR: 0.0006932809623525957 Training loss: 6.2703399658203125
2025-12-09 06:22:12.464 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 554 LR: 0.0006920879817317588 Training loss: 6.138643264770508
2025-12-09 06:22:12.931 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 555 LR: 0.0006908937168681175 Training loss: 5.977785110473633
2025-12-09 06:22:13.397 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 556 LR: 0.0006896981757461699 Training loss: 6.014770984649658
2025-12-09 06:22:13.864 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 557 LR: 0.0006885013663589461 Training loss: 6.3066020011901855
2025-12-09 06:22:14.331 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 558 LR: 0.0006873032967079561 Training loss: 6.069610595703125
2025-12-09 06:22:14.797 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 559 LR: 0.000686103974803135 Training loss: 6.192286968231201
2025-12-09 06:22:15.263 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 560 LR: 0.0006849034086627905 Training loss: 5.9325971603393555
2025-12-09 06:22:15.731 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 561 LR: 0.0006837016063135491 Training loss: 6.092118740081787
2025-12-09 06:22:16.196 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 562 LR: 0.0006824985757903016 Training loss: 5.941325664520264
2025-12-09 06:22:16.664 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 563 LR: 0.0006812943251361505 Training loss: 5.779540061950684
2025-12-09 06:22:17.131 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 564 LR: 0.0006800888624023553 Training loss: 6.06511926651001
2025-12-09 06:22:17.597 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 565 LR: 0.0006788821956482796 Training loss: 5.973557472229004
2025-12-09 06:22:18.064 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 566 LR: 0.0006776743329413364 Training loss: 6.001845359802246
2025-12-09 06:22:18.531 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 567 LR: 0.0006764652823569344 Training loss: 5.722583770751953
2025-12-09 06:22:18.999 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 568 LR: 0.0006752550519784246 Training loss: 6.310602188110352
2025-12-09 06:22:19.465 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 569 LR: 0.0006740436498970453 Training loss: 6.1380791664123535
2025-12-09 06:22:19.932 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 570 LR: 0.0006728310842118683 Training loss: 5.975714683532715
2025-12-09 06:22:20.399 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 571 LR: 0.0006716173630297455 Training loss: 6.261602878570557
2025-12-09 06:22:20.868 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 572 LR: 0.0006704024944652537 Training loss: 6.119521141052246
2025-12-09 06:22:21.336 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 573 LR: 0.0006691864866406407 Training loss: 5.914389133453369
2025-12-09 06:22:21.803 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 574 LR: 0.0006679693476857712 Training loss: 6.090519428253174
2025-12-09 06:22:22.270 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 575 LR: 0.0006667510857380722 Training loss: 6.023551940917969
2025-12-09 06:22:22.737 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 576 LR: 0.0006655317089424791 Training loss: 6.22312068939209
2025-12-09 06:22:23.205 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 577 LR: 0.0006643112254513802 Training loss: 6.120436191558838
2025-12-09 06:22:23.672 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 578 LR: 0.0006630896434245634 Training loss: 5.914721965789795
2025-12-09 06:22:24.140 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 579 LR: 0.0006618669710291606 Training loss: 6.152281284332275
2025-12-09 06:22:24.608 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 580 LR: 0.0006606432164395939 Training loss: 6.031538963317871
2025-12-09 06:22:25.075 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 581 LR: 0.0006594183878375206 Training loss: 5.865419387817383
2025-12-09 06:22:25.544 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 582 LR: 0.0006581924934117783 Training loss: 5.930459499359131
2025-12-09 06:22:26.012 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 583 LR: 0.0006569655413583307 Training loss: 5.854280471801758
2025-12-09 06:22:26.481 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 584 LR: 0.0006557375398802124 Training loss: 6.044309616088867
2025-12-09 06:22:26.949 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 585 LR: 0.0006545084971874737 Training loss: 5.791024208068848
2025-12-09 06:22:27.415 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 586 LR: 0.0006532784214971269 Training loss: 5.988039016723633
2025-12-09 06:22:27.882 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 587 LR: 0.0006520473210330902 Training loss: 6.014409065246582
2025-12-09 06:22:28.350 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 588 LR: 0.0006508152040261328 Training loss: 6.0400190353393555
2025-12-09 06:22:28.817 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 589 LR: 0.0006495820787138209 Training loss: 6.077284336090088
2025-12-09 06:22:29.285 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 590 LR: 0.0006483479533404613 Training loss: 5.740128040313721
2025-12-09 06:22:29.751 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 591 LR: 0.0006471128361570475 Training loss: 6.045762538909912
2025-12-09 06:22:30.217 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 592 LR: 0.0006458767354212036 Training loss: 6.295018672943115
2025-12-09 06:22:30.685 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 593 LR: 0.0006446396593971294 Training loss: 5.9323601722717285
2025-12-09 06:22:31.153 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 594 LR: 0.0006434016163555452 Training loss: 6.038866996765137
2025-12-09 06:22:31.620 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 595 LR: 0.0006421626145736366 Training loss: 6.048922538757324
2025-12-09 06:22:32.086 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 596 LR: 0.0006409226623349991 Training loss: 5.905361652374268
2025-12-09 06:22:32.553 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 597 LR: 0.0006396817679295822 Training loss: 5.911748886108398
2025-12-09 06:22:33.021 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 598 LR: 0.0006384399396536354 Training loss: 5.945967197418213
2025-12-09 06:22:33.487 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 599 LR: 0.0006371971858096508 Training loss: 5.968288421630859
2025-12-09 06:22:33.954 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 600 LR: 0.0006359535147063091 Training loss: 5.927513599395752
2025-12-09 06:22:34.421 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 601 LR: 0.0006347089346584234 Training loss: 5.996970176696777
2025-12-09 06:22:34.889 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 602 LR: 0.0006334634539868836 Training loss: 6.087929725646973
2025-12-09 06:22:35.357 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 603 LR: 0.0006322170810186012 Training loss: 6.008944034576416
2025-12-09 06:22:35.825 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 604 LR: 0.0006309698240864529 Training loss: 5.985542297363281
2025-12-09 06:22:36.290 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 605 LR: 0.0006297216915292259 Training loss: 5.9658403396606445
2025-12-09 06:22:36.758 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 606 LR: 0.000628472691691561 Training loss: 6.023772239685059
2025-12-09 06:22:37.226 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 607 LR: 0.0006272228329238978 Training loss: 6.300682544708252
2025-12-09 06:22:37.693 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 608 LR: 0.0006259721235824182 Training loss: 6.007139682769775
2025-12-09 06:22:38.160 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 609 LR: 0.0006247205720289907 Training loss: 6.12792444229126
2025-12-09 06:22:38.627 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 610 LR: 0.0006234681866311148 Training loss: 6.280464172363281
2025-12-09 06:22:39.096 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 611 LR: 0.0006222149757618649 Training loss: 6.024805068969727
2025-12-09 06:22:39.562 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 612 LR: 0.0006209609477998338 Training loss: 5.722262382507324
2025-12-09 06:22:40.031 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 613 LR: 0.0006197061111290779 Training loss: 5.937759876251221
2025-12-09 06:22:40.498 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 614 LR: 0.0006184504741390595 Training loss: 5.995314598083496
2025-12-09 06:22:40.964 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 615 LR: 0.0006171940452245924 Training loss: 6.054802417755127
2025-12-09 06:22:41.433 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 616 LR: 0.0006159368327857844 Training loss: 5.9565229415893555
2025-12-09 06:22:41.900 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 617 LR: 0.0006146788452279818 Training loss: 5.864750385284424
2025-12-09 06:22:42.367 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 618 LR: 0.0006134200909617135 Training loss: 5.772416114807129
2025-12-09 06:22:42.835 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 619 LR: 0.0006121605784026339 Training loss: 5.703723430633545
2025-12-09 06:22:43.303 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 620 LR: 0.0006109003159714674 Training loss: 6.023716926574707
2025-12-09 06:22:43.770 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 621 LR: 0.0006096393120939516 Training loss: 6.2180938720703125
2025-12-09 06:22:44.237 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 622 LR: 0.0006083775752007818 Training loss: 6.046746730804443
2025-12-09 06:22:44.704 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 623 LR: 0.0006071151137275531 Training loss: 6.1374359130859375
2025-12-09 06:22:45.170 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 624 LR: 0.0006058519361147054 Training loss: 5.784409046173096
2025-12-09 06:22:45.637 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 625 LR: 0.0006045880508074668 Training loss: 6.178706169128418
2025-12-09 06:22:46.104 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 626 LR: 0.0006033234662557962 Training loss: 5.895832061767578
2025-12-09 06:22:46.572 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 627 LR: 0.0006020581909143279 Training loss: 6.089479446411133
2025-12-09 06:22:47.039 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 628 LR: 0.0006007922332423145 Training loss: 6.212917327880859
2025-12-09 06:22:47.505 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 629 LR: 0.0005995256017035703 Training loss: 5.797652244567871
2025-12-09 06:22:47.972 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 630 LR: 0.0005982583047664151 Training loss: 5.944849014282227
2025-12-09 06:22:48.439 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 631 LR: 0.0005969903509036172 Training loss: 6.190230369567871
2025-12-09 06:22:48.905 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 632 LR: 0.0005957217485923371 Training loss: 5.9897780418396
2025-12-09 06:22:49.373 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 633 LR: 0.0005944525063140702 Training loss: 6.087790489196777
2025-12-09 06:22:49.840 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 634 LR: 0.0005931826325545911 Training loss: 5.673516750335693
2025-12-09 06:22:50.307 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 635 LR: 0.0005919121358038958 Training loss: 5.978404521942139
2025-12-09 06:22:50.774 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 636 LR: 0.0005906410245561459 Training loss: 5.837960720062256
2025-12-09 06:22:51.241 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 637 LR: 0.0005893693073096108 Training loss: 6.021878242492676
2025-12-09 06:22:51.709 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 638 LR: 0.000588096992566612 Training loss: 6.026627063751221
2025-12-09 06:22:52.175 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 639 LR: 0.0005868240888334653 Training loss: 6.021473407745361
2025-12-09 06:22:52.643 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 640 LR: 0.0005855506046204242 Training loss: 5.998428821563721
2025-12-09 06:22:53.111 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 641 LR: 0.0005842765484416237 Training loss: 6.003559112548828
2025-12-09 06:22:53.578 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 642 LR: 0.0005830019288150222 Training loss: 5.768594264984131
2025-12-09 06:22:54.045 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 643 LR: 0.0005817267542623451 Training loss: 5.879754543304443
2025-12-09 06:22:54.514 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 644 LR: 0.0005804510333090287 Training loss: 5.959500312805176
2025-12-09 06:22:54.980 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 645 LR: 0.0005791747744841615 Training loss: 6.03556489944458
2025-12-09 06:22:55.447 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 646 LR: 0.0005778979863204283 Training loss: 5.772002696990967
2025-12-09 06:22:55.914 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 647 LR: 0.0005766206773540531 Training loss: 5.8848700523376465
2025-12-09 06:22:56.380 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 648 LR: 0.0005753428561247416 Training loss: 5.880325794219971
2025-12-09 06:22:56.847 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 649 LR: 0.0005740645311756245 Training loss: 5.946087837219238
2025-12-09 06:22:57.313 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 650 LR: 0.0005727857110532 Training loss: 5.6060872077941895
2025-12-09 06:22:57.780 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 651 LR: 0.0005715064043072771 Training loss: 5.979222774505615
2025-12-09 06:22:58.247 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 652 LR: 0.0005702266194909183 Training loss: 6.058495044708252
2025-12-09 06:22:58.714 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 653 LR: 0.0005689463651603818 Training loss: 5.826672554016113
2025-12-09 06:22:59.181 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 654 LR: 0.0005676656498750656 Training loss: 6.0508294105529785
2025-12-09 06:22:59.648 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 655 LR: 0.0005663844821974488 Training loss: 6.319285869598389
2025-12-09 06:23:00.115 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 656 LR: 0.0005651028706930357 Training loss: 5.677794456481934
2025-12-09 06:23:00.583 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 657 LR: 0.0005638208239302974 Training loss: 5.841457366943359
2025-12-09 06:23:01.051 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 658 LR: 0.0005625383504806149 Training loss: 5.72510290145874
2025-12-09 06:23:01.518 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 659 LR: 0.0005612554589182227 Training loss: 5.902950286865234
2025-12-09 06:23:01.984 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 660 LR: 0.0005599721578201499 Training loss: 6.084598064422607
2025-12-09 06:23:02.453 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 661 LR: 0.0005586884557661637 Training loss: 5.798118591308594
2025-12-09 06:23:02.921 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 662 LR: 0.0005574043613387125 Training loss: 5.912379741668701
2025-12-09 06:23:03.388 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 663 LR: 0.0005561198831228676 Training loss: 5.961943626403809
2025-12-09 06:23:03.855 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 664 LR: 0.0005548350297062658 Training loss: 5.870349407196045
2025-12-09 06:23:04.322 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 665 LR: 0.0005535498096790534 Training loss: 5.891114234924316
2025-12-09 06:23:04.791 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 666 LR: 0.0005522642316338268 Training loss: 5.983671188354492
2025-12-09 06:23:05.258 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 667 LR: 0.0005509783041655764 Training loss: 5.984257698059082
2025-12-09 06:23:05.726 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 668 LR: 0.0005496920358716291 Training loss: 6.13505744934082
2025-12-09 06:23:06.193 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 669 LR: 0.0005484054353515896 Training loss: 5.5110578536987305
2025-12-09 06:23:06.660 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 670 LR: 0.0005471185112072845 Training loss: 5.845148086547852
2025-12-09 06:23:07.128 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 671 LR: 0.0005458312720427037 Training loss: 5.928121089935303
2025-12-09 06:23:07.595 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 672 LR: 0.0005445437264639432 Training loss: 5.6271891593933105
2025-12-09 06:23:08.062 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 673 LR: 0.0005432558830791479 Training loss: 5.97352933883667
2025-12-09 06:23:08.529 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 674 LR: 0.0005419677504984534 Training loss: 6.002074241638184
2025-12-09 06:23:08.997 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 675 LR: 0.0005406793373339292 Training loss: 5.8104376792907715
2025-12-09 06:23:09.464 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 676 LR: 0.0005393906521995202 Training loss: 6.171755790710449
2025-12-09 06:23:09.932 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 677 LR: 0.0005381017037109899 Training loss: 5.847849369049072
2025-12-09 06:23:10.399 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 678 LR: 0.0005368125004858624 Training loss: 5.881814002990723
2025-12-09 06:23:10.866 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 679 LR: 0.000535523051143365 Training loss: 5.994688034057617
2025-12-09 06:23:11.333 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 680 LR: 0.0005342333643043704 Training loss: 6.094080448150635
2025-12-09 06:23:11.800 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 681 LR: 0.0005329434485913392 Training loss: 5.897552490234375
2025-12-09 06:23:12.267 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 682 LR: 0.0005316533126282621 Training loss: 5.683628559112549
2025-12-09 06:23:12.734 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 683 LR: 0.0005303629650406024 Training loss: 5.751935958862305
2025-12-09 06:23:13.201 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 684 LR: 0.0005290724144552379 Training loss: 5.9528374671936035
2025-12-09 06:23:13.668 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 685 LR: 0.0005277816695004043 Training loss: 5.976655006408691
2025-12-09 06:23:14.135 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 686 LR: 0.0005264907388056361 Training loss: 6.032215118408203
2025-12-09 06:23:14.602 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 687 LR: 0.00052519963100171 Training loss: 5.879661560058594
2025-12-09 06:23:15.070 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 688 LR: 0.0005239083547205866 Training loss: 5.903417587280273
2025-12-09 06:23:15.537 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 689 LR: 0.0005226169185953532 Training loss: 5.734226226806641
2025-12-09 06:23:16.005 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 690 LR: 0.0005213253312601653 Training loss: 5.903573989868164
2025-12-09 06:23:16.472 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 691 LR: 0.0005200336013501897 Training loss: 5.789977550506592
2025-12-09 06:23:16.939 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 692 LR: 0.0005187417375015465 Training loss: 5.885876655578613
2025-12-09 06:23:17.406 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 693 LR: 0.0005174497483512506 Training loss: 6.137598991394043
2025-12-09 06:23:17.873 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 694 LR: 0.0005161576425371554 Training loss: 6.037470817565918
2025-12-09 06:23:18.342 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 695 LR: 0.000514865428697894 Training loss: 5.783239364624023
2025-12-09 06:23:18.808 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 696 LR: 0.0005135731154728214 Training loss: 5.823617935180664
2025-12-09 06:23:19.275 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 697 LR: 0.000512280711501958 Training loss: 6.072936534881592
2025-12-09 06:23:19.743 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 698 LR: 0.0005109882254259297 Training loss: 5.9230570793151855
2025-12-09 06:23:20.209 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 699 LR: 0.0005096956658859122 Training loss: 5.789959907531738
2025-12-09 06:23:20.677 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 700 LR: 0.000508403041523572 Training loss: 5.70540714263916
2025-12-09 06:23:21.145 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 701 LR: 0.0005071103609810089 Training loss: 5.864384651184082
2025-12-09 06:23:21.611 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 702 LR: 0.0005058176329006986 Training loss: 5.807725429534912
2025-12-09 06:23:22.078 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 703 LR: 0.0005045248659254343 Training loss: 5.8502702713012695
2025-12-09 06:23:22.546 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 704 LR: 0.0005032320686982697 Training loss: 5.84209680557251
2025-12-09 06:23:23.013 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 705 LR: 0.0005019392498624602 Training loss: 5.785666465759277
2025-12-09 06:23:23.480 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 706 LR: 0.000500646418061406 Training loss: 6.000722885131836
2025-12-09 06:23:23.948 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 707 LR: 0.0004993535819385939 Training loss: 5.673994541168213
2025-12-09 06:23:24.416 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 708 LR: 0.0004980607501375399 Training loss: 6.032519340515137
2025-12-09 06:23:24.883 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 709 LR: 0.0004967679313017304 Training loss: 5.851055145263672
2025-12-09 06:23:25.351 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 710 LR: 0.0004954751340745658 Training loss: 5.832627773284912
2025-12-09 06:23:25.818 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 711 LR: 0.0004941823670993016 Training loss: 5.910096168518066
2025-12-09 06:23:26.284 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 712 LR: 0.0004928896390189912 Training loss: 6.057168006896973
2025-12-09 06:23:26.752 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 713 LR: 0.0004915969584764282 Training loss: 5.803464889526367
2025-12-09 06:23:27.219 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 714 LR: 0.0004903043341140879 Training loss: 5.915020942687988
2025-12-09 06:23:27.686 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 715 LR: 0.0004890117745740703 Training loss: 5.8084259033203125
2025-12-09 06:23:28.154 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 716 LR: 0.000487719288498042 Training loss: 5.890578746795654
2025-12-09 06:23:28.621 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 717 LR: 0.0004864268845271786 Training loss: 5.858270645141602
2025-12-09 06:23:29.088 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 718 LR: 0.0004851345713021062 Training loss: 5.70823335647583
2025-12-09 06:23:29.555 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 719 LR: 0.0004838423574628447 Training loss: 5.6567702293396
2025-12-09 06:23:30.022 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 720 LR: 0.0004825502516487497 Training loss: 6.0288190841674805
2025-12-09 06:23:30.490 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 721 LR: 0.0004812582624984537 Training loss: 5.8474297523498535
2025-12-09 06:23:30.957 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 722 LR: 0.0004799663986498103 Training loss: 5.896451473236084
2025-12-09 06:23:31.425 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 723 LR: 0.0004786746687398346 Training loss: 6.099342346191406
2025-12-09 06:23:31.892 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 724 LR: 0.00047738308140464686 Training loss: 5.810657978057861
2025-12-09 06:23:32.359 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 725 LR: 0.00047609164527941334 Training loss: 5.776134014129639
2025-12-09 06:23:32.827 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 726 LR: 0.00047480036899829003 Training loss: 5.759991645812988
2025-12-09 06:23:33.293 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 727 LR: 0.00047350926119436404 Training loss: 5.762973308563232
2025-12-09 06:23:33.761 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 728 LR: 0.0004722183304995958 Training loss: 5.945572853088379
2025-12-09 06:23:34.227 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 729 LR: 0.0004709275855447621 Training loss: 5.59588623046875
2025-12-09 06:23:34.694 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 730 LR: 0.00046963703495939764 Training loss: 5.651567459106445
2025-12-09 06:23:35.161 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 731 LR: 0.0004683466873717379 Training loss: 5.997030735015869
2025-12-09 06:23:35.629 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 732 LR: 0.00046705655140866074 Training loss: 6.038130760192871
2025-12-09 06:23:36.097 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 733 LR: 0.0004657666356956296 Training loss: 6.085302352905273
2025-12-09 06:23:36.564 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 734 LR: 0.0004644769488566351 Training loss: 5.780425071716309
2025-12-09 06:23:37.032 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 735 LR: 0.0004631874995141376 Training loss: 5.933200359344482
2025-12-09 06:23:37.499 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 736 LR: 0.00046189829628901034 Training loss: 5.894384384155273
2025-12-09 06:23:37.967 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 737 LR: 0.00046060934780047994 Training loss: 5.818901062011719
2025-12-09 06:23:38.434 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 738 LR: 0.00045932066266607093 Training loss: 6.122053146362305
2025-12-09 06:23:38.901 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 739 LR: 0.0004580322495015465 Training loss: 5.91628885269165
2025-12-09 06:23:39.369 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 740 LR: 0.00045674411692085226 Training loss: 5.779398441314697
2025-12-09 06:23:39.837 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 741 LR: 0.000455456273536057 Training loss: 5.768155097961426
2025-12-09 06:23:40.304 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 742 LR: 0.00045416872795729646 Training loss: 5.479480743408203
2025-12-09 06:23:40.771 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 743 LR: 0.00045288148879271575 Training loss: 5.962441444396973
2025-12-09 06:23:41.239 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 744 LR: 0.0004515945646484105 Training loss: 6.106289863586426
2025-12-09 06:23:41.707 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 745 LR: 0.00045030796412837105 Training loss: 5.636642932891846
2025-12-09 06:23:42.174 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 746 LR: 0.00044902169583442347 Training loss: 5.864704132080078
2025-12-09 06:23:42.642 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 747 LR: 0.00044773576836617336 Training loss: 5.545081615447998
2025-12-09 06:23:43.108 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 748 LR: 0.0004464501903209467 Training loss: 5.710413932800293
2025-12-09 06:23:43.574 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 749 LR: 0.0004451649702937342 Training loss: 6.614081382751465
2025-12-09 06:23:44.042 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 750 LR: 0.0004438801168771327 Training loss: 5.989441871643066
2025-12-09 06:23:44.509 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 751 LR: 0.00044259563866128754 Training loss: 5.620455265045166
2025-12-09 06:23:44.976 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 752 LR: 0.0004413115442338363 Training loss: 5.940189838409424
2025-12-09 06:23:45.445 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 753 LR: 0.0004400278421798501 Training loss: 5.895877361297607
2025-12-09 06:23:45.913 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 754 LR: 0.00043874454108177734 Training loss: 5.945780277252197
2025-12-09 06:23:46.380 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 755 LR: 0.000437461649519385 Training loss: 5.869385719299316
2025-12-09 06:23:46.848 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 756 LR: 0.0004361791760697027 Training loss: 6.003335475921631
2025-12-09 06:23:47.315 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 757 LR: 0.00043489712930696445 Training loss: 6.334963321685791
2025-12-09 06:23:47.782 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 758 LR: 0.00043361551780255115 Training loss: 5.910901069641113
2025-12-09 06:23:48.251 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 759 LR: 0.0004323343501249346 Training loss: 5.913428783416748
2025-12-09 06:23:48.718 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 760 LR: 0.00043105363483961814 Training loss: 5.9189934730529785
2025-12-09 06:23:49.184 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 761 LR: 0.00042977338050908186 Training loss: 5.910801410675049
2025-12-09 06:23:49.652 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 762 LR: 0.0004284935956927229 Training loss: 5.685042858123779
2025-12-09 06:23:50.119 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 763 LR: 0.00042721428894680017 Training loss: 5.92877721786499
2025-12-09 06:23:50.587 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 764 LR: 0.0004259354688243757 Training loss: 5.722573280334473
2025-12-09 06:23:51.055 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 765 LR: 0.00042465714387525844 Training loss: 5.8063483238220215
2025-12-09 06:23:51.523 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 766 LR: 0.0004233793226459471 Training loss: 5.7657060623168945
2025-12-09 06:23:51.992 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 767 LR: 0.0004221020136795718 Training loss: 6.037396430969238
2025-12-09 06:23:52.459 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 768 LR: 0.00042082522551583864 Training loss: 5.478235721588135
2025-12-09 06:23:52.926 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 769 LR: 0.0004195489666909713 Training loss: 5.805992603302002
2025-12-09 06:23:53.394 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 770 LR: 0.000418273245737655 Training loss: 5.617334842681885
2025-12-09 06:23:53.862 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 771 LR: 0.0004169980711849781 Training loss: 5.616131782531738
2025-12-09 06:23:54.330 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 772 LR: 0.0004157234515583764 Training loss: 5.749552249908447
2025-12-09 06:23:54.797 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 773 LR: 0.0004144493953795759 Training loss: 5.943315029144287
2025-12-09 06:23:55.265 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 774 LR: 0.00041317591116653486 Training loss: 5.892084121704102
2025-12-09 06:23:55.732 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 775 LR: 0.0004119030074333881 Training loss: 5.648956298828125
2025-12-09 06:23:56.200 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 776 LR: 0.0004106306926903891 Training loss: 5.857454299926758
2025-12-09 06:23:56.667 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 777 LR: 0.00040935897544385424 Training loss: 5.868516445159912
2025-12-09 06:23:57.136 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 778 LR: 0.0004080878641961042 Training loss: 6.136094093322754
2025-12-09 06:23:57.603 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 779 LR: 0.00040681736744540897 Training loss: 5.775565147399902
2025-12-09 06:23:58.070 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 780 LR: 0.00040554749368592994 Training loss: 5.606685638427734
2025-12-09 06:23:58.538 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 781 LR: 0.0004042782514076631 Training loss: 5.920065879821777
2025-12-09 06:23:59.004 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 782 LR: 0.00040300964909638283 Training loss: 5.726807594299316
2025-12-09 06:23:59.471 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 783 LR: 0.0004017416952335849 Training loss: 5.968114376068115
2025-12-09 06:23:59.939 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 784 LR: 0.0004004743982964298 Training loss: 5.605576992034912
2025-12-09 06:24:00.407 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 785 LR: 0.00039920776675768556 Training loss: 5.7565412521362305
2025-12-09 06:24:00.875 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 786 LR: 0.00039794180908567223 Training loss: 5.842111110687256
2025-12-09 06:24:01.343 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 787 LR: 0.000396676533744204 Training loss: 5.998059272766113
2025-12-09 06:24:01.811 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 788 LR: 0.0003954119491925333 Training loss: 5.903110504150391
2025-12-09 06:24:02.277 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 789 LR: 0.00039414806388529477 Training loss: 5.8067498207092285
2025-12-09 06:24:02.745 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 790 LR: 0.00039288488627244706 Training loss: 5.836160182952881
2025-12-09 06:24:03.213 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 791 LR: 0.00039162242479921837 Training loss: 5.7531867027282715
2025-12-09 06:24:03.680 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 792 LR: 0.0003903606879060483 Training loss: 5.610836029052734
2025-12-09 06:24:04.147 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 793 LR: 0.00038909968402853277 Training loss: 5.754672527313232
2025-12-09 06:24:04.614 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 794 LR: 0.0003878394215973663 Training loss: 5.765626907348633
2025-12-09 06:24:05.081 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 795 LR: 0.0003865799090382866 Training loss: 5.967775821685791
2025-12-09 06:24:05.548 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 796 LR: 0.00038532115477201833 Training loss: 5.9196906089782715
2025-12-09 06:24:06.015 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 797 LR: 0.00038406316721421575 Training loss: 5.971610069274902
2025-12-09 06:24:06.481 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 798 LR: 0.0003828059547754077 Training loss: 5.738533973693848
2025-12-09 06:24:06.951 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 799 LR: 0.00038154952586094037 Training loss: 5.7384138107299805
2025-12-09 06:24:07.418 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 800 LR: 0.0003802938888709222 Training loss: 5.645124912261963
2025-12-09 06:24:07.884 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 801 LR: 0.0003790390522001662 Training loss: 6.1324357986450195
2025-12-09 06:24:08.352 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 802 LR: 0.00037778502423813516 Training loss: 5.951962947845459
2025-12-09 06:24:08.820 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 803 LR: 0.0003765318133688853 Training loss: 5.893834114074707
2025-12-09 06:24:09.288 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 804 LR: 0.0003752794279710094 Training loss: 5.719192981719971
2025-12-09 06:24:09.756 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 805 LR: 0.00037402787641758193 Training loss: 5.646695613861084
2025-12-09 06:24:10.222 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 806 LR: 0.0003727771670761021 Training loss: 5.905247211456299
2025-12-09 06:24:10.691 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 807 LR: 0.000371527308308439 Training loss: 5.644716739654541
2025-12-09 06:24:11.157 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 808 LR: 0.000370278308470774 Training loss: 5.585508823394775
2025-12-09 06:24:11.625 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 809 LR: 0.00036903017591354703 Training loss: 5.926321029663086
2025-12-09 06:24:12.092 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 810 LR: 0.00036778291898139905 Training loss: 5.726807594299316
2025-12-09 06:24:12.559 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 811 LR: 0.0003665365460131165 Training loss: 5.847383975982666
2025-12-09 06:24:13.028 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 812 LR: 0.00036529106534157683 Training loss: 5.569434642791748
2025-12-09 06:24:13.495 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 813 LR: 0.0003640464852936909 Training loss: 6.139827251434326
2025-12-09 06:24:13.964 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 814 LR: 0.0003628028141903493 Training loss: 5.692925453186035
2025-12-09 06:24:14.433 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 815 LR: 0.00036156006034636465 Training loss: 5.832036018371582
2025-12-09 06:24:14.901 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 816 LR: 0.0003603182320704179 Training loss: 6.050859451293945
2025-12-09 06:24:15.370 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 817 LR: 0.0003590773376650012 Training loss: 5.740746974945068
2025-12-09 06:24:15.838 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 818 LR: 0.00035783738542636347 Training loss: 5.914417743682861
2025-12-09 06:24:16.307 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 819 LR: 0.00035659838364445503 Training loss: 5.831199645996094
2025-12-09 06:24:16.775 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 820 LR: 0.0003553603406028707 Training loss: 5.638940334320068
2025-12-09 06:24:17.244 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 821 LR: 0.0003541232645787964 Training loss: 5.812867641448975
2025-12-09 06:24:17.712 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 822 LR: 0.00035288716384295236 Training loss: 5.885923385620117
2025-12-09 06:24:18.179 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 823 LR: 0.00035165204665953874 Training loss: 5.582859039306641
2025-12-09 06:24:18.646 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 824 LR: 0.0003504179212861793 Training loss: 5.80289363861084
2025-12-09 06:24:19.113 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 825 LR: 0.00034918479597386727 Training loss: 6.065230369567871
2025-12-09 06:24:19.580 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 826 LR: 0.0003479526789669101 Training loss: 5.710422992706299
2025-12-09 06:24:20.048 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 827 LR: 0.00034672157850287313 Training loss: 6.341214656829834
2025-12-09 06:24:20.517 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 828 LR: 0.00034549150281252633 Training loss: 5.907323837280273
2025-12-09 06:24:20.985 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 829 LR: 0.00034426246011978767 Training loss: 6.12180233001709
2025-12-09 06:24:21.453 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 830 LR: 0.0003430344586416694 Training loss: 5.8759379386901855
2025-12-09 06:24:21.920 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 831 LR: 0.0003418075065882217 Training loss: 5.912018775939941
2025-12-09 06:24:22.387 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 832 LR: 0.0003405816121624795 Training loss: 5.506628036499023
2025-12-09 06:24:22.854 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 833 LR: 0.0003393567835604063 Training loss: 5.798395156860352
2025-12-09 06:24:23.322 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 834 LR: 0.0003381330289708395 Training loss: 5.916571617126465
2025-12-09 06:24:23.790 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 835 LR: 0.0003369103565754367 Training loss: 5.669247150421143
2025-12-09 06:24:24.257 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 836 LR: 0.0003356887745486198 Training loss: 5.503895282745361
2025-12-09 06:24:24.725 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 837 LR: 0.000334468291057521 Training loss: 5.577366352081299
2025-12-09 06:24:25.192 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 838 LR: 0.0003332489142619278 Training loss: 5.849240779876709
2025-12-09 06:24:25.658 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 839 LR: 0.00033203065231422903 Training loss: 5.671032428741455
2025-12-09 06:24:26.124 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 840 LR: 0.0003308135133593595 Training loss: 5.9094977378845215
2025-12-09 06:24:26.592 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 841 LR: 0.0003295975055347464 Training loss: 5.7107253074646
2025-12-09 06:24:27.059 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 842 LR: 0.0003283826369702546 Training loss: 5.765371799468994
2025-12-09 06:24:27.527 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 843 LR: 0.00032716891578813166 Training loss: 5.748772621154785
2025-12-09 06:24:27.994 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 844 LR: 0.0003259563501029548 Training loss: 6.133349895477295
2025-12-09 06:24:28.461 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 845 LR: 0.00032474494802157527 Training loss: 5.8919358253479
2025-12-09 06:24:28.929 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 846 LR: 0.00032353471764306563 Training loss: 5.7171311378479
2025-12-09 06:24:29.397 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 847 LR: 0.00032232566705866383 Training loss: 5.739695072174072
2025-12-09 06:24:29.864 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 848 LR: 0.0003211178043517205 Training loss: 5.610901355743408
2025-12-09 06:24:30.331 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 849 LR: 0.0003199111375976449 Training loss: 5.841629981994629
2025-12-09 06:24:30.800 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 850 LR: 0.0003187056748638497 Training loss: 5.891391277313232
2025-12-09 06:24:31.267 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 851 LR: 0.00031750142420969855 Training loss: 5.6829986572265625
2025-12-09 06:24:31.734 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 852 LR: 0.00031629839368645086 Training loss: 5.513379096984863
2025-12-09 06:24:32.202 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 853 LR: 0.00031509659133720946 Training loss: 5.670171737670898
2025-12-09 06:24:32.669 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 854 LR: 0.00031389602519686513 Training loss: 5.73388671875
2025-12-09 06:24:33.136 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 855 LR: 0.00031269670329204396 Training loss: 5.537606239318848
2025-12-09 06:24:33.603 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 856 LR: 0.000311498633641054 Training loss: 5.649070739746094
2025-12-09 06:24:34.070 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 857 LR: 0.0003103018242538302 Training loss: 5.819459438323975
2025-12-09 06:24:34.538 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 858 LR: 0.0003091062831318825 Training loss: 5.781098365783691
2025-12-09 06:24:35.004 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 859 LR: 0.00030791201826824117 Training loss: 5.658227443695068
2025-12-09 06:24:35.471 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 860 LR: 0.0003067190376474043 Training loss: 5.647216796875
2025-12-09 06:24:35.938 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 861 LR: 0.000305527349245283 Training loss: 5.780848503112793
2025-12-09 06:24:36.406 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 862 LR: 0.00030433696102915013 Training loss: 5.74306058883667
2025-12-09 06:24:36.872 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 863 LR: 0.0003031478809575852 Training loss: 5.861761093139648
2025-12-09 06:24:37.340 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 864 LR: 0.0003019601169804216 Training loss: 5.910327911376953
2025-12-09 06:24:37.807 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 865 LR: 0.00030077367703869464 Training loss: 5.590864181518555
2025-12-09 06:24:38.274 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 866 LR: 0.0002995885690645863 Training loss: 5.936538219451904
2025-12-09 06:24:38.742 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 867 LR: 0.000298404800981375 Training loss: 5.564272403717041
2025-12-09 06:24:39.209 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 868 LR: 0.0002972223807033794 Training loss: 5.901744842529297
2025-12-09 06:24:39.675 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 869 LR: 0.00029604131613590823 Training loss: 5.9608473777771
2025-12-09 06:24:40.142 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 870 LR: 0.00029486161517520596 Training loss: 5.9190168380737305
2025-12-09 06:24:40.610 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 871 LR: 0.0002936832857084003 Training loss: 5.666972637176514
2025-12-09 06:24:41.077 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 872 LR: 0.00029250633561345 Training loss: 5.884599685668945
2025-12-09 06:24:41.545 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 873 LR: 0.0002913307727590911 Training loss: 5.9547343254089355
2025-12-09 06:24:42.012 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 874 LR: 0.0002901566050047855 Training loss: 5.399609088897705
2025-12-09 06:24:42.479 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 875 LR: 0.0002889838402006677 Training loss: 5.781991004943848
2025-12-09 06:24:42.947 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 876 LR: 0.0002878124861874923 Training loss: 5.180776119232178
2025-12-09 06:24:43.414 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 877 LR: 0.0002866425507965822 Training loss: 5.931544780731201
2025-12-09 06:24:43.880 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 878 LR: 0.00028547404184977546 Training loss: 5.77543830871582
2025-12-09 06:24:44.348 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 879 LR: 0.0002843069671593734 Training loss: 5.804221153259277
2025-12-09 06:24:44.814 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 880 LR: 0.0002831413345280882 Training loss: 5.54613733291626
2025-12-09 06:24:45.280 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 881 LR: 0.00028197715174899183 Training loss: 5.608175277709961
2025-12-09 06:24:45.749 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 882 LR: 0.00028081442660546124 Training loss: 5.7656168937683105
2025-12-09 06:24:46.216 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 883 LR: 0.00027965316687112975 Training loss: 5.698238372802734
2025-12-09 06:24:46.684 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 884 LR: 0.00027849338030983255 Training loss: 5.9366960525512695
2025-12-09 06:24:47.151 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 885 LR: 0.0002773350746755553 Training loss: 5.60804557800293
2025-12-09 06:24:47.618 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 886 LR: 0.0002761782577123837 Training loss: 5.941510200500488
2025-12-09 06:24:48.085 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 887 LR: 0.00027502293715444973 Training loss: 5.821316719055176
2025-12-09 06:24:48.552 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 888 LR: 0.0002738691207258812 Training loss: 5.706758499145508
2025-12-09 06:24:49.020 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 889 LR: 0.0002727168161407497 Training loss: 5.784595012664795
2025-12-09 06:24:49.486 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 890 LR: 0.00027156603110301924 Training loss: 5.743590354919434
2025-12-09 06:24:49.954 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 891 LR: 0.0002704167733064941 Training loss: 5.413718223571777
2025-12-09 06:24:50.420 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 892 LR: 0.0002692690504347688 Training loss: 5.852714538574219
2025-12-09 06:24:50.887 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 893 LR: 0.00026812287016117476 Training loss: 5.8288254737854
2025-12-09 06:24:51.354 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 894 LR: 0.0002669782401487307 Training loss: 5.985422611236572
2025-12-09 06:24:51.822 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 895 LR: 0.00026583516805009057 Training loss: 5.665998458862305
2025-12-09 06:24:52.289 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 896 LR: 0.00026469366150749254 Training loss: 5.764840126037598
2025-12-09 06:24:52.756 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 897 LR: 0.00026355372815270835 Training loss: 5.643150329589844
2025-12-09 06:24:53.224 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 898 LR: 0.00026241537560699093 Training loss: 5.726045608520508
2025-12-09 06:24:53.690 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 899 LR: 0.00026127861148102547 Training loss: 5.753873825073242
2025-12-09 06:24:54.158 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 900 LR: 0.0002601434433748771 Training loss: 5.58125114440918
2025-12-09 06:24:54.627 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 901 LR: 0.0002590098788779396 Training loss: 5.737128734588623
2025-12-09 06:24:55.093 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 902 LR: 0.0002578779255688869 Training loss: 5.800232410430908
2025-12-09 06:24:55.561 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 903 LR: 0.00025674759101562006 Training loss: 6.009848594665527
2025-12-09 06:24:56.028 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 904 LR: 0.00025561888277521793 Training loss: 6.100111961364746
2025-12-09 06:24:56.494 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 905 LR: 0.0002544918083938863 Training loss: 5.639158248901367
2025-12-09 06:24:56.961 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 906 LR: 0.00025336637540690737 Training loss: 5.452754020690918
2025-12-09 06:24:57.429 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 907 LR: 0.0002522425913385896 Training loss: 5.7961273193359375
2025-12-09 06:24:57.896 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 908 LR: 0.0002511204637022173 Training loss: 5.533639430999756
2025-12-09 06:24:58.362 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 909 LR: 0.0002500000000000001 Training loss: 6.017449855804443
2025-12-09 06:24:58.830 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 910 LR: 0.0002488812077230232 Training loss: 5.4676313400268555
2025-12-09 06:24:59.297 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 911 LR: 0.00024776409435119773 Training loss: 5.7960686683654785
2025-12-09 06:24:59.765 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 912 LR: 0.00024664866735320885 Training loss: 5.625445365905762
2025-12-09 06:25:00.233 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 913 LR: 0.00024553493418646847 Training loss: 5.739305019378662
2025-12-09 06:25:00.700 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 914 LR: 0.00024442290229706345 Training loss: 5.799587249755859
2025-12-09 06:25:01.166 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 915 LR: 0.00024331257911970627 Training loss: 5.9135284423828125
2025-12-09 06:25:01.636 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 916 LR: 0.0002422039720776858 Training loss: 5.8652849197387695
2025-12-09 06:25:02.102 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 917 LR: 0.0002410970885828171 Training loss: 6.03077507019043
2025-12-09 06:25:02.570 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 918 LR: 0.00023999193603539232 Training loss: 5.8304572105407715
2025-12-09 06:25:03.036 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 919 LR: 0.00023888852182413084 Training loss: 5.578185081481934
2025-12-09 06:25:03.504 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 920 LR: 0.00023778685332613008 Training loss: 5.909846782684326
2025-12-09 06:25:03.971 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 921 LR: 0.00023668693790681634 Training loss: 5.378263473510742
2025-12-09 06:25:04.438 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 922 LR: 0.000235588782919895 Training loss: 5.833137035369873
2025-12-09 06:25:04.905 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 923 LR: 0.00023449239570730207 Training loss: 5.598538398742676
2025-12-09 06:25:05.373 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 924 LR: 0.0002333977835991545 Training loss: 5.769738674163818
2025-12-09 06:25:05.840 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 925 LR: 0.0002323049539137015 Training loss: 5.672354698181152
2025-12-09 06:25:06.308 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 926 LR: 0.00023121391395727542 Training loss: 5.696536540985107
2025-12-09 06:25:06.774 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 927 LR: 0.00023012467102424372 Training loss: 5.7949676513671875
2025-12-09 06:25:07.243 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 928 LR: 0.00022903723239695812 Training loss: 5.73016881942749
2025-12-09 06:25:07.710 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 929 LR: 0.00022795160534570865 Training loss: 5.748900413513184
2025-12-09 06:25:08.177 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 930 LR: 0.00022686779712867316 Training loss: 5.721595764160156
2025-12-09 06:25:08.645 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 931 LR: 0.0002257858149918688 Training loss: 5.5197625160217285
2025-12-09 06:25:09.112 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 932 LR: 0.00022470566616910497 Training loss: 5.84758186340332
2025-12-09 06:25:09.578 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 933 LR: 0.00022362735788193367 Training loss: 5.648962020874023
2025-12-09 06:25:10.047 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 934 LR: 0.0002225508973396016 Training loss: 5.605413913726807
2025-12-09 06:25:10.514 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 935 LR: 0.00022147629173900203 Training loss: 5.737784385681152
2025-12-09 06:25:10.982 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 936 LR: 0.00022040354826462666 Training loss: 5.834323883056641
2025-12-09 06:25:11.450 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 937 LR: 0.00021933267408851754 Training loss: 5.732626914978027
2025-12-09 06:25:11.917 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 938 LR: 0.0002182636763702192 Training loss: 6.027937412261963
2025-12-09 06:25:12.385 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 939 LR: 0.0002171965622567308 Training loss: 6.0556769371032715
2025-12-09 06:25:12.853 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 940 LR: 0.0002161313388824579 Training loss: 5.7963972091674805
2025-12-09 06:25:13.321 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 941 LR: 0.00021506801336916597 Training loss: 5.319733619689941
2025-12-09 06:25:13.788 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 942 LR: 0.00021400659282593083 Training loss: 5.731003761291504
2025-12-09 06:25:14.255 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 943 LR: 0.0002129470843490932 Training loss: 5.60092830657959
2025-12-09 06:25:14.721 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 944 LR: 0.00021188949502220985 Training loss: 5.676009654998779
2025-12-09 06:25:15.189 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 945 LR: 0.00021083383191600674 Training loss: 5.481441020965576
2025-12-09 06:25:15.656 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 946 LR: 0.00020978010208833186 Training loss: 5.974453449249268
2025-12-09 06:25:16.123 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 947 LR: 0.00020872831258410724 Training loss: 5.39748477935791
2025-12-09 06:25:16.591 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 948 LR: 0.0002076784704352835 Training loss: 6.05164098739624
2025-12-09 06:25:17.059 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 949 LR: 0.0002066305826607911 Training loss: 5.868663787841797
2025-12-09 06:25:17.526 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 950 LR: 0.0002055846562664944 Training loss: 5.75549840927124
2025-12-09 06:25:17.993 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 951 LR: 0.00020454069824514442 Training loss: 5.796819686889648
2025-12-09 06:25:18.460 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 952 LR: 0.00020349871557633244 Training loss: 5.6682658195495605
2025-12-09 06:25:18.928 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 953 LR: 0.00020245871522644283 Training loss: 5.555483818054199
2025-12-09 06:25:19.394 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 954 LR: 0.00020142070414860702 Training loss: 5.652686595916748
2025-12-09 06:25:19.861 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 955 LR: 0.00020038468928265663 Training loss: 5.762458324432373
2025-12-09 06:25:20.329 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 956 LR: 0.00019935067755507714 Training loss: 5.846061706542969
2025-12-09 06:25:20.796 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 957 LR: 0.00019831867587896218 Training loss: 5.446188926696777
2025-12-09 06:25:21.263 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 958 LR: 0.00019728869115396574 Training loss: 5.664962291717529
2025-12-09 06:25:21.730 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 959 LR: 0.00019626073026625818 Training loss: 5.593261241912842
2025-12-09 06:25:22.196 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 960 LR: 0.00019523480008847854 Training loss: 5.763365745544434
2025-12-09 06:25:22.664 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 961 LR: 0.00019421090747968878 Training loss: 5.804842472076416
2025-12-09 06:25:23.131 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 962 LR: 0.00019318905928532908 Training loss: 5.532291889190674
2025-12-09 06:25:23.599 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 963 LR: 0.00019216926233717085 Training loss: 5.645594120025635
2025-12-09 06:25:24.067 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 964 LR: 0.00019115152345327153 Training loss: 5.838769912719727
2025-12-09 06:25:24.534 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 965 LR: 0.00019013584943792884 Training loss: 5.585958480834961
2025-12-09 06:25:25.002 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 966 LR: 0.00018912224708163562 Training loss: 5.7097601890563965
2025-12-09 06:25:25.470 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 967 LR: 0.00018811072316103405 Training loss: 5.808177947998047
2025-12-09 06:25:25.937 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 968 LR: 0.00018710128443887063 Training loss: 5.597345352172852
2025-12-09 06:25:26.405 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 969 LR: 0.00018609393766395082 Training loss: 5.730659008026123
2025-12-09 06:25:26.872 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 970 LR: 0.00018508868957109364 Training loss: 5.53712797164917
2025-12-09 06:25:27.340 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 971 LR: 0.00018408554688108787 Training loss: 5.563708782196045
2025-12-09 06:25:27.806 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 972 LR: 0.0001830845163006448 Training loss: 5.635926723480225
2025-12-09 06:25:28.272 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 973 LR: 0.00018208560452235623 Training loss: 5.7686638832092285
2025-12-09 06:25:28.740 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 974 LR: 0.00018108881822464696 Training loss: 5.7326579093933105
2025-12-09 06:25:29.206 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 975 LR: 0.00018009416407173257 Training loss: 5.912825107574463
2025-12-09 06:25:29.673 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 976 LR: 0.00017910164871357332 Training loss: 5.781198024749756
2025-12-09 06:25:30.140 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 977 LR: 0.00017811127878582955 Training loss: 5.548468589782715
2025-12-09 06:25:30.607 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 978 LR: 0.00017712306090981894 Training loss: 5.527726650238037
2025-12-09 06:25:31.074 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 979 LR: 0.00017613700169247056 Training loss: 5.667447090148926
2025-12-09 06:25:31.542 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 980 LR: 0.00017515310772628145 Training loss: 5.75480842590332
2025-12-09 06:25:32.009 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 981 LR: 0.00017417138558927244 Training loss: 5.946415424346924
2025-12-09 06:25:32.476 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 982 LR: 0.00017319184184494418 Training loss: 5.765820026397705
2025-12-09 06:25:32.942 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 983 LR: 0.00017221448304223326 Training loss: 5.735979080200195
2025-12-09 06:25:33.409 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 984 LR: 0.00017123931571546826 Training loss: 5.5757622718811035
2025-12-09 06:25:33.875 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 985 LR: 0.0001702663463843264 Training loss: 5.762546062469482
2025-12-09 06:25:34.343 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 986 LR: 0.0001692955815537895 Training loss: 5.907923698425293
2025-12-09 06:25:34.810 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 987 LR: 0.0001683270277141014 Training loss: 5.6144819259643555
2025-12-09 06:25:35.278 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 988 LR: 0.00016736069134072278 Training loss: 5.64561653137207
2025-12-09 06:25:35.746 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 989 LR: 0.00016639657889429017 Training loss: 5.276859283447266
2025-12-09 06:25:36.213 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 990 LR: 0.00016543469682057105 Training loss: 5.741942405700684
2025-12-09 06:25:36.679 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 991 LR: 0.00016447505155042086 Training loss: 5.681844234466553
2025-12-09 06:25:37.147 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 992 LR: 0.00016351764949974136 Training loss: 5.922126770019531
2025-12-09 06:25:37.615 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 993 LR: 0.00016256249706943628 Training loss: 5.5622382164001465
2025-12-09 06:25:38.082 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 994 LR: 0.00016160960064536906 Training loss: 5.775669097900391
2025-12-09 06:25:38.550 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 995 LR: 0.00016065896659832026 Training loss: 5.265828609466553
2025-12-09 06:25:39.017 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 996 LR: 0.00015971060128394484 Training loss: 5.517321586608887
2025-12-09 06:25:39.484 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 997 LR: 0.00015876451104272955 Training loss: 5.685500621795654
2025-12-09 06:25:39.951 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 998 LR: 0.00015782070219995127 Training loss: 5.649285793304443
2025-12-09 06:25:40.418 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 999 LR: 0.00015687918106563326 Training loss: 5.762657165527344
2025-12-09 06:25:40.885 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1000 LR: 0.00015593995393450445 Training loss: 5.66349458694458
2025-12-09 06:25:41.353 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1001 LR: 0.0001550030270859565 Training loss: 5.7989301681518555
2025-12-09 06:25:41.819 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1002 LR: 0.00015406840678400203 Training loss: 5.145389556884766
2025-12-09 06:25:42.286 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1003 LR: 0.00015313609927723333 Training loss: 5.673158645629883
2025-12-09 06:25:42.754 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1004 LR: 0.000152206110798779 Training loss: 5.64682149887085
2025-12-09 06:25:43.222 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1005 LR: 0.00015127844756626435 Training loss: 5.792689323425293
2025-12-09 06:25:43.689 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1006 LR: 0.0001503531157817684 Training loss: 5.793715476989746
2025-12-09 06:25:44.156 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1007 LR: 0.0001494301216317822 Training loss: 5.811964988708496
2025-12-09 06:25:44.624 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1008 LR: 0.00014850947128716913 Training loss: 5.673066139221191
2025-12-09 06:25:45.091 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1009 LR: 0.00014759117090312195 Training loss: 5.61484956741333
2025-12-09 06:25:45.558 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1010 LR: 0.00014667522661912248 Training loss: 5.774988651275635
2025-12-09 06:25:46.026 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1011 LR: 0.00014576164455890013 Training loss: 5.7139997482299805
2025-12-09 06:25:46.492 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1012 LR: 0.00014485043083039151 Training loss: 5.721340179443359
2025-12-09 06:25:46.959 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1013 LR: 0.00014394159152569902 Training loss: 5.804656028747559
2025-12-09 06:25:47.428 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1014 LR: 0.00014303513272105056 Training loss: 5.619495868682861
2025-12-09 06:25:47.895 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1015 LR: 0.00014213106047675857 Training loss: 5.593759059906006
2025-12-09 06:25:48.362 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1016 LR: 0.00014122938083717962 Training loss: 5.771063327789307
2025-12-09 06:25:48.830 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1017 LR: 0.00014033009983067452 Training loss: 5.653869152069092
2025-12-09 06:25:49.297 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1018 LR: 0.00013943322346956667 Training loss: 5.556626319885254
2025-12-09 06:25:49.764 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1019 LR: 0.00013853875775010356 Training loss: 5.760036468505859
2025-12-09 06:25:50.231 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1020 LR: 0.0001376467086524156 Training loss: 5.364576816558838
2025-12-09 06:25:50.698 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1021 LR: 0.00013675708214047578 Training loss: 5.784079551696777
2025-12-09 06:25:51.165 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1022 LR: 0.0001358698841620614 Training loss: 5.53885555267334
2025-12-09 06:25:51.633 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1023 LR: 0.0001349851206487127 Training loss: 5.544549942016602
2025-12-09 06:25:52.099 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1024 LR: 0.00013410279751569399 Training loss: 5.770901679992676
2025-12-09 06:25:52.566 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1025 LR: 0.0001332229206619538 Training loss: 5.555123805999756
2025-12-09 06:25:53.033 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1026 LR: 0.00013234549597008571 Training loss: 5.731255054473877
2025-12-09 06:25:53.501 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1027 LR: 0.00013147052930628884 Training loss: 5.467245101928711
2025-12-09 06:25:53.969 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1028 LR: 0.0001305980265203286 Training loss: 5.678750514984131
2025-12-09 06:25:54.436 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1029 LR: 0.0001297279934454978 Training loss: 5.945334434509277
2025-12-09 06:25:54.903 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1030 LR: 0.00012886043589857725 Training loss: 5.413649559020996
2025-12-09 06:25:55.371 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1031 LR: 0.00012799535967979747 Training loss: 5.805866718292236
2025-12-09 06:25:55.840 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1032 LR: 0.0001271327705727991 Training loss: 5.886573314666748
2025-12-09 06:25:56.308 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1033 LR: 0.00012627267434459538 Training loss: 5.6361613273620605
2025-12-09 06:25:56.775 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1034 LR: 0.000125415076745532 Training loss: 5.95461368560791
2025-12-09 06:25:57.243 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1035 LR: 0.0001245599835092504 Training loss: 5.764476776123047
2025-12-09 06:25:57.712 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1036 LR: 0.00012370740035264828 Training loss: 5.6712541580200195
2025-12-09 06:25:58.177 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1037 LR: 0.0001228573329758413 Training loss: 5.528520584106445
2025-12-09 06:25:58.646 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1038 LR: 0.00012200978706212606 Training loss: 5.661635398864746
2025-12-09 06:25:59.113 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1039 LR: 0.00012116476827794104 Training loss: 5.485980987548828
2025-12-09 06:25:59.581 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1040 LR: 0.00012032228227282915 Training loss: 5.700064659118652
2025-12-09 06:26:00.048 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1041 LR: 0.00011948233467939979 Training loss: 5.628999710083008
2025-12-09 06:26:00.517 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1042 LR: 0.00011864493111329145 Training loss: 5.58160400390625
2025-12-09 06:26:00.986 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1043 LR: 0.00011781007717313392 Training loss: 5.626138687133789
2025-12-09 06:26:01.453 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1044 LR: 0.00011697777844051105 Training loss: 5.573593616485596
2025-12-09 06:26:01.921 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1045 LR: 0.00011614804047992322 Training loss: 5.660101413726807
2025-12-09 06:26:02.389 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1046 LR: 0.00011532086883875025 Training loss: 5.67253303527832
2025-12-09 06:26:02.857 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1047 LR: 0.00011449626904721472 Training loss: 5.505903244018555
2025-12-09 06:26:03.324 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1048 LR: 0.00011367424661834369 Training loss: 5.432671070098877
2025-12-09 06:26:03.791 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1049 LR: 0.00011285480704793377 Training loss: 5.883012771606445
2025-12-09 06:26:04.259 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1050 LR: 0.00011203795581451288 Training loss: 5.571609020233154
2025-12-09 06:26:04.727 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1051 LR: 0.00011122369837930362 Training loss: 5.886396408081055
2025-12-09 06:26:05.194 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1052 LR: 0.00011041204018618833 Training loss: 5.545042991638184
2025-12-09 06:26:05.661 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1053 LR: 0.0001096029866616704 Training loss: 5.684857368469238
2025-12-09 06:26:06.128 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1054 LR: 0.00010879654321484011 Training loss: 5.743921279907227
2025-12-09 06:26:06.595 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1055 LR: 0.00010799271523733716 Training loss: 5.748534202575684
2025-12-09 06:26:07.063 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1056 LR: 0.00010719150810331497 Training loss: 5.5196990966796875
2025-12-09 06:26:07.530 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1057 LR: 0.00010639292716940486 Training loss: 5.544920921325684
2025-12-09 06:26:07.997 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1058 LR: 0.00010559697777468013 Training loss: 5.561920642852783
2025-12-09 06:26:08.465 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1059 LR: 0.00010480366524062041 Training loss: 5.90406608581543
2025-12-09 06:26:08.933 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1060 LR: 0.00010401299487107613 Training loss: 5.689167022705078
2025-12-09 06:26:09.399 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1061 LR: 0.00010322497195223285 Training loss: 5.508450031280518
2025-12-09 06:26:09.867 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1062 LR: 0.00010243960175257604 Training loss: 5.726937294006348
2025-12-09 06:26:10.334 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1063 LR: 0.00010165688952285651 Training loss: 5.652782440185547
2025-12-09 06:26:10.801 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1064 LR: 0.00010087684049605351 Training loss: 5.431547164916992
2025-12-09 06:26:11.269 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1065 LR: 0.00010009945988734204 Training loss: 5.67059850692749
2025-12-09 06:26:11.737 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1066 LR: 9.932475289405629e-05 Training loss: 5.36952543258667
2025-12-09 06:26:12.205 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1067 LR: 9.855272469565529e-05 Training loss: 5.896531581878662
2025-12-09 06:26:12.672 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1068 LR: 9.7783380453689e-05 Training loss: 5.5059003829956055
2025-12-09 06:26:13.141 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1069 LR: 9.701672531176286e-05 Training loss: 5.597864151000977
2025-12-09 06:26:13.608 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1070 LR: 9.62527643955039e-05 Training loss: 5.6993889808654785
2025-12-09 06:26:14.074 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1071 LR: 9.549150281252633e-05 Training loss: 5.646664142608643
2025-12-09 06:26:14.541 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1072 LR: 9.473294565239743e-05 Training loss: 5.690876483917236
2025-12-09 06:26:15.009 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1073 LR: 9.397709798660358e-05 Training loss: 5.6453423500061035
2025-12-09 06:26:15.475 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1074 LR: 9.322396486851626e-05 Training loss: 5.786416530609131
2025-12-09 06:26:15.942 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1075 LR: 9.247355133335827e-05 Training loss: 5.4108428955078125
2025-12-09 06:26:16.409 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1076 LR: 9.172586239816988e-05 Training loss: 5.790513515472412
2025-12-09 06:26:16.877 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1077 LR: 9.098090306177625e-05 Training loss: 5.396699905395508
2025-12-09 06:26:17.344 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1078 LR: 9.023867830475213e-05 Training loss: 5.505746841430664
2025-12-09 06:26:17.811 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1079 LR: 8.949919308939081e-05 Training loss: 5.7753400802612305
2025-12-09 06:26:18.278 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1080 LR: 8.876245235966885e-05 Training loss: 5.553652763366699
2025-12-09 06:26:18.745 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1081 LR: 8.802846104121476e-05 Training loss: 5.377942085266113
2025-12-09 06:26:19.213 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1082 LR: 8.72972240412751e-05 Training loss: 5.301043510437012
2025-12-09 06:26:19.681 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1083 LR: 8.656874624868133e-05 Training loss: 5.306333541870117
2025-12-09 06:26:20.148 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1084 LR: 8.584303253381848e-05 Training loss: 5.801242828369141
2025-12-09 06:26:20.615 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1085 LR: 8.512008774859136e-05 Training loss: 5.817789554595947
2025-12-09 06:26:21.082 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1086 LR: 8.439991672639264e-05 Training loss: 5.667264938354492
2025-12-09 06:26:21.550 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1087 LR: 8.368252428207041e-05 Training loss: 5.546916961669922
2025-12-09 06:26:22.017 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1088 LR: 8.296791521189595e-05 Training loss: 5.658734321594238
2025-12-09 06:26:22.485 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1089 LR: 8.225609429353187e-05 Training loss: 5.648155689239502
2025-12-09 06:26:22.953 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1090 LR: 8.154706628599989e-05 Training loss: 5.816089153289795
2025-12-09 06:26:23.421 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1091 LR: 8.084083592964941e-05 Training loss: 5.5077996253967285
2025-12-09 06:26:23.889 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1092 LR: 8.013740794612512e-05 Training loss: 5.647052764892578
2025-12-09 06:26:24.356 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1093 LR: 7.943678703833656e-05 Training loss: 5.583168029785156
2025-12-09 06:26:24.824 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1094 LR: 7.873897789042523e-05 Training loss: 5.757285118103027
2025-12-09 06:26:25.291 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1095 LR: 7.804398516773465e-05 Training loss: 5.579251289367676
2025-12-09 06:26:25.758 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1096 LR: 7.73518135167784e-05 Training loss: 5.923926830291748
2025-12-09 06:26:26.227 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1097 LR: 7.666246756520878e-05 Training loss: 5.5069379806518555
2025-12-09 06:26:26.694 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1098 LR: 7.597595192178702e-05 Training loss: 5.621498107910156
2025-12-09 06:26:27.162 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1099 LR: 7.529227117635135e-05 Training loss: 5.856463432312012
2025-12-09 06:26:27.630 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1100 LR: 7.46114298997867e-05 Training loss: 5.611770153045654
2025-12-09 06:26:28.097 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1101 LR: 7.393343264399439e-05 Training loss: 5.810179233551025
2025-12-09 06:26:28.564 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1102 LR: 7.325828394186118e-05 Training loss: 5.392609119415283
2025-12-09 06:26:29.032 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1103 LR: 7.258598830722945e-05 Training loss: 5.447052478790283
2025-12-09 06:26:29.499 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1104 LR: 7.191655023486682e-05 Training loss: 5.6374592781066895
2025-12-09 06:26:29.967 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1105 LR: 7.1249974200436e-05 Training loss: 5.663275718688965
2025-12-09 06:26:30.436 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1106 LR: 7.058626466046503e-05 Training loss: 5.554201126098633
2025-12-09 06:26:30.903 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1107 LR: 6.992542605231739e-05 Training loss: 5.6151204109191895
2025-12-09 06:26:31.370 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1108 LR: 6.926746279416235e-05 Training loss: 5.96565580368042
2025-12-09 06:26:31.838 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1109 LR: 6.861237928494579e-05 Training loss: 5.672525882720947
2025-12-09 06:26:32.304 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1110 LR: 6.796017990435977e-05 Training loss: 5.794447898864746
2025-12-09 06:26:32.771 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1111 LR: 6.731086901281458e-05 Training loss: 5.858203887939453
2025-12-09 06:26:33.238 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1112 LR: 6.666445095140866e-05 Training loss: 5.540797233581543
2025-12-09 06:26:33.706 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1113 LR: 6.602093004189964e-05 Training loss: 5.4367756843566895
2025-12-09 06:26:34.172 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1114 LR: 6.538031058667609e-05 Training loss: 5.81824254989624
2025-12-09 06:26:34.639 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1115 LR: 6.474259686872808e-05 Training loss: 5.602832794189453
2025-12-09 06:26:35.107 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1116 LR: 6.410779315161885e-05 Training loss: 5.832193851470947
2025-12-09 06:26:35.575 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1117 LR: 6.347590367945616e-05 Training loss: 5.705311298370361
2025-12-09 06:26:36.042 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1118 LR: 6.284693267686403e-05 Training loss: 5.850257396697998
2025-12-09 06:26:36.510 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1119 LR: 6.222088434895462e-05 Training loss: 5.609844207763672
2025-12-09 06:26:36.978 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1120 LR: 6.159776288129976e-05 Training loss: 5.535736083984375
2025-12-09 06:26:37.446 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1121 LR: 6.097757243990321e-05 Training loss: 5.517319679260254
2025-12-09 06:26:37.913 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1122 LR: 6.0360317171172794e-05 Training loss: 5.627869129180908
2025-12-09 06:26:38.379 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1123 LR: 5.974600120189289e-05 Training loss: 5.711635589599609
2025-12-09 06:26:38.847 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1124 LR: 5.9134628639195996e-05 Training loss: 5.55789852142334
2025-12-09 06:26:39.315 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1125 LR: 5.852620357053651e-05 Training loss: 5.536013603210449
2025-12-09 06:26:39.783 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1126 LR: 5.7920730063662554e-05 Training loss: 5.700062274932861
2025-12-09 06:26:40.250 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1127 LR: 5.7318212166588554e-05 Training loss: 5.909403324127197
2025-12-09 06:26:40.718 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1128 LR: 5.671865390756947e-05 Training loss: 5.741126537322998
2025-12-09 06:26:41.185 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1129 LR: 5.612205929507208e-05 Training loss: 5.529011249542236
2025-12-09 06:26:41.654 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1130 LR: 5.5528432317749844e-05 Training loss: 5.649233341217041
2025-12-09 06:26:42.122 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1131 LR: 5.493777694441521e-05 Training loss: 5.674505233764648
2025-12-09 06:26:42.588 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1132 LR: 5.4350097124013286e-05 Training loss: 5.487098693847656
2025-12-09 06:26:43.056 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1133 LR: 5.376539678559566e-05 Training loss: 5.592713356018066
2025-12-09 06:26:43.524 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1134 LR: 5.318367983829392e-05 Training loss: 5.799946308135986
2025-12-09 06:26:43.991 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1135 LR: 5.260495017129363e-05 Training loss: 5.508407115936279
2025-12-09 06:26:44.458 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1136 LR: 5.202921165380825e-05 Training loss: 5.592840671539307
2025-12-09 06:26:44.926 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1137 LR: 5.145646813505339e-05 Training loss: 5.803933620452881
2025-12-09 06:26:45.392 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1138 LR: 5.088672344422085e-05 Training loss: 5.642345428466797
2025-12-09 06:26:45.859 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1139 LR: 5.031998139045352e-05 Training loss: 5.588759899139404
2025-12-09 06:26:46.326 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1140 LR: 4.97562457628189e-05 Training loss: 5.688412189483643
2025-12-09 06:26:46.793 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1141 LR: 4.9195520330285124e-05 Training loss: 5.737488269805908
2025-12-09 06:26:47.261 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1142 LR: 4.8637808841694775e-05 Training loss: 5.635636806488037
2025-12-09 06:26:47.729 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1143 LR: 4.8083115025739754e-05 Training loss: 5.9192280769348145
2025-12-09 06:26:48.196 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1144 LR: 4.753144259093733e-05 Training loss: 5.431977272033691
2025-12-09 06:26:48.664 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1145 LR: 4.698279522560439e-05 Training loss: 5.485271453857422
2025-12-09 06:26:49.132 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1146 LR: 4.643717659783309e-05 Training loss: 5.634044647216797
2025-12-09 06:26:49.599 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1147 LR: 4.589459035546645e-05 Training loss: 5.752906322479248
2025-12-09 06:26:50.066 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1148 LR: 4.535504012607383e-05 Training loss: 5.462630271911621
2025-12-09 06:26:50.534 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1149 LR: 4.481852951692672e-05 Training loss: 5.932657241821289
2025-12-09 06:26:51.002 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1150 LR: 4.4285062114974575e-05 Training loss: 5.9985270500183105
2025-12-09 06:26:51.470 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1151 LR: 4.375464148682095e-05 Training loss: 5.489444732666016
2025-12-09 06:26:51.939 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1152 LR: 4.322727117869951e-05 Training loss: 5.852685928344727
2025-12-09 06:26:52.406 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1153 LR: 4.2702954716450637e-05 Training loss: 5.435731410980225
2025-12-09 06:26:52.873 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1154 LR: 4.218169560549706e-05 Training loss: 5.604273796081543
2025-12-09 06:26:53.341 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1155 LR: 4.166349733082153e-05 Training loss: 5.69252872467041
2025-12-09 06:26:53.808 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1156 LR: 4.114836335694289e-05 Training loss: 5.825382232666016
2025-12-09 06:26:54.275 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1157 LR: 4.063629712789246e-05 Training loss: 5.583965301513672
2025-12-09 06:26:54.742 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1158 LR: 4.012730206719228e-05 Training loss: 5.4862565994262695
2025-12-09 06:26:55.209 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1159 LR: 3.962138157783085e-05 Training loss: 5.656826496124268
2025-12-09 06:26:55.677 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1160 LR: 3.911853904224144e-05 Training loss: 5.631187915802002
2025-12-09 06:26:56.144 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1161 LR: 3.861877782227885e-05 Training loss: 5.78636360168457
2025-12-09 06:26:56.611 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1162 LR: 3.812210125919713e-05 Training loss: 5.6125335693359375
2025-12-09 06:26:57.078 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1163 LR: 3.762851267362721e-05 Training loss: 5.692668437957764
2025-12-09 06:26:57.546 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1164 LR: 3.713801536555483e-05 Training loss: 5.795663356781006
2025-12-09 06:26:58.012 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1165 LR: 3.665061261429831e-05 Training loss: 5.58101749420166
2025-12-09 06:26:58.478 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1166 LR: 3.6166307678486664e-05 Training loss: 5.916579246520996
2025-12-09 06:26:58.945 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1167 LR: 3.56851037960379e-05 Training loss: 5.584523677825928
2025-12-09 06:26:59.413 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1168 LR: 3.520700418413719e-05 Training loss: 5.753702640533447
2025-12-09 06:26:59.879 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1169 LR: 3.4732012039215774e-05 Training loss: 5.488398551940918
2025-12-09 06:27:00.347 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1170 LR: 3.426013053692878e-05 Training loss: 5.608371734619141
2025-12-09 06:27:00.815 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1171 LR: 3.379136283213513e-05 Training loss: 5.750909328460693
2025-12-09 06:27:01.282 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1172 LR: 3.332571205887547e-05 Training loss: 5.716735363006592
2025-12-09 06:27:01.750 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1173 LR: 3.286318133035132e-05 Training loss: 5.544454097747803
2025-12-09 06:27:02.218 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1174 LR: 3.240377373890518e-05 Training loss: 5.66205358505249
2025-12-09 06:27:02.686 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1175 LR: 3.194749235599864e-05 Training loss: 5.61714506149292
2025-12-09 06:27:03.152 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1176 LR: 3.1494340232192667e-05 Training loss: 5.454209327697754
2025-12-09 06:27:03.620 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1177 LR: 3.1044320397126733e-05 Training loss: 5.662132740020752
2025-12-09 06:27:04.097 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1178 LR: 3.059743585949903e-05 Training loss: 5.582338809967041
2025-12-09 06:27:04.565 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1179 LR: 3.0153689607045842e-05 Training loss: 5.544749736785889
2025-12-09 06:27:05.033 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1180 LR: 2.9713084606521945e-05 Training loss: 5.509570121765137
2025-12-09 06:27:05.500 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1181 LR: 2.9275623803680596e-05 Training loss: 5.935827255249023
2025-12-09 06:27:05.967 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1182 LR: 2.884131012325386e-05 Training loss: 5.6180338859558105
2025-12-09 06:27:06.435 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1183 LR: 2.841014646893336e-05 Training loss: 5.556715488433838
2025-12-09 06:27:06.902 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1184 LR: 2.798213572335001e-05 Training loss: 5.651158332824707
2025-12-09 06:27:07.369 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1185 LR: 2.7557280748055968e-05 Training loss: 5.491872310638428
2025-12-09 06:27:07.838 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1186 LR: 2.7135584383504387e-05 Training loss: 5.690375328063965
2025-12-09 06:27:08.306 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1187 LR: 2.6717049449030972e-05 Training loss: 5.664240837097168
2025-12-09 06:27:08.773 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1188 LR: 2.63016787428354e-05 Training loss: 5.588521480560303
2025-12-09 06:27:09.240 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1189 LR: 2.5889475041961763e-05 Training loss: 5.898824691772461
2025-12-09 06:27:09.708 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1190 LR: 2.548044110228087e-05 Training loss: 5.87980318069458
2025-12-09 06:27:10.175 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1191 LR: 2.5074579658471265e-05 Training loss: 5.402915954589844
2025-12-09 06:27:10.642 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1192 LR: 2.467189342400128e-05 Training loss: 5.855480670928955
2025-12-09 06:27:11.109 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1193 LR: 2.4272385091110517e-05 Training loss: 5.593552589416504
2025-12-09 06:27:11.576 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1194 LR: 2.3876057330792345e-05 Training loss: 5.55757999420166
2025-12-09 06:27:12.043 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1195 LR: 2.3482912792775647e-05 Training loss: 5.56766939163208
2025-12-09 06:27:12.511 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1196 LR: 2.3092954105507157e-05 Training loss: 5.68970251083374
2025-12-09 06:27:12.978 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1197 LR: 2.2706183876134045e-05 Training loss: 5.587614059448242
2025-12-09 06:27:13.446 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1198 LR: 2.232260469048647e-05 Training loss: 5.636559009552002
2025-12-09 06:27:13.914 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1199 LR: 2.1942219113060213e-05 Training loss: 5.583391189575195
2025-12-09 06:27:14.381 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1200 LR: 2.1565029686999303e-05 Training loss: 5.474298477172852
2025-12-09 06:27:14.848 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1201 LR: 2.119103893407964e-05 Training loss: 5.6609625816345215
2025-12-09 06:27:15.316 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1202 LR: 2.082024935469157e-05 Training loss: 5.648471355438232
2025-12-09 06:27:15.783 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1203 LR: 2.0452663427823094e-05 Training loss: 5.747808456420898
2025-12-09 06:27:16.250 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1204 LR: 2.0088283611044034e-05 Training loss: 5.437796592712402
2025-12-09 06:27:16.717 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1205 LR: 1.972711234048885e-05 Training loss: 5.5835113525390625
2025-12-09 06:27:17.185 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1206 LR: 1.9369152030840554e-05 Training loss: 5.555801868438721
2025-12-09 06:27:17.653 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1207 LR: 1.901440507531482e-05 Training loss: 5.469766139984131
2025-12-09 06:27:18.120 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1208 LR: 1.866287384564369e-05 Training loss: 5.459372520446777
2025-12-09 06:27:18.588 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1209 LR: 1.8314560692059833e-05 Training loss: 5.6813459396362305
2025-12-09 06:27:19.055 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1210 LR: 1.7969467943280858e-05 Training loss: 5.68479585647583
2025-12-09 06:27:19.522 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1211 LR: 1.7627597906493653e-05 Training loss: 5.85972785949707
2025-12-09 06:27:19.989 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1212 LR: 1.728895286733906e-05 Training loss: 5.5599775314331055
2025-12-09 06:27:20.456 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1213 LR: 1.6953535089896554e-05 Training loss: 5.773135662078857
2025-12-09 06:27:20.925 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1214 LR: 1.6621346816668993e-05 Training loss: 5.732036113739014
2025-12-09 06:27:21.393 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1215 LR: 1.6292390268568102e-05 Training loss: 5.859450817108154
2025-12-09 06:27:21.859 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1216 LR: 1.596666764489868e-05 Training loss: 5.519025802612305
2025-12-09 06:27:22.326 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1217 LR: 1.5644181123344924e-05 Training loss: 5.603123664855957
2025-12-09 06:27:22.793 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1218 LR: 1.5324932859955398e-05 Training loss: 5.828614711761475
2025-12-09 06:27:23.260 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1219 LR: 1.5008924989128259e-05 Training loss: 5.600504398345947
2025-12-09 06:27:23.728 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1220 LR: 1.4696159623597883e-05 Training loss: 5.513500690460205
2025-12-09 06:27:24.195 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1221 LR: 1.438663885441982e-05 Training loss: 5.390438556671143
2025-12-09 06:27:24.663 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1222 LR: 1.4080364750957474e-05 Training loss: 5.592267990112305
2025-12-09 06:27:25.131 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1223 LR: 1.3777339360867836e-05 Training loss: 5.249383449554443
2025-12-09 06:27:25.599 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1224 LR: 1.3477564710088097e-05 Training loss: 5.464416980743408
2025-12-09 06:27:26.066 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1225 LR: 1.3181042802821896e-05 Training loss: 5.668729305267334
2025-12-09 06:27:26.532 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1226 LR: 1.2887775621526043e-05 Training loss: 5.68759822845459
2025-12-09 06:27:27.000 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1227 LR: 1.2597765126897198e-05 Training loss: 5.7902302742004395
2025-12-09 06:27:27.467 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1228 LR: 1.2311013257858827e-05 Training loss: 5.74226713180542
2025-12-09 06:27:27.934 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1229 LR: 1.2027521931548213e-05 Training loss: 5.712626934051514
2025-12-09 06:27:28.401 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1230 LR: 1.174729304330352e-05 Training loss: 5.830248832702637
2025-12-09 06:27:28.868 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1231 LR: 1.1470328466651304e-05 Training loss: 5.6272382736206055
2025-12-09 06:27:29.335 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1232 LR: 1.1196630053294021e-05 Training loss: 5.559598922729492
2025-12-09 06:27:29.803 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1233 LR: 1.0926199633097156e-05 Training loss: 5.457801342010498
2025-12-09 06:27:30.270 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1234 LR: 1.0659039014077942e-05 Training loss: 5.594297409057617
2025-12-09 06:27:30.738 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1235 LR: 1.0395149982392104e-05 Training loss: 5.513419151306152
2025-12-09 06:27:31.206 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1236 LR: 1.0134534302323029e-05 Training loss: 5.543528079986572
2025-12-09 06:27:31.672 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1237 LR: 9.877193716269051e-06 Training loss: 5.745672702789307
2025-12-09 06:27:32.141 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1238 LR: 9.623129944732467e-06 Training loss: 5.371747970581055
2025-12-09 06:27:32.609 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1239 LR: 9.372344686307655e-06 Training loss: 5.723545074462891
2025-12-09 06:27:33.076 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1240 LR: 9.124839617669855e-06 Training loss: 5.68230676651001
2025-12-09 06:27:33.545 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1241 LR: 8.880616393563967e-06 Training loss: 5.573060035705566
2025-12-09 06:27:34.012 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1242 LR: 8.639676646793382e-06 Training loss: 5.6866302490234375
2025-12-09 06:27:34.478 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1243 LR: 8.402021988209219e-06 Training loss: 5.73712682723999
2025-12-09 06:27:34.946 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1244 LR: 8.167654006699443e-06 Training loss: 5.565633296966553
2025-12-09 06:27:35.414 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1245 LR: 7.936574269178377e-06 Training loss: 5.593021392822266
2025-12-09 06:27:35.882 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1246 LR: 7.708784320575924e-06 Training loss: 5.367753505706787
2025-12-09 06:27:36.350 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1247 LR: 7.4842856838276405e-06 Training loss: 5.531205177307129
2025-12-09 06:27:36.818 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1248 LR: 7.263079859864297e-06 Training loss: 5.726797103881836
2025-12-09 06:27:37.286 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1249 LR: 7.045168327601769e-06 Training loss: 5.286255836486816
2025-12-09 06:27:37.752 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1250 LR: 6.8305525439315005e-06 Training loss: 5.887726306915283
2025-12-09 06:27:38.221 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1251 LR: 6.61923394371039e-06 Training loss: 5.576294898986816
2025-12-09 06:27:38.688 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1252 LR: 6.41121393975147e-06 Training loss: 5.828747272491455
2025-12-09 06:27:39.154 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1253 LR: 6.206493922814249e-06 Training loss: 5.568203926086426
2025-12-09 06:27:39.622 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1254 LR: 6.005075261595494e-06 Training loss: 5.577451229095459
2025-12-09 06:27:40.089 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1255 LR: 5.8069593027202385e-06 Training loss: 5.746551036834717
2025-12-09 06:27:40.556 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1256 LR: 5.612147370732457e-06 Training loss: 5.774831295013428
2025-12-09 06:27:41.024 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1257 LR: 5.42064076808646e-06 Training loss: 5.760713577270508
2025-12-09 06:27:41.491 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1258 LR: 5.232440775138181e-06 Training loss: 5.535802364349365
2025-12-09 06:27:41.958 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1259 LR: 5.047548650136513e-06 Training loss: 5.9053802490234375
2025-12-09 06:27:42.427 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1260 LR: 4.865965629214819e-06 Training loss: 5.642457008361816
2025-12-09 06:27:42.894 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1261 LR: 4.687692926382992e-06 Training loss: 5.774807929992676
2025-12-09 06:27:43.361 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1262 LR: 4.51273173351896e-06 Training loss: 5.645866394042969
2025-12-09 06:27:43.828 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1263 LR: 4.341083220360864e-06 Training loss: 5.621842384338379
2025-12-09 06:27:44.295 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1264 LR: 4.172748534499449e-06 Training loss: 5.773690700531006
2025-12-09 06:27:44.762 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1265 LR: 4.007728801370014e-06 Training loss: 5.489048480987549
2025-12-09 06:27:45.230 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1266 LR: 3.846025124245145e-06 Training loss: 5.654952526092529
2025-12-09 06:27:45.697 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1267 LR: 3.687638584227382e-06 Training loss: 5.766232013702393
2025-12-09 06:27:46.165 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1268 LR: 3.5325702402416173e-06 Training loss: 5.810569763183594
2025-12-09 06:27:46.632 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1269 LR: 3.3808211290284885e-06 Training loss: 5.653355121612549
2025-12-09 06:27:47.099 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1270 LR: 3.2323922651372184e-06 Training loss: 5.356765270233154
2025-12-09 06:27:47.565 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1271 LR: 3.087284640918786e-06 Training loss: 5.5408244132995605
2025-12-09 06:27:48.033 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1272 LR: 2.9454992265193214e-06 Training loss: 5.748331069946289
2025-12-09 06:27:48.500 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1273 LR: 2.807036969873722e-06 Training loss: 5.702627182006836
2025-12-09 06:27:48.967 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1274 LR: 2.671898796699268e-06 Training loss: 5.541053771972656
2025-12-09 06:27:49.435 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1275 LR: 2.5400856104894065e-06 Training loss: 5.4618072509765625
2025-12-09 06:27:49.903 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1276 LR: 2.411598292507533e-06 Training loss: 5.5818681716918945
2025-12-09 06:27:50.371 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1277 LR: 2.2864377017816074e-06 Training loss: 5.612471103668213
2025-12-09 06:27:50.838 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1278 LR: 2.1646046750978256e-06 Training loss: 5.778676509857178
2025-12-09 06:27:51.305 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1279 LR: 2.0461000269953455e-06 Training loss: 5.4517598152160645
2025-12-09 06:27:51.772 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1280 LR: 1.9309245497608486e-06 Training loss: 5.589808940887451
2025-12-09 06:27:52.240 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1281 LR: 1.8190790134231528e-06 Training loss: 5.500786304473877
2025-12-09 06:27:52.706 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1282 LR: 1.7105641657479965e-06 Training loss: 5.722471237182617
2025-12-09 06:27:53.173 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1283 LR: 1.6053807322333191e-06 Training loss: 5.783844947814941
2025-12-09 06:27:53.641 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1284 LR: 1.503529416103988e-06 Training loss: 5.487351894378662
2025-12-09 06:27:54.109 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1285 LR: 1.4050108983074683e-06 Training loss: 5.64127254486084
2025-12-09 06:27:54.576 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1286 LR: 1.30982583750916e-06 Training loss: 5.850975036621094
2025-12-09 06:27:55.045 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1287 LR: 1.2179748700879012e-06 Training loss: 5.526861667633057
2025-12-09 06:27:55.512 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1288 LR: 1.1294586101317506e-06 Training loss: 5.290582180023193
2025-12-09 06:27:55.979 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1289 LR: 1.044277649433989e-06 Training loss: 5.816086292266846
2025-12-09 06:27:56.446 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1290 LR: 9.624325574890126e-07 Training loss: 5.715165138244629
2025-12-09 06:27:56.914 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1291 LR: 8.839238814886685e-07 Training loss: 6.102156639099121
2025-12-09 06:27:57.380 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1292 LR: 8.08752146318481e-07 Training loss: 5.500128269195557
2025-12-09 06:27:57.848 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1293 LR: 7.369178545542087e-07 Training loss: 5.305417060852051
2025-12-09 06:27:58.317 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1294 LR: 6.684214864584037e-07 Training loss: 5.718468189239502
2025-12-09 06:27:58.784 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1295 LR: 6.032634999773023e-07 Training loss: 5.666542053222656
2025-12-09 06:27:59.251 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1296 LR: 5.41444330737717e-07 Training loss: 5.703028678894043
2025-12-09 06:27:59.718 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1297 LR: 4.82964392044205e-07 Training loss: 5.607959270477295
2025-12-09 06:28:00.186 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1298 LR: 4.278240748760709e-07 Training loss: 5.808310031890869
2025-12-09 06:28:00.654 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1299 LR: 3.7602374788497927e-07 Training loss: 5.860080718994141
2025-12-09 06:28:01.122 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1300 LR: 3.2756375739245723e-07 Training loss: 5.725442409515381
2025-12-09 06:28:01.589 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1301 LR: 2.824444273875071e-07 Training loss: 5.629772186279297
2025-12-09 06:28:02.057 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1302 LR: 2.4066605952444145e-07 Training loss: 5.501169681549072
2025-12-09 06:28:02.526 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1303 LR: 2.0222893312099588e-07 Training loss: 5.473904609680176
2025-12-09 06:28:02.993 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1304 LR: 1.6713330515627513e-07 Training loss: 5.404736518859863
2025-12-09 06:28:03.463 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1305 LR: 1.3537941026914301e-07 Training loss: 5.833473205566406
2025-12-09 06:28:03.931 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1306 LR: 1.0696746075666841e-07 Training loss: 5.5154829025268555
2025-12-09 06:28:04.398 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1307 LR: 8.189764657262622e-08 Training loss: 5.590994834899902
2025-12-09 06:28:04.866 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1308 LR: 6.017013532627625e-08 Training loss: 5.606598854064941
2025-12-09 06:28:05.336 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1309 LR: 4.1785072281363966e-08 Training loss: 5.563065528869629
2025-12-09 06:28:05.803 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1310 LR: 2.6742580354788272e-08 Training loss: 5.621431350708008
2025-12-09 06:28:06.271 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1311 LR: 1.504276011621286e-08 Training loss: 5.596556186676025
2025-12-09 06:28:06.738 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1312 LR: 6.685689787122584e-09 Training loss: 5.699776649475098
2025-12-09 06:28:07.206 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1313 LR: 1.6714252404348428e-09 Training loss: 5.402499675750732
2025-12-09 06:28:07.372 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1314 LR: 0.0 Training loss: 5.767021179199219
