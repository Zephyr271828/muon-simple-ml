2025-12-09 12:08:18.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 0.0001 Training loss: 12.170064926147461
2025-12-09 12:08:19.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 0.0002 Training loss: 12.184918403625488
2025-12-09 12:08:19.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 0.0003 Training loss: 11.754435539245605
2025-12-09 12:08:20.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.0004 Training loss: 12.27744197845459
2025-12-09 12:08:20.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.0005 Training loss: 11.831865310668945
2025-12-09 12:08:20.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.0006 Training loss: 14.916245460510254
2025-12-09 12:08:21.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.0007000000000000001 Training loss: 11.486196517944336
2025-12-09 12:08:21.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.0008 Training loss: 11.31525993347168
2025-12-09 12:08:21.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.0009 Training loss: 11.023606300354004
2025-12-09 12:08:22.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.001 Training loss: 10.214353561401367
2025-12-09 12:08:22.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.0011 Training loss: 9.86246109008789
2025-12-09 12:08:23.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.0012 Training loss: 9.579612731933594
2025-12-09 12:08:23.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.0013000000000000002 Training loss: 10.253408432006836
2025-12-09 12:08:23.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.0014000000000000002 Training loss: 10.104713439941406
2025-12-09 12:08:24.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.0015 Training loss: 10.649124145507812
2025-12-09 12:08:24.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.0016 Training loss: 11.402729034423828
2025-12-09 12:08:25.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.0017000000000000001 Training loss: 10.756668090820312
2025-12-09 12:08:25.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.0018 Training loss: 10.350683212280273
2025-12-09 12:08:25.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.0019 Training loss: 10.91805362701416
2025-12-09 12:08:26.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.002 Training loss: 10.321366310119629
2025-12-09 12:08:26.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.0021 Training loss: 10.615242958068848
2025-12-09 12:08:26.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.0022 Training loss: 11.06346607208252
2025-12-09 12:08:27.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0023 Training loss: 10.7371187210083
2025-12-09 12:08:27.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0024 Training loss: 10.925910949707031
2025-12-09 12:08:28.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.0025 Training loss: 10.363612174987793
2025-12-09 12:08:28.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0026000000000000003 Training loss: 10.53652286529541
2025-12-09 12:08:28.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0027 Training loss: 10.149921417236328
2025-12-09 12:08:29.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0028000000000000004 Training loss: 9.477069854736328
2025-12-09 12:08:29.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.0029 Training loss: 9.719392776489258
2025-12-09 12:08:30.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.003 Training loss: 10.145552635192871
2025-12-09 12:08:30.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.0031 Training loss: 9.310223579406738
2025-12-09 12:08:30.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.0032 Training loss: 9.468799591064453
2025-12-09 12:08:31.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.0033000000000000004 Training loss: 9.521818161010742
2025-12-09 12:08:31.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.0034000000000000002 Training loss: 9.629865646362305
2025-12-09 12:08:31.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.0034999999999999996 Training loss: 10.103878021240234
2025-12-09 12:08:32.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.0036 Training loss: 9.9768648147583
2025-12-09 12:08:32.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.0037 Training loss: 9.500727653503418
2025-12-09 12:08:33.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.0038 Training loss: 9.748136520385742
2025-12-09 12:08:33.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.0039000000000000003 Training loss: 9.906102180480957
2025-12-09 12:08:33.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.004 Training loss: 9.449374198913574
2025-12-09 12:08:34.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.0040999999999999995 Training loss: 9.277169227600098
2025-12-09 12:08:34.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.0042 Training loss: 9.883162498474121
2025-12-09 12:08:35.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.0043 Training loss: 9.790602684020996
2025-12-09 12:08:35.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.0044 Training loss: 9.258489608764648
2025-12-09 12:08:35.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.0045000000000000005 Training loss: 9.511161804199219
2025-12-09 12:08:36.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0046 Training loss: 9.714949607849121
2025-12-09 12:08:36.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.0047 Training loss: 9.396007537841797
2025-12-09 12:08:36.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0048 Training loss: 10.306133270263672
2025-12-09 12:08:37.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.0049 Training loss: 8.879067420959473
2025-12-09 12:08:37.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.005 Training loss: 9.412596702575684
2025-12-09 12:08:38.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0051 Training loss: 9.650125503540039
2025-12-09 12:08:38.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.005200000000000001 Training loss: 9.59280776977539
2025-12-09 12:08:38.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0053 Training loss: 9.271748542785645
2025-12-09 12:08:39.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0054 Training loss: 9.351101875305176
2025-12-09 12:08:39.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0055000000000000005 Training loss: 9.179855346679688
2025-12-09 12:08:40.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.005600000000000001 Training loss: 9.229619026184082
2025-12-09 12:08:40.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.005699999999999999 Training loss: 9.2984037399292
2025-12-09 12:08:40.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.0058 Training loss: 9.09618091583252
2025-12-09 12:08:41.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0059 Training loss: 9.728814125061035
2025-12-09 12:08:41.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.006 Training loss: 8.871776580810547
2025-12-09 12:08:41.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.0061 Training loss: 8.845198631286621
2025-12-09 12:08:42.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.0062 Training loss: 9.005327224731445
2025-12-09 12:08:42.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.0063 Training loss: 8.70460033416748
2025-12-09 12:08:43.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.0064 Training loss: 8.990307807922363
2025-12-09 12:08:43.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.006500000000000001 Training loss: 8.98755931854248
2025-12-09 12:08:43.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.006600000000000001 Training loss: 9.136075973510742
2025-12-09 12:08:44.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.0067 Training loss: 9.705595970153809
2025-12-09 12:08:44.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.0068000000000000005 Training loss: 8.994864463806152
2025-12-09 12:08:45.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.0069 Training loss: 9.073720932006836
2025-12-09 12:08:45.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.006999999999999999 Training loss: 8.893858909606934
2025-12-09 12:08:45.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.0070999999999999995 Training loss: 9.131304740905762
2025-12-09 12:08:46.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0072 Training loss: 8.978266716003418
2025-12-09 12:08:46.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.0073 Training loss: 9.040152549743652
2025-12-09 12:08:46.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.0074 Training loss: 10.171576499938965
2025-12-09 12:08:47.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0075 Training loss: 9.474857330322266
2025-12-09 12:08:47.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.0076 Training loss: 9.661016464233398
2025-12-09 12:08:48.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0077 Training loss: 8.941466331481934
2025-12-09 12:08:48.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0078000000000000005 Training loss: 9.137253761291504
2025-12-09 12:08:48.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.0079 Training loss: 8.939679145812988
2025-12-09 12:08:49.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.008 Training loss: 8.99409008026123
2025-12-09 12:08:49.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.008100000000000001 Training loss: 8.604039192199707
2025-12-09 12:08:50.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.008199999999999999 Training loss: 8.987570762634277
2025-12-09 12:08:50.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.0083 Training loss: 10.443532943725586
2025-12-09 12:08:50.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.0084 Training loss: 8.703121185302734
2025-12-09 12:08:51.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.0085 Training loss: 8.924248695373535
2025-12-09 12:08:51.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.0086 Training loss: 9.061330795288086
2025-12-09 12:08:51.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.0087 Training loss: 8.660703659057617
2025-12-09 12:08:52.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.0088 Training loss: 8.77477741241455
2025-12-09 12:08:52.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0089 Training loss: 8.866009712219238
2025-12-09 12:08:53.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.009000000000000001 Training loss: 8.45508098602295
2025-12-09 12:08:53.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0091 Training loss: 8.733882904052734
2025-12-09 12:08:53.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0092 Training loss: 8.404272079467773
2025-12-09 12:08:54.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.009300000000000001 Training loss: 8.606319427490234
2025-12-09 12:08:54.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.0094 Training loss: 9.244502067565918
2025-12-09 12:08:55.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.0095 Training loss: 8.738530158996582
2025-12-09 12:08:55.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0096 Training loss: 8.500126838684082
2025-12-09 12:08:55.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0097 Training loss: 9.194744110107422
2025-12-09 12:08:56.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.0098 Training loss: 8.297425270080566
2025-12-09 12:08:56.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.0099 Training loss: 8.366095542907715
2025-12-09 12:08:56.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.01 Training loss: 8.139660835266113
2025-12-09 12:08:57.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.009999999029798808 Training loss: 8.825663566589355
2025-12-09 12:08:57.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.00999999611919561 Training loss: 9.192920684814453
2025-12-09 12:08:58.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.009999991268191535 Training loss: 8.678776741027832
2025-12-09 12:08:58.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.009999984476788465 Training loss: 8.922257423400879
2025-12-09 12:08:58.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.009999975744989035 Training loss: 8.315218925476074
2025-12-09 12:08:59.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.009999965072796636 Training loss: 8.5543851852417
2025-12-09 12:08:59.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.009999952460215409 Training loss: 8.319211959838867
2025-12-09 12:09:00.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.009999937907250246 Training loss: 8.577340126037598
2025-12-09 12:09:00.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.009999921413906798 Training loss: 8.453024864196777
2025-12-09 12:09:00.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.009999902980191464 Training loss: 7.965429306030273
2025-12-09 12:09:01.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.009999882606111399 Training loss: 8.30908489227295
2025-12-09 12:09:01.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.009999860291674507 Training loss: 8.209409713745117
2025-12-09 12:09:01.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.009999836036889453 Training loss: 8.130854606628418
2025-12-09 12:09:02.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.009999809841765645 Training loss: 8.371667861938477
2025-12-09 12:09:02.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.00999978170631325 Training loss: 8.269380569458008
2025-12-09 12:09:03.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.009999751630543188 Training loss: 8.26938247680664
2025-12-09 12:09:03.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.00999971961446713 Training loss: 8.508975982666016
2025-12-09 12:09:03.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.009999685658097501 Training loss: 8.213861465454102
2025-12-09 12:09:04.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.009999649761447477 Training loss: 8.258675575256348
2025-12-09 12:09:04.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.009999611924530994 Training loss: 8.440298080444336
2025-12-09 12:09:05.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.00999957214736273 Training loss: 8.043511390686035
2025-12-09 12:09:05.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.009999530429958124 Training loss: 9.581023216247559
2025-12-09 12:09:05.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.009999486772333366 Training loss: 8.29524040222168
2025-12-09 12:09:06.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.0099994411745054 Training loss: 8.045818328857422
2025-12-09 12:09:06.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.009999393636491919 Training loss: 8.36774730682373
2025-12-09 12:09:07.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.00999934415831137 Training loss: 8.058642387390137
2025-12-09 12:09:07.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.009999292739982958 Training loss: 7.847105026245117
2025-12-09 12:09:07.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.009999239381526638 Training loss: 8.452837944030762
2025-12-09 12:09:08.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.009999184082963117 Training loss: 8.287938117980957
2025-12-09 12:09:08.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.009999126844313852 Training loss: 7.968504428863525
2025-12-09 12:09:08.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.00999906766560106 Training loss: 8.757999420166016
2025-12-09 12:09:09.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.009999006546847707 Training loss: 8.773309707641602
2025-12-09 12:09:09.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.009998943488077507 Training loss: 8.178851127624512
2025-12-09 12:09:10.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.009998878489314937 Training loss: 8.448615074157715
2025-12-09 12:09:10.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.009998811550585221 Training loss: 8.193500518798828
2025-12-09 12:09:10.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.009998742671914335 Training loss: 7.843728065490723
2025-12-09 12:09:11.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.00999867185332901 Training loss: 8.440666198730469
2025-12-09 12:09:11.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.00999859909485673 Training loss: 8.545753479003906
2025-12-09 12:09:12.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.00999852439652573 Training loss: 8.017623901367188
2025-12-09 12:09:12.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.009998447758365002 Training loss: 8.155682563781738
2025-12-09 12:09:12.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.009998369180404282 Training loss: 8.505350112915039
2025-12-09 12:09:13.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.00999828866267407 Training loss: 8.17191219329834
2025-12-09 12:09:13.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.00999820620520561 Training loss: 7.76599645614624
2025-12-09 12:09:13.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.009998121808030905 Training loss: 7.8285698890686035
2025-12-09 12:09:14.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.009998035471182706 Training loss: 7.961518287658691
2025-12-09 12:09:14.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.00999794719469452 Training loss: 7.995956897735596
2025-12-09 12:09:15.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.009997856978600603 Training loss: 7.729369163513184
2025-12-09 12:09:15.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.009997764822935967 Training loss: 8.489041328430176
2025-12-09 12:09:15.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.009997670727736378 Training loss: 7.627173900604248
2025-12-09 12:09:16.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.009997574693038351 Training loss: 8.046211242675781
2025-12-09 12:09:16.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.009997476718879152 Training loss: 8.012835502624512
2025-12-09 12:09:17.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.009997376805296809 Training loss: 7.858917713165283
2025-12-09 12:09:17.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.009997274952330094 Training loss: 7.798433303833008
2025-12-09 12:09:17.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.00999717116001853 Training loss: 7.6611833572387695
2025-12-09 12:09:18.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.009997065428402403 Training loss: 7.77113151550293
2025-12-09 12:09:18.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.009996957757522741 Training loss: 7.629952907562256
2025-12-09 12:09:18.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.009996848147421333 Training loss: 8.32978343963623
2025-12-09 12:09:19.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.009996736598140715 Training loss: 7.759995937347412
2025-12-09 12:09:19.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.009996623109724174 Training loss: 7.7806925773620605
2025-12-09 12:09:20.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.009996507682215754 Training loss: 7.711127758026123
2025-12-09 12:09:20.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.009996390315660254 Training loss: 8.064342498779297
2025-12-09 12:09:20.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.009996271010103216 Training loss: 8.056184768676758
2025-12-09 12:09:21.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.009996149765590946 Training loss: 7.973913192749023
2025-12-09 12:09:21.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.00999602658217049 Training loss: 7.673681735992432
2025-12-09 12:09:22.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.009995901459889657 Training loss: 7.743933200836182
2025-12-09 12:09:22.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.009995774398797007 Training loss: 7.9503936767578125
2025-12-09 12:09:22.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.009995645398941846 Training loss: 7.854694843292236
2025-12-09 12:09:23.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.009995514460374237 Training loss: 8.840680122375488
2025-12-09 12:09:23.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.009995381583144995 Training loss: 7.926991939544678
2025-12-09 12:09:24.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.009995246767305689 Training loss: 7.991504669189453
2025-12-09 12:09:24.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.009995110012908634 Training loss: 8.647549629211426
2025-12-09 12:09:24.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.009994971320006905 Training loss: 8.638116836547852
2025-12-09 12:09:25.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.009994830688654326 Training loss: 7.837826728820801
2025-12-09 12:09:25.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.009994688118905472 Training loss: 7.982965469360352
2025-12-09 12:09:25.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.009994543610815672 Training loss: 7.909854888916016
2025-12-09 12:09:26.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.009994397164441006 Training loss: 7.636953830718994
2025-12-09 12:09:26.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.009994248779838311 Training loss: 7.7177629470825195
2025-12-09 12:09:27.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.009994098457065167 Training loss: 7.593714714050293
2025-12-09 12:09:27.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.009993946196179913 Training loss: 7.90408992767334
2025-12-09 12:09:27.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.009993791997241638 Training loss: 7.447245121002197
2025-12-09 12:09:28.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.009993635860310187 Training loss: 7.987897872924805
2025-12-09 12:09:28.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.00999347778544615 Training loss: 8.807696342468262
2025-12-09 12:09:29.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.009993317772710874 Training loss: 8.011459350585938
2025-12-09 12:09:29.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.009993155822166457 Training loss: 7.672153949737549
2025-12-09 12:09:29.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.009992991933875747 Training loss: 7.905570030212402
2025-12-09 12:09:30.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.009992826107902348 Training loss: 7.966920852661133
2025-12-09 12:09:30.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.009992658344310614 Training loss: 8.014066696166992
2025-12-09 12:09:30.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.00999248864316565 Training loss: 7.788671016693115
2025-12-09 12:09:31.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.009992317004533314 Training loss: 8.097505569458008
2025-12-09 12:09:31.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.009992143428480213 Training loss: 7.436538219451904
2025-12-09 12:09:32.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.009991967915073714 Training loss: 9.000367164611816
2025-12-09 12:09:32.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.009991790464381926 Training loss: 7.687380790710449
2025-12-09 12:09:32.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.009991611076473714 Training loss: 7.817506313323975
2025-12-09 12:09:33.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.009991429751418698 Training loss: 7.845398426055908
2025-12-09 12:09:33.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.009991246489287245 Training loss: 7.898739814758301
2025-12-09 12:09:34.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.009991061290150474 Training loss: 8.389544486999512
2025-12-09 12:09:34.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.009990874154080258 Training loss: 8.080915451049805
2025-12-09 12:09:34.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.009990685081149222 Training loss: 7.8143534660339355
2025-12-09 12:09:35.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.009990494071430742 Training loss: 7.810513973236084
2025-12-09 12:09:35.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.009990301124998944 Training loss: 7.586644172668457
2025-12-09 12:09:36.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.009990106241928705 Training loss: 8.30894947052002
2025-12-09 12:09:36.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.009989909422295658 Training loss: 7.760539531707764
2025-12-09 12:09:36.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.009989710666176184 Training loss: 7.8273162841796875
2025-12-09 12:09:37.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.009989509973647417 Training loss: 8.076226234436035
2025-12-09 12:09:37.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.009989307344787242 Training loss: 8.00147819519043
2025-12-09 12:09:37.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.009989102779674294 Training loss: 7.648038387298584
2025-12-09 12:09:38.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.00998889627838796 Training loss: 8.294280052185059
2025-12-09 12:09:38.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.00998868784100838 Training loss: 8.10207462310791
2025-12-09 12:09:39.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.009988477467616446 Training loss: 7.8098063468933105
2025-12-09 12:09:39.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0099882651582938 Training loss: 7.996528148651123
2025-12-09 12:09:39.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.009988050913122831 Training loss: 7.8935041427612305
2025-12-09 12:09:40.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.009987834732186687 Training loss: 7.483582019805908
2025-12-09 12:09:40.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.009987616615569263 Training loss: 7.841493606567383
2025-12-09 12:09:41.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.009987396563355204 Training loss: 7.943686008453369
2025-12-09 12:09:41.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.009987174575629911 Training loss: 7.738529205322266
2025-12-09 12:09:41.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.009986950652479532 Training loss: 7.780220031738281
2025-12-09 12:09:42.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.009986724793990967 Training loss: 7.507023811340332
2025-12-09 12:09:42.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.009986497000251867 Training loss: 7.7358198165893555
2025-12-09 12:09:42.982 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.009986267271350633 Training loss: 7.841141700744629
2025-12-09 12:09:43.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.00998603560737642 Training loss: 8.848093032836914
2025-12-09 12:09:43.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.009985802008419132 Training loss: 8.524969100952148
2025-12-09 12:09:44.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.009985566474569425 Training loss: 8.15163516998291
2025-12-09 12:09:44.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.009985329005918702 Training loss: 8.094366073608398
2025-12-09 12:09:44.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.009985089602559125 Training loss: 7.855593204498291
2025-12-09 12:09:45.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.009984848264583597 Training loss: 8.451111793518066
2025-12-09 12:09:45.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.00998460499208578 Training loss: 8.240860939025879
2025-12-09 12:09:46.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.00998435978516008 Training loss: 7.794686794281006
2025-12-09 12:09:46.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.00998411264390166 Training loss: 7.4082722663879395
2025-12-09 12:09:46.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.009983863568406429 Training loss: 7.827634811401367
2025-12-09 12:09:47.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.009983612558771048 Training loss: 8.044790267944336
2025-12-09 12:09:47.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.00998335961509293 Training loss: 7.893807411193848
2025-12-09 12:09:48.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.009983104737470239 Training loss: 7.61346435546875
2025-12-09 12:09:48.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.009982847926001886 Training loss: 7.987704753875732
2025-12-09 12:09:48.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.009982589180787534 Training loss: 7.532567501068115
2025-12-09 12:09:49.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.009982328501927597 Training loss: 7.991108417510986
2025-12-09 12:09:49.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.009982065889523242 Training loss: 7.823573112487793
2025-12-09 12:09:49.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.00998180134367638 Training loss: 8.040810585021973
2025-12-09 12:09:50.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.009981534864489678 Training loss: 7.717865467071533
2025-12-09 12:09:50.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.009981266452066553 Training loss: 7.781715393066406
2025-12-09 12:09:51.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.009980996106511169 Training loss: 7.907845973968506
2025-12-09 12:09:51.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.009980723827928441 Training loss: 7.4603705406188965
2025-12-09 12:09:51.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.009980449616424037 Training loss: 7.384414196014404
2025-12-09 12:09:52.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.00998017347210437 Training loss: 7.438211917877197
2025-12-09 12:09:52.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.009979895395076608 Training loss: 7.722017765045166
2025-12-09 12:09:53.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.009979615385448668 Training loss: 7.570188522338867
2025-12-09 12:09:53.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.009979333443329217 Training loss: 7.740850925445557
2025-12-09 12:09:53.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.00997904956882767 Training loss: 7.847959041595459
2025-12-09 12:09:54.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.009978763762054192 Training loss: 7.808260917663574
2025-12-09 12:09:54.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0099784760231197 Training loss: 7.644620418548584
2025-12-09 12:09:54.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.00997818635213586 Training loss: 7.466878414154053
2025-12-09 12:09:55.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.009977894749215089 Training loss: 7.768025875091553
2025-12-09 12:09:55.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.00997760121447055 Training loss: 7.487614154815674
2025-12-09 12:09:56.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.009977305748016158 Training loss: 7.807164669036865
2025-12-09 12:09:56.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.00997700834996658 Training loss: 7.479662895202637
2025-12-09 12:09:56.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.009976709020437229 Training loss: 7.512643814086914
2025-12-09 12:09:57.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.00997640775954427 Training loss: 7.740013122558594
2025-12-09 12:09:57.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.009976104567404616 Training loss: 7.899715900421143
2025-12-09 12:09:58.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.009975799444135928 Training loss: 7.656102180480957
2025-12-09 12:09:58.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.009975492389856622 Training loss: 7.662411212921143
2025-12-09 12:09:58.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.009975183404685856 Training loss: 7.383532524108887
2025-12-09 12:09:59.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.009974872488743543 Training loss: 7.691189765930176
2025-12-09 12:09:59.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.009974559642150344 Training loss: 7.698823928833008
2025-12-09 12:10:00.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.009974244865027668 Training loss: 7.542869567871094
2025-12-09 12:10:00.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.009973928157497673 Training loss: 7.766332626342773
2025-12-09 12:10:00.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.009973609519683268 Training loss: 8.39306926727295
2025-12-09 12:10:01.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.009973288951708112 Training loss: 7.504817008972168
2025-12-09 12:10:01.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.009972966453696608 Training loss: 7.6773881912231445
2025-12-09 12:10:01.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.009972642025773911 Training loss: 7.503420829772949
2025-12-09 12:10:02.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.009972315668065928 Training loss: 7.82017183303833
2025-12-09 12:10:02.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.00997198738069931 Training loss: 7.844531059265137
2025-12-09 12:10:03.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.009971657163801459 Training loss: 7.538690567016602
2025-12-09 12:10:03.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.009971325017500525 Training loss: 7.709425926208496
2025-12-09 12:10:03.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.00997099094192541 Training loss: 7.522182464599609
2025-12-09 12:10:04.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.009970654937205762 Training loss: 7.742945671081543
2025-12-09 12:10:04.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.009970317003471976 Training loss: 7.5407233238220215
2025-12-09 12:10:05.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.009969977140855197 Training loss: 7.855037212371826
2025-12-09 12:10:05.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.009969635349487322 Training loss: 7.270535945892334
2025-12-09 12:10:05.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.009969291629500991 Training loss: 7.783672332763672
2025-12-09 12:10:06.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.009968945981029596 Training loss: 7.636234760284424
2025-12-09 12:10:06.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.009968598404207276 Training loss: 7.436007499694824
2025-12-09 12:10:06.982 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.009968248899168919 Training loss: 7.629038333892822
2025-12-09 12:10:07.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.00996789746605016 Training loss: 7.426293849945068
2025-12-09 12:10:07.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.009967544104987387 Training loss: 7.807324409484863
2025-12-09 12:10:08.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.009967188816117727 Training loss: 7.685818195343018
2025-12-09 12:10:08.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.009966831599579066 Training loss: 7.583306789398193
2025-12-09 12:10:08.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.00996647245551003 Training loss: 8.31084156036377
2025-12-09 12:10:09.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.009966111384049996 Training loss: 7.5246806144714355
2025-12-09 12:10:09.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.009965748385339089 Training loss: 8.415411949157715
2025-12-09 12:10:10.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.00996538345951818 Training loss: 7.569220542907715
2025-12-09 12:10:10.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.009965016606728895 Training loss: 7.672807216644287
2025-12-09 12:10:10.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.009964647827113595 Training loss: 7.511192321777344
2025-12-09 12:10:11.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.009964277120815402 Training loss: 8.138970375061035
2025-12-09 12:10:11.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.009963904487978178 Training loss: 8.002615928649902
2025-12-09 12:10:12.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.009963529928746533 Training loss: 7.594285488128662
2025-12-09 12:10:12.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.009963153443265827 Training loss: 7.645310401916504
2025-12-09 12:10:12.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.00996277503168217 Training loss: 7.52149772644043
2025-12-09 12:10:13.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.00996239469414241 Training loss: 9.012992858886719
2025-12-09 12:10:13.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.009962012430794153 Training loss: 7.391480922698975
2025-12-09 12:10:13.953 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.009961628241785746 Training loss: 8.210860252380371
2025-12-09 12:10:14.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.009961242127266288 Training loss: 7.7436699867248535
2025-12-09 12:10:14.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.009960854087385618 Training loss: 7.419352054595947
2025-12-09 12:10:15.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.00996046412229433 Training loss: 7.608795642852783
2025-12-09 12:10:15.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.009960072232143761 Training loss: 7.620068550109863
2025-12-09 12:10:15.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.009959678417085997 Training loss: 7.683347225189209
2025-12-09 12:10:16.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.009959282677273869 Training loss: 7.517338752746582
2025-12-09 12:10:16.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.009958885012860954 Training loss: 7.703037261962891
2025-12-09 12:10:17.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.009958485424001582 Training loss: 7.520098686218262
2025-12-09 12:10:17.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.009958083910850821 Training loss: 7.625129222869873
2025-12-09 12:10:17.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.009957680473564495 Training loss: 7.634808540344238
2025-12-09 12:10:18.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.009957275112299165 Training loss: 7.308627605438232
2025-12-09 12:10:18.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.009956867827212149 Training loss: 7.314211845397949
2025-12-09 12:10:18.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.009956458618461502 Training loss: 7.978985786437988
2025-12-09 12:10:19.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.009956047486206033 Training loss: 7.59154748916626
2025-12-09 12:10:19.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.00995563443060529 Training loss: 7.486171245574951
2025-12-09 12:10:20.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.00995521945181958 Training loss: 7.4280548095703125
2025-12-09 12:10:20.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.00995480255000994 Training loss: 7.615382671356201
2025-12-09 12:10:20.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.009954383725338167 Training loss: 7.890956401824951
2025-12-09 12:10:21.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.009953962977966795 Training loss: 7.73366117477417
2025-12-09 12:10:21.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.00995354030805911 Training loss: 7.610858917236328
2025-12-09 12:10:22.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.009953115715779141 Training loss: 7.766814708709717
2025-12-09 12:10:22.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.009952689201291663 Training loss: 7.546913146972656
2025-12-09 12:10:22.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.0099522607647622 Training loss: 7.671908378601074
2025-12-09 12:10:23.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.00995183040635702 Training loss: 7.5001115798950195
2025-12-09 12:10:23.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.009951398126243134 Training loss: 7.750489234924316
2025-12-09 12:10:24.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.009950963924588304 Training loss: 7.490151882171631
2025-12-09 12:10:24.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.009950527801561034 Training loss: 8.283973693847656
2025-12-09 12:10:24.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.009950089757330574 Training loss: 7.722535133361816
2025-12-09 12:10:25.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.009949649792066922 Training loss: 7.52833366394043
2025-12-09 12:10:25.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.00994920790594082 Training loss: 7.726585388183594
2025-12-09 12:10:25.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.009948764099123755 Training loss: 7.429949760437012
2025-12-09 12:10:26.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.00994831837178796 Training loss: 7.554405212402344
2025-12-09 12:10:26.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.009947870724106411 Training loss: 7.362534523010254
2025-12-09 12:10:27.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.009947421156252837 Training loss: 7.373218536376953
2025-12-09 12:10:27.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.009946969668401697 Training loss: 7.729368686676025
2025-12-09 12:10:27.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.009946516260728214 Training loss: 7.620269775390625
2025-12-09 12:10:28.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.009946060933408342 Training loss: 7.277665615081787
2025-12-09 12:10:28.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.009945603686618785 Training loss: 7.541835308074951
2025-12-09 12:10:29.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.009945144520536991 Training loss: 7.708131790161133
2025-12-09 12:10:29.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.009944683435341155 Training loss: 7.325390338897705
2025-12-09 12:10:29.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.009944220431210215 Training loss: 7.681406497955322
2025-12-09 12:10:30.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.009943755508323854 Training loss: 7.711911201477051
2025-12-09 12:10:30.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.009943288666862497 Training loss: 7.072324752807617
2025-12-09 12:10:30.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.00994281990700732 Training loss: 7.478427410125732
2025-12-09 12:10:31.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.009942349228940238 Training loss: 7.608855724334717
2025-12-09 12:10:31.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.00994187663284391 Training loss: 7.219157695770264
2025-12-09 12:10:32.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.009941402118901743 Training loss: 7.436713218688965
2025-12-09 12:10:32.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.009940925687297887 Training loss: 7.518409252166748
2025-12-09 12:10:32.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.009940447338217234 Training loss: 7.60910177230835
2025-12-09 12:10:33.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.009939967071845425 Training loss: 7.3450493812561035
2025-12-09 12:10:33.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.009939484888368837 Training loss: 7.2926812171936035
2025-12-09 12:10:34.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.009939000787974602 Training loss: 7.557651519775391
2025-12-09 12:10:34.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.009938514770850585 Training loss: 7.773036003112793
2025-12-09 12:10:34.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.009938026837185403 Training loss: 7.457873344421387
2025-12-09 12:10:35.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.009937536987168413 Training loss: 7.8358869552612305
2025-12-09 12:10:35.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.009937045220989716 Training loss: 7.753752708435059
2025-12-09 12:10:36.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.009936551538840153 Training loss: 7.52466344833374
2025-12-09 12:10:36.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.009936055940911319 Training loss: 7.474754333496094
2025-12-09 12:10:36.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.009935558427395541 Training loss: 7.374904632568359
2025-12-09 12:10:37.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.009935058998485898 Training loss: 7.710376262664795
2025-12-09 12:10:37.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.009934557654376204 Training loss: 7.382701873779297
2025-12-09 12:10:37.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.009934054395261025 Training loss: 7.562123775482178
2025-12-09 12:10:38.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.009933549221335665 Training loss: 7.758755207061768
2025-12-09 12:10:38.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.009933042132796171 Training loss: 7.503002643585205
2025-12-09 12:10:39.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.009932533129839334 Training loss: 7.297426700592041
2025-12-09 12:10:39.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.00993202221266269 Training loss: 7.895272731781006
2025-12-09 12:10:39.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.009931509381464514 Training loss: 7.370941162109375
2025-12-09 12:10:40.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.009930994636443828 Training loss: 7.502427577972412
2025-12-09 12:10:40.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.009930477977800391 Training loss: 7.5730671882629395
2025-12-09 12:10:41.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.009929959405734712 Training loss: 7.507777690887451
2025-12-09 12:10:41.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.009929438920448038 Training loss: 7.405078411102295
2025-12-09 12:10:41.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.009928916522142357 Training loss: 7.482422828674316
2025-12-09 12:10:42.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.0099283922110204 Training loss: 7.280696392059326
2025-12-09 12:10:42.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.009927865987285648 Training loss: 7.204545021057129
2025-12-09 12:10:42.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.009927337851142314 Training loss: 7.272457599639893
2025-12-09 12:10:43.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.009926807802795359 Training loss: 7.3040876388549805
2025-12-09 12:10:43.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.009926275842450481 Training loss: 7.5086565017700195
2025-12-09 12:10:44.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.009925741970314128 Training loss: 8.262140274047852
2025-12-09 12:10:44.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.009925206186593483 Training loss: 7.542784214019775
2025-12-09 12:10:44.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.009924668491496473 Training loss: 7.32572078704834
2025-12-09 12:10:45.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.009924128885231769 Training loss: 8.07414722442627
2025-12-09 12:10:45.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.009923587368008779 Training loss: 8.38573169708252
2025-12-09 12:10:46.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.009923043940037657 Training loss: 7.513071060180664
2025-12-09 12:10:46.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.009922498601529295 Training loss: 7.588703632354736
2025-12-09 12:10:46.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.00992195135269533 Training loss: 7.699126243591309
2025-12-09 12:10:47.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.009921402193748138 Training loss: 7.510539531707764
2025-12-09 12:10:47.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.009920851124900838 Training loss: 7.941081523895264
2025-12-09 12:10:48.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.009920298146367286 Training loss: 7.652683258056641
2025-12-09 12:10:48.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.009919743258362085 Training loss: 7.740662574768066
2025-12-09 12:10:48.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.009919186461100576 Training loss: 7.3388872146606445
2025-12-09 12:10:49.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.009918627754798839 Training loss: 8.08931827545166
2025-12-09 12:10:49.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0099180671396737 Training loss: 7.312778949737549
2025-12-09 12:10:49.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.009917504615942721 Training loss: 7.873477935791016
2025-12-09 12:10:50.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.009916940183824205 Training loss: 7.021512031555176
2025-12-09 12:10:50.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.009916373843537201 Training loss: 7.4081830978393555
2025-12-09 12:10:51.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.009915805595301492 Training loss: 7.2504048347473145
2025-12-09 12:10:51.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.009915235439337602 Training loss: 7.077890396118164
2025-12-09 12:10:51.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.009914663375866804 Training loss: 7.401708602905273
2025-12-09 12:10:52.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.009914089405111097 Training loss: 8.433760643005371
2025-12-09 12:10:52.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.009913513527293234 Training loss: 7.24807071685791
2025-12-09 12:10:53.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.009912935742636698 Training loss: 7.72402811050415
2025-12-09 12:10:53.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.009912356051365718 Training loss: 7.553000450134277
2025-12-09 12:10:53.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.009911774453705257 Training loss: 7.34434700012207
2025-12-09 12:10:54.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.00991119094988103 Training loss: 7.497420310974121
2025-12-09 12:10:54.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.009910605540119475 Training loss: 7.398504734039307
2025-12-09 12:10:55.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.009910018224647781 Training loss: 7.406291961669922
2025-12-09 12:10:55.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.009909429003693876 Training loss: 7.377997398376465
2025-12-09 12:10:55.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.009908837877486422 Training loss: 7.792779922485352
2025-12-09 12:10:56.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.009908244846254825 Training loss: 7.293363571166992
2025-12-09 12:10:56.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.009907649910229228 Training loss: 7.202423095703125
2025-12-09 12:10:56.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.009907053069640516 Training loss: 7.250880241394043
2025-12-09 12:10:57.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.009906454324720308 Training loss: 7.551741600036621
2025-12-09 12:10:57.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.009905853675700968 Training loss: 7.603823184967041
2025-12-09 12:10:58.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.009905251122815597 Training loss: 7.812702178955078
2025-12-09 12:10:58.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.00990464666629803 Training loss: 7.273106098175049
2025-12-09 12:10:58.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.009904040306382847 Training loss: 7.633992671966553
2025-12-09 12:10:59.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.009903432043305365 Training loss: 7.485961437225342
2025-12-09 12:10:59.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.009902821877301638 Training loss: 7.553870677947998
2025-12-09 12:11:00.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.00990220980860846 Training loss: 7.369173526763916
2025-12-09 12:11:00.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.009901595837463363 Training loss: 7.182636260986328
2025-12-09 12:11:00.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.009900979964104618 Training loss: 7.387495040893555
2025-12-09 12:11:01.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.00990036218877123 Training loss: 7.474361419677734
2025-12-09 12:11:01.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.00989974251170295 Training loss: 7.3514909744262695
2025-12-09 12:11:01.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.00989912093314026 Training loss: 7.317968845367432
2025-12-09 12:11:02.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.009898497453324384 Training loss: 7.713379859924316
2025-12-09 12:11:02.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.009897872072497281 Training loss: 7.669250011444092
2025-12-09 12:11:03.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.00989724479090165 Training loss: 7.455208778381348
2025-12-09 12:11:03.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.009896615608780924 Training loss: 7.459601879119873
2025-12-09 12:11:03.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.00989598452637928 Training loss: 7.341777324676514
2025-12-09 12:11:04.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.009895351543941628 Training loss: 7.325250625610352
2025-12-09 12:11:04.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.009894716661713616 Training loss: 7.599484920501709
2025-12-09 12:11:05.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.009894079879941628 Training loss: 8.131826400756836
2025-12-09 12:11:05.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.009893441198872787 Training loss: 7.342393398284912
2025-12-09 12:11:05.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.009892800618754954 Training loss: 7.144485950469971
2025-12-09 12:11:06.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.009892158139836724 Training loss: 7.552736759185791
2025-12-09 12:11:06.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.00989151376236743 Training loss: 7.09807825088501
2025-12-09 12:11:07.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.009890867486597146 Training loss: 7.582273960113525
2025-12-09 12:11:07.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.009890219312776677 Training loss: 7.272790908813477
2025-12-09 12:11:07.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.009889569241157564 Training loss: 7.790186405181885
2025-12-09 12:11:08.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.00988891727199209 Training loss: 7.7741498947143555
2025-12-09 12:11:08.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.009888263405533271 Training loss: 7.498084545135498
2025-12-09 12:11:08.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.009887607642034859 Training loss: 7.629440784454346
2025-12-09 12:11:09.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.009886949981751346 Training loss: 7.526432514190674
2025-12-09 12:11:09.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.009886290424937952 Training loss: 7.369968414306641
2025-12-09 12:11:10.113 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.009885628971850642 Training loss: 7.356497287750244
2025-12-09 12:11:10.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.009884965622746112 Training loss: 7.848931789398193
2025-12-09 12:11:10.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.009884300377881794 Training loss: 7.395492076873779
2025-12-09 12:11:11.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.009883633237515857 Training loss: 7.2290520668029785
2025-12-09 12:11:11.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.009882964201907207 Training loss: 7.10294771194458
2025-12-09 12:11:12.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.00988229327131548 Training loss: 7.681521892547607
2025-12-09 12:11:12.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.009881620446001056 Training loss: 7.494019031524658
2025-12-09 12:11:12.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.00988094572622504 Training loss: 7.592530250549316
2025-12-09 12:11:13.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.00988026911224928 Training loss: 7.594344615936279
2025-12-09 12:11:13.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.00987959060433636 Training loss: 6.903561115264893
2025-12-09 12:11:13.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.009878910202749589 Training loss: 7.602128505706787
2025-12-09 12:11:14.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.009878227907753022 Training loss: 7.494284152984619
2025-12-09 12:11:14.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.009877543719611444 Training loss: 7.454542636871338
2025-12-09 12:11:15.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.009876857638590373 Training loss: 7.539631366729736
2025-12-09 12:11:15.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.009876169664956067 Training loss: 7.437558650970459
2025-12-09 12:11:15.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.009875479798975512 Training loss: 7.4343485832214355
2025-12-09 12:11:16.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.009874788040916432 Training loss: 7.03497314453125
2025-12-09 12:11:16.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.009874094391047288 Training loss: 7.338759899139404
2025-12-09 12:11:17.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.009873398849637267 Training loss: 7.393733978271484
2025-12-09 12:11:17.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.009872701416956299 Training loss: 7.449803352355957
2025-12-09 12:11:17.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.009872002093275042 Training loss: 6.609776496887207
2025-12-09 12:11:18.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.00987130087886489 Training loss: 7.118298053741455
2025-12-09 12:11:18.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.009870597773997972 Training loss: 7.310823917388916
2025-12-09 12:11:19.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.009869892778947148 Training loss: 6.787532806396484
2025-12-09 12:11:19.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.009869185893986013 Training loss: 7.455399990081787
2025-12-09 12:11:19.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.009868477119388895 Training loss: 7.685577392578125
2025-12-09 12:11:20.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.009867766455430856 Training loss: 7.957728385925293
2025-12-09 12:11:20.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.009867053902387693 Training loss: 7.4016804695129395
2025-12-09 12:11:20.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.009866339460535929 Training loss: 7.871706485748291
2025-12-09 12:11:21.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.009865623130152828 Training loss: 7.691350936889648
2025-12-09 12:11:21.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.009864904911516384 Training loss: 7.426024436950684
2025-12-09 12:11:22.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.009864184804905323 Training loss: 7.637496471405029
2025-12-09 12:11:22.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.009863462810599103 Training loss: 7.7560529708862305
2025-12-09 12:11:22.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.009862738928877922 Training loss: 7.497246265411377
2025-12-09 12:11:23.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.009862013160022696 Training loss: 7.326463222503662
2025-12-09 12:11:23.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.009861285504315085 Training loss: 7.425178050994873
2025-12-09 12:11:24.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.00986055596203748 Training loss: 7.3292412757873535
2025-12-09 12:11:24.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.009859824533472998 Training loss: 7.353517532348633
2025-12-09 12:11:24.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.009859091218905498 Training loss: 7.161673069000244
2025-12-09 12:11:25.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.00985835601861956 Training loss: 7.671576023101807
2025-12-09 12:11:25.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.009857618932900504 Training loss: 7.222116947174072
2025-12-09 12:11:25.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.009856879962034375 Training loss: 7.1739888191223145
2025-12-09 12:11:26.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.009856139106307955 Training loss: 7.991626739501953
2025-12-09 12:11:26.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.009855396366008757 Training loss: 7.440537452697754
2025-12-09 12:11:27.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.009854651741425023 Training loss: 7.294981956481934
2025-12-09 12:11:27.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.009853905232845728 Training loss: 7.397503852844238
2025-12-09 12:11:27.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.009853156840560576 Training loss: 7.2816290855407715
2025-12-09 12:11:28.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.009852406564860004 Training loss: 7.8152337074279785
2025-12-09 12:11:28.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.009851654406035179 Training loss: 7.371341228485107
2025-12-09 12:11:29.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.009850900364378 Training loss: 7.889325141906738
2025-12-09 12:11:29.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.009850144440181096 Training loss: 8.205016136169434
2025-12-09 12:11:29.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.009849386633737824 Training loss: 7.2632737159729
2025-12-09 12:11:30.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.009848626945342278 Training loss: 7.766486644744873
2025-12-09 12:11:30.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.009847865375289276 Training loss: 7.1428914070129395
2025-12-09 12:11:31.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.009847101923874366 Training loss: 7.393019676208496
2025-12-09 12:11:31.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.009846336591393832 Training loss: 7.491754531860352
2025-12-09 12:11:31.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.009845569378144686 Training loss: 7.153282642364502
2025-12-09 12:11:32.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.009844800284424663 Training loss: 6.593554496765137
2025-12-09 12:11:32.574 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.00984402931053224 Training loss: 7.691162586212158
2025-12-09 12:11:32.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.009843256456766609 Training loss: 8.095849990844727
2025-12-09 12:11:33.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.009842481723427705 Training loss: 7.014219284057617
2025-12-09 12:11:33.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.009841705110816185 Training loss: 7.712803363800049
2025-12-09 12:11:34.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.00984092661923344 Training loss: 7.516927242279053
2025-12-09 12:11:34.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.009840146248981585 Training loss: 7.529959201812744
2025-12-09 12:11:34.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.009839364000363466 Training loss: 7.772701740264893
2025-12-09 12:11:35.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.00983857987368266 Training loss: 7.472396373748779
2025-12-09 12:11:35.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.009837793869243468 Training loss: 6.994795799255371
2025-12-09 12:11:36.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.009837005987350926 Training loss: 6.762487411499023
2025-12-09 12:11:36.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.009836216228310797 Training loss: 6.88243293762207
2025-12-09 12:11:36.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.009835424592429568 Training loss: 7.398321628570557
2025-12-09 12:11:37.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.009834631080014457 Training loss: 7.611600399017334
2025-12-09 12:11:37.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.009833835691373412 Training loss: 7.529797554016113
2025-12-09 12:11:37.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.00983303842681511 Training loss: 7.403950214385986
2025-12-09 12:11:38.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.009832239286648949 Training loss: 7.301347732543945
2025-12-09 12:11:38.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.009831438271185065 Training loss: 7.726388454437256
2025-12-09 12:11:39.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.009830635380734313 Training loss: 7.250888347625732
2025-12-09 12:11:39.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.009829830615608279 Training loss: 7.446057319641113
2025-12-09 12:11:39.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.009829023976119278 Training loss: 7.567038059234619
2025-12-09 12:11:40.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.009828215462580352 Training loss: 7.579563140869141
2025-12-09 12:11:40.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.009827405075305266 Training loss: 7.8742499351501465
2025-12-09 12:11:41.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.009826592814608518 Training loss: 7.51179838180542
2025-12-09 12:11:41.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.00982577868080533 Training loss: 7.528382778167725
2025-12-09 12:11:41.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.009824962674211653 Training loss: 7.257623195648193
2025-12-09 12:11:42.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.009824144795144159 Training loss: 7.529794216156006
2025-12-09 12:11:42.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.009823325043920255 Training loss: 7.353743076324463
2025-12-09 12:11:43.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.009822503420858067 Training loss: 7.2763671875
2025-12-09 12:11:43.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.009821679926276456 Training loss: 7.497102737426758
2025-12-09 12:11:43.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.009820854560494998 Training loss: 7.80940055847168
2025-12-09 12:11:44.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.009820027323834007 Training loss: 7.501173973083496
2025-12-09 12:11:44.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.009819198216614512 Training loss: 7.291538238525391
2025-12-09 12:11:44.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.009818367239158278 Training loss: 7.486466884613037
2025-12-09 12:11:45.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.009817534391787787 Training loss: 7.261708736419678
2025-12-09 12:11:45.745 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.009816699674826256 Training loss: 7.419973373413086
2025-12-09 12:11:46.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.009815863088597618 Training loss: 7.315542221069336
2025-12-09 12:11:46.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.009815024633426537 Training loss: 7.880640029907227
2025-12-09 12:11:46.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.0098141843096384 Training loss: 7.744953155517578
2025-12-09 12:11:47.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.009813342117559323 Training loss: 7.632628440856934
2025-12-09 12:11:47.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.009812498057516142 Training loss: 8.361857414245605
2025-12-09 12:11:48.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.009811652129836422 Training loss: 7.379230976104736
2025-12-09 12:11:48.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.009810804334848449 Training loss: 7.632153511047363
2025-12-09 12:11:48.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.009809954672881238 Training loss: 7.205657482147217
2025-12-09 12:11:49.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.009809103144264524 Training loss: 7.294486999511719
2025-12-09 12:11:49.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.009808249749328769 Training loss: 7.4048075675964355
2025-12-09 12:11:50.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.009807394488405159 Training loss: 7.236947536468506
2025-12-09 12:11:50.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.009806537361825607 Training loss: 7.476173400878906
2025-12-09 12:11:50.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.009805678369922742 Training loss: 7.323919773101807
2025-12-09 12:11:51.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.009804817513029926 Training loss: 7.470529556274414
2025-12-09 12:11:51.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.009803954791481238 Training loss: 7.483381271362305
2025-12-09 12:11:51.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.009803090205611487 Training loss: 7.256255149841309
2025-12-09 12:11:52.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.009802223755756198 Training loss: 7.211571216583252
2025-12-09 12:11:52.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.009801355442251625 Training loss: 7.214414596557617
2025-12-09 12:11:53.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.009800485265434745 Training loss: 7.273148059844971
2025-12-09 12:11:53.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.009799613225643253 Training loss: 7.493269443511963
2025-12-09 12:11:53.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.009798739323215573 Training loss: 7.44381046295166
2025-12-09 12:11:54.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.00979786355849085 Training loss: 6.868198394775391
2025-12-09 12:11:54.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.009796985931808949 Training loss: 6.963034629821777
2025-12-09 12:11:55.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.009796106443510462 Training loss: 7.580628871917725
2025-12-09 12:11:55.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.009795225093936702 Training loss: 8.474045753479004
2025-12-09 12:11:55.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.009794341883429699 Training loss: 7.672577381134033
2025-12-09 12:11:56.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.009793456812332214 Training loss: 7.333316802978516
2025-12-09 12:11:56.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.009792569880987725 Training loss: 8.371347427368164
2025-12-09 12:11:56.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.009791681089740432 Training loss: 7.4932475090026855
2025-12-09 12:11:57.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.009790790438935257 Training loss: 7.167281150817871
2025-12-09 12:11:57.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.009789897928917846 Training loss: 7.522182941436768
2025-12-09 12:11:58.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.009789003560034561 Training loss: 7.472830295562744
2025-12-09 12:11:58.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.009788107332632493 Training loss: 7.408020496368408
2025-12-09 12:11:58.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.009787209247059453 Training loss: 7.436878204345703
2025-12-09 12:11:59.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.009786309303663962 Training loss: 7.256771087646484
2025-12-09 12:11:59.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.009785407502795277 Training loss: 7.503124713897705
2025-12-09 12:12:00.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.009784503844803368 Training loss: 7.3758673667907715
2025-12-09 12:12:00.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.009783598330038924 Training loss: 7.35767936706543
2025-12-09 12:12:00.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.009782690958853361 Training loss: 7.662302017211914
2025-12-09 12:12:01.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.009781781731598813 Training loss: 7.986825942993164
2025-12-09 12:12:01.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.00978087064862813 Training loss: 7.295827388763428
2025-12-09 12:12:02.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.009779957710294886 Training loss: 8.332552909851074
2025-12-09 12:12:02.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.009779042916953376 Training loss: 7.397876739501953
2025-12-09 12:12:02.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.009778126268958612 Training loss: 7.115326404571533
2025-12-09 12:12:03.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.009777207766666329 Training loss: 7.123432159423828
2025-12-09 12:12:03.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.00977628741043298 Training loss: 7.230593204498291
2025-12-09 12:12:03.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.009775365200615735 Training loss: 7.017728805541992
2025-12-09 12:12:04.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.009774441137572488 Training loss: 7.292820930480957
2025-12-09 12:12:04.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.009773515221661847 Training loss: 7.211131572723389
2025-12-09 12:12:05.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.009772587453243142 Training loss: 7.450753211975098
2025-12-09 12:12:05.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.009771657832676426 Training loss: 7.433441638946533
2025-12-09 12:12:05.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.009770726360322463 Training loss: 7.300180435180664
2025-12-09 12:12:06.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.009769793036542742 Training loss: 7.278715133666992
2025-12-09 12:12:06.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.009768857861699462 Training loss: 7.516940593719482
2025-12-09 12:12:07.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.009767920836155552 Training loss: 7.418342113494873
2025-12-09 12:12:07.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.009766981960274652 Training loss: 7.058056831359863
2025-12-09 12:12:07.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.009766041234421121 Training loss: 7.587108135223389
2025-12-09 12:12:08.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.009765098658960036 Training loss: 7.254961967468262
2025-12-09 12:12:08.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.00976415423425719 Training loss: 7.871984958648682
2025-12-09 12:12:08.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.0097632079606791 Training loss: 7.9509806632995605
2025-12-09 12:12:09.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.009762259838592994 Training loss: 7.290749549865723
2025-12-09 12:12:09.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.009761309868366819 Training loss: 8.080552101135254
2025-12-09 12:12:10.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.009760358050369242 Training loss: 7.329413890838623
2025-12-09 12:12:10.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.009759404384969644 Training loss: 7.351097106933594
2025-12-09 12:12:10.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.009758448872538121 Training loss: 7.902377605438232
2025-12-09 12:12:11.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.009757491513445493 Training loss: 7.717203617095947
2025-12-09 12:12:11.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.009756532308063294 Training loss: 7.429409503936768
2025-12-09 12:12:12.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.009755571256763764 Training loss: 7.2099103927612305
2025-12-09 12:12:12.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.009754608359919878 Training loss: 7.727548599243164
2025-12-09 12:12:12.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.009753643617905313 Training loss: 7.668389797210693
2025-12-09 12:12:13.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.009752677031094465 Training loss: 7.57176399230957
2025-12-09 12:12:13.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.009751708599862451 Training loss: 7.128892421722412
2025-12-09 12:12:14.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.009750738324585098 Training loss: 7.357558727264404
2025-12-09 12:12:14.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.009749766205638952 Training loss: 7.3873748779296875
2025-12-09 12:12:14.794 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.009748792243401274 Training loss: 8.239011764526367
2025-12-09 12:12:15.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.009747816438250036 Training loss: 7.435668468475342
2025-12-09 12:12:15.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.009746838790563934 Training loss: 7.249029636383057
2025-12-09 12:12:15.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.009745859300722371 Training loss: 7.461339473724365
2025-12-09 12:12:16.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.009744877969105468 Training loss: 7.839138507843018
2025-12-09 12:12:16.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.009743894796094062 Training loss: 7.599367618560791
2025-12-09 12:12:17.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.009742909782069702 Training loss: 7.2118611335754395
2025-12-09 12:12:17.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.009741922927414652 Training loss: 7.466182231903076
2025-12-09 12:12:17.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.009740934232511893 Training loss: 7.237792491912842
2025-12-09 12:12:18.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.009739943697745118 Training loss: 7.878453254699707
2025-12-09 12:12:18.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.009738951323498732 Training loss: 7.242652893066406
2025-12-09 12:12:19.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.009737957110157859 Training loss: 7.183384895324707
2025-12-09 12:12:19.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.009736961058108331 Training loss: 7.120657444000244
2025-12-09 12:12:19.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.009735963167736698 Training loss: 7.417238235473633
2025-12-09 12:12:20.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.009734963439430222 Training loss: 7.280272006988525
2025-12-09 12:12:20.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.009733961873576877 Training loss: 7.187076568603516
2025-12-09 12:12:20.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.009732958470565352 Training loss: 7.5882673263549805
2025-12-09 12:12:21.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.009731953230785049 Training loss: 7.417818546295166
2025-12-09 12:12:21.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.009730946154626078 Training loss: 7.130001068115234
2025-12-09 12:12:22.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.00972993724247927 Training loss: 8.098163604736328
2025-12-09 12:12:22.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.009728926494736164 Training loss: 7.723449230194092
2025-12-09 12:12:22.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.009727913911789008 Training loss: 7.166381359100342
2025-12-09 12:12:23.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.009726899494030768 Training loss: 7.298944473266602
2025-12-09 12:12:23.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.009725883241855119 Training loss: 7.358877658843994
2025-12-09 12:12:24.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.009724865155656449 Training loss: 7.444201469421387
2025-12-09 12:12:24.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.009723845235829857 Training loss: 7.356246471405029
2025-12-09 12:12:24.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.009722823482771155 Training loss: 7.395292282104492
2025-12-09 12:12:25.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.009721799896876864 Training loss: 7.930926322937012
2025-12-09 12:12:25.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.009720774478544218 Training loss: 7.37047815322876
2025-12-09 12:12:26.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.009719747228171163 Training loss: 7.3419294357299805
2025-12-09 12:12:26.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.009718718146156354 Training loss: 7.350857257843018
2025-12-09 12:12:26.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.00971768723289916 Training loss: 7.321159839630127
2025-12-09 12:12:27.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.009716654488799652 Training loss: 7.347329616546631
2025-12-09 12:12:27.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.009715619914258624 Training loss: 7.285747528076172
2025-12-09 12:12:27.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.00971458350967757 Training loss: 7.209366798400879
2025-12-09 12:12:28.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.009713545275458703 Training loss: 7.065714359283447
2025-12-09 12:12:28.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.009712505212004938 Training loss: 6.884268760681152
2025-12-09 12:12:29.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.009711463319719903 Training loss: 7.965512275695801
2025-12-09 12:12:29.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.009710419599007938 Training loss: 7.210707187652588
2025-12-09 12:12:29.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.009709374050274088 Training loss: 7.7941083908081055
2025-12-09 12:12:30.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.009708326673924114 Training loss: 7.474368095397949
2025-12-09 12:12:30.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.009707277470364482 Training loss: 7.417293071746826
2025-12-09 12:12:31.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.009706226440002363 Training loss: 7.027703285217285
2025-12-09 12:12:31.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.009705173583245644 Training loss: 7.43784761428833
2025-12-09 12:12:31.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.009704118900502918 Training loss: 7.358889579772949
2025-12-09 12:12:32.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.009703062392183489 Training loss: 7.510584354400635
2025-12-09 12:12:32.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.009702004058697363 Training loss: 7.240025997161865
2025-12-09 12:12:33.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.00970094390045526 Training loss: 7.694633960723877
2025-12-09 12:12:33.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.00969988191786861 Training loss: 7.279272556304932
2025-12-09 12:12:33.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.009698818111349544 Training loss: 7.334325790405273
2025-12-09 12:12:34.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.009697752481310905 Training loss: 7.427333354949951
2025-12-09 12:12:34.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.009696685028166244 Training loss: 7.587650775909424
2025-12-09 12:12:34.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.00969561575232982 Training loss: 7.06468391418457
2025-12-09 12:12:35.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.009694544654216595 Training loss: 7.3552165031433105
2025-12-09 12:12:35.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.009693471734242244 Training loss: 6.934377670288086
2025-12-09 12:12:36.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.009692396992823146 Training loss: 7.115750312805176
2025-12-09 12:12:36.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.009691320430376385 Training loss: 7.861351013183594
2025-12-09 12:12:36.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.009690242047319756 Training loss: 7.456040859222412
2025-12-09 12:12:37.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.009689161844071757 Training loss: 7.280932426452637
2025-12-09 12:12:37.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.009688079821051594 Training loss: 7.219519138336182
2025-12-09 12:12:38.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.009686995978679181 Training loss: 7.389139175415039
2025-12-09 12:12:38.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.009685910317375132 Training loss: 7.50624942779541
2025-12-09 12:12:38.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.009684822837560777 Training loss: 7.645272254943848
2025-12-09 12:12:39.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.00968373353965814 Training loss: 7.443727970123291
2025-12-09 12:12:39.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.009682642424089958 Training loss: 7.522425174713135
2025-12-09 12:12:39.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.009681549491279673 Training loss: 7.613651752471924
2025-12-09 12:12:40.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.00968045474165143 Training loss: 7.452301025390625
2025-12-09 12:12:40.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.00967935817563008 Training loss: 7.9926958084106445
2025-12-09 12:12:41.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.00967825979364118 Training loss: 7.3258819580078125
2025-12-09 12:12:41.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.009677159596110986 Training loss: 7.542942523956299
2025-12-09 12:12:41.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.009676057583466471 Training loss: 7.506320476531982
2025-12-09 12:12:42.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.009674953756135297 Training loss: 7.27277135848999
2025-12-09 12:12:42.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.009673848114545842 Training loss: 7.9960551261901855
2025-12-09 12:12:43.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.009672740659127184 Training loss: 7.1671223640441895
2025-12-09 12:12:43.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.009671631390309103 Training loss: 7.480555534362793
2025-12-09 12:12:43.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.009670520308522083 Training loss: 7.3441267013549805
2025-12-09 12:12:44.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.009669407414197318 Training loss: 7.146144866943359
2025-12-09 12:12:44.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.009668292707766698 Training loss: 7.326939105987549
