2025-12-09 12:04:25.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 9.209644317626953
2025-12-09 12:04:25.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 9.209714889526367
2025-12-09 12:04:25.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 9.20905876159668
2025-12-09 12:04:25.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 9.209120750427246
2025-12-09 12:04:25.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 9.209829330444336
2025-12-09 12:04:25.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 9.209404945373535
2025-12-09 12:04:25.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 9.20901870727539
2025-12-09 12:04:25.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 9.2091064453125
2025-12-09 12:04:26.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 9.209918975830078
2025-12-09 12:04:26.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 9.209446907043457
2025-12-09 12:04:26.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 9.209345817565918
2025-12-09 12:04:26.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 9.209320068359375
2025-12-09 12:04:26.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 9.208237648010254
2025-12-09 12:04:26.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 9.208518981933594
2025-12-09 12:04:26.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 9.208145141601562
2025-12-09 12:04:26.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 9.2085599899292
2025-12-09 12:04:26.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 9.209213256835938
2025-12-09 12:04:26.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 9.208502769470215
2025-12-09 12:04:26.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 9.208298683166504
2025-12-09 12:04:26.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 9.208725929260254
2025-12-09 12:04:26.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 9.208651542663574
2025-12-09 12:04:26.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 9.207782745361328
2025-12-09 12:04:26.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 9.20805549621582
2025-12-09 12:04:26.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 9.208426475524902
2025-12-09 12:04:26.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 9.207901000976562
2025-12-09 12:04:26.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 9.208357810974121
2025-12-09 12:04:26.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 9.208651542663574
2025-12-09 12:04:26.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 9.206693649291992
2025-12-09 12:04:26.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 9.207845687866211
2025-12-09 12:04:26.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 9.207093238830566
2025-12-09 12:04:26.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 9.206916809082031
2025-12-09 12:04:26.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 9.20736026763916
2025-12-09 12:04:26.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 9.206315040588379
2025-12-09 12:04:26.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 9.206199645996094
2025-12-09 12:04:26.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 9.20627498626709
2025-12-09 12:04:26.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 9.206171035766602
2025-12-09 12:04:26.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 9.206101417541504
2025-12-09 12:04:26.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 9.206751823425293
2025-12-09 12:04:26.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 9.205167770385742
2025-12-09 12:04:26.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 9.204970359802246
2025-12-09 12:04:26.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 9.204676628112793
2025-12-09 12:04:26.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 9.205011367797852
2025-12-09 12:04:26.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 9.205023765563965
2025-12-09 12:04:26.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 9.204270362854004
2025-12-09 12:04:26.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 9.203763961791992
2025-12-09 12:04:26.677 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 9.203432083129883
2025-12-09 12:04:26.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 9.202577590942383
2025-12-09 12:04:26.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 9.20364761352539
2025-12-09 12:04:26.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 9.203619003295898
2025-12-09 12:04:26.748 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 9.203049659729004
2025-12-09 12:04:26.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 9.202397346496582
2025-12-09 12:04:26.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 9.201444625854492
2025-12-09 12:04:26.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 9.2021484375
2025-12-09 12:04:26.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 9.201743125915527
2025-12-09 12:04:26.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 9.201619148254395
2025-12-09 12:04:26.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 9.201549530029297
2025-12-09 12:04:26.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 9.201935768127441
2025-12-09 12:04:26.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 9.202043533325195
2025-12-09 12:04:26.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 9.200179100036621
2025-12-09 12:04:26.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 9.199420928955078
2025-12-09 12:04:26.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 9.199178695678711
2025-12-09 12:04:26.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 9.199477195739746
2025-12-09 12:04:26.982 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 9.199333190917969
2025-12-09 12:04:27.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 9.198615074157715
2025-12-09 12:04:27.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 9.198126792907715
2025-12-09 12:04:27.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 9.197563171386719
2025-12-09 12:04:27.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 9.197915077209473
2025-12-09 12:04:27.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 9.197680473327637
2025-12-09 12:04:27.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 9.197928428649902
2025-12-09 12:04:27.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 9.195914268493652
2025-12-09 12:04:27.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 9.1966552734375
2025-12-09 12:04:27.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 9.195870399475098
2025-12-09 12:04:27.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 9.195106506347656
2025-12-09 12:04:27.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 9.195870399475098
2025-12-09 12:04:27.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 9.195059776306152
2025-12-09 12:04:27.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 9.192647933959961
2025-12-09 12:04:27.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 9.193913459777832
2025-12-09 12:04:27.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 9.19375228881836
2025-12-09 12:04:27.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 9.193603515625
2025-12-09 12:04:27.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 9.19227409362793
2025-12-09 12:04:27.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 9.190899848937988
2025-12-09 12:04:27.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 9.190997123718262
2025-12-09 12:04:27.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 9.191049575805664
2025-12-09 12:04:27.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 9.189915657043457
2025-12-09 12:04:27.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 9.190652847290039
2025-12-09 12:04:27.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 9.188364028930664
2025-12-09 12:04:27.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 9.186989784240723
2025-12-09 12:04:27.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 9.188607215881348
2025-12-09 12:04:27.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 9.188634872436523
2025-12-09 12:04:27.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 9.18769359588623
2025-12-09 12:04:27.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 9.186058044433594
2025-12-09 12:04:27.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 9.185221672058105
2025-12-09 12:04:27.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 9.187432289123535
2025-12-09 12:04:27.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 9.185113906860352
2025-12-09 12:04:27.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 9.186395645141602
2025-12-09 12:04:27.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 9.186455726623535
2025-12-09 12:04:27.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 9.183403015136719
2025-12-09 12:04:27.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 9.183899879455566
2025-12-09 12:04:27.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 9.182343482971191
2025-12-09 12:04:27.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 9.18252182006836
2025-12-09 12:04:27.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.698463103929542e-05 Training loss: 9.182820320129395
2025-12-09 12:04:27.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 8.83022221559489e-05 Training loss: 9.179750442504883
2025-12-09 12:04:27.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 7.500000000000001e-05 Training loss: 9.180055618286133
2025-12-09 12:04:27.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 5.868240888334653e-05 Training loss: 9.181901931762695
2025-12-09 12:04:27.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 4.131759111665349e-05 Training loss: 9.180261611938477
2025-12-09 12:04:27.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 2.500000000000001e-05 Training loss: 9.179333686828613
2025-12-09 12:04:27.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 1.1697777844051105e-05 Training loss: 9.178815841674805
2025-12-09 12:04:27.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 3.0153689607045845e-06 Training loss: 9.179183959960938
2025-12-09 12:04:27.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0 Training loss: 9.1808500289917
