2025-12-09 11:47:08.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 12.145103454589844
2025-12-09 11:47:09.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 12.176996231079102
2025-12-09 11:47:09.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 12.145171165466309
2025-12-09 11:47:09.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 12.13653564453125
2025-12-09 11:47:10.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 12.163667678833008
2025-12-09 11:47:10.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 12.136428833007812
2025-12-09 11:47:11.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 12.098267555236816
2025-12-09 11:47:11.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 12.043051719665527
2025-12-09 11:47:11.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 12.114592552185059
2025-12-09 11:47:12.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 11.996326446533203
2025-12-09 11:47:12.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 11.960759162902832
2025-12-09 11:47:12.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 11.895442008972168
2025-12-09 11:47:13.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 11.87214469909668
2025-12-09 11:47:13.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 11.827155113220215
2025-12-09 11:47:14.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 11.558284759521484
2025-12-09 11:47:14.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 11.68525505065918
2025-12-09 11:47:14.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 11.31070327758789
2025-12-09 11:47:15.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 11.184494972229004
2025-12-09 11:47:15.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 10.998677253723145
2025-12-09 11:47:16.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 10.854060173034668
2025-12-09 11:47:16.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 10.740215301513672
2025-12-09 11:47:16.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 10.76933479309082
2025-12-09 11:47:17.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 10.602653503417969
2025-12-09 11:47:17.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 10.235729217529297
2025-12-09 11:47:18.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 10.116432189941406
2025-12-09 11:47:18.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 10.39419174194336
2025-12-09 11:47:18.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 10.380270957946777
2025-12-09 11:47:19.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 10.161845207214355
2025-12-09 11:47:19.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 9.958392143249512
2025-12-09 11:47:19.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 9.568705558776855
2025-12-09 11:47:20.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 9.786627769470215
2025-12-09 11:47:20.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 9.62728214263916
2025-12-09 11:47:21.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 9.540205001831055
2025-12-09 11:47:21.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 9.423073768615723
2025-12-09 11:47:21.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 9.586657524108887
2025-12-09 11:47:22.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 9.336458206176758
2025-12-09 11:47:22.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 9.885966300964355
2025-12-09 11:47:23.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 9.267749786376953
2025-12-09 11:47:23.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 9.294771194458008
2025-12-09 11:47:23.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 8.978522300720215
2025-12-09 11:47:24.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 9.261975288391113
2025-12-09 11:47:24.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 9.256571769714355
2025-12-09 11:47:24.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 9.023041725158691
2025-12-09 11:47:25.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 9.1301908493042
2025-12-09 11:47:25.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 8.83480453491211
2025-12-09 11:47:26.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 9.077311515808105
2025-12-09 11:47:26.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 8.607157707214355
2025-12-09 11:47:26.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 8.761695861816406
2025-12-09 11:47:27.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 8.93116283416748
2025-12-09 11:47:27.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 8.942452430725098
2025-12-09 11:47:28.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 8.428116798400879
2025-12-09 11:47:28.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 8.799565315246582
2025-12-09 11:47:28.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 8.709877014160156
2025-12-09 11:47:29.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 8.549063682556152
2025-12-09 11:47:29.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 8.728723526000977
2025-12-09 11:47:29.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 8.682965278625488
2025-12-09 11:47:30.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 8.859166145324707
2025-12-09 11:47:30.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 8.542308807373047
2025-12-09 11:47:31.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 8.16097640991211
2025-12-09 11:47:31.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 8.49697494506836
2025-12-09 11:47:31.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 8.658379554748535
2025-12-09 11:47:32.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 8.84610652923584
2025-12-09 11:47:32.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 8.814373970031738
2025-12-09 11:47:33.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 8.165688514709473
2025-12-09 11:47:33.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 8.040759086608887
2025-12-09 11:47:33.831 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 8.185894012451172
2025-12-09 11:47:34.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 8.439620971679688
2025-12-09 11:47:34.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 8.350719451904297
2025-12-09 11:47:34.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 8.508283615112305
2025-12-09 11:47:35.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 8.072927474975586
2025-12-09 11:47:35.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 8.299278259277344
2025-12-09 11:47:36.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 8.146361351013184
2025-12-09 11:47:36.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 8.029796600341797
2025-12-09 11:47:36.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 8.219923973083496
2025-12-09 11:47:37.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 8.442108154296875
2025-12-09 11:47:37.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 8.116660118103027
2025-12-09 11:47:38.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 7.952785968780518
2025-12-09 11:47:38.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 8.357368469238281
2025-12-09 11:47:38.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 8.084672927856445
2025-12-09 11:47:39.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 8.449590682983398
2025-12-09 11:47:39.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 8.24378490447998
2025-12-09 11:47:39.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 8.198479652404785
2025-12-09 11:47:40.376 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 8.030122756958008
2025-12-09 11:47:40.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 8.17776870727539
2025-12-09 11:47:41.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 8.134732246398926
2025-12-09 11:47:41.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 8.518845558166504
2025-12-09 11:47:41.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 8.330638885498047
2025-12-09 11:47:42.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 7.68256139755249
2025-12-09 11:47:42.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 7.784154415130615
2025-12-09 11:47:43.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 8.628256797790527
2025-12-09 11:47:43.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 7.738435745239258
2025-12-09 11:47:43.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 7.834094047546387
2025-12-09 11:47:44.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 7.788382053375244
2025-12-09 11:47:44.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 8.027979850769043
2025-12-09 11:47:44.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 7.85819149017334
2025-12-09 11:47:45.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 8.636942863464355
2025-12-09 11:47:45.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 8.137662887573242
2025-12-09 11:47:46.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 8.04203987121582
2025-12-09 11:47:46.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 7.925161361694336
2025-12-09 11:47:46.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 8.528118133544922
2025-12-09 11:47:47.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.999999029798809e-05 Training loss: 8.08510971069336
2025-12-09 11:47:47.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 9.999996119195611e-05 Training loss: 7.772557735443115
2025-12-09 11:47:48.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 9.999991268191536e-05 Training loss: 8.40029239654541
2025-12-09 11:47:48.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 9.999984476788465e-05 Training loss: 7.798978328704834
2025-12-09 11:47:48.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 9.999975744989037e-05 Training loss: 7.673266887664795
2025-12-09 11:47:49.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 9.999965072796636e-05 Training loss: 8.110108375549316
2025-12-09 11:47:49.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 9.999952460215408e-05 Training loss: 8.358715057373047
2025-12-09 11:47:50.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 9.999937907250246e-05 Training loss: 7.84780740737915
2025-12-09 11:47:50.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 9.999921413906798e-05 Training loss: 8.00473403930664
2025-12-09 11:47:50.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 9.999902980191464e-05 Training loss: 7.821457386016846
2025-12-09 11:47:51.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 9.999882606111399e-05 Training loss: 7.807631492614746
2025-12-09 11:47:51.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 9.999860291674508e-05 Training loss: 8.09992790222168
2025-12-09 11:47:51.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 9.999836036889453e-05 Training loss: 7.9720778465271
2025-12-09 11:47:52.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 9.999809841765644e-05 Training loss: 8.154169082641602
2025-12-09 11:47:52.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 9.999781706313251e-05 Training loss: 7.857701301574707
2025-12-09 11:47:53.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 9.999751630543188e-05 Training loss: 7.739567279815674
2025-12-09 11:47:53.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 9.99971961446713e-05 Training loss: 7.83629846572876
2025-12-09 11:47:53.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 9.999685658097502e-05 Training loss: 8.03139591217041
2025-12-09 11:47:54.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 9.999649761447478e-05 Training loss: 7.811523914337158
2025-12-09 11:47:54.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 9.999611924530994e-05 Training loss: 7.8334126472473145
2025-12-09 11:47:55.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 9.999572147362731e-05 Training loss: 8.113614082336426
2025-12-09 11:47:55.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 9.999530429958124e-05 Training loss: 8.453021049499512
2025-12-09 11:47:55.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 9.999486772333366e-05 Training loss: 7.78454065322876
2025-12-09 11:47:56.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 9.999441174505399e-05 Training loss: 7.672814846038818
2025-12-09 11:47:56.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 9.999393636491918e-05 Training loss: 7.839169502258301
2025-12-09 11:47:56.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 9.99934415831137e-05 Training loss: 8.00721549987793
2025-12-09 11:47:57.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 9.99929273998296e-05 Training loss: 7.81346321105957
2025-12-09 11:47:57.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 9.99923938152664e-05 Training loss: 7.790741920471191
2025-12-09 11:47:58.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 9.999184082963118e-05 Training loss: 8.008183479309082
2025-12-09 11:47:58.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 9.999126844313853e-05 Training loss: 8.185885429382324
2025-12-09 11:47:58.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 9.999067665601061e-05 Training loss: 8.227400779724121
2025-12-09 11:47:59.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 9.999006546847707e-05 Training loss: 7.901724338531494
2025-12-09 11:47:59.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 9.998943488077508e-05 Training loss: 8.421446800231934
2025-12-09 11:48:00.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 9.998878489314938e-05 Training loss: 7.886033058166504
2025-12-09 11:48:00.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 9.99881155058522e-05 Training loss: 7.850650310516357
2025-12-09 11:48:00.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 9.998742671914335e-05 Training loss: 7.740858554840088
2025-12-09 11:48:01.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 9.99867185332901e-05 Training loss: 8.094813346862793
2025-12-09 11:48:01.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 9.998599094856732e-05 Training loss: 8.009747505187988
2025-12-09 11:48:01.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 9.99852439652573e-05 Training loss: 8.028159141540527
2025-12-09 11:48:02.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 9.998447758365002e-05 Training loss: 7.9801740646362305
2025-12-09 11:48:02.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 9.998369180404283e-05 Training loss: 7.898463726043701
2025-12-09 11:48:03.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 9.99828866267407e-05 Training loss: 7.922643184661865
2025-12-09 11:48:03.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 9.998206205205611e-05 Training loss: 8.147125244140625
2025-12-09 11:48:03.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 9.998121808030906e-05 Training loss: 8.163900375366211
2025-12-09 11:48:04.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 9.998035471182708e-05 Training loss: 7.428576469421387
2025-12-09 11:48:04.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 9.997947194694519e-05 Training loss: 7.723243713378906
2025-12-09 11:48:05.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 9.997856978600604e-05 Training loss: 7.922468185424805
2025-12-09 11:48:05.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 9.997764822935967e-05 Training loss: 8.341830253601074
2025-12-09 11:48:05.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 9.997670727736378e-05 Training loss: 7.5742387771606445
2025-12-09 11:48:06.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 9.99757469303835e-05 Training loss: 7.456731796264648
2025-12-09 11:48:06.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 9.997476718879153e-05 Training loss: 7.90753698348999
2025-12-09 11:48:07.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 9.99737680529681e-05 Training loss: 7.594541549682617
2025-12-09 11:48:07.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 9.997274952330094e-05 Training loss: 7.418360233306885
2025-12-09 11:48:07.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 9.997171160018531e-05 Training loss: 7.8998284339904785
2025-12-09 11:48:08.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 9.997065428402403e-05 Training loss: 7.448208332061768
2025-12-09 11:48:08.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 9.996957757522742e-05 Training loss: 7.978304386138916
2025-12-09 11:48:08.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 9.996848147421334e-05 Training loss: 8.025504112243652
2025-12-09 11:48:09.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 9.996736598140714e-05 Training loss: 7.877490520477295
2025-12-09 11:48:09.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 9.996623109724174e-05 Training loss: 7.579190254211426
2025-12-09 11:48:10.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 9.996507682215754e-05 Training loss: 7.638476848602295
2025-12-09 11:48:10.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 9.996390315660253e-05 Training loss: 7.909550189971924
2025-12-09 11:48:10.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 9.996271010103216e-05 Training loss: 7.994347095489502
2025-12-09 11:48:11.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 9.996149765590946e-05 Training loss: 7.711395263671875
2025-12-09 11:48:11.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 9.99602658217049e-05 Training loss: 7.531627178192139
2025-12-09 11:48:12.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 9.995901459889658e-05 Training loss: 7.756680011749268
2025-12-09 11:48:12.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 9.995774398797007e-05 Training loss: 7.904731750488281
2025-12-09 11:48:12.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 9.995645398941846e-05 Training loss: 7.638429164886475
2025-12-09 11:48:13.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 9.995514460374238e-05 Training loss: 7.522543430328369
2025-12-09 11:48:13.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 9.995381583144996e-05 Training loss: 8.254206657409668
2025-12-09 11:48:13.982 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 9.995246767305688e-05 Training loss: 7.609104633331299
2025-12-09 11:48:14.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 9.995110012908634e-05 Training loss: 7.655765533447266
2025-12-09 11:48:14.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 9.994971320006905e-05 Training loss: 7.9198079109191895
2025-12-09 11:48:15.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 9.994830688654326e-05 Training loss: 7.372212886810303
2025-12-09 11:48:15.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 9.994688118905472e-05 Training loss: 7.547969818115234
2025-12-09 11:48:15.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 9.994543610815671e-05 Training loss: 7.6139349937438965
2025-12-09 11:48:16.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 9.994397164441007e-05 Training loss: 7.527105808258057
2025-12-09 11:48:16.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 9.994248779838311e-05 Training loss: 7.312665939331055
2025-12-09 11:48:17.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 9.994098457065166e-05 Training loss: 7.398762226104736
2025-12-09 11:48:17.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 9.993946196179913e-05 Training loss: 7.725341320037842
2025-12-09 11:48:17.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 9.993791997241639e-05 Training loss: 7.731175899505615
2025-12-09 11:48:18.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 9.993635860310187e-05 Training loss: 7.705629348754883
2025-12-09 11:48:18.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 9.99347778544615e-05 Training loss: 7.41988468170166
2025-12-09 11:48:19.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 9.993317772710874e-05 Training loss: 7.58156156539917
2025-12-09 11:48:19.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 9.993155822166457e-05 Training loss: 8.819605827331543
2025-12-09 11:48:19.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 9.992991933875748e-05 Training loss: 7.416795253753662
2025-12-09 11:48:20.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 9.99282610790235e-05 Training loss: 7.567806243896484
2025-12-09 11:48:20.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 9.992658344310614e-05 Training loss: 7.696567058563232
2025-12-09 11:48:20.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 9.992488643165651e-05 Training loss: 7.639448642730713
2025-12-09 11:48:21.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 9.992317004533313e-05 Training loss: 7.434476375579834
2025-12-09 11:48:21.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 9.992143428480214e-05 Training loss: 7.397044658660889
2025-12-09 11:48:22.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 9.991967915073714e-05 Training loss: 7.3311309814453125
2025-12-09 11:48:22.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 9.991790464381926e-05 Training loss: 7.2498579025268555
2025-12-09 11:48:22.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 9.991611076473714e-05 Training loss: 7.438169479370117
2025-12-09 11:48:23.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 9.991429751418697e-05 Training loss: 7.436784267425537
2025-12-09 11:48:23.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 9.991246489287245e-05 Training loss: 7.2839813232421875
2025-12-09 11:48:24.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 9.991061290150475e-05 Training loss: 8.275676727294922
2025-12-09 11:48:24.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 9.990874154080259e-05 Training loss: 8.676860809326172
2025-12-09 11:48:24.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 9.990685081149222e-05 Training loss: 7.48333740234375
2025-12-09 11:48:25.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 9.990494071430742e-05 Training loss: 7.744640827178955
2025-12-09 11:48:25.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 9.990301124998945e-05 Training loss: 7.497315883636475
2025-12-09 11:48:25.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 9.990106241928706e-05 Training loss: 7.6768364906311035
2025-12-09 11:48:26.376 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 9.989909422295659e-05 Training loss: 7.527669906616211
2025-12-09 11:48:26.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 9.989710666176186e-05 Training loss: 7.640161037445068
2025-12-09 11:48:27.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 9.989509973647417e-05 Training loss: 7.434682369232178
2025-12-09 11:48:27.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 9.989307344787242e-05 Training loss: 8.302355766296387
2025-12-09 11:48:27.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 9.989102779674293e-05 Training loss: 7.614448547363281
2025-12-09 11:48:28.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 9.98889627838796e-05 Training loss: 7.161438941955566
2025-12-09 11:48:28.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 9.98868784100838e-05 Training loss: 7.43381929397583
2025-12-09 11:48:29.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 9.988477467616447e-05 Training loss: 8.221230506896973
2025-12-09 11:48:29.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 9.988265158293799e-05 Training loss: 7.626047134399414
2025-12-09 11:48:29.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 9.98805091312283e-05 Training loss: 7.715358734130859
2025-12-09 11:48:30.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 9.987834732186687e-05 Training loss: 7.847178936004639
2025-12-09 11:48:30.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 9.987616615569263e-05 Training loss: 7.457144737243652
2025-12-09 11:48:31.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 9.987396563355205e-05 Training loss: 7.559576988220215
2025-12-09 11:48:31.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 9.987174575629911e-05 Training loss: 7.543483734130859
2025-12-09 11:48:31.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 9.986950652479532e-05 Training loss: 7.1467108726501465
2025-12-09 11:48:32.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 9.986724793990966e-05 Training loss: 8.083647727966309
2025-12-09 11:48:32.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 9.986497000251866e-05 Training loss: 8.035528182983398
2025-12-09 11:48:32.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 9.986267271350633e-05 Training loss: 7.622312545776367
2025-12-09 11:48:33.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 9.98603560737642e-05 Training loss: 7.248511791229248
2025-12-09 11:48:33.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 9.985802008419131e-05 Training loss: 7.402602672576904
2025-12-09 11:48:34.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 9.985566474569424e-05 Training loss: 7.221917629241943
2025-12-09 11:48:34.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 9.985329005918702e-05 Training loss: 7.166650772094727
2025-12-09 11:48:34.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 9.985089602559125e-05 Training loss: 7.768223762512207
2025-12-09 11:48:35.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 9.984848264583597e-05 Training loss: 7.374870300292969
2025-12-09 11:48:35.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 9.98460499208578e-05 Training loss: 7.250491142272949
2025-12-09 11:48:36.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 9.98435978516008e-05 Training loss: 7.34370231628418
2025-12-09 11:48:36.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 9.98411264390166e-05 Training loss: 7.145953178405762
2025-12-09 11:48:36.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 9.983863568406428e-05 Training loss: 7.33269739151001
2025-12-09 11:48:37.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 9.983612558771049e-05 Training loss: 7.694819927215576
2025-12-09 11:48:37.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 9.983359615092931e-05 Training loss: 7.677737236022949
2025-12-09 11:48:37.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 9.983104737470239e-05 Training loss: 8.05290412902832
2025-12-09 11:48:38.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 9.982847926001886e-05 Training loss: 7.4027557373046875
2025-12-09 11:48:38.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 9.982589180787534e-05 Training loss: 7.453749179840088
2025-12-09 11:48:39.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 9.982328501927599e-05 Training loss: 7.220217704772949
2025-12-09 11:48:39.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 9.982065889523242e-05 Training loss: 7.592085838317871
2025-12-09 11:48:39.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 9.98180134367638e-05 Training loss: 7.485268592834473
2025-12-09 11:48:40.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 9.981534864489679e-05 Training loss: 7.414720058441162
2025-12-09 11:48:40.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 9.981266452066553e-05 Training loss: 7.267216682434082
2025-12-09 11:48:41.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 9.98099610651117e-05 Training loss: 7.376457691192627
2025-12-09 11:48:41.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 9.980723827928441e-05 Training loss: 7.125808238983154
2025-12-09 11:48:41.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 9.980449616424037e-05 Training loss: 7.077689170837402
2025-12-09 11:48:42.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 9.98017347210437e-05 Training loss: 7.9965691566467285
2025-12-09 11:48:42.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 9.979895395076609e-05 Training loss: 8.030732154846191
2025-12-09 11:48:43.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 9.979615385448669e-05 Training loss: 7.653727054595947
2025-12-09 11:48:43.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 9.979333443329217e-05 Training loss: 7.254208087921143
2025-12-09 11:48:43.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 9.97904956882767e-05 Training loss: 7.755012035369873
2025-12-09 11:48:44.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 9.978763762054194e-05 Training loss: 7.3413472175598145
2025-12-09 11:48:44.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 9.978476023119701e-05 Training loss: 7.24556827545166
2025-12-09 11:48:44.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 9.978186352135861e-05 Training loss: 7.915196895599365
2025-12-09 11:48:45.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 9.977894749215089e-05 Training loss: 7.548702239990234
2025-12-09 11:48:45.748 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 9.97760121447055e-05 Training loss: 7.573354721069336
2025-12-09 11:48:46.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 9.977305748016159e-05 Training loss: 7.190713405609131
2025-12-09 11:48:46.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 9.977008349966582e-05 Training loss: 7.067152500152588
2025-12-09 11:48:46.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 9.976709020437229e-05 Training loss: 7.215725898742676
2025-12-09 11:48:47.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 9.97640775954427e-05 Training loss: 7.430906295776367
2025-12-09 11:48:47.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 9.976104567404617e-05 Training loss: 7.325526714324951
2025-12-09 11:48:48.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 9.97579944413593e-05 Training loss: 7.468432903289795
2025-12-09 11:48:48.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 9.975492389856622e-05 Training loss: 7.1791672706604
2025-12-09 11:48:48.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 9.975183404685856e-05 Training loss: 7.394776821136475
2025-12-09 11:48:49.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 9.974872488743543e-05 Training loss: 7.532541751861572
2025-12-09 11:48:49.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 9.974559642150345e-05 Training loss: 7.562143325805664
2025-12-09 11:48:50.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 9.974244865027669e-05 Training loss: 7.146413803100586
2025-12-09 11:48:50.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 9.973928157497674e-05 Training loss: 7.274050235748291
2025-12-09 11:48:50.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 9.973609519683268e-05 Training loss: 7.147783279418945
2025-12-09 11:48:51.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 9.973288951708111e-05 Training loss: 7.315310001373291
2025-12-09 11:48:51.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 9.972966453696608e-05 Training loss: 7.324540138244629
2025-12-09 11:48:51.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 9.972642025773912e-05 Training loss: 7.000606060028076
2025-12-09 11:48:52.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 9.972315668065929e-05 Training loss: 6.98887825012207
2025-12-09 11:48:52.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 9.97198738069931e-05 Training loss: 7.278721809387207
2025-12-09 11:48:53.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 9.971657163801458e-05 Training loss: 7.338680267333984
2025-12-09 11:48:53.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 9.971325017500526e-05 Training loss: 6.79439115524292
2025-12-09 11:48:53.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 9.970990941925411e-05 Training loss: 7.395223617553711
2025-12-09 11:48:54.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 9.970654937205762e-05 Training loss: 7.412186145782471
2025-12-09 11:48:54.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 9.970317003471976e-05 Training loss: 7.47524356842041
2025-12-09 11:48:55.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 9.969977140855198e-05 Training loss: 6.990269660949707
2025-12-09 11:48:55.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 9.969635349487321e-05 Training loss: 7.417163372039795
2025-12-09 11:48:55.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 9.969291629500991e-05 Training loss: 7.028880596160889
2025-12-09 11:48:56.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 9.968945981029596e-05 Training loss: 6.950544834136963
2025-12-09 11:48:56.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 9.968598404207275e-05 Training loss: 7.2215986251831055
2025-12-09 11:48:56.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 9.96824889916892e-05 Training loss: 6.949516773223877
2025-12-09 11:48:57.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 9.96789746605016e-05 Training loss: 7.122054100036621
2025-12-09 11:48:57.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 9.967544104987387e-05 Training loss: 7.130945205688477
2025-12-09 11:48:58.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 9.967188816117727e-05 Training loss: 7.165381908416748
2025-12-09 11:48:58.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 9.966831599579066e-05 Training loss: 7.171438217163086
2025-12-09 11:48:58.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 9.96647245551003e-05 Training loss: 6.993332386016846
2025-12-09 11:48:59.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 9.966111384049997e-05 Training loss: 7.026773452758789
2025-12-09 11:48:59.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 9.965748385339089e-05 Training loss: 6.915960311889648
2025-12-09 11:49:00.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 9.96538345951818e-05 Training loss: 7.4057183265686035
2025-12-09 11:49:00.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 9.965016606728894e-05 Training loss: 6.6158037185668945
2025-12-09 11:49:00.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 9.964647827113595e-05 Training loss: 7.042331218719482
2025-12-09 11:49:01.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 9.964277120815401e-05 Training loss: 7.067566394805908
2025-12-09 11:49:01.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 9.963904487978177e-05 Training loss: 7.420267105102539
2025-12-09 11:49:02.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 9.963529928746534e-05 Training loss: 7.239110469818115
2025-12-09 11:49:02.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 9.963153443265828e-05 Training loss: 7.016342639923096
2025-12-09 11:49:02.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 9.96277503168217e-05 Training loss: 7.30832052230835
2025-12-09 11:49:03.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 9.96239469414241e-05 Training loss: 7.486076831817627
2025-12-09 11:49:03.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 9.962012430794153e-05 Training loss: 6.996462821960449
2025-12-09 11:49:03.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 9.961628241785747e-05 Training loss: 7.275088787078857
2025-12-09 11:49:04.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 9.961242127266288e-05 Training loss: 7.036124229431152
2025-12-09 11:49:04.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 9.960854087385619e-05 Training loss: 7.138568878173828
2025-12-09 11:49:05.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 9.96046412229433e-05 Training loss: 7.27836275100708
2025-12-09 11:49:05.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 9.960072232143762e-05 Training loss: 7.222910404205322
2025-12-09 11:49:05.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 9.959678417085997e-05 Training loss: 7.376580238342285
2025-12-09 11:49:06.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 9.95928267727387e-05 Training loss: 7.027856826782227
2025-12-09 11:49:06.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 9.958885012860954e-05 Training loss: 6.891918659210205
2025-12-09 11:49:07.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 9.958485424001583e-05 Training loss: 7.220438003540039
2025-12-09 11:49:07.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 9.958083910850821e-05 Training loss: 7.412985324859619
2025-12-09 11:49:07.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 9.957680473564495e-05 Training loss: 6.984160900115967
2025-12-09 11:49:08.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 9.957275112299165e-05 Training loss: 6.969766139984131
2025-12-09 11:49:08.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 9.956867827212148e-05 Training loss: 7.236194133758545
2025-12-09 11:49:09.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 9.956458618461502e-05 Training loss: 7.263391971588135
2025-12-09 11:49:09.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 9.956047486206032e-05 Training loss: 6.808859825134277
2025-12-09 11:49:09.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 9.955634430605291e-05 Training loss: 7.241218090057373
2025-12-09 11:49:10.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 9.955219451819579e-05 Training loss: 7.194659233093262
2025-12-09 11:49:10.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 9.954802550009942e-05 Training loss: 7.172647476196289
2025-12-09 11:49:10.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 9.954383725338167e-05 Training loss: 6.904300212860107
2025-12-09 11:49:11.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 9.953962977966795e-05 Training loss: 7.35193395614624
2025-12-09 11:49:11.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 9.953540308059111e-05 Training loss: 7.136175632476807
2025-12-09 11:49:12.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 9.953115715779141e-05 Training loss: 6.810515880584717
2025-12-09 11:49:12.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 9.952689201291664e-05 Training loss: 7.4253950119018555
2025-12-09 11:49:12.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 9.9522607647622e-05 Training loss: 7.113484859466553
2025-12-09 11:49:13.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 9.951830406357019e-05 Training loss: 6.839158058166504
2025-12-09 11:49:13.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 9.951398126243134e-05 Training loss: 6.8677825927734375
2025-12-09 11:49:14.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 9.950963924588303e-05 Training loss: 7.254299163818359
2025-12-09 11:49:14.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 9.950527801561033e-05 Training loss: 7.482301712036133
2025-12-09 11:49:14.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 9.950089757330574e-05 Training loss: 7.237466812133789
2025-12-09 11:49:15.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 9.949649792066922e-05 Training loss: 7.319311618804932
2025-12-09 11:49:15.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 9.94920790594082e-05 Training loss: 7.123021125793457
2025-12-09 11:49:15.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 9.948764099123755e-05 Training loss: 6.791804790496826
2025-12-09 11:49:16.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 9.94831837178796e-05 Training loss: 7.2132158279418945
2025-12-09 11:49:16.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 9.947870724106412e-05 Training loss: 6.904420375823975
2025-12-09 11:49:17.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 9.947421156252836e-05 Training loss: 6.888669013977051
2025-12-09 11:49:17.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 9.946969668401697e-05 Training loss: 7.128454208374023
2025-12-09 11:49:17.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 9.946516260728214e-05 Training loss: 6.722099781036377
2025-12-09 11:49:18.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 9.946060933408341e-05 Training loss: 7.524021148681641
2025-12-09 11:49:18.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 9.945603686618785e-05 Training loss: 7.416651725769043
2025-12-09 11:49:19.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 9.945144520536992e-05 Training loss: 7.200228691101074
2025-12-09 11:49:19.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 9.944683435341155e-05 Training loss: 7.398989200592041
2025-12-09 11:49:19.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 9.944220431210216e-05 Training loss: 7.004769325256348
2025-12-09 11:49:20.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 9.943755508323855e-05 Training loss: 7.647043228149414
2025-12-09 11:49:20.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 9.943288666862498e-05 Training loss: 6.783438682556152
2025-12-09 11:49:21.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 9.942819907007321e-05 Training loss: 6.895878314971924
2025-12-09 11:49:21.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 9.942349228940237e-05 Training loss: 7.13479471206665
2025-12-09 11:49:21.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 9.941876632843909e-05 Training loss: 7.133122444152832
2025-12-09 11:49:22.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 9.941402118901744e-05 Training loss: 7.188307762145996
2025-12-09 11:49:22.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 9.940925687297886e-05 Training loss: 7.728641033172607
2025-12-09 11:49:22.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 9.940447338217234e-05 Training loss: 6.750404357910156
2025-12-09 11:49:23.363 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 9.939967071845423e-05 Training loss: 7.283710956573486
2025-12-09 11:49:23.748 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 9.939484888368838e-05 Training loss: 7.092391014099121
2025-12-09 11:49:24.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 9.939000787974602e-05 Training loss: 6.59874153137207
2025-12-09 11:49:24.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 9.938514770850587e-05 Training loss: 6.900854110717773
2025-12-09 11:49:24.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 9.938026837185404e-05 Training loss: 7.216620922088623
2025-12-09 11:49:25.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 9.937536987168413e-05 Training loss: 8.951762199401855
2025-12-09 11:49:25.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 9.937045220989715e-05 Training loss: 6.992628574371338
2025-12-09 11:49:26.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 9.936551538840155e-05 Training loss: 7.195681571960449
2025-12-09 11:49:26.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 9.93605594091132e-05 Training loss: 8.083684921264648
2025-12-09 11:49:26.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 9.935558427395542e-05 Training loss: 6.768604278564453
2025-12-09 11:49:27.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 9.935058998485897e-05 Training loss: 6.998510360717773
2025-12-09 11:49:27.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 9.934557654376205e-05 Training loss: 7.720041751861572
2025-12-09 11:49:28.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 9.934054395261026e-05 Training loss: 7.123677730560303
2025-12-09 11:49:28.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 9.933549221335664e-05 Training loss: 7.08010196685791
2025-12-09 11:49:28.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 9.933042132796171e-05 Training loss: 7.247946739196777
2025-12-09 11:49:29.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 9.932533129839334e-05 Training loss: 6.9896368980407715
2025-12-09 11:49:29.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 9.932022212662691e-05 Training loss: 6.6833648681640625
2025-12-09 11:49:29.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 9.931509381464515e-05 Training loss: 6.903198719024658
2025-12-09 11:49:30.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 9.930994636443829e-05 Training loss: 6.911981105804443
2025-12-09 11:49:30.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 9.930477977800392e-05 Training loss: 7.544430732727051
2025-12-09 11:49:31.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 9.929959405734712e-05 Training loss: 7.058236598968506
2025-12-09 11:49:31.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 9.929438920448037e-05 Training loss: 7.559010028839111
2025-12-09 11:49:31.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 9.928916522142357e-05 Training loss: 7.448326110839844
2025-12-09 11:49:32.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 9.928392211020401e-05 Training loss: 7.11624002456665
2025-12-09 11:49:32.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.927865987285649e-05 Training loss: 6.817259788513184
2025-12-09 11:49:33.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 9.927337851142314e-05 Training loss: 6.706788063049316
2025-12-09 11:49:33.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 9.926807802795359e-05 Training loss: 7.270288944244385
2025-12-09 11:49:33.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 9.926275842450483e-05 Training loss: 6.917986869812012
2025-12-09 11:49:34.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 9.925741970314129e-05 Training loss: 7.114480972290039
2025-12-09 11:49:34.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 9.925206186593484e-05 Training loss: 7.157128810882568
2025-12-09 11:49:35.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 9.924668491496474e-05 Training loss: 7.290952682495117
2025-12-09 11:49:35.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 9.92412888523177e-05 Training loss: 6.966279983520508
2025-12-09 11:49:35.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 9.923587368008778e-05 Training loss: 6.8722991943359375
2025-12-09 11:49:36.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 9.923043940037657e-05 Training loss: 6.847870349884033
2025-12-09 11:49:36.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 9.922498601529296e-05 Training loss: 7.559738636016846
2025-12-09 11:49:36.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 9.92195135269533e-05 Training loss: 7.03010368347168
2025-12-09 11:49:37.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 9.921402193748139e-05 Training loss: 7.360805511474609
2025-12-09 11:49:37.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 9.920851124900837e-05 Training loss: 6.97221040725708
2025-12-09 11:49:38.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 9.920298146367286e-05 Training loss: 7.1341166496276855
2025-12-09 11:49:38.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 9.919743258362085e-05 Training loss: 7.413518905639648
2025-12-09 11:49:38.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 9.919186461100576e-05 Training loss: 7.363177299499512
2025-12-09 11:49:39.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 9.91862775479884e-05 Training loss: 7.320401668548584
2025-12-09 11:49:39.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 9.9180671396737e-05 Training loss: 6.877528190612793
2025-12-09 11:49:40.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 9.91750461594272e-05 Training loss: 6.596088886260986
2025-12-09 11:49:40.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 9.916940183824206e-05 Training loss: 7.335231304168701
2025-12-09 11:49:40.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 9.916373843537201e-05 Training loss: 7.011961460113525
2025-12-09 11:49:41.207 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 9.915805595301491e-05 Training loss: 6.793820381164551
2025-12-09 11:49:41.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 9.915235439337603e-05 Training loss: 6.965399742126465
2025-12-09 11:49:41.982 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 9.914663375866804e-05 Training loss: 7.1608052253723145
2025-12-09 11:49:42.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 9.914089405111098e-05 Training loss: 7.205203533172607
2025-12-09 11:49:42.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 9.913513527293235e-05 Training loss: 7.483813285827637
2025-12-09 11:49:43.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 9.912935742636698e-05 Training loss: 7.048422336578369
2025-12-09 11:49:43.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 9.912356051365718e-05 Training loss: 7.017841339111328
2025-12-09 11:49:43.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 9.911774453705258e-05 Training loss: 6.965842247009277
2025-12-09 11:49:44.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 9.91119094988103e-05 Training loss: 7.142075061798096
2025-12-09 11:49:44.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 9.910605540119475e-05 Training loss: 7.5451459884643555
2025-12-09 11:49:45.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 9.91001822464778e-05 Training loss: 6.9043498039245605
2025-12-09 11:49:45.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 9.909429003693876e-05 Training loss: 6.639228820800781
2025-12-09 11:49:45.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 9.908837877486423e-05 Training loss: 6.866599082946777
2025-12-09 11:49:46.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 9.908244846254826e-05 Training loss: 7.022936820983887
2025-12-09 11:49:46.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 9.907649910229229e-05 Training loss: 6.858850479125977
2025-12-09 11:49:47.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 9.907053069640517e-05 Training loss: 6.916691303253174
2025-12-09 11:49:47.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 9.90645432472031e-05 Training loss: 7.217833042144775
2025-12-09 11:49:47.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 9.905853675700969e-05 Training loss: 6.9660725593566895
2025-12-09 11:49:48.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 9.905251122815596e-05 Training loss: 7.267037391662598
2025-12-09 11:49:48.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 9.90464666629803e-05 Training loss: 6.958216667175293
2025-12-09 11:49:48.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 9.904040306382846e-05 Training loss: 7.296041965484619
2025-12-09 11:49:49.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 9.903432043305365e-05 Training loss: 7.03193998336792
2025-12-09 11:49:49.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 9.902821877301637e-05 Training loss: 6.818295955657959
2025-12-09 11:49:50.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 9.90220980860846e-05 Training loss: 7.238439083099365
2025-12-09 11:49:50.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 9.901595837463363e-05 Training loss: 7.068245887756348
2025-12-09 11:49:50.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 9.900979964104617e-05 Training loss: 6.842331409454346
2025-12-09 11:49:51.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 9.900362188771231e-05 Training loss: 7.43743896484375
2025-12-09 11:49:51.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 9.899742511702951e-05 Training loss: 7.243923187255859
2025-12-09 11:49:52.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 9.89912093314026e-05 Training loss: 7.2780985832214355
2025-12-09 11:49:52.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 9.898497453324384e-05 Training loss: 6.957734107971191
2025-12-09 11:49:52.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 9.897872072497281e-05 Training loss: 6.964870452880859
2025-12-09 11:49:53.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 9.897244790901649e-05 Training loss: 7.59340238571167
2025-12-09 11:49:53.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 9.896615608780925e-05 Training loss: 6.9806976318359375
2025-12-09 11:49:54.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 9.895984526379281e-05 Training loss: 7.290073871612549
2025-12-09 11:49:54.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 9.895351543941629e-05 Training loss: 7.168740749359131
2025-12-09 11:49:54.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 9.894716661713617e-05 Training loss: 7.410833835601807
2025-12-09 11:49:55.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 9.894079879941627e-05 Training loss: 7.270066738128662
2025-12-09 11:49:55.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 9.893441198872787e-05 Training loss: 7.008913993835449
2025-12-09 11:49:55.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 9.892800618754954e-05 Training loss: 6.6544928550720215
2025-12-09 11:49:56.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 9.892158139836725e-05 Training loss: 6.891770362854004
2025-12-09 11:49:56.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 9.891513762367431e-05 Training loss: 7.0645036697387695
2025-12-09 11:49:57.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 9.890867486597146e-05 Training loss: 6.773699760437012
2025-12-09 11:49:57.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 9.890219312776676e-05 Training loss: 6.650774002075195
2025-12-09 11:49:57.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 9.889569241157563e-05 Training loss: 6.947473049163818
2025-12-09 11:49:58.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 9.888917271992091e-05 Training loss: 6.8173346519470215
2025-12-09 11:49:58.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 9.888263405533271e-05 Training loss: 6.951380252838135
2025-12-09 11:49:59.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 9.88760764203486e-05 Training loss: 6.903751373291016
2025-12-09 11:49:59.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 9.886949981751346e-05 Training loss: 6.989677906036377
2025-12-09 11:49:59.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 9.886290424937952e-05 Training loss: 7.047475337982178
2025-12-09 11:50:00.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 9.885628971850642e-05 Training loss: 7.344315528869629
2025-12-09 11:50:00.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 9.884965622746111e-05 Training loss: 6.912552833557129
2025-12-09 11:50:00.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 9.884300377881795e-05 Training loss: 7.069790363311768
2025-12-09 11:50:01.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 9.883633237515858e-05 Training loss: 6.594280242919922
2025-12-09 11:50:01.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 9.882964201907207e-05 Training loss: 7.141423225402832
2025-12-09 11:50:02.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 9.882293271315481e-05 Training loss: 6.95171594619751
2025-12-09 11:50:02.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 9.881620446001056e-05 Training loss: 6.7073774337768555
2025-12-09 11:50:02.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 9.88094572622504e-05 Training loss: 6.972420692443848
2025-12-09 11:50:03.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 9.88026911224928e-05 Training loss: 6.703334331512451
2025-12-09 11:50:03.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 9.879590604336359e-05 Training loss: 7.602982521057129
2025-12-09 11:50:04.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 9.87891020274959e-05 Training loss: 6.853431224822998
2025-12-09 11:50:04.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 9.878227907753021e-05 Training loss: 7.530290126800537
2025-12-09 11:50:04.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 9.877543719611444e-05 Training loss: 7.657013893127441
2025-12-09 11:50:05.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 9.876857638590373e-05 Training loss: 6.9029316902160645
2025-12-09 11:50:05.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 9.876169664956067e-05 Training loss: 6.999636650085449
2025-12-09 11:50:06.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 9.875479798975512e-05 Training loss: 6.503961563110352
2025-12-09 11:50:06.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 9.874788040916432e-05 Training loss: 7.23370885848999
2025-12-09 11:50:06.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 9.874094391047289e-05 Training loss: 6.834693431854248
2025-12-09 11:50:07.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 9.873398849637268e-05 Training loss: 7.012709140777588
2025-12-09 11:50:07.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 9.872701416956299e-05 Training loss: 6.815609455108643
2025-12-09 11:50:07.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 9.872002093275042e-05 Training loss: 7.250544548034668
2025-12-09 11:50:08.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 9.871300878864891e-05 Training loss: 7.012099742889404
2025-12-09 11:50:08.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 9.870597773997972e-05 Training loss: 6.85342264175415
2025-12-09 11:50:09.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 9.869892778947148e-05 Training loss: 6.695843696594238
2025-12-09 11:50:09.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 9.869185893986012e-05 Training loss: 7.000168800354004
2025-12-09 11:50:09.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 9.868477119388896e-05 Training loss: 7.115825176239014
2025-12-09 11:50:10.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 9.867766455430857e-05 Training loss: 6.559372901916504
2025-12-09 11:50:10.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 9.867053902387693e-05 Training loss: 6.422725677490234
2025-12-09 11:50:11.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 9.86633946053593e-05 Training loss: 7.381414890289307
2025-12-09 11:50:11.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 9.865623130152828e-05 Training loss: 6.428493976593018
2025-12-09 11:50:11.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 9.864904911516384e-05 Training loss: 6.901484489440918
2025-12-09 11:50:12.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 9.864184804905323e-05 Training loss: 6.926694393157959
2025-12-09 11:50:12.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 9.863462810599105e-05 Training loss: 7.690785884857178
2025-12-09 11:50:13.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 9.862738928877922e-05 Training loss: 7.333956241607666
2025-12-09 11:50:13.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 9.862013160022696e-05 Training loss: 6.818979263305664
2025-12-09 11:50:13.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 9.861285504315085e-05 Training loss: 6.5373430252075195
2025-12-09 11:50:14.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 9.860555962037479e-05 Training loss: 7.1257123947143555
2025-12-09 11:50:14.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 9.859824533472998e-05 Training loss: 6.78510856628418
2025-12-09 11:50:14.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 9.859091218905498e-05 Training loss: 6.864948749542236
2025-12-09 11:50:15.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 9.85835601861956e-05 Training loss: 7.237854957580566
2025-12-09 11:50:15.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 9.857618932900503e-05 Training loss: 6.98051643371582
2025-12-09 11:50:16.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 9.856879962034374e-05 Training loss: 7.083234786987305
2025-12-09 11:50:16.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 9.856139106307955e-05 Training loss: 7.141849040985107
2025-12-09 11:50:16.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 9.855396366008758e-05 Training loss: 7.1941399574279785
2025-12-09 11:50:17.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 9.854651741425023e-05 Training loss: 7.011606693267822
2025-12-09 11:50:17.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 9.853905232845728e-05 Training loss: 6.917628765106201
2025-12-09 11:50:18.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 9.853156840560575e-05 Training loss: 6.988471031188965
2025-12-09 11:50:18.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 9.852406564860003e-05 Training loss: 7.088883399963379
2025-12-09 11:50:18.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 9.851654406035179e-05 Training loss: 7.138969421386719
2025-12-09 11:50:19.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 9.850900364378e-05 Training loss: 6.862949371337891
2025-12-09 11:50:19.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 9.850144440181096e-05 Training loss: 6.818655967712402
2025-12-09 11:50:20.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 9.849386633737825e-05 Training loss: 6.813723564147949
2025-12-09 11:50:20.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 9.848626945342278e-05 Training loss: 7.61210823059082
2025-12-09 11:50:20.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 9.847865375289275e-05 Training loss: 6.931758880615234
2025-12-09 11:50:21.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 9.847101923874367e-05 Training loss: 6.965424537658691
2025-12-09 11:50:21.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 9.846336591393833e-05 Training loss: 6.209145545959473
2025-12-09 11:50:21.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 9.845569378144686e-05 Training loss: 7.304688930511475
2025-12-09 11:50:22.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 9.844800284424664e-05 Training loss: 7.044193744659424
2025-12-09 11:50:22.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 9.844029310532239e-05 Training loss: 6.9135966300964355
2025-12-09 11:50:23.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 9.843256456766609e-05 Training loss: 7.650106430053711
2025-12-09 11:50:23.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 9.842481723427705e-05 Training loss: 6.587161064147949
2025-12-09 11:50:23.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 9.841705110816187e-05 Training loss: 7.765134334564209
2025-12-09 11:50:24.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 9.840926619233441e-05 Training loss: 7.1059722900390625
2025-12-09 11:50:24.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 9.840146248981585e-05 Training loss: 6.972935199737549
2025-12-09 11:50:25.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 9.839364000363467e-05 Training loss: 7.158896446228027
2025-12-09 11:50:25.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 9.83857987368266e-05 Training loss: 6.910734176635742
2025-12-09 11:50:25.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 9.837793869243468e-05 Training loss: 7.00017786026001
2025-12-09 11:50:26.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 9.837005987350926e-05 Training loss: 7.106931209564209
2025-12-09 11:50:26.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 9.836216228310798e-05 Training loss: 6.689429759979248
2025-12-09 11:50:26.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 9.835424592429567e-05 Training loss: 6.858794212341309
2025-12-09 11:50:27.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 9.834631080014457e-05 Training loss: 7.0745086669921875
2025-12-09 11:50:27.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 9.833835691373413e-05 Training loss: 6.774682521820068
2025-12-09 11:50:28.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 9.83303842681511e-05 Training loss: 7.2738423347473145
2025-12-09 11:50:28.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 9.83223928664895e-05 Training loss: 7.125803470611572
2025-12-09 11:50:28.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 9.831438271185065e-05 Training loss: 7.303215026855469
2025-12-09 11:50:29.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 9.830635380734313e-05 Training loss: 7.088649749755859
2025-12-09 11:50:29.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 9.82983061560828e-05 Training loss: 7.275162696838379
2025-12-09 11:50:30.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 9.829023976119279e-05 Training loss: 7.131931781768799
2025-12-09 11:50:30.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 9.828215462580353e-05 Training loss: 6.668101787567139
2025-12-09 11:50:30.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 9.827405075305267e-05 Training loss: 6.6733808517456055
2025-12-09 11:50:31.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 9.826592814608518e-05 Training loss: 6.775439739227295
2025-12-09 11:50:31.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 9.825778680805331e-05 Training loss: 6.7551798820495605
2025-12-09 11:50:32.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 9.824962674211653e-05 Training loss: 7.314277648925781
2025-12-09 11:50:32.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 9.824144795144159e-05 Training loss: 6.978423118591309
2025-12-09 11:50:32.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 9.823325043920254e-05 Training loss: 6.975545883178711
2025-12-09 11:50:33.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 9.822503420858069e-05 Training loss: 7.1154561042785645
2025-12-09 11:50:33.597 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 9.821679926276456e-05 Training loss: 7.022782802581787
2025-12-09 11:50:33.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 9.820854560494999e-05 Training loss: 6.947037220001221
2025-12-09 11:50:34.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 9.820027323834006e-05 Training loss: 6.716480255126953
2025-12-09 11:50:34.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 9.819198216614512e-05 Training loss: 6.743873119354248
2025-12-09 11:50:35.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 9.818367239158278e-05 Training loss: 6.926332473754883
2025-12-09 11:50:35.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 9.817534391787789e-05 Training loss: 7.252163410186768
2025-12-09 11:50:35.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 9.816699674826255e-05 Training loss: 6.840665817260742
2025-12-09 11:50:36.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 9.815863088597618e-05 Training loss: 7.723925590515137
2025-12-09 11:50:36.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 9.815024633426538e-05 Training loss: 6.687836647033691
2025-12-09 11:50:37.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 9.814184309638402e-05 Training loss: 6.5613813400268555
2025-12-09 11:50:37.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 9.813342117559323e-05 Training loss: 6.768777847290039
2025-12-09 11:50:37.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 9.812498057516143e-05 Training loss: 7.644130706787109
2025-12-09 11:50:38.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 9.811652129836421e-05 Training loss: 7.134343147277832
2025-12-09 11:50:38.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 9.810804334848449e-05 Training loss: 7.164360523223877
2025-12-09 11:50:39.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 9.809954672881238e-05 Training loss: 6.7673468589782715
2025-12-09 11:50:39.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 9.809103144264525e-05 Training loss: 7.103536128997803
2025-12-09 11:50:39.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 9.808249749328768e-05 Training loss: 7.1449875831604
2025-12-09 11:50:40.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 9.80739448840516e-05 Training loss: 6.494079113006592
2025-12-09 11:50:40.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 9.806537361825606e-05 Training loss: 6.57370138168335
2025-12-09 11:50:40.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 9.805678369922742e-05 Training loss: 6.983403205871582
2025-12-09 11:50:41.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 9.804817513029927e-05 Training loss: 6.9228386878967285
2025-12-09 11:50:41.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 9.803954791481239e-05 Training loss: 6.778756618499756
2025-12-09 11:50:42.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 9.803090205611487e-05 Training loss: 6.856255054473877
2025-12-09 11:50:42.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 9.802223755756198e-05 Training loss: 6.72905158996582
2025-12-09 11:50:42.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 9.801355442251625e-05 Training loss: 6.850779056549072
2025-12-09 11:50:43.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 9.800485265434744e-05 Training loss: 6.868256092071533
2025-12-09 11:50:43.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 9.799613225643253e-05 Training loss: 6.7737202644348145
2025-12-09 11:50:44.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 9.798739323215574e-05 Training loss: 6.774923801422119
2025-12-09 11:50:44.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 9.797863558490849e-05 Training loss: 7.0140180587768555
2025-12-09 11:50:44.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 9.79698593180895e-05 Training loss: 6.976245403289795
2025-12-09 11:50:45.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 9.796106443510462e-05 Training loss: 6.829812049865723
2025-12-09 11:50:45.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 9.795225093936702e-05 Training loss: 6.906742572784424
2025-12-09 11:50:46.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 9.794341883429699e-05 Training loss: 6.930849075317383
2025-12-09 11:50:46.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 9.793456812332215e-05 Training loss: 7.001607418060303
2025-12-09 11:50:46.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 9.792569880987726e-05 Training loss: 6.682878494262695
2025-12-09 11:50:47.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 9.791681089740432e-05 Training loss: 6.848859786987305
2025-12-09 11:50:47.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 9.790790438935256e-05 Training loss: 6.484069347381592
2025-12-09 11:50:47.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 9.789897928917847e-05 Training loss: 6.7772932052612305
2025-12-09 11:50:48.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 9.789003560034561e-05 Training loss: 6.866575241088867
2025-12-09 11:50:48.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 9.788107332632495e-05 Training loss: 6.780346393585205
2025-12-09 11:50:49.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 9.787209247059452e-05 Training loss: 6.858809471130371
2025-12-09 11:50:49.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 9.786309303663963e-05 Training loss: 6.768187999725342
2025-12-09 11:50:49.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 9.785407502795278e-05 Training loss: 6.763391017913818
2025-12-09 11:50:50.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 9.784503844803368e-05 Training loss: 6.827047348022461
2025-12-09 11:50:50.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 9.783598330038925e-05 Training loss: 6.56864070892334
2025-12-09 11:50:51.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 9.782690958853362e-05 Training loss: 7.004622936248779
2025-12-09 11:50:51.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 9.781781731598812e-05 Training loss: 6.896975040435791
2025-12-09 11:50:51.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 9.780870648628128e-05 Training loss: 6.5168633460998535
2025-12-09 11:50:52.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 9.779957710294886e-05 Training loss: 6.931194305419922
2025-12-09 11:50:52.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 9.779042916953376e-05 Training loss: 7.912079811096191
2025-12-09 11:50:53.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 9.778126268958613e-05 Training loss: 6.902949810028076
2025-12-09 11:50:53.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 9.77720776666633e-05 Training loss: 6.834272861480713
2025-12-09 11:50:53.794 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 9.77628741043298e-05 Training loss: 6.90239143371582
2025-12-09 11:50:54.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 9.775365200615735e-05 Training loss: 6.978382587432861
2025-12-09 11:50:54.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 9.774441137572487e-05 Training loss: 6.79665470123291
2025-12-09 11:50:54.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 9.773515221661846e-05 Training loss: 7.056282997131348
2025-12-09 11:50:55.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 9.772587453243143e-05 Training loss: 6.698540687561035
2025-12-09 11:50:55.734 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 9.771657832676427e-05 Training loss: 7.082544803619385
2025-12-09 11:50:56.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 9.770726360322463e-05 Training loss: 7.505589962005615
2025-12-09 11:50:56.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 9.769793036542741e-05 Training loss: 6.792557716369629
2025-12-09 11:50:56.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 9.768857861699463e-05 Training loss: 6.664902687072754
2025-12-09 11:50:57.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 9.767920836155553e-05 Training loss: 6.79031229019165
2025-12-09 11:50:57.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 9.766981960274653e-05 Training loss: 6.4748992919921875
2025-12-09 11:50:58.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 9.766041234421122e-05 Training loss: 6.8009209632873535
2025-12-09 11:50:58.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 9.765098658960036e-05 Training loss: 6.563292980194092
2025-12-09 11:50:58.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 9.764154234257192e-05 Training loss: 6.8018293380737305
2025-12-09 11:50:59.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 9.763207960679101e-05 Training loss: 6.766617774963379
2025-12-09 11:50:59.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 9.762259838592994e-05 Training loss: 6.633728981018066
2025-12-09 11:51:00.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 9.761309868366819e-05 Training loss: 7.0273590087890625
2025-12-09 11:51:00.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 9.760358050369243e-05 Training loss: 6.586808681488037
2025-12-09 11:51:00.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 9.759404384969643e-05 Training loss: 6.4387593269348145
2025-12-09 11:51:01.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 9.758448872538122e-05 Training loss: 6.521852970123291
2025-12-09 11:51:01.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 9.757491513445493e-05 Training loss: 7.733351230621338
2025-12-09 11:51:01.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 9.756532308063293e-05 Training loss: 7.135603904724121
2025-12-09 11:51:02.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 9.755571256763765e-05 Training loss: 6.748829364776611
2025-12-09 11:51:02.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 9.754608359919879e-05 Training loss: 7.082398414611816
2025-12-09 11:51:03.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 9.753643617905313e-05 Training loss: 6.831174373626709
2025-12-09 11:51:03.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 9.752677031094466e-05 Training loss: 6.830504894256592
2025-12-09 11:51:03.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 9.751708599862452e-05 Training loss: 6.883012294769287
2025-12-09 11:51:04.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 9.750738324585098e-05 Training loss: 6.5276570320129395
2025-12-09 11:51:04.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 9.749766205638952e-05 Training loss: 6.715087413787842
2025-12-09 11:51:05.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 9.748792243401273e-05 Training loss: 7.134062767028809
2025-12-09 11:51:05.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 9.747816438250037e-05 Training loss: 6.580774784088135
2025-12-09 11:51:05.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 9.746838790563934e-05 Training loss: 6.9306182861328125
2025-12-09 11:51:06.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 9.74585930072237e-05 Training loss: 6.236834526062012
2025-12-09 11:51:06.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 9.744877969105469e-05 Training loss: 6.927964210510254
2025-12-09 11:51:07.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 9.743894796094062e-05 Training loss: 6.955658912658691
2025-12-09 11:51:07.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 9.742909782069701e-05 Training loss: 7.390912055969238
2025-12-09 11:51:07.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 9.741922927414651e-05 Training loss: 6.817129611968994
2025-12-09 11:51:08.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 9.740934232511894e-05 Training loss: 7.0487518310546875
2025-12-09 11:51:08.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 9.739943697745118e-05 Training loss: 6.792307376861572
2025-12-09 11:51:08.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 9.738951323498732e-05 Training loss: 6.597773551940918
2025-12-09 11:51:09.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 9.737957110157858e-05 Training loss: 7.194668769836426
2025-12-09 11:51:09.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 9.736961058108332e-05 Training loss: 6.721730709075928
2025-12-09 11:51:10.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 9.735963167736698e-05 Training loss: 6.7273125648498535
2025-12-09 11:51:10.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 9.734963439430222e-05 Training loss: 6.827000617980957
2025-12-09 11:51:10.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 9.733961873576878e-05 Training loss: 6.58355188369751
2025-12-09 11:51:11.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 9.732958470565353e-05 Training loss: 6.988039016723633
2025-12-09 11:51:11.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 9.731953230785049e-05 Training loss: 6.86458158493042
2025-12-09 11:51:12.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 9.730946154626079e-05 Training loss: 7.11777400970459
2025-12-09 11:51:12.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 9.729937242479271e-05 Training loss: 6.7841386795043945
2025-12-09 11:51:12.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 9.728926494736164e-05 Training loss: 6.570395469665527
2025-12-09 11:51:13.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 9.727913911789009e-05 Training loss: 6.612871170043945
2025-12-09 11:51:13.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 9.726899494030768e-05 Training loss: 6.600027561187744
2025-12-09 11:51:13.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 9.725883241855119e-05 Training loss: 6.914009094238281
2025-12-09 11:51:14.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 9.724865155656448e-05 Training loss: 6.708413600921631
2025-12-09 11:51:14.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 9.723845235829857e-05 Training loss: 6.590179920196533
2025-12-09 11:51:15.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 9.722823482771155e-05 Training loss: 6.409059524536133
2025-12-09 11:51:15.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 9.721799896876864e-05 Training loss: 6.420908451080322
2025-12-09 11:51:15.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 9.720774478544219e-05 Training loss: 6.9892578125
2025-12-09 11:51:16.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 9.719747228171163e-05 Training loss: 7.300526142120361
2025-12-09 11:51:16.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 9.718718146156355e-05 Training loss: 6.618362903594971
2025-12-09 11:51:17.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 9.717687232899159e-05 Training loss: 6.496706485748291
2025-12-09 11:51:17.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 9.716654488799652e-05 Training loss: 6.8204755783081055
2025-12-09 11:51:17.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 9.715619914258624e-05 Training loss: 6.8043622970581055
2025-12-09 11:51:18.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 9.71458350967757e-05 Training loss: 6.805016040802002
2025-12-09 11:51:18.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 9.713545275458703e-05 Training loss: 6.730920791625977
2025-12-09 11:51:19.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 9.712505212004938e-05 Training loss: 6.537230968475342
2025-12-09 11:51:19.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 9.711463319719904e-05 Training loss: 7.005712985992432
2025-12-09 11:51:19.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 9.710419599007939e-05 Training loss: 6.810000419616699
2025-12-09 11:51:20.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 9.70937405027409e-05 Training loss: 6.942133903503418
2025-12-09 11:51:20.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 9.708326673924115e-05 Training loss: 6.716490745544434
2025-12-09 11:51:20.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 9.707277470364482e-05 Training loss: 6.940902233123779
2025-12-09 11:51:21.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 9.706226440002363e-05 Training loss: 6.607178688049316
2025-12-09 11:51:21.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 9.705173583245645e-05 Training loss: 6.307256698608398
2025-12-09 11:51:22.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 9.704118900502919e-05 Training loss: 6.515537261962891
2025-12-09 11:51:22.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 9.703062392183489e-05 Training loss: 6.657983303070068
2025-12-09 11:51:22.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 9.702004058697363e-05 Training loss: 6.7905683517456055
2025-12-09 11:51:23.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 9.700943900455262e-05 Training loss: 6.807360649108887
2025-12-09 11:51:23.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 9.69988191786861e-05 Training loss: 6.6713547706604
2025-12-09 11:51:24.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 9.698818111349543e-05 Training loss: 7.139111042022705
2025-12-09 11:51:24.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 9.697752481310904e-05 Training loss: 6.529998779296875
2025-12-09 11:51:24.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 9.696685028166244e-05 Training loss: 6.291393756866455
2025-12-09 11:51:25.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 9.69561575232982e-05 Training loss: 7.700027942657471
2025-12-09 11:51:25.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 9.694544654216596e-05 Training loss: 6.585041522979736
2025-12-09 11:51:26.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 9.693471734242243e-05 Training loss: 6.357657432556152
2025-12-09 11:51:26.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 9.692396992823145e-05 Training loss: 6.971815586090088
2025-12-09 11:51:26.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 9.691320430376385e-05 Training loss: 6.779513835906982
2025-12-09 11:51:27.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 9.690242047319755e-05 Training loss: 7.00014591217041
2025-12-09 11:51:27.597 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 9.689161844071757e-05 Training loss: 6.531767845153809
2025-12-09 11:51:27.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 9.688079821051595e-05 Training loss: 7.906946182250977
2025-12-09 11:51:28.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 9.68699597867918e-05 Training loss: 7.001306056976318
2025-12-09 11:51:28.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 9.685910317375134e-05 Training loss: 6.83883810043335
2025-12-09 11:51:29.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 9.684822837560776e-05 Training loss: 6.697249889373779
2025-12-09 11:51:29.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 9.683733539658139e-05 Training loss: 6.743311882019043
2025-12-09 11:51:29.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 9.682642424089958e-05 Training loss: 6.579504013061523
2025-12-09 11:51:30.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 9.681549491279674e-05 Training loss: 6.569587707519531
2025-12-09 11:51:30.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 9.68045474165143e-05 Training loss: 6.7995405197143555
2025-12-09 11:51:31.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 9.679358175630081e-05 Training loss: 6.597778797149658
2025-12-09 11:51:31.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 9.67825979364118e-05 Training loss: 6.746580600738525
2025-12-09 11:51:31.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 9.677159596110987e-05 Training loss: 5.439647197723389
2025-12-09 11:51:32.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 9.676057583466472e-05 Training loss: 6.774657249450684
2025-12-09 11:51:32.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 9.674953756135298e-05 Training loss: 6.686281681060791
2025-12-09 11:51:33.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 9.673848114545843e-05 Training loss: 6.770918846130371
2025-12-09 11:51:33.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 9.672740659127184e-05 Training loss: 6.451181411743164
2025-12-09 11:51:33.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 9.671631390309102e-05 Training loss: 6.942211627960205
2025-12-09 11:51:34.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 9.670520308522084e-05 Training loss: 6.735526084899902
2025-12-09 11:51:34.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 9.66940741419732e-05 Training loss: 6.830439567565918
2025-12-09 11:51:34.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 9.668292707766699e-05 Training loss: 7.0077924728393555
