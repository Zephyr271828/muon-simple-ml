2025-12-09 12:07:14.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 2.9999999999999997e-06 Training loss: 4.675591945648193
2025-12-09 12:07:14.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 5.999999999999999e-06 Training loss: 4.885908126831055
2025-12-09 12:07:14.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 8.999999999999999e-06 Training loss: 4.871219635009766
2025-12-09 12:07:14.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 1.1999999999999999e-05 Training loss: 4.859221935272217
2025-12-09 12:07:14.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 1.4999999999999999e-05 Training loss: 4.885030269622803
2025-12-09 12:07:14.745 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 1.7999999999999997e-05 Training loss: 4.951552391052246
2025-12-09 12:07:14.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 2.1e-05 Training loss: 4.943704128265381
2025-12-09 12:07:14.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 2.3999999999999997e-05 Training loss: 4.799649715423584
2025-12-09 12:07:14.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 2.6999999999999996e-05 Training loss: 4.951313018798828
2025-12-09 12:07:14.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 2.9999999999999997e-05 Training loss: 4.83967924118042
2025-12-09 12:07:14.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 3.2999999999999996e-05 Training loss: 4.796036243438721
2025-12-09 12:07:14.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 3.5999999999999994e-05 Training loss: 4.709758281707764
2025-12-09 12:07:14.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 3.9e-05 Training loss: 4.8590898513793945
2025-12-09 12:07:14.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 4.2e-05 Training loss: 4.81242561340332
2025-12-09 12:07:14.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 4.4999999999999996e-05 Training loss: 4.780944347381592
2025-12-09 12:07:14.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 4.7999999999999994e-05 Training loss: 4.86430549621582
2025-12-09 12:07:14.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 5.1e-05 Training loss: 4.801452159881592
2025-12-09 12:07:14.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 5.399999999999999e-05 Training loss: 4.829966068267822
2025-12-09 12:07:14.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 5.6999999999999996e-05 Training loss: 4.784231185913086
2025-12-09 12:07:14.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 5.9999999999999995e-05 Training loss: 4.927567481994629
2025-12-09 12:07:14.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 6.299999999999999e-05 Training loss: 4.799587249755859
2025-12-09 12:07:14.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 6.599999999999999e-05 Training loss: 4.862672805786133
2025-12-09 12:07:14.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 6.9e-05 Training loss: 4.808459758758545
2025-12-09 12:07:14.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 7.199999999999999e-05 Training loss: 4.700407981872559
2025-12-09 12:07:14.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 7.5e-05 Training loss: 4.737342834472656
2025-12-09 12:07:14.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 7.8e-05 Training loss: 4.76406192779541
2025-12-09 12:07:14.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 8.1e-05 Training loss: 4.642794132232666
2025-12-09 12:07:14.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 8.4e-05 Training loss: 4.62866735458374
2025-12-09 12:07:14.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 8.699999999999999e-05 Training loss: 4.593667507171631
2025-12-09 12:07:14.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 8.999999999999999e-05 Training loss: 4.638008117675781
2025-12-09 12:07:14.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 9.3e-05 Training loss: 4.730047702789307
2025-12-09 12:07:14.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 9.599999999999999e-05 Training loss: 4.675140857696533
2025-12-09 12:07:14.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 9.9e-05 Training loss: 4.692230701446533
2025-12-09 12:07:15.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.000102 Training loss: 4.563708305358887
2025-12-09 12:07:15.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00010499999999999999 Training loss: 4.5642805099487305
2025-12-09 12:07:15.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00010799999999999998 Training loss: 4.5718607902526855
2025-12-09 12:07:15.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00011099999999999999 Training loss: 4.665913105010986
2025-12-09 12:07:15.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00011399999999999999 Training loss: 4.751561641693115
2025-12-09 12:07:15.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.000117 Training loss: 4.510075569152832
2025-12-09 12:07:15.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.00011999999999999999 Training loss: 4.514347076416016
2025-12-09 12:07:15.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00012299999999999998 Training loss: 4.428974628448486
2025-12-09 12:07:15.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00012599999999999997 Training loss: 4.663456439971924
2025-12-09 12:07:15.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.000129 Training loss: 4.4891204833984375
2025-12-09 12:07:15.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00013199999999999998 Training loss: 4.596987247467041
2025-12-09 12:07:15.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.000135 Training loss: 4.501766681671143
2025-12-09 12:07:15.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.000138 Training loss: 4.524409770965576
2025-12-09 12:07:15.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00014099999999999998 Training loss: 4.363064289093018
2025-12-09 12:07:15.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00014399999999999998 Training loss: 4.421557426452637
2025-12-09 12:07:15.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.000147 Training loss: 4.325135707855225
2025-12-09 12:07:15.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.00015 Training loss: 4.521927356719971
2025-12-09 12:07:15.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00015299999999999998 Training loss: 4.510693073272705
2025-12-09 12:07:15.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.000156 Training loss: 4.414879322052002
2025-12-09 12:07:15.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.000159 Training loss: 4.469440460205078
2025-12-09 12:07:15.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.000162 Training loss: 4.390416622161865
2025-12-09 12:07:15.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.000165 Training loss: 4.291649341583252
2025-12-09 12:07:15.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.000168 Training loss: 4.371419906616211
2025-12-09 12:07:15.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00017099999999999998 Training loss: 4.419365406036377
2025-12-09 12:07:15.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00017399999999999997 Training loss: 4.466007709503174
2025-12-09 12:07:15.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00017699999999999997 Training loss: 4.29286003112793
2025-12-09 12:07:15.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.00017999999999999998 Training loss: 4.347824573516846
2025-12-09 12:07:15.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00018299999999999998 Training loss: 4.313650131225586
2025-12-09 12:07:15.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.000186 Training loss: 4.2996320724487305
2025-12-09 12:07:15.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00018899999999999999 Training loss: 4.411309242248535
2025-12-09 12:07:15.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00019199999999999998 Training loss: 4.392375469207764
2025-12-09 12:07:15.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.000195 Training loss: 4.342013835906982
2025-12-09 12:07:15.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.000198 Training loss: 4.136110305786133
2025-12-09 12:07:15.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.000201 Training loss: 4.322570323944092
2025-12-09 12:07:15.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.000204 Training loss: 4.504336357116699
2025-12-09 12:07:15.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00020699999999999996 Training loss: 4.359325885772705
2025-12-09 12:07:15.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.00020999999999999998 Training loss: 4.267481327056885
2025-12-09 12:07:15.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00021299999999999997 Training loss: 4.240442276000977
2025-12-09 12:07:15.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.00021599999999999996 Training loss: 4.269577980041504
2025-12-09 12:07:15.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00021899999999999998 Training loss: 4.3126220703125
2025-12-09 12:07:15.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00022199999999999998 Training loss: 4.264740943908691
2025-12-09 12:07:15.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.000225 Training loss: 4.304041385650635
2025-12-09 12:07:15.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00022799999999999999 Training loss: 4.342585563659668
2025-12-09 12:07:15.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.00023099999999999998 Training loss: 4.225215435028076
2025-12-09 12:07:15.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.000234 Training loss: 4.238094329833984
2025-12-09 12:07:15.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.000237 Training loss: 4.1013641357421875
2025-12-09 12:07:15.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.00023999999999999998 Training loss: 4.137601375579834
2025-12-09 12:07:15.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.000243 Training loss: 4.208112716674805
2025-12-09 12:07:15.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00024599999999999996 Training loss: 4.042497634887695
2025-12-09 12:07:15.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.000249 Training loss: 4.082161903381348
2025-12-09 12:07:15.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00025199999999999995 Training loss: 4.021085739135742
2025-12-09 12:07:15.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00025499999999999996 Training loss: 4.117061614990234
2025-12-09 12:07:15.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.000258 Training loss: 4.101733684539795
2025-12-09 12:07:15.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.000261 Training loss: 4.1793718338012695
2025-12-09 12:07:15.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00026399999999999997 Training loss: 4.069555759429932
2025-12-09 12:07:15.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.000267 Training loss: 4.142802715301514
2025-12-09 12:07:15.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.00027 Training loss: 4.091071605682373
2025-12-09 12:07:15.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00027299999999999997 Training loss: 4.003241062164307
2025-12-09 12:07:15.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.000276 Training loss: 4.205959796905518
2025-12-09 12:07:15.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.000279 Training loss: 4.085240840911865
2025-12-09 12:07:15.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00028199999999999997 Training loss: 3.9423696994781494
2025-12-09 12:07:15.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.000285 Training loss: 3.976818799972534
2025-12-09 12:07:15.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00028799999999999995 Training loss: 3.844233989715576
2025-12-09 12:07:15.574 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.00029099999999999997 Training loss: 4.122962474822998
2025-12-09 12:07:15.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.000294 Training loss: 4.012948513031006
2025-12-09 12:07:15.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00029699999999999996 Training loss: 4.084410190582275
2025-12-09 12:07:15.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0003 Training loss: 4.006274223327637
2025-12-09 12:07:15.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.00029999125880491846 Training loss: 3.9180312156677246
2025-12-09 12:07:15.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.00029996503623845393 Training loss: 4.157601833343506
2025-12-09 12:07:15.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.00029992133535682725 Training loss: 3.7917330265045166
2025-12-09 12:07:15.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.00029986016125334406 Training loss: 4.022398471832275
2025-12-09 12:07:15.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0002997815210578015 Training loss: 3.9028992652893066
2025-12-09 12:07:15.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0002996854239356567 Training loss: 3.6368207931518555
2025-12-09 12:07:15.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0002995718810869589 Training loss: 3.9158775806427
2025-12-09 12:07:15.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.00029944090574504395 Training loss: 3.997800350189209
2025-12-09 12:07:15.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0002992925131749921 Training loss: 3.922684669494629
2025-12-09 12:07:15.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.0002991267206718486 Training loss: 3.997042417526245
2025-12-09 12:07:15.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.00029894354755860845 Training loss: 3.983301877975464
2025-12-09 12:07:15.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.00029874301518396376 Training loss: 3.9115090370178223
2025-12-09 12:07:15.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.000298525146919816 Training loss: 3.784433603286743
2025-12-09 12:07:15.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0002982899681585518 Training loss: 3.9330942630767822
2025-12-09 12:07:15.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.00029803750631008356 Training loss: 4.054771900177002
2025-12-09 12:07:15.745 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.00029776779079865496 Training loss: 3.946742534637451
2025-12-09 12:07:15.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.00029748085305941123 Training loss: 3.8163058757781982
2025-12-09 12:07:15.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.0002971767265347358 Training loss: 3.8733677864074707
2025-12-09 12:07:15.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0002968554466703525 Training loss: 4.033291339874268
2025-12-09 12:07:15.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.0002965170509111942 Training loss: 3.871288299560547
2025-12-09 12:07:15.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.0002961615786970389 Training loss: 3.8288285732269287
2025-12-09 12:07:15.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.00029578907145791274 Training loss: 3.8580048084259033
2025-12-09 12:07:15.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.00029539957260926183 Training loss: 4.093703269958496
2025-12-09 12:07:15.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.0002949931275468917 Training loss: 3.7587690353393555
2025-12-09 12:07:15.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0002945697836416767 Training loss: 3.7400197982788086
2025-12-09 12:07:15.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.000294129590234039 Training loss: 4.073376178741455
2025-12-09 12:07:15.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.00029367259862819804 Training loss: 3.834859609603882
2025-12-09 12:07:15.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.00029319886208619073 Training loss: 3.784738063812256
2025-12-09 12:07:15.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.00029270843582166427 Training loss: 3.941598415374756
2025-12-09 12:07:15.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.00029220137699344055 Training loss: 3.6843490600585938
2025-12-09 12:07:15.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.0002916777446988548 Training loss: 3.738886594772339
2025-12-09 12:07:15.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.00029113759996686743 Training loss: 3.91898250579834
2025-12-09 12:07:15.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0002905810057509515 Training loss: 3.7622387409210205
2025-12-09 12:07:15.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.00029000802692175537 Training loss: 3.910658359527588
2025-12-09 12:07:15.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.0002894187302595419 Training loss: 3.9051711559295654
2025-12-09 12:07:15.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0002888131844464056 Training loss: 3.9172677993774414
2025-12-09 12:07:15.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0002881914600582676 Training loss: 4.010610103607178
2025-12-09 12:07:15.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.0002875536295566501 Training loss: 3.8408126831054688
2025-12-09 12:07:15.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.000286899767280231 Training loss: 3.7234044075012207
2025-12-09 12:07:15.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0002862299494361798 Training loss: 3.644010066986084
2025-12-09 12:07:15.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0002855442540912758 Training loss: 3.721810817718506
2025-12-09 12:07:15.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.00028484276116280926 Training loss: 3.6394424438476562
2025-12-09 12:07:15.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0002841255524092674 Training loss: 3.8273167610168457
2025-12-09 12:07:15.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.00028339271142080534 Training loss: 3.5553746223449707
2025-12-09 12:07:16.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.00028264432360950353 Training loss: 3.6868467330932617
2025-12-09 12:07:16.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.00028188047619941343 Training loss: 3.766221046447754
2025-12-09 12:07:16.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0002811012582163913 Training loss: 3.6361472606658936
2025-12-09 12:07:16.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.00028030676047772265 Training loss: 3.6413087844848633
2025-12-09 12:07:16.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.000279497075581537 Training loss: 3.742798089981079
2025-12-09 12:07:16.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0002786722978960161 Training loss: 3.711651086807251
2025-12-09 12:07:16.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0002778325235483954 Training loss: 3.7389109134674072
2025-12-09 12:07:16.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.00027697785041376006 Training loss: 3.918407917022705
2025-12-09 12:07:16.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0002761083781036381 Training loss: 3.6649069786071777
2025-12-09 12:07:16.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.00027522420795439065 Training loss: 3.6707448959350586
2025-12-09 12:07:16.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.0002743254430154012 Training loss: 3.7214224338531494
2025-12-09 12:07:16.113 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0002734121880370652 Training loss: 3.57132887840271
2025-12-09 12:07:16.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.0002724845494585816 Training loss: 3.7085087299346924
2025-12-09 12:07:16.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0002715426353955476 Training loss: 3.713063955307007
2025-12-09 12:07:16.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.0002705865556273575 Training loss: 3.743959426879883
2025-12-09 12:07:16.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0002696164215844081 Training loss: 3.7432546615600586
2025-12-09 12:07:16.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.00026863234633511183 Training loss: 3.6230833530426025
2025-12-09 12:07:16.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.00026763444457271837 Training loss: 3.714338779449463
2025-12-09 12:07:16.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.0002666228326019474 Training loss: 3.6829123497009277
2025-12-09 12:07:16.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.00026559762832543336 Training loss: 3.607056140899658
2025-12-09 12:07:16.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.000264558951229984 Training loss: 3.5092387199401855
2025-12-09 12:07:16.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.00026350692237265427 Training loss: 3.6232190132141113
2025-12-09 12:07:16.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.0002624416643666371 Training loss: 3.6281826496124268
2025-12-09 12:07:16.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.000261363301366973 Training loss: 3.4754631519317627
2025-12-09 12:07:16.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.00026027195905608006 Training loss: 3.43827223777771
2025-12-09 12:07:16.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.0002591677646291054 Training loss: 3.5617356300354004
2025-12-09 12:07:16.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.00025805084677910095 Training loss: 3.7357285022735596
2025-12-09 12:07:16.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.0002569213356820244 Training loss: 3.3817296028137207
2025-12-09 12:07:16.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0002557793629815669 Training loss: 3.6034584045410156
2025-12-09 12:07:16.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.00025462506177381043 Training loss: 3.505260944366455
2025-12-09 12:07:16.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.00025345856659171563 Training loss: 3.5239908695220947
2025-12-09 12:07:16.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.00025228001338944175 Training loss: 3.4501819610595703
2025-12-09 12:07:16.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0002510895395265016 Training loss: 3.57647442817688
2025-12-09 12:07:16.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.00024988728375175214 Training loss: 3.5000205039978027
2025-12-09 12:07:16.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.00024867338618722357 Training loss: 3.7064850330352783
2025-12-09 12:07:16.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.0002474479883117882 Training loss: 3.4890758991241455
2025-12-09 12:07:16.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.00024621123294467096 Training loss: 3.7049951553344727
2025-12-09 12:07:16.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.0002449632642288045 Training loss: 3.786771297454834
2025-12-09 12:07:16.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.00024370422761402867 Training loss: 3.547865867614746
2025-12-09 12:07:16.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.0002424342698401391 Training loss: 3.3763506412506104
2025-12-09 12:07:16.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.00024115353891978431 Training loss: 3.650451421737671
2025-12-09 12:07:16.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.00023986218412121537 Training loss: 3.5093817710876465
2025-12-09 12:07:16.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.00023856035595088839 Training loss: 3.707420587539673
2025-12-09 12:07:16.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.00023724820613592337 Training loss: 3.623662233352661
2025-12-09 12:07:16.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.00023592588760642044 Training loss: 3.688542366027832
2025-12-09 12:07:16.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.00023459355447763596 Training loss: 3.3492114543914795
2025-12-09 12:07:16.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.00023325136203202049 Training loss: 3.6206002235412598
2025-12-09 12:07:16.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.00023189946670112069 Training loss: 3.5046353340148926
2025-12-09 12:07:16.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.00023053802604734757 Training loss: 3.539571762084961
2025-12-09 12:07:16.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.00022916719874561226 Training loss: 3.1859757900238037
2025-12-09 12:07:16.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.0002277871445648332 Training loss: 3.8380937576293945
2025-12-09 12:07:16.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.00022639802434931444 Training loss: 3.492570161819458
2025-12-09 12:07:16.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.000225 Training loss: 3.5640487670898438
2025-12-09 12:07:16.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.00022359323445560406 Training loss: 3.5004935264587402
2025-12-09 12:07:16.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.00022217789167362073 Training loss: 3.6436283588409424
2025-12-09 12:07:16.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.00022075413661121492 Training loss: 3.6535794734954834
2025-12-09 12:07:16.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.00021932213520599653 Training loss: 3.585606336593628
2025-12-09 12:07:16.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.00021788205435668083 Training loss: 3.8735604286193848
2025-12-09 12:07:16.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.00021643406190363624 Training loss: 3.563248634338379
2025-12-09 12:07:16.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.00021497832660932295 Training loss: 3.446505069732666
2025-12-09 12:07:16.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.00021351501813862356 Training loss: 3.572026252746582
2025-12-09 12:07:16.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0002120443070390687 Training loss: 3.4428024291992188
2025-12-09 12:07:16.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.00021056636472096025 Training loss: 3.5409460067749023
2025-12-09 12:07:16.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.00020908136343739307 Training loss: 3.503737211227417
2025-12-09 12:07:16.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.00020758947626417943 Training loss: 3.42832612991333
2025-12-09 12:07:16.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0002060908770796769 Training loss: 3.4298810958862305
2025-12-09 12:07:16.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.00020458574054452313 Training loss: 3.5509212017059326
2025-12-09 12:07:16.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.00020307424208127912 Training loss: 3.212313652038574
2025-12-09 12:07:16.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.00020155655785398393 Training loss: 3.427323818206787
2025-12-09 12:07:16.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.0002000328647476231 Training loss: 3.3637020587921143
2025-12-09 12:07:16.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.00019850334034751226 Training loss: 3.3944292068481445
2025-12-09 12:07:16.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.00019696816291860038 Training loss: 3.2389044761657715
2025-12-09 12:07:16.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0001954275113846926 Training loss: 3.3001134395599365
2025-12-09 12:07:16.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.00019388156530759712 Training loss: 3.5598580837249756
2025-12-09 12:07:16.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.00019233050486619713 Training loss: 3.4889798164367676
2025-12-09 12:07:16.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0001907745108354514 Training loss: 3.4471163749694824
2025-12-09 12:07:16.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.00018921376456532482 Training loss: 3.335768938064575
2025-12-09 12:07:16.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.00018764844795965229 Training loss: 3.608708381652832
2025-12-09 12:07:16.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.00018607874345493805 Training loss: 3.3905012607574463
2025-12-09 12:07:16.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.00018450483399909263 Training loss: 3.3243699073791504
2025-12-09 12:07:16.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.00018292690303011076 Training loss: 3.3811445236206055
2025-12-09 12:07:16.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.00018134513445469127 Training loss: 3.4462738037109375
2025-12-09 12:07:16.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.00017975971262680347 Training loss: 3.2401247024536133
2025-12-09 12:07:16.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.00017817082232620052 Training loss: 3.3246517181396484
2025-12-09 12:07:16.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.00017657864873688343 Training loss: 3.7276837825775146
2025-12-09 12:07:16.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.00017498337742551817 Training loss: 3.233639717102051
2025-12-09 12:07:16.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.00017338519431980796 Training loss: 3.4738574028015137
2025-12-09 12:07:16.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.00017178428568682353 Training loss: 3.36116623878479
2025-12-09 12:07:16.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0001701808381112938 Training loss: 3.4222259521484375
2025-12-09 12:07:16.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.00016857503847385953 Training loss: 3.37644100189209
2025-12-09 12:07:16.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.00016696707392929266 Training loss: 3.317875385284424
2025-12-09 12:07:16.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0001653571318846834 Training loss: 3.5582714080810547
2025-12-09 12:07:16.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.00016374539997759821 Training loss: 3.1501996517181396
2025-12-09 12:07:16.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.00016213206605421063 Training loss: 3.2689919471740723
2025-12-09 12:07:16.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.0001605173181474081 Training loss: 3.410737991333008
2025-12-09 12:07:16.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.00015890134445487676 Training loss: 3.473517417907715
2025-12-09 12:07:16.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.00015728433331716724 Training loss: 3.31606125831604
2025-12-09 12:07:16.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.0001556664731957435 Training loss: 3.332010269165039
2025-12-09 12:07:16.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.00015404795265101806 Training loss: 3.5092790126800537
2025-12-09 12:07:16.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.00015242896032037522 Training loss: 3.1533138751983643
2025-12-09 12:07:16.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.00015080968489618565 Training loss: 3.274678945541382
2025-12-09 12:07:16.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.00014919031510381435 Training loss: 3.403329372406006
2025-12-09 12:07:16.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.00014757103967962475 Training loss: 3.2997899055480957
2025-12-09 12:07:16.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.00014595204734898197 Training loss: 3.430919647216797
2025-12-09 12:07:16.953 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0001443335268042565 Training loss: 3.3933589458465576
2025-12-09 12:07:16.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.0001427156666828328 Training loss: 3.3401997089385986
2025-12-09 12:07:16.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.00014109865554512319 Training loss: 3.2582006454467773
2025-12-09 12:07:16.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.00013948268185259188 Training loss: 3.009890079498291
2025-12-09 12:07:16.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.00013786793394578937 Training loss: 3.4422214031219482
2025-12-09 12:07:17.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.0001362546000224018 Training loss: 3.329972505569458
2025-12-09 12:07:17.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.00013464286811531661 Training loss: 3.340825080871582
2025-12-09 12:07:17.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.00013303292607070737 Training loss: 3.4059219360351562
2025-12-09 12:07:17.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.0001314249615261405 Training loss: 3.3284530639648438
2025-12-09 12:07:17.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0001298191618887062 Training loss: 3.42215633392334
2025-12-09 12:07:17.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.00012821571431317647 Training loss: 3.2409703731536865
2025-12-09 12:07:17.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.00012661480568019201 Training loss: 3.274017810821533
2025-12-09 12:07:17.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0001250166225744818 Training loss: 3.136139392852783
2025-12-09 12:07:17.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0001234213512631166 Training loss: 3.44783353805542
2025-12-09 12:07:17.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00012182917767379948 Training loss: 3.385079860687256
2025-12-09 12:07:17.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.00012024028737319652 Training loss: 3.3134114742279053
2025-12-09 12:07:17.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.00011865486554530873 Training loss: 3.404299259185791
2025-12-09 12:07:17.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.0001170730969698893 Training loss: 3.097822666168213
2025-12-09 12:07:17.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.00011549516600090737 Training loss: 3.442605495452881
2025-12-09 12:07:17.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.00011392125654506198 Training loss: 3.3552534580230713
2025-12-09 12:07:17.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.00011235155204034767 Training loss: 3.2098329067230225
2025-12-09 12:07:17.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.00011078623543467518 Training loss: 3.627460479736328
2025-12-09 12:07:17.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.00010922548916454855 Training loss: 2.9352195262908936
2025-12-09 12:07:17.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.00010766949513380284 Training loss: 3.3836233615875244
2025-12-09 12:07:17.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.00010611843469240288 Training loss: 3.159932851791382
2025-12-09 12:07:17.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.00010457248861530741 Training loss: 3.156075954437256
2025-12-09 12:07:17.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.00010303183708139964 Training loss: 3.0727531909942627
2025-12-09 12:07:17.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.00010149665965248775 Training loss: 3.3273932933807373
2025-12-09 12:07:17.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 9.996713525237694e-05 Training loss: 3.176445722579956
2025-12-09 12:07:17.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 9.8443442146016e-05 Training loss: 3.164435863494873
2025-12-09 12:07:17.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 9.692575791872089e-05 Training loss: 3.3897275924682617
2025-12-09 12:07:17.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 9.541425945547687e-05 Training loss: 3.207587957382202
2025-12-09 12:07:17.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 9.390912292032309e-05 Training loss: 3.2820281982421875
2025-12-09 12:07:17.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 9.241052373582057e-05 Training loss: 3.1047592163085938
2025-12-09 12:07:17.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 9.091863656260695e-05 Training loss: 3.279874086380005
2025-12-09 12:07:17.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 8.943363527903976e-05 Training loss: 3.1794703006744385
2025-12-09 12:07:17.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 8.795569296093132e-05 Training loss: 3.3596737384796143
2025-12-09 12:07:17.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 8.648498186137653e-05 Training loss: 3.430663824081421
2025-12-09 12:07:17.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 8.502167339067705e-05 Training loss: 3.311479091644287
2025-12-09 12:07:17.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 8.356593809636371e-05 Training loss: 3.2098934650421143
2025-12-09 12:07:17.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 8.211794564331917e-05 Training loss: 3.5889248847961426
2025-12-09 12:07:17.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 8.067786479400346e-05 Training loss: 3.2645957469940186
2025-12-09 12:07:17.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 7.924586338878511e-05 Training loss: 3.1882035732269287
2025-12-09 12:07:17.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 7.782210832637923e-05 Training loss: 3.295732259750366
2025-12-09 12:07:17.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 7.640676554439594e-05 Training loss: 3.103464126586914
2025-12-09 12:07:17.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 7.500000000000002e-05 Training loss: 3.2837419509887695
2025-12-09 12:07:17.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 7.36019756506856e-05 Training loss: 3.3652451038360596
2025-12-09 12:07:17.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 7.22128554351668e-05 Training loss: 3.365544080734253
2025-12-09 12:07:17.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 7.083280125438766e-05 Training loss: 3.2252843379974365
2025-12-09 12:07:17.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 6.946197395265242e-05 Training loss: 3.379284143447876
2025-12-09 12:07:17.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 6.810053329887928e-05 Training loss: 3.1630499362945557
2025-12-09 12:07:17.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 6.674863796797953e-05 Training loss: 3.2435319423675537
2025-12-09 12:07:17.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 6.540644552236401e-05 Training loss: 3.264002561569214
2025-12-09 12:07:17.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 6.407411239357953e-05 Training loss: 3.182868003845215
2025-12-09 12:07:17.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 6.275179386407663e-05 Training loss: 3.306928873062134
2025-12-09 12:07:17.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 6.143964404911164e-05 Training loss: 3.358489990234375
2025-12-09 12:07:17.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 6.013781587878463e-05 Training loss: 3.233064889907837
2025-12-09 12:07:17.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 5.8846461080215626e-05 Training loss: 3.3502564430236816
2025-12-09 12:07:17.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 5.756573015986089e-05 Training loss: 3.2924578189849854
2025-12-09 12:07:17.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 5.629577238597132e-05 Training loss: 3.278231620788574
2025-12-09 12:07:17.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 5.503673577119552e-05 Training loss: 3.0899147987365723
2025-12-09 12:07:17.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 5.378876705532904e-05 Training loss: 3.2839109897613525
2025-12-09 12:07:17.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 5.2552011688211835e-05 Training loss: 3.3940322399139404
2025-12-09 12:07:17.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 5.1326613812776434e-05 Training loss: 3.0551414489746094
2025-12-09 12:07:17.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 5.011271624824786e-05 Training loss: 3.181072950363159
2025-12-09 12:07:17.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 4.891046047349837e-05 Training loss: 3.219020366668701
2025-12-09 12:07:17.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 4.7719986610558234e-05 Training loss: 3.3582167625427246
2025-12-09 12:07:17.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 4.654143340828435e-05 Training loss: 3.156688928604126
2025-12-09 12:07:17.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 4.537493822618958e-05 Training loss: 3.090094804763794
2025-12-09 12:07:17.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 4.422063701843316e-05 Training loss: 3.0830931663513184
2025-12-09 12:07:17.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 4.3078664317975646e-05 Training loss: 3.2513034343719482
2025-12-09 12:07:17.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 4.194915322089898e-05 Training loss: 3.3742527961730957
2025-12-09 12:07:17.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 4.08322353708946e-05 Training loss: 3.1681063175201416
2025-12-09 12:07:17.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 3.972804094391998e-05 Training loss: 3.2358336448669434
2025-12-09 12:07:17.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 3.863669863302697e-05 Training loss: 3.361556053161621
2025-12-09 12:07:17.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 3.755833563336293e-05 Training loss: 3.0888140201568604
2025-12-09 12:07:17.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 3.64930776273457e-05 Training loss: 3.2408623695373535
2025-12-09 12:07:17.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 3.5441048770015954e-05 Training loss: 3.3154890537261963
2025-12-09 12:07:17.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 3.4402371674566626e-05 Training loss: 3.0793747901916504
2025-12-09 12:07:17.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 3.3377167398052636e-05 Training loss: 3.0461583137512207
2025-12-09 12:07:17.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 3.2365555427281634e-05 Training loss: 3.3208065032958984
2025-12-09 12:07:17.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 3.136765366488817e-05 Training loss: 3.23040771484375
2025-12-09 12:07:17.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 3.038357841559191e-05 Training loss: 3.213009834289551
2025-12-09 12:07:17.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 2.941344437264249e-05 Training loss: 3.1196043491363525
2025-12-09 12:07:17.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 2.8457364604452372e-05 Training loss: 3.2254700660705566
2025-12-09 12:07:17.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 2.7515450541418338e-05 Training loss: 3.2013378143310547
2025-12-09 12:07:17.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 2.658781196293482e-05 Training loss: 2.945838212966919
2025-12-09 12:07:17.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 2.5674556984598822e-05 Training loss: 3.0646207332611084
2025-12-09 12:07:17.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 2.477579204560935e-05 Training loss: 3.1705214977264404
2025-12-09 12:07:17.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 2.389162189636188e-05 Training loss: 3.3946847915649414
2025-12-09 12:07:17.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 2.3022149586239968e-05 Training loss: 3.045461893081665
2025-12-09 12:07:17.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 2.216747645160462e-05 Training loss: 3.0493438243865967
2025-12-09 12:07:17.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 2.1327702103983863e-05 Training loss: 3.226665735244751
2025-12-09 12:07:17.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 2.0502924418463013e-05 Training loss: 3.142559051513672
2025-12-09 12:07:17.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 1.9693239522277327e-05 Training loss: 3.317655563354492
2025-12-09 12:07:17.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 1.889874178360864e-05 Training loss: 2.8801205158233643
2025-12-09 12:07:17.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 1.8119523800586568e-05 Training loss: 3.26218318939209
2025-12-09 12:07:17.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 1.735567639049648e-05 Training loss: 3.2514638900756836
2025-12-09 12:07:17.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 1.6607288579194638e-05 Training loss: 3.08738112449646
2025-12-09 12:07:17.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 1.5874447590732538e-05 Training loss: 3.3183889389038086
2025-12-09 12:07:17.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 1.5157238837190716e-05 Training loss: 3.5364527702331543
2025-12-09 12:07:17.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 1.4455745908724226e-05 Training loss: 3.133774995803833
2025-12-09 12:07:17.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 1.3770050563820179e-05 Training loss: 3.23453688621521
2025-12-09 12:07:17.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 1.3100232719768994e-05 Training loss: 3.4116036891937256
2025-12-09 12:07:17.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 1.2446370443349863e-05 Training loss: 3.03609561920166
2025-12-09 12:07:17.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 1.180853994173236e-05 Training loss: 3.242274761199951
2025-12-09 12:07:17.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 1.118681555359438e-05 Training loss: 3.4171640872955322
2025-12-09 12:07:17.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 1.058126974045811e-05 Training loss: 3.5130434036254883
2025-12-09 12:07:17.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 9.991973078244636e-06 Training loss: 3.07549786567688
2025-12-09 12:07:17.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 9.418994249048472e-06 Training loss: 3.2387588024139404
2025-12-09 12:07:17.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 8.862400033132571e-06 Training loss: 3.012404680252075
2025-12-09 12:07:17.953 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 8.322255301145204e-06 Training loss: 3.19584321975708
2025-12-09 12:07:17.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 7.798623006559435e-06 Training loss: 3.02966046333313
2025-12-09 12:07:17.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 7.291564178335718e-06 Training loss: 3.231389284133911
2025-12-09 12:07:17.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 6.801137913809213e-06 Training loss: 3.3831729888916016
2025-12-09 12:07:17.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 6.3274013718019434e-06 Training loss: 3.420488119125366
2025-12-09 12:07:17.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 5.870409765960965e-06 Training loss: 3.252845525741577
2025-12-09 12:07:18.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 5.430216358323309e-06 Training loss: 3.122375965118408
2025-12-09 12:07:18.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 5.006872453108329e-06 Training loss: 3.264364719390869
2025-12-09 12:07:18.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 4.600427390738159e-06 Training loss: 3.3171768188476562
2025-12-09 12:07:18.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 4.210928542087206e-06 Training loss: 3.3729772567749023
2025-12-09 12:07:18.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 3.838421302961098e-06 Training loss: 3.2765159606933594
2025-12-09 12:07:18.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 3.482949088805742e-06 Training loss: 2.9655325412750244
2025-12-09 12:07:18.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 3.1445533296474478e-06 Training loss: 3.0852444171905518
2025-12-09 12:07:18.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 2.823273465264142e-06 Training loss: 3.1815950870513916
2025-12-09 12:07:18.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 2.519146940588762e-06 Training loss: 2.994985818862915
2025-12-09 12:07:18.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 2.232209201345031e-06 Training loss: 3.2087788581848145
2025-12-09 12:07:18.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 1.9624936899163945e-06 Training loss: 3.097398281097412
2025-12-09 12:07:18.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 1.7100318414482061e-06 Training loss: 3.1446478366851807
2025-12-09 12:07:18.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 1.4748530801840074e-06 Training loss: 3.2366440296173096
2025-12-09 12:07:18.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 1.2569848160362384e-06 Training loss: 3.0719645023345947
2025-12-09 12:07:18.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 1.056452441391542e-06 Training loss: 2.9776196479797363
2025-12-09 12:07:18.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 8.732793281513661e-07 Training loss: 3.138159990310669
2025-12-09 12:07:18.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 7.07486825007908e-07 Training loss: 3.2798709869384766
2025-12-09 12:07:18.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 5.590942549560051e-07 Training loss: 3.14107084274292
2025-12-09 12:07:18.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 4.281189130410534e-07 Training loss: 3.123828649520874
2025-12-09 12:07:18.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 3.1457606434325266e-07 Training loss: 3.232196807861328
2025-12-09 12:07:18.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 2.184789421984634e-07 Training loss: 3.1917500495910645
2025-12-09 12:07:18.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 1.3983874665589035e-07 Training loss: 3.0976192951202393
2025-12-09 12:07:18.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 7.866464317276e-08 Training loss: 3.381108522415161
2025-12-09 12:07:18.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 3.4963761546041855e-08 Training loss: 3.2190427780151367
2025-12-09 12:07:18.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 8.741195081479747e-09 Training loss: 3.3721187114715576
2025-12-09 12:07:18.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0 Training loss: 3.5541114807128906
