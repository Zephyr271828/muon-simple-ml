2025-12-09 05:58:21.869 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.17855453491211
2025-12-09 05:58:22.380 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.142802238464355
2025-12-09 05:58:22.883 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.139546394348145
2025-12-09 05:58:23.387 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 12.144693374633789
2025-12-09 05:58:23.892 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 12.127348899841309
2025-12-09 05:58:24.398 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 12.080896377563477
2025-12-09 05:58:24.903 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 12.072973251342773
2025-12-09 05:58:25.409 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 12.051131248474121
2025-12-09 05:58:25.915 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 12.024076461791992
2025-12-09 05:58:26.421 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 11.987349510192871
2025-12-09 05:58:26.929 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 11.953912734985352
2025-12-09 05:58:27.435 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 11.870376586914062
2025-12-09 05:58:27.942 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 11.83733081817627
2025-12-09 05:58:28.450 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 11.762577056884766
2025-12-09 05:58:28.957 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 11.652628898620605
2025-12-09 05:58:29.464 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 11.601371765136719
2025-12-09 05:58:29.970 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 11.42482852935791
2025-12-09 05:58:30.475 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 11.406804084777832
2025-12-09 05:58:30.979 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 11.08371639251709
2025-12-09 05:58:31.485 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 11.050994873046875
2025-12-09 05:58:31.991 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 10.778533935546875
2025-12-09 05:58:32.498 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 10.647117614746094
2025-12-09 05:58:33.003 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 10.479384422302246
2025-12-09 05:58:33.510 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 10.25794506072998
2025-12-09 05:58:34.017 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 10.031065940856934
2025-12-09 05:58:34.524 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 9.668577194213867
2025-12-09 05:58:35.028 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 9.477779388427734
2025-12-09 05:58:35.535 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 9.204483032226562
2025-12-09 05:58:36.039 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 9.027958869934082
2025-12-09 05:58:36.544 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 8.812506675720215
2025-12-09 05:58:37.050 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 8.578287124633789
2025-12-09 05:58:37.552 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 8.465983390808105
2025-12-09 05:58:38.056 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 8.484501838684082
2025-12-09 05:58:38.562 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 8.280755043029785
2025-12-09 05:58:39.066 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 8.180728912353516
2025-12-09 05:58:39.572 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 8.083670616149902
2025-12-09 05:58:40.074 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 8.141716003417969
2025-12-09 05:58:40.579 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 7.943166732788086
2025-12-09 05:58:41.080 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 7.924951076507568
2025-12-09 05:58:41.585 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 7.828102111816406
2025-12-09 05:58:42.088 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 7.7223286628723145
2025-12-09 05:58:42.594 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 7.771373748779297
2025-12-09 05:58:43.097 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 7.730897903442383
2025-12-09 05:58:43.601 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 7.535735130310059
2025-12-09 05:58:44.102 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 7.677570819854736
2025-12-09 05:58:44.607 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 7.763072967529297
2025-12-09 05:58:45.109 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 7.867091178894043
2025-12-09 05:58:45.613 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 7.864384174346924
2025-12-09 05:58:46.117 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 8.250462532043457
2025-12-09 05:58:46.621 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 7.635434627532959
2025-12-09 05:58:47.122 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 7.7789411544799805
2025-12-09 05:58:47.626 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 7.781872749328613
2025-12-09 05:58:48.129 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 7.875618934631348
2025-12-09 05:58:48.635 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 7.725113868713379
2025-12-09 05:58:49.138 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 7.850266456604004
2025-12-09 05:58:49.643 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 7.6348371505737305
2025-12-09 05:58:50.145 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 7.706689357757568
2025-12-09 05:58:50.650 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 7.640408515930176
2025-12-09 05:58:51.153 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 7.547081470489502
2025-12-09 05:58:51.658 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 7.4380717277526855
2025-12-09 05:58:52.162 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 7.686999320983887
2025-12-09 05:58:52.666 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 7.656585693359375
2025-12-09 05:58:53.168 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 7.580813884735107
2025-12-09 05:58:53.673 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 7.577962875366211
2025-12-09 05:58:54.175 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 7.522787570953369
2025-12-09 05:58:54.679 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 7.734539031982422
2025-12-09 05:58:55.182 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 7.4071431159973145
2025-12-09 05:58:55.687 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 7.408689022064209
2025-12-09 05:58:56.190 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 7.263315200805664
2025-12-09 05:58:56.694 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 7.425450325012207
2025-12-09 05:58:57.197 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 7.40788459777832
2025-12-09 05:58:57.702 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 7.322413444519043
2025-12-09 05:58:58.207 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 7.200441360473633
2025-12-09 05:58:58.715 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 7.307587623596191
2025-12-09 05:58:59.219 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 7.611891746520996
2025-12-09 05:58:59.725 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 7.363847732543945
2025-12-09 05:59:00.229 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 7.196549892425537
2025-12-09 05:59:00.735 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 7.31696081161499
2025-12-09 05:59:01.239 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 7.417405605316162
2025-12-09 05:59:01.744 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 7.1832499504089355
2025-12-09 05:59:02.249 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 7.185321807861328
2025-12-09 05:59:02.754 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 7.420031547546387
2025-12-09 05:59:03.258 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 7.298267364501953
2025-12-09 05:59:03.765 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 7.144493579864502
2025-12-09 05:59:04.271 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 7.133296966552734
2025-12-09 05:59:04.778 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 7.201062202453613
2025-12-09 05:59:05.282 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 7.424673080444336
2025-12-09 05:59:05.788 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 7.05512809753418
2025-12-09 05:59:06.292 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 6.704799652099609
2025-12-09 05:59:06.798 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 7.511752605438232
2025-12-09 05:59:07.302 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 7.089079856872559
2025-12-09 05:59:07.808 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 7.238956451416016
2025-12-09 05:59:08.313 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 6.892822265625
2025-12-09 05:59:08.818 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 6.9399309158325195
2025-12-09 05:59:09.322 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 6.963627338409424
2025-12-09 05:59:09.829 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 6.724367618560791
2025-12-09 05:59:10.336 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 6.8752593994140625
2025-12-09 05:59:10.845 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 6.781843185424805
2025-12-09 05:59:11.352 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 6.904169082641602
2025-12-09 05:59:11.859 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 6.9416117668151855
2025-12-09 05:59:12.365 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 100 LR: 0.0009977359612865424 Training loss: 6.734469413757324
2025-12-09 05:59:12.873 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 101 LR: 0.0009909643486313534 Training loss: 6.831672191619873
2025-12-09 05:59:13.378 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 102 LR: 0.0009797464868072487 Training loss: 6.6441779136657715
2025-12-09 05:59:13.885 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 103 LR: 0.0009641839665080363 Training loss: 6.812857151031494
2025-12-09 05:59:14.392 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 104 LR: 0.0009444177243274617 Training loss: 6.628629684448242
2025-12-09 05:59:14.898 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 105 LR: 0.0009206267664155906 Training loss: 6.721500396728516
2025-12-09 05:59:15.406 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 106 LR: 0.0008930265473713938 Training loss: 6.7978034019470215
2025-12-09 05:59:15.912 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 107 LR: 0.000861867019052535 Training loss: 6.579850196838379
2025-12-09 05:59:16.417 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 108 LR: 0.0008274303669726426 Training loss: 6.520145893096924
2025-12-09 05:59:16.924 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 109 LR: 0.0007900284547855992 Training loss: 6.686147212982178
2025-12-09 05:59:17.431 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 110 LR: 0.00075 Training loss: 6.6664228439331055
2025-12-09 05:59:17.937 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 111 LR: 0.0007077075065009433 Training loss: 6.551093578338623
2025-12-09 05:59:18.445 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 112 LR: 0.0006635339816587109 Training loss: 6.916040420532227
2025-12-09 05:59:18.951 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 113 LR: 0.0006178794677547138 Training loss: 6.667355060577393
2025-12-09 05:59:19.456 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 114 LR: 0.0005711574191366427 Training loss: 6.466421127319336
2025-12-09 05:59:19.962 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 115 LR: 0.0005237909579118712 Training loss: 6.396367073059082
2025-12-09 05:59:20.470 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 116 LR: 0.0004762090420881289 Training loss: 6.667576789855957
2025-12-09 05:59:20.977 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 117 LR: 0.0004288425808633575 Training loss: 6.43951940536499
2025-12-09 05:59:21.485 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 118 LR: 0.0003821205322452863 Training loss: 6.8331379890441895
2025-12-09 05:59:21.993 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 119 LR: 0.0003364660183412892 Training loss: 6.629560470581055
2025-12-09 05:59:22.500 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 120 LR: 0.0002922924934990568 Training loss: 6.691417694091797
2025-12-09 05:59:23.007 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 121 LR: 0.0002500000000000001 Training loss: 6.544744491577148
2025-12-09 05:59:23.514 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 122 LR: 0.00020997154521440098 Training loss: 6.710838794708252
2025-12-09 05:59:24.019 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 123 LR: 0.0001725696330273575 Training loss: 6.800848484039307
2025-12-09 05:59:24.527 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 124 LR: 0.0001381329809474649 Training loss: 6.526759147644043
2025-12-09 05:59:25.035 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 125 LR: 0.00010697345262860636 Training loss: 6.475398063659668
2025-12-09 05:59:25.542 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 126 LR: 7.937323358440934e-05 Training loss: 6.5423173904418945
2025-12-09 05:59:26.049 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 127 LR: 5.5582275672538315e-05 Training loss: 6.665869235992432
2025-12-09 05:59:26.557 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 128 LR: 3.5816033491963716e-05 Training loss: 6.643221855163574
2025-12-09 05:59:27.062 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 129 LR: 2.025351319275137e-05 Training loss: 6.398490905761719
2025-12-09 05:59:27.569 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 130 LR: 9.035651368646646e-06 Training loss: 6.640430927276611
2025-12-09 05:59:28.074 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 131 LR: 2.2640387134577057e-06 Training loss: 6.582034111022949
2025-12-09 05:59:28.400 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 132 LR: 0.0 Training loss: 6.779344081878662
