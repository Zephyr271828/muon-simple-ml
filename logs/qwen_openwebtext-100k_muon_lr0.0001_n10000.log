2025-12-09 11:57:14.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 12.036367416381836
2025-12-09 11:57:14.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 12.055171012878418
2025-12-09 11:57:14.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 12.067523956298828
2025-12-09 11:57:15.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 12.057825088500977
2025-12-09 11:57:15.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 12.030237197875977
2025-12-09 11:57:15.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 12.029718399047852
2025-12-09 11:57:15.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 12.045454025268555
2025-12-09 11:57:15.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 12.010782241821289
2025-12-09 11:57:15.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 12.030315399169922
2025-12-09 11:57:15.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 12.013559341430664
2025-12-09 11:57:15.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 12.040477752685547
2025-12-09 11:57:16.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 12.048235893249512
2025-12-09 11:57:16.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 12.039077758789062
2025-12-09 11:57:16.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 12.01540756225586
2025-12-09 11:57:16.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 11.999001502990723
2025-12-09 11:57:16.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 12.039562225341797
2025-12-09 11:57:16.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 12.008613586425781
2025-12-09 11:57:16.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 12.028059959411621
2025-12-09 11:57:17.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 12.044475555419922
2025-12-09 11:57:17.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 11.981945991516113
2025-12-09 11:57:17.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 12.031135559082031
2025-12-09 11:57:17.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 12.018762588500977
2025-12-09 11:57:17.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 11.977777481079102
2025-12-09 11:57:17.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 11.955656051635742
2025-12-09 11:57:17.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 12.021017074584961
2025-12-09 11:57:17.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 12.000387191772461
2025-12-09 11:57:18.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 11.943187713623047
2025-12-09 11:57:18.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 11.96904468536377
2025-12-09 11:57:18.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 11.985953330993652
2025-12-09 11:57:18.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 11.908731460571289
2025-12-09 11:57:18.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 11.920449256896973
2025-12-09 11:57:18.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 11.907462120056152
2025-12-09 11:57:19.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 11.948436737060547
2025-12-09 11:57:19.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 11.915759086608887
2025-12-09 11:57:19.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 11.917670249938965
2025-12-09 11:57:19.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 11.916658401489258
2025-12-09 11:57:19.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 11.897252082824707
2025-12-09 11:57:19.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 11.860623359680176
2025-12-09 11:57:19.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 11.905898094177246
2025-12-09 11:57:19.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 11.875168800354004
2025-12-09 11:57:20.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 11.82493782043457
2025-12-09 11:57:20.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 11.801054954528809
2025-12-09 11:57:20.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 11.786138534545898
2025-12-09 11:57:20.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 11.795989036560059
2025-12-09 11:57:20.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 11.760711669921875
2025-12-09 11:57:20.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 11.792525291442871
2025-12-09 11:57:20.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 11.684263229370117
2025-12-09 11:57:20.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 11.753244400024414
2025-12-09 11:57:21.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 11.67737865447998
2025-12-09 11:57:21.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 11.702920913696289
2025-12-09 11:57:21.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 11.756077766418457
2025-12-09 11:57:21.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 11.673077583312988
2025-12-09 11:57:21.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 11.614233016967773
2025-12-09 11:57:21.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 11.599508285522461
2025-12-09 11:57:21.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 11.520856857299805
2025-12-09 11:57:21.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 11.57048225402832
2025-12-09 11:57:22.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 11.49599838256836
2025-12-09 11:57:22.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 11.569892883300781
2025-12-09 11:57:22.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 11.554603576660156
2025-12-09 11:57:22.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 11.43634033203125
2025-12-09 11:57:22.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 11.410787582397461
2025-12-09 11:57:22.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 11.334914207458496
2025-12-09 11:57:22.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 11.442435264587402
2025-12-09 11:57:23.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 11.406007766723633
2025-12-09 11:57:23.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 11.267633438110352
2025-12-09 11:57:23.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 11.20435619354248
2025-12-09 11:57:23.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 11.193140029907227
2025-12-09 11:57:23.597 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 11.146675109863281
2025-12-09 11:57:23.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 11.294628143310547
2025-12-09 11:57:23.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 11.044686317443848
2025-12-09 11:57:23.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 11.113097190856934
2025-12-09 11:57:24.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 10.98831558227539
2025-12-09 11:57:24.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 11.068995475769043
2025-12-09 11:57:24.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 10.849246978759766
2025-12-09 11:57:24.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 11.029029846191406
2025-12-09 11:57:24.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 10.767083168029785
2025-12-09 11:57:24.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 11.064640045166016
2025-12-09 11:57:24.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 10.719366073608398
2025-12-09 11:57:25.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 10.711146354675293
2025-12-09 11:57:25.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 10.646607398986816
2025-12-09 11:57:25.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 10.598191261291504
2025-12-09 11:57:25.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 10.72862720489502
2025-12-09 11:57:25.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 10.4871187210083
2025-12-09 11:57:25.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 10.487870216369629
2025-12-09 11:57:25.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 10.389994621276855
2025-12-09 11:57:25.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 10.4053373336792
2025-12-09 11:57:26.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 10.323309898376465
2025-12-09 11:57:26.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 10.22712516784668
2025-12-09 11:57:26.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 10.226532936096191
2025-12-09 11:57:26.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 10.033377647399902
2025-12-09 11:57:26.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 10.285572052001953
2025-12-09 11:57:26.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 10.085925102233887
2025-12-09 11:57:26.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 10.088675498962402
2025-12-09 11:57:27.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 10.01040267944336
2025-12-09 11:57:27.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 10.011077880859375
2025-12-09 11:57:27.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 9.853168487548828
2025-12-09 11:57:27.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 9.963327407836914
2025-12-09 11:57:27.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 9.740853309631348
2025-12-09 11:57:27.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 10.144967079162598
2025-12-09 11:57:27.786 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 9.730020523071289
2025-12-09 11:57:27.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.999999072578703e-05 Training loss: 9.630147933959961
2025-12-09 11:57:28.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 9.999996290315153e-05 Training loss: 9.627694129943848
2025-12-09 11:57:28.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 9.999991653210385e-05 Training loss: 9.667829513549805
2025-12-09 11:57:28.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 9.999985161266117e-05 Training loss: 9.619974136352539
2025-12-09 11:57:28.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 9.999976814484758e-05 Training loss: 10.014693260192871
2025-12-09 11:57:28.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 9.999966612869405e-05 Training loss: 9.366647720336914
2025-12-09 11:57:28.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 9.999954556423843e-05 Training loss: 8.987460136413574
2025-12-09 11:57:28.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 9.999940645152541e-05 Training loss: 9.615381240844727
2025-12-09 11:57:28.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 9.999924879060665e-05 Training loss: 9.273347854614258
2025-12-09 11:57:29.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 9.999907258154059e-05 Training loss: 9.275617599487305
2025-12-09 11:57:29.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 9.999887782439263e-05 Training loss: 9.240117073059082
2025-12-09 11:57:29.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 9.999866451923501e-05 Training loss: 9.088343620300293
2025-12-09 11:57:29.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 9.999843266614685e-05 Training loss: 9.047431945800781
2025-12-09 11:57:29.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 9.999818226521415e-05 Training loss: 9.108661651611328
2025-12-09 11:57:29.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 9.999791331652984e-05 Training loss: 8.907038688659668
2025-12-09 11:57:29.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 9.999762582019365e-05 Training loss: 8.979951858520508
2025-12-09 11:57:30.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 9.999731977631227e-05 Training loss: 8.612056732177734
2025-12-09 11:57:30.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 9.999699518499921e-05 Training loss: 8.966264724731445
2025-12-09 11:57:30.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 9.999665204637487e-05 Training loss: 8.615577697753906
2025-12-09 11:57:30.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 9.999629036056657e-05 Training loss: 8.81956958770752
2025-12-09 11:57:30.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 9.999591012770848e-05 Training loss: 8.885807991027832
2025-12-09 11:57:30.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 9.999551134794164e-05 Training loss: 8.73504638671875
2025-12-09 11:57:30.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 9.999509402141401e-05 Training loss: 8.6514310836792
2025-12-09 11:57:30.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 9.999465814828036e-05 Training loss: 8.76676082611084
2025-12-09 11:57:31.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 9.999420372870242e-05 Training loss: 8.587395668029785
2025-12-09 11:57:31.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 9.999373076284877e-05 Training loss: 9.025795936584473
2025-12-09 11:57:31.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 9.999323925089486e-05 Training loss: 8.538195610046387
2025-12-09 11:57:31.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 9.999272919302301e-05 Training loss: 8.487483024597168
2025-12-09 11:57:31.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 9.999220058942245e-05 Training loss: 8.378059387207031
2025-12-09 11:57:31.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 9.999165344028926e-05 Training loss: 8.518070220947266
2025-12-09 11:57:31.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 9.999108774582645e-05 Training loss: 8.50197696685791
2025-12-09 11:57:31.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 9.999050350624382e-05 Training loss: 8.356917381286621
2025-12-09 11:57:32.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 9.998990072175813e-05 Training loss: 8.671404838562012
2025-12-09 11:57:32.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 9.998927939259303e-05 Training loss: 8.479084014892578
2025-12-09 11:57:32.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 9.998863951897897e-05 Training loss: 8.014450073242188
2025-12-09 11:57:32.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 9.998798110115333e-05 Training loss: 8.518638610839844
2025-12-09 11:57:32.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 9.998730413936037e-05 Training loss: 8.347447395324707
2025-12-09 11:57:32.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 9.998660863385123e-05 Training loss: 8.285057067871094
2025-12-09 11:57:32.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 9.99858945848839e-05 Training loss: 8.185754776000977
2025-12-09 11:57:33.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 9.998516199272327e-05 Training loss: 8.030879020690918
2025-12-09 11:57:33.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 9.998441085764113e-05 Training loss: 8.130260467529297
2025-12-09 11:57:33.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 9.998364117991612e-05 Training loss: 8.501321792602539
2025-12-09 11:57:33.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 9.998285295983376e-05 Training loss: 8.012680053710938
2025-12-09 11:57:33.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 9.998204619768646e-05 Training loss: 8.130764961242676
2025-12-09 11:57:33.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 9.998122089377349e-05 Training loss: 8.13751220703125
2025-12-09 11:57:33.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 9.998037704840102e-05 Training loss: 8.112275123596191
2025-12-09 11:57:33.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 9.99795146618821e-05 Training loss: 8.068370819091797
2025-12-09 11:57:34.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 9.997863373453663e-05 Training loss: 8.233158111572266
2025-12-09 11:57:34.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 9.997773426669142e-05 Training loss: 7.991042613983154
2025-12-09 11:57:34.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 9.997681625868013e-05 Training loss: 8.336577415466309
2025-12-09 11:57:34.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 9.997587971084335e-05 Training loss: 7.987461566925049
2025-12-09 11:57:34.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 9.997492462352846e-05 Training loss: 8.087884902954102
2025-12-09 11:57:34.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 9.997395099708982e-05 Training loss: 8.166196823120117
2025-12-09 11:57:34.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 9.997295883188856e-05 Training loss: 8.036577224731445
2025-12-09 11:57:35.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 9.997194812829276e-05 Training loss: 8.231599807739258
2025-12-09 11:57:35.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 9.997091888667738e-05 Training loss: 7.879671573638916
2025-12-09 11:57:35.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 9.996987110742422e-05 Training loss: 7.6072821617126465
2025-12-09 11:57:35.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 9.996880479092198e-05 Training loss: 7.719918727874756
2025-12-09 11:57:35.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 9.996771993756621e-05 Training loss: 7.8951616287231445
2025-12-09 11:57:35.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 9.996661654775938e-05 Training loss: 7.976646423339844
2025-12-09 11:57:35.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 9.996549462191082e-05 Training loss: 8.425024032592773
2025-12-09 11:57:35.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 9.99643541604367e-05 Training loss: 8.2512788772583
2025-12-09 11:57:36.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 9.99631951637601e-05 Training loss: 7.407425403594971
2025-12-09 11:57:36.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 9.996201763231099e-05 Training loss: 7.73447322845459
2025-12-09 11:57:36.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 9.996082156652618e-05 Training loss: 8.08664608001709
2025-12-09 11:57:36.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 9.995960696684939e-05 Training loss: 7.5427565574646
2025-12-09 11:57:36.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 9.995837383373119e-05 Training loss: 7.541266441345215
2025-12-09 11:57:36.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 9.995712216762902e-05 Training loss: 7.503180503845215
2025-12-09 11:57:36.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 9.995585196900723e-05 Training loss: 8.512582778930664
2025-12-09 11:57:36.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 9.9954563238337e-05 Training loss: 7.915310859680176
2025-12-09 11:57:37.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 9.995325597609645e-05 Training loss: 7.631989479064941
2025-12-09 11:57:37.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 9.99519301827705e-05 Training loss: 7.876887321472168
2025-12-09 11:57:37.363 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 9.995058585885095e-05 Training loss: 7.814043045043945
2025-12-09 11:57:37.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 9.994922300483656e-05 Training loss: 8.083382606506348
2025-12-09 11:57:37.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 9.99478416212329e-05 Training loss: 7.699570178985596
2025-12-09 11:57:37.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 9.994644170855237e-05 Training loss: 7.851292133331299
2025-12-09 11:57:37.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 9.994502326731434e-05 Training loss: 7.812880992889404
2025-12-09 11:57:38.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 9.994358629804499e-05 Training loss: 7.470415115356445
2025-12-09 11:57:38.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 9.994213080127739e-05 Training loss: 7.678866386413574
2025-12-09 11:57:38.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 9.994065677755147e-05 Training loss: 7.679513931274414
2025-12-09 11:57:38.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 9.993916422741409e-05 Training loss: 7.240365028381348
2025-12-09 11:57:38.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 9.99376531514189e-05 Training loss: 7.588984966278076
2025-12-09 11:57:38.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 9.993612355012647e-05 Training loss: 7.600711822509766
2025-12-09 11:57:38.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 9.993457542410424e-05 Training loss: 7.652915000915527
2025-12-09 11:57:38.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 9.993300877392651e-05 Training loss: 7.473021507263184
2025-12-09 11:57:39.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 9.993142360017446e-05 Training loss: 7.531064510345459
2025-12-09 11:57:39.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 9.992981990343614e-05 Training loss: 7.611759662628174
2025-12-09 11:57:39.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 9.992819768430647e-05 Training loss: 7.523959159851074
2025-12-09 11:57:39.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 9.992655694338725e-05 Training loss: 7.854403972625732
2025-12-09 11:57:39.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 9.992489768128713e-05 Training loss: 7.554591178894043
2025-12-09 11:57:39.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 9.992321989862166e-05 Training loss: 7.381766319274902
2025-12-09 11:57:39.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 9.992152359601322e-05 Training loss: 7.475583076477051
2025-12-09 11:57:39.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 9.99198087740911e-05 Training loss: 7.565568447113037
2025-12-09 11:57:40.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 9.991807543349146e-05 Training loss: 7.842536926269531
2025-12-09 11:57:40.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 9.99163235748573e-05 Training loss: 7.654867649078369
2025-12-09 11:57:40.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 9.99145531988385e-05 Training loss: 7.351114749908447
2025-12-09 11:57:40.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 9.99127643060918e-05 Training loss: 8.531035423278809
2025-12-09 11:57:40.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 9.991095689728087e-05 Training loss: 7.474036693572998
2025-12-09 11:57:40.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 9.990913097307614e-05 Training loss: 7.351780891418457
2025-12-09 11:57:40.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 9.990728653415504e-05 Training loss: 8.363186836242676
2025-12-09 11:57:41.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 9.990542358120174e-05 Training loss: 7.421618938446045
2025-12-09 11:57:41.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 9.990354211490735e-05 Training loss: 7.286938190460205
2025-12-09 11:57:41.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 9.990164213596986e-05 Training loss: 7.263092041015625
2025-12-09 11:57:41.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 9.989972364509408e-05 Training loss: 7.76845121383667
2025-12-09 11:57:41.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 9.989778664299172e-05 Training loss: 7.395857810974121
2025-12-09 11:57:41.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 9.989583113038135e-05 Training loss: 7.543057918548584
2025-12-09 11:57:41.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 9.989385710798837e-05 Training loss: 8.240867614746094
2025-12-09 11:57:41.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 9.989186457654513e-05 Training loss: 7.483976364135742
2025-12-09 11:57:42.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 9.988985353679077e-05 Training loss: 7.412898540496826
2025-12-09 11:57:42.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 9.988782398947131e-05 Training loss: 7.513901710510254
2025-12-09 11:57:42.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 9.988577593533967e-05 Training loss: 7.595154285430908
2025-12-09 11:57:42.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 9.988370937515561e-05 Training loss: 7.646005153656006
2025-12-09 11:57:42.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 9.988162430968575e-05 Training loss: 7.542147159576416
2025-12-09 11:57:42.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 9.987952073970359e-05 Training loss: 7.250340938568115
2025-12-09 11:57:42.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 9.98773986659895e-05 Training loss: 7.605935573577881
2025-12-09 11:57:43.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 9.987525808933068e-05 Training loss: 7.590118885040283
2025-12-09 11:57:43.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 9.987309901052121e-05 Training loss: 7.331213474273682
2025-12-09 11:57:43.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 9.98709214303621e-05 Training loss: 7.560491561889648
2025-12-09 11:57:43.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 9.986872534966109e-05 Training loss: 7.344175815582275
2025-12-09 11:57:43.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 9.986651076923288e-05 Training loss: 7.168997287750244
2025-12-09 11:57:43.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 9.986427768989903e-05 Training loss: 7.61029577255249
2025-12-09 11:57:43.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 9.986202611248793e-05 Training loss: 6.667059421539307
2025-12-09 11:57:43.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 9.985975603783484e-05 Training loss: 7.347821235656738
2025-12-09 11:57:44.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 9.98574674667819e-05 Training loss: 7.677192687988281
2025-12-09 11:57:44.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 9.985516040017807e-05 Training loss: 7.5960373878479
2025-12-09 11:57:44.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 9.985283483887923e-05 Training loss: 7.530910015106201
2025-12-09 11:57:44.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 9.985049078374806e-05 Training loss: 7.332867622375488
2025-12-09 11:57:44.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 9.984812823565417e-05 Training loss: 7.403707504272461
2025-12-09 11:57:44.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 9.984574719547395e-05 Training loss: 7.269711017608643
2025-12-09 11:57:44.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 9.984334766409071e-05 Training loss: 7.311942100524902
2025-12-09 11:57:44.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 9.98409296423946e-05 Training loss: 7.574908256530762
2025-12-09 11:57:45.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 9.983849313128264e-05 Training loss: 7.4487481117248535
2025-12-09 11:57:45.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 9.983603813165869e-05 Training loss: 7.1945061683654785
2025-12-09 11:57:45.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 9.983356464443347e-05 Training loss: 7.234274864196777
2025-12-09 11:57:45.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 9.983107267052457e-05 Training loss: 7.3845906257629395
2025-12-09 11:57:45.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 9.982856221085644e-05 Training loss: 6.814684867858887
2025-12-09 11:57:45.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 9.982603326636037e-05 Training loss: 7.083205699920654
2025-12-09 11:57:45.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 9.982348583797454e-05 Training loss: 7.080016613006592
2025-12-09 11:57:46.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 9.982091992664392e-05 Training loss: 7.145181179046631
2025-12-09 11:57:46.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 9.981833553332045e-05 Training loss: 7.786893844604492
2025-12-09 11:57:46.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 9.981573265896281e-05 Training loss: 7.403869152069092
2025-12-09 11:57:46.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 9.981311130453659e-05 Training loss: 6.931947231292725
2025-12-09 11:57:46.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 9.981047147101426e-05 Training loss: 7.173469066619873
2025-12-09 11:57:46.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 9.980781315937507e-05 Training loss: 7.367379665374756
2025-12-09 11:57:46.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 9.98051363706052e-05 Training loss: 7.399955749511719
2025-12-09 11:57:46.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 9.980244110569765e-05 Training loss: 7.139119625091553
2025-12-09 11:57:47.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 9.979972736565226e-05 Training loss: 7.285726070404053
2025-12-09 11:57:47.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 9.979699515147578e-05 Training loss: 6.53759241104126
2025-12-09 11:57:47.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 9.979424446418173e-05 Training loss: 6.995182514190674
2025-12-09 11:57:47.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 9.979147530479056e-05 Training loss: 7.436007499694824
2025-12-09 11:57:47.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 9.978868767432954e-05 Training loss: 7.520694732666016
2025-12-09 11:57:47.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 9.978588157383277e-05 Training loss: 7.252113342285156
2025-12-09 11:57:47.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 9.978305700434125e-05 Training loss: 7.330478191375732
2025-12-09 11:57:48.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 9.97802139669028e-05 Training loss: 7.400696754455566
2025-12-09 11:57:48.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 9.97773524625721e-05 Training loss: 7.146157264709473
2025-12-09 11:57:48.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 9.977447249241066e-05 Training loss: 7.3700408935546875
2025-12-09 11:57:48.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 9.977157405748687e-05 Training loss: 7.120455265045166
2025-12-09 11:57:48.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 9.976865715887595e-05 Training loss: 7.175747871398926
2025-12-09 11:57:48.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 9.976572179765999e-05 Training loss: 7.169113636016846
2025-12-09 11:57:48.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 9.976276797492793e-05 Training loss: 7.2894110679626465
2025-12-09 11:57:48.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 9.975979569177552e-05 Training loss: 7.2020697593688965
2025-12-09 11:57:49.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 9.975680494930538e-05 Training loss: 7.492094993591309
2025-12-09 11:57:49.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 9.9753795748627e-05 Training loss: 7.736581325531006
2025-12-09 11:57:49.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 9.975076809085669e-05 Training loss: 7.051456451416016
2025-12-09 11:57:49.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 9.974772197711761e-05 Training loss: 7.294482707977295
2025-12-09 11:57:49.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 9.97446574085398e-05 Training loss: 7.630684852600098
2025-12-09 11:57:49.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 9.974157438626008e-05 Training loss: 7.393791675567627
2025-12-09 11:57:49.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 9.973847291142218e-05 Training loss: 6.996034145355225
2025-12-09 11:57:50.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 9.973535298517663e-05 Training loss: 7.610676288604736
2025-12-09 11:57:50.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 9.973221460868086e-05 Training loss: 7.4989094734191895
2025-12-09 11:57:50.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 9.972905778309906e-05 Training loss: 7.485886573791504
2025-12-09 11:57:50.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 9.972588250960234e-05 Training loss: 7.3458943367004395
2025-12-09 11:57:50.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 9.972268878936863e-05 Training loss: 7.396247386932373
2025-12-09 11:57:50.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 9.97194766235827e-05 Training loss: 7.1093597412109375
2025-12-09 11:57:50.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 9.971624601343615e-05 Training loss: 7.2115912437438965
2025-12-09 11:57:50.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 9.971299696012743e-05 Training loss: 7.3473005294799805
2025-12-09 11:57:51.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 9.970972946486185e-05 Training loss: 7.517838001251221
2025-12-09 11:57:51.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 9.970644352885157e-05 Training loss: 7.313090801239014
2025-12-09 11:57:51.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 9.970313915331553e-05 Training loss: 7.161703109741211
2025-12-09 11:57:51.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 9.969981633947956e-05 Training loss: 7.454007625579834
2025-12-09 11:57:51.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 9.969647508857631e-05 Training loss: 7.296258449554443
2025-12-09 11:57:51.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 9.969311540184532e-05 Training loss: 7.2616496086120605
2025-12-09 11:57:51.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 9.968973728053288e-05 Training loss: 6.993233680725098
2025-12-09 11:57:52.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 9.968634072589218e-05 Training loss: 7.187115669250488
2025-12-09 11:57:52.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 9.968292573918325e-05 Training loss: 7.507740497589111
2025-12-09 11:57:52.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 9.967949232167294e-05 Training loss: 7.288326740264893
2025-12-09 11:57:52.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 9.967604047463493e-05 Training loss: 7.006239414215088
2025-12-09 11:57:52.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 9.967257019934975e-05 Training loss: 7.4978156089782715
2025-12-09 11:57:52.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 9.966908149710476e-05 Training loss: 6.494487762451172
2025-12-09 11:57:52.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 9.966557436919416e-05 Training loss: 7.371699810028076
2025-12-09 11:57:52.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 9.966204881691898e-05 Training loss: 6.712113857269287
2025-12-09 11:57:53.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 9.965850484158711e-05 Training loss: 6.246139049530029
2025-12-09 11:57:53.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 9.965494244451324e-05 Training loss: 7.376897811889648
2025-12-09 11:57:53.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 9.96513616270189e-05 Training loss: 7.149404048919678
2025-12-09 11:57:53.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 9.964776239043246e-05 Training loss: 7.258501052856445
2025-12-09 11:57:53.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 9.964414473608912e-05 Training loss: 6.396061420440674
2025-12-09 11:57:53.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 9.964050866533094e-05 Training loss: 7.078734397888184
2025-12-09 11:57:53.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 9.963685417950677e-05 Training loss: 7.144811630249023
2025-12-09 11:57:54.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 9.96331812799723e-05 Training loss: 6.866636753082275
2025-12-09 11:57:54.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 9.962948996809008e-05 Training loss: 7.034787178039551
2025-12-09 11:57:54.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 9.962578024522948e-05 Training loss: 7.228332996368408
2025-12-09 11:57:54.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 9.962205211276665e-05 Training loss: 7.348635673522949
2025-12-09 11:57:54.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 9.961830557208464e-05 Training loss: 8.055850982666016
2025-12-09 11:57:54.662 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 9.961454062457329e-05 Training loss: 6.955918312072754
2025-12-09 11:57:54.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 9.961075727162928e-05 Training loss: 7.023338317871094
2025-12-09 11:57:54.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 9.960695551465611e-05 Training loss: 7.170572757720947
2025-12-09 11:57:55.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 9.960313535506411e-05 Training loss: 7.15117073059082
2025-12-09 11:57:55.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 9.959929679427047e-05 Training loss: 7.104955196380615
2025-12-09 11:57:55.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 9.959543983369912e-05 Training loss: 6.717082977294922
2025-12-09 11:57:55.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 9.959156447478091e-05 Training loss: 7.102162837982178
2025-12-09 11:57:55.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 9.958767071895347e-05 Training loss: 7.352577209472656
2025-12-09 11:57:55.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 9.958375856766127e-05 Training loss: 6.979311466217041
2025-12-09 11:57:55.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 9.957982802235556e-05 Training loss: 7.097249984741211
2025-12-09 11:57:55.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 9.957587908449448e-05 Training loss: 7.166380882263184
2025-12-09 11:57:56.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 9.957191175554294e-05 Training loss: 7.167508602142334
2025-12-09 11:57:56.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 9.956792603697273e-05 Training loss: 7.595554351806641
2025-12-09 11:57:56.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 9.956392193026239e-05 Training loss: 7.486525535583496
2025-12-09 11:57:56.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 9.955989943689734e-05 Training loss: 7.3216352462768555
2025-12-09 11:57:56.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 9.955585855836978e-05 Training loss: 6.966623783111572
2025-12-09 11:57:56.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 9.955179929617875e-05 Training loss: 7.963873863220215
2025-12-09 11:57:56.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 9.954772165183013e-05 Training loss: 6.994626998901367
2025-12-09 11:57:57.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 9.954362562683658e-05 Training loss: 7.157822608947754
2025-12-09 11:57:57.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 9.95395112227176e-05 Training loss: 6.67520809173584
2025-12-09 11:57:57.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 9.95353784409995e-05 Training loss: 7.03367805480957
2025-12-09 11:57:57.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 9.953122728321542e-05 Training loss: 7.020949363708496
2025-12-09 11:57:57.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 9.952705775090529e-05 Training loss: 7.136720180511475
2025-12-09 11:57:57.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 9.952286984561592e-05 Training loss: 7.042449474334717
2025-12-09 11:57:57.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 9.951866356890084e-05 Training loss: 6.146900653839111
2025-12-09 11:57:57.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 9.951443892232047e-05 Training loss: 7.282291412353516
2025-12-09 11:57:58.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 9.951019590744203e-05 Training loss: 7.145144939422607
2025-12-09 11:57:58.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 9.950593452583952e-05 Training loss: 7.190146446228027
2025-12-09 11:57:58.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 9.95016547790938e-05 Training loss: 7.097532749176025
2025-12-09 11:57:58.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 9.949735666879252e-05 Training loss: 7.457273006439209
2025-12-09 11:57:58.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 9.949304019653012e-05 Training loss: 6.961640357971191
2025-12-09 11:57:58.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 9.94887053639079e-05 Training loss: 6.9899444580078125
2025-12-09 11:57:58.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 9.948435217253393e-05 Training loss: 7.453649044036865
2025-12-09 11:57:59.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 9.947998062402313e-05 Training loss: 7.13655424118042
2025-12-09 11:57:59.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 9.947559071999719e-05 Training loss: 7.217369556427002
2025-12-09 11:57:59.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 9.947118246208462e-05 Training loss: 7.461833477020264
2025-12-09 11:57:59.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 9.946675585192075e-05 Training loss: 6.987400054931641
2025-12-09 11:57:59.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 9.946231089114774e-05 Training loss: 7.052767276763916
2025-12-09 11:57:59.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 9.945784758141448e-05 Training loss: 6.945354461669922
2025-12-09 11:57:59.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 9.945336592437678e-05 Training loss: 7.324432849884033
2025-12-09 11:58:00.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 9.944886592169713e-05 Training loss: 7.026764392852783
2025-12-09 11:58:00.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 9.944434757504492e-05 Training loss: 6.759068489074707
2025-12-09 11:58:00.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 9.94398108860963e-05 Training loss: 6.904333591461182
2025-12-09 11:58:00.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 9.943525585653428e-05 Training loss: 7.403304100036621
2025-12-09 11:58:00.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 9.94306824880486e-05 Training loss: 7.277830123901367
2025-12-09 11:58:00.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 9.942609078233581e-05 Training loss: 7.14279317855835
2025-12-09 11:58:00.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 9.942148074109934e-05 Training loss: 7.287108421325684
2025-12-09 11:58:00.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 9.941685236604934e-05 Training loss: 7.071829795837402
2025-12-09 11:58:01.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 9.941220565890279e-05 Training loss: 6.903158187866211
2025-12-09 11:58:01.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 9.94075406213835e-05 Training loss: 7.42385721206665
2025-12-09 11:58:01.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 9.940285725522203e-05 Training loss: 6.968172073364258
2025-12-09 11:58:01.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 9.939815556215575e-05 Training loss: 7.854931354522705
2025-12-09 11:58:01.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 9.939343554392886e-05 Training loss: 6.8612141609191895
2025-12-09 11:58:01.734 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 9.938869720229234e-05 Training loss: 6.945045471191406
2025-12-09 11:58:01.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 9.938394053900395e-05 Training loss: 6.859571933746338
2025-12-09 11:58:01.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 9.937916555582828e-05 Training loss: 7.1368608474731445
2025-12-09 11:58:02.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 9.937437225453669e-05 Training loss: 7.174140453338623
2025-12-09 11:58:02.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 9.936956063690733e-05 Training loss: 7.827453136444092
2025-12-09 11:58:02.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 9.936473070472518e-05 Training loss: 6.966213226318359
2025-12-09 11:58:02.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 9.935988245978199e-05 Training loss: 7.364627838134766
2025-12-09 11:58:02.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 9.935501590387628e-05 Training loss: 7.28662633895874
2025-12-09 11:58:02.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 9.935013103881343e-05 Training loss: 6.816360950469971
2025-12-09 11:58:02.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 9.934522786640555e-05 Training loss: 6.90017032623291
2025-12-09 11:58:03.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 9.934030638847155e-05 Training loss: 6.914398670196533
2025-12-09 11:58:03.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 9.933536660683717e-05 Training loss: 7.420283317565918
2025-12-09 11:58:03.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 9.933040852333488e-05 Training loss: 7.159262180328369
2025-12-09 11:58:03.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 9.9325432139804e-05 Training loss: 6.904821872711182
2025-12-09 11:58:03.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 9.932043745809063e-05 Training loss: 6.791374683380127
2025-12-09 11:58:03.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 9.93154244800476e-05 Training loss: 6.848004341125488
2025-12-09 11:58:03.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.931039320753456e-05 Training loss: 6.802274227142334
2025-12-09 11:58:04.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 9.9305343642418e-05 Training loss: 6.1545329093933105
2025-12-09 11:58:04.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 9.930027578657113e-05 Training loss: 6.835149765014648
2025-12-09 11:58:04.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 9.929518964187395e-05 Training loss: 7.477100849151611
2025-12-09 11:58:04.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 9.929008521021325e-05 Training loss: 7.282159328460693
2025-12-09 11:58:04.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 9.928496249348265e-05 Training loss: 6.777239799499512
2025-12-09 11:58:04.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 9.92798214935825e-05 Training loss: 7.053509712219238
2025-12-09 11:58:04.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 9.927466221241996e-05 Training loss: 6.479123115539551
2025-12-09 11:58:04.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 9.926948465190892e-05 Training loss: 7.121148109436035
2025-12-09 11:58:05.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 9.926428881397015e-05 Training loss: 6.740291118621826
2025-12-09 11:58:05.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 9.925907470053111e-05 Training loss: 6.890580654144287
2025-12-09 11:58:05.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 9.925384231352606e-05 Training loss: 6.972421169281006
2025-12-09 11:58:05.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 9.924859165489608e-05 Training loss: 6.844672679901123
2025-12-09 11:58:05.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 9.924332272658898e-05 Training loss: 7.109844207763672
2025-12-09 11:58:05.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 9.923803553055937e-05 Training loss: 6.986715793609619
2025-12-09 11:58:05.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 9.923273006876865e-05 Training loss: 7.519983768463135
2025-12-09 11:58:05.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 9.922740634318495e-05 Training loss: 6.5456953048706055
2025-12-09 11:58:06.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 9.922206435578323e-05 Training loss: 6.97835636138916
2025-12-09 11:58:06.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 9.921670410854518e-05 Training loss: 6.6711201667785645
2025-12-09 11:58:06.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 9.92113256034593e-05 Training loss: 7.059864044189453
2025-12-09 11:58:06.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 9.920592884252082e-05 Training loss: 7.066532611846924
2025-12-09 11:58:06.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 9.920051382773179e-05 Training loss: 7.303539276123047
2025-12-09 11:58:06.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 9.919508056110102e-05 Training loss: 7.366818904876709
2025-12-09 11:58:06.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 9.918962904464407e-05 Training loss: 7.140793800354004
2025-12-09 11:58:07.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 9.918415928038325e-05 Training loss: 7.075247764587402
2025-12-09 11:58:07.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 9.917867127034772e-05 Training loss: 7.032847881317139
2025-12-09 11:58:07.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 9.917316501657334e-05 Training loss: 6.807161331176758
2025-12-09 11:58:07.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 9.916764052110274e-05 Training loss: 7.130211353302002
2025-12-09 11:58:07.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 9.916209778598535e-05 Training loss: 6.563636779785156
2025-12-09 11:58:07.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 9.915653681327737e-05 Training loss: 7.0649237632751465
2025-12-09 11:58:07.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 9.915095760504169e-05 Training loss: 6.621163368225098
2025-12-09 11:58:07.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 9.914536016334808e-05 Training loss: 7.585535049438477
2025-12-09 11:58:08.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 9.913974449027298e-05 Training loss: 6.911890029907227
2025-12-09 11:58:08.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 9.913411058789963e-05 Training loss: 7.0244669914245605
2025-12-09 11:58:08.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 9.912845845831805e-05 Training loss: 7.029130935668945
2025-12-09 11:58:08.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 9.912278810362498e-05 Training loss: 7.169125556945801
2025-12-09 11:58:08.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 9.911709952592397e-05 Training loss: 7.360884666442871
2025-12-09 11:58:08.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 9.911139272732526e-05 Training loss: 7.164026737213135
2025-12-09 11:58:08.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 9.910566770994594e-05 Training loss: 7.07269287109375
2025-12-09 11:58:09.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 9.909992447590979e-05 Training loss: 6.782312870025635
2025-12-09 11:58:09.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 9.909416302734736e-05 Training loss: 6.953774452209473
2025-12-09 11:58:09.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 9.908838336639597e-05 Training loss: 6.6797590255737305
2025-12-09 11:58:09.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 9.908258549519971e-05 Training loss: 7.082310676574707
2025-12-09 11:58:09.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 9.907676941590939e-05 Training loss: 7.613663673400879
2025-12-09 11:58:09.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 9.907093513068259e-05 Training loss: 6.992173671722412
2025-12-09 11:58:09.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 9.906508264168366e-05 Training loss: 7.442356586456299
2025-12-09 11:58:09.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 9.905921195108368e-05 Training loss: 7.163409233093262
2025-12-09 11:58:10.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 9.90533230610605e-05 Training loss: 6.903024673461914
2025-12-09 11:58:10.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 9.90474159737987e-05 Training loss: 6.8212971687316895
2025-12-09 11:58:10.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 9.904149069148963e-05 Training loss: 6.725666522979736
2025-12-09 11:58:10.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 9.903554721633139e-05 Training loss: 6.917799949645996
2025-12-09 11:58:10.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 9.902958555052882e-05 Training loss: 6.904211044311523
2025-12-09 11:58:10.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 9.902360569629349e-05 Training loss: 6.639390468597412
2025-12-09 11:58:10.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 9.901760765584375e-05 Training loss: 6.745560646057129
2025-12-09 11:58:11.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 9.901159143140471e-05 Training loss: 7.122737407684326
2025-12-09 11:58:11.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 9.900555702520816e-05 Training loss: 6.757495880126953
2025-12-09 11:58:11.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 9.89995044394927e-05 Training loss: 6.940248966217041
2025-12-09 11:58:11.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 9.899343367650365e-05 Training loss: 6.525867938995361
2025-12-09 11:58:11.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 9.898734473849305e-05 Training loss: 6.766597747802734
2025-12-09 11:58:11.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 9.898123762771971e-05 Training loss: 6.852272987365723
2025-12-09 11:58:11.819 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 9.89751123464492e-05 Training loss: 7.015379428863525
2025-12-09 11:58:11.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 9.896896889695378e-05 Training loss: 6.723658084869385
2025-12-09 11:58:12.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 9.896280728151248e-05 Training loss: 6.797286510467529
2025-12-09 11:58:12.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 9.895662750241108e-05 Training loss: 7.086207389831543
2025-12-09 11:58:12.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 9.89504295619421e-05 Training loss: 6.84187126159668
2025-12-09 11:58:12.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 9.894421346240473e-05 Training loss: 7.024752616882324
2025-12-09 11:58:12.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 9.893797920610496e-05 Training loss: 6.730753421783447
2025-12-09 11:58:12.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 9.893172679535553e-05 Training loss: 6.849332809448242
2025-12-09 11:58:12.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 9.892545623247586e-05 Training loss: 7.136153221130371
2025-12-09 11:58:13.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 9.891916751979218e-05 Training loss: 6.771117687225342
2025-12-09 11:58:13.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 9.891286065963734e-05 Training loss: 6.728635311126709
2025-12-09 11:58:13.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 9.890653565435101e-05 Training loss: 6.91156530380249
2025-12-09 11:58:13.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 9.89001925062796e-05 Training loss: 6.653972148895264
2025-12-09 11:58:13.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 9.889383121777617e-05 Training loss: 6.65187406539917
2025-12-09 11:58:13.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 9.88874517912006e-05 Training loss: 7.2303009033203125
2025-12-09 11:58:13.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 9.888105422891943e-05 Training loss: 6.5512542724609375
2025-12-09 11:58:13.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 9.887463853330594e-05 Training loss: 6.880410194396973
2025-12-09 11:58:14.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 9.886820470674018e-05 Training loss: 7.005861759185791
2025-12-09 11:58:14.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 9.88617527516089e-05 Training loss: 6.681546688079834
2025-12-09 11:58:14.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 9.885528267030557e-05 Training loss: 6.8335862159729
2025-12-09 11:58:14.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 9.884879446523035e-05 Training loss: 7.087092399597168
2025-12-09 11:58:14.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 9.88422881387902e-05 Training loss: 6.729354381561279
2025-12-09 11:58:14.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 9.883576369339875e-05 Training loss: 7.2489447593688965
2025-12-09 11:58:14.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 9.882922113147637e-05 Training loss: 7.604700565338135
2025-12-09 11:58:15.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 9.882266045545012e-05 Training loss: 7.311307907104492
2025-12-09 11:58:15.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 9.881608166775383e-05 Training loss: 7.120318412780762
2025-12-09 11:58:15.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 9.880948477082804e-05 Training loss: 6.555830001831055
2025-12-09 11:58:15.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 9.880286976711992e-05 Training loss: 7.0111846923828125
2025-12-09 11:58:15.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 9.87962366590835e-05 Training loss: 6.793332576751709
2025-12-09 11:58:15.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 9.878958544917942e-05 Training loss: 6.814214706420898
2025-12-09 11:58:15.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 9.87829161398751e-05 Training loss: 6.570484638214111
2025-12-09 11:58:15.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 9.87762287336446e-05 Training loss: 6.848060607910156
2025-12-09 11:58:16.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 9.876952323296877e-05 Training loss: 6.885112762451172
2025-12-09 11:58:16.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 9.876279964033512e-05 Training loss: 6.871891498565674
2025-12-09 11:58:16.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 9.87560579582379e-05 Training loss: 7.176794528961182
2025-12-09 11:58:16.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 9.874929818917806e-05 Training loss: 7.134247303009033
2025-12-09 11:58:16.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 9.874252033566327e-05 Training loss: 6.831822395324707
2025-12-09 11:58:16.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 9.87357244002079e-05 Training loss: 6.421219825744629
2025-12-09 11:58:16.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 9.8728910385333e-05 Training loss: 6.927199363708496
2025-12-09 11:58:16.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 9.872207829356641e-05 Training loss: 6.650744915008545
2025-12-09 11:58:17.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 9.871522812744256e-05 Training loss: 6.646908760070801
2025-12-09 11:58:17.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 9.870835988950268e-05 Training loss: 7.344549655914307
2025-12-09 11:58:17.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 9.870147358229467e-05 Training loss: 7.436823844909668
2025-12-09 11:58:17.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 9.869456920837312e-05 Training loss: 6.690093994140625
2025-12-09 11:58:17.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 9.868764677029934e-05 Training loss: 6.847703456878662
2025-12-09 11:58:17.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 9.868070627064135e-05 Training loss: 6.576296329498291
2025-12-09 11:58:17.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 9.867374771197383e-05 Training loss: 7.09814453125
2025-12-09 11:58:18.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 9.866677109687822e-05 Training loss: 6.858487129211426
2025-12-09 11:58:18.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 9.86597764279426e-05 Training loss: 6.946013927459717
2025-12-09 11:58:18.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 9.865276370776177e-05 Training loss: 7.082106590270996
2025-12-09 11:58:18.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 9.864573293893725e-05 Training loss: 6.631976127624512
2025-12-09 11:58:18.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 9.863868412407721e-05 Training loss: 6.9261956214904785
2025-12-09 11:58:18.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 9.863161726579655e-05 Training loss: 6.846278190612793
2025-12-09 11:58:18.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 9.862453236671685e-05 Training loss: 7.17305326461792
2025-12-09 11:58:18.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 9.861742942946639e-05 Training loss: 7.155831336975098
2025-12-09 11:58:19.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 9.861030845668014e-05 Training loss: 7.236730575561523
2025-12-09 11:58:19.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 9.860316945099973e-05 Training loss: 6.269207000732422
2025-12-09 11:58:19.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 9.859601241507353e-05 Training loss: 6.712277412414551
2025-12-09 11:58:19.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 9.858883735155657e-05 Training loss: 6.629607200622559
2025-12-09 11:58:19.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 9.858164426311059e-05 Training loss: 7.025750637054443
2025-12-09 11:58:19.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 9.857443315240397e-05 Training loss: 6.653988361358643
2025-12-09 11:58:19.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 9.856720402211182e-05 Training loss: 6.793638706207275
2025-12-09 11:58:20.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 9.855995687491591e-05 Training loss: 7.173320770263672
2025-12-09 11:58:20.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 9.855269171350471e-05 Training loss: 6.4739603996276855
2025-12-09 11:58:20.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 9.854540854057337e-05 Training loss: 7.299199104309082
2025-12-09 11:58:20.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 9.85381073588237e-05 Training loss: 7.289359092712402
2025-12-09 11:58:20.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 9.853078817096424e-05 Training loss: 7.002792835235596
2025-12-09 11:58:20.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 9.852345097971016e-05 Training loss: 7.134862422943115
2025-12-09 11:58:20.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 9.851609578778332e-05 Training loss: 7.0596818923950195
2025-12-09 11:58:20.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 9.850872259791228e-05 Training loss: 6.809314250946045
2025-12-09 11:58:21.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 9.850133141283226e-05 Training loss: 6.614190578460693
2025-12-09 11:58:21.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 9.849392223528514e-05 Training loss: 6.96136474609375
2025-12-09 11:58:21.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 9.84864950680195e-05 Training loss: 6.608044147491455
2025-12-09 11:58:21.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 9.84790499137906e-05 Training loss: 7.3006157875061035
2025-12-09 11:58:21.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 9.847158677536034e-05 Training loss: 7.152731895446777
2025-12-09 11:58:21.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 9.84641056554973e-05 Training loss: 6.986096382141113
2025-12-09 11:58:21.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 9.845660655697679e-05 Training loss: 6.960428237915039
2025-12-09 11:58:22.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 9.844908948258067e-05 Training loss: 6.831304550170898
2025-12-09 11:58:22.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 9.844155443509759e-05 Training loss: 6.908234596252441
2025-12-09 11:58:22.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 9.84340014173228e-05 Training loss: 7.026753902435303
2025-12-09 11:58:22.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 9.842643043205822e-05 Training loss: 7.0078630447387695
2025-12-09 11:58:22.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 9.841884148211247e-05 Training loss: 7.0872344970703125
2025-12-09 11:58:22.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 9.84112345703008e-05 Training loss: 6.685581684112549
2025-12-09 11:58:22.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 9.84036096994451e-05 Training loss: 6.6200151443481445
2025-12-09 11:58:22.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 9.839596687237403e-05 Training loss: 6.632592678070068
2025-12-09 11:58:23.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 9.838830609192277e-05 Training loss: 7.87579345703125
2025-12-09 11:58:23.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 9.838062736093328e-05 Training loss: 7.353219985961914
2025-12-09 11:58:23.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 9.837293068225408e-05 Training loss: 6.617096900939941
2025-12-09 11:58:23.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 9.836521605874044e-05 Training loss: 6.692335605621338
2025-12-09 11:58:23.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 9.835748349325422e-05 Training loss: 6.7921037673950195
2025-12-09 11:58:23.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 9.834973298866395e-05 Training loss: 7.442142009735107
2025-12-09 11:58:23.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 9.834196454784485e-05 Training loss: 6.86769962310791
2025-12-09 11:58:24.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 9.833417817367874e-05 Training loss: 6.889784336090088
2025-12-09 11:58:24.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 9.832637386905412e-05 Training loss: 7.121029376983643
2025-12-09 11:58:24.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 9.831855163686618e-05 Training loss: 6.961062908172607
2025-12-09 11:58:24.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 9.831071148001667e-05 Training loss: 6.9824910163879395
2025-12-09 11:58:24.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 9.830285340141408e-05 Training loss: 6.427636623382568
2025-12-09 11:58:24.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 9.829497740397349e-05 Training loss: 6.871574401855469
2025-12-09 11:58:24.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 9.828708349061664e-05 Training loss: 6.855907440185547
2025-12-09 11:58:24.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 9.827917166427195e-05 Training loss: 6.81779146194458
2025-12-09 11:58:25.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 9.827124192787444e-05 Training loss: 5.863516330718994
2025-12-09 11:58:25.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 9.82632942843658e-05 Training loss: 7.372718811035156
2025-12-09 11:58:25.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 9.825532873669435e-05 Training loss: 6.748238563537598
2025-12-09 11:58:25.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 9.824734528781505e-05 Training loss: 6.536512851715088
2025-12-09 11:58:25.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 9.823934394068952e-05 Training loss: 7.131877422332764
2025-12-09 11:58:25.739 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 9.823132469828601e-05 Training loss: 6.80369758605957
2025-12-09 11:58:25.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 9.822328756357942e-05 Training loss: 6.845089912414551
2025-12-09 11:58:26.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 9.821523253955122e-05 Training loss: 6.869593143463135
2025-12-09 11:58:26.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 9.820715962918964e-05 Training loss: 6.5875325202941895
2025-12-09 11:58:26.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 9.819906883548943e-05 Training loss: 6.9649858474731445
2025-12-09 11:58:26.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 9.819096016145203e-05 Training loss: 7.042397499084473
2025-12-09 11:58:26.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 9.81828336100855e-05 Training loss: 6.626626491546631
2025-12-09 11:58:26.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 9.817468918440454e-05 Training loss: 7.472657203674316
2025-12-09 11:58:26.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 9.816652688743049e-05 Training loss: 7.327666282653809
2025-12-09 11:58:26.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 9.815834672219127e-05 Training loss: 6.8741559982299805
2025-12-09 11:58:27.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 9.815014869172149e-05 Training loss: 6.812949180603027
2025-12-09 11:58:27.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 9.814193279906237e-05 Training loss: 7.3673481941223145
2025-12-09 11:58:27.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 9.81336990472617e-05 Training loss: 6.137852191925049
2025-12-09 11:58:27.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 9.8125447439374e-05 Training loss: 7.345660209655762
2025-12-09 11:58:27.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 9.811717797846033e-05 Training loss: 6.826103687286377
2025-12-09 11:58:27.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 9.81088906675884e-05 Training loss: 6.962007999420166
2025-12-09 11:58:27.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 9.810058550983254e-05 Training loss: 6.504824161529541
2025-12-09 11:58:27.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 9.809226250827371e-05 Training loss: 6.382596492767334
2025-12-09 11:58:28.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 9.808392166599948e-05 Training loss: 5.751303195953369
2025-12-09 11:58:28.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 9.807556298610404e-05 Training loss: 6.765973091125488
2025-12-09 11:58:28.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 9.806718647168818e-05 Training loss: 6.856298923492432
2025-12-09 11:58:28.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 9.805879212585933e-05 Training loss: 6.979004859924316
2025-12-09 11:58:28.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 9.805037995173155e-05 Training loss: 6.982579231262207
2025-12-09 11:58:28.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 9.804194995242548e-05 Training loss: 6.674861907958984
2025-12-09 11:58:28.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 9.803350213106836e-05 Training loss: 6.944133758544922
2025-12-09 11:58:29.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 9.802503649079411e-05 Training loss: 6.713926792144775
2025-12-09 11:58:29.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 9.801655303474318e-05 Training loss: 6.68861198425293
2025-12-09 11:58:29.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 9.80080517660627e-05 Training loss: 7.154351711273193
2025-12-09 11:58:29.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 9.799953268790633e-05 Training loss: 6.516645431518555
2025-12-09 11:58:29.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 9.799099580343441e-05 Training loss: 6.924363136291504
2025-12-09 11:58:29.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 9.798244111581382e-05 Training loss: 7.007630825042725
2025-12-09 11:58:29.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 9.797386862821813e-05 Training loss: 6.631745338439941
2025-12-09 11:58:29.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 9.796527834382745e-05 Training loss: 6.699329376220703
2025-12-09 11:58:30.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 9.795667026582847e-05 Training loss: 6.564159870147705
2025-12-09 11:58:30.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 9.794804439741456e-05 Training loss: 6.866763591766357
2025-12-09 11:58:30.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 9.79394007417856e-05 Training loss: 7.317873477935791
2025-12-09 11:58:30.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 9.793073930214817e-05 Training loss: 6.712386131286621
2025-12-09 11:58:30.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 9.792206008171533e-05 Training loss: 6.679441928863525
2025-12-09 11:58:30.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 9.791336308370687e-05 Training loss: 6.876049995422363
2025-12-09 11:58:30.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 9.790464831134903e-05 Training loss: 6.208228588104248
2025-12-09 11:58:31.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 9.789591576787476e-05 Training loss: 7.009117603302002
2025-12-09 11:58:31.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 9.788716545652353e-05 Training loss: 6.870438098907471
2025-12-09 11:58:31.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 9.787839738054146e-05 Training loss: 5.722658157348633
2025-12-09 11:58:31.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 9.786961154318121e-05 Training loss: 6.7608866691589355
2025-12-09 11:58:31.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 9.786080794770207e-05 Training loss: 6.514794826507568
2025-12-09 11:58:31.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 9.785198659736988e-05 Training loss: 6.5366387367248535
2025-12-09 11:58:31.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 9.784314749545707e-05 Training loss: 6.8431196212768555
2025-12-09 11:58:31.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 9.78342906452427e-05 Training loss: 6.74320125579834
2025-12-09 11:58:32.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 9.782541605001235e-05 Training loss: 7.152538299560547
2025-12-09 11:58:32.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 9.781652371305824e-05 Training loss: 5.9849467277526855
2025-12-09 11:58:32.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 9.780761363767914e-05 Training loss: 7.119777679443359
2025-12-09 11:58:32.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 9.779868582718041e-05 Training loss: 6.619010925292969
2025-12-09 11:58:32.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 9.778974028487398e-05 Training loss: 6.696942329406738
2025-12-09 11:58:32.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 9.778077701407837e-05 Training loss: 6.492534637451172
2025-12-09 11:58:32.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 9.777179601811867e-05 Training loss: 7.589662075042725
2025-12-09 11:58:33.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 9.776279730032654e-05 Training loss: 6.367037773132324
2025-12-09 11:58:33.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 9.775378086404023e-05 Training loss: 6.982028961181641
2025-12-09 11:58:33.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 9.774474671260457e-05 Training loss: 6.908581733703613
2025-12-09 11:58:33.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 9.77356948493709e-05 Training loss: 6.830528736114502
2025-12-09 11:58:33.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 9.77266252776972e-05 Training loss: 7.529296398162842
2025-12-09 11:58:33.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 9.771753800094803e-05 Training loss: 6.503760814666748
2025-12-09 11:58:33.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 9.770843302249443e-05 Training loss: 6.979055404663086
2025-12-09 11:58:33.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 9.769931034571408e-05 Training loss: 6.372653007507324
2025-12-09 11:58:34.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 9.76901699739912e-05 Training loss: 6.991969108581543
2025-12-09 11:58:34.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 9.768101191071661e-05 Training loss: 6.837868690490723
2025-12-09 11:58:34.376 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 9.767183615928765e-05 Training loss: 6.751780033111572
2025-12-09 11:58:34.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 9.766264272310822e-05 Training loss: 6.437783241271973
2025-12-09 11:58:34.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 9.765343160558879e-05 Training loss: 6.424837589263916
2025-12-09 11:58:34.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 9.764420281014642e-05 Training loss: 5.715467929840088
2025-12-09 11:58:34.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 9.763495634020467e-05 Training loss: 6.872989654541016
2025-12-09 11:58:35.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 9.762569219919372e-05 Training loss: 6.702643394470215
2025-12-09 11:58:35.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 9.761641039055026e-05 Training loss: 6.520061492919922
2025-12-09 11:58:35.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 9.760711091771755e-05 Training loss: 6.807140827178955
2025-12-09 11:58:35.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 9.759779378414542e-05 Training loss: 6.95611047744751
2025-12-09 11:58:35.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 9.758845899329021e-05 Training loss: 7.098390579223633
2025-12-09 11:58:35.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 9.757910654861483e-05 Training loss: 6.87119722366333
2025-12-09 11:58:35.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 9.756973645358876e-05 Training loss: 6.516587257385254
2025-12-09 11:58:35.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 9.7560348711688e-05 Training loss: 6.703334808349609
2025-12-09 11:58:36.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 9.755094332639512e-05 Training loss: 7.160772800445557
2025-12-09 11:58:36.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 9.754152030119921e-05 Training loss: 6.631410121917725
2025-12-09 11:58:36.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 9.75320796395959e-05 Training loss: 6.677167892456055
2025-12-09 11:58:36.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 9.752262134508742e-05 Training loss: 5.692044258117676
2025-12-09 11:58:36.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 9.751314542118246e-05 Training loss: 6.76406717300415
2025-12-09 11:58:36.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 9.750365187139632e-05 Training loss: 6.753148555755615
2025-12-09 11:58:36.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 9.749414069925078e-05 Training loss: 6.816843032836914
2025-12-09 11:58:37.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 9.74846119082742e-05 Training loss: 6.472335338592529
2025-12-09 11:58:37.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 9.747506550200146e-05 Training loss: 6.6498589515686035
2025-12-09 11:58:37.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 9.746550148397398e-05 Training loss: 7.209900856018066
2025-12-09 11:58:37.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 9.745591985773971e-05 Training loss: 7.070281028747559
2025-12-09 11:58:37.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 9.744632062685311e-05 Training loss: 6.873435974121094
2025-12-09 11:58:37.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 9.743670379487522e-05 Training loss: 6.667647838592529
2025-12-09 11:58:37.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 9.742706936537358e-05 Training loss: 7.135715007781982
2025-12-09 11:58:37.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 9.741741734192224e-05 Training loss: 6.843263149261475
2025-12-09 11:58:38.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 9.740774772810182e-05 Training loss: 6.8653669357299805
2025-12-09 11:58:38.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 9.739806052749943e-05 Training loss: 7.3989386558532715
2025-12-09 11:58:38.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 9.738835574370871e-05 Training loss: 6.671631336212158
2025-12-09 11:58:38.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 9.737863338032985e-05 Training loss: 6.887812614440918
2025-12-09 11:58:38.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 9.736889344096952e-05 Training loss: 5.561546325683594
2025-12-09 11:58:38.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 9.735913592924093e-05 Training loss: 6.182898044586182
2025-12-09 11:58:38.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 9.734936084876383e-05 Training loss: 6.693870544433594
2025-12-09 11:58:39.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 9.733956820316444e-05 Training loss: 6.984302520751953
2025-12-09 11:58:39.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 9.732975799607555e-05 Training loss: 6.761662483215332
2025-12-09 11:58:39.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 9.731993023113642e-05 Training loss: 7.061807155609131
2025-12-09 11:58:39.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 9.731008491199284e-05 Training loss: 6.682724475860596
2025-12-09 11:58:39.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 9.730022204229714e-05 Training loss: 6.593185901641846
2025-12-09 11:58:39.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 9.729034162570811e-05 Training loss: 6.700758457183838
2025-12-09 11:58:39.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 9.728044366589108e-05 Training loss: 6.698999881744385
2025-12-09 11:58:39.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 9.727052816651788e-05 Training loss: 6.805421352386475
2025-12-09 11:58:40.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 9.726059513126685e-05 Training loss: 6.035464286804199
2025-12-09 11:58:40.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 9.725064456382283e-05 Training loss: 7.1326727867126465
2025-12-09 11:58:40.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 9.724067646787717e-05 Training loss: 6.645845890045166
2025-12-09 11:58:40.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 9.723069084712772e-05 Training loss: 6.35807991027832
2025-12-09 11:58:40.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 9.722068770527883e-05 Training loss: 6.671358108520508
2025-12-09 11:58:40.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 9.721066704604134e-05 Training loss: 6.900519847869873
2025-12-09 11:58:40.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 9.720062887313261e-05 Training loss: 6.683053493499756
2025-12-09 11:58:41.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 9.71905731902765e-05 Training loss: 6.6826491355896
2025-12-09 11:58:41.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 9.718050000120334e-05 Training loss: 6.6714959144592285
2025-12-09 11:58:41.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 9.717040930964995e-05 Training loss: 6.70261287689209
2025-12-09 11:58:41.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 9.716030111935967e-05 Training loss: 6.703032493591309
2025-12-09 11:58:41.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 9.715017543408233e-05 Training loss: 7.437222003936768
2025-12-09 11:58:41.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 9.714003225757424e-05 Training loss: 7.342932224273682
2025-12-09 11:58:41.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 9.712987159359818e-05 Training loss: 6.440367698669434
2025-12-09 11:58:41.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 9.711969344592346e-05 Training loss: 6.536821365356445
2025-12-09 11:58:42.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 9.710949781832585e-05 Training loss: 6.580696105957031
2025-12-09 11:58:42.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 9.709928471458759e-05 Training loss: 7.221097946166992
2025-12-09 11:58:42.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 9.708905413849743e-05 Training loss: 6.471004009246826
2025-12-09 11:58:42.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 9.707880609385059e-05 Training loss: 6.932465553283691
2025-12-09 11:58:42.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 9.706854058444876e-05 Training loss: 6.7544660568237305
2025-12-09 11:58:42.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 9.705825761410014e-05 Training loss: 6.290647506713867
2025-12-09 11:58:42.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 9.704795718661939e-05 Training loss: 6.579319953918457
2025-12-09 11:58:43.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 9.703763930582761e-05 Training loss: 6.751395225524902
2025-12-09 11:58:43.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 9.702730397555247e-05 Training loss: 7.1127519607543945
2025-12-09 11:58:43.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 9.7016951199628e-05 Training loss: 6.697425365447998
2025-12-09 11:58:43.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 9.700658098189475e-05 Training loss: 7.026671886444092
2025-12-09 11:58:43.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 9.69961933261998e-05 Training loss: 6.724151134490967
2025-12-09 11:58:43.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 9.698578823639659e-05 Training loss: 6.697884559631348
2025-12-09 11:58:43.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 9.697536571634509e-05 Training loss: 6.724366188049316
2025-12-09 11:58:43.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 9.696492576991174e-05 Training loss: 6.921086311340332
2025-12-09 11:58:44.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 9.695446840096944e-05 Training loss: 6.786365509033203
2025-12-09 11:58:44.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 9.694399361339752e-05 Training loss: 6.901047229766846
2025-12-09 11:58:44.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 9.693350141108182e-05 Training loss: 6.753592014312744
2025-12-09 11:58:44.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 9.692299179791459e-05 Training loss: 6.497702598571777
2025-12-09 11:58:44.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 9.69124647777946e-05 Training loss: 7.245876789093018
2025-12-09 11:58:44.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 9.690192035462702e-05 Training loss: 7.310575008392334
2025-12-09 11:58:44.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 9.689135853232349e-05 Training loss: 6.710145473480225
2025-12-09 11:58:45.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 9.688077931480212e-05 Training loss: 6.765429496765137
2025-12-09 11:58:45.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 9.687018270598749e-05 Training loss: 7.647744655609131
2025-12-09 11:58:45.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 9.685956870981058e-05 Training loss: 6.33074426651001
2025-12-09 11:58:45.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 9.684893733020888e-05 Training loss: 7.040675163269043
2025-12-09 11:58:45.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 9.683828857112627e-05 Training loss: 6.341652870178223
2025-12-09 11:58:45.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 9.682762243651308e-05 Training loss: 6.763451099395752
2025-12-09 11:58:45.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 9.681693893032618e-05 Training loss: 7.440788269042969
2025-12-09 11:58:45.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 9.680623805652876e-05 Training loss: 6.551554203033447
2025-12-09 11:58:46.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 9.679551981909053e-05 Training loss: 6.743480682373047
2025-12-09 11:58:46.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 9.67847842219876e-05 Training loss: 6.352529048919678
2025-12-09 11:58:46.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 9.677403126920256e-05 Training loss: 6.533418655395508
2025-12-09 11:58:46.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 9.676326096472441e-05 Training loss: 6.148078918457031
2025-12-09 11:58:46.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 9.675247331254858e-05 Training loss: 6.525641441345215
2025-12-09 11:58:46.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 9.674166831667697e-05 Training loss: 6.286558151245117
2025-12-09 11:58:46.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 9.673084598111789e-05 Training loss: 6.643375396728516
2025-12-09 11:58:47.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 9.672000630988605e-05 Training loss: 6.721625328063965
2025-12-09 11:58:47.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 9.670914930700267e-05 Training loss: 6.87216854095459
2025-12-09 11:58:47.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 9.669827497649536e-05 Training loss: 6.382967472076416
2025-12-09 11:58:47.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 9.668738332239813e-05 Training loss: 6.4672160148620605
2025-12-09 11:58:47.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 9.667647434875145e-05 Training loss: 6.32840633392334
2025-12-09 11:58:47.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 9.66655480596022e-05 Training loss: 6.788444519042969
2025-12-09 11:58:47.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 9.665460445900368e-05 Training loss: 6.835482120513916
2025-12-09 11:58:47.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 9.664364355101565e-05 Training loss: 6.814599990844727
2025-12-09 11:58:48.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 9.663266533970424e-05 Training loss: 6.767668724060059
2025-12-09 11:58:48.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 9.662166982914203e-05 Training loss: 6.876009941101074
2025-12-09 11:58:48.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 9.661065702340801e-05 Training loss: 6.66388463973999
2025-12-09 11:58:48.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 9.659962692658758e-05 Training loss: 6.7456183433532715
2025-12-09 11:58:48.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 9.658857954277254e-05 Training loss: 6.428355693817139
2025-12-09 11:58:48.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 9.657751487606115e-05 Training loss: 6.497432231903076
2025-12-09 11:58:48.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 9.656643293055804e-05 Training loss: 6.81856632232666
2025-12-09 11:58:49.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 9.655533371037426e-05 Training loss: 7.335843563079834
2025-12-09 11:58:49.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 9.65442172196273e-05 Training loss: 6.729017734527588
2025-12-09 11:58:49.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 9.653308346244098e-05 Training loss: 6.623913764953613
2025-12-09 11:58:49.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 9.652193244294562e-05 Training loss: 7.500526428222656
2025-12-09 11:58:49.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 9.651076416527787e-05 Training loss: 6.596665859222412
2025-12-09 11:58:49.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 9.64995786335808e-05 Training loss: 6.621098041534424
2025-12-09 11:58:49.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 9.648837585200393e-05 Training loss: 6.800987243652344
2025-12-09 11:58:50.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 9.64771558247031e-05 Training loss: 6.792128562927246
2025-12-09 11:58:50.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 9.64659185558406e-05 Training loss: 6.625694751739502
2025-12-09 11:58:50.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 9.64546640495851e-05 Training loss: 6.761484622955322
2025-12-09 11:58:50.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 9.644339231011168e-05 Training loss: 6.613680362701416
2025-12-09 11:58:50.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 9.643210334160177e-05 Training loss: 6.399632930755615
2025-12-09 11:58:50.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 9.642079714824328e-05 Training loss: 6.523263931274414
2025-12-09 11:58:50.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 9.64094737342304e-05 Training loss: 6.756138324737549
