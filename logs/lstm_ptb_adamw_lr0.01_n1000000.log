2025-12-09 12:04:10.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 0.0001 Training loss: 9.20436954498291
2025-12-09 12:04:10.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 0.0002 Training loss: 9.203845024108887
2025-12-09 12:04:10.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 0.0003 Training loss: 9.20042896270752
2025-12-09 12:04:10.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.0004 Training loss: 9.194469451904297
2025-12-09 12:04:10.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.0005 Training loss: 9.180693626403809
2025-12-09 12:04:10.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.0006 Training loss: 9.162062644958496
2025-12-09 12:04:10.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.0007000000000000001 Training loss: 9.132651329040527
2025-12-09 12:04:10.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.0008 Training loss: 9.07766056060791
2025-12-09 12:04:11.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.0009 Training loss: 8.891289710998535
2025-12-09 12:04:11.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.001 Training loss: 8.499991416931152
2025-12-09 12:04:11.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.0011 Training loss: 7.954373359680176
2025-12-09 12:04:11.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.0012 Training loss: 7.4146528244018555
2025-12-09 12:04:11.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.0013000000000000002 Training loss: 7.085751533508301
2025-12-09 12:04:11.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.0014000000000000002 Training loss: 6.868657112121582
2025-12-09 12:04:11.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.0015 Training loss: 6.723479270935059
2025-12-09 12:04:11.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.0016 Training loss: 6.896402835845947
2025-12-09 12:04:11.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.0017000000000000001 Training loss: 6.888359069824219
2025-12-09 12:04:11.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.0018 Training loss: 6.947624206542969
2025-12-09 12:04:11.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.0019 Training loss: 7.029740333557129
2025-12-09 12:04:11.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.002 Training loss: 6.945425987243652
2025-12-09 12:04:11.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.0021 Training loss: 7.117844104766846
2025-12-09 12:04:11.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.0022 Training loss: 7.098738670349121
2025-12-09 12:04:11.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0023 Training loss: 6.995744705200195
2025-12-09 12:04:11.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0024 Training loss: 6.912787914276123
2025-12-09 12:04:11.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.0025 Training loss: 7.010916709899902
2025-12-09 12:04:11.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0026000000000000003 Training loss: 7.068184852600098
2025-12-09 12:04:11.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0027 Training loss: 6.990671157836914
2025-12-09 12:04:11.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0028000000000000004 Training loss: 7.010786533355713
2025-12-09 12:04:11.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.0029 Training loss: 7.026779651641846
2025-12-09 12:04:11.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.003 Training loss: 7.101102352142334
2025-12-09 12:04:11.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.0031 Training loss: 6.967899799346924
2025-12-09 12:04:11.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.0032 Training loss: 6.976363182067871
2025-12-09 12:04:11.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.0033000000000000004 Training loss: 6.982227325439453
2025-12-09 12:04:11.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.0034000000000000002 Training loss: 7.084316730499268
2025-12-09 12:04:11.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.0034999999999999996 Training loss: 6.991450786590576
2025-12-09 12:04:11.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.0036 Training loss: 7.084311008453369
2025-12-09 12:04:11.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.0037 Training loss: 7.11817741394043
2025-12-09 12:04:11.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.0038 Training loss: 7.11536979675293
2025-12-09 12:04:11.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.0039000000000000003 Training loss: 7.074993133544922
2025-12-09 12:04:11.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.004 Training loss: 7.002956390380859
2025-12-09 12:04:11.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.0040999999999999995 Training loss: 7.003382205963135
2025-12-09 12:04:11.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.0042 Training loss: 7.089687824249268
2025-12-09 12:04:11.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.0043 Training loss: 6.993752479553223
2025-12-09 12:04:11.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.0044 Training loss: 7.113613128662109
2025-12-09 12:04:11.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.0045000000000000005 Training loss: 7.114232540130615
2025-12-09 12:04:11.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0046 Training loss: 7.07330846786499
2025-12-09 12:04:11.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.0047 Training loss: 7.033651351928711
2025-12-09 12:04:11.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0048 Training loss: 7.100823879241943
2025-12-09 12:04:11.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.0049 Training loss: 7.105159282684326
2025-12-09 12:04:11.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.005 Training loss: 7.109808921813965
2025-12-09 12:04:11.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0051 Training loss: 6.962384223937988
2025-12-09 12:04:11.677 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.005200000000000001 Training loss: 7.110578536987305
2025-12-09 12:04:11.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0053 Training loss: 7.009326457977295
2025-12-09 12:04:11.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0054 Training loss: 7.04449462890625
2025-12-09 12:04:11.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0055000000000000005 Training loss: 7.035348892211914
2025-12-09 12:04:11.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.005600000000000001 Training loss: 7.035664081573486
2025-12-09 12:04:11.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.005699999999999999 Training loss: 7.099505424499512
2025-12-09 12:04:11.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.0058 Training loss: 7.099474906921387
2025-12-09 12:04:11.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0059 Training loss: 7.080123424530029
2025-12-09 12:04:11.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.006 Training loss: 7.000962257385254
2025-12-09 12:04:11.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.0061 Training loss: 7.079909801483154
2025-12-09 12:04:11.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.0062 Training loss: 7.1234822273254395
2025-12-09 12:04:11.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.0063 Training loss: 7.1272292137146
2025-12-09 12:04:11.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.0064 Training loss: 7.108482360839844
2025-12-09 12:04:11.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.006500000000000001 Training loss: 7.038355350494385
2025-12-09 12:04:11.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.006600000000000001 Training loss: 7.2524518966674805
2025-12-09 12:04:11.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.0067 Training loss: 7.086324691772461
2025-12-09 12:04:11.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.0068000000000000005 Training loss: 7.112554550170898
2025-12-09 12:04:11.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.0069 Training loss: 7.168956279754639
2025-12-09 12:04:11.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.006999999999999999 Training loss: 7.162772178649902
2025-12-09 12:04:11.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.0070999999999999995 Training loss: 7.146013259887695
2025-12-09 12:04:11.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0072 Training loss: 7.034452438354492
2025-12-09 12:04:12.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.0073 Training loss: 7.187313556671143
2025-12-09 12:04:12.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.0074 Training loss: 7.225828170776367
2025-12-09 12:04:12.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0075 Training loss: 7.155353546142578
2025-12-09 12:04:12.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.0076 Training loss: 7.204015254974365
2025-12-09 12:04:12.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0077 Training loss: 7.180032730102539
2025-12-09 12:04:12.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0078000000000000005 Training loss: 7.123750686645508
2025-12-09 12:04:12.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.0079 Training loss: 7.299188137054443
2025-12-09 12:04:12.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.008 Training loss: 7.265347480773926
2025-12-09 12:04:12.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.008100000000000001 Training loss: 7.275278568267822
2025-12-09 12:04:12.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.008199999999999999 Training loss: 7.20993709564209
2025-12-09 12:04:12.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.0083 Training loss: 7.249151229858398
2025-12-09 12:04:12.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.0084 Training loss: 7.316743850708008
2025-12-09 12:04:12.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.0085 Training loss: 7.258840560913086
2025-12-09 12:04:12.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.0086 Training loss: 7.203760147094727
2025-12-09 12:04:12.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.0087 Training loss: 7.189537525177002
2025-12-09 12:04:12.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.0088 Training loss: 7.353734016418457
2025-12-09 12:04:12.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0089 Training loss: 7.278975963592529
2025-12-09 12:04:12.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.009000000000000001 Training loss: 7.238102436065674
2025-12-09 12:04:12.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0091 Training loss: 7.2588911056518555
2025-12-09 12:04:12.295 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0092 Training loss: 7.321264743804932
2025-12-09 12:04:12.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.009300000000000001 Training loss: 7.462705612182617
2025-12-09 12:04:12.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.0094 Training loss: 7.317253112792969
2025-12-09 12:04:12.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.0095 Training loss: 7.360952854156494
2025-12-09 12:04:12.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0096 Training loss: 7.3530378341674805
2025-12-09 12:04:12.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0097 Training loss: 7.305195331573486
2025-12-09 12:04:12.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.0098 Training loss: 7.292384624481201
2025-12-09 12:04:12.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.0099 Training loss: 7.310821056365967
2025-12-09 12:04:12.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.01 Training loss: 7.439445495605469
2025-12-09 12:04:12.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.009698463103929543 Training loss: 7.373385906219482
2025-12-09 12:04:12.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.00883022221559489 Training loss: 7.380871772766113
2025-12-09 12:04:12.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0075 Training loss: 7.446134090423584
2025-12-09 12:04:12.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.005868240888334653 Training loss: 7.297813415527344
2025-12-09 12:04:12.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0041317591116653484 Training loss: 7.462462902069092
2025-12-09 12:04:12.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0025000000000000014 Training loss: 7.315382480621338
2025-12-09 12:04:12.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0011697777844051104 Training loss: 7.153946399688721
2025-12-09 12:04:12.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.00030153689607045843 Training loss: 7.102310657501221
2025-12-09 12:04:12.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0 Training loss: 7.129591464996338
