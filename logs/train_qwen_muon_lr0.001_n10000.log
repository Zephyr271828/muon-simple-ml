2025-12-09 06:29:20.330 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.116342544555664
2025-12-09 06:29:20.848 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.116877555847168
2025-12-09 06:29:21.354 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.108124732971191
2025-12-09 06:29:21.860 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 12.129400253295898
2025-12-09 06:29:22.365 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 12.10183048248291
2025-12-09 06:29:22.869 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 12.059013366699219
2025-12-09 06:29:23.374 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 12.066671371459961
2025-12-09 06:29:23.881 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 12.053584098815918
2025-12-09 06:29:24.385 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 12.002582550048828
2025-12-09 06:29:24.892 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 11.971059799194336
2025-12-09 06:29:25.397 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 11.928885459899902
2025-12-09 06:29:25.903 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 11.877546310424805
2025-12-09 06:29:26.408 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 11.79122543334961
2025-12-09 06:29:26.913 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 11.747114181518555
2025-12-09 06:29:27.420 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 11.662969589233398
2025-12-09 06:29:27.923 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 11.536468505859375
2025-12-09 06:29:28.430 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 11.46602725982666
2025-12-09 06:29:28.935 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 11.318635940551758
2025-12-09 06:29:29.441 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 11.152777671813965
2025-12-09 06:29:29.946 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 11.110660552978516
2025-12-09 06:29:30.451 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 10.762877464294434
2025-12-09 06:29:30.955 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 10.69394302368164
2025-12-09 06:29:31.460 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 10.407730102539062
2025-12-09 06:29:31.965 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 10.195449829101562
2025-12-09 06:29:32.472 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 9.926923751831055
2025-12-09 06:29:32.977 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 9.758774757385254
2025-12-09 06:29:33.482 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 9.546778678894043
2025-12-09 06:29:33.987 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 9.346651077270508
2025-12-09 06:29:34.493 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 9.015697479248047
2025-12-09 06:29:34.998 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 8.85280990600586
2025-12-09 06:29:35.503 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 8.656216621398926
2025-12-09 06:29:36.007 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 8.574960708618164
2025-12-09 06:29:36.513 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 8.308713912963867
2025-12-09 06:29:37.018 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 8.138708114624023
2025-12-09 06:29:37.522 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 8.16897201538086
2025-12-09 06:29:38.028 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 8.214497566223145
2025-12-09 06:29:38.531 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 8.002928733825684
2025-12-09 06:29:39.035 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 7.719184875488281
2025-12-09 06:29:39.540 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 8.26900863647461
2025-12-09 06:29:40.045 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 8.178377151489258
2025-12-09 06:29:40.552 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 7.866079807281494
2025-12-09 06:29:41.056 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 7.766022682189941
2025-12-09 06:29:41.561 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 7.960513114929199
2025-12-09 06:29:42.065 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 7.697634220123291
2025-12-09 06:29:42.568 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 7.921100616455078
2025-12-09 06:29:43.072 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 7.813446044921875
2025-12-09 06:29:43.575 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 7.682936668395996
2025-12-09 06:29:44.081 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 7.8150153160095215
2025-12-09 06:29:44.586 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 7.770563125610352
2025-12-09 06:29:45.091 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 7.522376537322998
2025-12-09 06:29:45.596 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 8.002930641174316
2025-12-09 06:29:46.099 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 7.780301570892334
2025-12-09 06:29:46.606 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 7.7610321044921875
2025-12-09 06:29:47.111 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 7.943402290344238
2025-12-09 06:29:47.616 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 8.039873123168945
2025-12-09 06:29:48.121 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 7.723792552947998
2025-12-09 06:29:48.628 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 7.543587684631348
2025-12-09 06:29:49.133 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 7.756563186645508
2025-12-09 06:29:49.639 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 7.420205116271973
2025-12-09 06:29:50.144 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 7.823761463165283
2025-12-09 06:29:50.649 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 7.651045799255371
2025-12-09 06:29:51.154 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 7.469245433807373
2025-12-09 06:29:51.659 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 7.587036609649658
2025-12-09 06:29:52.164 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 7.866040229797363
2025-12-09 06:29:52.670 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 7.814622402191162
2025-12-09 06:29:53.175 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 7.62641716003418
2025-12-09 06:29:53.682 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 7.355491638183594
2025-12-09 06:29:54.187 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 7.7820611000061035
2025-12-09 06:29:54.694 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 7.7273077964782715
2025-12-09 06:29:55.200 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 7.568475723266602
2025-12-09 06:29:55.705 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 7.599614143371582
2025-12-09 06:29:56.212 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 7.703836441040039
2025-12-09 06:29:56.717 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 7.32199764251709
2025-12-09 06:29:57.223 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 7.4129133224487305
2025-12-09 06:29:57.728 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 7.454483985900879
2025-12-09 06:29:58.233 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 7.290021896362305
2025-12-09 06:29:58.739 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 7.307305335998535
2025-12-09 06:29:59.245 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 7.2446489334106445
2025-12-09 06:29:59.753 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 7.451361656188965
2025-12-09 06:30:00.259 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 7.321106433868408
2025-12-09 06:30:00.766 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 7.293147563934326
2025-12-09 06:30:01.273 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 6.831362247467041
2025-12-09 06:30:01.779 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 7.189730644226074
2025-12-09 06:30:02.286 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 7.163190841674805
2025-12-09 06:30:02.792 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 7.008025646209717
2025-12-09 06:30:03.297 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 7.233152389526367
2025-12-09 06:30:03.803 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 7.212646007537842
2025-12-09 06:30:04.309 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 6.993469715118408
2025-12-09 06:30:04.813 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 7.293636322021484
2025-12-09 06:30:05.320 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 6.964263439178467
2025-12-09 06:30:05.827 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 7.11272668838501
2025-12-09 06:30:06.333 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 7.184266090393066
2025-12-09 06:30:06.839 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 6.825060844421387
2025-12-09 06:30:07.346 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 7.207716464996338
2025-12-09 06:30:07.851 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 6.875274181365967
2025-12-09 06:30:08.356 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 6.892500400543213
2025-12-09 06:30:08.863 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 7.00841760635376
2025-12-09 06:30:09.369 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 6.651056289672852
2025-12-09 06:30:09.876 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 6.926379680633545
2025-12-09 06:30:10.383 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 6.798862934112549
2025-12-09 06:30:10.888 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 100 LR: 0.0009999983285747596 Training loss: 7.017972946166992
2025-12-09 06:30:11.395 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 101 LR: 0.0009999933143102129 Training loss: 6.722943305969238
2025-12-09 06:30:11.901 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 102 LR: 0.000999984957239884 Training loss: 6.892018795013428
2025-12-09 06:30:12.405 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 103 LR: 0.0009999732574196452 Training loss: 7.163273811340332
2025-12-09 06:30:12.910 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 104 LR: 0.0009999582149277186 Training loss: 6.713996410369873
2025-12-09 06:30:13.415 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 105 LR: 0.0009999398298646738 Training loss: 7.009433269500732
2025-12-09 06:30:13.921 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 106 LR: 0.0009999181023534274 Training loss: 6.747503757476807
2025-12-09 06:30:14.428 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 107 LR: 0.0009998930325392434 Training loss: 6.883190631866455
2025-12-09 06:30:14.935 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 108 LR: 0.000999864620589731 Training loss: 6.756165504455566
2025-12-09 06:30:15.443 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 109 LR: 0.0009998328666948437 Training loss: 6.747577667236328
2025-12-09 06:30:15.948 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 110 LR: 0.0009997977710668792 Training loss: 6.820046901702881
2025-12-09 06:30:16.454 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 111 LR: 0.0009997593339404756 Training loss: 6.781250476837158
2025-12-09 06:30:16.960 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 112 LR: 0.0009997175555726127 Training loss: 6.925004482269287
2025-12-09 06:30:17.466 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 113 LR: 0.0009996724362426074 Training loss: 6.755500793457031
2025-12-09 06:30:17.971 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 114 LR: 0.000999623976252115 Training loss: 6.7600998878479
2025-12-09 06:30:18.477 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 115 LR: 0.0009995721759251239 Training loss: 6.977629661560059
2025-12-09 06:30:18.984 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 116 LR: 0.0009995170356079557 Training loss: 7.032373428344727
2025-12-09 06:30:19.490 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 117 LR: 0.0009994585556692623 Training loss: 6.4545488357543945
2025-12-09 06:30:19.996 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 118 LR: 0.0009993967365000227 Training loss: 6.990739345550537
2025-12-09 06:30:20.503 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 119 LR: 0.0009993315785135415 Training loss: 6.621821880340576
2025-12-09 06:30:21.008 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 120 LR: 0.0009992630821454458 Training loss: 6.791906356811523
2025-12-09 06:30:21.514 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 121 LR: 0.0009991912478536816 Training loss: 6.788209915161133
2025-12-09 06:30:22.021 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 122 LR: 0.0009991160761185114 Training loss: 6.552758693695068
2025-12-09 06:30:22.527 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 123 LR: 0.0009990375674425109 Training loss: 6.797916889190674
2025-12-09 06:30:23.034 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 124 LR: 0.000998955722350566 Training loss: 6.824532985687256
2025-12-09 06:30:23.541 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 125 LR: 0.0009988705413898683 Training loss: 6.626457214355469
2025-12-09 06:30:24.047 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 126 LR: 0.0009987820251299122 Training loss: 6.951217174530029
2025-12-09 06:30:24.553 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 127 LR: 0.0009986901741624908 Training loss: 6.8834967613220215
2025-12-09 06:30:25.061 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 128 LR: 0.0009985949891016925 Training loss: 6.74041223526001
2025-12-09 06:30:25.568 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 129 LR: 0.000998496470583896 Training loss: 6.606372356414795
2025-12-09 06:30:26.075 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 130 LR: 0.0009983946192677667 Training loss: 6.714237689971924
2025-12-09 06:30:26.581 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 131 LR: 0.000998289435834252 Training loss: 6.61438512802124
2025-12-09 06:30:27.088 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 132 LR: 0.000998180920986577 Training loss: 6.678038120269775
2025-12-09 06:30:27.595 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 133 LR: 0.0009980690754502392 Training loss: 6.676041126251221
2025-12-09 06:30:28.104 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 134 LR: 0.0009979538999730047 Training loss: 6.859891414642334
2025-12-09 06:30:28.610 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 135 LR: 0.0009978353953249022 Training loss: 6.687777996063232
2025-12-09 06:30:29.117 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 136 LR: 0.0009977135622982185 Training loss: 6.893641948699951
2025-12-09 06:30:29.623 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 137 LR: 0.0009975884017074926 Training loss: 6.768707275390625
2025-12-09 06:30:30.130 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 138 LR: 0.0009974599143895107 Training loss: 6.671888828277588
2025-12-09 06:30:30.637 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 139 LR: 0.0009973281012033007 Training loss: 6.384809494018555
2025-12-09 06:30:31.145 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 140 LR: 0.0009971929630301264 Training loss: 6.473389625549316
2025-12-09 06:30:31.651 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 141 LR: 0.0009970545007734807 Training loss: 6.672591209411621
2025-12-09 06:30:32.157 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 142 LR: 0.0009969127153590812 Training loss: 6.585361480712891
2025-12-09 06:30:32.664 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 143 LR: 0.0009967676077348628 Training loss: 6.673216342926025
2025-12-09 06:30:33.172 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 144 LR: 0.0009966191788709714 Training loss: 6.3591485023498535
2025-12-09 06:30:33.679 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 145 LR: 0.0009964674297597584 Training loss: 6.545261383056641
2025-12-09 06:30:34.186 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 146 LR: 0.0009963123614157728 Training loss: 6.70952844619751
2025-12-09 06:30:34.694 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 147 LR: 0.0009961539748757548 Training loss: 6.729162216186523
2025-12-09 06:30:35.200 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 148 LR: 0.00099599227119863 Training loss: 6.636107921600342
2025-12-09 06:30:35.706 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 149 LR: 0.0009958272514655007 Training loss: 6.997057914733887
2025-12-09 06:30:36.212 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 150 LR: 0.0009956589167796391 Training loss: 6.694056034088135
2025-12-09 06:30:36.719 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 151 LR: 0.000995487268266481 Training loss: 6.664320945739746
2025-12-09 06:30:37.225 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 152 LR: 0.000995312307073617 Training loss: 6.728961944580078
2025-12-09 06:30:37.731 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 153 LR: 0.0009951340343707852 Training loss: 6.441093444824219
2025-12-09 06:30:38.239 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 154 LR: 0.0009949524513498636 Training loss: 6.7123613357543945
2025-12-09 06:30:38.745 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 155 LR: 0.0009947675592248619 Training loss: 6.807971477508545
2025-12-09 06:30:39.250 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 156 LR: 0.0009945793592319135 Training loss: 6.706089973449707
2025-12-09 06:30:39.755 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 157 LR: 0.0009943878526292675 Training loss: 6.242629051208496
2025-12-09 06:30:40.262 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 158 LR: 0.0009941930406972797 Training loss: 6.644195079803467
2025-12-09 06:30:40.769 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 159 LR: 0.0009939949247384046 Training loss: 6.394998550415039
2025-12-09 06:30:41.275 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 160 LR: 0.0009937935060771858 Training loss: 6.566801071166992
2025-12-09 06:30:41.780 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 161 LR: 0.0009935887860602487 Training loss: 6.37938117980957
2025-12-09 06:30:42.286 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 162 LR: 0.0009933807660562897 Training loss: 6.595104217529297
2025-12-09 06:30:42.792 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 163 LR: 0.0009931694474560684 Training loss: 6.482468605041504
2025-12-09 06:30:43.298 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 164 LR: 0.0009929548316723982 Training loss: 6.601807594299316
2025-12-09 06:30:43.803 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 165 LR: 0.0009927369201401357 Training loss: 6.601203441619873
2025-12-09 06:30:44.309 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 166 LR: 0.0009925157143161724 Training loss: 6.780970573425293
2025-12-09 06:30:44.814 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 167 LR: 0.0009922912156794242 Training loss: 6.5147905349731445
2025-12-09 06:30:45.320 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 168 LR: 0.0009920634257308217 Training loss: 6.450717449188232
2025-12-09 06:30:45.826 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 169 LR: 0.0009918323459933004 Training loss: 6.674407958984375
2025-12-09 06:30:46.333 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 170 LR: 0.0009915979780117908 Training loss: 6.544033527374268
2025-12-09 06:30:46.842 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 171 LR: 0.0009913603233532068 Training loss: 6.5788254737854
2025-12-09 06:30:47.348 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 172 LR: 0.000991119383606436 Training loss: 6.597067356109619
2025-12-09 06:30:47.853 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 173 LR: 0.0009908751603823302 Training loss: 6.285754203796387
2025-12-09 06:30:48.359 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 174 LR: 0.0009906276553136924 Training loss: 6.498919486999512
2025-12-09 06:30:48.866 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 175 LR: 0.0009903768700552675 Training loss: 6.441333770751953
2025-12-09 06:30:49.373 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 176 LR: 0.000990122806283731 Training loss: 6.584496974945068
2025-12-09 06:30:49.880 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 177 LR: 0.000989865465697677 Training loss: 6.534862995147705
2025-12-09 06:30:50.388 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 178 LR: 0.000989604850017608 Training loss: 6.600459575653076
2025-12-09 06:30:50.896 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 179 LR: 0.0009893409609859221 Training loss: 6.368947505950928
2025-12-09 06:30:51.404 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 180 LR: 0.0009890738003669028 Training loss: 6.452103614807129
2025-12-09 06:30:51.911 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 181 LR: 0.000988803369946706 Training loss: 6.70009708404541
2025-12-09 06:30:52.418 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 182 LR: 0.0009885296715333488 Training loss: 6.612001895904541
2025-12-09 06:30:52.924 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 183 LR: 0.0009882527069566965 Training loss: 6.815769672393799
2025-12-09 06:30:53.434 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 184 LR: 0.0009879724780684517 Training loss: 6.396687984466553
2025-12-09 06:30:53.941 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 185 LR: 0.0009876889867421411 Training loss: 6.305079936981201
2025-12-09 06:30:54.449 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 186 LR: 0.0009874022348731028 Training loss: 6.3007283210754395
2025-12-09 06:30:54.954 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 187 LR: 0.000987112224378474 Training loss: 6.582096099853516
2025-12-09 06:30:55.460 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 188 LR: 0.0009868189571971783 Training loss: 6.432522773742676
2025-12-09 06:30:55.966 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 189 LR: 0.0009865224352899118 Training loss: 6.4411301612854
2025-12-09 06:30:56.474 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 190 LR: 0.0009862226606391323 Training loss: 6.439727306365967
2025-12-09 06:30:56.983 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 191 LR: 0.0009859196352490424 Training loss: 6.21989631652832
2025-12-09 06:30:57.492 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 192 LR: 0.0009856133611455802 Training loss: 6.250848770141602
2025-12-09 06:30:58.000 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 193 LR: 0.000985303840376402 Training loss: 6.756260395050049
2025-12-09 06:30:58.507 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 194 LR: 0.0009849910750108718 Training loss: 6.492710113525391
2025-12-09 06:30:59.013 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 195 LR: 0.0009846750671400446 Training loss: 6.700652599334717
2025-12-09 06:30:59.521 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 196 LR: 0.000984355818876655 Training loss: 6.2502851486206055
2025-12-09 06:31:00.027 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 197 LR: 0.0009840333323551014 Training loss: 6.312800884246826
2025-12-09 06:31:00.533 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 198 LR: 0.000983707609731432 Training loss: 6.256222248077393
2025-12-09 06:31:01.041 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 199 LR: 0.000983378653183331 Training loss: 6.57323694229126
2025-12-09 06:31:01.550 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 200 LR: 0.0009830464649101035 Training loss: 6.44638204574585
2025-12-09 06:31:02.057 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 201 LR: 0.000982711047132661 Training loss: 6.341508388519287
2025-12-09 06:31:02.562 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 202 LR: 0.0009823724020935065 Training loss: 6.54835319519043
2025-12-09 06:31:03.069 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 203 LR: 0.000982030532056719 Training loss: 6.155842304229736
2025-12-09 06:31:03.577 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 204 LR: 0.0009816854393079402 Training loss: 6.306351184844971
2025-12-09 06:31:04.084 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 205 LR: 0.0009813371261543564 Training loss: 6.371088981628418
2025-12-09 06:31:04.591 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 206 LR: 0.0009809855949246852 Training loss: 6.474634647369385
2025-12-09 06:31:05.098 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 207 LR: 0.0009806308479691594 Training loss: 6.303302764892578
2025-12-09 06:31:05.604 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 208 LR: 0.0009802728876595111 Training loss: 6.535948753356934
2025-12-09 06:31:06.113 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 209 LR: 0.000979911716388956 Training loss: 6.025048732757568
2025-12-09 06:31:06.619 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 210 LR: 0.000979547336572177 Training loss: 6.0898118019104
2025-12-09 06:31:07.126 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 211 LR: 0.0009791797506453084 Training loss: 6.305805683135986
2025-12-09 06:31:07.632 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 212 LR: 0.0009788089610659203 Training loss: 6.1900129318237305
2025-12-09 06:31:08.139 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 213 LR: 0.0009784349703130008 Training loss: 6.166955947875977
2025-12-09 06:31:08.647 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 214 LR: 0.0009780577808869398 Training loss: 6.596085071563721
2025-12-09 06:31:09.153 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 215 LR: 0.0009776773953095136 Training loss: 6.273273468017578
2025-12-09 06:31:09.659 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 216 LR: 0.000977293816123866 Training loss: 6.451337814331055
2025-12-09 06:31:10.168 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 217 LR: 0.0009769070458944928 Training loss: 6.434126377105713
2025-12-09 06:31:10.675 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 218 LR: 0.0009765170872072244 Training loss: 6.485489845275879
2025-12-09 06:31:11.181 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 219 LR: 0.0009761239426692076 Training loss: 6.445631504058838
2025-12-09 06:31:11.686 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 220 LR: 0.0009757276149088896 Training loss: 6.464045524597168
2025-12-09 06:31:12.193 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 221 LR: 0.0009753281065759988 Training loss: 6.174381256103516
2025-12-09 06:31:12.700 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 222 LR: 0.0009749254203415288 Training loss: 6.307826995849609
2025-12-09 06:31:13.207 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 223 LR: 0.0009745195588977192 Training loss: 6.120899200439453
2025-12-09 06:31:13.714 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 224 LR: 0.0009741105249580382 Training loss: 6.218282699584961
2025-12-09 06:31:14.220 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 225 LR: 0.0009736983212571646 Training loss: 6.343192100524902
2025-12-09 06:31:14.726 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 226 LR: 0.000973282950550969 Training loss: 6.3412275314331055
2025-12-09 06:31:15.232 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 227 LR: 0.0009728644156164958 Training loss: 6.178679943084717
2025-12-09 06:31:15.740 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 228 LR: 0.000972442719251944 Training loss: 6.353629112243652
2025-12-09 06:31:16.246 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 229 LR: 0.00097201786427665 Training loss: 6.239922046661377
2025-12-09 06:31:16.754 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 230 LR: 0.0009715898535310668 Training loss: 6.239296913146973
2025-12-09 06:31:17.260 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 231 LR: 0.0009711586898767462 Training loss: 6.401379585266113
2025-12-09 06:31:17.768 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 232 LR: 0.0009707243761963195 Training loss: 6.10394287109375
2025-12-09 06:31:18.276 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 233 LR: 0.0009702869153934781 Training loss: 6.150032997131348
2025-12-09 06:31:18.784 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 234 LR: 0.0009698463103929542 Training loss: 6.422966957092285
2025-12-09 06:31:19.291 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 235 LR: 0.0009694025641405011 Training loss: 6.28596830368042
2025-12-09 06:31:19.797 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 236 LR: 0.0009689556796028733 Training loss: 6.208000183105469
2025-12-09 06:31:20.303 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 237 LR: 0.0009685056597678075 Training loss: 6.393467903137207
2025-12-09 06:31:20.809 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 238 LR: 0.0009680525076440014 Training loss: 6.111340045928955
2025-12-09 06:31:21.313 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 239 LR: 0.0009675962262610949 Training loss: 6.409978866577148
2025-12-09 06:31:21.818 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 240 LR: 0.0009671368186696487 Training loss: 6.25543212890625
2025-12-09 06:31:22.324 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 241 LR: 0.0009666742879411247 Training loss: 6.160175323486328
2025-12-09 06:31:22.831 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 242 LR: 0.0009662086371678649 Training loss: 6.559408664703369
2025-12-09 06:31:23.338 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 243 LR: 0.0009657398694630713 Training loss: 6.3812103271484375
2025-12-09 06:31:23.844 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 244 LR: 0.0009652679879607843 Training loss: 6.4662981033325195
2025-12-09 06:31:24.351 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 245 LR: 0.0009647929958158627 Training loss: 6.181790828704834
2025-12-09 06:31:24.858 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 246 LR: 0.0009643148962039621 Training loss: 6.1926069259643555
2025-12-09 06:31:25.364 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 247 LR: 0.0009638336923215134 Training loss: 6.13532829284668
2025-12-09 06:31:25.873 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 248 LR: 0.0009633493873857018 Training loss: 6.073739051818848
2025-12-09 06:31:26.379 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 249 LR: 0.0009628619846344453 Training loss: 6.336163520812988
2025-12-09 06:31:26.885 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 250 LR: 0.0009623714873263729 Training loss: 6.175967216491699
2025-12-09 06:31:27.390 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 251 LR: 0.000961877898740803 Training loss: 6.1903815269470215
2025-12-09 06:31:27.895 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 252 LR: 0.0009613812221777212 Training loss: 5.98799991607666
2025-12-09 06:31:28.400 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 253 LR: 0.0009608814609577585 Training loss: 6.276057243347168
2025-12-09 06:31:28.908 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 254 LR: 0.0009603786184221692 Training loss: 6.267941474914551
2025-12-09 06:31:29.414 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 255 LR: 0.0009598726979328079 Training loss: 6.086759567260742
2025-12-09 06:31:29.920 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 256 LR: 0.0009593637028721076 Training loss: 6.196647644042969
2025-12-09 06:31:30.428 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 257 LR: 0.0009588516366430573 Training loss: 6.147960662841797
2025-12-09 06:31:30.936 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 258 LR: 0.0009583365026691784 Training loss: 6.097784996032715
2025-12-09 06:31:31.443 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 259 LR: 0.000957818304394503 Training loss: 6.50624418258667
2025-12-09 06:31:31.949 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 260 LR: 0.0009572970452835494 Training loss: 6.165832042694092
2025-12-09 06:31:32.456 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 261 LR: 0.0009567727288213005 Training loss: 6.147640705108643
2025-12-09 06:31:32.964 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 262 LR: 0.0009562453585131791 Training loss: 6.143994331359863
2025-12-09 06:31:33.471 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 263 LR: 0.0009557149378850254 Training loss: 6.05144739151001
2025-12-09 06:31:33.979 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 264 LR: 0.0009551814704830733 Training loss: 6.300386428833008
2025-12-09 06:31:34.486 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 265 LR: 0.0009546449598739262 Training loss: 6.3411383628845215
2025-12-09 06:31:34.993 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 266 LR: 0.0009541054096445336 Training loss: 6.298660755157471
2025-12-09 06:31:35.500 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 267 LR: 0.0009535628234021669 Training loss: 6.216376781463623
2025-12-09 06:31:36.006 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 268 LR: 0.0009530172047743957 Training loss: 5.985350608825684
2025-12-09 06:31:36.512 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 269 LR: 0.0009524685574090626 Training loss: 6.135243892669678
2025-12-09 06:31:37.019 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 270 LR: 0.0009519168849742603 Training loss: 6.2989397048950195
2025-12-09 06:31:37.525 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 271 LR: 0.0009513621911583053 Training loss: 6.118211269378662
2025-12-09 06:31:38.032 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 272 LR: 0.0009508044796697148 Training loss: 5.892117023468018
2025-12-09 06:31:38.539 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 273 LR: 0.0009502437542371811 Training loss: 6.116428852081299
2025-12-09 06:31:39.047 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 274 LR: 0.0009496800186095466 Training loss: 6.030820369720459
2025-12-09 06:31:39.552 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 275 LR: 0.0009491132765557791 Training loss: 6.124300956726074
2025-12-09 06:31:40.059 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 276 LR: 0.0009485435318649467 Training loss: 6.15615177154541
2025-12-09 06:31:40.565 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 277 LR: 0.0009479707883461918 Training loss: 6.03819465637207
2025-12-09 06:31:41.073 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 278 LR: 0.0009473950498287066 Training loss: 6.223549842834473
2025-12-09 06:31:41.581 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 279 LR: 0.0009468163201617061 Training loss: 6.383290767669678
2025-12-09 06:31:42.087 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 280 LR: 0.0009462346032144044 Training loss: 6.255985736846924
2025-12-09 06:31:42.593 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 281 LR: 0.0009456499028759868 Training loss: 6.2980875968933105
2025-12-09 06:31:43.099 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 282 LR: 0.0009450622230555847 Training loss: 6.157431125640869
2025-12-09 06:31:44.057 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 283 LR: 0.0009444715676822502 Training loss: 6.185354709625244
2025-12-09 06:31:44.562 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 284 LR: 0.0009438779407049281 Training loss: 6.0954813957214355
2025-12-09 06:31:45.068 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 285 LR: 0.0009432813460924307 Training loss: 6.14732551574707
2025-12-09 06:31:45.574 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 286 LR: 0.0009426817878334115 Training loss: 6.200128078460693
2025-12-09 06:31:46.082 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 287 LR: 0.0009420792699363377 Training loss: 6.336069583892822
2025-12-09 06:31:46.589 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 288 LR: 0.0009414737964294635 Training loss: 6.265318393707275
2025-12-09 06:31:47.094 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 289 LR: 0.000940865371360804 Training loss: 6.111889362335205
2025-12-09 06:31:47.600 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 290 LR: 0.0009402539987981071 Training loss: 6.163387298583984
2025-12-09 06:31:48.107 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 291 LR: 0.0009396396828288272 Training loss: 5.954472064971924
2025-12-09 06:31:48.614 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 292 LR: 0.0009390224275600969 Training loss: 6.056597709655762
2025-12-09 06:31:49.121 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 293 LR: 0.0009384022371187003 Training loss: 6.232737064361572
2025-12-09 06:31:49.630 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 294 LR: 0.0009377791156510454 Training loss: 6.381580829620361
2025-12-09 06:31:50.139 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 295 LR: 0.000937153067323136 Training loss: 6.037169456481934
2025-12-09 06:31:50.646 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 296 LR: 0.0009365240963205439 Training loss: 6.243714809417725
2025-12-09 06:31:51.152 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 297 LR: 0.0009358922068483812 Training loss: 6.0426506996154785
2025-12-09 06:31:51.660 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 298 LR: 0.000935257403131272 Training loss: 5.579031944274902
2025-12-09 06:31:52.167 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 299 LR: 0.0009346196894133239 Training loss: 5.820310592651367
2025-12-09 06:31:52.673 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 300 LR: 0.0009339790699581003 Training loss: 6.260839462280273
2025-12-09 06:31:53.179 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 301 LR: 0.0009333355490485915 Training loss: 6.356048107147217
2025-12-09 06:31:53.686 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 302 LR: 0.0009326891309871854 Training loss: 6.017233371734619
2025-12-09 06:31:54.192 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 303 LR: 0.0009320398200956402 Training loss: 6.188876152038574
2025-12-09 06:31:54.697 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 304 LR: 0.0009313876207150542 Training loss: 5.975833892822266
2025-12-09 06:31:55.202 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 305 LR: 0.0009307325372058377 Training loss: 6.016231536865234
2025-12-09 06:31:55.707 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 306 LR: 0.0009300745739476828 Training loss: 6.405404090881348
2025-12-09 06:31:56.212 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 307 LR: 0.0009294137353395351 Training loss: 6.1594648361206055
2025-12-09 06:31:56.717 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 308 LR: 0.000928750025799564 Training loss: 6.012383937835693
2025-12-09 06:31:57.223 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 309 LR: 0.0009280834497651332 Training loss: 6.044687271118164
2025-12-09 06:31:57.730 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 310 LR: 0.0009274140116927706 Training loss: 6.283945560455322
2025-12-09 06:31:58.237 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 311 LR: 0.0009267417160581388 Training loss: 6.030928134918213
2025-12-09 06:31:58.744 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 312 LR: 0.0009260665673560057 Training loss: 6.333026885986328
2025-12-09 06:31:59.250 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 313 LR: 0.0009253885701002134 Training loss: 6.00808572769165
2025-12-09 06:31:59.757 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 314 LR: 0.0009247077288236488 Training loss: 6.112598419189453
2025-12-09 06:32:00.266 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 315 LR: 0.0009240240480782129 Training loss: 5.914462566375732
2025-12-09 06:32:00.774 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 316 LR: 0.0009233375324347912 Training loss: 5.666536808013916
2025-12-09 06:32:01.281 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 317 LR: 0.0009226481864832216 Training loss: 6.077095985412598
2025-12-09 06:32:01.790 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 318 LR: 0.0009219560148322654 Training loss: 5.9536027908325195
2025-12-09 06:32:02.298 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 319 LR: 0.0009212610221095747 Training loss: 6.309561252593994
2025-12-09 06:32:02.805 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 320 LR: 0.0009205632129616635 Training loss: 5.966425895690918
2025-12-09 06:32:03.311 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 321 LR: 0.0009198625920538749 Training loss: 5.941380023956299
2025-12-09 06:32:03.819 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 322 LR: 0.0009191591640703507 Training loss: 6.0235137939453125
2025-12-09 06:32:04.326 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 323 LR: 0.0009184529337140002 Training loss: 6.015697956085205
2025-12-09 06:32:04.832 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 324 LR: 0.0009177439057064682 Training loss: 5.8852643966674805
2025-12-09 06:32:05.338 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 325 LR: 0.0009170320847881042 Training loss: 5.854556560516357
2025-12-09 06:32:05.846 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 326 LR: 0.0009163174757179297 Training loss: 5.8945159912109375
2025-12-09 06:32:06.353 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 327 LR: 0.0009156000832736073 Training loss: 6.075408935546875
2025-12-09 06:32:06.858 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 328 LR: 0.0009148799122514087 Training loss: 5.928370952606201
2025-12-09 06:32:07.365 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 329 LR: 0.0009141569674661816 Training loss: 5.997189521789551
2025-12-09 06:32:07.874 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 330 LR: 0.0009134312537513187 Training loss: 6.108007431030273
2025-12-09 06:32:08.381 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 331 LR: 0.000912702775958725 Training loss: 6.236727237701416
2025-12-09 06:32:08.888 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 332 LR: 0.0009119715389587853 Training loss: 6.335387229919434
2025-12-09 06:32:09.394 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 333 LR: 0.0009112375476403312 Training loss: 5.964171886444092
2025-12-09 06:32:09.900 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 334 LR: 0.0009105008069106094 Training loss: 6.128701210021973
2025-12-09 06:32:10.407 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 335 LR: 0.0009097613216952478 Training loss: 5.976101875305176
2025-12-09 06:32:10.913 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 336 LR: 0.0009090190969382239 Training loss: 5.943304538726807
2025-12-09 06:32:11.419 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 337 LR: 0.00090827413760183 Training loss: 5.950320720672607
2025-12-09 06:32:11.924 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 338 LR: 0.0009075264486666419 Training loss: 6.049367904663086
2025-12-09 06:32:12.431 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 339 LR: 0.0009067760351314837 Training loss: 6.117856502532959
2025-12-09 06:32:12.936 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 340 LR: 0.0009060229020133965 Training loss: 6.073702335357666
2025-12-09 06:32:13.443 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 341 LR: 0.0009052670543476026 Training loss: 6.028308391571045
2025-12-09 06:32:13.949 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 342 LR: 0.0009045084971874737 Training loss: 5.574581623077393
2025-12-09 06:32:14.457 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 343 LR: 0.0009037472356044962 Training loss: 5.869457721710205
2025-12-09 06:32:14.963 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 344 LR: 0.0009029832746882371 Training loss: 5.9781060218811035
2025-12-09 06:32:15.471 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 345 LR: 0.000902216619546311 Training loss: 5.955306053161621
2025-12-09 06:32:15.977 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 346 LR: 0.0009014472753043447 Training loss: 6.004350185394287
2025-12-09 06:32:16.485 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 347 LR: 0.0009006752471059439 Training loss: 5.8505377769470215
2025-12-09 06:32:16.990 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 348 LR: 0.000899900540112658 Training loss: 5.712448596954346
2025-12-09 06:32:17.498 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 349 LR: 0.0008991231595039464 Training loss: 6.121856212615967
2025-12-09 06:32:18.006 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 350 LR: 0.0008983431104771436 Training loss: 6.197713851928711
2025-12-09 06:32:18.513 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 351 LR: 0.0008975603982474239 Training loss: 5.829681873321533
2025-12-09 06:32:19.021 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 352 LR: 0.0008967750280477673 Training loss: 5.904694080352783
2025-12-09 06:32:19.526 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 353 LR: 0.0008959870051289241 Training loss: 5.93130350112915
2025-12-09 06:32:20.034 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 354 LR: 0.0008951963347593796 Training loss: 5.838367938995361
2025-12-09 06:32:20.540 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 355 LR: 0.00089440302222532 Training loss: 6.090460300445557
2025-12-09 06:32:21.047 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 356 LR: 0.0008936070728305952 Training loss: 5.952385902404785
2025-12-09 06:32:21.554 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 357 LR: 0.000892808491896685 Training loss: 6.138863563537598
2025-12-09 06:32:22.062 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 358 LR: 0.0008920072847626629 Training loss: 6.001729488372803
2025-12-09 06:32:22.570 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 359 LR: 0.0008912034567851599 Training loss: 5.8031907081604
2025-12-09 06:32:23.079 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 360 LR: 0.0008903970133383297 Training loss: 5.700504779815674
2025-12-09 06:32:23.585 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 361 LR: 0.0008895879598138119 Training loss: 5.703771591186523
2025-12-09 06:32:24.093 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 362 LR: 0.0008887763016206965 Training loss: 5.736793518066406
2025-12-09 06:32:24.599 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 363 LR: 0.0008879620441854873 Training loss: 6.05190372467041
2025-12-09 06:32:25.106 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 364 LR: 0.0008871451929520662 Training loss: 5.858899116516113
2025-12-09 06:32:25.614 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 365 LR: 0.0008863257533816562 Training loss: 5.800132751464844
2025-12-09 06:32:26.120 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 366 LR: 0.0008855037309527853 Training loss: 5.868147850036621
2025-12-09 06:32:26.628 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 367 LR: 0.0008846791311612497 Training loss: 6.047089576721191
2025-12-09 06:32:27.137 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 368 LR: 0.000883851959520077 Training loss: 5.882683277130127
2025-12-09 06:32:27.644 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 369 LR: 0.000883022221559489 Training loss: 5.8884735107421875
2025-12-09 06:32:28.151 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 370 LR: 0.0008821899228268662 Training loss: 6.092260837554932
2025-12-09 06:32:28.657 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 371 LR: 0.0008813550688867087 Training loss: 5.847267150878906
2025-12-09 06:32:29.165 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 372 LR: 0.0008805176653206003 Training loss: 6.0313005447387695
2025-12-09 06:32:29.672 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 373 LR: 0.0008796777177271708 Training loss: 5.841001987457275
2025-12-09 06:32:30.180 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 374 LR: 0.000878835231722059 Training loss: 6.066800594329834
2025-12-09 06:32:30.687 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 375 LR: 0.000877990212937874 Training loss: 6.112681865692139
2025-12-09 06:32:31.193 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 376 LR: 0.0008771426670241587 Training loss: 5.725773811340332
2025-12-09 06:32:31.700 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 377 LR: 0.0008762925996473518 Training loss: 5.935172080993652
2025-12-09 06:32:32.205 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 378 LR: 0.0008754400164907496 Training loss: 5.894252777099609
2025-12-09 06:32:32.711 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 379 LR: 0.0008745849232544681 Training loss: 5.897027969360352
2025-12-09 06:32:33.219 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 380 LR: 0.0008737273256554048 Training loss: 6.066956996917725
2025-12-09 06:32:33.725 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 381 LR: 0.0008728672294272009 Training loss: 5.7916646003723145
2025-12-09 06:32:34.232 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 382 LR: 0.0008720046403202027 Training loss: 5.879262924194336
2025-12-09 06:32:34.738 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 383 LR: 0.0008711395641014228 Training loss: 5.8487443923950195
2025-12-09 06:32:35.244 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 384 LR: 0.0008702720065545023 Training loss: 5.984360694885254
2025-12-09 06:32:35.751 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 385 LR: 0.0008694019734796714 Training loss: 5.754322052001953
2025-12-09 06:32:36.257 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 386 LR: 0.0008685294706937113 Training loss: 6.098299980163574
2025-12-09 06:32:36.764 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 387 LR: 0.0008676545040299144 Training loss: 6.039943218231201
2025-12-09 06:32:37.271 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 388 LR: 0.0008667770793380463 Training loss: 5.871782302856445
2025-12-09 06:32:37.780 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 389 LR: 0.0008658972024843061 Training loss: 5.822333812713623
2025-12-09 06:32:38.285 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 390 LR: 0.0008650148793512873 Training loss: 5.709933757781982
2025-12-09 06:32:38.794 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 391 LR: 0.0008641301158379387 Training loss: 5.849564552307129
2025-12-09 06:32:39.300 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 392 LR: 0.0008632429178595242 Training loss: 6.006031513214111
2025-12-09 06:32:39.807 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 393 LR: 0.0008623532913475847 Training loss: 5.825960636138916
2025-12-09 06:32:40.314 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 394 LR: 0.0008614612422498965 Training loss: 5.684635639190674
2025-12-09 06:32:40.821 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 395 LR: 0.0008605667765304334 Training loss: 5.56766939163208
2025-12-09 06:32:41.327 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 396 LR: 0.0008596699001693256 Training loss: 5.961772918701172
2025-12-09 06:32:41.832 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 397 LR: 0.0008587706191628204 Training loss: 5.687686443328857
2025-12-09 06:32:42.341 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 398 LR: 0.0008578689395232416 Training loss: 5.758023738861084
2025-12-09 06:32:42.847 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 399 LR: 0.0008569648672789496 Training loss: 5.748421669006348
2025-12-09 06:32:43.355 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 400 LR: 0.0008560584084743011 Training loss: 5.740757942199707
2025-12-09 06:32:43.861 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 401 LR: 0.0008551495691696085 Training loss: 5.889166831970215
2025-12-09 06:32:44.370 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 402 LR: 0.0008542383554411 Training loss: 5.77662467956543
2025-12-09 06:32:44.878 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 403 LR: 0.0008533247733808776 Training loss: 5.557956218719482
2025-12-09 06:32:45.384 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 404 LR: 0.0008524088290968781 Training loss: 6.113729476928711
2025-12-09 06:32:45.892 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 405 LR: 0.000851490528712831 Training loss: 5.829861640930176
2025-12-09 06:32:46.397 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 406 LR: 0.0008505698783682179 Training loss: 5.692340850830078
2025-12-09 06:32:46.904 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 407 LR: 0.0008496468842182317 Training loss: 5.794431209564209
2025-12-09 06:32:47.410 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 408 LR: 0.0008487215524337357 Training loss: 5.963126182556152
2025-12-09 06:32:47.917 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 409 LR: 0.0008477938892012209 Training loss: 5.930992603302002
2025-12-09 06:32:48.426 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 410 LR: 0.0008468639007227668 Training loss: 5.860614776611328
2025-12-09 06:32:48.933 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 411 LR: 0.0008459315932159979 Training loss: 5.8933515548706055
2025-12-09 06:32:49.440 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 412 LR: 0.0008449969729140437 Training loss: 5.749500274658203
2025-12-09 06:32:49.946 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 413 LR: 0.0008440600460654957 Training loss: 5.89990758895874
2025-12-09 06:32:50.451 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 414 LR: 0.0008431208189343669 Training loss: 5.968441486358643
2025-12-09 06:32:50.957 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 415 LR: 0.0008421792978000489 Training loss: 5.777835369110107
2025-12-09 06:32:51.464 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 416 LR: 0.0008412354889572705 Training loss: 5.889816761016846
2025-12-09 06:32:51.970 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 417 LR: 0.0008402893987160552 Training loss: 5.963777542114258
2025-12-09 06:32:52.477 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 418 LR: 0.0008393410334016798 Training loss: 5.769247055053711
2025-12-09 06:32:52.984 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 419 LR: 0.000838390399354631 Training loss: 5.638875961303711
2025-12-09 06:32:53.489 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 420 LR: 0.0008374375029305639 Training loss: 5.809526443481445
2025-12-09 06:32:53.996 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 421 LR: 0.0008364823505002586 Training loss: 5.5709547996521
2025-12-09 06:32:54.501 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 422 LR: 0.0008355249484495791 Training loss: 5.750577449798584
2025-12-09 06:32:55.007 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 423 LR: 0.0008345653031794292 Training loss: 5.836145877838135
2025-12-09 06:32:55.515 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 424 LR: 0.0008336034211057098 Training loss: 5.740524768829346
2025-12-09 06:32:56.023 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 425 LR: 0.0008326393086592772 Training loss: 5.864962577819824
2025-12-09 06:32:56.530 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 426 LR: 0.0008316729722858987 Training loss: 6.048435688018799
2025-12-09 06:32:57.037 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 427 LR: 0.0008307044184462104 Training loss: 5.7857794761657715
2025-12-09 06:32:57.543 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 428 LR: 0.0008297336536156738 Training loss: 5.693047046661377
2025-12-09 06:32:58.049 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 429 LR: 0.0008287606842845319 Training loss: 5.902565002441406
2025-12-09 06:32:58.557 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 430 LR: 0.0008277855169577668 Training loss: 5.9737982749938965
2025-12-09 06:32:59.066 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 431 LR: 0.000826808158155056 Training loss: 5.853889465332031
2025-12-09 06:32:59.574 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 432 LR: 0.0008258286144107276 Training loss: 5.871363162994385
2025-12-09 06:33:00.080 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 433 LR: 0.0008248468922737186 Training loss: 5.841880798339844
2025-12-09 06:33:00.587 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 434 LR: 0.0008238629983075294 Training loss: 5.866787910461426
2025-12-09 06:33:01.094 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 435 LR: 0.0008228769390901811 Training loss: 5.709280967712402
2025-12-09 06:33:01.600 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 436 LR: 0.0008218887212141705 Training loss: 5.914875507354736
2025-12-09 06:33:02.106 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 437 LR: 0.0008208983512864268 Training loss: 5.715381145477295
2025-12-09 06:33:02.612 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 438 LR: 0.0008199058359282674 Training loss: 5.858870506286621
2025-12-09 06:33:03.119 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 439 LR: 0.000818911181775353 Training loss: 5.752959728240967
2025-12-09 06:33:03.628 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 440 LR: 0.0008179143954776439 Training loss: 5.795363426208496
2025-12-09 06:33:04.137 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 441 LR: 0.0008169154836993551 Training loss: 5.623910427093506
2025-12-09 06:33:04.643 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 442 LR: 0.0008159144531189122 Training loss: 5.742959499359131
2025-12-09 06:33:05.151 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 443 LR: 0.0008149113104289063 Training loss: 5.551873683929443
2025-12-09 06:33:05.659 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 444 LR: 0.0008139060623360494 Training loss: 6.086275577545166
2025-12-09 06:33:06.166 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 445 LR: 0.0008128987155611295 Training loss: 5.702785968780518
2025-12-09 06:33:06.673 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 446 LR: 0.000811889276838966 Training loss: 5.929310321807861
2025-12-09 06:33:07.180 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 447 LR: 0.0008108777529183644 Training loss: 5.781951427459717
2025-12-09 06:33:07.687 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 448 LR: 0.0008098641505620711 Training loss: 5.297598838806152
2025-12-09 06:33:08.194 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 449 LR: 0.0008088484765467285 Training loss: 5.6649699211120605
2025-12-09 06:33:08.699 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 450 LR: 0.0008078307376628291 Training loss: 5.978306293487549
2025-12-09 06:33:09.205 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 451 LR: 0.000806810940714671 Training loss: 5.939676761627197
2025-12-09 06:33:09.712 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 452 LR: 0.0008057890925203113 Training loss: 5.879908084869385
2025-12-09 06:33:10.219 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 453 LR: 0.0008047651999115216 Training loss: 5.5141143798828125
2025-12-09 06:33:10.726 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 454 LR: 0.0008037392697337418 Training loss: 5.908991813659668
2025-12-09 06:33:11.232 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 455 LR: 0.0008027113088460343 Training loss: 5.813582420349121
2025-12-09 06:33:11.739 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 456 LR: 0.0008016813241210379 Training loss: 5.572383880615234
2025-12-09 06:33:12.246 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 457 LR: 0.0008006493224449228 Training loss: 5.515806198120117
2025-12-09 06:33:12.754 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 458 LR: 0.0007996153107173435 Training loss: 5.5243635177612305
2025-12-09 06:33:13.261 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 459 LR: 0.0007985792958513931 Training loss: 5.779189586639404
2025-12-09 06:33:13.768 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 460 LR: 0.0007975412847735573 Training loss: 5.787647247314453
2025-12-09 06:33:14.275 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 461 LR: 0.0007965012844236677 Training loss: 5.7288899421691895
2025-12-09 06:33:14.782 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 462 LR: 0.0007954593017548556 Training loss: 5.752686023712158
2025-12-09 06:33:15.288 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 463 LR: 0.0007944153437335057 Training loss: 5.872347831726074
2025-12-09 06:33:15.822 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 464 LR: 0.000793369417339209 Training loss: 5.75461483001709
2025-12-09 06:33:16.372 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 465 LR: 0.0007923215295647166 Training loss: 5.65929651260376
2025-12-09 06:33:16.879 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 466 LR: 0.0007912716874158928 Training loss: 5.482263088226318
2025-12-09 06:33:17.386 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 467 LR: 0.0007902198979116684 Training loss: 5.994809627532959
2025-12-09 06:33:17.893 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 468 LR: 0.0007891661680839932 Training loss: 5.81983757019043
2025-12-09 06:33:18.400 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 469 LR: 0.0007881105049777901 Training loss: 5.678767204284668
2025-12-09 06:33:18.909 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 470 LR: 0.0007870529156509068 Training loss: 5.3351640701293945
2025-12-09 06:33:19.417 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 471 LR: 0.0007859934071740692 Training loss: 5.721083641052246
2025-12-09 06:33:19.925 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 472 LR: 0.0007849319866308342 Training loss: 5.794522285461426
2025-12-09 06:33:20.434 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 473 LR: 0.0007838686611175421 Training loss: 5.751916408538818
2025-12-09 06:33:20.941 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 474 LR: 0.0007828034377432694 Training loss: 5.88385009765625
2025-12-09 06:33:21.450 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 475 LR: 0.0007817363236297808 Training loss: 5.698157787322998
2025-12-09 06:33:21.957 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 476 LR: 0.0007806673259114826 Training loss: 5.547921180725098
2025-12-09 06:33:22.466 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 477 LR: 0.0007795964517353734 Training loss: 5.438798427581787
2025-12-09 06:33:22.975 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 478 LR: 0.0007785237082609981 Training loss: 5.48090124130249
2025-12-09 06:33:23.483 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 479 LR: 0.0007774491026603985 Training loss: 5.638854026794434
2025-12-09 06:33:23.992 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 480 LR: 0.0007763726421180664 Training loss: 5.761342525482178
2025-12-09 06:33:24.497 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 481 LR: 0.000775294333830895 Training loss: 5.440661430358887
2025-12-09 06:33:25.003 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 482 LR: 0.0007742141850081313 Training loss: 5.547495365142822
2025-12-09 06:33:25.510 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 483 LR: 0.000773132202871327 Training loss: 5.480717658996582
2025-12-09 06:33:26.019 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 484 LR: 0.0007720483946542913 Training loss: 5.7129411697387695
2025-12-09 06:33:26.527 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 485 LR: 0.0007709627676030419 Training loss: 5.447939872741699
2025-12-09 06:33:27.035 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 486 LR: 0.0007698753289757565 Training loss: 5.692437648773193
2025-12-09 06:33:27.540 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 487 LR: 0.0007687860860427245 Training loss: 5.511127471923828
2025-12-09 06:33:28.049 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 488 LR: 0.0007676950460862986 Training loss: 5.587021350860596
2025-12-09 06:33:28.556 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 489 LR: 0.0007666022164008457 Training loss: 5.363147735595703
2025-12-09 06:33:29.065 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 490 LR: 0.000765507604292698 Training loss: 5.640226364135742
2025-12-09 06:33:29.573 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 491 LR: 0.000764411217080105 Training loss: 5.440036296844482
2025-12-09 06:33:30.081 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 492 LR: 0.0007633130620931837 Training loss: 5.557584285736084
2025-12-09 06:33:30.590 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 493 LR: 0.00076221314667387 Training loss: 5.823167324066162
2025-12-09 06:33:31.098 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 494 LR: 0.0007611114781758692 Training loss: 5.373256206512451
2025-12-09 06:33:31.605 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 495 LR: 0.0007600080639646077 Training loss: 5.297717571258545
2025-12-09 06:33:32.113 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 496 LR: 0.000758902911417183 Training loss: 5.818274021148682
2025-12-09 06:33:32.621 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 497 LR: 0.0007577960279223142 Training loss: 5.465669631958008
2025-12-09 06:33:33.127 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 498 LR: 0.0007566874208802939 Training loss: 5.700517177581787
2025-12-09 06:33:33.635 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 499 LR: 0.0007555770977029366 Training loss: 5.7090911865234375
2025-12-09 06:33:34.142 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 500 LR: 0.0007544650658135314 Training loss: 5.393418312072754
2025-12-09 06:33:34.649 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 501 LR: 0.0007533513326467912 Training loss: 5.70849609375
2025-12-09 06:33:35.157 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 502 LR: 0.0007522359056488024 Training loss: 5.912680625915527
2025-12-09 06:33:35.664 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 503 LR: 0.0007511187922769767 Training loss: 5.664364814758301
2025-12-09 06:33:36.172 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 504 LR: 0.00075 Training loss: 5.723367691040039
2025-12-09 06:33:36.680 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 505 LR: 0.0007488795362977829 Training loss: 5.953936576843262
2025-12-09 06:33:37.187 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 506 LR: 0.0007477574086614104 Training loss: 5.488393783569336
2025-12-09 06:33:37.694 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 507 LR: 0.0007466336245930927 Training loss: 5.428400039672852
2025-12-09 06:33:38.201 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 508 LR: 0.0007455081916061139 Training loss: 5.637845993041992
2025-12-09 06:33:38.709 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 509 LR: 0.0007443811172247821 Training loss: 5.458367824554443
2025-12-09 06:33:39.216 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 510 LR: 0.0007432524089843799 Training loss: 5.266580581665039
2025-12-09 06:33:39.725 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 511 LR: 0.0007421220744311132 Training loss: 5.738125801086426
2025-12-09 06:33:40.233 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 512 LR: 0.0007409901211220605 Training loss: 5.575358867645264
2025-12-09 06:33:40.740 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 513 LR: 0.0007398565566251232 Training loss: 5.4406514167785645
2025-12-09 06:33:41.249 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 514 LR: 0.0007387213885189745 Training loss: 5.536782741546631
2025-12-09 06:33:41.756 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 515 LR: 0.0007375846243930091 Training loss: 5.442332744598389
2025-12-09 06:33:42.264 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 516 LR: 0.0007364462718472918 Training loss: 5.821971893310547
2025-12-09 06:33:42.773 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 517 LR: 0.0007353063384925075 Training loss: 5.855403423309326
2025-12-09 06:33:43.279 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 518 LR: 0.0007341648319499096 Training loss: 5.851457595825195
2025-12-09 06:33:43.786 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 519 LR: 0.0007330217598512695 Training loss: 5.548707008361816
2025-12-09 06:33:44.291 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 520 LR: 0.0007318771298388254 Training loss: 5.871469020843506
2025-12-09 06:33:44.800 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 521 LR: 0.0007307309495652312 Training loss: 5.684508323669434
2025-12-09 06:33:45.304 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 522 LR: 0.0007295832266935059 Training loss: 5.784623622894287
2025-12-09 06:33:45.810 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 523 LR: 0.0007284339688969809 Training loss: 5.5061540603637695
2025-12-09 06:33:46.314 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 524 LR: 0.0007272831838592503 Training loss: 5.380953788757324
2025-12-09 06:33:46.879 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 525 LR: 0.0007261308792741188 Training loss: 5.438716411590576
2025-12-09 06:33:47.383 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 526 LR: 0.0007249770628455503 Training loss: 5.6608357429504395
2025-12-09 06:33:47.890 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 527 LR: 0.0007238217422876163 Training loss: 5.996045112609863
2025-12-09 06:33:48.395 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 528 LR: 0.0007226649253244447 Training loss: 5.7365875244140625
2025-12-09 06:33:48.901 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 529 LR: 0.0007215066196901676 Training loss: 5.713079452514648
2025-12-09 06:33:49.405 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 530 LR: 0.0007203468331288703 Training loss: 5.816573619842529
2025-12-09 06:33:49.911 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 531 LR: 0.0007191855733945387 Training loss: 5.57931661605835
2025-12-09 06:33:50.415 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 532 LR: 0.0007180228482510084 Training loss: 5.7826457023620605
2025-12-09 06:33:50.920 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 533 LR: 0.0007168586654719117 Training loss: 5.395193576812744
2025-12-09 06:33:51.425 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 534 LR: 0.0007156930328406268 Training loss: 5.713797092437744
2025-12-09 06:33:51.931 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 535 LR: 0.0007145259581502247 Training loss: 5.519108295440674
2025-12-09 06:33:52.437 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 536 LR: 0.0007133574492034179 Training loss: 5.401934623718262
2025-12-09 06:33:52.944 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 537 LR: 0.0007121875138125077 Training loss: 5.770552635192871
2025-12-09 06:33:53.450 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 538 LR: 0.0007110161597993325 Training loss: 5.317663669586182
2025-12-09 06:33:53.958 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 539 LR: 0.0007098433949952145 Training loss: 5.6069746017456055
2025-12-09 06:33:54.463 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 540 LR: 0.000708669227240909 Training loss: 5.547606945037842
2025-12-09 06:33:54.969 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 541 LR: 0.0007074936643865501 Training loss: 5.238879203796387
2025-12-09 06:33:55.473 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 542 LR: 0.0007063167142915998 Training loss: 5.574277400970459
2025-12-09 06:33:55.980 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 543 LR: 0.0007051383848247942 Training loss: 5.550777435302734
2025-12-09 06:33:56.486 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 544 LR: 0.0007039586838640917 Training loss: 5.592338562011719
2025-12-09 06:33:56.991 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 545 LR: 0.0007027776192966206 Training loss: 5.671858310699463
2025-12-09 06:33:57.497 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 546 LR: 0.0007015951990186251 Training loss: 5.5877556800842285
2025-12-09 06:33:58.002 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 547 LR: 0.0007004114309354136 Training loss: 5.58228874206543
2025-12-09 06:33:58.507 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 548 LR: 0.0006992263229613054 Training loss: 5.655249118804932
2025-12-09 06:33:59.015 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 549 LR: 0.0006980398830195785 Training loss: 5.680187702178955
2025-12-09 06:33:59.519 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 550 LR: 0.000696852119042415 Training loss: 5.5690436363220215
2025-12-09 06:34:00.026 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 551 LR: 0.0006956630389708499 Training loss: 5.556385517120361
2025-12-09 06:34:00.533 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 552 LR: 0.0006944726507547168 Training loss: 5.599639415740967
2025-12-09 06:34:01.042 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 553 LR: 0.0006932809623525957 Training loss: 5.480795383453369
2025-12-09 06:34:01.549 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 554 LR: 0.0006920879817317588 Training loss: 5.573889255523682
2025-12-09 06:34:02.055 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 555 LR: 0.0006908937168681175 Training loss: 5.610354900360107
2025-12-09 06:34:02.561 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 556 LR: 0.0006896981757461699 Training loss: 5.520896911621094
2025-12-09 06:34:03.069 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 557 LR: 0.0006885013663589461 Training loss: 5.738489627838135
2025-12-09 06:34:03.580 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 558 LR: 0.0006873032967079561 Training loss: 5.778453826904297
2025-12-09 06:34:04.087 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 559 LR: 0.000686103974803135 Training loss: 5.696466445922852
2025-12-09 06:34:04.595 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 560 LR: 0.0006849034086627905 Training loss: 5.675117015838623
2025-12-09 06:34:05.101 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 561 LR: 0.0006837016063135491 Training loss: 5.345706462860107
2025-12-09 06:34:05.608 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 562 LR: 0.0006824985757903016 Training loss: 5.835233211517334
2025-12-09 06:34:06.115 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 563 LR: 0.0006812943251361505 Training loss: 5.736652374267578
2025-12-09 06:34:06.623 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 564 LR: 0.0006800888624023553 Training loss: 5.465051174163818
2025-12-09 06:34:07.129 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 565 LR: 0.0006788821956482796 Training loss: 5.824210166931152
2025-12-09 06:34:07.637 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 566 LR: 0.0006776743329413364 Training loss: 5.416356563568115
2025-12-09 06:34:08.146 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 567 LR: 0.0006764652823569344 Training loss: 5.857579231262207
2025-12-09 06:34:08.655 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 568 LR: 0.0006752550519784246 Training loss: 5.634779930114746
2025-12-09 06:34:09.162 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 569 LR: 0.0006740436498970453 Training loss: 5.350144863128662
2025-12-09 06:34:09.667 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 570 LR: 0.0006728310842118683 Training loss: 5.68186092376709
2025-12-09 06:34:10.175 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 571 LR: 0.0006716173630297455 Training loss: 5.602110862731934
2025-12-09 06:34:10.681 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 572 LR: 0.0006704024944652537 Training loss: 5.606213092803955
2025-12-09 06:34:11.189 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 573 LR: 0.0006691864866406407 Training loss: 5.5673441886901855
2025-12-09 06:34:11.696 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 574 LR: 0.0006679693476857712 Training loss: 5.66749382019043
2025-12-09 06:34:12.202 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 575 LR: 0.0006667510857380722 Training loss: 5.7464799880981445
2025-12-09 06:34:12.709 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 576 LR: 0.0006655317089424791 Training loss: 5.515605449676514
2025-12-09 06:34:13.217 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 577 LR: 0.0006643112254513802 Training loss: 5.738411903381348
2025-12-09 06:34:13.724 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 578 LR: 0.0006630896434245634 Training loss: 5.556448936462402
2025-12-09 06:34:14.231 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 579 LR: 0.0006618669710291606 Training loss: 5.6167311668396
2025-12-09 06:34:14.738 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 580 LR: 0.0006606432164395939 Training loss: 5.238954067230225
2025-12-09 06:34:15.244 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 581 LR: 0.0006594183878375206 Training loss: 5.611363410949707
2025-12-09 06:34:15.753 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 582 LR: 0.0006581924934117783 Training loss: 5.411931037902832
2025-12-09 06:34:16.260 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 583 LR: 0.0006569655413583307 Training loss: 5.651376724243164
2025-12-09 06:34:16.767 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 584 LR: 0.0006557375398802124 Training loss: 5.513300895690918
2025-12-09 06:34:17.274 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 585 LR: 0.0006545084971874737 Training loss: 5.575392723083496
2025-12-09 06:34:17.780 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 586 LR: 0.0006532784214971269 Training loss: 5.710262775421143
2025-12-09 06:34:18.285 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 587 LR: 0.0006520473210330902 Training loss: 5.7857890129089355
2025-12-09 06:34:18.792 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 588 LR: 0.0006508152040261328 Training loss: 5.444179058074951
2025-12-09 06:34:19.296 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 589 LR: 0.0006495820787138209 Training loss: 5.73022985458374
2025-12-09 06:34:19.802 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 590 LR: 0.0006483479533404613 Training loss: 5.530411243438721
2025-12-09 06:34:20.308 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 591 LR: 0.0006471128361570475 Training loss: 5.56705379486084
2025-12-09 06:34:20.814 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 592 LR: 0.0006458767354212036 Training loss: 5.325702667236328
2025-12-09 06:34:21.318 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 593 LR: 0.0006446396593971294 Training loss: 5.343180179595947
2025-12-09 06:34:21.825 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 594 LR: 0.0006434016163555452 Training loss: 5.849728107452393
2025-12-09 06:34:22.331 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 595 LR: 0.0006421626145736366 Training loss: 5.134585380554199
2025-12-09 06:34:22.837 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 596 LR: 0.0006409226623349991 Training loss: 5.399899959564209
2025-12-09 06:34:23.342 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 597 LR: 0.0006396817679295822 Training loss: 5.5123186111450195
2025-12-09 06:34:23.848 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 598 LR: 0.0006384399396536354 Training loss: 5.799159049987793
2025-12-09 06:34:24.352 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 599 LR: 0.0006371971858096508 Training loss: 5.12395715713501
2025-12-09 06:34:24.860 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 600 LR: 0.0006359535147063091 Training loss: 5.6466569900512695
2025-12-09 06:34:25.365 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 601 LR: 0.0006347089346584234 Training loss: 5.554803848266602
2025-12-09 06:34:25.873 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 602 LR: 0.0006334634539868836 Training loss: 5.613688945770264
2025-12-09 06:34:26.377 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 603 LR: 0.0006322170810186012 Training loss: 5.542600631713867
2025-12-09 06:34:26.882 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 604 LR: 0.0006309698240864529 Training loss: 5.448422431945801
2025-12-09 06:34:27.387 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 605 LR: 0.0006297216915292259 Training loss: 5.739650249481201
2025-12-09 06:34:27.896 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 606 LR: 0.000628472691691561 Training loss: 5.168315887451172
2025-12-09 06:34:28.401 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 607 LR: 0.0006272228329238978 Training loss: 5.329827308654785
2025-12-09 06:34:28.908 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 608 LR: 0.0006259721235824182 Training loss: 5.524674892425537
2025-12-09 06:34:29.411 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 609 LR: 0.0006247205720289907 Training loss: 5.285892009735107
2025-12-09 06:34:29.919 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 610 LR: 0.0006234681866311148 Training loss: 5.599186420440674
2025-12-09 06:34:30.425 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 611 LR: 0.0006222149757618649 Training loss: 5.508014678955078
2025-12-09 06:34:30.931 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 612 LR: 0.0006209609477998338 Training loss: 5.537717819213867
2025-12-09 06:34:31.435 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 613 LR: 0.0006197061111290779 Training loss: 5.65221643447876
2025-12-09 06:34:31.943 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 614 LR: 0.0006184504741390595 Training loss: 5.581277370452881
2025-12-09 06:34:32.448 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 615 LR: 0.0006171940452245924 Training loss: 5.374187469482422
2025-12-09 06:34:32.954 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 616 LR: 0.0006159368327857844 Training loss: 5.52617073059082
2025-12-09 06:34:33.460 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 617 LR: 0.0006146788452279818 Training loss: 5.516632080078125
2025-12-09 06:34:33.967 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 618 LR: 0.0006134200909617135 Training loss: 5.231686592102051
2025-12-09 06:34:34.470 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 619 LR: 0.0006121605784026339 Training loss: 5.41485071182251
2025-12-09 06:34:34.976 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 620 LR: 0.0006109003159714674 Training loss: 5.210238933563232
2025-12-09 06:34:35.480 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 621 LR: 0.0006096393120939516 Training loss: 5.389270782470703
2025-12-09 06:34:35.986 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 622 LR: 0.0006083775752007818 Training loss: 5.322793960571289
2025-12-09 06:34:36.491 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 623 LR: 0.0006071151137275531 Training loss: 5.394049644470215
2025-12-09 06:34:36.997 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 624 LR: 0.0006058519361147054 Training loss: 5.726523399353027
2025-12-09 06:34:37.502 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 625 LR: 0.0006045880508074668 Training loss: 5.286665439605713
2025-12-09 06:34:38.009 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 626 LR: 0.0006033234662557962 Training loss: 5.281159400939941
2025-12-09 06:34:38.513 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 627 LR: 0.0006020581909143279 Training loss: 5.4173994064331055
2025-12-09 06:34:39.018 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 628 LR: 0.0006007922332423145 Training loss: 5.375534534454346
2025-12-09 06:34:39.523 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 629 LR: 0.0005995256017035703 Training loss: 5.225310802459717
2025-12-09 06:34:40.031 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 630 LR: 0.0005982583047664151 Training loss: 5.497130870819092
2025-12-09 06:34:40.535 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 631 LR: 0.0005969903509036172 Training loss: 5.5912065505981445
2025-12-09 06:34:41.041 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 632 LR: 0.0005957217485923371 Training loss: 5.364015579223633
2025-12-09 06:34:41.545 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 633 LR: 0.0005944525063140702 Training loss: 5.300098419189453
2025-12-09 06:34:42.050 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 634 LR: 0.0005931826325545911 Training loss: 5.206030368804932
2025-12-09 06:34:42.557 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 635 LR: 0.0005919121358038958 Training loss: 5.477181911468506
2025-12-09 06:34:43.067 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 636 LR: 0.0005906410245561459 Training loss: 5.562467575073242
2025-12-09 06:34:43.573 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 637 LR: 0.0005893693073096108 Training loss: 5.209292411804199
2025-12-09 06:34:44.080 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 638 LR: 0.000588096992566612 Training loss: 5.531305313110352
2025-12-09 06:34:44.587 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 639 LR: 0.0005868240888334653 Training loss: 5.299934387207031
2025-12-09 06:34:45.093 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 640 LR: 0.0005855506046204242 Training loss: 5.522555828094482
2025-12-09 06:34:45.599 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 641 LR: 0.0005842765484416237 Training loss: 5.44581937789917
2025-12-09 06:34:46.105 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 642 LR: 0.0005830019288150222 Training loss: 5.709800720214844
2025-12-09 06:34:46.614 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 643 LR: 0.0005817267542623451 Training loss: 5.520503997802734
2025-12-09 06:34:47.122 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 644 LR: 0.0005804510333090287 Training loss: 5.422797679901123
2025-12-09 06:34:47.630 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 645 LR: 0.0005791747744841615 Training loss: 5.444368839263916
2025-12-09 06:34:48.135 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 646 LR: 0.0005778979863204283 Training loss: 5.505731105804443
2025-12-09 06:34:48.643 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 647 LR: 0.0005766206773540531 Training loss: 5.463115692138672
2025-12-09 06:34:49.150 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 648 LR: 0.0005753428561247416 Training loss: 5.424783706665039
2025-12-09 06:34:49.656 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 649 LR: 0.0005740645311756245 Training loss: 5.193671703338623
2025-12-09 06:34:50.164 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 650 LR: 0.0005727857110532 Training loss: 5.60100793838501
2025-12-09 06:34:50.670 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 651 LR: 0.0005715064043072771 Training loss: 5.646783351898193
2025-12-09 06:34:51.177 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 652 LR: 0.0005702266194909183 Training loss: 5.444650173187256
2025-12-09 06:34:51.684 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 653 LR: 0.0005689463651603818 Training loss: 5.247546195983887
2025-12-09 06:34:52.191 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 654 LR: 0.0005676656498750656 Training loss: 5.156333923339844
2025-12-09 06:34:52.697 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 655 LR: 0.0005663844821974488 Training loss: 5.360962867736816
2025-12-09 06:34:53.203 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 656 LR: 0.0005651028706930357 Training loss: 5.682407379150391
2025-12-09 06:34:53.711 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 657 LR: 0.0005638208239302974 Training loss: 5.506241798400879
2025-12-09 06:34:54.217 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 658 LR: 0.0005625383504806149 Training loss: 5.347499370574951
2025-12-09 06:34:54.724 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 659 LR: 0.0005612554589182227 Training loss: 5.2903618812561035
2025-12-09 06:34:55.230 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 660 LR: 0.0005599721578201499 Training loss: 5.5228705406188965
2025-12-09 06:34:55.738 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 661 LR: 0.0005586884557661637 Training loss: 5.378962993621826
2025-12-09 06:34:56.245 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 662 LR: 0.0005574043613387125 Training loss: 5.4755167961120605
2025-12-09 06:34:56.751 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 663 LR: 0.0005561198831228676 Training loss: 5.643684387207031
2025-12-09 06:34:57.258 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 664 LR: 0.0005548350297062658 Training loss: 5.32220983505249
2025-12-09 06:34:57.765 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 665 LR: 0.0005535498096790534 Training loss: 5.371120452880859
2025-12-09 06:34:58.273 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 666 LR: 0.0005522642316338268 Training loss: 5.439716339111328
2025-12-09 06:34:58.780 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 667 LR: 0.0005509783041655764 Training loss: 5.202536106109619
2025-12-09 06:34:59.285 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 668 LR: 0.0005496920358716291 Training loss: 5.460991382598877
2025-12-09 06:34:59.791 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 669 LR: 0.0005484054353515896 Training loss: 5.460024833679199
2025-12-09 06:35:00.294 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 670 LR: 0.0005471185112072845 Training loss: 5.2693071365356445
2025-12-09 06:35:00.802 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 671 LR: 0.0005458312720427037 Training loss: 5.473319053649902
2025-12-09 06:35:01.306 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 672 LR: 0.0005445437264639432 Training loss: 5.203338146209717
2025-12-09 06:35:01.812 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 673 LR: 0.0005432558830791479 Training loss: 5.401544570922852
2025-12-09 06:35:02.317 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 674 LR: 0.0005419677504984534 Training loss: 5.429361343383789
2025-12-09 06:35:02.823 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 675 LR: 0.0005406793373339292 Training loss: 5.331297397613525
2025-12-09 06:35:03.329 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 676 LR: 0.0005393906521995202 Training loss: 5.738683223724365
2025-12-09 06:35:03.836 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 677 LR: 0.0005381017037109899 Training loss: 5.410077095031738
2025-12-09 06:35:04.342 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 678 LR: 0.0005368125004858624 Training loss: 5.496735095977783
2025-12-09 06:35:04.849 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 679 LR: 0.000535523051143365 Training loss: 5.7952985763549805
2025-12-09 06:35:05.355 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 680 LR: 0.0005342333643043704 Training loss: 5.091698169708252
2025-12-09 06:35:05.862 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 681 LR: 0.0005329434485913392 Training loss: 5.315821170806885
2025-12-09 06:35:06.368 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 682 LR: 0.0005316533126282621 Training loss: 5.659584999084473
2025-12-09 06:35:06.875 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 683 LR: 0.0005303629650406024 Training loss: 5.353680610656738
2025-12-09 06:35:07.380 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 684 LR: 0.0005290724144552379 Training loss: 5.461094379425049
2025-12-09 06:35:07.888 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 685 LR: 0.0005277816695004043 Training loss: 5.3240509033203125
2025-12-09 06:35:08.391 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 686 LR: 0.0005264907388056361 Training loss: 5.302343845367432
2025-12-09 06:35:08.899 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 687 LR: 0.00052519963100171 Training loss: 5.532780170440674
2025-12-09 06:35:09.403 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 688 LR: 0.0005239083547205866 Training loss: 5.451340198516846
2025-12-09 06:35:09.909 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 689 LR: 0.0005226169185953532 Training loss: 5.230733871459961
2025-12-09 06:35:10.413 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 690 LR: 0.0005213253312601653 Training loss: 5.5438923835754395
2025-12-09 06:35:10.920 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 691 LR: 0.0005200336013501897 Training loss: 5.728674411773682
2025-12-09 06:35:11.425 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 692 LR: 0.0005187417375015465 Training loss: 5.442759037017822
2025-12-09 06:35:11.931 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 693 LR: 0.0005174497483512506 Training loss: 5.425396919250488
2025-12-09 06:35:12.437 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 694 LR: 0.0005161576425371554 Training loss: 5.589004039764404
2025-12-09 06:35:12.942 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 695 LR: 0.000514865428697894 Training loss: 5.376169204711914
2025-12-09 06:35:13.446 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 696 LR: 0.0005135731154728214 Training loss: 5.498895645141602
2025-12-09 06:35:13.953 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 697 LR: 0.000512280711501958 Training loss: 5.42750358581543
2025-12-09 06:35:14.458 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 698 LR: 0.0005109882254259297 Training loss: 5.129254341125488
2025-12-09 06:35:14.964 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 699 LR: 0.0005096956658859122 Training loss: 5.469648361206055
2025-12-09 06:35:15.468 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 700 LR: 0.000508403041523572 Training loss: 5.02642297744751
2025-12-09 06:35:15.974 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 701 LR: 0.0005071103609810089 Training loss: 5.464561939239502
2025-12-09 06:35:16.478 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 702 LR: 0.0005058176329006986 Training loss: 5.389904975891113
2025-12-09 06:35:16.985 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 703 LR: 0.0005045248659254343 Training loss: 5.4396138191223145
2025-12-09 06:35:17.489 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 704 LR: 0.0005032320686982697 Training loss: 5.381026268005371
2025-12-09 06:35:17.996 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 705 LR: 0.0005019392498624602 Training loss: 5.471817493438721
2025-12-09 06:35:18.500 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 706 LR: 0.000500646418061406 Training loss: 5.7374467849731445
2025-12-09 06:35:19.007 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 707 LR: 0.0004993535819385939 Training loss: 5.513378143310547
2025-12-09 06:35:19.512 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 708 LR: 0.0004980607501375399 Training loss: 5.546234607696533
2025-12-09 06:35:20.020 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 709 LR: 0.0004967679313017304 Training loss: 5.40563440322876
2025-12-09 06:35:20.526 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 710 LR: 0.0004954751340745658 Training loss: 5.256894588470459
2025-12-09 06:35:21.032 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 711 LR: 0.0004941823670993016 Training loss: 5.674759864807129
2025-12-09 06:35:21.538 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 712 LR: 0.0004928896390189912 Training loss: 5.173502445220947
2025-12-09 06:35:22.046 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 713 LR: 0.0004915969584764282 Training loss: 5.584695816040039
2025-12-09 06:35:22.552 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 714 LR: 0.0004903043341140879 Training loss: 5.536176681518555
2025-12-09 06:35:23.058 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 715 LR: 0.0004890117745740703 Training loss: 5.110823154449463
2025-12-09 06:35:23.565 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 716 LR: 0.000487719288498042 Training loss: 5.325491428375244
2025-12-09 06:35:24.071 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 717 LR: 0.0004864268845271786 Training loss: 5.376158237457275
2025-12-09 06:35:24.579 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 718 LR: 0.0004851345713021062 Training loss: 5.307737350463867
2025-12-09 06:35:25.086 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 719 LR: 0.0004838423574628447 Training loss: 5.240143775939941
2025-12-09 06:35:25.592 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 720 LR: 0.0004825502516487497 Training loss: 5.562854766845703
2025-12-09 06:35:26.099 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 721 LR: 0.0004812582624984537 Training loss: 5.161525726318359
2025-12-09 06:35:26.606 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 722 LR: 0.0004799663986498103 Training loss: 5.449770450592041
2025-12-09 06:35:27.111 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 723 LR: 0.0004786746687398346 Training loss: 5.252573490142822
2025-12-09 06:35:27.618 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 724 LR: 0.00047738308140464686 Training loss: 5.410732269287109
2025-12-09 06:35:28.125 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 725 LR: 0.00047609164527941334 Training loss: 5.384839057922363
2025-12-09 06:35:28.631 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 726 LR: 0.00047480036899829003 Training loss: 4.977147102355957
2025-12-09 06:35:29.139 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 727 LR: 0.00047350926119436404 Training loss: 5.248425006866455
2025-12-09 06:35:29.646 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 728 LR: 0.0004722183304995958 Training loss: 5.5419921875
2025-12-09 06:35:30.154 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 729 LR: 0.0004709275855447621 Training loss: 5.312745094299316
2025-12-09 06:35:30.662 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 730 LR: 0.00046963703495939764 Training loss: 5.4555253982543945
2025-12-09 06:35:31.170 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 731 LR: 0.0004683466873717379 Training loss: 5.245416641235352
2025-12-09 06:35:31.677 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 732 LR: 0.00046705655140866074 Training loss: 5.3310866355896
2025-12-09 06:35:32.184 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 733 LR: 0.0004657666356956296 Training loss: 5.247591972351074
2025-12-09 06:35:32.692 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 734 LR: 0.0004644769488566351 Training loss: 5.293309211730957
2025-12-09 06:35:33.199 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 735 LR: 0.0004631874995141376 Training loss: 5.127845287322998
2025-12-09 06:35:33.705 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 736 LR: 0.00046189829628901034 Training loss: 5.199929714202881
2025-12-09 06:35:34.212 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 737 LR: 0.00046060934780047994 Training loss: 5.391140460968018
2025-12-09 06:35:34.717 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 738 LR: 0.00045932066266607093 Training loss: 4.8891167640686035
2025-12-09 06:35:35.224 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 739 LR: 0.0004580322495015465 Training loss: 5.422140121459961
2025-12-09 06:35:35.730 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 740 LR: 0.00045674411692085226 Training loss: 5.545619010925293
2025-12-09 06:35:36.238 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 741 LR: 0.000455456273536057 Training loss: 5.295997619628906
2025-12-09 06:35:36.746 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 742 LR: 0.00045416872795729646 Training loss: 5.34999418258667
2025-12-09 06:35:37.253 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 743 LR: 0.00045288148879271575 Training loss: 5.328889846801758
2025-12-09 06:35:37.760 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 744 LR: 0.0004515945646484105 Training loss: 5.4612812995910645
2025-12-09 06:35:38.267 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 745 LR: 0.00045030796412837105 Training loss: 5.147245407104492
2025-12-09 06:35:38.775 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 746 LR: 0.00044902169583442347 Training loss: 5.141621112823486
2025-12-09 06:35:39.283 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 747 LR: 0.00044773576836617336 Training loss: 5.209555625915527
2025-12-09 06:35:39.789 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 748 LR: 0.0004464501903209467 Training loss: 5.345383167266846
2025-12-09 06:35:40.294 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 749 LR: 0.0004451649702937342 Training loss: 5.584374904632568
2025-12-09 06:35:40.800 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 750 LR: 0.0004438801168771327 Training loss: 5.2721099853515625
2025-12-09 06:35:41.305 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 751 LR: 0.00044259563866128754 Training loss: 5.31793737411499
2025-12-09 06:35:41.811 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 752 LR: 0.0004413115442338363 Training loss: 5.471248149871826
2025-12-09 06:35:42.316 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 753 LR: 0.0004400278421798501 Training loss: 5.47495698928833
2025-12-09 06:35:42.824 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 754 LR: 0.00043874454108177734 Training loss: 5.270859241485596
2025-12-09 06:35:43.328 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 755 LR: 0.000437461649519385 Training loss: 5.2669572830200195
2025-12-09 06:35:43.834 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 756 LR: 0.0004361791760697027 Training loss: 5.644258499145508
2025-12-09 06:35:44.337 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 757 LR: 0.00043489712930696445 Training loss: 5.448400974273682
2025-12-09 06:35:44.845 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 758 LR: 0.00043361551780255115 Training loss: 5.114844799041748
2025-12-09 06:35:45.349 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 759 LR: 0.0004323343501249346 Training loss: 5.354622840881348
2025-12-09 06:35:45.856 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 760 LR: 0.00043105363483961814 Training loss: 5.36065673828125
2025-12-09 06:35:46.361 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 761 LR: 0.00042977338050908186 Training loss: 5.426145076751709
2025-12-09 06:35:46.868 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 762 LR: 0.0004284935956927229 Training loss: 5.030331134796143
2025-12-09 06:35:47.373 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 763 LR: 0.00042721428894680017 Training loss: 5.126349925994873
2025-12-09 06:35:47.879 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 764 LR: 0.0004259354688243757 Training loss: 5.592350482940674
2025-12-09 06:35:48.383 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 765 LR: 0.00042465714387525844 Training loss: 5.44254207611084
2025-12-09 06:35:48.890 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 766 LR: 0.0004233793226459471 Training loss: 5.506592273712158
2025-12-09 06:35:49.393 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 767 LR: 0.0004221020136795718 Training loss: 5.4817986488342285
2025-12-09 06:35:49.899 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 768 LR: 0.00042082522551583864 Training loss: 5.317622184753418
2025-12-09 06:35:50.404 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 769 LR: 0.0004195489666909713 Training loss: 5.060669422149658
2025-12-09 06:35:50.911 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 770 LR: 0.000418273245737655 Training loss: 5.048905849456787
2025-12-09 06:35:51.416 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 771 LR: 0.0004169980711849781 Training loss: 5.21221923828125
2025-12-09 06:35:51.922 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 772 LR: 0.0004157234515583764 Training loss: 4.900056838989258
2025-12-09 06:35:52.429 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 773 LR: 0.0004144493953795759 Training loss: 5.3181867599487305
2025-12-09 06:35:52.938 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 774 LR: 0.00041317591116653486 Training loss: 5.2849812507629395
2025-12-09 06:35:53.443 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 775 LR: 0.0004119030074333881 Training loss: 5.148640155792236
2025-12-09 06:35:53.950 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 776 LR: 0.0004106306926903891 Training loss: 5.472089767456055
2025-12-09 06:35:54.456 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 777 LR: 0.00040935897544385424 Training loss: 5.248226642608643
2025-12-09 06:35:54.962 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 778 LR: 0.0004080878641961042 Training loss: 5.173985004425049
2025-12-09 06:35:55.467 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 779 LR: 0.00040681736744540897 Training loss: 5.603574752807617
2025-12-09 06:35:55.973 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 780 LR: 0.00040554749368592994 Training loss: 5.185990810394287
2025-12-09 06:35:56.477 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 781 LR: 0.0004042782514076631 Training loss: 5.437000274658203
2025-12-09 06:35:56.983 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 782 LR: 0.00040300964909638283 Training loss: 5.182997226715088
2025-12-09 06:35:57.487 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 783 LR: 0.0004017416952335849 Training loss: 5.323938369750977
2025-12-09 06:35:57.993 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 784 LR: 0.0004004743982964298 Training loss: 5.181178569793701
2025-12-09 06:35:58.497 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 785 LR: 0.00039920776675768556 Training loss: 5.553844451904297
2025-12-09 06:35:59.003 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 786 LR: 0.00039794180908567223 Training loss: 5.348104000091553
2025-12-09 06:35:59.507 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 787 LR: 0.000396676533744204 Training loss: 5.393640518188477
2025-12-09 06:36:00.013 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 788 LR: 0.0003954119491925333 Training loss: 5.378676414489746
2025-12-09 06:36:00.518 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 789 LR: 0.00039414806388529477 Training loss: 5.35109806060791
2025-12-09 06:36:01.025 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 790 LR: 0.00039288488627244706 Training loss: 5.220794200897217
2025-12-09 06:36:01.530 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 791 LR: 0.00039162242479921837 Training loss: 5.243144989013672
2025-12-09 06:36:02.035 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 792 LR: 0.0003903606879060483 Training loss: 5.300614833831787
2025-12-09 06:36:02.540 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 793 LR: 0.00038909968402853277 Training loss: 5.514227867126465
2025-12-09 06:36:03.047 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 794 LR: 0.0003878394215973663 Training loss: 5.094855308532715
2025-12-09 06:36:03.555 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 795 LR: 0.0003865799090382866 Training loss: 5.120722770690918
2025-12-09 06:36:04.064 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 796 LR: 0.00038532115477201833 Training loss: 5.202106952667236
2025-12-09 06:36:04.571 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 797 LR: 0.00038406316721421575 Training loss: 5.409056186676025
2025-12-09 06:36:05.078 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 798 LR: 0.0003828059547754077 Training loss: 5.2857208251953125
2025-12-09 06:36:05.583 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 799 LR: 0.00038154952586094037 Training loss: 5.621222019195557
2025-12-09 06:36:06.091 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 800 LR: 0.0003802938888709222 Training loss: 5.641508102416992
2025-12-09 06:36:06.598 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 801 LR: 0.0003790390522001662 Training loss: 5.054666996002197
2025-12-09 06:36:07.105 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 802 LR: 0.00037778502423813516 Training loss: 5.285723686218262
2025-12-09 06:36:07.611 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 803 LR: 0.0003765318133688853 Training loss: 5.367669582366943
2025-12-09 06:36:08.118 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 804 LR: 0.0003752794279710094 Training loss: 5.141838073730469
2025-12-09 06:36:08.624 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 805 LR: 0.00037402787641758193 Training loss: 5.290276050567627
2025-12-09 06:36:09.131 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 806 LR: 0.0003727771670761021 Training loss: 5.255542278289795
2025-12-09 06:36:09.639 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 807 LR: 0.000371527308308439 Training loss: 5.364706993103027
2025-12-09 06:36:10.145 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 808 LR: 0.000370278308470774 Training loss: 5.415828704833984
2025-12-09 06:36:10.651 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 809 LR: 0.00036903017591354703 Training loss: 5.437868595123291
2025-12-09 06:36:11.158 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 810 LR: 0.00036778291898139905 Training loss: 4.793737411499023
2025-12-09 06:36:11.665 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 811 LR: 0.0003665365460131165 Training loss: 5.070176601409912
2025-12-09 06:36:12.173 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 812 LR: 0.00036529106534157683 Training loss: 5.208751678466797
2025-12-09 06:36:12.680 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 813 LR: 0.0003640464852936909 Training loss: 5.529294013977051
2025-12-09 06:36:13.187 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 814 LR: 0.0003628028141903493 Training loss: 5.315188407897949
2025-12-09 06:36:13.695 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 815 LR: 0.00036156006034636465 Training loss: 5.257559299468994
2025-12-09 06:36:14.201 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 816 LR: 0.0003603182320704179 Training loss: 5.325752258300781
2025-12-09 06:36:14.707 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 817 LR: 0.0003590773376650012 Training loss: 5.342979431152344
2025-12-09 06:36:15.215 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 818 LR: 0.00035783738542636347 Training loss: 5.011054039001465
2025-12-09 06:36:15.721 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 819 LR: 0.00035659838364445503 Training loss: 5.065721035003662
2025-12-09 06:36:16.226 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 820 LR: 0.0003553603406028707 Training loss: 5.395405292510986
2025-12-09 06:36:16.733 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 821 LR: 0.0003541232645787964 Training loss: 5.254034042358398
2025-12-09 06:36:17.241 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 822 LR: 0.00035288716384295236 Training loss: 5.28951358795166
2025-12-09 06:36:17.748 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 823 LR: 0.00035165204665953874 Training loss: 5.3473734855651855
2025-12-09 06:36:18.256 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 824 LR: 0.0003504179212861793 Training loss: 5.35814905166626
2025-12-09 06:36:18.764 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 825 LR: 0.00034918479597386727 Training loss: 5.274444103240967
2025-12-09 06:36:19.271 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 826 LR: 0.0003479526789669101 Training loss: 5.339177131652832
2025-12-09 06:36:19.778 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 827 LR: 0.00034672157850287313 Training loss: 5.505632400512695
2025-12-09 06:36:20.284 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 828 LR: 0.00034549150281252633 Training loss: 5.193842887878418
2025-12-09 06:36:20.790 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 829 LR: 0.00034426246011978767 Training loss: 5.048379898071289
2025-12-09 06:36:21.294 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 830 LR: 0.0003430344586416694 Training loss: 5.32592248916626
2025-12-09 06:36:21.799 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 831 LR: 0.0003418075065882217 Training loss: 5.334227561950684
2025-12-09 06:36:22.303 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 832 LR: 0.0003405816121624795 Training loss: 5.598026275634766
2025-12-09 06:36:22.808 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 833 LR: 0.0003393567835604063 Training loss: 5.175179958343506
2025-12-09 06:36:23.312 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 834 LR: 0.0003381330289708395 Training loss: 5.105233669281006
2025-12-09 06:36:23.819 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 835 LR: 0.0003369103565754367 Training loss: 5.242645740509033
2025-12-09 06:36:24.324 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 836 LR: 0.0003356887745486198 Training loss: 5.3331074714660645
2025-12-09 06:36:24.829 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 837 LR: 0.000334468291057521 Training loss: 5.235967636108398
2025-12-09 06:36:25.335 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 838 LR: 0.0003332489142619278 Training loss: 4.957318305969238
2025-12-09 06:36:25.842 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 839 LR: 0.00033203065231422903 Training loss: 5.067165374755859
2025-12-09 06:36:26.348 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 840 LR: 0.0003308135133593595 Training loss: 5.0878071784973145
2025-12-09 06:36:26.855 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 841 LR: 0.0003295975055347464 Training loss: 5.16434383392334
2025-12-09 06:36:27.361 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 842 LR: 0.0003283826369702546 Training loss: 5.534530162811279
2025-12-09 06:36:27.867 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 843 LR: 0.00032716891578813166 Training loss: 5.181488513946533
2025-12-09 06:36:28.372 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 844 LR: 0.0003259563501029548 Training loss: 5.013613224029541
2025-12-09 06:36:28.879 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 845 LR: 0.00032474494802157527 Training loss: 5.428837299346924
2025-12-09 06:36:29.383 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 846 LR: 0.00032353471764306563 Training loss: 5.099055767059326
2025-12-09 06:36:29.891 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 847 LR: 0.00032232566705866383 Training loss: 5.393548011779785
2025-12-09 06:36:30.395 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 848 LR: 0.0003211178043517205 Training loss: 5.161959648132324
2025-12-09 06:36:30.901 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 849 LR: 0.0003199111375976449 Training loss: 5.0495781898498535
2025-12-09 06:36:31.405 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 850 LR: 0.0003187056748638497 Training loss: 5.037445545196533
2025-12-09 06:36:31.913 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 851 LR: 0.00031750142420969855 Training loss: 5.415943145751953
2025-12-09 06:36:32.417 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 852 LR: 0.00031629839368645086 Training loss: 5.319888591766357
2025-12-09 06:36:32.923 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 853 LR: 0.00031509659133720946 Training loss: 5.343287467956543
2025-12-09 06:36:33.428 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 854 LR: 0.00031389602519686513 Training loss: 5.232692241668701
2025-12-09 06:36:33.935 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 855 LR: 0.00031269670329204396 Training loss: 5.411853790283203
2025-12-09 06:36:34.440 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 856 LR: 0.000311498633641054 Training loss: 5.0422444343566895
2025-12-09 06:36:34.946 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 857 LR: 0.0003103018242538302 Training loss: 5.254400253295898
2025-12-09 06:36:35.451 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 858 LR: 0.0003091062831318825 Training loss: 5.353294372558594
2025-12-09 06:36:35.956 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 859 LR: 0.00030791201826824117 Training loss: 5.147210597991943
2025-12-09 06:36:36.460 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 860 LR: 0.0003067190376474043 Training loss: 5.284110069274902
2025-12-09 06:36:36.967 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 861 LR: 0.000305527349245283 Training loss: 5.254392147064209
2025-12-09 06:36:37.471 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 862 LR: 0.00030433696102915013 Training loss: 5.063594818115234
2025-12-09 06:36:37.978 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 863 LR: 0.0003031478809575852 Training loss: 5.36370849609375
2025-12-09 06:36:38.483 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 864 LR: 0.0003019601169804216 Training loss: 5.185967922210693
2025-12-09 06:36:38.989 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 865 LR: 0.00030077367703869464 Training loss: 5.275118827819824
2025-12-09 06:36:39.494 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 866 LR: 0.0002995885690645863 Training loss: 4.78867769241333
2025-12-09 06:36:40.001 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 867 LR: 0.000298404800981375 Training loss: 5.296945095062256
2025-12-09 06:36:40.504 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 868 LR: 0.0002972223807033794 Training loss: 5.3821539878845215
2025-12-09 06:36:41.011 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 869 LR: 0.00029604131613590823 Training loss: 5.280019283294678
2025-12-09 06:36:41.517 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 870 LR: 0.00029486161517520596 Training loss: 5.164342880249023
2025-12-09 06:36:42.023 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 871 LR: 0.0002936832857084003 Training loss: 5.179409503936768
2025-12-09 06:36:42.527 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 872 LR: 0.00029250633561345 Training loss: 5.26992654800415
2025-12-09 06:36:43.034 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 873 LR: 0.0002913307727590911 Training loss: 5.187227249145508
2025-12-09 06:36:43.538 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 874 LR: 0.0002901566050047855 Training loss: 5.222865581512451
2025-12-09 06:36:44.044 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 875 LR: 0.0002889838402006677 Training loss: 5.337109088897705
2025-12-09 06:36:44.549 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 876 LR: 0.0002878124861874923 Training loss: 5.256197452545166
2025-12-09 06:36:45.057 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 877 LR: 0.0002866425507965822 Training loss: 5.400030612945557
2025-12-09 06:36:45.564 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 878 LR: 0.00028547404184977546 Training loss: 5.29117488861084
2025-12-09 06:36:46.072 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 879 LR: 0.0002843069671593734 Training loss: 5.089148044586182
2025-12-09 06:36:46.578 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 880 LR: 0.0002831413345280882 Training loss: 5.309259414672852
2025-12-09 06:36:47.085 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 881 LR: 0.00028197715174899183 Training loss: 5.15742826461792
2025-12-09 06:36:47.592 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 882 LR: 0.00028081442660546124 Training loss: 5.11648416519165
2025-12-09 06:36:48.098 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 883 LR: 0.00027965316687112975 Training loss: 5.0724897384643555
2025-12-09 06:36:48.607 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 884 LR: 0.00027849338030983255 Training loss: 5.42540979385376
2025-12-09 06:36:49.115 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 885 LR: 0.0002773350746755553 Training loss: 5.051258563995361
2025-12-09 06:36:49.624 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 886 LR: 0.0002761782577123837 Training loss: 4.910595893859863
2025-12-09 06:36:50.132 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 887 LR: 0.00027502293715444973 Training loss: 5.187869548797607
2025-12-09 06:36:50.639 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 888 LR: 0.0002738691207258812 Training loss: 5.106128215789795
2025-12-09 06:36:51.146 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 889 LR: 0.0002727168161407497 Training loss: 5.1896586418151855
2025-12-09 06:36:51.652 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 890 LR: 0.00027156603110301924 Training loss: 5.26613712310791
2025-12-09 06:36:52.160 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 891 LR: 0.0002704167733064941 Training loss: 5.070438861846924
2025-12-09 06:36:52.668 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 892 LR: 0.0002692690504347688 Training loss: 5.566954135894775
2025-12-09 06:36:53.177 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 893 LR: 0.00026812287016117476 Training loss: 5.130037307739258
2025-12-09 06:36:53.683 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 894 LR: 0.0002669782401487307 Training loss: 5.426290512084961
2025-12-09 06:36:54.191 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 895 LR: 0.00026583516805009057 Training loss: 5.165337562561035
2025-12-09 06:36:54.698 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 896 LR: 0.00026469366150749254 Training loss: 5.185267925262451
2025-12-09 06:36:55.206 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 897 LR: 0.00026355372815270835 Training loss: 5.336806774139404
2025-12-09 06:36:55.714 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 898 LR: 0.00026241537560699093 Training loss: 5.13301944732666
2025-12-09 06:36:56.222 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 899 LR: 0.00026127861148102547 Training loss: 5.049437999725342
2025-12-09 06:36:56.729 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 900 LR: 0.0002601434433748771 Training loss: 5.339849472045898
2025-12-09 06:36:57.235 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 901 LR: 0.0002590098788779396 Training loss: 5.097744941711426
2025-12-09 06:36:57.742 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 902 LR: 0.0002578779255688869 Training loss: 5.459117412567139
2025-12-09 06:36:58.251 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 903 LR: 0.00025674759101562006 Training loss: 5.605555057525635
2025-12-09 06:36:58.760 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 904 LR: 0.00025561888277521793 Training loss: 5.062516689300537
2025-12-09 06:36:59.265 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 905 LR: 0.0002544918083938863 Training loss: 5.108179092407227
2025-12-09 06:36:59.771 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 906 LR: 0.00025336637540690737 Training loss: 4.931724548339844
2025-12-09 06:37:00.280 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 907 LR: 0.0002522425913385896 Training loss: 5.424071311950684
2025-12-09 06:37:00.788 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 908 LR: 0.0002511204637022173 Training loss: 5.250260353088379
2025-12-09 06:37:01.291 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 909 LR: 0.0002500000000000001 Training loss: 5.209889888763428
2025-12-09 06:37:01.799 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 910 LR: 0.0002488812077230232 Training loss: 5.301787376403809
2025-12-09 06:37:02.303 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 911 LR: 0.00024776409435119773 Training loss: 5.203732490539551
2025-12-09 06:37:02.809 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 912 LR: 0.00024664866735320885 Training loss: 5.054083824157715
2025-12-09 06:37:03.312 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 913 LR: 0.00024553493418646847 Training loss: 5.21712589263916
2025-12-09 06:37:03.819 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 914 LR: 0.00024442290229706345 Training loss: 5.0134711265563965
2025-12-09 06:37:04.323 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 915 LR: 0.00024331257911970627 Training loss: 5.1609673500061035
2025-12-09 06:37:04.829 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 916 LR: 0.0002422039720776858 Training loss: 4.874352931976318
2025-12-09 06:37:05.333 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 917 LR: 0.0002410970885828171 Training loss: 5.297615051269531
2025-12-09 06:37:05.840 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 918 LR: 0.00023999193603539232 Training loss: 5.104078769683838
2025-12-09 06:37:06.343 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 919 LR: 0.00023888852182413084 Training loss: 5.258426189422607
2025-12-09 06:37:06.849 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 920 LR: 0.00023778685332613008 Training loss: 5.332468032836914
2025-12-09 06:37:07.354 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 921 LR: 0.00023668693790681634 Training loss: 5.127704620361328
2025-12-09 06:37:07.861 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 922 LR: 0.000235588782919895 Training loss: 5.292299270629883
2025-12-09 06:37:08.365 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 923 LR: 0.00023449239570730207 Training loss: 4.972316265106201
2025-12-09 06:37:08.872 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 924 LR: 0.0002333977835991545 Training loss: 5.085062026977539
2025-12-09 06:37:09.376 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 925 LR: 0.0002323049539137015 Training loss: 5.174763202667236
2025-12-09 06:37:09.884 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 926 LR: 0.00023121391395727542 Training loss: 4.977289199829102
2025-12-09 06:37:10.388 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 927 LR: 0.00023012467102424372 Training loss: 5.173715114593506
2025-12-09 06:37:10.896 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 928 LR: 0.00022903723239695812 Training loss: 5.149336338043213
2025-12-09 06:37:11.401 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 929 LR: 0.00022795160534570865 Training loss: 5.363941669464111
2025-12-09 06:37:11.907 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 930 LR: 0.00022686779712867316 Training loss: 5.001607894897461
2025-12-09 06:37:12.411 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 931 LR: 0.0002257858149918688 Training loss: 5.279721736907959
2025-12-09 06:37:12.917 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 932 LR: 0.00022470566616910497 Training loss: 5.258906841278076
2025-12-09 06:37:13.421 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 933 LR: 0.00022362735788193367 Training loss: 4.988527297973633
2025-12-09 06:37:13.928 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 934 LR: 0.0002225508973396016 Training loss: 5.341268539428711
2025-12-09 06:37:14.431 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 935 LR: 0.00022147629173900203 Training loss: 4.966921329498291
2025-12-09 06:37:14.939 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 936 LR: 0.00022040354826462666 Training loss: 5.160452842712402
2025-12-09 06:37:15.444 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 937 LR: 0.00021933267408851754 Training loss: 5.086184501647949
2025-12-09 06:37:15.951 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 938 LR: 0.0002182636763702192 Training loss: 5.169779300689697
2025-12-09 06:37:16.458 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 939 LR: 0.0002171965622567308 Training loss: 5.322562217712402
2025-12-09 06:37:16.964 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 940 LR: 0.0002161313388824579 Training loss: 5.031422138214111
2025-12-09 06:37:17.469 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 941 LR: 0.00021506801336916597 Training loss: 5.256865501403809
2025-12-09 06:37:17.977 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 942 LR: 0.00021400659282593083 Training loss: 5.172545909881592
2025-12-09 06:37:18.483 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 943 LR: 0.0002129470843490932 Training loss: 5.210935115814209
2025-12-09 06:37:18.987 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 944 LR: 0.00021188949502220985 Training loss: 5.2387847900390625
2025-12-09 06:37:19.491 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 945 LR: 0.00021083383191600674 Training loss: 5.234600067138672
2025-12-09 06:37:19.997 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 946 LR: 0.00020978010208833186 Training loss: 5.116860389709473
2025-12-09 06:37:20.500 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 947 LR: 0.00020872831258410724 Training loss: 5.029960632324219
2025-12-09 06:37:21.007 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 948 LR: 0.0002076784704352835 Training loss: 5.569661617279053
2025-12-09 06:37:21.510 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 949 LR: 0.0002066305826607911 Training loss: 5.348269939422607
2025-12-09 06:37:22.017 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 950 LR: 0.0002055846562664944 Training loss: 5.031496047973633
2025-12-09 06:37:22.522 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 951 LR: 0.00020454069824514442 Training loss: 5.412001609802246
2025-12-09 06:37:23.029 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 952 LR: 0.00020349871557633244 Training loss: 4.772120475769043
2025-12-09 06:37:23.534 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 953 LR: 0.00020245871522644283 Training loss: 5.293758392333984
2025-12-09 06:37:24.041 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 954 LR: 0.00020142070414860702 Training loss: 5.203555107116699
2025-12-09 06:37:24.545 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 955 LR: 0.00020038468928265663 Training loss: 5.03409481048584
2025-12-09 06:37:25.052 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 956 LR: 0.00019935067755507714 Training loss: 5.281276702880859
2025-12-09 06:37:25.558 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 957 LR: 0.00019831867587896218 Training loss: 5.337550163269043
2025-12-09 06:37:26.066 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 958 LR: 0.00019728869115396574 Training loss: 5.082960605621338
2025-12-09 06:37:26.572 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 959 LR: 0.00019626073026625818 Training loss: 4.949314594268799
2025-12-09 06:37:27.080 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 960 LR: 0.00019523480008847854 Training loss: 5.177562713623047
2025-12-09 06:37:27.585 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 961 LR: 0.00019421090747968878 Training loss: 4.7334418296813965
2025-12-09 06:37:28.093 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 962 LR: 0.00019318905928532908 Training loss: 5.145971775054932
2025-12-09 06:37:28.599 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 963 LR: 0.00019216926233717085 Training loss: 5.046810150146484
2025-12-09 06:37:29.107 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 964 LR: 0.00019115152345327153 Training loss: 5.041445255279541
2025-12-09 06:37:29.613 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 965 LR: 0.00019013584943792884 Training loss: 5.14656925201416
2025-12-09 06:37:30.120 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 966 LR: 0.00018912224708163562 Training loss: 5.1976141929626465
2025-12-09 06:37:30.628 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 967 LR: 0.00018811072316103405 Training loss: 5.303891181945801
2025-12-09 06:37:31.134 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 968 LR: 0.00018710128443887063 Training loss: 5.257090091705322
2025-12-09 06:37:31.641 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 969 LR: 0.00018609393766395082 Training loss: 4.71868371963501
2025-12-09 06:37:32.149 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 970 LR: 0.00018508868957109364 Training loss: 5.326347827911377
2025-12-09 06:37:32.656 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 971 LR: 0.00018408554688108787 Training loss: 4.987061023712158
2025-12-09 06:37:33.163 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 972 LR: 0.0001830845163006448 Training loss: 5.046142101287842
2025-12-09 06:37:33.670 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 973 LR: 0.00018208560452235623 Training loss: 5.09234619140625
2025-12-09 06:37:34.176 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 974 LR: 0.00018108881822464696 Training loss: 5.552682876586914
2025-12-09 06:37:34.682 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 975 LR: 0.00018009416407173257 Training loss: 5.205550670623779
2025-12-09 06:37:35.189 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 976 LR: 0.00017910164871357332 Training loss: 5.316054821014404
2025-12-09 06:37:35.696 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 977 LR: 0.00017811127878582955 Training loss: 4.917858123779297
2025-12-09 06:37:36.201 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 978 LR: 0.00017712306090981894 Training loss: 5.041701793670654
2025-12-09 06:37:36.708 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 979 LR: 0.00017613700169247056 Training loss: 4.982639312744141
2025-12-09 06:37:37.215 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 980 LR: 0.00017515310772628145 Training loss: 5.171400547027588
2025-12-09 06:37:37.723 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 981 LR: 0.00017417138558927244 Training loss: 5.156561851501465
2025-12-09 06:37:38.228 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 982 LR: 0.00017319184184494418 Training loss: 4.994600296020508
2025-12-09 06:37:38.734 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 983 LR: 0.00017221448304223326 Training loss: 5.375201225280762
2025-12-09 06:37:39.239 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 984 LR: 0.00017123931571546826 Training loss: 5.171107292175293
2025-12-09 06:37:39.747 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 985 LR: 0.0001702663463843264 Training loss: 5.257665634155273
2025-12-09 06:37:40.253 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 986 LR: 0.0001692955815537895 Training loss: 5.137796878814697
2025-12-09 06:37:40.761 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 987 LR: 0.0001683270277141014 Training loss: 5.340952396392822
2025-12-09 06:37:41.271 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 988 LR: 0.00016736069134072278 Training loss: 5.22112512588501
2025-12-09 06:37:41.777 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 989 LR: 0.00016639657889429017 Training loss: 5.032062530517578
2025-12-09 06:37:42.283 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 990 LR: 0.00016543469682057105 Training loss: 5.310925483703613
2025-12-09 06:37:42.789 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 991 LR: 0.00016447505155042086 Training loss: 5.2146148681640625
2025-12-09 06:37:43.293 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 992 LR: 0.00016351764949974136 Training loss: 5.084804534912109
2025-12-09 06:37:43.798 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 993 LR: 0.00016256249706943628 Training loss: 5.089147567749023
2025-12-09 06:37:44.302 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 994 LR: 0.00016160960064536906 Training loss: 5.261728763580322
2025-12-09 06:37:44.809 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 995 LR: 0.00016065896659832026 Training loss: 5.137542247772217
2025-12-09 06:37:45.313 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 996 LR: 0.00015971060128394484 Training loss: 5.076667785644531
2025-12-09 06:37:45.819 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 997 LR: 0.00015876451104272955 Training loss: 5.160645484924316
2025-12-09 06:37:46.323 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 998 LR: 0.00015782070219995127 Training loss: 5.12410831451416
2025-12-09 06:37:46.828 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 999 LR: 0.00015687918106563326 Training loss: 5.089380741119385
2025-12-09 06:37:47.334 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1000 LR: 0.00015593995393450445 Training loss: 5.196939468383789
2025-12-09 06:37:47.843 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1001 LR: 0.0001550030270859565 Training loss: 5.287285327911377
2025-12-09 06:37:48.346 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1002 LR: 0.00015406840678400203 Training loss: 5.266974925994873
2025-12-09 06:37:48.855 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1003 LR: 0.00015313609927723333 Training loss: 4.988394737243652
2025-12-09 06:37:49.360 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1004 LR: 0.000152206110798779 Training loss: 4.990608215332031
2025-12-09 06:37:49.868 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1005 LR: 0.00015127844756626435 Training loss: 5.108800888061523
2025-12-09 06:37:50.372 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1006 LR: 0.0001503531157817684 Training loss: 5.185396194458008
2025-12-09 06:37:50.880 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1007 LR: 0.0001494301216317822 Training loss: 5.156940937042236
2025-12-09 06:37:51.386 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1008 LR: 0.00014850947128716913 Training loss: 5.134410858154297
2025-12-09 06:37:51.893 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1009 LR: 0.00014759117090312195 Training loss: 5.140490531921387
2025-12-09 06:37:52.397 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1010 LR: 0.00014667522661912248 Training loss: 4.998571872711182
2025-12-09 06:37:52.904 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1011 LR: 0.00014576164455890013 Training loss: 5.371351718902588
2025-12-09 06:37:53.407 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1012 LR: 0.00014485043083039151 Training loss: 5.133688926696777
2025-12-09 06:37:53.914 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1013 LR: 0.00014394159152569902 Training loss: 4.9556121826171875
2025-12-09 06:37:54.420 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1014 LR: 0.00014303513272105056 Training loss: 5.069442272186279
2025-12-09 06:37:54.925 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1015 LR: 0.00014213106047675857 Training loss: 5.068905353546143
2025-12-09 06:37:55.429 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1016 LR: 0.00014122938083717962 Training loss: 5.146854877471924
2025-12-09 06:37:55.935 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1017 LR: 0.00014033009983067452 Training loss: 4.9433441162109375
2025-12-09 06:37:56.439 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1018 LR: 0.00013943322346956667 Training loss: 5.17777156829834
2025-12-09 06:37:56.946 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1019 LR: 0.00013853875775010356 Training loss: 5.001087665557861
2025-12-09 06:37:57.450 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1020 LR: 0.0001376467086524156 Training loss: 4.987729072570801
2025-12-09 06:37:57.956 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1021 LR: 0.00013675708214047578 Training loss: 5.302513122558594
2025-12-09 06:37:58.464 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1022 LR: 0.0001358698841620614 Training loss: 5.270053386688232
2025-12-09 06:37:58.971 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1023 LR: 0.0001349851206487127 Training loss: 5.068531513214111
2025-12-09 06:37:59.476 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1024 LR: 0.00013410279751569399 Training loss: 5.098647594451904
2025-12-09 06:37:59.982 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1025 LR: 0.0001332229206619538 Training loss: 5.197565078735352
2025-12-09 06:38:00.487 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1026 LR: 0.00013234549597008571 Training loss: 5.285714149475098
2025-12-09 06:38:00.994 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1027 LR: 0.00013147052930628884 Training loss: 4.850401401519775
2025-12-09 06:38:01.498 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1028 LR: 0.0001305980265203286 Training loss: 5.144167423248291
2025-12-09 06:38:02.005 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1029 LR: 0.0001297279934454978 Training loss: 4.876617431640625
2025-12-09 06:38:02.511 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1030 LR: 0.00012886043589857725 Training loss: 5.220320224761963
2025-12-09 06:38:03.018 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1031 LR: 0.00012799535967979747 Training loss: 5.141378879547119
2025-12-09 06:38:03.523 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1032 LR: 0.0001271327705727991 Training loss: 4.9960832595825195
2025-12-09 06:38:04.028 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1033 LR: 0.00012627267434459538 Training loss: 4.96108865737915
2025-12-09 06:38:04.532 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1034 LR: 0.000125415076745532 Training loss: 5.003615379333496
2025-12-09 06:38:05.039 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1035 LR: 0.0001245599835092504 Training loss: 5.187745094299316
2025-12-09 06:38:05.545 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1036 LR: 0.00012370740035264828 Training loss: 4.956505298614502
2025-12-09 06:38:06.053 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1037 LR: 0.0001228573329758413 Training loss: 5.105019569396973
2025-12-09 06:38:06.558 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1038 LR: 0.00012200978706212606 Training loss: 5.145074844360352
2025-12-09 06:38:07.064 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1039 LR: 0.00012116476827794104 Training loss: 5.251063346862793
2025-12-09 06:38:07.571 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1040 LR: 0.00012032228227282915 Training loss: 5.3330769538879395
2025-12-09 06:38:08.077 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1041 LR: 0.00011948233467939979 Training loss: 5.009391784667969
2025-12-09 06:38:08.584 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1042 LR: 0.00011864493111329145 Training loss: 5.204982757568359
2025-12-09 06:38:09.090 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1043 LR: 0.00011781007717313392 Training loss: 5.311103820800781
2025-12-09 06:38:09.597 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1044 LR: 0.00011697777844051105 Training loss: 4.986172676086426
2025-12-09 06:38:10.103 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1045 LR: 0.00011614804047992322 Training loss: 5.138177871704102
2025-12-09 06:38:10.610 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1046 LR: 0.00011532086883875025 Training loss: 5.238357067108154
2025-12-09 06:38:11.117 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1047 LR: 0.00011449626904721472 Training loss: 5.305387496948242
2025-12-09 06:38:11.626 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1048 LR: 0.00011367424661834369 Training loss: 4.963011741638184
2025-12-09 06:38:12.134 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1049 LR: 0.00011285480704793377 Training loss: 5.2563886642456055
2025-12-09 06:38:12.640 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1050 LR: 0.00011203795581451288 Training loss: 5.06411075592041
2025-12-09 06:38:13.147 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1051 LR: 0.00011122369837930362 Training loss: 5.12468957901001
2025-12-09 06:38:13.655 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1052 LR: 0.00011041204018618833 Training loss: 4.934945583343506
2025-12-09 06:38:14.161 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1053 LR: 0.0001096029866616704 Training loss: 5.368044376373291
2025-12-09 06:38:14.666 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1054 LR: 0.00010879654321484011 Training loss: 5.278330326080322
2025-12-09 06:38:15.173 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1055 LR: 0.00010799271523733716 Training loss: 5.082770347595215
2025-12-09 06:38:15.679 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1056 LR: 0.00010719150810331497 Training loss: 5.191122531890869
2025-12-09 06:38:16.186 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1057 LR: 0.00010639292716940486 Training loss: 4.9045562744140625
2025-12-09 06:38:16.691 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1058 LR: 0.00010559697777468013 Training loss: 5.058173179626465
2025-12-09 06:38:17.198 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1059 LR: 0.00010480366524062041 Training loss: 4.983829021453857
2025-12-09 06:38:17.704 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1060 LR: 0.00010401299487107613 Training loss: 5.231223106384277
2025-12-09 06:38:18.212 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1061 LR: 0.00010322497195223285 Training loss: 4.8549957275390625
2025-12-09 06:38:18.718 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1062 LR: 0.00010243960175257604 Training loss: 4.9525957107543945
2025-12-09 06:38:19.224 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1063 LR: 0.00010165688952285651 Training loss: 5.328983306884766
2025-12-09 06:38:19.732 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1064 LR: 0.00010087684049605351 Training loss: 5.268122673034668
2025-12-09 06:38:20.241 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1065 LR: 0.00010009945988734204 Training loss: 4.969598770141602
2025-12-09 06:38:20.749 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1066 LR: 9.932475289405629e-05 Training loss: 5.027522087097168
2025-12-09 06:38:21.255 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1067 LR: 9.855272469565529e-05 Training loss: 4.907242774963379
2025-12-09 06:38:21.763 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1068 LR: 9.7783380453689e-05 Training loss: 5.072864055633545
2025-12-09 06:38:22.272 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1069 LR: 9.701672531176286e-05 Training loss: 4.945041179656982
2025-12-09 06:38:22.778 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1070 LR: 9.62527643955039e-05 Training loss: 5.0050458908081055
2025-12-09 06:38:23.287 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1071 LR: 9.549150281252633e-05 Training loss: 4.692295551300049
2025-12-09 06:38:23.793 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1072 LR: 9.473294565239743e-05 Training loss: 5.12713623046875
2025-12-09 06:38:24.297 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1073 LR: 9.397709798660358e-05 Training loss: 4.875246047973633
2025-12-09 06:38:24.804 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1074 LR: 9.322396486851626e-05 Training loss: 5.295327663421631
2025-12-09 06:38:25.308 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1075 LR: 9.247355133335827e-05 Training loss: 4.9936017990112305
2025-12-09 06:38:25.814 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1076 LR: 9.172586239816988e-05 Training loss: 4.77893590927124
2025-12-09 06:38:26.319 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1077 LR: 9.098090306177625e-05 Training loss: 4.904489517211914
2025-12-09 06:38:26.826 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1078 LR: 9.023867830475213e-05 Training loss: 5.097687244415283
2025-12-09 06:38:27.330 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1079 LR: 8.949919308939081e-05 Training loss: 5.067734241485596
2025-12-09 06:38:27.838 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1080 LR: 8.876245235966885e-05 Training loss: 4.728035926818848
2025-12-09 06:38:28.344 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1081 LR: 8.802846104121476e-05 Training loss: 5.086495876312256
2025-12-09 06:38:28.852 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1082 LR: 8.72972240412751e-05 Training loss: 5.227725982666016
2025-12-09 06:38:29.356 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1083 LR: 8.656874624868133e-05 Training loss: 4.863283157348633
2025-12-09 06:38:29.863 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1084 LR: 8.584303253381848e-05 Training loss: 5.173802852630615
2025-12-09 06:38:30.370 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1085 LR: 8.512008774859136e-05 Training loss: 5.148697376251221
2025-12-09 06:38:30.876 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1086 LR: 8.439991672639264e-05 Training loss: 5.07431697845459
2025-12-09 06:38:31.381 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1087 LR: 8.368252428207041e-05 Training loss: 5.089526176452637
2025-12-09 06:38:31.887 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1088 LR: 8.296791521189595e-05 Training loss: 5.013929843902588
2025-12-09 06:38:32.392 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1089 LR: 8.225609429353187e-05 Training loss: 5.2669267654418945
2025-12-09 06:38:32.900 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1090 LR: 8.154706628599989e-05 Training loss: 4.886359214782715
2025-12-09 06:38:33.405 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1091 LR: 8.084083592964941e-05 Training loss: 4.921736240386963
2025-12-09 06:38:33.911 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1092 LR: 8.013740794612512e-05 Training loss: 5.067159652709961
2025-12-09 06:38:34.416 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1093 LR: 7.943678703833656e-05 Training loss: 5.114887237548828
2025-12-09 06:38:34.922 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1094 LR: 7.873897789042523e-05 Training loss: 4.720829963684082
2025-12-09 06:38:35.427 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1095 LR: 7.804398516773465e-05 Training loss: 5.022157669067383
2025-12-09 06:38:35.934 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1096 LR: 7.73518135167784e-05 Training loss: 5.089077949523926
2025-12-09 06:38:36.439 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1097 LR: 7.666246756520878e-05 Training loss: 5.237839221954346
2025-12-09 06:38:36.946 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1098 LR: 7.597595192178702e-05 Training loss: 5.565190315246582
2025-12-09 06:38:37.451 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1099 LR: 7.529227117635135e-05 Training loss: 5.195168972015381
2025-12-09 06:38:37.958 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1100 LR: 7.46114298997867e-05 Training loss: 5.070818901062012
2025-12-09 06:38:38.462 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1101 LR: 7.393343264399439e-05 Training loss: 5.028101921081543
2025-12-09 06:38:38.968 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1102 LR: 7.325828394186118e-05 Training loss: 5.380706787109375
2025-12-09 06:38:39.473 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1103 LR: 7.258598830722945e-05 Training loss: 4.928155422210693
2025-12-09 06:38:39.980 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1104 LR: 7.191655023486682e-05 Training loss: 5.176582336425781
2025-12-09 06:38:40.484 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1105 LR: 7.1249974200436e-05 Training loss: 5.054225921630859
2025-12-09 06:38:40.990 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1106 LR: 7.058626466046503e-05 Training loss: 4.876331806182861
2025-12-09 06:38:41.495 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1107 LR: 6.992542605231739e-05 Training loss: 5.334898948669434
2025-12-09 06:38:42.002 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1108 LR: 6.926746279416235e-05 Training loss: 5.357376575469971
2025-12-09 06:38:42.506 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1109 LR: 6.861237928494579e-05 Training loss: 5.2515950202941895
2025-12-09 06:38:43.013 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1110 LR: 6.796017990435977e-05 Training loss: 5.00348424911499
2025-12-09 06:38:43.517 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1111 LR: 6.731086901281458e-05 Training loss: 4.847311973571777
2025-12-09 06:38:44.024 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1112 LR: 6.666445095140866e-05 Training loss: 5.071485996246338
2025-12-09 06:38:44.530 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1113 LR: 6.602093004189964e-05 Training loss: 5.152307033538818
2025-12-09 06:38:45.038 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1114 LR: 6.538031058667609e-05 Training loss: 5.276870250701904
2025-12-09 06:38:45.542 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1115 LR: 6.474259686872808e-05 Training loss: 5.235515117645264
2025-12-09 06:38:46.048 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1116 LR: 6.410779315161885e-05 Training loss: 5.290916442871094
2025-12-09 06:38:46.553 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1117 LR: 6.347590367945616e-05 Training loss: 5.228994846343994
2025-12-09 06:38:47.062 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1118 LR: 6.284693267686403e-05 Training loss: 5.064115047454834
2025-12-09 06:38:47.569 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1119 LR: 6.222088434895462e-05 Training loss: 4.795873165130615
2025-12-09 06:38:48.076 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1120 LR: 6.159776288129976e-05 Training loss: 5.232834815979004
2025-12-09 06:38:48.584 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1121 LR: 6.097757243990321e-05 Training loss: 4.977684020996094
2025-12-09 06:38:49.090 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1122 LR: 6.0360317171172794e-05 Training loss: 4.932199954986572
2025-12-09 06:38:49.596 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1123 LR: 5.974600120189289e-05 Training loss: 5.038114547729492
2025-12-09 06:38:50.101 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1124 LR: 5.9134628639195996e-05 Training loss: 5.2087931632995605
2025-12-09 06:38:50.608 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1125 LR: 5.852620357053651e-05 Training loss: 5.103091239929199
2025-12-09 06:38:51.115 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1126 LR: 5.7920730063662554e-05 Training loss: 5.168487071990967
2025-12-09 06:38:51.622 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1127 LR: 5.7318212166588554e-05 Training loss: 5.502992630004883
2025-12-09 06:38:52.130 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1128 LR: 5.671865390756947e-05 Training loss: 5.177426338195801
2025-12-09 06:38:52.637 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1129 LR: 5.612205929507208e-05 Training loss: 5.0992112159729
2025-12-09 06:38:53.145 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1130 LR: 5.5528432317749844e-05 Training loss: 5.199077129364014
2025-12-09 06:38:53.652 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1131 LR: 5.493777694441521e-05 Training loss: 5.257262706756592
2025-12-09 06:38:54.157 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1132 LR: 5.4350097124013286e-05 Training loss: 5.0211501121521
2025-12-09 06:38:54.664 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1133 LR: 5.376539678559566e-05 Training loss: 5.205865383148193
2025-12-09 06:38:55.171 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1134 LR: 5.318367983829392e-05 Training loss: 4.934480667114258
2025-12-09 06:38:55.678 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1135 LR: 5.260495017129363e-05 Training loss: 5.159953594207764
2025-12-09 06:38:56.184 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1136 LR: 5.202921165380825e-05 Training loss: 4.830154895782471
2025-12-09 06:38:56.693 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1137 LR: 5.145646813505339e-05 Training loss: 5.180978298187256
2025-12-09 06:38:57.200 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1138 LR: 5.088672344422085e-05 Training loss: 5.240221977233887
2025-12-09 06:38:57.707 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1139 LR: 5.031998139045352e-05 Training loss: 4.934210777282715
2025-12-09 06:38:58.215 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1140 LR: 4.97562457628189e-05 Training loss: 5.106637954711914
2025-12-09 06:38:58.724 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1141 LR: 4.9195520330285124e-05 Training loss: 5.032790184020996
2025-12-09 06:38:59.231 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1142 LR: 4.8637808841694775e-05 Training loss: 5.400628566741943
2025-12-09 06:38:59.737 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1143 LR: 4.8083115025739754e-05 Training loss: 5.238104343414307
2025-12-09 06:39:00.245 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1144 LR: 4.753144259093733e-05 Training loss: 5.081979751586914
2025-12-09 06:39:00.752 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1145 LR: 4.698279522560439e-05 Training loss: 5.1375412940979
2025-12-09 06:39:01.260 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1146 LR: 4.643717659783309e-05 Training loss: 4.789981365203857
2025-12-09 06:39:01.768 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1147 LR: 4.589459035546645e-05 Training loss: 5.347136974334717
2025-12-09 06:39:02.276 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1148 LR: 4.535504012607383e-05 Training loss: 5.055014610290527
2025-12-09 06:39:02.784 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1149 LR: 4.481852951692672e-05 Training loss: 5.224839687347412
2025-12-09 06:39:03.290 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1150 LR: 4.4285062114974575e-05 Training loss: 5.022178649902344
2025-12-09 06:39:03.794 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1151 LR: 4.375464148682095e-05 Training loss: 5.231297492980957
2025-12-09 06:39:04.299 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1152 LR: 4.322727117869951e-05 Training loss: 5.199582576751709
2025-12-09 06:39:04.807 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1153 LR: 4.2702954716450637e-05 Training loss: 5.214181900024414
2025-12-09 06:39:05.311 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1154 LR: 4.218169560549706e-05 Training loss: 5.209395885467529
2025-12-09 06:39:05.817 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1155 LR: 4.166349733082153e-05 Training loss: 5.096210956573486
2025-12-09 06:39:06.321 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1156 LR: 4.114836335694289e-05 Training loss: 5.040946006774902
2025-12-09 06:39:06.828 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1157 LR: 4.063629712789246e-05 Training loss: 4.952970504760742
2025-12-09 06:39:07.333 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1158 LR: 4.012730206719228e-05 Training loss: 5.078481674194336
2025-12-09 06:39:07.840 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1159 LR: 3.962138157783085e-05 Training loss: 4.938448905944824
2025-12-09 06:39:08.346 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1160 LR: 3.911853904224144e-05 Training loss: 5.02566385269165
2025-12-09 06:39:08.853 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1161 LR: 3.861877782227885e-05 Training loss: 4.894737243652344
2025-12-09 06:39:09.359 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1162 LR: 3.812210125919713e-05 Training loss: 4.967076301574707
2025-12-09 06:39:09.866 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1163 LR: 3.762851267362721e-05 Training loss: 4.988385200500488
2025-12-09 06:39:10.370 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1164 LR: 3.713801536555483e-05 Training loss: 5.2363786697387695
2025-12-09 06:39:10.879 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1165 LR: 3.665061261429831e-05 Training loss: 5.467879295349121
2025-12-09 06:39:11.384 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1166 LR: 3.6166307678486664e-05 Training loss: 5.085550308227539
2025-12-09 06:39:11.890 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1167 LR: 3.56851037960379e-05 Training loss: 5.120542526245117
2025-12-09 06:39:12.395 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1168 LR: 3.520700418413719e-05 Training loss: 5.415722846984863
2025-12-09 06:39:12.901 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1169 LR: 3.4732012039215774e-05 Training loss: 5.097561836242676
2025-12-09 06:39:13.406 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1170 LR: 3.426013053692878e-05 Training loss: 5.313784122467041
2025-12-09 06:39:13.914 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1171 LR: 3.379136283213513e-05 Training loss: 5.231395244598389
2025-12-09 06:39:14.417 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1172 LR: 3.332571205887547e-05 Training loss: 4.951331615447998
2025-12-09 06:39:14.923 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1173 LR: 3.286318133035132e-05 Training loss: 5.10695219039917
2025-12-09 06:39:15.428 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1174 LR: 3.240377373890518e-05 Training loss: 5.03569221496582
2025-12-09 06:39:15.935 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1175 LR: 3.194749235599864e-05 Training loss: 5.175807476043701
2025-12-09 06:39:16.440 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1176 LR: 3.1494340232192667e-05 Training loss: 4.873810291290283
2025-12-09 06:39:16.948 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1177 LR: 3.1044320397126733e-05 Training loss: 5.1562628746032715
2025-12-09 06:39:17.452 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1178 LR: 3.059743585949903e-05 Training loss: 5.001333236694336
2025-12-09 06:39:17.960 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1179 LR: 3.0153689607045842e-05 Training loss: 4.983585357666016
2025-12-09 06:39:18.465 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1180 LR: 2.9713084606521945e-05 Training loss: 4.828852653503418
2025-12-09 06:39:18.971 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1181 LR: 2.9275623803680596e-05 Training loss: 4.991667747497559
2025-12-09 06:39:19.476 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1182 LR: 2.884131012325386e-05 Training loss: 5.334991931915283
2025-12-09 06:39:19.983 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1183 LR: 2.841014646893336e-05 Training loss: 4.992245674133301
2025-12-09 06:39:20.487 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1184 LR: 2.798213572335001e-05 Training loss: 5.1196112632751465
2025-12-09 06:39:20.994 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1185 LR: 2.7557280748055968e-05 Training loss: 4.987288951873779
2025-12-09 06:39:21.498 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1186 LR: 2.7135584383504387e-05 Training loss: 4.946538925170898
2025-12-09 06:39:22.006 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1187 LR: 2.6717049449030972e-05 Training loss: 4.973904132843018
2025-12-09 06:39:22.511 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1188 LR: 2.63016787428354e-05 Training loss: 4.753460884094238
2025-12-09 06:39:23.018 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1189 LR: 2.5889475041961763e-05 Training loss: 4.873575687408447
2025-12-09 06:39:23.522 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1190 LR: 2.548044110228087e-05 Training loss: 4.991891384124756
2025-12-09 06:39:24.028 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1191 LR: 2.5074579658471265e-05 Training loss: 5.0377278327941895
2025-12-09 06:39:24.534 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1192 LR: 2.467189342400128e-05 Training loss: 5.134784698486328
2025-12-09 06:39:25.040 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1193 LR: 2.4272385091110517e-05 Training loss: 5.1002912521362305
2025-12-09 06:39:25.544 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1194 LR: 2.3876057330792345e-05 Training loss: 5.104673862457275
2025-12-09 06:39:26.052 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1195 LR: 2.3482912792775647e-05 Training loss: 4.809692859649658
2025-12-09 06:39:26.557 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1196 LR: 2.3092954105507157e-05 Training loss: 5.100940704345703
2025-12-09 06:39:27.064 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1197 LR: 2.2706183876134045e-05 Training loss: 4.921576976776123
2025-12-09 06:39:27.572 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1198 LR: 2.232260469048647e-05 Training loss: 5.176441669464111
2025-12-09 06:39:28.080 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1199 LR: 2.1942219113060213e-05 Training loss: 5.1934309005737305
2025-12-09 06:39:28.588 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1200 LR: 2.1565029686999303e-05 Training loss: 5.016970157623291
2025-12-09 06:39:29.096 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1201 LR: 2.119103893407964e-05 Training loss: 4.743013381958008
2025-12-09 06:39:29.604 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1202 LR: 2.082024935469157e-05 Training loss: 5.1542229652404785
2025-12-09 06:39:30.110 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1203 LR: 2.0452663427823094e-05 Training loss: 5.327695369720459
2025-12-09 06:39:30.618 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1204 LR: 2.0088283611044034e-05 Training loss: 5.086644649505615
2025-12-09 06:39:31.127 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1205 LR: 1.972711234048885e-05 Training loss: 4.902934551239014
2025-12-09 06:39:31.636 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1206 LR: 1.9369152030840554e-05 Training loss: 4.860082626342773
2025-12-09 06:39:32.144 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1207 LR: 1.901440507531482e-05 Training loss: 5.092313289642334
2025-12-09 06:39:32.652 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1208 LR: 1.866287384564369e-05 Training loss: 5.101746559143066
2025-12-09 06:39:33.159 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1209 LR: 1.8314560692059833e-05 Training loss: 5.004693508148193
2025-12-09 06:39:33.669 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1210 LR: 1.7969467943280858e-05 Training loss: 5.077561855316162
2025-12-09 06:39:34.175 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1211 LR: 1.7627597906493653e-05 Training loss: 4.805635452270508
2025-12-09 06:39:34.681 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1212 LR: 1.728895286733906e-05 Training loss: 5.02857780456543
2025-12-09 06:39:35.188 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1213 LR: 1.6953535089896554e-05 Training loss: 5.154504299163818
2025-12-09 06:39:35.695 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1214 LR: 1.6621346816668993e-05 Training loss: 5.268507957458496
2025-12-09 06:39:36.202 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1215 LR: 1.6292390268568102e-05 Training loss: 4.855146408081055
2025-12-09 06:39:36.709 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1216 LR: 1.596666764489868e-05 Training loss: 4.82800817489624
2025-12-09 06:39:37.219 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1217 LR: 1.5644181123344924e-05 Training loss: 5.233628749847412
2025-12-09 06:39:37.727 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1218 LR: 1.5324932859955398e-05 Training loss: 4.879431247711182
2025-12-09 06:39:38.235 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1219 LR: 1.5008924989128259e-05 Training loss: 5.159229278564453
2025-12-09 06:39:38.743 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1220 LR: 1.4696159623597883e-05 Training loss: 5.062284469604492
2025-12-09 06:39:39.251 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1221 LR: 1.438663885441982e-05 Training loss: 4.946559429168701
2025-12-09 06:39:39.759 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1222 LR: 1.4080364750957474e-05 Training loss: 5.049838066101074
2025-12-09 06:39:40.266 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1223 LR: 1.3777339360867836e-05 Training loss: 5.195394992828369
2025-12-09 06:39:40.775 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1224 LR: 1.3477564710088097e-05 Training loss: 4.889562129974365
2025-12-09 06:39:41.282 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1225 LR: 1.3181042802821896e-05 Training loss: 5.058943748474121
2025-12-09 06:39:41.789 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1226 LR: 1.2887775621526043e-05 Training loss: 4.9972615242004395
2025-12-09 06:39:42.295 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1227 LR: 1.2597765126897198e-05 Training loss: 5.112585544586182
2025-12-09 06:39:42.801 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1228 LR: 1.2311013257858827e-05 Training loss: 4.976977348327637
2025-12-09 06:39:43.306 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1229 LR: 1.2027521931548213e-05 Training loss: 5.0485453605651855
2025-12-09 06:39:43.814 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1230 LR: 1.174729304330352e-05 Training loss: 4.732755184173584
2025-12-09 06:39:44.319 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1231 LR: 1.1470328466651304e-05 Training loss: 5.286560535430908
2025-12-09 06:39:44.825 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1232 LR: 1.1196630053294021e-05 Training loss: 4.734756946563721
2025-12-09 06:39:45.329 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1233 LR: 1.0926199633097156e-05 Training loss: 4.980459213256836
2025-12-09 06:39:45.836 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1234 LR: 1.0659039014077942e-05 Training loss: 5.16513204574585
2025-12-09 06:39:46.342 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1235 LR: 1.0395149982392104e-05 Training loss: 4.985260963439941
2025-12-09 06:39:46.849 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1236 LR: 1.0134534302323029e-05 Training loss: 5.014730453491211
2025-12-09 06:39:47.353 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1237 LR: 9.877193716269051e-06 Training loss: 4.800093173980713
2025-12-09 06:39:47.860 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1238 LR: 9.623129944732467e-06 Training loss: 5.239362716674805
2025-12-09 06:39:48.365 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1239 LR: 9.372344686307655e-06 Training loss: 5.12267541885376
2025-12-09 06:39:48.872 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1240 LR: 9.124839617669855e-06 Training loss: 5.035121917724609
2025-12-09 06:39:49.377 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1241 LR: 8.880616393563967e-06 Training loss: 4.84353494644165
2025-12-09 06:39:49.883 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1242 LR: 8.639676646793382e-06 Training loss: 4.923860549926758
2025-12-09 06:39:50.388 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1243 LR: 8.402021988209219e-06 Training loss: 5.082405090332031
2025-12-09 06:39:50.895 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1244 LR: 8.167654006699443e-06 Training loss: 4.996723175048828
2025-12-09 06:39:51.400 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1245 LR: 7.936574269178377e-06 Training loss: 5.091312408447266
2025-12-09 06:39:51.908 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1246 LR: 7.708784320575924e-06 Training loss: 5.065152645111084
2025-12-09 06:39:52.413 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1247 LR: 7.4842856838276405e-06 Training loss: 4.869030475616455
2025-12-09 06:39:52.919 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1248 LR: 7.263079859864297e-06 Training loss: 4.965134620666504
2025-12-09 06:39:53.424 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1249 LR: 7.045168327601769e-06 Training loss: 5.193537712097168
2025-12-09 06:39:53.931 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1250 LR: 6.8305525439315005e-06 Training loss: 5.143831253051758
2025-12-09 06:39:54.435 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1251 LR: 6.61923394371039e-06 Training loss: 5.4133524894714355
2025-12-09 06:39:54.943 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1252 LR: 6.41121393975147e-06 Training loss: 5.062694072723389
2025-12-09 06:39:55.450 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1253 LR: 6.206493922814249e-06 Training loss: 5.119912624359131
2025-12-09 06:39:55.956 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1254 LR: 6.005075261595494e-06 Training loss: 4.9972662925720215
2025-12-09 06:39:56.461 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1255 LR: 5.8069593027202385e-06 Training loss: 5.30062198638916
2025-12-09 06:39:56.968 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1256 LR: 5.612147370732457e-06 Training loss: 5.244294166564941
2025-12-09 06:39:57.473 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1257 LR: 5.42064076808646e-06 Training loss: 4.849387168884277
2025-12-09 06:39:57.980 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1258 LR: 5.232440775138181e-06 Training loss: 5.200512409210205
2025-12-09 06:39:58.484 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1259 LR: 5.047548650136513e-06 Training loss: 5.153063774108887
2025-12-09 06:39:58.989 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1260 LR: 4.865965629214819e-06 Training loss: 5.054477691650391
2025-12-09 06:39:59.495 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1261 LR: 4.687692926382992e-06 Training loss: 5.167379856109619
2025-12-09 06:40:00.001 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1262 LR: 4.51273173351896e-06 Training loss: 4.906381130218506
2025-12-09 06:40:00.506 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1263 LR: 4.341083220360864e-06 Training loss: 5.0534234046936035
2025-12-09 06:40:01.014 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1264 LR: 4.172748534499449e-06 Training loss: 5.084905624389648
2025-12-09 06:40:01.519 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1265 LR: 4.007728801370014e-06 Training loss: 5.112563610076904
2025-12-09 06:40:02.024 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1266 LR: 3.846025124245145e-06 Training loss: 5.05866813659668
2025-12-09 06:40:02.529 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1267 LR: 3.687638584227382e-06 Training loss: 4.912283420562744
2025-12-09 06:40:03.035 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1268 LR: 3.5325702402416173e-06 Training loss: 4.927056789398193
2025-12-09 06:40:03.542 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1269 LR: 3.3808211290284885e-06 Training loss: 5.149849891662598
2025-12-09 06:40:04.049 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1270 LR: 3.2323922651372184e-06 Training loss: 5.054138660430908
2025-12-09 06:40:04.555 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1271 LR: 3.087284640918786e-06 Training loss: 5.010931968688965
2025-12-09 06:40:05.060 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1272 LR: 2.9454992265193214e-06 Training loss: 5.021953582763672
2025-12-09 06:40:05.565 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1273 LR: 2.807036969873722e-06 Training loss: 4.9572553634643555
2025-12-09 06:40:06.072 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1274 LR: 2.671898796699268e-06 Training loss: 5.131413459777832
2025-12-09 06:40:06.579 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1275 LR: 2.5400856104894065e-06 Training loss: 4.984812259674072
2025-12-09 06:40:07.085 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1276 LR: 2.411598292507533e-06 Training loss: 5.066394805908203
2025-12-09 06:40:07.592 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1277 LR: 2.2864377017816074e-06 Training loss: 4.89996862411499
2025-12-09 06:40:08.098 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1278 LR: 2.1646046750978256e-06 Training loss: 4.92779016494751
2025-12-09 06:40:08.604 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1279 LR: 2.0461000269953455e-06 Training loss: 5.3600850105285645
2025-12-09 06:40:09.112 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1280 LR: 1.9309245497608486e-06 Training loss: 5.113396644592285
2025-12-09 06:40:09.618 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1281 LR: 1.8190790134231528e-06 Training loss: 5.058226108551025
2025-12-09 06:40:10.125 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1282 LR: 1.7105641657479965e-06 Training loss: 4.968355178833008
2025-12-09 06:40:10.634 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1283 LR: 1.6053807322333191e-06 Training loss: 5.219520092010498
2025-12-09 06:40:11.141 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1284 LR: 1.503529416103988e-06 Training loss: 5.1630425453186035
2025-12-09 06:40:11.650 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1285 LR: 1.4050108983074683e-06 Training loss: 5.17979621887207
2025-12-09 06:40:12.156 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1286 LR: 1.30982583750916e-06 Training loss: 5.341156482696533
2025-12-09 06:40:12.664 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1287 LR: 1.2179748700879012e-06 Training loss: 4.940842628479004
2025-12-09 06:40:13.171 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1288 LR: 1.1294586101317506e-06 Training loss: 4.876718997955322
2025-12-09 06:40:13.679 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1289 LR: 1.044277649433989e-06 Training loss: 5.238819122314453
2025-12-09 06:40:14.187 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1290 LR: 9.624325574890126e-07 Training loss: 4.8720903396606445
2025-12-09 06:40:14.694 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1291 LR: 8.839238814886685e-07 Training loss: 4.885980129241943
2025-12-09 06:40:15.199 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1292 LR: 8.08752146318481e-07 Training loss: 4.965731143951416
2025-12-09 06:40:15.706 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1293 LR: 7.369178545542087e-07 Training loss: 4.972187042236328
2025-12-09 06:40:16.214 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1294 LR: 6.684214864584037e-07 Training loss: 5.001369953155518
2025-12-09 06:40:16.723 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1295 LR: 6.032634999773023e-07 Training loss: 5.032280445098877
2025-12-09 06:40:17.229 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1296 LR: 5.41444330737717e-07 Training loss: 4.969507694244385
2025-12-09 06:40:17.737 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1297 LR: 4.82964392044205e-07 Training loss: 4.98810338973999
2025-12-09 06:40:18.246 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1298 LR: 4.278240748760709e-07 Training loss: 5.00898551940918
2025-12-09 06:40:18.755 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1299 LR: 3.7602374788497927e-07 Training loss: 5.312619209289551
2025-12-09 06:40:19.263 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1300 LR: 3.2756375739245723e-07 Training loss: 5.102360725402832
2025-12-09 06:40:19.771 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1301 LR: 2.824444273875071e-07 Training loss: 5.028977394104004
2025-12-09 06:40:20.279 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1302 LR: 2.4066605952444145e-07 Training loss: 5.037347793579102
2025-12-09 06:40:20.786 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1303 LR: 2.0222893312099588e-07 Training loss: 4.96403169631958
2025-12-09 06:40:21.294 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1304 LR: 1.6713330515627513e-07 Training loss: 5.288458824157715
2025-12-09 06:40:21.801 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1305 LR: 1.3537941026914301e-07 Training loss: 5.065418243408203
2025-12-09 06:40:22.307 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1306 LR: 1.0696746075666841e-07 Training loss: 4.8017497062683105
2025-12-09 06:40:22.815 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1307 LR: 8.189764657262622e-08 Training loss: 5.425082206726074
2025-12-09 06:40:23.319 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1308 LR: 6.017013532627625e-08 Training loss: 5.045687675476074
2025-12-09 06:40:23.826 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1309 LR: 4.1785072281363966e-08 Training loss: 5.1073384284973145
2025-12-09 06:40:24.330 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1310 LR: 2.6742580354788272e-08 Training loss: 5.235489845275879
2025-12-09 06:40:24.838 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1311 LR: 1.504276011621286e-08 Training loss: 5.082433700561523
2025-12-09 06:40:25.343 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1312 LR: 6.685689787122584e-09 Training loss: 5.279845714569092
2025-12-09 06:40:25.849 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1313 LR: 1.6714252404348428e-09 Training loss: 5.074512958526611
2025-12-09 06:40:26.076 | INFO     | __main__:<module>:362 - Epoch: 0 Step: 1314 LR: 0.0 Training loss: 5.307467937469482
