2025-12-09 12:05:02.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 3e-05 Training loss: 11.98813247680664
2025-12-09 12:05:03.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 6e-05 Training loss: 12.020317077636719
2025-12-09 12:05:03.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 8.999999999999999e-05 Training loss: 12.033624649047852
2025-12-09 12:05:03.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.00012 Training loss: 12.005095481872559
2025-12-09 12:05:03.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.00015000000000000001 Training loss: 12.001751899719238
2025-12-09 12:05:03.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.00017999999999999998 Training loss: 11.996685028076172
2025-12-09 12:05:03.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.00021000000000000004 Training loss: 11.931672096252441
2025-12-09 12:05:03.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.00024 Training loss: 11.921452522277832
2025-12-09 12:05:03.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.00027 Training loss: 11.826909065246582
2025-12-09 12:05:04.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.00030000000000000003 Training loss: 11.865828514099121
2025-12-09 12:05:04.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00033 Training loss: 11.724854469299316
2025-12-09 12:05:04.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00035999999999999997 Training loss: 11.614480018615723
2025-12-09 12:05:04.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00039000000000000005 Training loss: 11.625214576721191
2025-12-09 12:05:04.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00042000000000000007 Training loss: 11.446258544921875
2025-12-09 12:05:04.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00045 Training loss: 11.374361991882324
2025-12-09 12:05:04.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00048 Training loss: 11.055753707885742
2025-12-09 12:05:04.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00051 Training loss: 10.87437915802002
2025-12-09 12:05:05.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00054 Training loss: 10.909364700317383
2025-12-09 12:05:05.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00057 Training loss: 10.469635009765625
2025-12-09 12:05:05.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0006000000000000001 Training loss: 10.037959098815918
2025-12-09 12:05:05.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00063 Training loss: 9.900455474853516
2025-12-09 12:05:05.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00066 Training loss: 9.990485191345215
2025-12-09 12:05:05.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0006900000000000001 Training loss: 9.535585403442383
2025-12-09 12:05:05.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0007199999999999999 Training loss: 9.310676574707031
2025-12-09 12:05:05.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00075 Training loss: 9.177281379699707
2025-12-09 12:05:06.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0007800000000000001 Training loss: 9.009505271911621
2025-12-09 12:05:06.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0008100000000000001 Training loss: 8.584514617919922
2025-12-09 12:05:06.354 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0008400000000000001 Training loss: 8.662240982055664
2025-12-09 12:05:06.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00087 Training loss: 8.357013702392578
2025-12-09 12:05:06.597 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0009 Training loss: 8.188308715820312
2025-12-09 12:05:06.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00093 Training loss: 8.414538383483887
2025-12-09 12:05:06.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00096 Training loss: 8.390768051147461
2025-12-09 12:05:06.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00099 Training loss: 7.885852336883545
2025-12-09 12:05:07.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00102 Training loss: 7.9445953369140625
2025-12-09 12:05:07.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00105 Training loss: 7.992331027984619
2025-12-09 12:05:07.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00108 Training loss: 8.24866008758545
2025-12-09 12:05:07.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00111 Training loss: 8.662283897399902
2025-12-09 12:05:07.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00114 Training loss: 8.074654579162598
2025-12-09 12:05:07.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00117 Training loss: 8.109217643737793
2025-12-09 12:05:07.819 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0012000000000000001 Training loss: 7.965890884399414
2025-12-09 12:05:07.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00123 Training loss: 8.189459800720215
2025-12-09 12:05:08.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00126 Training loss: 7.842183589935303
2025-12-09 12:05:08.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00129 Training loss: 8.327285766601562
2025-12-09 12:05:08.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00132 Training loss: 8.489036560058594
2025-12-09 12:05:08.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00135 Training loss: 8.092158317565918
2025-12-09 12:05:08.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0013800000000000002 Training loss: 7.6095147132873535
2025-12-09 12:05:08.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00141 Training loss: 7.578208923339844
2025-12-09 12:05:08.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0014399999999999999 Training loss: 7.249727725982666
2025-12-09 12:05:08.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00147 Training loss: 7.911329746246338
2025-12-09 12:05:09.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0015 Training loss: 7.829705715179443
2025-12-09 12:05:09.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0015300000000000001 Training loss: 7.940003395080566
2025-12-09 12:05:09.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0015600000000000002 Training loss: 7.680728435516357
2025-12-09 12:05:09.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.00159 Training loss: 7.6409382820129395
2025-12-09 12:05:09.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0016200000000000001 Training loss: 7.4993462562561035
2025-12-09 12:05:09.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0016500000000000002 Training loss: 7.598169803619385
2025-12-09 12:05:09.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0016800000000000003 Training loss: 6.730731964111328
2025-12-09 12:05:09.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00171 Training loss: 8.407793045043945
2025-12-09 12:05:10.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00174 Training loss: 7.621516704559326
2025-12-09 12:05:10.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0017699999999999999 Training loss: 7.604882717132568
2025-12-09 12:05:10.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0018 Training loss: 7.5927042961120605
2025-12-09 12:05:10.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00183 Training loss: 7.0711259841918945
2025-12-09 12:05:10.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00186 Training loss: 7.033199310302734
2025-12-09 12:05:10.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00189 Training loss: 7.571732521057129
2025-12-09 12:05:10.734 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00192 Training loss: 7.5596089363098145
2025-12-09 12:05:10.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0019500000000000001 Training loss: 7.225132465362549
2025-12-09 12:05:10.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00198 Training loss: 6.966214656829834
2025-12-09 12:05:11.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00201 Training loss: 7.603925704956055
2025-12-09 12:05:11.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00204 Training loss: 7.737853050231934
2025-12-09 12:05:11.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00207 Training loss: 7.299221992492676
2025-12-09 12:05:11.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0021 Training loss: 7.369157314300537
2025-12-09 12:05:11.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00213 Training loss: 7.340426921844482
2025-12-09 12:05:11.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.00216 Training loss: 7.222747325897217
2025-12-09 12:05:11.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00219 Training loss: 7.451982021331787
2025-12-09 12:05:11.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00222 Training loss: 7.374504089355469
2025-12-09 12:05:12.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0022500000000000003 Training loss: 8.08111572265625
2025-12-09 12:05:12.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00228 Training loss: 8.207511901855469
2025-12-09 12:05:12.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.00231 Training loss: 7.2296833992004395
2025-12-09 12:05:12.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.00234 Training loss: 7.442329406738281
2025-12-09 12:05:12.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00237 Training loss: 7.636672496795654
2025-12-09 12:05:12.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0024000000000000002 Training loss: 7.433643817901611
2025-12-09 12:05:12.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0024300000000000003 Training loss: 7.646920680999756
2025-12-09 12:05:12.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00246 Training loss: 7.607159614562988
2025-12-09 12:05:13.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00249 Training loss: 8.273204803466797
2025-12-09 12:05:13.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00252 Training loss: 6.974884033203125
2025-12-09 12:05:13.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00255 Training loss: 7.209382057189941
2025-12-09 12:05:13.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00258 Training loss: 7.208792209625244
2025-12-09 12:05:13.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00261 Training loss: 7.687203407287598
2025-12-09 12:05:13.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00264 Training loss: 7.039453029632568
2025-12-09 12:05:13.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.00267 Training loss: 7.280423641204834
2025-12-09 12:05:13.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0027 Training loss: 7.048717021942139
2025-12-09 12:05:14.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0027300000000000002 Training loss: 7.38893461227417
2025-12-09 12:05:14.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0027600000000000003 Training loss: 7.068789482116699
2025-12-09 12:05:14.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.0027900000000000004 Training loss: 7.514190673828125
2025-12-09 12:05:14.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00282 Training loss: 7.105762004852295
2025-12-09 12:05:14.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00285 Training loss: 7.182415008544922
2025-12-09 12:05:14.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0028799999999999997 Training loss: 7.177349090576172
2025-12-09 12:05:14.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.00291 Training loss: 7.424893379211426
2025-12-09 12:05:14.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00294 Training loss: 6.7787933349609375
2025-12-09 12:05:15.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00297 Training loss: 7.701885223388672
2025-12-09 12:05:15.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.003 Training loss: 7.05919075012207
2025-12-09 12:05:15.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0029999997217736107 Training loss: 7.086114883422852
2025-12-09 12:05:15.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.002999998887094546 Training loss: 7.598290920257568
2025-12-09 12:05:15.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0029999974959631155 Training loss: 7.5694355964660645
2025-12-09 12:05:15.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0029999955483798347 Training loss: 7.1781182289123535
2025-12-09 12:05:15.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0029999930443454273 Training loss: 6.992284297943115
2025-12-09 12:05:15.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.002999989983860821 Training loss: 7.246082305908203
2025-12-09 12:05:16.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0029999863669271528 Training loss: 7.459183692932129
2025-12-09 12:05:16.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0029999821935457623 Training loss: 7.429252624511719
2025-12-09 12:05:16.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0029999774637181993 Training loss: 7.095832347869873
2025-12-09 12:05:16.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.002999972177446218 Training loss: 7.317591190338135
2025-12-09 12:05:16.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.002999966334731779 Training loss: 7.615779876708984
2025-12-09 12:05:16.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0029999599355770503 Training loss: 6.770733833312988
2025-12-09 12:05:16.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0029999529799844054 Training loss: 7.502468109130859
2025-12-09 12:05:16.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0029999454679564244 Training loss: 7.484908580780029
2025-12-09 12:05:16.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.002999937399495895 Training loss: 6.646720886230469
2025-12-09 12:05:17.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0029999287746058094 Training loss: 7.510659217834473
2025-12-09 12:05:17.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.002999919593289368 Training loss: 7.504597187042236
2025-12-09 12:05:17.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.002999909855549976 Training loss: 6.8735456466674805
2025-12-09 12:05:17.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0029998995613912463 Training loss: 7.484748840332031
2025-12-09 12:05:17.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.002999888710816997 Training loss: 7.469799518585205
2025-12-09 12:05:17.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.002999877303831254 Training loss: 7.0493340492248535
2025-12-09 12:05:17.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.002999865340438249 Training loss: 7.920214653015137
2025-12-09 12:05:17.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.0029998528206424202 Training loss: 6.873972415924072
2025-12-09 12:05:18.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.0029998397444484107 Training loss: 7.196199417114258
2025-12-09 12:05:18.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0029998261118610726 Training loss: 7.917972087860107
2025-12-09 12:05:18.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.002999811922885463 Training loss: 6.8861517906188965
2025-12-09 12:05:18.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.0029997971775268454 Training loss: 7.283421516418457
2025-12-09 12:05:18.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.00299978187579069 Training loss: 7.357768535614014
2025-12-09 12:05:18.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0029997660176826735 Training loss: 6.943240165710449
2025-12-09 12:05:18.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.002999749603208678 Training loss: 7.233653545379639
2025-12-09 12:05:18.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.002999732632374793 Training loss: 7.9168596267700195
2025-12-09 12:05:19.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.002999715105187314 Training loss: 7.243625164031982
2025-12-09 12:05:19.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.002999697021652744 Training loss: 6.353390693664551
2025-12-09 12:05:19.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.002999678381777791 Training loss: 7.287785053253174
2025-12-09 12:05:19.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.002999659185569369 Training loss: 6.828713893890381
2025-12-09 12:05:19.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0029996394330345996 Training loss: 6.904609203338623
2025-12-09 12:05:19.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0029996191241808113 Training loss: 7.045434474945068
2025-12-09 12:05:19.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.002999598259015537 Training loss: 7.082573890686035
2025-12-09 12:05:19.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.002999576837546517 Training loss: 6.936346054077148
2025-12-09 12:05:20.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0029995548597816983 Training loss: 7.18700647354126
2025-12-09 12:05:20.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.002999532325729234 Training loss: 7.107272624969482
2025-12-09 12:05:20.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.0029995092353974837 Training loss: 8.086138725280762
2025-12-09 12:05:20.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.002999485588795013 Training loss: 7.249373912811279
2025-12-09 12:05:20.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.0029994613859305936 Training loss: 7.223480224609375
2025-12-09 12:05:20.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0029994366268132045 Training loss: 6.80667781829834
2025-12-09 12:05:20.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.0029994113114520304 Training loss: 6.744720935821533
2025-12-09 12:05:20.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0029993854398564627 Training loss: 7.405220031738281
2025-12-09 12:05:21.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0029993590120360987 Training loss: 7.144330978393555
2025-12-09 12:05:21.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.0029993320280007423 Training loss: 7.1497392654418945
2025-12-09 12:05:21.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.002999304487760404 Training loss: 6.602901458740234
2025-12-09 12:05:21.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0029992763913253002 Training loss: 7.206544876098633
2025-12-09 12:05:21.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.002999247738705854 Training loss: 6.98017692565918
2025-12-09 12:05:21.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0029992185299126946 Training loss: 6.835174560546875
2025-12-09 12:05:21.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.0029991887649566565 Training loss: 7.12421178817749
2025-12-09 12:05:21.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.002999158443848783 Training loss: 7.790450572967529
2025-12-09 12:05:22.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0029991275666003212 Training loss: 6.811736106872559
2025-12-09 12:05:22.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.0029990961332227264 Training loss: 7.060420036315918
2025-12-09 12:05:22.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.002999064143727659 Training loss: 7.154933452606201
2025-12-09 12:05:22.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.0029990315981269864 Training loss: 7.296911716461182
2025-12-09 12:05:22.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0029989984964327813 Training loss: 7.282171726226807
2025-12-09 12:05:22.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.0029989648386573244 Training loss: 7.152685165405273
2025-12-09 12:05:22.748 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.002998930624813101 Training loss: 7.012467384338379
2025-12-09 12:05:22.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.002998895854912803 Training loss: 7.233880519866943
2025-12-09 12:05:22.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.0029988605289693296 Training loss: 7.140772342681885
2025-12-09 12:05:23.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0029988246469957857 Training loss: 7.3661675453186035
2025-12-09 12:05:23.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.002998788209005482 Training loss: 7.312524318695068
2025-12-09 12:05:23.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.002998751215011936 Training loss: 6.516375541687012
2025-12-09 12:05:23.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0029987136650288706 Training loss: 6.929812431335449
2025-12-09 12:05:23.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.002998675559070217 Training loss: 6.8609724044799805
2025-12-09 12:05:23.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.00299863689715011 Training loss: 6.895111560821533
2025-12-09 12:05:23.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0029985976792828934 Training loss: 7.254406929016113
2025-12-09 12:05:23.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.0029985579054831145 Training loss: 6.654031276702881
2025-12-09 12:05:24.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0029985175757655286 Training loss: 7.010246753692627
2025-12-09 12:05:24.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.002998476690145097 Training loss: 7.15181303024292
2025-12-09 12:05:24.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.0029984352486369867 Training loss: 6.963212966918945
2025-12-09 12:05:24.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.002998393251256571 Training loss: 7.211718559265137
2025-12-09 12:05:24.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0029983506980194303 Training loss: 7.077202320098877
2025-12-09 12:05:24.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0029983075889413497 Training loss: 6.9745378494262695
2025-12-09 12:05:24.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.0029982639240383217 Training loss: 7.192485809326172
2025-12-09 12:05:24.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.0029982197033265445 Training loss: 6.301922798156738
2025-12-09 12:05:25.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0029981749268224228 Training loss: 7.0376763343811035
2025-12-09 12:05:25.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.0029981295945425666 Training loss: 6.540614128112793
2025-12-09 12:05:25.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.002998083706503794 Training loss: 6.860949993133545
2025-12-09 12:05:25.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.002998037262723127 Training loss: 6.9038825035095215
2025-12-09 12:05:25.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.002997990263217795 Training loss: 6.875637054443359
2025-12-09 12:05:25.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0029979427080052334 Training loss: 7.065805435180664
2025-12-09 12:05:25.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.002997894597103084 Training loss: 6.904855728149414
2025-12-09 12:05:25.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.0029978459305291943 Training loss: 7.1725263595581055
2025-12-09 12:05:26.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0029977967083016175 Training loss: 6.729778289794922
2025-12-09 12:05:26.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.002997746930438614 Training loss: 6.934265613555908
2025-12-09 12:05:26.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0029976965969586494 Training loss: 6.941344261169434
2025-12-09 12:05:26.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0029976457078803964 Training loss: 7.19559383392334
2025-12-09 12:05:26.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.0029975942632227332 Training loss: 6.979376792907715
2025-12-09 12:05:26.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.002997542263004744 Training loss: 7.3300981521606445
2025-12-09 12:05:26.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.002997489707245719 Training loss: 7.249724388122559
2025-12-09 12:05:26.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0029974365959651544 Training loss: 6.929182052612305
2025-12-09 12:05:27.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0029973829291827544 Training loss: 6.691507816314697
2025-12-09 12:05:27.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.002997328706918426 Training loss: 6.938060283660889
2025-12-09 12:05:27.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0029972739291922843 Training loss: 6.9993085861206055
2025-12-09 12:05:27.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0029972185960246514 Training loss: 7.4263105392456055
2025-12-09 12:05:27.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0029971627074360523 Training loss: 7.228862762451172
2025-12-09 12:05:27.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0029971062634472205 Training loss: 6.750738620758057
2025-12-09 12:05:27.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0029970492640790957 Training loss: 7.2763166427612305
2025-12-09 12:05:27.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.002996991709352822 Training loss: 6.641522407531738
2025-12-09 12:05:28.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0029969335992897513 Training loss: 6.886725902557373
2025-12-09 12:05:28.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0029968749339114404 Training loss: 7.2846503257751465
2025-12-09 12:05:28.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.0029968157132396513 Training loss: 7.206923484802246
2025-12-09 12:05:28.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.002996755937296354 Training loss: 7.082550048828125
2025-12-09 12:05:28.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.002996695606103723 Training loss: 6.808716297149658
2025-12-09 12:05:28.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0029966347196841393 Training loss: 6.572547912597656
2025-12-09 12:05:28.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.00299657327806019 Training loss: 6.8004279136657715
2025-12-09 12:05:28.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.0029965112812546683 Training loss: 7.0698957443237305
2025-12-09 12:05:28.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0029964487292905725 Training loss: 6.591031551361084
2025-12-09 12:05:29.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.0029963856221911075 Training loss: 6.883304595947266
2025-12-09 12:05:29.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.002996321959979685 Training loss: 6.934451103210449
2025-12-09 12:05:29.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.00299625774267992 Training loss: 7.29334020614624
2025-12-09 12:05:29.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0029961929703156364 Training loss: 6.379184722900391
2025-12-09 12:05:29.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.002996127642910863 Training loss: 6.92647647857666
2025-12-09 12:05:29.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.0029960617604898325 Training loss: 7.028370380401611
2025-12-09 12:05:29.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.002995995323076986 Training loss: 7.0811543464660645
2025-12-09 12:05:29.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.002995928330696971 Training loss: 6.890685558319092
2025-12-09 12:05:30.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.002995860783374638 Training loss: 7.706643104553223
2025-12-09 12:05:30.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0029957926811350452 Training loss: 6.878013610839844
2025-12-09 12:05:30.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0029957240240034567 Training loss: 6.7413740158081055
2025-12-09 12:05:30.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0029956548120053422 Training loss: 7.170962810516357
2025-12-09 12:05:30.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.0029955850451663765 Training loss: 6.870187759399414
2025-12-09 12:05:30.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.0029955147235124417 Training loss: 7.636745929718018
2025-12-09 12:05:30.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.002995443847069625 Training loss: 7.187682151794434
2025-12-09 12:05:30.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0029953724158642185 Training loss: 6.975300312042236
2025-12-09 12:05:31.064 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0029953004299227213 Training loss: 7.082615375518799
2025-12-09 12:05:31.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.002995227889271838 Training loss: 6.888105392456055
2025-12-09 12:05:31.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.002995154793938479 Training loss: 7.163969039916992
2025-12-09 12:05:31.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0029950811439497607 Training loss: 6.54183292388916
2025-12-09 12:05:31.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0029950069393330043 Training loss: 7.248185157775879
2025-12-09 12:05:31.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.002994932180115737 Training loss: 6.550455570220947
2025-12-09 12:05:31.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0029948568663256928 Training loss: 7.025433540344238
2025-12-09 12:05:31.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.0029947809979908114 Training loss: 7.061462879180908
2025-12-09 12:05:32.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.002994704575139236 Training loss: 7.30240535736084
2025-12-09 12:05:32.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.002994627597799318 Training loss: 7.129021167755127
2025-12-09 12:05:32.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0029945500659996132 Training loss: 6.7972092628479
2025-12-09 12:05:32.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.0029944719797688844 Training loss: 6.6796650886535645
2025-12-09 12:05:32.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.002994393339136098 Training loss: 7.10182523727417
2025-12-09 12:05:32.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.0029943141441304277 Training loss: 6.628809452056885
2025-12-09 12:05:32.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.0029942343947812517 Training loss: 6.81244421005249
2025-12-09 12:05:32.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.002994154091118156 Training loss: 6.9828081130981445
2025-12-09 12:05:33.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0029940732331709295 Training loss: 6.6157708168029785
2025-12-09 12:05:33.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.0029939918209695676 Training loss: 7.071329116821289
2025-12-09 12:05:33.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0029939098545442733 Training loss: 6.941823959350586
2025-12-09 12:05:33.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0029938273339254516 Training loss: 6.677472114562988
2025-12-09 12:05:33.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.002993744259143717 Training loss: 6.711587429046631
2025-12-09 12:05:33.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.002993660630229886 Training loss: 6.82505464553833
2025-12-09 12:05:33.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.0029935764472149833 Training loss: 7.037490367889404
2025-12-09 12:05:33.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0029934917101302376 Training loss: 7.223073482513428
2025-12-09 12:05:34.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.002993406419007084 Training loss: 7.10621976852417
2025-12-09 12:05:34.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.0029933205738771626 Training loss: 6.809376239776611
2025-12-09 12:05:34.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.0029932341747723194 Training loss: 6.802060604095459
2025-12-09 12:05:34.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.002993147221724606 Training loss: 6.593541622161865
2025-12-09 12:05:34.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0029930597147662785 Training loss: 6.7338409423828125
2025-12-09 12:05:34.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.0029929716539297997 Training loss: 6.879372596740723
2025-12-09 12:05:34.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.0029928830392478376 Training loss: 7.171481132507324
2025-12-09 12:05:34.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.002992793870753265 Training loss: 6.703210353851318
2025-12-09 12:05:34.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0029927041484791614 Training loss: 6.11191463470459
2025-12-09 12:05:35.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00299261387245881 Training loss: 6.605636119842529
2025-12-09 12:05:35.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0029925230427257006 Training loss: 6.912030220031738
2025-12-09 12:05:35.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.0029924316593135285 Training loss: 6.914347171783447
2025-12-09 12:05:35.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.0029923397222561938 Training loss: 6.732860088348389
2025-12-09 12:05:35.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0029922472315878023 Training loss: 6.930025100708008
2025-12-09 12:05:35.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.002992154187342665 Training loss: 6.907292366027832
2025-12-09 12:05:35.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.002992060589555299 Training loss: 6.37298059463501
2025-12-09 12:05:35.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0029919664382604253 Training loss: 6.750514984130859
2025-12-09 12:05:36.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.0029918717334929718 Training loss: 6.665954113006592
2025-12-09 12:05:36.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.00299177647528807 Training loss: 6.813029766082764
2025-12-09 12:05:36.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.002991680663681059 Training loss: 5.885826587677002
2025-12-09 12:05:36.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.002991584298707481 Training loss: 6.899281978607178
2025-12-09 12:05:36.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.002991487380403084 Training loss: 7.518653392791748
2025-12-09 12:05:36.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.002991389908803823 Training loss: 7.222137928009033
2025-12-09 12:05:36.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0029912918839458554 Training loss: 6.804786205291748
2025-12-09 12:05:36.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.002991193305865547 Training loss: 7.185172080993652
2025-12-09 12:05:37.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0029910941745994657 Training loss: 6.8946380615234375
2025-12-09 12:05:37.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0029909944901843864 Training loss: 7.345077037811279
2025-12-09 12:05:37.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.002990894252657289 Training loss: 7.333892822265625
2025-12-09 12:05:37.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.0029907934620553595 Training loss: 6.997591495513916
2025-12-09 12:05:37.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0029906921184159863 Training loss: 6.679353713989258
2025-12-09 12:05:37.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0029905902217767654 Training loss: 6.816385269165039
2025-12-09 12:05:37.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0029904877721754976 Training loss: 7.0955424308776855
2025-12-09 12:05:37.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.002990384769650188 Training loss: 6.82263708114624
2025-12-09 12:05:38.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0029902812142390475 Training loss: 6.762483596801758
2025-12-09 12:05:38.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0029901771059804923 Training loss: 6.780555725097656
2025-12-09 12:05:38.295 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0029900724449131427 Training loss: 6.386040210723877
2025-12-09 12:05:38.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0029899672310758248 Training loss: 6.883411407470703
2025-12-09 12:05:38.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0029898614645075695 Training loss: 7.01676607131958
2025-12-09 12:05:38.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.002989755145247613 Training loss: 6.611011981964111
2025-12-09 12:05:38.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.002989648273335397 Training loss: 7.019101142883301
2025-12-09 12:05:38.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0029895408488105667 Training loss: 7.096496105194092
2025-12-09 12:05:39.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0029894328717129737 Training loss: 6.5327582359313965
2025-12-09 12:05:39.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.0029893243420826736 Training loss: 6.870201110839844
2025-12-09 12:05:39.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.002989215259959928 Training loss: 6.733623504638672
2025-12-09 12:05:39.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.002989105625385203 Training loss: 6.927218437194824
2025-12-09 12:05:39.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.002988995438399169 Training loss: 6.964476585388184
2025-12-09 12:05:39.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0029888846990427024 Training loss: 6.757341384887695
2025-12-09 12:05:39.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.002988773407356884 Training loss: 7.1066389083862305
2025-12-09 12:05:39.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.0029886615633829996 Training loss: 6.322603225708008
2025-12-09 12:05:40.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.002988549167162539 Training loss: 6.427431583404541
2025-12-09 12:05:40.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.0029884362187371986 Training loss: 6.963607311248779
2025-12-09 12:05:40.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0029883227181488783 Training loss: 6.9178547859191895
2025-12-09 12:05:40.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.002988208665439683 Training loss: 6.541426181793213
2025-12-09 12:05:40.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.0029880940606519233 Training loss: 6.805783748626709
2025-12-09 12:05:40.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.002987978903828114 Training loss: 6.969445705413818
2025-12-09 12:05:40.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0029878631950109734 Training loss: 6.805370807647705
2025-12-09 12:05:40.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.0029877469342434273 Training loss: 7.025158882141113
2025-12-09 12:05:41.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.002987630121568604 Training loss: 6.805266380310059
2025-12-09 12:05:41.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.002987512757029838 Training loss: 6.598630905151367
2025-12-09 12:05:41.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0029873948406706667 Training loss: 6.352892875671387
2025-12-09 12:05:41.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0029872763725348342 Training loss: 6.993279933929443
2025-12-09 12:05:41.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.0029871573526662884 Training loss: 6.742519378662109
2025-12-09 12:05:41.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0029870377811091822 Training loss: 6.9930009841918945
2025-12-09 12:05:41.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.002986917657907872 Training loss: 6.519716262817383
2025-12-09 12:05:41.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.00298679698310692 Training loss: 7.770962715148926
2025-12-09 12:05:41.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.002986675756751093 Training loss: 7.010343074798584
2025-12-09 12:05:42.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0029865539788853624 Training loss: 6.959561347961426
2025-12-09 12:05:42.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.0029864316495549037 Training loss: 6.989856719970703
2025-12-09 12:05:42.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.0029863087688050973 Training loss: 6.9069952964782715
2025-12-09 12:05:42.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.002986185336681528 Training loss: 6.645585536956787
2025-12-09 12:05:42.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.0029860613532299847 Training loss: 6.952005863189697
2025-12-09 12:05:42.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.0029859368184964627 Training loss: 6.6477203369140625
2025-12-09 12:05:42.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.002985811732527159 Training loss: 7.0222320556640625
2025-12-09 12:05:42.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0029856860953684774 Training loss: 6.6990485191345215
2025-12-09 12:05:43.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0029855599070670253 Training loss: 6.454990386962891
2025-12-09 12:05:43.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.0029854331676696143 Training loss: 6.622445106506348
2025-12-09 12:05:43.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.0029853058772232608 Training loss: 6.689058780670166
2025-12-09 12:05:43.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.0029851780357751856 Training loss: 6.2664594650268555
2025-12-09 12:05:43.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.002985049643372814 Training loss: 6.52475118637085
2025-12-09 12:05:43.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0029849207000637755 Training loss: 6.678162574768066
2025-12-09 12:05:43.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.0029847912058959033 Training loss: 6.927253723144531
2025-12-09 12:05:43.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.002984661160917237 Training loss: 6.8126726150512695
2025-12-09 12:05:44.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.002984530565176018 Training loss: 7.009664058685303
2025-12-09 12:05:44.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.002984399418720694 Training loss: 6.624544620513916
2025-12-09 12:05:44.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.0029842677215999158 Training loss: 6.5386271476745605
2025-12-09 12:05:44.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.002984135473862539 Training loss: 6.407007694244385
2025-12-09 12:05:44.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.002984002675557623 Training loss: 6.570512294769287
2025-12-09 12:05:44.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.002983869326734432 Training loss: 6.532273292541504
2025-12-09 12:05:44.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.0029837354274424347 Training loss: 6.729857921600342
2025-12-09 12:05:44.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.002983600977731303 Training loss: 6.378969669342041
2025-12-09 12:05:45.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.0029834659776509136 Training loss: 7.510632514953613
2025-12-09 12:05:45.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.0029833304272513473 Training loss: 6.683416843414307
2025-12-09 12:05:45.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.002983194326582889 Training loss: 6.808837413787842
2025-12-09 12:05:45.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0029830576756960285 Training loss: 6.818580627441406
2025-12-09 12:05:45.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0029829204746414577 Training loss: 6.602586269378662
2025-12-09 12:05:45.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0029827827234700744 Training loss: 5.905323505401611
2025-12-09 12:05:45.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.00298264442223298 Training loss: 6.948307514190674
2025-12-09 12:05:45.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.0029825055709814803 Training loss: 7.455341815948486
2025-12-09 12:05:46.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.002982366169767084 Training loss: 6.869459629058838
2025-12-09 12:05:46.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.002982226218641505 Training loss: 6.885716915130615
2025-12-09 12:05:46.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.002982085717656661 Training loss: 6.678483486175537
2025-12-09 12:05:46.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0029819446668646723 Training loss: 6.679804801940918
2025-12-09 12:05:46.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0029818030663178656 Training loss: 6.837352752685547
2025-12-09 12:05:46.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.00298166091606877 Training loss: 6.841495990753174
2025-12-09 12:05:46.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.0029815182161701185 Training loss: 6.787259101867676
2025-12-09 12:05:46.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0029813749666748484 Training loss: 6.735292911529541
2025-12-09 12:05:47.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.0029812311676361003 Training loss: 6.574674129486084
2025-12-09 12:05:47.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.00298108681910722 Training loss: 6.6183695793151855
2025-12-09 12:05:47.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.0029809419211417553 Training loss: 6.583162307739258
2025-12-09 12:05:47.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.0029807964737934593 Training loss: 6.841292858123779
2025-12-09 12:05:47.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0029806504771162884 Training loss: 6.667411804199219
2025-12-09 12:05:47.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.0029805039311644028 Training loss: 6.444013595581055
2025-12-09 12:05:47.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.002980356835992166 Training loss: 7.527584075927734
2025-12-09 12:05:47.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.0029802091916541463 Training loss: 6.606066703796387
2025-12-09 12:05:48.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.002980060998205115 Training loss: 6.430929660797119
2025-12-09 12:05:48.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.0029799122557000466 Training loss: 6.374064922332764
2025-12-09 12:05:48.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.0029797629641941203 Training loss: 6.807084560394287
2025-12-09 12:05:48.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.002979613123742719 Training loss: 6.848287105560303
2025-12-09 12:05:48.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.0029794627344014277 Training loss: 6.897701740264893
2025-12-09 12:05:48.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.002979311796226037 Training loss: 6.638086318969727
2025-12-09 12:05:48.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.00297916030927254 Training loss: 7.404041767120361
2025-12-09 12:05:48.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.0029790082735971337 Training loss: 6.88470983505249
2025-12-09 12:05:49.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.0029788556892562184 Training loss: 6.763189792633057
2025-12-09 12:05:49.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.002978702556306398 Training loss: 6.6315836906433105
2025-12-09 12:05:49.290 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.00297854887480448 Training loss: 6.436560153961182
2025-12-09 12:05:49.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.002978394644807475 Training loss: 6.867447853088379
2025-12-09 12:05:49.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.0029782398663725984 Training loss: 6.524511814117432
2025-12-09 12:05:49.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.0029780845395572676 Training loss: 6.580059051513672
2025-12-09 12:05:49.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.0029779286644191043 Training loss: 6.952443599700928
2025-12-09 12:05:49.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.002977772241015933 Training loss: 6.746650218963623
2025-12-09 12:05:50.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.002977615269405782 Training loss: 6.474046230316162
2025-12-09 12:05:50.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0029774577496468825 Training loss: 6.598649978637695
2025-12-09 12:05:50.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.0029772996817976696 Training loss: 6.622788906097412
2025-12-09 12:05:50.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.002977141065916781 Training loss: 6.862191200256348
2025-12-09 12:05:50.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.0029769819020630597 Training loss: 6.291868686676025
2025-12-09 12:05:50.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0029768221902955485 Training loss: 6.594232082366943
2025-12-09 12:05:50.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.002976661930673497 Training loss: 6.357644557952881
2025-12-09 12:05:50.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.002976501123256355 Training loss: 6.541407585144043
2025-12-09 12:05:51.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.0029763397681037787 Training loss: 6.670552730560303
2025-12-09 12:05:51.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.0029761778652756246 Training loss: 7.7720866203308105
2025-12-09 12:05:51.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.0029760154148319538 Training loss: 6.528280258178711
2025-12-09 12:05:51.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.0029758524168330305 Training loss: 6.716691970825195
2025-12-09 12:05:51.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.0029756888713393216 Training loss: 6.676687240600586
2025-12-09 12:05:51.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.002975524778411498 Training loss: 7.010941028594971
2025-12-09 12:05:51.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.0029753601381104318 Training loss: 6.745908260345459
2025-12-09 12:05:51.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.0029751949504972 Training loss: 6.755494594573975
2025-12-09 12:05:52.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0029750292156330823 Training loss: 6.949006080627441
2025-12-09 12:05:52.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.0029748629335795604 Training loss: 7.18541955947876
2025-12-09 12:05:52.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.002974696104398321 Training loss: 6.591330528259277
2025-12-09 12:05:52.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.002974528728151251 Training loss: 6.770793437957764
2025-12-09 12:05:52.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.0029743608049004424 Training loss: 6.570029258728027
2025-12-09 12:05:52.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.002974192334708189 Training loss: 6.469422817230225
2025-12-09 12:05:52.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.002974023317636989 Training loss: 6.49569034576416
2025-12-09 12:05:52.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.0029738537537495413 Training loss: 6.162042140960693
2025-12-09 12:05:52.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.0029736836431087494 Training loss: 6.575479984283447
2025-12-09 12:05:53.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.0029735129857777188 Training loss: 6.488759994506836
2025-12-09 12:05:53.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.002973341781819758 Training loss: 6.601925373077393
2025-12-09 12:05:53.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.002973170031298378 Training loss: 6.40312385559082
2025-12-09 12:05:53.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.0029729977342772937 Training loss: 6.450708866119385
2025-12-09 12:05:53.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.0029728248908204207 Training loss: 7.596249103546143
2025-12-09 12:05:53.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.0029726515009918793 Training loss: 7.53360652923584
2025-12-09 12:05:53.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.0029724775648559913 Training loss: 6.8780107498168945
2025-12-09 12:05:53.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0029723030824772814 Training loss: 6.445672512054443
2025-12-09 12:05:54.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.002972128053920478 Training loss: 7.416211128234863
2025-12-09 12:05:54.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.00297195247925051 Training loss: 6.566400527954102
2025-12-09 12:05:54.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.0029717763585325103 Training loss: 6.5160441398620605
2025-12-09 12:05:54.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.002971599691831815 Training loss: 6.800753593444824
2025-12-09 12:05:54.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.0029714224792139607 Training loss: 6.634922504425049
2025-12-09 12:05:54.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.002971244720744689 Training loss: 6.7791547775268555
2025-12-09 12:05:54.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.0029710664164899416 Training loss: 6.782408714294434
2025-12-09 12:05:54.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.0029708875665158643 Training loss: 6.822163105010986
2025-12-09 12:05:55.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.0029707081708888047 Training loss: 6.74821138381958
2025-12-09 12:05:55.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.0029705282296753127 Training loss: 6.194578170776367
2025-12-09 12:05:55.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.002970347742942141 Training loss: 6.548239231109619
2025-12-09 12:05:55.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.002970166710756245 Training loss: 6.072834491729736
2025-12-09 12:05:55.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.002969985133184781 Training loss: 6.844629764556885
2025-12-09 12:05:55.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0029698030102951094 Training loss: 6.3774003982543945
2025-12-09 12:05:55.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0029696203421547916 Training loss: 6.292753219604492
2025-12-09 12:05:55.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.0029694371288315913 Training loss: 6.436191558837891
2025-12-09 12:05:56.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.0029692533703934757 Training loss: 6.366152286529541
2025-12-09 12:05:56.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.002969069066908613 Training loss: 6.702482223510742
2025-12-09 12:05:56.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0029688842184453744 Training loss: 6.569467544555664
2025-12-09 12:05:56.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.002968698825072332 Training loss: 6.725257396697998
2025-12-09 12:05:56.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.0029685128868582626 Training loss: 6.452209949493408
2025-12-09 12:05:56.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.0029683264038721418 Training loss: 6.076386451721191
2025-12-09 12:05:56.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.0029681393761831487 Training loss: 6.797595024108887
2025-12-09 12:05:56.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.002967951803860666 Training loss: 6.443729400634766
2025-12-09 12:05:57.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.002967763686974276 Training loss: 6.910253524780273
2025-12-09 12:05:57.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.002967575025593765 Training loss: 6.936112880706787
2025-12-09 12:05:57.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.00296738581978912 Training loss: 6.789383411407471
2025-12-09 12:05:57.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0029671960696305306 Training loss: 6.286722660064697
2025-12-09 12:05:57.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.002967005775188388 Training loss: 6.644083023071289
2025-12-09 12:05:57.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.0029668149365332853 Training loss: 6.542397499084473
2025-12-09 12:05:57.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.002966623553736018 Training loss: 6.516792297363281
2025-12-09 12:05:57.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.0029664316268675824 Training loss: 6.53737735748291
2025-12-09 12:05:58.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0029662391559991783 Training loss: 6.592297554016113
2025-12-09 12:05:58.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.0029660461412022057 Training loss: 7.604376316070557
2025-12-09 12:05:58.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.002965852582548267 Training loss: 6.254014492034912
2025-12-09 12:05:58.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.0029656584801091668 Training loss: 6.340149402618408
2025-12-09 12:05:58.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.0029654638339569107 Training loss: 7.411369323730469
2025-12-09 12:05:58.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.002965268644163706 Training loss: 6.685967445373535
2025-12-09 12:05:58.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.0029650729108019625 Training loss: 6.49324893951416
2025-12-09 12:05:58.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.002964876633944291 Training loss: 6.2864766120910645
2025-12-09 12:05:59.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.0029646798136635038 Training loss: 7.112297534942627
2025-12-09 12:05:59.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.002964482450032615 Training loss: 6.6277594566345215
2025-12-09 12:05:59.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.002964284543124841 Training loss: 6.333153247833252
2025-12-09 12:05:59.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.0029640860930135976 Training loss: 6.84635066986084
2025-12-09 12:05:59.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.002963887099772505 Training loss: 6.529354095458984
2025-12-09 12:05:59.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.0029636875634753827 Training loss: 6.497745037078857
2025-12-09 12:05:59.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.002963487484196253 Training loss: 6.736903667449951
2025-12-09 12:05:59.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.002963286862009338 Training loss: 6.9636616706848145
2025-12-09 12:06:00.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.0029630856969890627 Training loss: 6.979200839996338
2025-12-09 12:06:00.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.0029628839892100536 Training loss: 6.5458784103393555
2025-12-09 12:06:00.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.002962681738747137 Training loss: 6.587778568267822
2025-12-09 12:06:00.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.002962478945675342 Training loss: 6.74720573425293
2025-12-09 12:06:00.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.002962275610069898 Training loss: 6.341144561767578
2025-12-09 12:06:00.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.002962071732006237 Training loss: 6.232266426086426
2025-12-09 12:06:00.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.00296186731155999 Training loss: 7.296854496002197
2025-12-09 12:06:00.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.0029616623488069923 Training loss: 6.866327285766602
2025-12-09 12:06:01.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.0029614568438232768 Training loss: 6.656506538391113
2025-12-09 12:06:01.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.0029612507966850807 Training loss: 6.867827892303467
2025-12-09 12:06:01.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.0029610442074688398 Training loss: 6.49148416519165
2025-12-09 12:06:01.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.0029608370762511937 Training loss: 6.465587615966797
2025-12-09 12:06:01.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.0029606294031089804 Training loss: 6.068771839141846
2025-12-09 12:06:01.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.00296042118811924 Training loss: 6.681188106536865
2025-12-09 12:06:01.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.002960212431359215 Training loss: 6.268427848815918
2025-12-09 12:06:01.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.0029600031329063466 Training loss: 6.794858932495117
2025-12-09 12:06:01.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.002959793292838278 Training loss: 6.239582061767578
2025-12-09 12:06:02.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.002959582911232853 Training loss: 6.586069583892822
2025-12-09 12:06:02.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.0029593719881681173 Training loss: 6.824810981750488
2025-12-09 12:06:02.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.002959160523722316 Training loss: 6.707910537719727
2025-12-09 12:06:02.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0029589485179738963 Training loss: 6.8673624992370605
2025-12-09 12:06:02.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0029587359710015054 Training loss: 6.5138397216796875
2025-12-09 12:06:02.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.0029585228828839915 Training loss: 6.838531494140625
2025-12-09 12:06:02.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.002958309253700404 Training loss: 6.917374134063721
2025-12-09 12:06:02.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.002958095083529992 Training loss: 6.793575286865234
2025-12-09 12:06:03.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0029578803724522058 Training loss: 5.655684471130371
2025-12-09 12:06:03.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.002957665120546697 Training loss: 6.541335582733154
2025-12-09 12:06:03.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.0029574493278933175 Training loss: 6.607463359832764
2025-12-09 12:06:03.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.002957232994572119 Training loss: 6.734254360198975
2025-12-09 12:06:03.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.0029570161206633546 Training loss: 6.510766983032227
2025-12-09 12:06:03.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.0029567987062474772 Training loss: 6.709718227386475
2025-12-09 12:06:03.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.002956580751405141 Training loss: 6.504281997680664
2025-12-09 12:06:03.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.002956362256217201 Training loss: 6.557107448577881
2025-12-09 12:06:04.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.0029561432207647113 Training loss: 6.65219259262085
2025-12-09 12:06:04.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.002955923645128927 Training loss: 6.471831798553467
2025-12-09 12:06:04.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.0029557035293913047 Training loss: 6.287477493286133
2025-12-09 12:06:04.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.0029554828736334995 Training loss: 6.563843250274658
2025-12-09 12:06:04.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0029552616779373684 Training loss: 6.865727424621582
2025-12-09 12:06:04.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.0029550399423849674 Training loss: 6.446978569030762
2025-12-09 12:06:04.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.002954817667058554 Training loss: 6.318028450012207
2025-12-09 12:06:04.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.002954594852040585 Training loss: 5.71954345703125
2025-12-09 12:06:05.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.0029543714974137178 Training loss: 6.738978385925293
2025-12-09 12:06:05.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.00295414760326081 Training loss: 6.495001792907715
2025-12-09 12:06:05.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.002953923169664919 Training loss: 6.588277816772461
2025-12-09 12:06:05.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.002953698196709303 Training loss: 6.528335094451904
2025-12-09 12:06:05.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.00295347268447742 Training loss: 6.70581579208374
2025-12-09 12:06:05.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.002953246633052928 Training loss: 6.691713809967041
2025-12-09 12:06:05.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.0029530200425196837 Training loss: 7.209948539733887
2025-12-09 12:06:05.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.0029527929129617467 Training loss: 6.690213680267334
2025-12-09 12:06:06.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.002952565244463374 Training loss: 7.236590385437012
2025-12-09 12:06:06.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.0029523370371090235 Training loss: 6.684006214141846
2025-12-09 12:06:06.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.002952108290983353 Training loss: 6.421080589294434
2025-12-09 12:06:06.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.002951879006171221 Training loss: 6.622962951660156
2025-12-09 12:06:06.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.0029516491827576833 Training loss: 6.544199466705322
2025-12-09 12:06:06.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.0029514188208279984 Training loss: 6.922192096710205
2025-12-09 12:06:06.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.0029511879204676223 Training loss: 6.914835453033447
2025-12-09 12:06:06.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0029509564817622133 Training loss: 6.756515026092529
2025-12-09 12:06:07.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0029507245047976265 Training loss: 6.704845905303955
2025-12-09 12:06:07.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.002950491989659918 Training loss: 6.601622581481934
2025-12-09 12:06:07.295 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.0029502589364353454 Training loss: 6.527646064758301
2025-12-09 12:06:07.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.0029500253452103622 Training loss: 6.629278182983398
2025-12-09 12:06:07.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.0029497912160716235 Training loss: 6.625006198883057
2025-12-09 12:06:07.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.002949556549105985 Training loss: 7.164630889892578
2025-12-09 12:06:07.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.0029493213444005 Training loss: 6.582413196563721
2025-12-09 12:06:07.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.002949085602042422 Training loss: 7.090836524963379
2025-12-09 12:06:08.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.0029488493221192045 Training loss: 6.221736431121826
2025-12-09 12:06:08.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.002948612504718499 Training loss: 6.576568126678467
2025-12-09 12:06:08.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.0029483751499281585 Training loss: 6.178523540496826
2025-12-09 12:06:08.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.0029481372578362332 Training loss: 6.442831039428711
2025-12-09 12:06:08.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.002947898828530974 Training loss: 6.502846717834473
2025-12-09 12:06:08.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.00294765986210083 Training loss: 6.322373867034912
2025-12-09 12:06:08.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0029474203586344516 Training loss: 6.050717353820801
2025-12-09 12:06:08.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.0029471803182206857 Training loss: 6.424219608306885
2025-12-09 12:06:09.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.0029469397409485807 Training loss: 6.62857723236084
2025-12-09 12:06:09.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.0029466986269073825 Training loss: 6.508120059967041
2025-12-09 12:06:09.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.0029464569761865366 Training loss: 6.612873554229736
2025-12-09 12:06:09.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.002946214788875689 Training loss: 6.184014797210693
2025-12-09 12:06:09.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.0029459720650646826 Training loss: 6.4313740730285645
2025-12-09 12:06:09.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.0029457288048435606 Training loss: 6.021550178527832
2025-12-09 12:06:09.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.002945485008302565 Training loss: 5.214909076690674
2025-12-09 12:06:09.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.0029452406755321363 Training loss: 6.838201999664307
2025-12-09 12:06:10.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.0029449958066229145 Training loss: 6.202032566070557
2025-12-09 12:06:10.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.0029447504016657383 Training loss: 6.4004011154174805
2025-12-09 12:06:10.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.002944504460751645 Training loss: 6.6075873374938965
2025-12-09 12:06:10.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.002944257983971871 Training loss: 6.8642730712890625
2025-12-09 12:06:10.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.002944010971417851 Training loss: 6.5561842918396
2025-12-09 12:06:10.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.00294376342318122 Training loss: 6.447722911834717
2025-12-09 12:06:10.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.00294351533935381 Training loss: 6.399353504180908
2025-12-09 12:06:10.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.002943266720027652 Training loss: 6.589293003082275
2025-12-09 12:06:10.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0029430175652949762 Training loss: 6.7755446434021
2025-12-09 12:06:11.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.0029427678752482114 Training loss: 6.503210544586182
2025-12-09 12:06:11.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.0029425176499799843 Training loss: 6.8726301193237305
2025-12-09 12:06:11.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.002942266889583121 Training loss: 6.270790100097656
2025-12-09 12:06:11.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.0029420155941506454 Training loss: 6.648542881011963
2025-12-09 12:06:11.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.00294176376377578 Training loss: 6.604698657989502
2025-12-09 12:06:11.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.0029415113985519466 Training loss: 6.753939151763916
2025-12-09 12:06:11.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.0029412584985727642 Training loss: 7.065680027008057
2025-12-09 12:06:11.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.002941005063932051 Training loss: 7.319888591766357
2025-12-09 12:06:12.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.002940751094723823 Training loss: 6.486825466156006
2025-12-09 12:06:12.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.0029404965910422953 Training loss: 6.579789638519287
2025-12-09 12:06:12.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.0029402415529818805 Training loss: 6.405035018920898
2025-12-09 12:06:12.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.0029399859806371895 Training loss: 6.709202766418457
2025-12-09 12:06:12.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.002939729874103032 Training loss: 6.760897159576416
2025-12-09 12:06:12.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.002939473233474415 Training loss: 6.436379432678223
2025-12-09 12:06:12.819 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.002939216058846544 Training loss: 7.561707973480225
2025-12-09 12:06:12.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.0029389583503148234 Training loss: 6.544485092163086
2025-12-09 12:06:13.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.0029387001079748537 Training loss: 6.518718242645264
2025-12-09 12:06:13.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.0029384413319224366 Training loss: 5.948535919189453
2025-12-09 12:06:13.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.002938182022253568 Training loss: 6.197293758392334
2025-12-09 12:06:13.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.002937922179064445 Training loss: 6.665858268737793
2025-12-09 12:06:13.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.00293766180245146 Training loss: 6.580999851226807
2025-12-09 12:06:13.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.0029374008925112057 Training loss: 6.56744909286499
2025-12-09 12:06:13.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.0029371394493404707 Training loss: 6.561537265777588
2025-12-09 12:06:13.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.0029368774730362426 Training loss: 6.02355432510376
2025-12-09 12:06:14.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.002936614963695706 Training loss: 6.823266506195068
2025-12-09 12:06:14.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.002936351921416244 Training loss: 6.285183906555176
2025-12-09 12:06:14.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.0029360883462954362 Training loss: 6.3579840660095215
2025-12-09 12:06:14.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.002935824238431062 Training loss: 6.423604965209961
2025-12-09 12:06:14.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.0029355595979210962 Training loss: 6.4203410148620605
2025-12-09 12:06:14.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.002935294424863712 Training loss: 5.817826747894287
2025-12-09 12:06:14.794 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.002935028719357281 Training loss: 5.739675998687744
2025-12-09 12:06:14.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.0029347624815003704 Training loss: 6.755683422088623
2025-12-09 12:06:15.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.0029344957113917472 Training loss: 6.686555862426758
2025-12-09 12:06:15.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.002934228409130374 Training loss: 6.905627250671387
2025-12-09 12:06:15.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.0029339605748154125 Training loss: 6.464472770690918
2025-12-09 12:06:15.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.0029336922085462193 Training loss: 6.782835006713867
2025-12-09 12:06:15.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.002933423310422351 Training loss: 6.549301624298096
2025-12-09 12:06:15.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.00293315388054356 Training loss: 6.267641067504883
2025-12-09 12:06:15.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.002932883919009796 Training loss: 6.312150955200195
2025-12-09 12:06:15.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.002932613425921207 Training loss: 6.599656581878662
2025-12-09 12:06:16.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.002932342401378137 Training loss: 6.5836358070373535
2025-12-09 12:06:16.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.0029320708454811267 Training loss: 6.503737449645996
2025-12-09 12:06:16.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.002931798758330916 Training loss: 6.755625247955322
2025-12-09 12:06:16.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.002931526140028441 Training loss: 6.328779697418213
2025-12-09 12:06:16.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0029312529906748326 Training loss: 6.5220489501953125
2025-12-09 12:06:16.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.0029309793103714224 Training loss: 6.4843268394470215
2025-12-09 12:06:16.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.002930705099219736 Training loss: 6.772233486175537
2025-12-09 12:06:16.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.0029304303573214983 Training loss: 6.428831100463867
2025-12-09 12:06:17.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.0029301550847786293 Training loss: 6.781599998474121
2025-12-09 12:06:17.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.0029298792816932462 Training loss: 6.574564456939697
2025-12-09 12:06:17.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.0029296029481676636 Training loss: 6.625732421875
2025-12-09 12:06:17.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.0029293260843043924 Training loss: 6.6084184646606445
2025-12-09 12:06:17.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.0029290486902061397 Training loss: 6.419661045074463
2025-12-09 12:06:17.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0029287707659758117 Training loss: 5.985689163208008
2025-12-09 12:06:17.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.0029284923117165076 Training loss: 6.254428386688232
2025-12-09 12:06:17.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.0029282133275315265 Training loss: 6.6333794593811035
2025-12-09 12:06:17.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.0029279338135243626 Training loss: 6.140649795532227
2025-12-09 12:06:18.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.0029276537697987062 Training loss: 6.57239294052124
2025-12-09 12:06:18.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.0029273731964584446 Training loss: 6.270838737487793
2025-12-09 12:06:18.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.0029270920936076625 Training loss: 6.352469444274902
2025-12-09 12:06:18.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.0029268104613506397 Training loss: 6.354484558105469
2025-12-09 12:06:18.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.0029265282997918535 Training loss: 6.302236080169678
2025-12-09 12:06:18.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.0029262456090359762 Training loss: 6.3806939125061035
2025-12-09 12:06:18.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.002925962389187877 Training loss: 6.580389976501465
2025-12-09 12:06:18.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.0029256786403526226 Training loss: 6.569784641265869
2025-12-09 12:06:19.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.0029253943626354737 Training loss: 6.580355167388916
2025-12-09 12:06:19.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0029251095561418894 Training loss: 6.36591911315918
2025-12-09 12:06:19.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0029248242209775235 Training loss: 5.67539119720459
2025-12-09 12:06:19.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.002924538357248226 Training loss: 6.477421760559082
2025-12-09 12:06:19.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.0029242519650600437 Training loss: 6.490217685699463
2025-12-09 12:06:19.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.002923965044519219 Training loss: 6.582173824310303
2025-12-09 12:06:19.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.002923677595732191 Training loss: 6.364938735961914
2025-12-09 12:06:19.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0029233896188055933 Training loss: 6.517190933227539
2025-12-09 12:06:20.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.0029231011138462566 Training loss: 6.4929280281066895
2025-12-09 12:06:20.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.0029228120809612072 Training loss: 6.222652435302734
2025-12-09 12:06:20.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.002922522520257667 Training loss: 6.4005327224731445
2025-12-09 12:06:20.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.0029222324318430542 Training loss: 6.500649452209473
2025-12-09 12:06:20.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.0029219418158249826 Training loss: 6.5463643074035645
2025-12-09 12:06:20.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.0029216506723112614 Training loss: 6.182040691375732
2025-12-09 12:06:20.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.0029213590014098953 Training loss: 6.670246124267578
2025-12-09 12:06:20.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.002921066803229085 Training loss: 6.527848243713379
2025-12-09 12:06:21.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.002920774077877228 Training loss: 6.138282299041748
2025-12-09 12:06:21.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.0029204808254629146 Training loss: 6.420607566833496
2025-12-09 12:06:21.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.002920187046094933 Training loss: 6.688811302185059
2025-12-09 12:06:21.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.002919892739882266 Training loss: 6.260159969329834
2025-12-09 12:06:21.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.0029195979069340924 Training loss: 5.897103786468506
2025-12-09 12:06:21.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.0029193025473597855 Training loss: 6.633561134338379
2025-12-09 12:06:21.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0029190066612689142 Training loss: 6.113748550415039
2025-12-09 12:06:21.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0029187102487712433 Training loss: 6.553441524505615
2025-12-09 12:06:22.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.0029184133099767326 Training loss: 7.09044075012207
2025-12-09 12:06:22.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.0029181158449955364 Training loss: 6.109679222106934
2025-12-09 12:06:22.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.0029178178539380054 Training loss: 6.647181034088135
2025-12-09 12:06:22.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.0029175193369146844 Training loss: 6.053887367248535
2025-12-09 12:06:22.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.002917220294036315 Training loss: 7.125547885894775
2025-12-09 12:06:22.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0029169207254138314 Training loss: 6.571855068206787
2025-12-09 12:06:22.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.0029166206311583647 Training loss: 6.518782138824463
2025-12-09 12:06:22.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.00291632001138124 Training loss: 6.4908857345581055
2025-12-09 12:06:23.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0029160188661939783 Training loss: 6.400137901306152
2025-12-09 12:06:23.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.002915717195708295 Training loss: 6.3501434326171875
2025-12-09 12:06:23.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.0029154150000361 Training loss: 6.33779239654541
2025-12-09 12:06:23.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.0029151122792894987 Training loss: 6.762510299682617
2025-12-09 12:06:23.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.00291480903358079 Training loss: 6.576660633087158
2025-12-09 12:06:23.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.00291450526302247 Training loss: 6.591068267822266
2025-12-09 12:06:23.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0029142009677272274 Training loss: 6.274646759033203
2025-12-09 12:06:23.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.0029138961478079456 Training loss: 5.932990550994873
2025-12-09 12:06:24.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.002913590803377704 Training loss: 6.439676284790039
2025-12-09 12:06:24.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.0029132849345497756 Training loss: 6.329270362854004
2025-12-09 12:06:24.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.0029129785414376275 Training loss: 6.703711032867432
2025-12-09 12:06:24.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.0029126716241549225 Training loss: 6.507875919342041
2025-12-09 12:06:24.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0029123641828155173 Training loss: 6.356836795806885
2025-12-09 12:06:24.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.0029120562175334627 Training loss: 6.335257053375244
2025-12-09 12:06:24.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0029117477284230043 Training loss: 6.642904758453369
2025-12-09 12:06:24.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.0029114387155985814 Training loss: 6.370178699493408
2025-12-09 12:06:25.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.0029111291791748283 Training loss: 6.915926933288574
2025-12-09 12:06:25.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.002910819119266574 Training loss: 6.338812828063965
2025-12-09 12:06:25.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.0029105085359888397 Training loss: 6.148807048797607
2025-12-09 12:06:25.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.0029101974294568427 Training loss: 6.199697971343994
2025-12-09 12:06:25.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.0029098857997859936 Training loss: 6.68057107925415
2025-12-09 12:06:25.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.0029095736470918974 Training loss: 6.827271461486816
2025-12-09 12:06:25.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.0029092609714903525 Training loss: 6.526318073272705
2025-12-09 12:06:25.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.002908947773097352 Training loss: 6.738820552825928
2025-12-09 12:06:26.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.002908634052029083 Training loss: 6.212721824645996
2025-12-09 12:06:26.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.0029083198084019256 Training loss: 6.323048114776611
2025-12-09 12:06:26.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0029080050423324543 Training loss: 6.410024166107178
2025-12-09 12:06:26.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.002907689753937438 Training loss: 6.039742946624756
2025-12-09 12:06:26.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.0029073739433338377 Training loss: 6.425073146820068
2025-12-09 12:06:26.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.0029070576106388106 Training loss: 6.164061069488525
2025-12-09 12:06:26.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.002906740755969705 Training loss: 6.155194282531738
2025-12-09 12:06:26.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.002906423379444064 Training loss: 6.36160135269165
2025-12-09 12:06:27.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.0029061054811796248 Training loss: 5.5694260597229
2025-12-09 12:06:27.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.0029057870612943177 Training loss: 6.374414443969727
2025-12-09 12:06:27.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.0029054681199062664 Training loss: 6.260662078857422
2025-12-09 12:06:27.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.002905148657133788 Training loss: 6.149483680725098
2025-12-09 12:06:27.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.0029048286730953927 Training loss: 6.4309983253479
2025-12-09 12:06:27.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.002904508167909785 Training loss: 6.940184116363525
2025-12-09 12:06:27.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.002904187141695863 Training loss: 6.20512580871582
2025-12-09 12:06:27.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.002903865594572716 Training loss: 6.61351203918457
2025-12-09 12:06:28.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.002903543526659628 Training loss: 6.683595657348633
2025-12-09 12:06:28.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.0029032209380760766 Training loss: 6.724071979522705
2025-12-09 12:06:28.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.0029028978289417323 Training loss: 6.699657917022705
2025-12-09 12:06:28.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.002902574199376457 Training loss: 6.500405311584473
2025-12-09 12:06:28.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.002902250049500309 Training loss: 6.364421367645264
2025-12-09 12:06:28.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.0029019253794335363 Training loss: 6.678765773773193
2025-12-09 12:06:28.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.0029016001892965817 Training loss: 6.098539352416992
2025-12-09 12:06:28.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.00290127447921008 Training loss: 6.5119500160217285
2025-12-09 12:06:29.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.0029009482492948608 Training loss: 6.15609884262085
2025-12-09 12:06:29.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.002900621499671944 Training loss: 6.679952144622803
2025-12-09 12:06:29.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.0029002942304625435 Training loss: 6.348617076873779
2025-12-09 12:06:29.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.0028999664417880657 Training loss: 6.336254596710205
2025-12-09 12:06:29.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.0028996381337701104 Training loss: 6.015413761138916
2025-12-09 12:06:29.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.0028993093065304695 Training loss: 6.440831184387207
2025-12-09 12:06:29.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.002898979960191127 Training loss: 6.234418869018555
2025-12-09 12:06:29.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.002898650094874261 Training loss: 6.042644500732422
2025-12-09 12:06:30.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.00289831971070224 Training loss: 6.275795936584473
2025-12-09 12:06:30.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.002897988807797627 Training loss: 6.067231178283691
2025-12-09 12:06:30.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.002897657386283176 Training loss: 7.487936019897461
2025-12-09 12:06:30.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.0028973254462818345 Training loss: 6.422121524810791
2025-12-09 12:06:30.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.002896992987916741 Training loss: 6.401440620422363
2025-12-09 12:06:30.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.0028966600113112277 Training loss: 6.007553577423096
2025-12-09 12:06:30.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.002896326516588819 Training loss: 6.299907207489014
2025-12-09 12:06:30.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.0028959925038732296 Training loss: 6.563823699951172
2025-12-09 12:06:31.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.0028956579732883686 Training loss: 6.310547351837158
2025-12-09 12:06:31.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.002895322924958336 Training loss: 6.556789398193359
2025-12-09 12:06:31.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.002894987359007424 Training loss: 6.165389537811279
2025-12-09 12:06:31.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.0028946512755601175 Training loss: 6.5900397300720215
2025-12-09 12:06:31.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.0028943146747410927 Training loss: 6.432644367218018
2025-12-09 12:06:31.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.002893977556675218 Training loss: 6.723244667053223
2025-12-09 12:06:31.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.002893639921487553 Training loss: 6.725358486175537
2025-12-09 12:06:31.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.0028933017693033502 Training loss: 5.72571325302124
2025-12-09 12:06:32.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.002892963100248053 Training loss: 6.450347900390625
2025-12-09 12:06:32.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.0028926239144472982 Training loss: 6.3730998039245605
2025-12-09 12:06:32.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.002892284212026912 Training loss: 5.979291915893555
