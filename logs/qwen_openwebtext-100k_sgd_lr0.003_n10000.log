2025-12-09 12:16:00.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 3e-05 Training loss: 12.024267196655273
2025-12-09 12:16:00.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 6e-05 Training loss: 12.030048370361328
2025-12-09 12:16:00.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 8.999999999999999e-05 Training loss: 12.044998168945312
2025-12-09 12:16:00.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.00012 Training loss: 12.014548301696777
2025-12-09 12:16:00.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.00015000000000000001 Training loss: 12.041017532348633
2025-12-09 12:16:00.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.00017999999999999998 Training loss: 12.05860424041748
2025-12-09 12:16:00.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.00021000000000000004 Training loss: 12.04239559173584
2025-12-09 12:16:00.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.00024 Training loss: 12.050808906555176
2025-12-09 12:16:01.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.00027 Training loss: 12.016907691955566
2025-12-09 12:16:01.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.00030000000000000003 Training loss: 12.0440092086792
2025-12-09 12:16:01.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00033 Training loss: 12.010168075561523
2025-12-09 12:16:01.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00035999999999999997 Training loss: 12.021406173706055
2025-12-09 12:16:01.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00039000000000000005 Training loss: 12.054570198059082
2025-12-09 12:16:01.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00042000000000000007 Training loss: 12.007979393005371
2025-12-09 12:16:01.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00045 Training loss: 11.979269027709961
2025-12-09 12:16:01.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00048 Training loss: 12.01866340637207
2025-12-09 12:16:01.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00051 Training loss: 11.992287635803223
2025-12-09 12:16:01.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00054 Training loss: 11.972848892211914
2025-12-09 12:16:01.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00057 Training loss: 11.961433410644531
2025-12-09 12:16:01.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0006000000000000001 Training loss: 12.02200984954834
2025-12-09 12:16:01.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00063 Training loss: 11.9581298828125
2025-12-09 12:16:02.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00066 Training loss: 11.951875686645508
2025-12-09 12:16:02.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0006900000000000001 Training loss: 11.898673057556152
2025-12-09 12:16:02.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0007199999999999999 Training loss: 11.938273429870605
2025-12-09 12:16:02.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00075 Training loss: 11.873459815979004
2025-12-09 12:16:02.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0007800000000000001 Training loss: 11.898334503173828
2025-12-09 12:16:02.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0008100000000000001 Training loss: 11.80880069732666
2025-12-09 12:16:02.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0008400000000000001 Training loss: 11.820951461791992
2025-12-09 12:16:02.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00087 Training loss: 11.840654373168945
2025-12-09 12:16:02.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0009 Training loss: 11.82915210723877
2025-12-09 12:16:02.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00093 Training loss: 11.78573989868164
2025-12-09 12:16:02.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00096 Training loss: 11.737135887145996
2025-12-09 12:16:02.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00099 Training loss: 11.72135066986084
2025-12-09 12:16:02.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00102 Training loss: 11.577619552612305
2025-12-09 12:16:03.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00105 Training loss: 11.629162788391113
2025-12-09 12:16:03.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00108 Training loss: 11.60847282409668
2025-12-09 12:16:03.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00111 Training loss: 11.51427936553955
2025-12-09 12:16:03.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00114 Training loss: 11.558639526367188
2025-12-09 12:16:03.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00117 Training loss: 11.480337142944336
2025-12-09 12:16:03.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0012000000000000001 Training loss: 11.400237083435059
2025-12-09 12:16:03.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00123 Training loss: 11.47065544128418
2025-12-09 12:16:03.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00126 Training loss: 11.341158866882324
2025-12-09 12:16:03.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00129 Training loss: 11.390970230102539
2025-12-09 12:16:03.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00132 Training loss: 11.354901313781738
2025-12-09 12:16:03.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00135 Training loss: 11.258203506469727
2025-12-09 12:16:03.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0013800000000000002 Training loss: 11.186676025390625
2025-12-09 12:16:03.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00141 Training loss: 11.047822952270508
2025-12-09 12:16:03.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0014399999999999999 Training loss: 11.143980026245117
2025-12-09 12:16:04.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00147 Training loss: 11.017434120178223
2025-12-09 12:16:04.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0015 Training loss: 11.021531105041504
2025-12-09 12:16:04.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0015300000000000001 Training loss: 10.812978744506836
2025-12-09 12:16:04.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0015600000000000002 Training loss: 10.97402572631836
2025-12-09 12:16:04.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.00159 Training loss: 10.872167587280273
2025-12-09 12:16:04.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0016200000000000001 Training loss: 10.896175384521484
2025-12-09 12:16:04.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0016500000000000002 Training loss: 10.721477508544922
2025-12-09 12:16:04.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0016800000000000003 Training loss: 10.798027992248535
2025-12-09 12:16:04.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00171 Training loss: 11.192351341247559
2025-12-09 12:16:04.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00174 Training loss: 11.227590560913086
2025-12-09 12:16:04.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0017699999999999999 Training loss: 10.61880111694336
2025-12-09 12:16:04.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0018 Training loss: 10.831496238708496
2025-12-09 12:16:04.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00183 Training loss: 10.537388801574707
2025-12-09 12:16:05.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00186 Training loss: 10.475534439086914
2025-12-09 12:16:05.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00189 Training loss: 10.547052383422852
2025-12-09 12:16:05.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00192 Training loss: 10.634500503540039
2025-12-09 12:16:05.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0019500000000000001 Training loss: 10.683850288391113
2025-12-09 12:16:05.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00198 Training loss: 10.380910873413086
2025-12-09 12:16:05.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00201 Training loss: 10.123600006103516
2025-12-09 12:16:05.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00204 Training loss: 10.367328643798828
2025-12-09 12:16:05.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00207 Training loss: 10.174383163452148
2025-12-09 12:16:05.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0021 Training loss: 10.232754707336426
2025-12-09 12:16:05.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00213 Training loss: 10.271026611328125
2025-12-09 12:16:05.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.00216 Training loss: 10.364805221557617
2025-12-09 12:16:05.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00219 Training loss: 10.129598617553711
2025-12-09 12:16:05.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00222 Training loss: 10.157048225402832
2025-12-09 12:16:06.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0022500000000000003 Training loss: 10.249174118041992
2025-12-09 12:16:06.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00228 Training loss: 10.095078468322754
2025-12-09 12:16:06.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.00231 Training loss: 10.230103492736816
2025-12-09 12:16:06.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.00234 Training loss: 10.051762580871582
2025-12-09 12:16:06.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00237 Training loss: 9.978800773620605
2025-12-09 12:16:06.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0024000000000000002 Training loss: 10.231526374816895
2025-12-09 12:16:06.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0024300000000000003 Training loss: 10.003779411315918
2025-12-09 12:16:06.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00246 Training loss: 10.278371810913086
2025-12-09 12:16:06.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00249 Training loss: 10.062847137451172
2025-12-09 12:16:06.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00252 Training loss: 9.986542701721191
2025-12-09 12:16:06.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00255 Training loss: 9.964905738830566
2025-12-09 12:16:06.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00258 Training loss: 10.08197021484375
2025-12-09 12:16:06.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00261 Training loss: 9.700592041015625
2025-12-09 12:16:07.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00264 Training loss: 9.862425804138184
2025-12-09 12:16:07.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.00267 Training loss: 9.781599044799805
2025-12-09 12:16:07.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0027 Training loss: 9.8959321975708
2025-12-09 12:16:07.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0027300000000000002 Training loss: 10.065193176269531
2025-12-09 12:16:07.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0027600000000000003 Training loss: 9.945561408996582
2025-12-09 12:16:07.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.0027900000000000004 Training loss: 10.251777648925781
2025-12-09 12:16:07.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00282 Training loss: 9.768040657043457
2025-12-09 12:16:07.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00285 Training loss: 9.619107246398926
2025-12-09 12:16:07.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0028799999999999997 Training loss: 9.95107364654541
2025-12-09 12:16:07.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.00291 Training loss: 9.867955207824707
2025-12-09 12:16:07.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00294 Training loss: 9.853203773498535
2025-12-09 12:16:07.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00297 Training loss: 10.02677059173584
2025-12-09 12:16:07.953 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.003 Training loss: 9.929947853088379
2025-12-09 12:16:08.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0029999997217736107 Training loss: 9.957551956176758
2025-12-09 12:16:08.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.002999998887094546 Training loss: 10.110867500305176
2025-12-09 12:16:08.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0029999974959631155 Training loss: 9.79988956451416
2025-12-09 12:16:08.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0029999955483798347 Training loss: 9.741684913635254
2025-12-09 12:16:08.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0029999930443454273 Training loss: 9.793586730957031
2025-12-09 12:16:08.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.002999989983860821 Training loss: 9.906944274902344
2025-12-09 12:16:08.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0029999863669271528 Training loss: 9.280632019042969
2025-12-09 12:16:08.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0029999821935457623 Training loss: 9.982831001281738
2025-12-09 12:16:08.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0029999774637181993 Training loss: 9.720170974731445
2025-12-09 12:16:08.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.002999972177446218 Training loss: 9.69477367401123
2025-12-09 12:16:08.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.002999966334731779 Training loss: 9.720417022705078
2025-12-09 12:16:08.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0029999599355770503 Training loss: 9.775152206420898
2025-12-09 12:16:08.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0029999529799844054 Training loss: 9.924912452697754
2025-12-09 12:16:09.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0029999454679564244 Training loss: 10.032919883728027
2025-12-09 12:16:09.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.002999937399495895 Training loss: 9.712276458740234
2025-12-09 12:16:09.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0029999287746058094 Training loss: 10.333159446716309
2025-12-09 12:16:09.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.002999919593289368 Training loss: 9.71900463104248
2025-12-09 12:16:09.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.002999909855549976 Training loss: 9.724533081054688
2025-12-09 12:16:09.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0029998995613912463 Training loss: 9.871687889099121
2025-12-09 12:16:09.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.002999888710816997 Training loss: 9.701870918273926
2025-12-09 12:16:09.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.002999877303831254 Training loss: 10.169604301452637
2025-12-09 12:16:09.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.002999865340438249 Training loss: 9.808095932006836
2025-12-09 12:16:09.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.0029998528206424202 Training loss: 9.542765617370605
2025-12-09 12:16:09.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.0029998397444484107 Training loss: 9.321769714355469
2025-12-09 12:16:09.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0029998261118610726 Training loss: 9.569223403930664
2025-12-09 12:16:10.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.002999811922885463 Training loss: 9.352450370788574
2025-12-09 12:16:10.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.0029997971775268454 Training loss: 9.689104080200195
2025-12-09 12:16:10.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.00299978187579069 Training loss: 9.59543514251709
2025-12-09 12:16:10.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0029997660176826735 Training loss: 9.687918663024902
2025-12-09 12:16:10.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.002999749603208678 Training loss: 9.565632820129395
2025-12-09 12:16:10.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.002999732632374793 Training loss: 9.77469253540039
2025-12-09 12:16:10.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.002999715105187314 Training loss: 9.772965431213379
2025-12-09 12:16:10.547 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.002999697021652744 Training loss: 9.598884582519531
2025-12-09 12:16:10.623 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.002999678381777791 Training loss: 9.772110939025879
2025-12-09 12:16:10.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.002999659185569369 Training loss: 9.777083396911621
2025-12-09 12:16:10.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0029996394330345996 Training loss: 9.468250274658203
2025-12-09 12:16:10.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0029996191241808113 Training loss: 9.635578155517578
2025-12-09 12:16:10.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.002999598259015537 Training loss: 9.694147109985352
2025-12-09 12:16:11.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.002999576837546517 Training loss: 9.215314865112305
2025-12-09 12:16:11.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0029995548597816983 Training loss: 9.620136260986328
2025-12-09 12:16:11.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.002999532325729234 Training loss: 9.188176155090332
2025-12-09 12:16:11.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.0029995092353974837 Training loss: 9.781842231750488
2025-12-09 12:16:11.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.002999485588795013 Training loss: 9.700920104980469
2025-12-09 12:16:11.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.0029994613859305936 Training loss: 9.582155227661133
2025-12-09 12:16:11.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0029994366268132045 Training loss: 9.26371955871582
2025-12-09 12:16:11.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.0029994113114520304 Training loss: 9.501544952392578
2025-12-09 12:16:11.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0029993854398564627 Training loss: 10.193399429321289
2025-12-09 12:16:11.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0029993590120360987 Training loss: 9.854642868041992
2025-12-09 12:16:11.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.0029993320280007423 Training loss: 9.66426944732666
2025-12-09 12:16:11.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.002999304487760404 Training loss: 9.72213077545166
2025-12-09 12:16:11.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0029992763913253002 Training loss: 9.603127479553223
2025-12-09 12:16:12.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.002999247738705854 Training loss: 9.551066398620605
2025-12-09 12:16:12.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0029992185299126946 Training loss: 9.61121940612793
2025-12-09 12:16:12.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.0029991887649566565 Training loss: 9.53122615814209
2025-12-09 12:16:12.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.002999158443848783 Training loss: 9.577966690063477
2025-12-09 12:16:12.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0029991275666003212 Training loss: 9.442188262939453
2025-12-09 12:16:12.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.0029990961332227264 Training loss: 9.46190071105957
2025-12-09 12:16:12.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.002999064143727659 Training loss: 9.59204387664795
2025-12-09 12:16:12.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.0029990315981269864 Training loss: 9.720100402832031
2025-12-09 12:16:12.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0029989984964327813 Training loss: 9.58468246459961
2025-12-09 12:16:12.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.0029989648386573244 Training loss: 9.646653175354004
2025-12-09 12:16:12.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.002998930624813101 Training loss: 9.623867988586426
2025-12-09 12:16:12.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.002998895854912803 Training loss: 9.491554260253906
2025-12-09 12:16:12.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.0029988605289693296 Training loss: 9.638243675231934
2025-12-09 12:16:12.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0029988246469957857 Training loss: 9.560232162475586
2025-12-09 12:16:13.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.002998788209005482 Training loss: 9.512137413024902
2025-12-09 12:16:13.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.002998751215011936 Training loss: 9.745166778564453
2025-12-09 12:16:13.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0029987136650288706 Training loss: 9.343249320983887
2025-12-09 12:16:13.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.002998675559070217 Training loss: 9.556411743164062
2025-12-09 12:16:13.376 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.00299863689715011 Training loss: 9.569089889526367
2025-12-09 12:16:13.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0029985976792828934 Training loss: 9.456480979919434
2025-12-09 12:16:13.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.0029985579054831145 Training loss: 9.488321304321289
2025-12-09 12:16:13.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0029985175757655286 Training loss: 9.486700057983398
2025-12-09 12:16:13.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.002998476690145097 Training loss: 9.630712509155273
2025-12-09 12:16:13.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.0029984352486369867 Training loss: 9.315751075744629
2025-12-09 12:16:13.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.002998393251256571 Training loss: 9.553813934326172
2025-12-09 12:16:13.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0029983506980194303 Training loss: 8.671069145202637
2025-12-09 12:16:13.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0029983075889413497 Training loss: 9.48643970489502
2025-12-09 12:16:14.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.0029982639240383217 Training loss: 9.567416191101074
2025-12-09 12:16:14.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.0029982197033265445 Training loss: 9.511649131774902
2025-12-09 12:16:14.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0029981749268224228 Training loss: 9.456369400024414
2025-12-09 12:16:14.295 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.0029981295945425666 Training loss: 9.591076850891113
2025-12-09 12:16:14.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.002998083706503794 Training loss: 9.494033813476562
2025-12-09 12:16:14.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.002998037262723127 Training loss: 9.603808403015137
2025-12-09 12:16:14.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.002997990263217795 Training loss: 9.639784812927246
2025-12-09 12:16:14.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0029979427080052334 Training loss: 9.645179748535156
2025-12-09 12:16:14.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.002997894597103084 Training loss: 9.266925811767578
2025-12-09 12:16:14.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.0029978459305291943 Training loss: 9.235666275024414
2025-12-09 12:16:14.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0029977967083016175 Training loss: 9.524900436401367
2025-12-09 12:16:14.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.002997746930438614 Training loss: 9.510200500488281
2025-12-09 12:16:14.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0029976965969586494 Training loss: 9.681041717529297
2025-12-09 12:16:15.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0029976457078803964 Training loss: 9.574689865112305
2025-12-09 12:16:15.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.0029975942632227332 Training loss: 9.384693145751953
2025-12-09 12:16:15.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.002997542263004744 Training loss: 9.744258880615234
2025-12-09 12:16:15.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.002997489707245719 Training loss: 9.4008207321167
2025-12-09 12:16:15.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0029974365959651544 Training loss: 9.530940055847168
2025-12-09 12:16:15.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0029973829291827544 Training loss: 9.623276710510254
2025-12-09 12:16:15.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.002997328706918426 Training loss: 9.596612930297852
2025-12-09 12:16:15.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0029972739291922843 Training loss: 9.669483184814453
2025-12-09 12:16:15.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0029972185960246514 Training loss: 9.5020170211792
2025-12-09 12:16:15.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0029971627074360523 Training loss: 9.485213279724121
2025-12-09 12:16:15.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0029971062634472205 Training loss: 9.205092430114746
2025-12-09 12:16:15.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0029970492640790957 Training loss: 9.96835994720459
2025-12-09 12:16:15.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.002996991709352822 Training loss: 9.735901832580566
2025-12-09 12:16:16.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0029969335992897513 Training loss: 9.104571342468262
2025-12-09 12:16:16.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0029968749339114404 Training loss: 9.349067687988281
2025-12-09 12:16:16.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.0029968157132396513 Training loss: 9.409013748168945
2025-12-09 12:16:16.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.002996755937296354 Training loss: 9.42534065246582
2025-12-09 12:16:16.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.002996695606103723 Training loss: 9.77735424041748
2025-12-09 12:16:16.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0029966347196841393 Training loss: 9.623948097229004
2025-12-09 12:16:16.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.00299657327806019 Training loss: 9.612764358520508
2025-12-09 12:16:16.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.0029965112812546683 Training loss: 9.55854606628418
2025-12-09 12:16:16.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0029964487292905725 Training loss: 9.658710479736328
2025-12-09 12:16:16.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.0029963856221911075 Training loss: 9.414606094360352
2025-12-09 12:16:16.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.002996321959979685 Training loss: 9.780546188354492
2025-12-09 12:16:16.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.00299625774267992 Training loss: 9.491350173950195
2025-12-09 12:16:16.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0029961929703156364 Training loss: 9.5531644821167
2025-12-09 12:16:17.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.002996127642910863 Training loss: 9.538506507873535
2025-12-09 12:16:17.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.0029960617604898325 Training loss: 9.65483570098877
2025-12-09 12:16:17.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.002995995323076986 Training loss: 9.628771781921387
2025-12-09 12:16:17.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.002995928330696971 Training loss: 9.41217041015625
2025-12-09 12:16:17.354 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.002995860783374638 Training loss: 9.626004219055176
2025-12-09 12:16:17.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0029957926811350452 Training loss: 9.533929824829102
2025-12-09 12:16:17.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0029957240240034567 Training loss: 9.605578422546387
2025-12-09 12:16:17.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0029956548120053422 Training loss: 9.39479923248291
2025-12-09 12:16:17.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.0029955850451663765 Training loss: 9.511984825134277
2025-12-09 12:16:17.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.0029955147235124417 Training loss: 9.290897369384766
2025-12-09 12:16:17.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.002995443847069625 Training loss: 9.367731094360352
2025-12-09 12:16:17.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0029953724158642185 Training loss: 9.529491424560547
2025-12-09 12:16:17.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0029953004299227213 Training loss: 9.350485801696777
2025-12-09 12:16:18.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.002995227889271838 Training loss: 9.522795677185059
2025-12-09 12:16:18.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.002995154793938479 Training loss: 9.489496231079102
2025-12-09 12:16:18.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0029950811439497607 Training loss: 9.572196006774902
2025-12-09 12:16:18.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0029950069393330043 Training loss: 9.427127838134766
2025-12-09 12:16:18.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.002994932180115737 Training loss: 9.63280200958252
2025-12-09 12:16:18.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0029948568663256928 Training loss: 9.551048278808594
2025-12-09 12:16:18.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.0029947809979908114 Training loss: 9.382096290588379
2025-12-09 12:16:18.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.002994704575139236 Training loss: 9.475234031677246
2025-12-09 12:16:18.662 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.002994627597799318 Training loss: 9.436227798461914
2025-12-09 12:16:18.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0029945500659996132 Training loss: 9.84658145904541
2025-12-09 12:16:18.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.0029944719797688844 Training loss: 9.417877197265625
2025-12-09 12:16:18.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.002994393339136098 Training loss: 9.445592880249023
2025-12-09 12:16:18.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.0029943141441304277 Training loss: 9.622904777526855
2025-12-09 12:16:19.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.0029942343947812517 Training loss: 9.50822925567627
2025-12-09 12:16:19.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.002994154091118156 Training loss: 9.539823532104492
2025-12-09 12:16:19.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0029940732331709295 Training loss: 9.391936302185059
2025-12-09 12:16:19.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.0029939918209695676 Training loss: 9.806024551391602
2025-12-09 12:16:19.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0029939098545442733 Training loss: 9.553793907165527
2025-12-09 12:16:19.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0029938273339254516 Training loss: 9.623029708862305
2025-12-09 12:16:19.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.002993744259143717 Training loss: 9.641209602355957
2025-12-09 12:16:19.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.002993660630229886 Training loss: 9.444461822509766
2025-12-09 12:16:19.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.0029935764472149833 Training loss: 9.505025863647461
2025-12-09 12:16:19.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0029934917101302376 Training loss: 9.585330963134766
2025-12-09 12:16:19.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.002993406419007084 Training loss: 9.33229923248291
2025-12-09 12:16:19.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.0029933205738771626 Training loss: 9.61073112487793
2025-12-09 12:16:19.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.0029932341747723194 Training loss: 9.829262733459473
2025-12-09 12:16:20.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.002993147221724606 Training loss: 9.679767608642578
2025-12-09 12:16:20.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0029930597147662785 Training loss: 9.661776542663574
2025-12-09 12:16:20.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.0029929716539297997 Training loss: 9.398561477661133
2025-12-09 12:16:20.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.0029928830392478376 Training loss: 9.62486457824707
2025-12-09 12:16:20.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.002992793870753265 Training loss: 9.755523681640625
2025-12-09 12:16:20.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0029927041484791614 Training loss: 9.474492073059082
2025-12-09 12:16:20.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00299261387245881 Training loss: 9.764665603637695
2025-12-09 12:16:20.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0029925230427257006 Training loss: 9.61962604522705
2025-12-09 12:16:20.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.0029924316593135285 Training loss: 9.596590995788574
2025-12-09 12:16:20.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.0029923397222561938 Training loss: 9.373687744140625
2025-12-09 12:16:20.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0029922472315878023 Training loss: 9.586187362670898
2025-12-09 12:16:20.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.002992154187342665 Training loss: 9.51445484161377
2025-12-09 12:16:20.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.002992060589555299 Training loss: 9.291923522949219
2025-12-09 12:16:21.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0029919664382604253 Training loss: 9.541047096252441
2025-12-09 12:16:21.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.0029918717334929718 Training loss: 9.45482063293457
2025-12-09 12:16:21.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.00299177647528807 Training loss: 9.628026008605957
2025-12-09 12:16:21.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.002991680663681059 Training loss: 9.655082702636719
2025-12-09 12:16:21.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.002991584298707481 Training loss: 9.748641014099121
2025-12-09 12:16:21.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.002991487380403084 Training loss: 9.541589736938477
2025-12-09 12:16:21.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.002991389908803823 Training loss: 9.443746566772461
2025-12-09 12:16:21.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0029912918839458554 Training loss: 9.688247680664062
2025-12-09 12:16:21.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.002991193305865547 Training loss: 9.647560119628906
2025-12-09 12:16:21.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0029910941745994657 Training loss: 9.250069618225098
2025-12-09 12:16:21.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0029909944901843864 Training loss: 9.530627250671387
2025-12-09 12:16:21.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.002990894252657289 Training loss: 8.862994194030762
2025-12-09 12:16:21.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.0029907934620553595 Training loss: 9.584985733032227
2025-12-09 12:16:22.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0029906921184159863 Training loss: 9.702744483947754
2025-12-09 12:16:22.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0029905902217767654 Training loss: 9.602036476135254
2025-12-09 12:16:22.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0029904877721754976 Training loss: 9.52615737915039
2025-12-09 12:16:22.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.002990384769650188 Training loss: 9.421480178833008
2025-12-09 12:16:22.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0029902812142390475 Training loss: 9.440927505493164
2025-12-09 12:16:22.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0029901771059804923 Training loss: 9.714567184448242
2025-12-09 12:16:22.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0029900724449131427 Training loss: 9.488678932189941
2025-12-09 12:16:22.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0029899672310758248 Training loss: 9.493684768676758
2025-12-09 12:16:22.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0029898614645075695 Training loss: 9.603487014770508
2025-12-09 12:16:22.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.002989755145247613 Training loss: 9.341974258422852
2025-12-09 12:16:22.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.002989648273335397 Training loss: 9.545735359191895
2025-12-09 12:16:22.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0029895408488105667 Training loss: 9.689003944396973
2025-12-09 12:16:22.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0029894328717129737 Training loss: 9.538588523864746
2025-12-09 12:16:23.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.0029893243420826736 Training loss: 9.604409217834473
2025-12-09 12:16:23.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.002989215259959928 Training loss: 9.341399192810059
2025-12-09 12:16:23.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.002989105625385203 Training loss: 9.57245922088623
2025-12-09 12:16:23.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.002988995438399169 Training loss: 9.493836402893066
2025-12-09 12:16:23.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0029888846990427024 Training loss: 9.568458557128906
2025-12-09 12:16:23.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.002988773407356884 Training loss: 9.488405227661133
2025-12-09 12:16:23.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.0029886615633829996 Training loss: 9.531139373779297
2025-12-09 12:16:23.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.002988549167162539 Training loss: 9.595377922058105
2025-12-09 12:16:23.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.0029884362187371986 Training loss: 9.55685043334961
2025-12-09 12:16:23.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0029883227181488783 Training loss: 9.710479736328125
2025-12-09 12:16:23.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.002988208665439683 Training loss: 9.710593223571777
2025-12-09 12:16:23.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.0029880940606519233 Training loss: 9.550383567810059
2025-12-09 12:16:23.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.002987978903828114 Training loss: 9.303019523620605
2025-12-09 12:16:24.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0029878631950109734 Training loss: 9.474717140197754
2025-12-09 12:16:24.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.0029877469342434273 Training loss: 9.576811790466309
2025-12-09 12:16:24.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.002987630121568604 Training loss: 9.379566192626953
2025-12-09 12:16:24.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.002987512757029838 Training loss: 9.685284614562988
2025-12-09 12:16:24.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0029873948406706667 Training loss: 9.540350914001465
2025-12-09 12:16:24.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0029872763725348342 Training loss: 9.3441743850708
2025-12-09 12:16:24.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.0029871573526662884 Training loss: 9.891968727111816
2025-12-09 12:16:24.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0029870377811091822 Training loss: 9.53328800201416
2025-12-09 12:16:24.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.002986917657907872 Training loss: 9.463130950927734
2025-12-09 12:16:24.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.00298679698310692 Training loss: 8.60487174987793
2025-12-09 12:16:24.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.002986675756751093 Training loss: 9.715242385864258
2025-12-09 12:16:24.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0029865539788853624 Training loss: 9.617271423339844
2025-12-09 12:16:24.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.0029864316495549037 Training loss: 9.47681713104248
2025-12-09 12:16:25.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.0029863087688050973 Training loss: 9.586777687072754
2025-12-09 12:16:25.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.002986185336681528 Training loss: 9.65115737915039
2025-12-09 12:16:25.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.0029860613532299847 Training loss: 9.652012825012207
2025-12-09 12:16:25.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.0029859368184964627 Training loss: 9.74710750579834
2025-12-09 12:16:25.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.002985811732527159 Training loss: 9.557132720947266
2025-12-09 12:16:25.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0029856860953684774 Training loss: 9.597989082336426
2025-12-09 12:16:25.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0029855599070670253 Training loss: 9.447511672973633
2025-12-09 12:16:25.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.0029854331676696143 Training loss: 9.558205604553223
2025-12-09 12:16:25.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.0029853058772232608 Training loss: 9.600244522094727
2025-12-09 12:16:25.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.0029851780357751856 Training loss: 9.733155250549316
2025-12-09 12:16:25.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.002985049643372814 Training loss: 9.525125503540039
2025-12-09 12:16:25.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0029849207000637755 Training loss: 9.499452590942383
2025-12-09 12:16:25.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.0029847912058959033 Training loss: 9.454212188720703
2025-12-09 12:16:26.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.002984661160917237 Training loss: 9.729186058044434
2025-12-09 12:16:26.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.002984530565176018 Training loss: 9.499289512634277
2025-12-09 12:16:26.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.002984399418720694 Training loss: 9.470978736877441
2025-12-09 12:16:26.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.0029842677215999158 Training loss: 9.552567481994629
2025-12-09 12:16:26.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.002984135473862539 Training loss: 9.639021873474121
2025-12-09 12:16:26.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.002984002675557623 Training loss: 9.589764595031738
2025-12-09 12:16:26.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.002983869326734432 Training loss: 10.02407455444336
2025-12-09 12:16:26.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.0029837354274424347 Training loss: 9.632492065429688
2025-12-09 12:16:26.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.002983600977731303 Training loss: 9.081780433654785
2025-12-09 12:16:26.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.0029834659776509136 Training loss: 9.43415355682373
2025-12-09 12:16:26.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.0029833304272513473 Training loss: 9.205355644226074
2025-12-09 12:16:26.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.002983194326582889 Training loss: 9.621922492980957
2025-12-09 12:16:26.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0029830576756960285 Training loss: 9.594614028930664
2025-12-09 12:16:27.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0029829204746414577 Training loss: 9.770735740661621
2025-12-09 12:16:27.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0029827827234700744 Training loss: 9.925622940063477
2025-12-09 12:16:27.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.00298264442223298 Training loss: 9.57961368560791
2025-12-09 12:16:27.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.0029825055709814803 Training loss: 9.541751861572266
2025-12-09 12:16:27.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.002982366169767084 Training loss: 9.572173118591309
2025-12-09 12:16:27.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.002982226218641505 Training loss: 9.436506271362305
2025-12-09 12:16:27.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.002982085717656661 Training loss: 9.890666007995605
2025-12-09 12:16:27.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0029819446668646723 Training loss: 9.301189422607422
2025-12-09 12:16:27.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0029818030663178656 Training loss: 9.42600154876709
2025-12-09 12:16:27.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.00298166091606877 Training loss: 9.613747596740723
2025-12-09 12:16:27.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.0029815182161701185 Training loss: 8.845274925231934
2025-12-09 12:16:27.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0029813749666748484 Training loss: 9.629897117614746
2025-12-09 12:16:27.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.0029812311676361003 Training loss: 9.2155122756958
2025-12-09 12:16:28.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.00298108681910722 Training loss: 8.993453025817871
2025-12-09 12:16:28.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.0029809419211417553 Training loss: 9.621447563171387
2025-12-09 12:16:28.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.0029807964737934593 Training loss: 9.459946632385254
2025-12-09 12:16:28.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0029806504771162884 Training loss: 9.609301567077637
2025-12-09 12:16:28.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.0029805039311644028 Training loss: 9.618473052978516
2025-12-09 12:16:28.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.002980356835992166 Training loss: 9.999166488647461
2025-12-09 12:16:28.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.0029802091916541463 Training loss: 9.546310424804688
2025-12-09 12:16:28.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.002980060998205115 Training loss: 9.588443756103516
2025-12-09 12:16:28.662 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.0029799122557000466 Training loss: 9.604683876037598
2025-12-09 12:16:28.739 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.0029797629641941203 Training loss: 9.41662311553955
2025-12-09 12:16:28.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.002979613123742719 Training loss: 9.560885429382324
2025-12-09 12:16:28.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.0029794627344014277 Training loss: 9.411450386047363
2025-12-09 12:16:28.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.002979311796226037 Training loss: 9.949519157409668
2025-12-09 12:16:29.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.00297916030927254 Training loss: 9.448962211608887
2025-12-09 12:16:29.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.0029790082735971337 Training loss: 9.27272891998291
2025-12-09 12:16:29.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.0029788556892562184 Training loss: 9.7153959274292
2025-12-09 12:16:29.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.002978702556306398 Training loss: 9.326899528503418
2025-12-09 12:16:29.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.00297854887480448 Training loss: 9.637229919433594
2025-12-09 12:16:29.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.002978394644807475 Training loss: 9.62520980834961
2025-12-09 12:16:29.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.0029782398663725984 Training loss: 9.437212944030762
2025-12-09 12:16:29.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.0029780845395572676 Training loss: 9.527874946594238
2025-12-09 12:16:29.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.0029779286644191043 Training loss: 9.555160522460938
2025-12-09 12:16:29.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.002977772241015933 Training loss: 8.962450981140137
2025-12-09 12:16:29.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.002977615269405782 Training loss: 9.515411376953125
2025-12-09 12:16:29.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0029774577496468825 Training loss: 9.17330551147461
2025-12-09 12:16:29.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.0029772996817976696 Training loss: 9.587197303771973
2025-12-09 12:16:30.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.002977141065916781 Training loss: 9.6254301071167
2025-12-09 12:16:30.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.0029769819020630597 Training loss: 9.451336860656738
2025-12-09 12:16:30.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0029768221902955485 Training loss: 9.54971981048584
2025-12-09 12:16:30.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.002976661930673497 Training loss: 9.771803855895996
2025-12-09 12:16:30.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.002976501123256355 Training loss: 9.65779972076416
2025-12-09 12:16:30.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.0029763397681037787 Training loss: 9.56623363494873
2025-12-09 12:16:30.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.0029761778652756246 Training loss: 9.62370491027832
2025-12-09 12:16:30.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.0029760154148319538 Training loss: 9.52963638305664
2025-12-09 12:16:30.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.0029758524168330305 Training loss: 9.540240287780762
2025-12-09 12:16:30.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.0029756888713393216 Training loss: 9.763920783996582
2025-12-09 12:16:30.819 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.002975524778411498 Training loss: 9.63623332977295
2025-12-09 12:16:30.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.0029753601381104318 Training loss: 9.459364891052246
2025-12-09 12:16:30.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.0029751949504972 Training loss: 9.664322853088379
2025-12-09 12:16:31.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0029750292156330823 Training loss: 9.621678352355957
2025-12-09 12:16:31.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.0029748629335795604 Training loss: 9.61216926574707
2025-12-09 12:16:31.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.002974696104398321 Training loss: 9.291147232055664
2025-12-09 12:16:31.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.002974528728151251 Training loss: 10.0809907913208
2025-12-09 12:16:31.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.0029743608049004424 Training loss: 9.753205299377441
2025-12-09 12:16:31.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.002974192334708189 Training loss: 9.538651466369629
2025-12-09 12:16:31.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.002974023317636989 Training loss: 9.645369529724121
2025-12-09 12:16:31.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.0029738537537495413 Training loss: 9.534046173095703
2025-12-09 12:16:31.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.0029736836431087494 Training loss: 9.445696830749512
2025-12-09 12:16:31.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.0029735129857777188 Training loss: 9.684082984924316
2025-12-09 12:16:31.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.002973341781819758 Training loss: 9.673885345458984
2025-12-09 12:16:31.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.002973170031298378 Training loss: 9.473320960998535
2025-12-09 12:16:31.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.0029729977342772937 Training loss: 9.430768966674805
2025-12-09 12:16:32.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.0029728248908204207 Training loss: 9.640727996826172
2025-12-09 12:16:32.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.0029726515009918793 Training loss: 9.184867858886719
2025-12-09 12:16:32.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.0029724775648559913 Training loss: 9.519246101379395
2025-12-09 12:16:32.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0029723030824772814 Training loss: 9.47592830657959
2025-12-09 12:16:32.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.002972128053920478 Training loss: 9.539436340332031
2025-12-09 12:16:32.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.00297195247925051 Training loss: 9.475079536437988
2025-12-09 12:16:32.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.0029717763585325103 Training loss: 9.958781242370605
2025-12-09 12:16:32.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.002971599691831815 Training loss: 9.69279670715332
2025-12-09 12:16:32.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.0029714224792139607 Training loss: 9.65684986114502
2025-12-09 12:16:32.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.002971244720744689 Training loss: 9.74117660522461
2025-12-09 12:16:32.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.0029710664164899416 Training loss: 9.416032791137695
2025-12-09 12:16:32.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.0029708875665158643 Training loss: 9.49895191192627
2025-12-09 12:16:32.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.0029707081708888047 Training loss: 9.82079029083252
2025-12-09 12:16:33.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.0029705282296753127 Training loss: 9.572121620178223
2025-12-09 12:16:33.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.002970347742942141 Training loss: 9.647329330444336
2025-12-09 12:16:33.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.002970166710756245 Training loss: 9.295740127563477
2025-12-09 12:16:33.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.002969985133184781 Training loss: 9.326733589172363
2025-12-09 12:16:33.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0029698030102951094 Training loss: 9.480841636657715
2025-12-09 12:16:33.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0029696203421547916 Training loss: 9.721881866455078
2025-12-09 12:16:33.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.0029694371288315913 Training loss: 9.830397605895996
2025-12-09 12:16:33.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.0029692533703934757 Training loss: 8.903940200805664
2025-12-09 12:16:33.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.002969069066908613 Training loss: 9.48189926147461
2025-12-09 12:16:33.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0029688842184453744 Training loss: 9.486452102661133
2025-12-09 12:16:33.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.002968698825072332 Training loss: 9.520160675048828
2025-12-09 12:16:33.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.0029685128868582626 Training loss: 9.465407371520996
2025-12-09 12:16:33.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.0029683264038721418 Training loss: 9.533485412597656
2025-12-09 12:16:34.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.0029681393761831487 Training loss: 9.57681655883789
2025-12-09 12:16:34.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.002967951803860666 Training loss: 9.383279800415039
2025-12-09 12:16:34.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.002967763686974276 Training loss: 8.802754402160645
2025-12-09 12:16:34.290 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.002967575025593765 Training loss: 9.402323722839355
2025-12-09 12:16:34.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.00296738581978912 Training loss: 9.577728271484375
2025-12-09 12:16:34.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0029671960696305306 Training loss: 9.502580642700195
2025-12-09 12:16:34.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.002967005775188388 Training loss: 9.717162132263184
2025-12-09 12:16:34.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.0029668149365332853 Training loss: 9.398416519165039
2025-12-09 12:16:34.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.002966623553736018 Training loss: 9.562500953674316
2025-12-09 12:16:34.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.0029664316268675824 Training loss: 9.41861629486084
2025-12-09 12:16:34.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0029662391559991783 Training loss: 9.298389434814453
2025-12-09 12:16:34.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.0029660461412022057 Training loss: 9.210808753967285
2025-12-09 12:16:34.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.002965852582548267 Training loss: 9.554868698120117
2025-12-09 12:16:35.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.0029656584801091668 Training loss: 8.863747596740723
2025-12-09 12:16:35.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.0029654638339569107 Training loss: 9.476123809814453
2025-12-09 12:16:35.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.002965268644163706 Training loss: 9.396323204040527
2025-12-09 12:16:35.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.0029650729108019625 Training loss: 9.233482360839844
2025-12-09 12:16:35.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.002964876633944291 Training loss: 9.584402084350586
2025-12-09 12:16:35.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.0029646798136635038 Training loss: 9.319867134094238
2025-12-09 12:16:35.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.002964482450032615 Training loss: 9.587183952331543
2025-12-09 12:16:35.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.002964284543124841 Training loss: 9.452611923217773
2025-12-09 12:16:35.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.0029640860930135976 Training loss: 9.367155075073242
2025-12-09 12:16:35.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.002963887099772505 Training loss: 9.352011680603027
2025-12-09 12:16:35.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.0029636875634753827 Training loss: 9.325849533081055
2025-12-09 12:16:35.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.002963487484196253 Training loss: 9.480679512023926
2025-12-09 12:16:35.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.002963286862009338 Training loss: 9.39728832244873
2025-12-09 12:16:36.064 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.0029630856969890627 Training loss: 9.236291885375977
2025-12-09 12:16:36.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.0029628839892100536 Training loss: 9.47652530670166
2025-12-09 12:16:36.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.002962681738747137 Training loss: 9.438436508178711
2025-12-09 12:16:36.295 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.002962478945675342 Training loss: 9.41916275024414
2025-12-09 12:16:36.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.002962275610069898 Training loss: 9.412542343139648
2025-12-09 12:16:36.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.002962071732006237 Training loss: 9.220414161682129
2025-12-09 12:16:36.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.00296186731155999 Training loss: 9.376840591430664
2025-12-09 12:16:36.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.0029616623488069923 Training loss: 9.234816551208496
2025-12-09 12:16:36.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.0029614568438232768 Training loss: 9.56785774230957
2025-12-09 12:16:36.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.0029612507966850807 Training loss: 9.413115501403809
2025-12-09 12:16:36.831 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.0029610442074688398 Training loss: 9.279918670654297
2025-12-09 12:16:36.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.0029608370762511937 Training loss: 9.48355484008789
2025-12-09 12:16:36.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.0029606294031089804 Training loss: 9.262818336486816
2025-12-09 12:16:37.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.00296042118811924 Training loss: 9.251300811767578
2025-12-09 12:16:37.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.002960212431359215 Training loss: 9.412346839904785
2025-12-09 12:16:37.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.0029600031329063466 Training loss: 9.310370445251465
2025-12-09 12:16:37.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.002959793292838278 Training loss: 9.31380844116211
2025-12-09 12:16:37.376 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.002959582911232853 Training loss: 8.67150592803955
2025-12-09 12:16:37.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.0029593719881681173 Training loss: 9.398473739624023
2025-12-09 12:16:37.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.002959160523722316 Training loss: 9.442413330078125
2025-12-09 12:16:37.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0029589485179738963 Training loss: 9.355364799499512
2025-12-09 12:16:37.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0029587359710015054 Training loss: 9.374746322631836
2025-12-09 12:16:37.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.0029585228828839915 Training loss: 9.300979614257812
2025-12-09 12:16:37.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.002958309253700404 Training loss: 8.975418090820312
2025-12-09 12:16:37.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.002958095083529992 Training loss: 9.358044624328613
2025-12-09 12:16:37.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0029578803724522058 Training loss: 9.214962005615234
2025-12-09 12:16:38.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.002957665120546697 Training loss: 9.486837387084961
2025-12-09 12:16:38.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.0029574493278933175 Training loss: 9.233968734741211
2025-12-09 12:16:38.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.002957232994572119 Training loss: 9.06673812866211
2025-12-09 12:16:38.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.0029570161206633546 Training loss: 9.138460159301758
2025-12-09 12:16:38.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.0029567987062474772 Training loss: 9.205246925354004
2025-12-09 12:16:38.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.002956580751405141 Training loss: 9.180876731872559
2025-12-09 12:16:38.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.002956362256217201 Training loss: 8.98560905456543
2025-12-09 12:16:38.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.0029561432207647113 Training loss: 9.059612274169922
2025-12-09 12:16:38.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.002955923645128927 Training loss: 9.757888793945312
2025-12-09 12:16:38.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.0029557035293913047 Training loss: 9.402297973632812
2025-12-09 12:16:38.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.0029554828736334995 Training loss: 9.328624725341797
2025-12-09 12:16:38.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0029552616779373684 Training loss: 9.056567192077637
2025-12-09 12:16:39.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.0029550399423849674 Training loss: 9.226826667785645
2025-12-09 12:16:39.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.002954817667058554 Training loss: 8.994226455688477
2025-12-09 12:16:39.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.002954594852040585 Training loss: 9.416035652160645
2025-12-09 12:16:39.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.0029543714974137178 Training loss: 9.343220710754395
2025-12-09 12:16:39.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.00295414760326081 Training loss: 9.196839332580566
2025-12-09 12:16:39.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.002953923169664919 Training loss: 9.456274032592773
2025-12-09 12:16:39.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.002953698196709303 Training loss: 9.270310401916504
2025-12-09 12:16:39.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.00295347268447742 Training loss: 9.169058799743652
2025-12-09 12:16:39.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.002953246633052928 Training loss: 9.098851203918457
2025-12-09 12:16:39.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.0029530200425196837 Training loss: 8.402982711791992
2025-12-09 12:16:39.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.0029527929129617467 Training loss: 9.184422492980957
2025-12-09 12:16:39.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.002952565244463374 Training loss: 9.158456802368164
2025-12-09 12:16:39.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.0029523370371090235 Training loss: 9.25639820098877
2025-12-09 12:16:40.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.002952108290983353 Training loss: 9.147337913513184
2025-12-09 12:16:40.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.002951879006171221 Training loss: 9.204399108886719
2025-12-09 12:16:40.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.0029516491827576833 Training loss: 8.294008255004883
2025-12-09 12:16:40.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.0029514188208279984 Training loss: 8.338339805603027
2025-12-09 12:16:40.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.0029511879204676223 Training loss: 9.042611122131348
2025-12-09 12:16:40.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0029509564817622133 Training loss: 9.201276779174805
2025-12-09 12:16:40.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0029507245047976265 Training loss: 9.089393615722656
2025-12-09 12:16:40.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.002950491989659918 Training loss: 9.792877197265625
2025-12-09 12:16:40.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.0029502589364353454 Training loss: 9.024571418762207
2025-12-09 12:16:40.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.0029500253452103622 Training loss: 8.681230545043945
2025-12-09 12:16:40.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.0029497912160716235 Training loss: 9.113551139831543
2025-12-09 12:16:40.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.002949556549105985 Training loss: 9.020648002624512
2025-12-09 12:16:40.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.0029493213444005 Training loss: 8.969304084777832
2025-12-09 12:16:41.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.002949085602042422 Training loss: 9.356931686401367
2025-12-09 12:16:41.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.0029488493221192045 Training loss: 8.906538963317871
2025-12-09 12:16:41.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.002948612504718499 Training loss: 9.114449501037598
2025-12-09 12:16:41.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.0029483751499281585 Training loss: 9.474995613098145
2025-12-09 12:16:41.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.0029481372578362332 Training loss: 8.797767639160156
2025-12-09 12:16:41.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.002947898828530974 Training loss: 8.918211936950684
2025-12-09 12:16:41.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.00294765986210083 Training loss: 9.089473724365234
2025-12-09 12:16:41.556 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0029474203586344516 Training loss: 9.049004554748535
2025-12-09 12:16:41.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.0029471803182206857 Training loss: 8.988728523254395
2025-12-09 12:16:41.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.0029469397409485807 Training loss: 8.509325981140137
2025-12-09 12:16:41.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.0029466986269073825 Training loss: 9.376230239868164
2025-12-09 12:16:41.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.0029464569761865366 Training loss: 9.304475784301758
2025-12-09 12:16:41.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.002946214788875689 Training loss: 9.32750129699707
2025-12-09 12:16:42.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.0029459720650646826 Training loss: 9.040985107421875
2025-12-09 12:16:42.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.0029457288048435606 Training loss: 8.863494873046875
2025-12-09 12:16:42.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.002945485008302565 Training loss: 9.021661758422852
2025-12-09 12:16:42.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.0029452406755321363 Training loss: 9.00477123260498
2025-12-09 12:16:42.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.0029449958066229145 Training loss: 9.090420722961426
2025-12-09 12:16:42.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.0029447504016657383 Training loss: 9.139474868774414
2025-12-09 12:16:42.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.002944504460751645 Training loss: 8.973185539245605
2025-12-09 12:16:42.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.002944257983971871 Training loss: 9.14085578918457
2025-12-09 12:16:42.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.002944010971417851 Training loss: 9.293137550354004
2025-12-09 12:16:42.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.00294376342318122 Training loss: 8.919214248657227
2025-12-09 12:16:42.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.00294351533935381 Training loss: 9.12099838256836
2025-12-09 12:16:42.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.002943266720027652 Training loss: 9.015776634216309
2025-12-09 12:16:42.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0029430175652949762 Training loss: 8.895827293395996
2025-12-09 12:16:43.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.0029427678752482114 Training loss: 7.991640567779541
2025-12-09 12:16:43.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.0029425176499799843 Training loss: 8.796234130859375
2025-12-09 12:16:43.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.002942266889583121 Training loss: 8.203845977783203
2025-12-09 12:16:43.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.0029420155941506454 Training loss: 9.134202003479004
2025-12-09 12:16:43.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.00294176376377578 Training loss: 8.967780113220215
2025-12-09 12:16:43.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.0029415113985519466 Training loss: 8.991778373718262
2025-12-09 12:16:43.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.0029412584985727642 Training loss: 9.286026000976562
2025-12-09 12:16:43.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.002941005063932051 Training loss: 9.017598152160645
2025-12-09 12:16:43.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.002940751094723823 Training loss: 8.955307960510254
2025-12-09 12:16:43.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.0029404965910422953 Training loss: 9.742033958435059
2025-12-09 12:16:43.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.0029402415529818805 Training loss: 8.946366310119629
2025-12-09 12:16:43.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.0029399859806371895 Training loss: 9.17198657989502
2025-12-09 12:16:43.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.002939729874103032 Training loss: 8.788299560546875
2025-12-09 12:16:44.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.002939473233474415 Training loss: 9.102885246276855
2025-12-09 12:16:44.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.002939216058846544 Training loss: 8.794160842895508
2025-12-09 12:16:44.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.0029389583503148234 Training loss: 8.966475486755371
2025-12-09 12:16:44.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.0029387001079748537 Training loss: 8.90625
2025-12-09 12:16:44.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.0029384413319224366 Training loss: 8.964856147766113
2025-12-09 12:16:44.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.002938182022253568 Training loss: 8.815251350402832
2025-12-09 12:16:44.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.002937922179064445 Training loss: 8.997275352478027
2025-12-09 12:16:44.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.00293766180245146 Training loss: 8.975824356079102
2025-12-09 12:16:44.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.0029374008925112057 Training loss: 8.792723655700684
2025-12-09 12:16:44.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.0029371394493404707 Training loss: 8.799601554870605
2025-12-09 12:16:44.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.0029368774730362426 Training loss: 9.025912284851074
2025-12-09 12:16:44.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.002936614963695706 Training loss: 8.880305290222168
2025-12-09 12:16:44.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.002936351921416244 Training loss: 8.394671440124512
2025-12-09 12:16:45.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.0029360883462954362 Training loss: 8.613177299499512
2025-12-09 12:16:45.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.002935824238431062 Training loss: 8.682658195495605
2025-12-09 12:16:45.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.0029355595979210962 Training loss: 8.368349075317383
2025-12-09 12:16:45.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.002935294424863712 Training loss: 8.462855339050293
2025-12-09 12:16:45.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.002935028719357281 Training loss: 7.799623966217041
2025-12-09 12:16:45.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.0029347624815003704 Training loss: 8.25006103515625
2025-12-09 12:16:45.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.0029344957113917472 Training loss: 8.836103439331055
2025-12-09 12:16:45.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.002934228409130374 Training loss: 9.048035621643066
2025-12-09 12:16:45.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.0029339605748154125 Training loss: 8.788352012634277
2025-12-09 12:16:45.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.0029336922085462193 Training loss: 8.703643798828125
2025-12-09 12:16:45.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.002933423310422351 Training loss: 9.090145111083984
2025-12-09 12:16:45.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.00293315388054356 Training loss: 9.264366149902344
2025-12-09 12:16:45.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.002932883919009796 Training loss: 8.82280445098877
2025-12-09 12:16:46.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.002932613425921207 Training loss: 8.817281723022461
2025-12-09 12:16:46.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.002932342401378137 Training loss: 8.754405975341797
2025-12-09 12:16:46.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.0029320708454811267 Training loss: 9.181951522827148
2025-12-09 12:16:46.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.002931798758330916 Training loss: 8.744832992553711
2025-12-09 12:16:46.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.002931526140028441 Training loss: 8.979411125183105
2025-12-09 12:16:46.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0029312529906748326 Training loss: 8.784424781799316
2025-12-09 12:16:46.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.0029309793103714224 Training loss: 9.048528671264648
2025-12-09 12:16:46.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.002930705099219736 Training loss: 9.03657054901123
2025-12-09 12:16:46.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.0029304303573214983 Training loss: 8.848872184753418
2025-12-09 12:16:46.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.0029301550847786293 Training loss: 8.466318130493164
2025-12-09 12:16:46.819 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.0029298792816932462 Training loss: 8.753170013427734
2025-12-09 12:16:46.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.0029296029481676636 Training loss: 8.961546897888184
2025-12-09 12:16:46.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.0029293260843043924 Training loss: 8.598791122436523
2025-12-09 12:16:47.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.0029290486902061397 Training loss: 8.76272964477539
2025-12-09 12:16:47.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0029287707659758117 Training loss: 8.655576705932617
2025-12-09 12:16:47.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.0029284923117165076 Training loss: 8.669281005859375
2025-12-09 12:16:47.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.0029282133275315265 Training loss: 9.000816345214844
2025-12-09 12:16:47.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.0029279338135243626 Training loss: 8.798831939697266
2025-12-09 12:16:47.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.0029276537697987062 Training loss: 9.086702346801758
2025-12-09 12:16:47.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.0029273731964584446 Training loss: 8.915675163269043
2025-12-09 12:16:47.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.0029270920936076625 Training loss: 8.670605659484863
2025-12-09 12:16:47.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.0029268104613506397 Training loss: 8.708213806152344
2025-12-09 12:16:47.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.0029265282997918535 Training loss: 8.545083999633789
2025-12-09 12:16:47.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.0029262456090359762 Training loss: 8.767526626586914
2025-12-09 12:16:47.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.002925962389187877 Training loss: 8.790420532226562
2025-12-09 12:16:47.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.0029256786403526226 Training loss: 9.19388198852539
2025-12-09 12:16:48.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.0029253943626354737 Training loss: 8.776461601257324
2025-12-09 12:16:48.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0029251095561418894 Training loss: 8.886541366577148
2025-12-09 12:16:48.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0029248242209775235 Training loss: 8.439096450805664
2025-12-09 12:16:48.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.002924538357248226 Training loss: 8.766740798950195
2025-12-09 12:16:48.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.0029242519650600437 Training loss: 8.753813743591309
2025-12-09 12:16:48.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.002923965044519219 Training loss: 8.71469497680664
2025-12-09 12:16:48.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.002923677595732191 Training loss: 8.880568504333496
2025-12-09 12:16:48.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0029233896188055933 Training loss: 8.90860652923584
2025-12-09 12:16:48.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.0029231011138462566 Training loss: 8.678508758544922
2025-12-09 12:16:48.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.0029228120809612072 Training loss: 8.752118110656738
2025-12-09 12:16:48.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.002922522520257667 Training loss: 8.895167350769043
2025-12-09 12:16:48.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.0029222324318430542 Training loss: 8.50835132598877
2025-12-09 12:16:48.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.0029219418158249826 Training loss: 8.685866355895996
2025-12-09 12:16:49.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.0029216506723112614 Training loss: 8.434123992919922
2025-12-09 12:16:49.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.0029213590014098953 Training loss: 8.807912826538086
2025-12-09 12:16:49.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.002921066803229085 Training loss: 8.795696258544922
2025-12-09 12:16:49.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.002920774077877228 Training loss: 8.62409782409668
2025-12-09 12:16:49.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.0029204808254629146 Training loss: 8.63919448852539
2025-12-09 12:16:49.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.002920187046094933 Training loss: 8.813116073608398
2025-12-09 12:16:49.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.002919892739882266 Training loss: 9.15286636352539
2025-12-09 12:16:49.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.0029195979069340924 Training loss: 9.131982803344727
2025-12-09 12:16:49.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.0029193025473597855 Training loss: 8.799570083618164
2025-12-09 12:16:49.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0029190066612689142 Training loss: 8.596378326416016
2025-12-09 12:16:49.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0029187102487712433 Training loss: 8.952079772949219
2025-12-09 12:16:49.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.0029184133099767326 Training loss: 8.730551719665527
2025-12-09 12:16:50.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.0029181158449955364 Training loss: 8.521834373474121
2025-12-09 12:16:50.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.0029178178539380054 Training loss: 8.735437393188477
2025-12-09 12:16:50.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.0029175193369146844 Training loss: 8.604974746704102
2025-12-09 12:16:50.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.002917220294036315 Training loss: 8.294682502746582
2025-12-09 12:16:50.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0029169207254138314 Training loss: 8.798830032348633
2025-12-09 12:16:50.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.0029166206311583647 Training loss: 8.715524673461914
2025-12-09 12:16:50.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.00291632001138124 Training loss: 8.729571342468262
2025-12-09 12:16:50.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0029160188661939783 Training loss: 8.437636375427246
2025-12-09 12:16:50.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.002915717195708295 Training loss: 8.828031539916992
2025-12-09 12:16:50.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.0029154150000361 Training loss: 8.314270973205566
2025-12-09 12:16:50.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.0029151122792894987 Training loss: 8.656627655029297
2025-12-09 12:16:50.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.00291480903358079 Training loss: 8.599956512451172
2025-12-09 12:16:50.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.00291450526302247 Training loss: 8.571654319763184
2025-12-09 12:16:51.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0029142009677272274 Training loss: 7.7149739265441895
2025-12-09 12:16:51.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.0029138961478079456 Training loss: 8.569557189941406
2025-12-09 12:16:51.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.002913590803377704 Training loss: 9.268027305603027
2025-12-09 12:16:51.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.0029132849345497756 Training loss: 7.725094795227051
2025-12-09 12:16:51.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.0029129785414376275 Training loss: 8.719278335571289
2025-12-09 12:16:51.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.0029126716241549225 Training loss: 8.99618148803711
2025-12-09 12:16:51.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0029123641828155173 Training loss: 8.499914169311523
2025-12-09 12:16:51.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.0029120562175334627 Training loss: 8.565044403076172
2025-12-09 12:16:51.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0029117477284230043 Training loss: 8.543782234191895
2025-12-09 12:16:51.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.0029114387155985814 Training loss: 8.266096115112305
2025-12-09 12:16:51.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.0029111291791748283 Training loss: 8.924657821655273
2025-12-09 12:16:51.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.002910819119266574 Training loss: 8.5638427734375
2025-12-09 12:16:51.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.0029105085359888397 Training loss: 8.497645378112793
2025-12-09 12:16:52.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.0029101974294568427 Training loss: 8.570106506347656
2025-12-09 12:16:52.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.0029098857997859936 Training loss: 8.540412902832031
2025-12-09 12:16:52.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.0029095736470918974 Training loss: 8.78285026550293
2025-12-09 12:16:52.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.0029092609714903525 Training loss: 8.213239669799805
2025-12-09 12:16:52.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.002908947773097352 Training loss: 8.395943641662598
2025-12-09 12:16:52.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.002908634052029083 Training loss: 8.587701797485352
2025-12-09 12:16:52.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.0029083198084019256 Training loss: 8.390528678894043
2025-12-09 12:16:52.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0029080050423324543 Training loss: 8.657302856445312
2025-12-09 12:16:52.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.002907689753937438 Training loss: 8.51025390625
2025-12-09 12:16:52.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.0029073739433338377 Training loss: 8.733620643615723
2025-12-09 12:16:52.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.0029070576106388106 Training loss: 8.434286117553711
2025-12-09 12:16:52.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.002906740755969705 Training loss: 8.62035846710205
2025-12-09 12:16:52.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.002906423379444064 Training loss: 8.601058006286621
2025-12-09 12:16:53.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.0029061054811796248 Training loss: 9.350693702697754
2025-12-09 12:16:53.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.0029057870612943177 Training loss: 8.795721054077148
2025-12-09 12:16:53.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.0029054681199062664 Training loss: 9.100000381469727
2025-12-09 12:16:53.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.002905148657133788 Training loss: 8.313495635986328
2025-12-09 12:16:53.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.0029048286730953927 Training loss: 8.65875244140625
2025-12-09 12:16:53.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.002904508167909785 Training loss: 8.574625015258789
2025-12-09 12:16:53.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.002904187141695863 Training loss: 8.741064071655273
2025-12-09 12:16:53.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.002903865594572716 Training loss: 8.313350677490234
2025-12-09 12:16:53.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.002903543526659628 Training loss: 8.848682403564453
2025-12-09 12:16:53.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.0029032209380760766 Training loss: 8.664220809936523
2025-12-09 12:16:53.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.0029028978289417323 Training loss: 8.930109977722168
2025-12-09 12:16:53.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.002902574199376457 Training loss: 8.37121295928955
2025-12-09 12:16:53.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.002902250049500309 Training loss: 8.481518745422363
2025-12-09 12:16:54.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.0029019253794335363 Training loss: 8.591337203979492
2025-12-09 12:16:54.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.0029016001892965817 Training loss: 8.58333969116211
2025-12-09 12:16:54.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.00290127447921008 Training loss: 8.395973205566406
2025-12-09 12:16:54.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.0029009482492948608 Training loss: 8.925212860107422
2025-12-09 12:16:54.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.002900621499671944 Training loss: 9.001579284667969
2025-12-09 12:16:54.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.0029002942304625435 Training loss: 8.683782577514648
2025-12-09 12:16:54.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.0028999664417880657 Training loss: 8.44072437286377
2025-12-09 12:16:54.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.0028996381337701104 Training loss: 8.21291732788086
2025-12-09 12:16:54.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.0028993093065304695 Training loss: 8.60464096069336
2025-12-09 12:16:54.745 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.002898979960191127 Training loss: 8.682043075561523
2025-12-09 12:16:54.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.002898650094874261 Training loss: 8.308127403259277
2025-12-09 12:16:54.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.00289831971070224 Training loss: 8.471393585205078
2025-12-09 12:16:54.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.002897988807797627 Training loss: 8.488303184509277
2025-12-09 12:16:55.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.002897657386283176 Training loss: 8.523402214050293
2025-12-09 12:16:55.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.0028973254462818345 Training loss: 8.563413619995117
2025-12-09 12:16:55.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.002896992987916741 Training loss: 8.397370338439941
2025-12-09 12:16:55.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.0028966600113112277 Training loss: 8.604233741760254
2025-12-09 12:16:55.363 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.002896326516588819 Training loss: 8.789735794067383
2025-12-09 12:16:55.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.0028959925038732296 Training loss: 8.06296443939209
2025-12-09 12:16:55.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.0028956579732883686 Training loss: 8.441934585571289
2025-12-09 12:16:55.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.002895322924958336 Training loss: 8.670072555541992
2025-12-09 12:16:55.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.002894987359007424 Training loss: 8.157548904418945
2025-12-09 12:16:55.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.0028946512755601175 Training loss: 8.53042984008789
2025-12-09 12:16:55.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.0028943146747410927 Training loss: 8.474655151367188
2025-12-09 12:16:55.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.002893977556675218 Training loss: 8.74514389038086
2025-12-09 12:16:55.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.002893639921487553 Training loss: 8.404834747314453
2025-12-09 12:16:56.064 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.0028933017693033502 Training loss: 8.617761611938477
2025-12-09 12:16:56.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.002892963100248053 Training loss: 8.39754867553711
2025-12-09 12:16:56.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.0028926239144472982 Training loss: 8.523600578308105
2025-12-09 12:16:56.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.002892284212026912 Training loss: 8.255760192871094
