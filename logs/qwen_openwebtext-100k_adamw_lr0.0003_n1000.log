2025-12-09 11:28:59.725 | INFO     | __main__:train:27 - Epoch: 0 Step: 0 LR: 2.9999999999999997e-06 Training loss: 12.037644386291504
2025-12-09 11:28:59.809 | INFO     | __main__:train:27 - Epoch: 0 Step: 1 LR: 5.999999999999999e-06 Training loss: 12.02186107635498
2025-12-09 11:28:59.887 | INFO     | __main__:train:27 - Epoch: 0 Step: 2 LR: 8.999999999999999e-06 Training loss: 12.056852340698242
2025-12-09 11:28:59.988 | INFO     | __main__:train:27 - Epoch: 0 Step: 3 LR: 1.1999999999999999e-05 Training loss: 12.01838207244873
2025-12-09 11:29:00.211 | INFO     | __main__:train:27 - Epoch: 0 Step: 4 LR: 1.4999999999999999e-05 Training loss: 12.021397590637207
2025-12-09 11:29:00.288 | INFO     | __main__:train:27 - Epoch: 0 Step: 5 LR: 1.7999999999999997e-05 Training loss: 11.992819786071777
2025-12-09 11:29:00.366 | INFO     | __main__:train:27 - Epoch: 0 Step: 6 LR: 2.1e-05 Training loss: 11.942936897277832
2025-12-09 11:29:00.445 | INFO     | __main__:train:27 - Epoch: 0 Step: 7 LR: 2.3999999999999997e-05 Training loss: 12.004547119140625
2025-12-09 11:29:00.522 | INFO     | __main__:train:27 - Epoch: 0 Step: 8 LR: 2.6999999999999996e-05 Training loss: 11.961760520935059
2025-12-09 11:29:00.599 | INFO     | __main__:train:27 - Epoch: 0 Step: 9 LR: 2.9999999999999997e-05 Training loss: 11.9354829788208
2025-12-09 11:29:00.676 | INFO     | __main__:train:27 - Epoch: 0 Step: 10 LR: 3.2999999999999996e-05 Training loss: 11.888416290283203
2025-12-09 11:29:00.753 | INFO     | __main__:train:27 - Epoch: 0 Step: 11 LR: 3.5999999999999994e-05 Training loss: 11.851875305175781
2025-12-09 11:29:00.831 | INFO     | __main__:train:27 - Epoch: 0 Step: 12 LR: 3.9e-05 Training loss: 11.807568550109863
2025-12-09 11:29:00.908 | INFO     | __main__:train:27 - Epoch: 0 Step: 13 LR: 4.2e-05 Training loss: 11.803182601928711
2025-12-09 11:29:00.986 | INFO     | __main__:train:27 - Epoch: 0 Step: 14 LR: 4.4999999999999996e-05 Training loss: 11.72277545928955
2025-12-09 11:29:01.063 | INFO     | __main__:train:27 - Epoch: 0 Step: 15 LR: 4.7999999999999994e-05 Training loss: 11.560173988342285
2025-12-09 11:29:01.140 | INFO     | __main__:train:27 - Epoch: 0 Step: 16 LR: 5.1e-05 Training loss: 11.544393539428711
2025-12-09 11:29:01.218 | INFO     | __main__:train:27 - Epoch: 0 Step: 17 LR: 5.399999999999999e-05 Training loss: 11.466588020324707
2025-12-09 11:29:01.295 | INFO     | __main__:train:27 - Epoch: 0 Step: 18 LR: 5.6999999999999996e-05 Training loss: 11.404267311096191
2025-12-09 11:29:01.374 | INFO     | __main__:train:27 - Epoch: 0 Step: 19 LR: 5.9999999999999995e-05 Training loss: 11.468050956726074
2025-12-09 11:29:01.452 | INFO     | __main__:train:27 - Epoch: 0 Step: 20 LR: 6.299999999999999e-05 Training loss: 11.214262962341309
2025-12-09 11:29:01.529 | INFO     | __main__:train:27 - Epoch: 0 Step: 21 LR: 6.599999999999999e-05 Training loss: 11.25281810760498
2025-12-09 11:29:01.606 | INFO     | __main__:train:27 - Epoch: 0 Step: 22 LR: 6.9e-05 Training loss: 11.267230987548828
2025-12-09 11:29:01.684 | INFO     | __main__:train:27 - Epoch: 0 Step: 23 LR: 7.199999999999999e-05 Training loss: 11.101861953735352
2025-12-09 11:29:01.761 | INFO     | __main__:train:27 - Epoch: 0 Step: 24 LR: 7.5e-05 Training loss: 11.109286308288574
2025-12-09 11:29:01.838 | INFO     | __main__:train:27 - Epoch: 0 Step: 25 LR: 7.8e-05 Training loss: 10.94545841217041
2025-12-09 11:29:01.919 | INFO     | __main__:train:27 - Epoch: 0 Step: 26 LR: 8.1e-05 Training loss: 11.136768341064453
2025-12-09 11:29:01.996 | INFO     | __main__:train:27 - Epoch: 0 Step: 27 LR: 8.4e-05 Training loss: 11.070140838623047
2025-12-09 11:29:02.078 | INFO     | __main__:train:27 - Epoch: 0 Step: 28 LR: 8.699999999999999e-05 Training loss: 10.963512420654297
2025-12-09 11:29:02.156 | INFO     | __main__:train:27 - Epoch: 0 Step: 29 LR: 8.999999999999999e-05 Training loss: 10.890528678894043
2025-12-09 11:29:02.239 | INFO     | __main__:train:27 - Epoch: 0 Step: 30 LR: 9.3e-05 Training loss: 10.770315170288086
2025-12-09 11:29:02.319 | INFO     | __main__:train:27 - Epoch: 0 Step: 31 LR: 9.599999999999999e-05 Training loss: 10.852534294128418
2025-12-09 11:29:02.399 | INFO     | __main__:train:27 - Epoch: 0 Step: 32 LR: 9.9e-05 Training loss: 10.688478469848633
2025-12-09 11:29:02.479 | INFO     | __main__:train:27 - Epoch: 0 Step: 33 LR: 0.000102 Training loss: 10.920064926147461
2025-12-09 11:29:02.561 | INFO     | __main__:train:27 - Epoch: 0 Step: 34 LR: 0.00010499999999999999 Training loss: 10.576824188232422
2025-12-09 11:29:02.642 | INFO     | __main__:train:27 - Epoch: 0 Step: 35 LR: 0.00010799999999999998 Training loss: 10.646220207214355
2025-12-09 11:29:02.725 | INFO     | __main__:train:27 - Epoch: 0 Step: 36 LR: 0.00011099999999999999 Training loss: 10.80760383605957
2025-12-09 11:29:02.806 | INFO     | __main__:train:27 - Epoch: 0 Step: 37 LR: 0.00011399999999999999 Training loss: 10.581005096435547
2025-12-09 11:29:02.886 | INFO     | __main__:train:27 - Epoch: 0 Step: 38 LR: 0.000117 Training loss: 10.443329811096191
2025-12-09 11:29:02.966 | INFO     | __main__:train:27 - Epoch: 0 Step: 39 LR: 0.00011999999999999999 Training loss: 10.378113746643066
2025-12-09 11:29:03.046 | INFO     | __main__:train:27 - Epoch: 0 Step: 40 LR: 0.00012299999999999998 Training loss: 10.340323448181152
2025-12-09 11:29:03.123 | INFO     | __main__:train:27 - Epoch: 0 Step: 41 LR: 0.00012599999999999997 Training loss: 10.307757377624512
2025-12-09 11:29:03.205 | INFO     | __main__:train:27 - Epoch: 0 Step: 42 LR: 0.000129 Training loss: 10.247437477111816
2025-12-09 11:29:03.285 | INFO     | __main__:train:27 - Epoch: 0 Step: 43 LR: 0.00013199999999999998 Training loss: 10.182003021240234
2025-12-09 11:29:03.366 | INFO     | __main__:train:27 - Epoch: 0 Step: 44 LR: 0.000135 Training loss: 10.301745414733887
2025-12-09 11:29:03.445 | INFO     | __main__:train:27 - Epoch: 0 Step: 45 LR: 0.000138 Training loss: 9.90143871307373
2025-12-09 11:29:03.527 | INFO     | __main__:train:27 - Epoch: 0 Step: 46 LR: 0.00014099999999999998 Training loss: 9.927388191223145
2025-12-09 11:29:03.606 | INFO     | __main__:train:27 - Epoch: 0 Step: 47 LR: 0.00014399999999999998 Training loss: 9.752543449401855
2025-12-09 11:29:03.688 | INFO     | __main__:train:27 - Epoch: 0 Step: 48 LR: 0.000147 Training loss: 9.680658340454102
2025-12-09 11:29:03.841 | INFO     | __main__:train:27 - Epoch: 0 Step: 49 LR: 0.00015 Training loss: 9.716715812683105
2025-12-09 11:29:03.923 | INFO     | __main__:train:27 - Epoch: 0 Step: 50 LR: 0.00015299999999999998 Training loss: 9.593426704406738
2025-12-09 11:29:04.006 | INFO     | __main__:train:27 - Epoch: 0 Step: 51 LR: 0.000156 Training loss: 9.836382865905762
2025-12-09 11:29:04.087 | INFO     | __main__:train:27 - Epoch: 0 Step: 52 LR: 0.000159 Training loss: 9.526766777038574
2025-12-09 11:29:04.170 | INFO     | __main__:train:27 - Epoch: 0 Step: 53 LR: 0.000162 Training loss: 9.274621963500977
2025-12-09 11:29:04.250 | INFO     | __main__:train:27 - Epoch: 0 Step: 54 LR: 0.000165 Training loss: 9.45907211303711
2025-12-09 11:29:04.331 | INFO     | __main__:train:27 - Epoch: 0 Step: 55 LR: 0.000168 Training loss: 9.363044738769531
2025-12-09 11:29:04.413 | INFO     | __main__:train:27 - Epoch: 0 Step: 56 LR: 0.00017099999999999998 Training loss: 9.185013771057129
2025-12-09 11:29:04.492 | INFO     | __main__:train:27 - Epoch: 0 Step: 57 LR: 0.00017399999999999997 Training loss: 9.155961990356445
2025-12-09 11:29:04.574 | INFO     | __main__:train:27 - Epoch: 0 Step: 58 LR: 0.00017699999999999997 Training loss: 8.963390350341797
2025-12-09 11:29:04.653 | INFO     | __main__:train:27 - Epoch: 0 Step: 59 LR: 0.00017999999999999998 Training loss: 8.903769493103027
2025-12-09 11:29:04.733 | INFO     | __main__:train:27 - Epoch: 0 Step: 60 LR: 0.00018299999999999998 Training loss: 8.947452545166016
2025-12-09 11:29:04.812 | INFO     | __main__:train:27 - Epoch: 0 Step: 61 LR: 0.000186 Training loss: 8.637624740600586
2025-12-09 11:29:04.894 | INFO     | __main__:train:27 - Epoch: 0 Step: 62 LR: 0.00018899999999999999 Training loss: 8.987654685974121
2025-12-09 11:29:04.972 | INFO     | __main__:train:27 - Epoch: 0 Step: 63 LR: 0.00019199999999999998 Training loss: 9.488537788391113
2025-12-09 11:29:05.053 | INFO     | __main__:train:27 - Epoch: 0 Step: 64 LR: 0.000195 Training loss: 8.574471473693848
2025-12-09 11:29:05.131 | INFO     | __main__:train:27 - Epoch: 0 Step: 65 LR: 0.000198 Training loss: 8.67086410522461
2025-12-09 11:29:05.209 | INFO     | __main__:train:27 - Epoch: 0 Step: 66 LR: 0.000201 Training loss: 8.557734489440918
2025-12-09 11:29:05.294 | INFO     | __main__:train:27 - Epoch: 0 Step: 67 LR: 0.000204 Training loss: 8.306811332702637
2025-12-09 11:29:05.376 | INFO     | __main__:train:27 - Epoch: 0 Step: 68 LR: 0.00020699999999999996 Training loss: 8.454537391662598
2025-12-09 11:29:05.458 | INFO     | __main__:train:27 - Epoch: 0 Step: 69 LR: 0.00020999999999999998 Training loss: 8.290716171264648
2025-12-09 11:29:05.540 | INFO     | __main__:train:27 - Epoch: 0 Step: 70 LR: 0.00021299999999999997 Training loss: 8.116287231445312
2025-12-09 11:29:05.620 | INFO     | __main__:train:27 - Epoch: 0 Step: 71 LR: 0.00021599999999999996 Training loss: 8.425786972045898
2025-12-09 11:29:05.698 | INFO     | __main__:train:27 - Epoch: 0 Step: 72 LR: 0.00021899999999999998 Training loss: 8.207781791687012
2025-12-09 11:29:05.781 | INFO     | __main__:train:27 - Epoch: 0 Step: 73 LR: 0.00022199999999999998 Training loss: 8.443338394165039
2025-12-09 11:29:05.862 | INFO     | __main__:train:27 - Epoch: 0 Step: 74 LR: 0.000225 Training loss: 8.020864486694336
2025-12-09 11:29:05.944 | INFO     | __main__:train:27 - Epoch: 0 Step: 75 LR: 0.00022799999999999999 Training loss: 8.526805877685547
2025-12-09 11:29:06.025 | INFO     | __main__:train:27 - Epoch: 0 Step: 76 LR: 0.00023099999999999998 Training loss: 8.010330200195312
2025-12-09 11:29:06.105 | INFO     | __main__:train:27 - Epoch: 0 Step: 77 LR: 0.000234 Training loss: 8.057363510131836
2025-12-09 11:29:06.186 | INFO     | __main__:train:27 - Epoch: 0 Step: 78 LR: 0.000237 Training loss: 8.030682563781738
2025-12-09 11:29:06.272 | INFO     | __main__:train:27 - Epoch: 0 Step: 79 LR: 0.00023999999999999998 Training loss: 7.767195701599121
2025-12-09 11:29:06.359 | INFO     | __main__:train:27 - Epoch: 0 Step: 80 LR: 0.000243 Training loss: 7.91826057434082
2025-12-09 11:29:06.442 | INFO     | __main__:train:27 - Epoch: 0 Step: 81 LR: 0.00024599999999999996 Training loss: 7.855338096618652
2025-12-09 11:29:06.524 | INFO     | __main__:train:27 - Epoch: 0 Step: 82 LR: 0.000249 Training loss: 7.70751428604126
2025-12-09 11:29:06.604 | INFO     | __main__:train:27 - Epoch: 0 Step: 83 LR: 0.00025199999999999995 Training loss: 7.745672225952148
2025-12-09 11:29:06.686 | INFO     | __main__:train:27 - Epoch: 0 Step: 84 LR: 0.00025499999999999996 Training loss: 7.279361248016357
2025-12-09 11:29:06.767 | INFO     | __main__:train:27 - Epoch: 0 Step: 85 LR: 0.000258 Training loss: 8.151378631591797
2025-12-09 11:29:06.850 | INFO     | __main__:train:27 - Epoch: 0 Step: 86 LR: 0.000261 Training loss: 7.861943244934082
2025-12-09 11:29:06.931 | INFO     | __main__:train:27 - Epoch: 0 Step: 87 LR: 0.00026399999999999997 Training loss: 7.846163272857666
2025-12-09 11:29:07.010 | INFO     | __main__:train:27 - Epoch: 0 Step: 88 LR: 0.000267 Training loss: 7.929221153259277
2025-12-09 11:29:07.092 | INFO     | __main__:train:27 - Epoch: 0 Step: 89 LR: 0.00027 Training loss: 7.9785380363464355
2025-12-09 11:29:07.175 | INFO     | __main__:train:27 - Epoch: 0 Step: 90 LR: 0.00027299999999999997 Training loss: 7.712737560272217
2025-12-09 11:29:07.261 | INFO     | __main__:train:27 - Epoch: 0 Step: 91 LR: 0.000276 Training loss: 7.83662223815918
2025-12-09 11:29:07.344 | INFO     | __main__:train:27 - Epoch: 0 Step: 92 LR: 0.000279 Training loss: 8.229238510131836
2025-12-09 11:29:07.424 | INFO     | __main__:train:27 - Epoch: 0 Step: 93 LR: 0.00028199999999999997 Training loss: 8.076539993286133
2025-12-09 11:29:07.504 | INFO     | __main__:train:27 - Epoch: 0 Step: 94 LR: 0.000285 Training loss: 7.822679042816162
2025-12-09 11:29:07.586 | INFO     | __main__:train:27 - Epoch: 0 Step: 95 LR: 0.00028799999999999995 Training loss: 7.826880931854248
2025-12-09 11:29:07.667 | INFO     | __main__:train:27 - Epoch: 0 Step: 96 LR: 0.00029099999999999997 Training loss: 7.958398818969727
2025-12-09 11:29:07.749 | INFO     | __main__:train:27 - Epoch: 0 Step: 97 LR: 0.000294 Training loss: 8.62903881072998
2025-12-09 11:29:07.831 | INFO     | __main__:train:27 - Epoch: 0 Step: 98 LR: 0.00029699999999999996 Training loss: 7.802905082702637
2025-12-09 11:29:07.910 | INFO     | __main__:train:27 - Epoch: 0 Step: 99 LR: 0.0003 Training loss: 7.765809535980225
2025-12-09 11:29:07.991 | INFO     | __main__:train:27 - Epoch: 0 Step: 100 LR: 0.0002999960152181958 Training loss: 8.081574440002441
2025-12-09 11:29:08.072 | INFO     | __main__:train:27 - Epoch: 0 Step: 101 LR: 0.0002999840610844965 Training loss: 8.578084945678711
2025-12-09 11:29:08.154 | INFO     | __main__:train:27 - Epoch: 0 Step: 102 LR: 0.00029996413823403024 Training loss: 7.773592948913574
2025-12-09 11:29:08.241 | INFO     | __main__:train:27 - Epoch: 0 Step: 103 LR: 0.00029993624772530646 Training loss: 7.59126091003418
2025-12-09 11:29:08.321 | INFO     | __main__:train:27 - Epoch: 0 Step: 104 LR: 0.0002999003910401598 Training loss: 8.061551094055176
2025-12-09 11:29:08.401 | INFO     | __main__:train:27 - Epoch: 0 Step: 105 LR: 0.0002998565700836711 Training loss: 7.7301225662231445
2025-12-09 11:29:08.483 | INFO     | __main__:train:27 - Epoch: 0 Step: 106 LR: 0.00029980478718406634 Training loss: 7.57077693939209
2025-12-09 11:29:08.565 | INFO     | __main__:train:27 - Epoch: 0 Step: 107 LR: 0.00029974504509259304 Training loss: 7.829253673553467
2025-12-09 11:29:08.648 | INFO     | __main__:train:27 - Epoch: 0 Step: 108 LR: 0.0002996773469833737 Training loss: 7.778169631958008
2025-12-09 11:29:08.730 | INFO     | __main__:train:27 - Epoch: 0 Step: 109 LR: 0.0002996016964532377 Training loss: 7.898550510406494
2025-12-09 11:29:08.810 | INFO     | __main__:train:27 - Epoch: 0 Step: 110 LR: 0.0002995180975215297 Training loss: 7.870378017425537
2025-12-09 11:29:08.890 | INFO     | __main__:train:27 - Epoch: 0 Step: 111 LR: 0.00029942655462989647 Training loss: 7.819524765014648
2025-12-09 11:29:08.972 | INFO     | __main__:train:27 - Epoch: 0 Step: 112 LR: 0.0002993270726420506 Training loss: 7.900980472564697
2025-12-09 11:29:09.050 | INFO     | __main__:train:27 - Epoch: 0 Step: 113 LR: 0.0002992196568435123 Training loss: 7.709563255310059
2025-12-09 11:29:09.131 | INFO     | __main__:train:27 - Epoch: 0 Step: 114 LR: 0.00029910431294132846 Training loss: 7.834761619567871
2025-12-09 11:29:09.214 | INFO     | __main__:train:27 - Epoch: 0 Step: 115 LR: 0.00029898104706376963 Training loss: 7.855879306793213
2025-12-09 11:29:09.295 | INFO     | __main__:train:27 - Epoch: 0 Step: 116 LR: 0.0002988498657600041 Training loss: 7.800398349761963
2025-12-09 11:29:09.378 | INFO     | __main__:train:27 - Epoch: 0 Step: 117 LR: 0.0002987107759997501 Training loss: 7.674918174743652
2025-12-09 11:29:09.460 | INFO     | __main__:train:27 - Epoch: 0 Step: 118 LR: 0.0002985637851729057 Training loss: 7.479474067687988
2025-12-09 11:29:09.542 | INFO     | __main__:train:27 - Epoch: 0 Step: 119 LR: 0.0002984089010891557 Training loss: 7.8297624588012695
2025-12-09 11:29:09.623 | INFO     | __main__:train:27 - Epoch: 0 Step: 120 LR: 0.0002982461319775573 Training loss: 7.577702522277832
2025-12-09 11:29:09.703 | INFO     | __main__:train:27 - Epoch: 0 Step: 121 LR: 0.00029807548648610235 Training loss: 7.696212291717529
2025-12-09 11:29:09.782 | INFO     | __main__:train:27 - Epoch: 0 Step: 122 LR: 0.0002978969736812582 Training loss: 7.479660511016846
2025-12-09 11:29:09.864 | INFO     | __main__:train:27 - Epoch: 0 Step: 123 LR: 0.00029771060304748583 Training loss: 7.917708873748779
2025-12-09 11:29:09.942 | INFO     | __main__:train:27 - Epoch: 0 Step: 124 LR: 0.00029751638448673607 Training loss: 8.071205139160156
2025-12-09 11:29:10.025 | INFO     | __main__:train:27 - Epoch: 0 Step: 125 LR: 0.00029731432831792343 Training loss: 8.082939147949219
2025-12-09 11:29:10.103 | INFO     | __main__:train:27 - Epoch: 0 Step: 126 LR: 0.0002971044452763778 Training loss: 7.749706745147705
2025-12-09 11:29:10.187 | INFO     | __main__:train:27 - Epoch: 0 Step: 127 LR: 0.00029688674651327427 Training loss: 7.523766040802002
2025-12-09 11:29:10.271 | INFO     | __main__:train:27 - Epoch: 0 Step: 128 LR: 0.00029666124359504034 Training loss: 7.958979606628418
2025-12-09 11:29:10.353 | INFO     | __main__:train:27 - Epoch: 0 Step: 129 LR: 0.0002964279485027417 Training loss: 7.735964775085449
2025-12-09 11:29:10.435 | INFO     | __main__:train:27 - Epoch: 0 Step: 130 LR: 0.00029618687363144555 Training loss: 7.684666633605957
2025-12-09 11:29:10.519 | INFO     | __main__:train:27 - Epoch: 0 Step: 131 LR: 0.00029593803178956207 Training loss: 7.5199456214904785
2025-12-09 11:29:10.599 | INFO     | __main__:train:27 - Epoch: 0 Step: 132 LR: 0.0002956814361981638 Training loss: 7.315461158752441
2025-12-09 11:29:10.678 | INFO     | __main__:train:27 - Epoch: 0 Step: 133 LR: 0.00029541710049028327 Training loss: 7.68791389465332
2025-12-09 11:29:10.760 | INFO     | __main__:train:27 - Epoch: 0 Step: 134 LR: 0.0002951450387101888 Training loss: 7.395266056060791
2025-12-09 11:29:10.838 | INFO     | __main__:train:27 - Epoch: 0 Step: 135 LR: 0.0002948652653126382 Training loss: 7.622626781463623
2025-12-09 11:29:10.921 | INFO     | __main__:train:27 - Epoch: 0 Step: 136 LR: 0.00029457779516211055 Training loss: 7.364285469055176
2025-12-09 11:29:11.000 | INFO     | __main__:train:27 - Epoch: 0 Step: 137 LR: 0.00029428264353201694 Training loss: 7.74252462387085
2025-12-09 11:29:11.077 | INFO     | __main__:train:27 - Epoch: 0 Step: 138 LR: 0.00029397982610388873 Training loss: 7.3596038818359375
2025-12-09 11:29:11.158 | INFO     | __main__:train:27 - Epoch: 0 Step: 139 LR: 0.00029366935896654414 Training loss: 6.986137866973877
2025-12-09 11:29:11.235 | INFO     | __main__:train:27 - Epoch: 0 Step: 140 LR: 0.0002933512586152339 Training loss: 7.412286758422852
2025-12-09 11:29:11.312 | INFO     | __main__:train:27 - Epoch: 0 Step: 141 LR: 0.0002930255419507646 Training loss: 7.348418235778809
2025-12-09 11:29:11.390 | INFO     | __main__:train:27 - Epoch: 0 Step: 142 LR: 0.00029269222627860067 Training loss: 6.856961250305176
2025-12-09 11:29:11.467 | INFO     | __main__:train:27 - Epoch: 0 Step: 143 LR: 0.00029235132930794516 Training loss: 7.450489044189453
2025-12-09 11:29:11.544 | INFO     | __main__:train:27 - Epoch: 0 Step: 144 LR: 0.00029200286915079867 Training loss: 7.4076714515686035
2025-12-09 11:29:11.622 | INFO     | __main__:train:27 - Epoch: 0 Step: 145 LR: 0.0002916468643209971 Training loss: 7.293088912963867
2025-12-09 11:29:11.699 | INFO     | __main__:train:27 - Epoch: 0 Step: 146 LR: 0.0002912833337332281 Training loss: 7.475632190704346
2025-12-09 11:29:11.776 | INFO     | __main__:train:27 - Epoch: 0 Step: 147 LR: 0.0002909122967020258 Training loss: 7.291499614715576
2025-12-09 11:29:11.854 | INFO     | __main__:train:27 - Epoch: 0 Step: 148 LR: 0.0002905337729407452 Training loss: 7.482780933380127
2025-12-09 11:29:11.931 | INFO     | __main__:train:27 - Epoch: 0 Step: 149 LR: 0.0002901477825605141 Training loss: 7.4955363273620605
2025-12-09 11:29:12.009 | INFO     | __main__:train:27 - Epoch: 0 Step: 150 LR: 0.0002897543460691651 Training loss: 7.32772970199585
2025-12-09 11:29:12.090 | INFO     | __main__:train:27 - Epoch: 0 Step: 151 LR: 0.00028935348437014594 Training loss: 7.5201873779296875
2025-12-09 11:29:12.168 | INFO     | __main__:train:27 - Epoch: 0 Step: 152 LR: 0.0002889452187614086 Training loss: 7.574679851531982
2025-12-09 11:29:12.246 | INFO     | __main__:train:27 - Epoch: 0 Step: 153 LR: 0.000288529570934278 Training loss: 7.477311134338379
2025-12-09 11:29:12.323 | INFO     | __main__:train:27 - Epoch: 0 Step: 154 LR: 0.0002881065629722994 Training loss: 7.544615268707275
2025-12-09 11:29:12.401 | INFO     | __main__:train:27 - Epoch: 0 Step: 155 LR: 0.0002876762173500653 Training loss: 7.439316749572754
2025-12-09 11:29:12.478 | INFO     | __main__:train:27 - Epoch: 0 Step: 156 LR: 0.000287238556932021 Training loss: 7.3984456062316895
2025-12-09 11:29:12.556 | INFO     | __main__:train:27 - Epoch: 0 Step: 157 LR: 0.0002867936049712502 Training loss: 7.249851226806641
2025-12-09 11:29:12.633 | INFO     | __main__:train:27 - Epoch: 0 Step: 158 LR: 0.0002863413851082392 Training loss: 7.3938212394714355
2025-12-09 11:29:12.711 | INFO     | __main__:train:27 - Epoch: 0 Step: 159 LR: 0.00028588192136962104 Training loss: 7.212482929229736
2025-12-09 11:29:12.788 | INFO     | __main__:train:27 - Epoch: 0 Step: 160 LR: 0.00028541523816689914 Training loss: 7.5575385093688965
2025-12-09 11:29:12.866 | INFO     | __main__:train:27 - Epoch: 0 Step: 161 LR: 0.00028494136029514987 Training loss: 7.738068103790283
2025-12-09 11:29:12.943 | INFO     | __main__:train:27 - Epoch: 0 Step: 162 LR: 0.00028446031293170545 Training loss: 7.865349769592285
2025-12-09 11:29:13.025 | INFO     | __main__:train:27 - Epoch: 0 Step: 163 LR: 0.00028397212163481643 Training loss: 7.573771953582764
2025-12-09 11:29:13.103 | INFO     | __main__:train:27 - Epoch: 0 Step: 164 LR: 0.00028347681234229327 Training loss: 7.4437150955200195
2025-12-09 11:29:13.180 | INFO     | __main__:train:27 - Epoch: 0 Step: 165 LR: 0.00028297441137012884 Training loss: 7.4191203117370605
2025-12-09 11:29:13.257 | INFO     | __main__:train:27 - Epoch: 0 Step: 166 LR: 0.0002824649454110998 Training loss: 7.602277755737305
2025-12-09 11:29:13.335 | INFO     | __main__:train:27 - Epoch: 0 Step: 167 LR: 0.00028194844153334864 Training loss: 7.243338108062744
2025-12-09 11:29:13.412 | INFO     | __main__:train:27 - Epoch: 0 Step: 168 LR: 0.0002814249271789453 Training loss: 7.387617111206055
2025-12-09 11:29:13.490 | INFO     | __main__:train:27 - Epoch: 0 Step: 169 LR: 0.0002808944301624295 Training loss: 7.686746597290039
2025-12-09 11:29:13.570 | INFO     | __main__:train:27 - Epoch: 0 Step: 170 LR: 0.00028035697866933275 Training loss: 7.631886959075928
2025-12-09 11:29:13.649 | INFO     | __main__:train:27 - Epoch: 0 Step: 171 LR: 0.00027981260125468064 Training loss: 7.5746235847473145
2025-12-09 11:29:13.727 | INFO     | __main__:train:27 - Epoch: 0 Step: 172 LR: 0.00027926132684147613 Training loss: 7.468559265136719
2025-12-09 11:29:13.805 | INFO     | __main__:train:27 - Epoch: 0 Step: 173 LR: 0.00027870318471916265 Training loss: 7.079607009887695
2025-12-09 11:29:13.883 | INFO     | __main__:train:27 - Epoch: 0 Step: 174 LR: 0.00027813820454206773 Training loss: 7.523289203643799
2025-12-09 11:29:13.966 | INFO     | __main__:train:27 - Epoch: 0 Step: 175 LR: 0.00027756641632782777 Training loss: 7.320193290710449
2025-12-09 11:29:14.044 | INFO     | __main__:train:27 - Epoch: 0 Step: 176 LR: 0.00027698785045579316 Training loss: 7.631661891937256
2025-12-09 11:29:14.122 | INFO     | __main__:train:27 - Epoch: 0 Step: 177 LR: 0.0002764025376654139 Training loss: 7.218743801116943
2025-12-09 11:29:14.200 | INFO     | __main__:train:27 - Epoch: 0 Step: 178 LR: 0.00027581050905460677 Training loss: 6.881557941436768
2025-12-09 11:29:14.277 | INFO     | __main__:train:27 - Epoch: 0 Step: 179 LR: 0.000275211796078103 Training loss: 7.298173904418945
2025-12-09 11:29:14.355 | INFO     | __main__:train:27 - Epoch: 0 Step: 180 LR: 0.0002746064305457768 Training loss: 7.345707893371582
2025-12-09 11:29:14.432 | INFO     | __main__:train:27 - Epoch: 0 Step: 181 LR: 0.00027399444462095573 Training loss: 7.335686206817627
2025-12-09 11:29:14.510 | INFO     | __main__:train:27 - Epoch: 0 Step: 182 LR: 0.00027337587081871143 Training loss: 7.058609962463379
2025-12-09 11:29:14.587 | INFO     | __main__:train:27 - Epoch: 0 Step: 183 LR: 0.00027275074200413233 Training loss: 7.0142669677734375
2025-12-09 11:29:14.665 | INFO     | __main__:train:27 - Epoch: 0 Step: 184 LR: 0.0002721190913905774 Training loss: 7.3090996742248535
2025-12-09 11:29:14.742 | INFO     | __main__:train:27 - Epoch: 0 Step: 185 LR: 0.0002714809525379117 Training loss: 7.676279544830322
2025-12-09 11:29:14.820 | INFO     | __main__:train:27 - Epoch: 0 Step: 186 LR: 0.000270836359350723 Training loss: 7.219002723693848
2025-12-09 11:29:14.902 | INFO     | __main__:train:27 - Epoch: 0 Step: 187 LR: 0.0002701853460765206 Training loss: 7.255081653594971
2025-12-09 11:29:14.979 | INFO     | __main__:train:27 - Epoch: 0 Step: 188 LR: 0.000269527947303916 Training loss: 7.489782333374023
2025-12-09 11:29:15.057 | INFO     | __main__:train:27 - Epoch: 0 Step: 189 LR: 0.00026886419796078465 Training loss: 7.145147800445557
2025-12-09 11:29:15.135 | INFO     | __main__:train:27 - Epoch: 0 Step: 190 LR: 0.00026819413331241067 Training loss: 6.997329235076904
2025-12-09 11:29:15.212 | INFO     | __main__:train:27 - Epoch: 0 Step: 191 LR: 0.0002675177889596129 Training loss: 7.362737655639648
2025-12-09 11:29:15.290 | INFO     | __main__:train:27 - Epoch: 0 Step: 192 LR: 0.0002668352008368537 Training loss: 7.652650356292725
2025-12-09 11:29:15.367 | INFO     | __main__:train:27 - Epoch: 0 Step: 193 LR: 0.00026614640521032936 Training loss: 7.6018853187561035
2025-12-09 11:29:15.445 | INFO     | __main__:train:27 - Epoch: 0 Step: 194 LR: 0.0002654514386760437 Training loss: 7.932971954345703
2025-12-09 11:29:15.523 | INFO     | __main__:train:27 - Epoch: 0 Step: 195 LR: 0.0002647503381578635 Training loss: 7.443295478820801
2025-12-09 11:29:15.600 | INFO     | __main__:train:27 - Epoch: 0 Step: 196 LR: 0.00026404314090555637 Training loss: 7.596792221069336
2025-12-09 11:29:15.678 | INFO     | __main__:train:27 - Epoch: 0 Step: 197 LR: 0.00026332988449281235 Training loss: 7.30412483215332
2025-12-09 11:29:15.755 | INFO     | __main__:train:27 - Epoch: 0 Step: 198 LR: 0.00026261060681524707 Training loss: 7.211666584014893
2025-12-09 11:29:15.836 | INFO     | __main__:train:27 - Epoch: 0 Step: 199 LR: 0.0002618853460883886 Training loss: 7.436271667480469
2025-12-09 11:29:15.914 | INFO     | __main__:train:27 - Epoch: 0 Step: 200 LR: 0.0002611541408456468 Training loss: 7.334305286407471
2025-12-09 11:29:15.992 | INFO     | __main__:train:27 - Epoch: 0 Step: 201 LR: 0.0002604170299362664 Training loss: 7.109330177307129
2025-12-09 11:29:16.069 | INFO     | __main__:train:27 - Epoch: 0 Step: 202 LR: 0.00025967405252326253 Training loss: 7.281046390533447
2025-12-09 11:29:16.147 | INFO     | __main__:train:27 - Epoch: 0 Step: 203 LR: 0.00025892524808134027 Training loss: 7.010278701782227
2025-12-09 11:29:16.225 | INFO     | __main__:train:27 - Epoch: 0 Step: 204 LR: 0.0002581706563947971 Training loss: 7.133116722106934
2025-12-09 11:29:16.303 | INFO     | __main__:train:27 - Epoch: 0 Step: 205 LR: 0.0002574103175554093 Training loss: 7.386382579803467
2025-12-09 11:29:16.380 | INFO     | __main__:train:27 - Epoch: 0 Step: 206 LR: 0.00025664427196030187 Training loss: 7.077276706695557
2025-12-09 11:29:16.458 | INFO     | __main__:train:27 - Epoch: 0 Step: 207 LR: 0.0002558725603098021 Training loss: 7.228611946105957
2025-12-09 11:29:16.536 | INFO     | __main__:train:27 - Epoch: 0 Step: 208 LR: 0.00025509522360527725 Training loss: 7.295699119567871
2025-12-09 11:29:16.617 | INFO     | __main__:train:27 - Epoch: 0 Step: 209 LR: 0.0002543123031469561 Training loss: 7.555499076843262
2025-12-09 11:29:16.697 | INFO     | __main__:train:27 - Epoch: 0 Step: 210 LR: 0.0002535238405317345 Training loss: 7.454056262969971
2025-12-09 11:29:16.786 | INFO     | __main__:train:27 - Epoch: 0 Step: 211 LR: 0.0002527298776509656 Training loss: 7.212718486785889
2025-12-09 11:29:16.867 | INFO     | __main__:train:27 - Epoch: 0 Step: 212 LR: 0.000251930456688234 Training loss: 7.403541564941406
2025-12-09 11:29:16.948 | INFO     | __main__:train:27 - Epoch: 0 Step: 213 LR: 0.00025112562011711433 Training loss: 7.7658467292785645
2025-12-09 11:29:17.029 | INFO     | __main__:train:27 - Epoch: 0 Step: 214 LR: 0.00025031541069891507 Training loss: 6.747452735900879
2025-12-09 11:29:17.109 | INFO     | __main__:train:27 - Epoch: 0 Step: 215 LR: 0.00024949987148040605 Training loss: 7.519379615783691
2025-12-09 11:29:17.190 | INFO     | __main__:train:27 - Epoch: 0 Step: 216 LR: 0.0002486790457915318 Training loss: 7.372292518615723
2025-12-09 11:29:17.269 | INFO     | __main__:train:27 - Epoch: 0 Step: 217 LR: 0.00024785297724310925 Training loss: 7.417111396789551
2025-12-09 11:29:17.347 | INFO     | __main__:train:27 - Epoch: 0 Step: 218 LR: 0.0002470217097245107 Training loss: 7.381319046020508
2025-12-09 11:29:17.425 | INFO     | __main__:train:27 - Epoch: 0 Step: 219 LR: 0.00024618528740133196 Training loss: 7.674012184143066
2025-12-09 11:29:17.503 | INFO     | __main__:train:27 - Epoch: 0 Step: 220 LR: 0.0002453437547130456 Training loss: 7.228405475616455
2025-12-09 11:29:17.581 | INFO     | __main__:train:27 - Epoch: 0 Step: 221 LR: 0.0002444971563706404 Training loss: 6.86984920501709
2025-12-09 11:29:17.662 | INFO     | __main__:train:27 - Epoch: 0 Step: 222 LR: 0.00024364553735424516 Training loss: 7.046127796173096
2025-12-09 11:29:17.746 | INFO     | __main__:train:27 - Epoch: 0 Step: 223 LR: 0.0002427889429107394 Training loss: 7.276291370391846
2025-12-09 11:29:17.830 | INFO     | __main__:train:27 - Epoch: 0 Step: 224 LR: 0.00024192741855134914 Training loss: 7.385700702667236
2025-12-09 11:29:17.911 | INFO     | __main__:train:27 - Epoch: 0 Step: 225 LR: 0.0002410610100492289 Training loss: 7.328099727630615
2025-12-09 11:29:17.994 | INFO     | __main__:train:27 - Epoch: 0 Step: 226 LR: 0.0002401897634370299 Training loss: 7.509421348571777
2025-12-09 11:29:18.072 | INFO     | __main__:train:27 - Epoch: 0 Step: 227 LR: 0.00023931372500445396 Training loss: 7.3624587059021
2025-12-09 11:29:18.153 | INFO     | __main__:train:27 - Epoch: 0 Step: 228 LR: 0.00023843294129579463 Training loss: 7.054219722747803
2025-12-09 11:29:18.233 | INFO     | __main__:train:27 - Epoch: 0 Step: 229 LR: 0.00023754745910746375 Training loss: 7.305927753448486
2025-12-09 11:29:18.316 | INFO     | __main__:train:27 - Epoch: 0 Step: 230 LR: 0.00023665732548550555 Training loss: 7.299483299255371
2025-12-09 11:29:18.399 | INFO     | __main__:train:27 - Epoch: 0 Step: 231 LR: 0.0002357625877230968 Training loss: 7.0613274574279785
2025-12-09 11:29:18.482 | INFO     | __main__:train:27 - Epoch: 0 Step: 232 LR: 0.00023486329335803424 Training loss: 7.298498630523682
2025-12-09 11:29:18.565 | INFO     | __main__:train:27 - Epoch: 0 Step: 233 LR: 0.0002339594901702088 Training loss: 6.89741325378418
2025-12-09 11:29:18.645 | INFO     | __main__:train:27 - Epoch: 0 Step: 234 LR: 0.00023305122617906716 Training loss: 7.107872009277344
2025-12-09 11:29:18.730 | INFO     | __main__:train:27 - Epoch: 0 Step: 235 LR: 0.00023213854964106032 Training loss: 7.375679016113281
2025-12-09 11:29:18.813 | INFO     | __main__:train:27 - Epoch: 0 Step: 236 LR: 0.00023122150904707973 Training loss: 7.231455326080322
2025-12-09 11:29:18.892 | INFO     | __main__:train:27 - Epoch: 0 Step: 237 LR: 0.00023030015311988105 Training loss: 7.309620380401611
2025-12-09 11:29:18.975 | INFO     | __main__:train:27 - Epoch: 0 Step: 238 LR: 0.00022937453081149542 Training loss: 7.307333946228027
2025-12-09 11:29:19.054 | INFO     | __main__:train:27 - Epoch: 0 Step: 239 LR: 0.00022844469130062857 Training loss: 6.859530925750732
2025-12-09 11:29:19.136 | INFO     | __main__:train:27 - Epoch: 0 Step: 240 LR: 0.00022751068399004803 Training loss: 7.180246353149414
2025-12-09 11:29:19.219 | INFO     | __main__:train:27 - Epoch: 0 Step: 241 LR: 0.0002265725585039583 Training loss: 7.22700309753418
2025-12-09 11:29:19.302 | INFO     | __main__:train:27 - Epoch: 0 Step: 242 LR: 0.00022563036468536423 Training loss: 7.171146869659424
2025-12-09 11:29:19.384 | INFO     | __main__:train:27 - Epoch: 0 Step: 243 LR: 0.00022468415259342293 Training loss: 7.173311233520508
2025-12-09 11:29:19.467 | INFO     | __main__:train:27 - Epoch: 0 Step: 244 LR: 0.00022373397250078413 Training loss: 7.383659362792969
2025-12-09 11:29:19.545 | INFO     | __main__:train:27 - Epoch: 0 Step: 245 LR: 0.0002227798748909191 Training loss: 7.093959808349609
