2025-12-09 12:06:10.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 9.206876754760742
2025-12-09 12:06:10.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 9.206351280212402
2025-12-09 12:06:10.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 9.206207275390625
2025-12-09 12:06:10.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 9.206313133239746
2025-12-09 12:06:10.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 9.206485748291016
2025-12-09 12:06:10.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 9.206218719482422
2025-12-09 12:06:10.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 9.205831527709961
2025-12-09 12:06:10.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 9.206082344055176
2025-12-09 12:06:10.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 9.207072257995605
2025-12-09 12:06:10.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 9.206341743469238
2025-12-09 12:06:10.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 9.206046104431152
2025-12-09 12:06:10.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 9.206380844116211
2025-12-09 12:06:10.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 9.206282615661621
2025-12-09 12:06:10.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 9.206995010375977
2025-12-09 12:06:11.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 9.206212997436523
2025-12-09 12:06:11.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 9.206011772155762
2025-12-09 12:06:11.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 9.20606803894043
2025-12-09 12:06:11.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 9.206092834472656
2025-12-09 12:06:11.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 9.206725120544434
2025-12-09 12:06:11.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 9.205892562866211
2025-12-09 12:06:11.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 9.206048011779785
2025-12-09 12:06:11.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 9.205269813537598
2025-12-09 12:06:11.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 9.20545482635498
2025-12-09 12:06:11.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 9.205982208251953
2025-12-09 12:06:11.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 9.206063270568848
2025-12-09 12:06:11.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 9.20632266998291
2025-12-09 12:06:11.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 9.205892562866211
2025-12-09 12:06:11.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 9.205707550048828
2025-12-09 12:06:11.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 9.206028938293457
2025-12-09 12:06:11.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 9.205422401428223
2025-12-09 12:06:11.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 9.205460548400879
2025-12-09 12:06:11.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 9.205836296081543
2025-12-09 12:06:11.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 9.205754280090332
2025-12-09 12:06:11.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 9.206059455871582
2025-12-09 12:06:11.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 9.206026077270508
2025-12-09 12:06:11.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 9.205235481262207
2025-12-09 12:06:11.354 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 9.2050199508667
2025-12-09 12:06:11.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 9.204569816589355
2025-12-09 12:06:11.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 9.20505142211914
2025-12-09 12:06:11.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 9.205095291137695
2025-12-09 12:06:11.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 9.205799102783203
2025-12-09 12:06:11.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 9.205530166625977
2025-12-09 12:06:11.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 9.204809188842773
2025-12-09 12:06:11.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 9.20627212524414
2025-12-09 12:06:11.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 9.205501556396484
2025-12-09 12:06:11.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 9.20466136932373
2025-12-09 12:06:11.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 9.204520225524902
2025-12-09 12:06:11.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 9.204052925109863
2025-12-09 12:06:11.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 9.203927993774414
2025-12-09 12:06:11.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 9.203824043273926
2025-12-09 12:06:11.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 9.204754829406738
2025-12-09 12:06:11.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 9.203754425048828
2025-12-09 12:06:11.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 9.204029083251953
2025-12-09 12:06:11.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 9.20383071899414
2025-12-09 12:06:11.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 9.204373359680176
2025-12-09 12:06:11.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 9.2037992477417
2025-12-09 12:06:11.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 9.204781532287598
2025-12-09 12:06:11.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 9.202730178833008
2025-12-09 12:06:11.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 9.204054832458496
2025-12-09 12:06:11.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 9.20325756072998
2025-12-09 12:06:11.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 9.203513145446777
2025-12-09 12:06:11.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 9.203205108642578
2025-12-09 12:06:11.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 9.203441619873047
2025-12-09 12:06:11.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 9.203180313110352
2025-12-09 12:06:11.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 9.203012466430664
2025-12-09 12:06:11.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 9.20279312133789
2025-12-09 12:06:11.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 9.203445434570312
2025-12-09 12:06:11.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 9.202742576599121
2025-12-09 12:06:11.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 9.203317642211914
2025-12-09 12:06:11.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 9.202839851379395
2025-12-09 12:06:11.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 9.203027725219727
2025-12-09 12:06:11.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 9.202582359313965
2025-12-09 12:06:11.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 9.20238971710205
2025-12-09 12:06:11.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 9.202912330627441
2025-12-09 12:06:11.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 9.201623916625977
2025-12-09 12:06:11.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 9.201671600341797
2025-12-09 12:06:11.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 9.201393127441406
2025-12-09 12:06:11.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 9.201011657714844
2025-12-09 12:06:11.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 9.201615333557129
2025-12-09 12:06:12.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 9.203155517578125
2025-12-09 12:06:12.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 9.201201438903809
2025-12-09 12:06:12.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 9.201642990112305
2025-12-09 12:06:12.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 9.200433731079102
2025-12-09 12:06:12.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 9.20090389251709
2025-12-09 12:06:12.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 9.200797080993652
2025-12-09 12:06:12.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 9.200785636901855
2025-12-09 12:06:12.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 9.199981689453125
2025-12-09 12:06:12.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 9.200504302978516
2025-12-09 12:06:12.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 9.201117515563965
2025-12-09 12:06:12.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 9.200688362121582
2025-12-09 12:06:12.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 9.199512481689453
2025-12-09 12:06:12.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 9.199265480041504
2025-12-09 12:06:12.207 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 9.20095157623291
2025-12-09 12:06:12.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 9.199548721313477
2025-12-09 12:06:12.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 9.199079513549805
2025-12-09 12:06:12.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 9.199514389038086
2025-12-09 12:06:12.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 9.199511528015137
2025-12-09 12:06:12.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 9.198975563049316
2025-12-09 12:06:12.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 9.198731422424316
2025-12-09 12:06:12.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 9.198858261108398
2025-12-09 12:06:12.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0009698463103929542 Training loss: 9.199006080627441
2025-12-09 12:06:12.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.000883022221559489 Training loss: 9.198145866394043
2025-12-09 12:06:12.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.00075 Training loss: 9.198347091674805
2025-12-09 12:06:12.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0005868240888334653 Training loss: 9.19830322265625
2025-12-09 12:06:12.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.00041317591116653486 Training loss: 9.19803237915039
2025-12-09 12:06:12.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0002500000000000001 Training loss: 9.19914436340332
2025-12-09 12:06:12.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.00011697777844051105 Training loss: 9.198724746704102
2025-12-09 12:06:12.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 3.0153689607045842e-05 Training loss: 9.19735050201416
2025-12-09 12:06:12.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0 Training loss: 9.19536304473877
