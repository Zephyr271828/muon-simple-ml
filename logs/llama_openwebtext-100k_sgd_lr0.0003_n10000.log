2025-12-09 12:53:43.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 2.9999999999999997e-06 Training loss: 12.203877449035645
2025-12-09 12:53:44.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 5.999999999999999e-06 Training loss: 12.191946983337402
2025-12-09 12:53:44.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 8.999999999999999e-06 Training loss: 12.120243072509766
2025-12-09 12:53:45.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 1.1999999999999999e-05 Training loss: 12.237682342529297
2025-12-09 12:53:45.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 1.4999999999999999e-05 Training loss: 12.169525146484375
2025-12-09 12:53:45.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 1.7999999999999997e-05 Training loss: 12.21381950378418
2025-12-09 12:53:46.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 2.1e-05 Training loss: 12.136531829833984
2025-12-09 12:53:46.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 2.3999999999999997e-05 Training loss: 12.173645973205566
2025-12-09 12:53:46.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 2.6999999999999996e-05 Training loss: 12.227005958557129
2025-12-09 12:53:47.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 2.9999999999999997e-05 Training loss: 12.248133659362793
2025-12-09 12:53:47.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 3.2999999999999996e-05 Training loss: 12.178958892822266
2025-12-09 12:53:48.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 3.5999999999999994e-05 Training loss: 12.216499328613281
2025-12-09 12:53:48.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 3.9e-05 Training loss: 12.20379638671875
2025-12-09 12:53:48.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 4.2e-05 Training loss: 12.182133674621582
2025-12-09 12:53:49.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 4.4999999999999996e-05 Training loss: 12.173523902893066
2025-12-09 12:53:49.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 4.7999999999999994e-05 Training loss: 12.212797164916992
2025-12-09 12:53:49.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 5.1e-05 Training loss: 12.161209106445312
2025-12-09 12:53:50.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 5.399999999999999e-05 Training loss: 12.255350112915039
2025-12-09 12:53:50.623 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 5.6999999999999996e-05 Training loss: 12.266639709472656
2025-12-09 12:53:50.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 5.9999999999999995e-05 Training loss: 12.12193489074707
2025-12-09 12:53:51.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 6.299999999999999e-05 Training loss: 12.137989044189453
2025-12-09 12:53:51.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 6.599999999999999e-05 Training loss: 12.195158004760742
2025-12-09 12:53:52.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 6.9e-05 Training loss: 12.150286674499512
2025-12-09 12:53:52.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 7.199999999999999e-05 Training loss: 12.177170753479004
2025-12-09 12:53:52.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 7.5e-05 Training loss: 12.124739646911621
2025-12-09 12:53:53.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 7.8e-05 Training loss: 12.147971153259277
2025-12-09 12:53:53.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 8.1e-05 Training loss: 12.183771133422852
2025-12-09 12:53:53.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 8.4e-05 Training loss: 12.139851570129395
2025-12-09 12:53:54.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 8.699999999999999e-05 Training loss: 12.124486923217773
2025-12-09 12:53:54.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 8.999999999999999e-05 Training loss: 12.168231964111328
2025-12-09 12:53:55.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 9.3e-05 Training loss: 12.168315887451172
2025-12-09 12:53:55.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 9.599999999999999e-05 Training loss: 12.111981391906738
2025-12-09 12:53:55.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 9.9e-05 Training loss: 12.11130428314209
2025-12-09 12:53:56.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.000102 Training loss: 12.182177543640137
2025-12-09 12:53:56.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00010499999999999999 Training loss: 12.096768379211426
2025-12-09 12:53:56.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00010799999999999998 Training loss: 12.045478820800781
2025-12-09 12:53:57.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00011099999999999999 Training loss: 12.11401081085205
2025-12-09 12:53:57.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00011399999999999999 Training loss: 12.106844902038574
2025-12-09 12:53:58.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.000117 Training loss: 12.083673477172852
2025-12-09 12:53:58.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.00011999999999999999 Training loss: 12.095328330993652
2025-12-09 12:53:58.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00012299999999999998 Training loss: 12.057110786437988
2025-12-09 12:53:59.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00012599999999999997 Training loss: 12.0422945022583
2025-12-09 12:53:59.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.000129 Training loss: 12.040175437927246
2025-12-09 12:53:59.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00013199999999999998 Training loss: 12.014174461364746
2025-12-09 12:54:00.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.000135 Training loss: 12.033540725708008
2025-12-09 12:54:00.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.000138 Training loss: 12.046425819396973
2025-12-09 12:54:01.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00014099999999999998 Training loss: 11.996696472167969
2025-12-09 12:54:01.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00014399999999999998 Training loss: 12.042367935180664
2025-12-09 12:54:01.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.000147 Training loss: 11.950074195861816
2025-12-09 12:54:02.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.00015 Training loss: 11.988748550415039
2025-12-09 12:54:02.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00015299999999999998 Training loss: 11.980616569519043
2025-12-09 12:54:02.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.000156 Training loss: 12.026400566101074
2025-12-09 12:54:03.295 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.000159 Training loss: 11.98784065246582
2025-12-09 12:54:03.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.000162 Training loss: 11.955266952514648
2025-12-09 12:54:04.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.000165 Training loss: 11.91154670715332
2025-12-09 12:54:04.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.000168 Training loss: 12.019571304321289
2025-12-09 12:54:04.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00017099999999999998 Training loss: 12.011927604675293
2025-12-09 12:54:05.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00017399999999999997 Training loss: 11.887373924255371
2025-12-09 12:54:05.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00017699999999999997 Training loss: 11.82070541381836
2025-12-09 12:54:05.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.00017999999999999998 Training loss: 11.820520401000977
2025-12-09 12:54:06.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00018299999999999998 Training loss: 11.801372528076172
2025-12-09 12:54:06.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.000186 Training loss: 11.889659881591797
2025-12-09 12:54:07.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00018899999999999999 Training loss: 11.804450035095215
2025-12-09 12:54:07.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00019199999999999998 Training loss: 11.867417335510254
2025-12-09 12:54:07.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.000195 Training loss: 11.780656814575195
2025-12-09 12:54:08.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.000198 Training loss: 11.580550193786621
2025-12-09 12:54:08.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.000201 Training loss: 11.803400993347168
2025-12-09 12:54:08.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.000204 Training loss: 11.63109016418457
2025-12-09 12:54:09.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00020699999999999996 Training loss: 11.78532886505127
2025-12-09 12:54:09.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.00020999999999999998 Training loss: 11.728583335876465
2025-12-09 12:54:10.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00021299999999999997 Training loss: 11.661027908325195
2025-12-09 12:54:10.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.00021599999999999996 Training loss: 11.751740455627441
2025-12-09 12:54:10.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00021899999999999998 Training loss: 11.506093978881836
2025-12-09 12:54:11.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00022199999999999998 Training loss: 11.647452354431152
2025-12-09 12:54:11.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.000225 Training loss: 11.613743782043457
2025-12-09 12:54:11.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00022799999999999999 Training loss: 11.73453140258789
2025-12-09 12:54:12.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.00023099999999999998 Training loss: 11.476470947265625
2025-12-09 12:54:12.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.000234 Training loss: 11.784992218017578
2025-12-09 12:54:12.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.000237 Training loss: 11.302520751953125
2025-12-09 12:54:13.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.00023999999999999998 Training loss: 11.42880630493164
2025-12-09 12:54:13.739 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.000243 Training loss: 11.326547622680664
2025-12-09 12:54:14.113 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00024599999999999996 Training loss: 11.255294799804688
2025-12-09 12:54:14.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.000249 Training loss: 11.239041328430176
2025-12-09 12:54:14.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00025199999999999995 Training loss: 11.223502159118652
2025-12-09 12:54:15.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00025499999999999996 Training loss: 11.151359558105469
2025-12-09 12:54:15.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.000258 Training loss: 11.159197807312012
2025-12-09 12:54:15.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.000261 Training loss: 11.091970443725586
2025-12-09 12:54:16.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00026399999999999997 Training loss: 10.967589378356934
2025-12-09 12:54:16.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.000267 Training loss: 10.885013580322266
2025-12-09 12:54:17.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.00027 Training loss: 10.869625091552734
2025-12-09 12:54:17.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00027299999999999997 Training loss: 10.823784828186035
2025-12-09 12:54:17.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.000276 Training loss: 10.650283813476562
2025-12-09 12:54:18.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.000279 Training loss: 10.938807487487793
2025-12-09 12:54:18.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00028199999999999997 Training loss: 10.703385353088379
2025-12-09 12:54:18.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.000285 Training loss: 10.443281173706055
2025-12-09 12:54:19.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00028799999999999995 Training loss: 11.064423561096191
2025-12-09 12:54:19.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.00029099999999999997 Training loss: 10.65998649597168
2025-12-09 12:54:20.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.000294 Training loss: 10.609807014465332
2025-12-09 12:54:20.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00029699999999999996 Training loss: 10.61587142944336
2025-12-09 12:54:20.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0003 Training loss: 10.869775772094727
2025-12-09 12:54:21.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.00029999997089396425 Training loss: 10.365324020385742
2025-12-09 12:54:21.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.00029999988357586825 Training loss: 10.497885704040527
2025-12-09 12:54:21.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.000299999738045746 Training loss: 10.383729934692383
2025-12-09 12:54:22.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0002999995343036539 Training loss: 10.799601554870605
2025-12-09 12:54:22.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.00029999927234967104 Training loss: 11.08602237701416
2025-12-09 12:54:23.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.00029999895218389905 Training loss: 10.65307331085205
2025-12-09 12:54:23.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0002999985738064622 Training loss: 10.39223861694336
2025-12-09 12:54:23.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.00029999813721750737 Training loss: 10.444615364074707
2025-12-09 12:54:24.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.00029999764241720394 Training loss: 10.457887649536133
2025-12-09 12:54:24.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.0002999970894057439 Training loss: 10.492886543273926
2025-12-09 12:54:24.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.00029999647818334195 Training loss: 10.306450843811035
2025-12-09 12:54:25.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0002999958087502352 Training loss: 10.295165061950684
2025-12-09 12:54:25.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.00029999508110668355 Training loss: 10.299060821533203
2025-12-09 12:54:26.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0002999942952529693 Training loss: 10.415765762329102
2025-12-09 12:54:26.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.00029999345118939745 Training loss: 10.070266723632812
2025-12-09 12:54:26.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0002999925489162956 Training loss: 10.279041290283203
2025-12-09 12:54:27.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.00029999158843401386 Training loss: 10.264524459838867
2025-12-09 12:54:27.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.000299990569742925 Training loss: 10.459352493286133
2025-12-09 12:54:27.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0002999894928434243 Training loss: 10.345303535461426
2025-12-09 12:54:28.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.00029998835773592975 Training loss: 10.643854141235352
2025-12-09 12:54:28.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.00029998716442088184 Training loss: 9.987205505371094
2025-12-09 12:54:29.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.0002999859128987437 Training loss: 10.181700706481934
2025-12-09 12:54:29.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.00029998460317000097 Training loss: 10.088730812072754
2025-12-09 12:54:29.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.00029998323523516195 Training loss: 10.06936264038086
2025-12-09 12:54:30.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0002999818090947575 Training loss: 9.919434547424316
2025-12-09 12:54:30.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.00029998032474934106 Training loss: 10.162863731384277
2025-12-09 12:54:30.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.0002999787821994887 Training loss: 9.946142196655273
2025-12-09 12:54:31.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.00029997718144579913 Training loss: 10.2642183303833
2025-12-09 12:54:31.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0002999755224888935 Training loss: 10.157005310058594
2025-12-09 12:54:32.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.00029997380532941555 Training loss: 10.28645133972168
2025-12-09 12:54:32.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.00029997202996803177 Training loss: 10.008413314819336
2025-12-09 12:54:32.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.0002999701964054312 Training loss: 10.215729713439941
2025-12-09 12:54:33.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0002999683046423252 Training loss: 10.282170295715332
2025-12-09 12:54:33.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.0002999663546794481 Training loss: 10.469746589660645
2025-12-09 12:54:33.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.00029996434651755657 Training loss: 10.454437255859375
2025-12-09 12:54:34.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.00029996228015743 Training loss: 10.460734367370605
2025-12-09 12:54:34.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0002999601555998703 Training loss: 9.90141773223877
2025-12-09 12:54:34.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.0002999579728457019 Training loss: 9.976826667785645
2025-12-09 12:54:35.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.0002999557318957719 Training loss: 10.374045372009277
2025-12-09 12:54:35.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.00029995343275095003 Training loss: 10.068692207336426
2025-12-09 12:54:36.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.00029995107541212843 Training loss: 9.908307075500488
2025-12-09 12:54:36.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.00029994865988022205 Training loss: 9.801227569580078
2025-12-09 12:54:36.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0002999461861561683 Training loss: 9.921012878417969
2025-12-09 12:54:37.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.0002999436542409271 Training loss: 10.405194282531738
2025-12-09 12:54:37.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0002999410641354812 Training loss: 9.794981002807617
2025-12-09 12:54:37.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.00029993841584083553 Training loss: 9.849342346191406
2025-12-09 12:54:38.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.00029993570935801805 Training loss: 10.263554573059082
2025-12-09 12:54:38.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.000299932944688079 Training loss: 9.743358612060547
2025-12-09 12:54:39.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.00029993012183209135 Training loss: 10.04559326171875
2025-12-09 12:54:39.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0002999272407911505 Training loss: 10.03580093383789
2025-12-09 12:54:39.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.00029992430156637454 Training loss: 10.00192928314209
2025-12-09 12:54:40.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.00029992130415890426 Training loss: 9.77278995513916
2025-12-09 12:54:40.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.00029991824856990276 Training loss: 10.072216033935547
2025-12-09 12:54:40.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.0002999151348005559 Training loss: 9.466947555541992
2025-12-09 12:54:41.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.0002999119628520721 Training loss: 9.843805313110352
2025-12-09 12:54:41.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.00029990873272568226 Training loss: 9.865580558776855
2025-12-09 12:54:42.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.00029990544442263996 Training loss: 10.221102714538574
2025-12-09 12:54:42.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0002999020979442214 Training loss: 9.741836547851562
2025-12-09 12:54:42.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.0002998986932917252 Training loss: 9.891409873962402
2025-12-09 12:54:43.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.00029989523046647257 Training loss: 9.882384300231934
2025-12-09 12:54:43.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.00029989170946980755 Training loss: 9.904751777648926
2025-12-09 12:54:43.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.00029988813030309644 Training loss: 9.982861518859863
2025-12-09 12:54:44.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.0002998844929677283 Training loss: 10.038582801818848
2025-12-09 12:54:44.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.00029988079746511465 Training loss: 10.689109802246094
2025-12-09 12:54:45.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.00029987704379668973 Training loss: 9.894947052001953
2025-12-09 12:54:45.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.0002998732319639102 Training loss: 9.716365814208984
2025-12-09 12:54:45.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.00029986936196825536 Training loss: 10.026769638061523
2025-12-09 12:54:46.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0002998654338112271 Training loss: 10.057333946228027
2025-12-09 12:54:46.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.00029986144749434985 Training loss: 9.74780559539795
2025-12-09 12:54:46.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.0002998574030191706 Training loss: 9.833230972290039
2025-12-09 12:54:47.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.000299853300387259 Training loss: 9.817741394042969
2025-12-09 12:54:47.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.00029984913960020714 Training loss: 10.075234413146973
2025-12-09 12:54:48.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.00029984492065962976 Training loss: 9.659953117370605
2025-12-09 12:54:48.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.00029984064356716414 Training loss: 9.959181785583496
2025-12-09 12:54:48.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.0002998363083244701 Training loss: 10.499865531921387
2025-12-09 12:54:49.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.00029983191493323017 Training loss: 9.521554946899414
2025-12-09 12:54:49.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0002998274633951493 Training loss: 9.720048904418945
2025-12-09 12:54:49.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.00029982295371195494 Training loss: 9.770681381225586
2025-12-09 12:54:50.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.00029981838588539735 Training loss: 9.644274711608887
2025-12-09 12:54:50.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.00029981375991724915 Training loss: 9.706631660461426
2025-12-09 12:54:50.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0002998090758093056 Training loss: 9.807294845581055
2025-12-09 12:54:51.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.00029980433356338447 Training loss: 9.671335220336914
2025-12-09 12:54:51.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.0002997995331813262 Training loss: 9.656155586242676
2025-12-09 12:54:52.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.00029979467466499367 Training loss: 9.573551177978516
2025-12-09 12:54:52.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.00029978975801627243 Training loss: 9.899996757507324
2025-12-09 12:54:52.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0002997847832370704 Training loss: 9.636026382446289
2025-12-09 12:54:53.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.0002997797503293184 Training loss: 9.946096420288086
2025-12-09 12:54:53.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.00029977465929496947 Training loss: 10.012309074401855
2025-12-09 12:54:53.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0002997695101359994 Training loss: 9.570425987243652
2025-12-09 12:54:54.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.0002997643028544064 Training loss: 9.519295692443848
2025-12-09 12:54:54.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0002997590374522114 Training loss: 9.60371208190918
2025-12-09 12:54:55.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0002997537139314577 Training loss: 9.574197769165039
2025-12-09 12:54:55.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.0002997483322942114 Training loss: 9.505603790283203
2025-12-09 12:54:55.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.0002997428925425609 Training loss: 9.809460639953613
2025-12-09 12:54:56.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.0002997373946786173 Training loss: 9.683867454528809
2025-12-09 12:54:56.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.00029973183870451417 Training loss: 9.710411071777344
2025-12-09 12:54:56.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0002997262246224077 Training loss: 9.725656509399414
2025-12-09 12:54:57.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.00029972055243447665 Training loss: 9.83613395690918
2025-12-09 12:54:57.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.00029971482214292223 Training loss: 9.710294723510742
2025-12-09 12:54:58.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.00029970903374996826 Training loss: 9.759239196777344
2025-12-09 12:54:58.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0002997031872578611 Training loss: 9.389281272888184
2025-12-09 12:54:58.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.00029969728266886973 Training loss: 9.617593765258789
2025-12-09 12:54:59.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.00029969131998528554 Training loss: 9.326614379882812
2025-12-09 12:54:59.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0002996852992094225 Training loss: 9.400396347045898
2025-12-09 12:54:59.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.00029967922034361723 Training loss: 9.542825698852539
2025-12-09 12:55:00.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0002996730833902287 Training loss: 9.540346145629883
2025-12-09 12:55:00.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.00029966688835163875 Training loss: 9.762099266052246
2025-12-09 12:55:01.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.00029966063523025136 Training loss: 9.478100776672363
2025-12-09 12:55:01.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.00029965432402849333 Training loss: 9.395551681518555
2025-12-09 12:55:01.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0002996479547488139 Training loss: 9.478132247924805
2025-12-09 12:55:02.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.0002996415273936849 Training loss: 9.523140907287598
2025-12-09 12:55:02.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.00029963504196560056 Training loss: 9.769227027893066
2025-12-09 12:55:02.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.00029962849846707786 Training loss: 9.206005096435547
2025-12-09 12:55:03.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.0002996218969006561 Training loss: 9.492788314819336
2025-12-09 12:55:03.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.00029961523726889733 Training loss: 9.445049285888672
2025-12-09 12:55:04.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.00029960851957438594 Training loss: 9.643376350402832
2025-12-09 12:55:04.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.000299601743819729 Training loss: 9.716588973999023
2025-12-09 12:55:04.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.00029959491000755594 Training loss: 9.622349739074707
2025-12-09 12:55:05.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.00029958801814051897 Training loss: 9.663907051086426
2025-12-09 12:55:05.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0002995810682212926 Training loss: 9.946918487548828
2025-12-09 12:55:05.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.0002995740602525739 Training loss: 9.718887329101562
2025-12-09 12:55:06.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0002995669942370827 Training loss: 9.646048545837402
2025-12-09 12:55:06.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.000299559870177561 Training loss: 9.694482803344727
2025-12-09 12:55:07.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0002995526880767737 Training loss: 9.539823532104492
2025-12-09 12:55:07.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.00029954544793750785 Training loss: 9.50555419921875
2025-12-09 12:55:07.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.00029953814976257335 Training loss: 9.455615997314453
2025-12-09 12:55:08.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.0002995307935548024 Training loss: 9.34410285949707
2025-12-09 12:55:08.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.0002995233793170498 Training loss: 9.332966804504395
2025-12-09 12:55:08.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.00029951590705219283 Training loss: 9.322219848632812
2025-12-09 12:55:09.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0002995083767631314 Training loss: 9.24411392211914
2025-12-09 12:55:09.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0002995007884527879 Training loss: 9.693151473999023
2025-12-09 12:55:09.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.00029949314212410715 Training loss: 9.551342964172363
2025-12-09 12:55:10.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.00029948543778005656 Training loss: 9.30289077758789
2025-12-09 12:55:10.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.00029947767542362597 Training loss: 9.459869384765625
2025-12-09 12:55:11.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.0002994698550578279 Training loss: 9.850378036499023
2025-12-09 12:55:11.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0002994619766856972 Training loss: 10.126166343688965
2025-12-09 12:55:11.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.00029945404031029134 Training loss: 9.499249458312988
2025-12-09 12:55:12.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.00029944604593469033 Training loss: 9.712681770324707
2025-12-09 12:55:12.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.00029943799356199656 Training loss: 9.400822639465332
2025-12-09 12:55:12.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.00029942988319533504 Training loss: 9.268694877624512
2025-12-09 12:55:13.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.0002994217148378532 Training loss: 9.456790924072266
2025-12-09 12:55:13.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.00029941348849272105 Training loss: 10.06268310546875
2025-12-09 12:55:14.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.0002994052041631311 Training loss: 9.3966064453125
2025-12-09 12:55:14.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.0002993968618522982 Training loss: 9.702396392822266
2025-12-09 12:55:14.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.0002993884615634601 Training loss: 9.595876693725586
2025-12-09 12:55:15.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.00029938000329987645 Training loss: 9.474395751953125
2025-12-09 12:55:15.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.00029937148706483003 Training loss: 9.241410255432129
2025-12-09 12:55:15.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.00029936291286162577 Training loss: 9.689478874206543
2025-12-09 12:55:16.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.000299354280693591 Training loss: 9.503055572509766
2025-12-09 12:55:16.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.0002993455905640758 Training loss: 9.350439071655273
2025-12-09 12:55:17.064 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0002993368424764526 Training loss: 9.530940055847168
2025-12-09 12:55:17.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.0002993280364341165 Training loss: 9.29137897491455
2025-12-09 12:55:17.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.00029931917244048473 Training loss: 10.15758228302002
2025-12-09 12:55:18.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.0002993102504989974 Training loss: 9.476675987243652
2025-12-09 12:55:18.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.00029930127061311685 Training loss: 9.928210258483887
2025-12-09 12:55:18.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.0002992922327863281 Training loss: 9.40673542022705
2025-12-09 12:55:19.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.00029928313702213844 Training loss: 9.243611335754395
2025-12-09 12:55:19.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.00029927398332407784 Training loss: 9.67699909210205
2025-12-09 12:55:20.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.00029926477169569865 Training loss: 9.561589241027832
2025-12-09 12:55:20.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.00029925550214057565 Training loss: 10.006404876708984
2025-12-09 12:55:20.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.00029924617466230624 Training loss: 9.518387794494629
2025-12-09 12:55:21.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.00029923678926451034 Training loss: 9.282245635986328
2025-12-09 12:55:21.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00029922734595083005 Training loss: 9.44579792022705
2025-12-09 12:55:21.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0002992178447249302 Training loss: 9.423521995544434
2025-12-09 12:55:22.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.00029920828559049805 Training loss: 9.666796684265137
2025-12-09 12:55:22.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.0002991986685512433 Training loss: 9.435577392578125
2025-12-09 12:55:23.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0002991889936108982 Training loss: 9.372468948364258
2025-12-09 12:55:23.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.0002991792607732173 Training loss: 9.665238380432129
2025-12-09 12:55:23.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.0002991694700419778 Training loss: 9.255369186401367
2025-12-09 12:55:24.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.00029915962142097925 Training loss: 9.31079387664795
2025-12-09 12:55:24.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.00029914971491404373 Training loss: 9.18508529663086
2025-12-09 12:55:24.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.00029913975052501575 Training loss: 9.444372177124023
2025-12-09 12:55:25.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.0002991297282577623 Training loss: 9.576423645019531
2025-12-09 12:55:25.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.00029911964811617285 Training loss: 9.31807804107666
2025-12-09 12:55:26.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.00029910951010415926 Training loss: 9.634868621826172
2025-12-09 12:55:26.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.0002990993142256559 Training loss: 9.385967254638672
2025-12-09 12:55:26.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0002990890604846196 Training loss: 9.23659896850586
2025-12-09 12:55:27.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.00029907874888502966 Training loss: 9.315237998962402
2025-12-09 12:55:27.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.00029906837943088785 Training loss: 10.020289421081543
2025-12-09 12:55:27.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.00029905795212621823 Training loss: 9.52686882019043
2025-12-09 12:55:28.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.00029904746697506754 Training loss: 9.682336807250977
2025-12-09 12:55:28.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.0002990369239815048 Training loss: 9.427224159240723
2025-12-09 12:55:28.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.00029902632314962157 Training loss: 9.122123718261719
2025-12-09 12:55:29.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0002990156644835318 Training loss: 9.399689674377441
2025-12-09 12:55:29.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.00029900494798737194 Training loss: 9.548599243164062
2025-12-09 12:55:30.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.00029899417366530085 Training loss: 10.00610065460205
2025-12-09 12:55:30.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.00029898334152149984 Training loss: 9.302172660827637
2025-12-09 12:55:30.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0002989724515601726 Training loss: 9.895065307617188
2025-12-09 12:55:31.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0002989615037855454 Training loss: 9.217927932739258
2025-12-09 12:55:31.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0002989504982018668 Training loss: 9.219483375549316
2025-12-09 12:55:31.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.00029893943481340785 Training loss: 9.467292785644531
2025-12-09 12:55:32.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.000298928313624462 Training loss: 9.241996765136719
2025-12-09 12:55:32.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.0002989171346393453 Training loss: 9.256806373596191
2025-12-09 12:55:33.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.00029890589786239595 Training loss: 9.514920234680176
2025-12-09 12:55:33.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0002988946032979748 Training loss: 9.147130012512207
2025-12-09 12:55:33.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.000298883250950465 Training loss: 10.179108619689941
2025-12-09 12:55:34.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.0002988718408242722 Training loss: 9.455885887145996
2025-12-09 12:55:34.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.00029886037292382455 Training loss: 9.328792572021484
2025-12-09 12:55:34.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.00029884884725357236 Training loss: 9.405986785888672
2025-12-09 12:55:35.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0002988372638179886 Training loss: 9.508146286010742
2025-12-09 12:55:35.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0002988256226215685 Training loss: 9.200616836547852
2025-12-09 12:55:36.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.0002988139236688299 Training loss: 9.536526679992676
2025-12-09 12:55:36.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.00029880216696431285 Training loss: 9.270835876464844
2025-12-09 12:55:36.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.0002987903525125799 Training loss: 9.203550338745117
2025-12-09 12:55:37.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.000298778480318216 Training loss: 9.56382942199707
2025-12-09 12:55:37.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0002987665503858286 Training loss: 9.776069641113281
2025-12-09 12:55:37.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.0002987545627200474 Training loss: 9.252485275268555
2025-12-09 12:55:38.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0002987425173255246 Training loss: 9.397527694702148
2025-12-09 12:55:38.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0002987304142069348 Training loss: 9.323119163513184
2025-12-09 12:55:39.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.0002987182533689749 Training loss: 9.379033088684082
2025-12-09 12:55:39.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0002987060348163644 Training loss: 9.379796028137207
2025-12-09 12:55:39.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.000298693758553845 Training loss: 8.833736419677734
2025-12-09 12:55:40.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.00029868142458618096 Training loss: 9.455320358276367
2025-12-09 12:55:40.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0002986690329181587 Training loss: 9.777547836303711
2025-12-09 12:55:40.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.00029865658355458736 Training loss: 9.509038925170898
2025-12-09 12:55:41.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0002986440765002982 Training loss: 9.274248123168945
2025-12-09 12:55:41.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.000298631511760145 Training loss: 8.982203483581543
2025-12-09 12:55:42.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.0002986188893390038 Training loss: 9.25153636932373
2025-12-09 12:55:42.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.0002986062092417733 Training loss: 9.34914493560791
2025-12-09 12:55:42.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.00029859347147337417 Training loss: 9.30716323852539
2025-12-09 12:55:43.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.0002985806760387499 Training loss: 9.395532608032227
2025-12-09 12:55:43.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.00029856782294286594 Training loss: 8.718557357788086
2025-12-09 12:55:43.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.00029855491219071053 Training loss: 9.373625755310059
2025-12-09 12:55:44.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.000298541943787294 Training loss: 9.365925788879395
2025-12-09 12:55:44.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.00029852891773764906 Training loss: 9.375944137573242
2025-12-09 12:55:44.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.00029851583404683096 Training loss: 9.321771621704102
2025-12-09 12:55:45.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0002985026927199172 Training loss: 9.41252613067627
2025-12-09 12:55:45.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.00029848949376200766 Training loss: 9.366135597229004
2025-12-09 12:55:46.113 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.0002984762371782246 Training loss: 9.557685852050781
2025-12-09 12:55:46.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.00029846292297371264 Training loss: 9.203336715698242
2025-12-09 12:55:46.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.0002984495511536388 Training loss: 9.29262638092041
2025-12-09 12:55:47.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.0002984361217231923 Training loss: 9.261770248413086
2025-12-09 12:55:47.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.00029842263468758505 Training loss: 9.190497398376465
2025-12-09 12:55:47.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.0002984090900520509 Training loss: 9.240849494934082
2025-12-09 12:55:48.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.00029839548782184636 Training loss: 9.135854721069336
2025-12-09 12:55:48.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.00029838182800225017 Training loss: 9.524638175964355
2025-12-09 12:55:49.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.00029836811059856354 Training loss: 9.302785873413086
2025-12-09 12:55:49.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.00029835433561610974 Training loss: 9.433793067932129
2025-12-09 12:55:49.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.0002983405030602346 Training loss: 9.109074592590332
2025-12-09 12:55:50.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.00029832661293630644 Training loss: 9.250844955444336
2025-12-09 12:55:50.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.00029831266524971557 Training loss: 9.278060913085938
2025-12-09 12:55:50.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.0002982986600058749 Training loss: 9.404057502746582
2025-12-09 12:55:51.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.0002982845972102196 Training loss: 9.373224258422852
2025-12-09 12:55:51.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.0002982704768682071 Training loss: 9.511934280395508
2025-12-09 12:55:52.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.00029825629898531724 Training loss: 9.044544219970703
2025-12-09 12:55:52.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.0002982420635670523 Training loss: 9.623822212219238
2025-12-09 12:55:52.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.00029822777061893653 Training loss: 9.219868659973145
2025-12-09 12:55:53.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.00029821342014651694 Training loss: 9.127206802368164
2025-12-09 12:55:53.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0002981990121553627 Training loss: 9.257619857788086
2025-12-09 12:55:53.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.0002981845466510651 Training loss: 9.20839786529541
2025-12-09 12:55:54.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.00029817002363923803 Training loss: 9.188211441040039
2025-12-09 12:55:54.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.00029815544312551754 Training loss: 9.233882904052734
2025-12-09 12:55:55.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.00029814080511556207 Training loss: 9.16540241241455
2025-12-09 12:55:55.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.00029812610961505234 Training loss: 9.302229881286621
2025-12-09 12:55:55.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.00029811135662969143 Training loss: 9.381011009216309
2025-12-09 12:55:56.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.00029809654616520456 Training loss: 9.223825454711914
2025-12-09 12:55:56.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.00029808167822733953 Training loss: 9.117572784423828
2025-12-09 12:55:56.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.0002980667528218662 Training loss: 9.28296184539795
2025-12-09 12:55:57.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0002980517699545769 Training loss: 9.393363952636719
2025-12-09 12:55:57.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.0002980367296312861 Training loss: 9.39069652557373
2025-12-09 12:55:58.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.00029802163185783074 Training loss: 9.256458282470703
2025-12-09 12:55:58.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.00029800647664006993 Training loss: 9.360499382019043
2025-12-09 12:55:58.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.0002979912639838851 Training loss: 9.291915893554688
2025-12-09 12:55:59.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.00029797599389518 Training loss: 9.371424674987793
2025-12-09 12:55:59.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.0002979606663798807 Training loss: 9.111937522888184
2025-12-09 12:55:59.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.0002979452814439354 Training loss: 9.230886459350586
2025-12-09 12:56:00.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.00029792983909331485 Training loss: 9.795951843261719
2025-12-09 12:56:00.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.0002979143393340117 Training loss: 9.052502632141113
2025-12-09 12:56:01.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.00029789878217204133 Training loss: 9.426223754882812
2025-12-09 12:56:01.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.00029788316761344106 Training loss: 9.372576713562012
2025-12-09 12:56:01.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.00029786749566427064 Training loss: 9.234742164611816
2025-12-09 12:56:02.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.000297851766330612 Training loss: 9.361167907714844
2025-12-09 12:56:02.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.00029783597961856946 Training loss: 9.048430442810059
2025-12-09 12:56:02.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.00029782013553426937 Training loss: 9.898022651672363
2025-12-09 12:56:03.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.00029780423408386073 Training loss: 9.338711738586426
2025-12-09 12:56:03.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.00029778827527351443 Training loss: 9.228965759277344
2025-12-09 12:56:03.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.0002977722591094238 Training loss: 9.191498756408691
2025-12-09 12:56:04.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.00029775618559780447 Training loss: 9.145196914672852
2025-12-09 12:56:04.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.00029774005474489417 Training loss: 9.311731338500977
2025-12-09 12:56:05.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.00029772386655695305 Training loss: 9.016215324401855
2025-12-09 12:56:05.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.0002977076210402633 Training loss: 9.696050643920898
2025-12-09 12:56:05.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.00029769131820112966 Training loss: 9.084351539611816
2025-12-09 12:56:06.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.00029767495804587885 Training loss: 9.044660568237305
2025-12-09 12:56:06.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.0002976585405808599 Training loss: 9.277303695678711
2025-12-09 12:56:06.982 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0002976420658124441 Training loss: 9.42293643951416
2025-12-09 12:56:07.354 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.0002976255337470251 Training loss: 9.26070785522461
2025-12-09 12:56:07.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.00029760894439101855 Training loss: 9.177753448486328
2025-12-09 12:56:08.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.0002975922977508625 Training loss: 9.171820640563965
2025-12-09 12:56:08.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0002975755938330172 Training loss: 9.166797637939453
2025-12-09 12:56:08.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.00029755883264396513 Training loss: 9.88825798034668
2025-12-09 12:56:09.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.00029754201419021094 Training loss: 9.2849702835083
2025-12-09 12:56:09.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.0002975251384782816 Training loss: 8.903902053833008
2025-12-09 12:56:09.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.00029750820551472615 Training loss: 9.00967788696289
2025-12-09 12:56:10.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.00029749121530611597 Training loss: 9.207409858703613
2025-12-09 12:56:10.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.0002974741678590447 Training loss: 9.776676177978516
2025-12-09 12:56:11.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.00029745706318012806 Training loss: 9.27531623840332
2025-12-09 12:56:11.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.00029743990127600406 Training loss: 9.20093822479248
2025-12-09 12:56:11.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.0002974226821533329 Training loss: 9.30087947845459
2025-12-09 12:56:12.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.000297405405818797 Training loss: 9.555909156799316
2025-12-09 12:56:12.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0002973880722791009 Training loss: 9.21084976196289
2025-12-09 12:56:12.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.0002973706815409715 Training loss: 9.965738296508789
2025-12-09 12:56:13.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.0002973532336111577 Training loss: 9.172026634216309
2025-12-09 12:56:13.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.00029733572849643085 Training loss: 9.29140853881836
2025-12-09 12:56:14.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.00029731816620358424 Training loss: 9.219646453857422
2025-12-09 12:56:14.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.0002973005467394334 Training loss: 9.013885498046875
2025-12-09 12:56:14.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.00029728287011081625 Training loss: 9.378066062927246
2025-12-09 12:56:15.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.0002972651363245927 Training loss: 9.229005813598633
2025-12-09 12:56:15.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.00029724734538764475 Training loss: 8.925328254699707
2025-12-09 12:56:15.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.0002972294973068768 Training loss: 9.074576377868652
2025-12-09 12:56:16.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.00029721159208921546 Training loss: 9.256260871887207
2025-12-09 12:56:16.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.00029719362974160924 Training loss: 8.908428192138672
2025-12-09 12:56:17.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.000297175610271029 Training loss: 9.10437297821045
2025-12-09 12:56:17.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.00029715753368446786 Training loss: 9.242813110351562
2025-12-09 12:56:17.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.00029713939998894087 Training loss: 9.339975357055664
2025-12-09 12:56:18.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.0002971212091914854 Training loss: 9.225467681884766
2025-12-09 12:56:18.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0002971029612991609 Training loss: 9.560355186462402
2025-12-09 12:56:18.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.0002970846563190491 Training loss: 9.00498104095459
2025-12-09 12:56:19.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.00029706629425825374 Training loss: 9.211400985717773
2025-12-09 12:56:19.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.00029704787512390085 Training loss: 9.286423683166504
2025-12-09 12:56:20.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.0002970293989231385 Training loss: 9.624122619628906
2025-12-09 12:56:20.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.0002970108656631369 Training loss: 9.143610954284668
2025-12-09 12:56:20.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.0002969922753510885 Training loss: 9.211831092834473
2025-12-09 12:56:21.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.00029697362799420776 Training loss: 9.109807014465332
2025-12-09 12:56:21.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.0002969549235997315 Training loss: 9.142949104309082
2025-12-09 12:56:21.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.0002969361621749184 Training loss: 9.063187599182129
2025-12-09 12:56:22.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.00029691734372704943 Training loss: 9.130542755126953
2025-12-09 12:56:22.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.0002968984682634277 Training loss: 9.084634780883789
2025-12-09 12:56:23.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.0002968795357913784 Training loss: 9.313718795776367
2025-12-09 12:56:23.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.0002968605463182488 Training loss: 9.320759773254395
2025-12-09 12:56:23.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0002968414998514085 Training loss: 8.798468589782715
2025-12-09 12:56:24.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0002968223963982488 Training loss: 9.325185775756836
2025-12-09 12:56:24.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.00029680323596618355 Training loss: 9.878939628601074
2025-12-09 12:56:24.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.00029678401856264857 Training loss: 9.10901165008545
2025-12-09 12:56:25.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.0002967647441951017 Training loss: 9.428182601928711
2025-12-09 12:56:25.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0002967454128710229 Training loss: 8.828875541687012
2025-12-09 12:56:25.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.00029672602459791434 Training loss: 9.285505294799805
2025-12-09 12:56:26.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.0002967065793833002 Training loss: 9.226536750793457
2025-12-09 12:56:26.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.0002966870772347269 Training loss: 9.051285743713379
2025-12-09 12:56:27.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.0002966675181597627 Training loss: 9.60312557220459
2025-12-09 12:56:27.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.0002966479021659981 Training loss: 9.125343322753906
2025-12-09 12:56:27.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.00029662822926104576 Training loss: 9.17833137512207
2025-12-09 12:56:28.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.0002966084994525403 Training loss: 9.002692222595215
2025-12-09 12:56:28.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.00029658871274813853 Training loss: 9.396143913269043
2025-12-09 12:56:28.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.00029656886915551924 Training loss: 8.982531547546387
2025-12-09 12:56:29.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.0002965489686823833 Training loss: 9.282485008239746
2025-12-09 12:56:29.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.00029652901133645377 Training loss: 8.957088470458984
2025-12-09 12:56:30.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.0002965089971254757 Training loss: 9.403698921203613
2025-12-09 12:56:30.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.0002964889260572162 Training loss: 9.31277084350586
2025-12-09 12:56:30.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0002964687981394644 Training loss: 9.116092681884766
2025-12-09 12:56:31.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.00029644861338003165 Training loss: 9.083768844604492
2025-12-09 12:56:31.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.0002964283717867512 Training loss: 9.579399108886719
2025-12-09 12:56:31.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.0002964080733674784 Training loss: 9.10669231414795
2025-12-09 12:56:32.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.0002963877181300907 Training loss: 9.07272720336914
2025-12-09 12:56:32.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.00029636730608248766 Training loss: 8.878406524658203
2025-12-09 12:56:33.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.0002963468372325906 Training loss: 9.336051940917969
2025-12-09 12:56:33.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.00029632631158834326 Training loss: 9.014948844909668
2025-12-09 12:56:33.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.00029630572915771117 Training loss: 9.067937850952148
2025-12-09 12:56:34.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.000296285089948682 Training loss: 8.72986125946045
2025-12-09 12:56:34.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.00029626439396926533 Training loss: 9.244791030883789
2025-12-09 12:56:34.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.00029624364122749294 Training loss: 9.114219665527344
2025-12-09 12:56:35.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.0002962228317314186 Training loss: 9.102987289428711
2025-12-09 12:56:35.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.00029620196548911797 Training loss: 9.139708518981934
2025-12-09 12:56:36.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.0002961810425086889 Training loss: 9.295684814453125
2025-12-09 12:56:36.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.00029616006279825126 Training loss: 9.185779571533203
2025-12-09 12:56:36.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.0002961390263659467 Training loss: 9.090341567993164
2025-12-09 12:56:37.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.0002961179332199391 Training loss: 9.203798294067383
2025-12-09 12:56:37.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.00029609678336841444 Training loss: 9.195960998535156
2025-12-09 12:56:37.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.00029607557681958035 Training loss: 9.034750938415527
2025-12-09 12:56:38.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.00029605431358166684 Training loss: 9.205110549926758
2025-12-09 12:56:38.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.00029603299366292565 Training loss: 8.76011848449707
2025-12-09 12:56:39.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.00029601161707163077 Training loss: 9.317877769470215
2025-12-09 12:56:39.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.00029599018381607785 Training loss: 9.066627502441406
2025-12-09 12:56:39.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.0002959686939045848 Training loss: 9.183294296264648
2025-12-09 12:56:40.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.00029594714734549146 Training loss: 9.117441177368164
2025-12-09 12:56:40.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.0002959255441471597 Training loss: 9.178250312805176
2025-12-09 12:56:40.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.0002959038843179731 Training loss: 9.14087200164795
2025-12-09 12:56:41.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.0002958821678663376 Training loss: 9.312933921813965
2025-12-09 12:56:41.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.00029586039480068087 Training loss: 9.039546012878418
2025-12-09 12:56:41.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.0002958385651294525 Training loss: 9.300651550292969
2025-12-09 12:56:42.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.00029581667886112434 Training loss: 9.565918922424316
2025-12-09 12:56:42.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.00029579473600418993 Training loss: 9.113941192626953
2025-12-09 12:56:43.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.0002957727365671649 Training loss: 9.202398300170898
2025-12-09 12:56:43.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.0002957506805585867 Training loss: 9.102546691894531
2025-12-09 12:56:43.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.00029572856798701504 Training loss: 9.370545387268066
2025-12-09 12:56:44.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0002957063988610312 Training loss: 8.890585899353027
2025-12-09 12:56:44.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0002956841731892386 Training loss: 9.192434310913086
2025-12-09 12:56:44.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.0002956618909802627 Training loss: 9.198614120483398
2025-12-09 12:56:45.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.00029563955224275065 Training loss: 9.149543762207031
2025-12-09 12:56:45.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.00029561715698537183 Training loss: 8.978593826293945
2025-12-09 12:56:46.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0002955947052168172 Training loss: 9.122238159179688
2025-12-09 12:56:46.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.0002955721969458001 Training loss: 9.170381546020508
2025-12-09 12:56:46.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.0002955496321810553 Training loss: 9.098953247070312
2025-12-09 12:56:47.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.00029552701093133994 Training loss: 9.19636058807373
2025-12-09 12:56:47.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.00029550433320543284 Training loss: 9.124703407287598
2025-12-09 12:56:47.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.0002954815990121347 Training loss: 9.018383026123047
2025-12-09 12:56:48.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.00029545880836026833 Training loss: 9.027019500732422
2025-12-09 12:56:48.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.0002954359612586782 Training loss: 9.186410903930664
2025-12-09 12:56:49.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.00029541305771623095 Training loss: 9.374932289123535
2025-12-09 12:56:49.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.00029539009774181494 Training loss: 9.185455322265625
2025-12-09 12:56:49.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.00029536708134434054 Training loss: 9.109084129333496
2025-12-09 12:56:50.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.00029534400853273985 Training loss: 9.151520729064941
2025-12-09 12:56:50.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0002953208793159671 Training loss: 9.017729759216309
2025-12-09 12:56:50.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.00029529769370299823 Training loss: 8.900045394897461
2025-12-09 12:56:51.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.0002952744517028311 Training loss: 9.308229446411133
2025-12-09 12:56:51.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.00029525115332448555 Training loss: 8.925193786621094
2025-12-09 12:56:52.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.0002952277985770032 Training loss: 8.975435256958008
2025-12-09 12:56:52.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.0002952043874694475 Training loss: 9.107489585876465
2025-12-09 12:56:52.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.00029518092001090397 Training loss: 9.486875534057617
2025-12-09 12:56:53.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.00029515739621047973 Training loss: 9.066099166870117
2025-12-09 12:56:53.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.000295133816077304 Training loss: 9.218374252319336
2025-12-09 12:56:53.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.0002951101796205278 Training loss: 8.983139991760254
2025-12-09 12:56:54.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.0002950864868493239 Training loss: 9.368581771850586
2025-12-09 12:56:54.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.00029506273777288696 Training loss: 9.370575904846191
2025-12-09 12:56:55.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.0002950389324004337 Training loss: 9.51565170288086
2025-12-09 12:56:55.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.00029501507074120237 Training loss: 9.035727500915527
2025-12-09 12:56:55.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.00029499115280445326 Training loss: 9.088890075683594
2025-12-09 12:56:56.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.0002949671785994685 Training loss: 9.119184494018555
2025-12-09 12:56:56.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.00029494314813555193 Training loss: 8.986550331115723
2025-12-09 12:56:56.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.00029491906142202934 Training loss: 9.207637786865234
2025-12-09 12:56:57.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.00029489491846824837 Training loss: 9.038305282592773
2025-12-09 12:56:57.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0002948707192835783 Training loss: 9.405960083007812
2025-12-09 12:56:58.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0002948464638774105 Training loss: 9.307050704956055
2025-12-09 12:56:58.376 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.00029482215225915795 Training loss: 9.307193756103516
2025-12-09 12:56:58.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.0002947977844382555 Training loss: 9.067586898803711
2025-12-09 12:56:59.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.0002947733604241599 Training loss: 9.139453887939453
2025-12-09 12:56:59.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.00029474888022634955 Training loss: 9.12491226196289
2025-12-09 12:56:59.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.00029472434385432474 Training loss: 9.085543632507324
2025-12-09 12:57:00.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.0002946997513176076 Training loss: 9.173100471496582
2025-12-09 12:57:00.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.000294675102625742 Training loss: 9.046978950500488
2025-12-09 12:57:00.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.00029465039778829366 Training loss: 9.033607482910156
2025-12-09 12:57:01.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.0002946256368148499 Training loss: 8.953560829162598
2025-12-09 12:57:01.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.00029460081971502015 Training loss: 9.179368019104004
2025-12-09 12:57:02.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.00029457594649843534 Training loss: 9.210073471069336
2025-12-09 12:57:02.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.0002945510171747483 Training loss: 8.864801406860352
2025-12-09 12:57:02.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.0002945260317536336 Training loss: 8.924651145935059
2025-12-09 12:57:03.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0002945009902447876 Training loss: 9.132740020751953
2025-12-09 12:57:03.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.00029447589265792847 Training loss: 9.099433898925781
2025-12-09 12:57:03.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.00029445073900279605 Training loss: 9.14075756072998
2025-12-09 12:57:04.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.000294425529289152 Training loss: 9.563340187072754
2025-12-09 12:57:04.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.00029440026352677966 Training loss: 9.114700317382812
2025-12-09 12:57:05.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.00029437494172548424 Training loss: 9.38036060333252
2025-12-09 12:57:05.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.00029434956389509263 Training loss: 9.24123477935791
2025-12-09 12:57:05.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.0002943241300454534 Training loss: 9.346354484558105
2025-12-09 12:57:06.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.0002942986401864371 Training loss: 8.989336013793945
2025-12-09 12:57:06.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.0002942730943279357 Training loss: 9.309723854064941
2025-12-09 12:57:06.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.000294247492479863 Training loss: 9.02142333984375
2025-12-09 12:57:07.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.00029422183465215474 Training loss: 9.01640510559082
2025-12-09 12:57:07.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.00029419612085476813 Training loss: 9.337462425231934
2025-12-09 12:57:08.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.0002941703510976822 Training loss: 9.41692066192627
2025-12-09 12:57:08.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.00029414452539089776 Training loss: 9.121394157409668
2025-12-09 12:57:08.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.00029411864374443716 Training loss: 8.995660781860352
2025-12-09 12:57:09.175 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.0002940927061683446 Training loss: 9.47302532196045
2025-12-09 12:57:09.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.0002940667126726859 Training loss: 9.014700889587402
2025-12-09 12:57:09.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0002940406632675487 Training loss: 9.141648292541504
2025-12-09 12:57:10.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.0002940145579630423 Training loss: 9.942425727844238
2025-12-09 12:57:10.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.00029398839676929756 Training loss: 9.136452674865723
2025-12-09 12:57:11.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.00029396217969646717 Training loss: 8.476707458496094
2025-12-09 12:57:11.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.00029393590675472545 Training loss: 8.986847877502441
2025-12-09 12:57:11.786 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.00029390957795426845 Training loss: 9.553542137145996
2025-12-09 12:57:12.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.0002938831933053138 Training loss: 9.35262680053711
2025-12-09 12:57:12.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.000293856752818101 Training loss: 9.069296836853027
2025-12-09 12:57:12.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.00029383025650289095 Training loss: 9.228521347045898
2025-12-09 12:57:13.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.0002938037043699664 Training loss: 8.97943115234375
2025-12-09 12:57:13.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.0002937770964296317 Training loss: 9.190155029296875
2025-12-09 12:57:14.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.0002937504326922129 Training loss: 9.200661659240723
2025-12-09 12:57:14.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.00029372371316805767 Training loss: 8.83920955657959
2025-12-09 12:57:14.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.00029369693786753534 Training loss: 8.907999992370605
2025-12-09 12:57:15.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.0002936701068010368 Training loss: 8.888679504394531
2025-12-09 12:57:15.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.0002936432199789748 Training loss: 9.137838363647461
2025-12-09 12:57:15.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.00029361627741178356 Training loss: 9.161111831665039
2025-12-09 12:57:16.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.00029358927910991885 Training loss: 9.09048843383789
2025-12-09 12:57:16.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.00029356222508385827 Training loss: 9.285493850708008
2025-12-09 12:57:16.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.000293535115344101 Training loss: 8.85970401763916
2025-12-09 12:57:17.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.0002935079499011677 Training loss: 9.201313018798828
2025-12-09 12:57:17.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.0002934807287656008 Training loss: 9.284392356872559
2025-12-09 12:57:18.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.00029345345194796435 Training loss: 8.939413070678711
2025-12-09 12:57:18.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.0002934261194588438 Training loss: 9.311909675598145
2025-12-09 12:57:18.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.00029339873130884654 Training loss: 9.117361068725586
2025-12-09 12:57:19.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.00029337128750860124 Training loss: 8.94629192352295
2025-12-09 12:57:19.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.00029334378806875836 Training loss: 9.138647079467773
2025-12-09 12:57:19.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.00029331623299998986 Training loss: 9.23121166229248
2025-12-09 12:57:20.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.0002932886223129894 Training loss: 9.257522583007812
2025-12-09 12:57:20.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.000293260956018472 Training loss: 9.571898460388184
2025-12-09 12:57:21.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.0002932332341271746 Training loss: 9.204678535461426
2025-12-09 12:57:21.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.00029320545664985535 Training loss: 9.073266983032227
2025-12-09 12:57:21.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.00029317762359729423 Training loss: 9.098213195800781
2025-12-09 12:57:22.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.00029314973498029275 Training loss: 8.921882629394531
2025-12-09 12:57:22.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.0002931217908096739 Training loss: 9.37714672088623
2025-12-09 12:57:22.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.0002930937910962822 Training loss: 8.809865951538086
2025-12-09 12:57:23.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.00029306573585098384 Training loss: 9.147000312805176
2025-12-09 12:57:23.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.00029303762508466654 Training loss: 9.59249210357666
2025-12-09 12:57:24.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.00029300945880823956 Training loss: 8.845988273620605
2025-12-09 12:57:24.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.0002929812370326336 Training loss: 9.397126197814941
2025-12-09 12:57:24.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.000292952959768801 Training loss: 8.890685081481934
2025-12-09 12:57:25.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.0002929246270277157 Training loss: 8.837602615356445
2025-12-09 12:57:25.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.000292896238820373 Training loss: 9.548345565795898
2025-12-09 12:57:25.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.0002928677951577898 Training loss: 9.125741958618164
2025-12-09 12:57:26.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.00029283929605100455 Training loss: 9.381918907165527
2025-12-09 12:57:26.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0002928107415110772 Training loss: 9.257268905639648
2025-12-09 12:57:27.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.0002927821315490893 Training loss: 8.80115032196045
2025-12-09 12:57:27.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.0002927534661761436 Training loss: 9.163384437561035
2025-12-09 12:57:27.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.00029272474540336475 Training loss: 9.14631462097168
2025-12-09 12:57:28.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.00029269596924189875 Training loss: 9.144092559814453
2025-12-09 12:57:28.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.0002926671377029129 Training loss: 9.25048542022705
2025-12-09 12:57:28.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.00029263825079759635 Training loss: 9.238311767578125
2025-12-09 12:57:29.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.00029260930853715935 Training loss: 8.925246238708496
2025-12-09 12:57:29.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.0002925803109328339 Training loss: 9.196764945983887
2025-12-09 12:57:30.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0002925512579958735 Training loss: 9.281548500061035
2025-12-09 12:57:30.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.0002925221497375529 Training loss: 8.911504745483398
2025-12-09 12:57:30.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.00029249298616916856 Training loss: 9.067721366882324
2025-12-09 12:57:31.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.00029246376730203817 Training loss: 9.807910919189453
2025-12-09 12:57:31.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.0002924344931475011 Training loss: 8.997244834899902
2025-12-09 12:57:31.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.000292405163716918 Training loss: 8.851713180541992
2025-12-09 12:57:32.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.0002923757790216711 Training loss: 9.093328475952148
2025-12-09 12:57:32.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.000292346339073164 Training loss: 8.867496490478516
2025-12-09 12:57:33.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.00029231684388282184 Training loss: 9.157648086547852
2025-12-09 12:57:33.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.000292287293462091 Training loss: 9.5057954788208
2025-12-09 12:57:33.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.0002922576878224395 Training loss: 9.07571792602539
2025-12-09 12:57:34.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.00029222802697535674 Training loss: 8.866219520568848
2025-12-09 12:57:34.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.0002921983109323535 Training loss: 9.487556457519531
2025-12-09 12:57:34.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0002921685397049619 Training loss: 9.260682106018066
2025-12-09 12:57:35.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0002921387133047357 Training loss: 9.649221420288086
2025-12-09 12:57:35.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.0002921088317432499 Training loss: 8.99112319946289
2025-12-09 12:57:35.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.0002920788950321009 Training loss: 9.228073120117188
2025-12-09 12:57:36.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.00029204890318290666 Training loss: 9.0889253616333
2025-12-09 12:57:36.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.0002920188562073063 Training loss: 8.849380493164062
2025-12-09 12:57:37.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0002919887541169605 Training loss: 8.964150428771973
2025-12-09 12:57:37.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.0002919585969235514 Training loss: 9.750072479248047
2025-12-09 12:57:37.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.00029192838463878236 Training loss: 9.227787971496582
2025-12-09 12:57:38.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.0002918981172743781 Training loss: 9.03126335144043
2025-12-09 12:57:38.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.00029186779484208485 Training loss: 9.248800277709961
2025-12-09 12:57:38.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.0002918374173536702 Training loss: 9.440632820129395
2025-12-09 12:57:39.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.000291806984820923 Training loss: 9.033592224121094
2025-12-09 12:57:39.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.00029177649725565353 Training loss: 8.941988945007324
2025-12-09 12:57:40.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.00029174595466969344 Training loss: 8.922493934631348
2025-12-09 12:57:40.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.00029171535707489565 Training loss: 9.109182357788086
2025-12-09 12:57:40.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.0002916847044831346 Training loss: 9.333260536193848
2025-12-09 12:57:41.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.0002916539969063059 Training loss: 9.567887306213379
2025-12-09 12:57:41.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.0002916232343563265 Training loss: 9.172450065612793
2025-12-09 12:57:41.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.0002915924168451349 Training loss: 9.468432426452637
2025-12-09 12:57:42.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.0002915615443846906 Training loss: 9.082683563232422
2025-12-09 12:57:42.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0002915306169869747 Training loss: 9.124251365661621
2025-12-09 12:57:43.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0002914996346639895 Training loss: 9.153823852539062
2025-12-09 12:57:43.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.00029146859742775865 Training loss: 9.14303970336914
2025-12-09 12:57:43.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.00029143750529032707 Training loss: 8.924274444580078
2025-12-09 12:57:44.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.0002914063582637611 Training loss: 8.901034355163574
2025-12-09 12:57:44.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.0002913751563601481 Training loss: 9.04995346069336
2025-12-09 12:57:44.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.0002913438995915971 Training loss: 9.23519229888916
2025-12-09 12:57:45.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0002913125879702381 Training loss: 8.895977020263672
2025-12-09 12:57:45.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.00029128122150822263 Training loss: 9.085457801818848
2025-12-09 12:57:46.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.0002912498002177234 Training loss: 8.996955871582031
2025-12-09 12:57:46.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0002912183241109344 Training loss: 8.834613800048828
2025-12-09 12:57:46.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.00029118679320007087 Training loss: 8.962486267089844
2025-12-09 12:57:47.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.0002911552074973693 Training loss: 8.895822525024414
2025-12-09 12:57:47.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.0002911235670150875 Training loss: 8.858377456665039
2025-12-09 12:57:47.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.0002910918717655046 Training loss: 9.223718643188477
2025-12-09 12:57:48.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.00029106012176092084 Training loss: 8.995407104492188
2025-12-09 12:57:48.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0002910283170136578 Training loss: 9.448935508728027
2025-12-09 12:57:49.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.00029099645753605827 Training loss: 9.17835521697998
2025-12-09 12:57:49.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.00029096454334048627 Training loss: 9.121918678283691
2025-12-09 12:57:49.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.0002909325744393271 Training loss: 9.263985633850098
2025-12-09 12:57:50.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.0002909005508449873 Training loss: 9.145827293395996
2025-12-09 12:57:50.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.0002908684725698946 Training loss: 9.526871681213379
2025-12-09 12:57:50.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0002908363396264978 Training loss: 9.110715866088867
2025-12-09 12:57:51.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.00029080415202726727 Training loss: 8.947153091430664
2025-12-09 12:57:51.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0002907719097846943 Training loss: 9.377164840698242
2025-12-09 12:57:51.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.0002907396129112915 Training loss: 9.258947372436523
2025-12-09 12:57:52.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.00029070726141959265 Training loss: 8.919565200805664
2025-12-09 12:57:52.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.00029067485532215267 Training loss: 9.262027740478516
2025-12-09 12:57:53.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.0002906423946315478 Training loss: 8.89858627319336
2025-12-09 12:57:53.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.00029060987936037536 Training loss: 9.141328811645508
2025-12-09 12:57:53.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.00029057730952125393 Training loss: 9.227574348449707
2025-12-09 12:57:54.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.0002905446851268233 Training loss: 9.339180946350098
2025-12-09 12:57:54.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.0002905120061897441 Training loss: 9.00328540802002
2025-12-09 12:57:54.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.0002904792727226987 Training loss: 8.941805839538574
2025-12-09 12:57:55.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.00029044648473839014 Training loss: 9.00764274597168
2025-12-09 12:57:55.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.0002904136422495429 Training loss: 9.123763084411621
2025-12-09 12:57:56.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0002903807452689024 Training loss: 8.996834754943848
2025-12-09 12:57:56.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.00029034779380923535 Training loss: 9.229575157165527
2025-12-09 12:57:56.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.00029031478788332955 Training loss: 8.97766399383545
2025-12-09 12:57:57.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.0002902817275039941 Training loss: 9.185547828674316
2025-12-09 12:57:57.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.00029024861268405887 Training loss: 8.963273048400879
2025-12-09 12:57:57.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.00029021544343637526 Training loss: 9.381844520568848
2025-12-09 12:57:58.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.00029018221977381546 Training loss: 9.212221145629883
2025-12-09 12:57:58.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.00029014894170927306 Training loss: 9.029964447021484
2025-12-09 12:57:59.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.0002901156092556625 Training loss: 9.23085880279541
2025-12-09 12:57:59.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.0002900822224259195 Training loss: 9.034636497497559
2025-12-09 12:57:59.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.0002900487812330009 Training loss: 9.034056663513184
2025-12-09 12:58:00.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.00029001528568988453 Training loss: 9.086995124816895
2025-12-09 12:58:00.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.00028998173580956934 Training loss: 9.167346000671387
2025-12-09 12:58:00.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.00028994813160507536 Training loss: 9.089946746826172
2025-12-09 12:58:01.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.0002899144730894438 Training loss: 9.051314353942871
2025-12-09 12:58:01.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.00028988076027573685 Training loss: 9.096094131469727
2025-12-09 12:58:02.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.00028984699317703775 Training loss: 9.733338356018066
2025-12-09 12:58:02.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.0002898131718064509 Training loss: 8.93356990814209
2025-12-09 12:58:02.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.00028977929617710166 Training loss: 8.917332649230957
2025-12-09 12:58:03.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.00028974536630213657 Training loss: 9.04427433013916
2025-12-09 12:58:03.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.00028971138219472303 Training loss: 9.154071807861328
2025-12-09 12:58:03.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.00028967734386804977 Training loss: 8.972593307495117
2025-12-09 12:58:04.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.0002896432513353264 Training loss: 8.974359512329102
2025-12-09 12:58:04.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.00028960910460978337 Training loss: 8.929336547851562
2025-12-09 12:58:05.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.0002895749037046725 Training loss: 8.85001277923584
2025-12-09 12:58:05.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.0002895406486332665 Training loss: 9.837650299072266
2025-12-09 12:58:05.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.00028950633940885907 Training loss: 8.892995834350586
2025-12-09 12:58:06.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.00028947197604476494 Training loss: 9.081396102905273
2025-12-09 12:58:06.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.00028943755855431985 Training loss: 9.047819137573242
2025-12-09 12:58:06.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.0002894030869508806 Training loss: 9.04812240600586
2025-12-09 12:58:07.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.0002893685612478249 Training loss: 9.44723129272461
2025-12-09 12:58:07.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.00028933398145855154 Training loss: 8.948987007141113
2025-12-09 12:58:08.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.0002892993475964802 Training loss: 9.000654220581055
2025-12-09 12:58:08.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.0002892646596750517 Training loss: 8.878006935119629
2025-12-09 12:58:08.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.0002892299177077277 Training loss: 9.158896446228027
2025-12-09 12:58:09.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.0002891951217079908 Training loss: 9.154838562011719
2025-12-09 12:58:09.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.0002891602716893448 Training loss: 9.076445579528809
2025-12-09 12:58:09.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.0002891253676653142 Training loss: 8.809889793395996
2025-12-09 12:58:10.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.00028909040964944456 Training loss: 8.930198669433594
2025-12-09 12:58:10.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.0002890553976553025 Training loss: 9.000362396240234
2025-12-09 12:58:10.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.00028902033169647543 Training loss: 8.755059242248535
2025-12-09 12:58:11.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.00028898521178657174 Training loss: 8.98930835723877
2025-12-09 12:58:11.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.0002889500379392209 Training loss: 9.108779907226562
2025-12-09 12:58:12.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.000288914810168073 Training loss: 8.869787216186523
2025-12-09 12:58:12.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.00028887952848679943 Training loss: 9.203433990478516
2025-12-09 12:58:12.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.0002888441929090922 Training loss: 8.920679092407227
2025-12-09 12:58:13.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.00028880880344866447 Training loss: 8.74101734161377
2025-12-09 12:58:13.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.00028877336011925005 Training loss: 8.954344749450684
2025-12-09 12:58:13.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.000288737862934604 Training loss: 9.220269203186035
2025-12-09 12:58:14.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 726 LR: 0.00028870231190850185 Training loss: 9.295598983764648
2025-12-09 12:58:14.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 727 LR: 0.00028866670705474047 Training loss: 9.316584587097168
2025-12-09 12:58:15.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 728 LR: 0.00028863104838713726 Training loss: 9.02859878540039
2025-12-09 12:58:15.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 729 LR: 0.00028859533591953074 Training loss: 9.574012756347656
2025-12-09 12:58:15.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 730 LR: 0.00028855956966578023 Training loss: 8.896282196044922
2025-12-09 12:58:16.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 731 LR: 0.00028852374963976585 Training loss: 9.186266899108887
2025-12-09 12:58:16.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 732 LR: 0.0002884878758553887 Training loss: 9.258809089660645
2025-12-09 12:58:16.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 733 LR: 0.00028845194832657065 Training loss: 9.349954605102539
2025-12-09 12:58:17.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 734 LR: 0.0002884159670672545 Training loss: 8.986023902893066
2025-12-09 12:58:17.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 735 LR: 0.00028837993209140385 Training loss: 9.450884819030762
