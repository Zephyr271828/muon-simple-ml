2025-12-09 12:12:08.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 2.9999999999999997e-06 Training loss: 11.988485336303711
2025-12-09 12:12:08.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 5.999999999999999e-06 Training loss: 12.019883155822754
2025-12-09 12:12:08.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 8.999999999999999e-06 Training loss: 12.016643524169922
2025-12-09 12:12:08.748 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 1.1999999999999999e-05 Training loss: 12.012618064880371
2025-12-09 12:12:08.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 1.4999999999999999e-05 Training loss: 12.033417701721191
2025-12-09 12:12:08.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 1.7999999999999997e-05 Training loss: 12.010530471801758
2025-12-09 12:12:08.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 2.1e-05 Training loss: 11.999041557312012
2025-12-09 12:12:09.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 2.3999999999999997e-05 Training loss: 12.024602890014648
2025-12-09 12:12:09.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 2.6999999999999996e-05 Training loss: 12.023719787597656
2025-12-09 12:12:09.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 2.9999999999999997e-05 Training loss: 12.025039672851562
2025-12-09 12:12:09.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 3.2999999999999996e-05 Training loss: 12.032837867736816
2025-12-09 12:12:09.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 3.5999999999999994e-05 Training loss: 11.977789878845215
2025-12-09 12:12:09.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 3.9e-05 Training loss: 12.015585899353027
2025-12-09 12:12:09.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 4.2e-05 Training loss: 12.038607597351074
2025-12-09 12:12:09.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 4.4999999999999996e-05 Training loss: 12.042963027954102
2025-12-09 12:12:09.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 4.7999999999999994e-05 Training loss: 12.00180721282959
2025-12-09 12:12:09.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 5.1e-05 Training loss: 12.003508567810059
2025-12-09 12:12:09.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 5.399999999999999e-05 Training loss: 12.028188705444336
2025-12-09 12:12:09.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 5.6999999999999996e-05 Training loss: 12.053606033325195
2025-12-09 12:12:09.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 5.9999999999999995e-05 Training loss: 11.997822761535645
2025-12-09 12:12:10.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 6.299999999999999e-05 Training loss: 12.014863967895508
2025-12-09 12:12:10.113 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 6.599999999999999e-05 Training loss: 12.030811309814453
2025-12-09 12:12:10.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 6.9e-05 Training loss: 12.01469612121582
2025-12-09 12:12:10.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 7.199999999999999e-05 Training loss: 12.011981010437012
2025-12-09 12:12:10.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 7.5e-05 Training loss: 11.997891426086426
2025-12-09 12:12:10.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 7.8e-05 Training loss: 12.021570205688477
2025-12-09 12:12:10.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 8.1e-05 Training loss: 12.051602363586426
2025-12-09 12:12:10.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 8.4e-05 Training loss: 11.982552528381348
2025-12-09 12:12:10.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 8.699999999999999e-05 Training loss: 12.014087677001953
2025-12-09 12:12:10.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 8.999999999999999e-05 Training loss: 12.015222549438477
2025-12-09 12:12:10.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 9.3e-05 Training loss: 11.958949089050293
2025-12-09 12:12:10.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 9.599999999999999e-05 Training loss: 11.996261596679688
2025-12-09 12:12:10.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 9.9e-05 Training loss: 12.016069412231445
2025-12-09 12:12:11.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.000102 Training loss: 12.067584991455078
2025-12-09 12:12:11.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00010499999999999999 Training loss: 12.017204284667969
2025-12-09 12:12:11.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00010799999999999998 Training loss: 11.924118995666504
2025-12-09 12:12:11.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00011099999999999999 Training loss: 12.038602828979492
2025-12-09 12:12:11.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00011399999999999999 Training loss: 11.981672286987305
2025-12-09 12:12:11.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.000117 Training loss: 11.98815631866455
2025-12-09 12:12:11.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.00011999999999999999 Training loss: 11.963424682617188
2025-12-09 12:12:11.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00012299999999999998 Training loss: 11.921338081359863
2025-12-09 12:12:11.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00012599999999999997 Training loss: 11.929407119750977
2025-12-09 12:12:11.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.000129 Training loss: 12.022296905517578
2025-12-09 12:12:11.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00013199999999999998 Training loss: 11.876920700073242
2025-12-09 12:12:11.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.000135 Training loss: 11.935954093933105
2025-12-09 12:12:11.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.000138 Training loss: 11.95319938659668
2025-12-09 12:12:12.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00014099999999999998 Training loss: 11.997225761413574
2025-12-09 12:12:12.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00014399999999999998 Training loss: 11.935653686523438
2025-12-09 12:12:12.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.000147 Training loss: 11.95724105834961
2025-12-09 12:12:12.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.00015 Training loss: 11.979856491088867
2025-12-09 12:12:12.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00015299999999999998 Training loss: 12.002161979675293
2025-12-09 12:12:12.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.000156 Training loss: 11.962347984313965
2025-12-09 12:12:12.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.000159 Training loss: 11.982053756713867
2025-12-09 12:12:12.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.000162 Training loss: 11.955131530761719
2025-12-09 12:12:12.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.000165 Training loss: 11.879355430603027
2025-12-09 12:12:12.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.000168 Training loss: 11.963486671447754
2025-12-09 12:12:12.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00017099999999999998 Training loss: 11.91454792022705
2025-12-09 12:12:12.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00017399999999999997 Training loss: 11.948946952819824
2025-12-09 12:12:12.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00017699999999999997 Training loss: 11.849044799804688
2025-12-09 12:12:12.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.00017999999999999998 Training loss: 11.9718599319458
2025-12-09 12:12:13.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00018299999999999998 Training loss: 11.906638145446777
2025-12-09 12:12:13.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.000186 Training loss: 11.903031349182129
2025-12-09 12:12:13.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00018899999999999999 Training loss: 11.905155181884766
2025-12-09 12:12:13.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00019199999999999998 Training loss: 11.894660949707031
2025-12-09 12:12:13.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.000195 Training loss: 11.913886070251465
2025-12-09 12:12:13.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.000198 Training loss: 11.869075775146484
2025-12-09 12:12:13.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.000201 Training loss: 11.864295959472656
2025-12-09 12:12:13.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.000204 Training loss: 11.92031192779541
2025-12-09 12:12:13.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00020699999999999996 Training loss: 11.872305870056152
2025-12-09 12:12:13.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.00020999999999999998 Training loss: 11.869165420532227
2025-12-09 12:12:13.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00021299999999999997 Training loss: 11.831799507141113
2025-12-09 12:12:13.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.00021599999999999996 Training loss: 11.851286888122559
2025-12-09 12:12:13.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00021899999999999998 Training loss: 11.910656929016113
2025-12-09 12:12:14.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00022199999999999998 Training loss: 11.811100006103516
2025-12-09 12:12:14.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.000225 Training loss: 11.83397102355957
2025-12-09 12:12:14.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00022799999999999999 Training loss: 11.755773544311523
2025-12-09 12:12:14.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.00023099999999999998 Training loss: 11.77124309539795
2025-12-09 12:12:14.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.000234 Training loss: 11.895484924316406
2025-12-09 12:12:14.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.000237 Training loss: 11.836806297302246
2025-12-09 12:12:14.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.00023999999999999998 Training loss: 11.790895462036133
2025-12-09 12:12:14.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.000243 Training loss: 11.69411849975586
2025-12-09 12:12:14.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00024599999999999996 Training loss: 11.746362686157227
2025-12-09 12:12:14.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.000249 Training loss: 11.646007537841797
2025-12-09 12:12:14.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00025199999999999995 Training loss: 11.681938171386719
2025-12-09 12:12:14.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00025499999999999996 Training loss: 11.65904426574707
2025-12-09 12:12:14.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.000258 Training loss: 11.750018119812012
2025-12-09 12:12:15.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.000261 Training loss: 11.736917495727539
2025-12-09 12:12:15.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00026399999999999997 Training loss: 11.830230712890625
2025-12-09 12:12:15.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.000267 Training loss: 11.675528526306152
2025-12-09 12:12:15.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.00027 Training loss: 11.635801315307617
2025-12-09 12:12:15.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00027299999999999997 Training loss: 11.643543243408203
2025-12-09 12:12:15.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.000276 Training loss: 11.617947578430176
2025-12-09 12:12:15.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.000279 Training loss: 11.600214958190918
2025-12-09 12:12:15.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00028199999999999997 Training loss: 11.562980651855469
2025-12-09 12:12:15.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.000285 Training loss: 11.592996597290039
2025-12-09 12:12:15.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00028799999999999995 Training loss: 11.488302230834961
2025-12-09 12:12:15.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.00029099999999999997 Training loss: 11.633698463439941
2025-12-09 12:12:15.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.000294 Training loss: 11.47545051574707
2025-12-09 12:12:15.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00029699999999999996 Training loss: 11.408560752868652
2025-12-09 12:12:16.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0003 Training loss: 11.572155952453613
2025-12-09 12:12:16.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.00029999997217736103 Training loss: 11.50780200958252
2025-12-09 12:12:16.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.00029999988870945456 Training loss: 11.574600219726562
2025-12-09 12:12:16.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0002999997495963115 Training loss: 11.477407455444336
2025-12-09 12:12:16.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.00029999955483798346 Training loss: 11.397965431213379
2025-12-09 12:12:16.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0002999993044345427 Training loss: 11.510024070739746
2025-12-09 12:12:16.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0002999989983860821 Training loss: 11.403233528137207
2025-12-09 12:12:16.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.00029999863669271526 Training loss: 11.354389190673828
2025-12-09 12:12:16.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0002999982193545762 Training loss: 11.343214988708496
2025-12-09 12:12:16.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0002999977463718199 Training loss: 11.4358549118042
2025-12-09 12:12:16.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.00029999721774462174 Training loss: 11.318583488464355
2025-12-09 12:12:16.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.00029999663347317785 Training loss: 11.256096839904785
2025-12-09 12:12:16.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.00029999599355770497 Training loss: 11.286069869995117
2025-12-09 12:12:17.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0002999952979984405 Training loss: 11.23662281036377
2025-12-09 12:12:17.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.00029999454679564244 Training loss: 11.299992561340332
2025-12-09 12:12:17.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.0002999937399495895 Training loss: 11.087885856628418
2025-12-09 12:12:17.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.00029999287746058093 Training loss: 11.281717300415039
2025-12-09 12:12:17.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.00029999195932893676 Training loss: 11.258094787597656
2025-12-09 12:12:17.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.00029999098555499756 Training loss: 11.217456817626953
2025-12-09 12:12:17.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0002999899561391246 Training loss: 11.245796203613281
2025-12-09 12:12:17.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.00029998887108169967 Training loss: 11.22295093536377
2025-12-09 12:12:17.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.0002999877303831254 Training loss: 11.118993759155273
2025-12-09 12:12:17.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.00029998653404382487 Training loss: 11.085098266601562
2025-12-09 12:12:17.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.000299985282064242 Training loss: 11.147326469421387
2025-12-09 12:12:17.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.00029998397444484104 Training loss: 10.926178932189941
2025-12-09 12:12:17.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0002999826111861073 Training loss: 11.189926147460938
2025-12-09 12:12:18.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.00029998119228854625 Training loss: 11.065835952758789
2025-12-09 12:12:18.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.0002999797177526845 Training loss: 11.195711135864258
2025-12-09 12:12:18.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.000299978187579069 Training loss: 11.193941116333008
2025-12-09 12:12:18.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0002999766017682673 Training loss: 11.386784553527832
2025-12-09 12:12:18.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.00029997496032086775 Training loss: 11.292831420898438
2025-12-09 12:12:18.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.00029997326323747927 Training loss: 10.907846450805664
2025-12-09 12:12:18.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.0002999715105187314 Training loss: 11.049338340759277
2025-12-09 12:12:18.556 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.00029996970216527436 Training loss: 11.130353927612305
2025-12-09 12:12:18.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.000299967838177779 Training loss: 11.11014175415039
2025-12-09 12:12:18.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.00029996591855693686 Training loss: 10.939108848571777
2025-12-09 12:12:18.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.00029996394330345996 Training loss: 11.052485466003418
2025-12-09 12:12:18.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0002999619124180811 Training loss: 10.897549629211426
2025-12-09 12:12:19.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.00029995982590155367 Training loss: 10.999734878540039
2025-12-09 12:12:19.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.00029995768375465164 Training loss: 11.184443473815918
2025-12-09 12:12:19.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0002999554859781698 Training loss: 11.201723098754883
2025-12-09 12:12:19.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.00029995323257292337 Training loss: 10.986186027526855
2025-12-09 12:12:19.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.0002999509235397483 Training loss: 11.050108909606934
2025-12-09 12:12:19.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.00029994855887950124 Training loss: 10.881783485412598
2025-12-09 12:12:19.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.00029994613859305933 Training loss: 10.845906257629395
2025-12-09 12:12:19.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0002999436626813204 Training loss: 10.854023933410645
2025-12-09 12:12:19.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.000299941131145203 Training loss: 10.909793853759766
2025-12-09 12:12:19.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0002999385439856462 Training loss: 11.03523063659668
2025-12-09 12:12:19.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0002999359012036099 Training loss: 10.92375659942627
2025-12-09 12:12:19.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.0002999332028000742 Training loss: 10.859685897827148
2025-12-09 12:12:19.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0002999304487760404 Training loss: 10.895059585571289
2025-12-09 12:12:19.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.00029992763913253 Training loss: 10.930769920349121
2025-12-09 12:12:20.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.00029992477387058537 Training loss: 10.947020530700684
2025-12-09 12:12:20.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0002999218529912694 Training loss: 10.8137788772583
2025-12-09 12:12:20.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.00029991887649566564 Training loss: 10.848978042602539
2025-12-09 12:12:20.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.00029991584438487825 Training loss: 10.988801002502441
2025-12-09 12:12:20.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0002999127566600321 Training loss: 10.887813568115234
2025-12-09 12:12:20.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.00029990961332227264 Training loss: 10.871634483337402
2025-12-09 12:12:20.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0002999064143727659 Training loss: 10.69404411315918
2025-12-09 12:12:20.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.00029990315981269863 Training loss: 10.740984916687012
2025-12-09 12:12:20.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0002998998496432781 Training loss: 10.675546646118164
2025-12-09 12:12:20.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.0002998964838657324 Training loss: 10.884519577026367
2025-12-09 12:12:20.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.0002998930624813101 Training loss: 10.918778419494629
2025-12-09 12:12:20.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.00029988958549128026 Training loss: 10.759039878845215
2025-12-09 12:12:20.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.00029988605289693295 Training loss: 10.796222686767578
2025-12-09 12:12:21.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0002998824646995785 Training loss: 10.64499282836914
2025-12-09 12:12:21.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.00029987882090054817 Training loss: 10.710432052612305
2025-12-09 12:12:21.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.0002998751215011935 Training loss: 10.7997407913208
2025-12-09 12:12:21.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.000299871366502887 Training loss: 10.889202117919922
2025-12-09 12:12:21.363 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.00029986755590702164 Training loss: 10.75041675567627
2025-12-09 12:12:21.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.000299863689715011 Training loss: 10.558945655822754
2025-12-09 12:12:21.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0002998597679282893 Training loss: 10.674521446228027
2025-12-09 12:12:21.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.00029985579054831146 Training loss: 10.646223068237305
2025-12-09 12:12:21.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0002998517575765528 Training loss: 10.642849922180176
2025-12-09 12:12:21.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.00029984766901450965 Training loss: 10.690605163574219
2025-12-09 12:12:21.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.00029984352486369867 Training loss: 10.733278274536133
2025-12-09 12:12:21.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.00029983932512565707 Training loss: 10.639750480651855
2025-12-09 12:12:21.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.00029983506980194296 Training loss: 10.741083145141602
2025-12-09 12:12:22.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.00029983075889413493 Training loss: 10.731307983398438
2025-12-09 12:12:22.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.00029982639240383214 Training loss: 10.6353178024292
2025-12-09 12:12:22.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.00029982197033265437 Training loss: 10.756240844726562
2025-12-09 12:12:22.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.00029981749268224225 Training loss: 10.690491676330566
2025-12-09 12:12:22.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.00029981295945425665 Training loss: 10.763368606567383
2025-12-09 12:12:22.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.00029980837065037935 Training loss: 10.591133117675781
2025-12-09 12:12:22.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.00029980372627231265 Training loss: 10.66025447845459
2025-12-09 12:12:22.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.00029979902632177945 Training loss: 10.568802833557129
2025-12-09 12:12:22.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0002997942708005233 Training loss: 10.555302619934082
2025-12-09 12:12:22.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.00029978945971030835 Training loss: 10.575874328613281
2025-12-09 12:12:22.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.0002997845930529194 Training loss: 10.393263816833496
2025-12-09 12:12:22.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.00029977967083016173 Training loss: 10.612215995788574
2025-12-09 12:12:22.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.00029977469304386133 Training loss: 10.616180419921875
2025-12-09 12:12:23.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0002997696596958649 Training loss: 10.584135055541992
2025-12-09 12:12:23.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0002997645707880396 Training loss: 10.563016891479492
2025-12-09 12:12:23.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.0002997594263222733 Training loss: 10.597294807434082
2025-12-09 12:12:23.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.00029975422630047435 Training loss: 10.400252342224121
2025-12-09 12:12:23.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.00029974897072457187 Training loss: 10.537753105163574
2025-12-09 12:12:23.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0002997436595965154 Training loss: 10.414833068847656
2025-12-09 12:12:23.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0002997382929182754 Training loss: 10.52497386932373
2025-12-09 12:12:23.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.00029973287069184255 Training loss: 10.704992294311523
2025-12-09 12:12:23.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0002997273929192284 Training loss: 10.511930465698242
2025-12-09 12:12:23.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0002997218596024651 Training loss: 10.465620040893555
2025-12-09 12:12:23.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.00029971627074360516 Training loss: 10.624897003173828
2025-12-09 12:12:23.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.00029971062634472203 Training loss: 10.503138542175293
2025-12-09 12:12:23.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.00029970492640790956 Training loss: 10.516456604003906
2025-12-09 12:12:24.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0002996991709352822 Training loss: 10.519794464111328
2025-12-09 12:12:24.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0002996933599289751 Training loss: 10.436507225036621
2025-12-09 12:12:24.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.000299687493391144 Training loss: 10.560504913330078
2025-12-09 12:12:24.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.00029968157132396507 Training loss: 10.587303161621094
2025-12-09 12:12:24.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.00029967559372963534 Training loss: 10.498185157775879
2025-12-09 12:12:24.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.00029966956061037227 Training loss: 10.473407745361328
2025-12-09 12:12:24.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.00029966347196841393 Training loss: 10.493012428283691
2025-12-09 12:12:24.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.000299657327806019 Training loss: 10.427425384521484
2025-12-09 12:12:24.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.0002996511281254668 Training loss: 10.51142692565918
2025-12-09 12:12:24.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0002996448729290572 Training loss: 10.602248191833496
2025-12-09 12:12:24.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.00029963856221911075 Training loss: 10.661251068115234
2025-12-09 12:12:24.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.00029963219599796843 Training loss: 10.451111793518066
2025-12-09 12:12:24.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.000299625774267992 Training loss: 10.5235595703125
2025-12-09 12:12:25.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0002996192970315636 Training loss: 10.297707557678223
2025-12-09 12:12:25.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.00029961276429108625 Training loss: 10.476105690002441
2025-12-09 12:12:25.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.00029960617604898323 Training loss: 10.514236450195312
2025-12-09 12:12:25.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0002995995323076986 Training loss: 10.462250709533691
2025-12-09 12:12:25.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.00029959283306969705 Training loss: 10.481025695800781
2025-12-09 12:12:25.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.00029958607833746375 Training loss: 10.427534103393555
2025-12-09 12:12:25.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0002995792681135045 Training loss: 10.417417526245117
2025-12-09 12:12:25.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.00029957240240034564 Training loss: 10.237824440002441
2025-12-09 12:12:25.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0002995654812005342 Training loss: 10.467877388000488
2025-12-09 12:12:25.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.0002995585045166376 Training loss: 10.47498893737793
2025-12-09 12:12:25.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.00029955147235124417 Training loss: 10.499985694885254
2025-12-09 12:12:25.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.00029954438470696247 Training loss: 10.322284698486328
2025-12-09 12:12:25.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0002995372415864218 Training loss: 10.376261711120605
2025-12-09 12:12:26.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0002995300429922721 Training loss: 10.371529579162598
2025-12-09 12:12:26.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.00029952278892718376 Training loss: 10.185587882995605
2025-12-09 12:12:26.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.0002995154793938479 Training loss: 10.19900131225586
2025-12-09 12:12:26.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.00029950811439497606 Training loss: 10.306455612182617
2025-12-09 12:12:26.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0002995006939333004 Training loss: 10.31859302520752
2025-12-09 12:12:26.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.00029949321801157365 Training loss: 10.259644508361816
2025-12-09 12:12:26.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.00029948568663256927 Training loss: 10.445984840393066
2025-12-09 12:12:26.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.0002994780997990811 Training loss: 10.184627532958984
2025-12-09 12:12:26.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0002994704575139236 Training loss: 10.365453720092773
2025-12-09 12:12:26.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.00029946275977993175 Training loss: 10.350852966308594
2025-12-09 12:12:26.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0002994550065999613 Training loss: 10.315569877624512
2025-12-09 12:12:26.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.0002994471979768884 Training loss: 10.25295639038086
2025-12-09 12:12:26.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.00029943933391360974 Training loss: 10.281044006347656
2025-12-09 12:12:26.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.00029943141441304274 Training loss: 10.13183879852295
2025-12-09 12:12:27.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.00029942343947812517 Training loss: 10.409323692321777
2025-12-09 12:12:27.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.0002994154091118156 Training loss: 10.453907012939453
2025-12-09 12:12:27.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0002994073233170929 Training loss: 10.18792724609375
2025-12-09 12:12:27.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.00029939918209695676 Training loss: 10.653705596923828
2025-12-09 12:12:27.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0002993909854544273 Training loss: 10.31118106842041
2025-12-09 12:12:27.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.00029938273339254515 Training loss: 10.420845985412598
2025-12-09 12:12:27.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.0002993744259143716 Training loss: 10.498724937438965
2025-12-09 12:12:27.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0002993660630229886 Training loss: 10.012089729309082
2025-12-09 12:12:27.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.0002993576447214983 Training loss: 10.066705703735352
2025-12-09 12:12:27.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0002993491710130237 Training loss: 10.244161605834961
2025-12-09 12:12:27.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.00029934064190070836 Training loss: 10.438501358032227
2025-12-09 12:12:27.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.00029933205738771624 Training loss: 10.298535346984863
2025-12-09 12:12:27.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.0002993234174772319 Training loss: 10.29333209991455
2025-12-09 12:12:28.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.00029931472217246057 Training loss: 10.203672409057617
2025-12-09 12:12:28.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0002993059714766278 Training loss: 10.339699745178223
2025-12-09 12:12:28.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.00029929716539297993 Training loss: 10.350663185119629
2025-12-09 12:12:28.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.00029928830392478376 Training loss: 10.234733581542969
2025-12-09 12:12:28.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0002992793870753265 Training loss: 10.250096321105957
2025-12-09 12:12:28.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0002992704148479161 Training loss: 10.266512870788574
2025-12-09 12:12:28.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00029926138724588097 Training loss: 10.347145080566406
2025-12-09 12:12:28.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.00029925230427257004 Training loss: 10.302846908569336
2025-12-09 12:12:28.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.0002992431659313528 Training loss: 10.316390037536621
2025-12-09 12:12:28.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.00029923397222561933 Training loss: 10.239485740661621
2025-12-09 12:12:28.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0002992247231587802 Training loss: 10.418526649475098
2025-12-09 12:12:28.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.00029921541873426647 Training loss: 10.287590026855469
2025-12-09 12:12:28.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.00029920605895552985 Training loss: 10.355920791625977
2025-12-09 12:12:29.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0002991966438260425 Training loss: 10.22227668762207
2025-12-09 12:12:29.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.0002991871733492971 Training loss: 10.113396644592285
2025-12-09 12:12:29.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.00029917764752880697 Training loss: 10.228078842163086
2025-12-09 12:12:29.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.0002991680663681059 Training loss: 10.266761779785156
2025-12-09 12:12:29.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.00029915842987074804 Training loss: 10.128660202026367
2025-12-09 12:12:29.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0002991487380403084 Training loss: 10.129972457885742
2025-12-09 12:12:29.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.00029913899088038226 Training loss: 10.027502059936523
2025-12-09 12:12:29.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.00029912918839458555 Training loss: 10.312114715576172
2025-12-09 12:12:29.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.00029911933058655464 Training loss: 10.211996078491211
2025-12-09 12:12:29.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.00029910941745994653 Training loss: 10.081042289733887
2025-12-09 12:12:29.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.00029909944901843863 Training loss: 10.312597274780273
2025-12-09 12:12:29.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0002990894252657289 Training loss: 10.43770980834961
2025-12-09 12:12:29.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.0002990793462055359 Training loss: 10.140006065368652
2025-12-09 12:12:30.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0002990692118415986 Training loss: 10.010988235473633
2025-12-09 12:12:30.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0002990590221776765 Training loss: 10.123008728027344
2025-12-09 12:12:30.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0002990487772175497 Training loss: 10.364123344421387
2025-12-09 12:12:30.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.00029903847696501876 Training loss: 10.09558391571045
2025-12-09 12:12:30.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.00029902812142390474 Training loss: 10.15112018585205
2025-12-09 12:12:30.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0002990177105980492 Training loss: 10.392627716064453
2025-12-09 12:12:30.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.00029900724449131424 Training loss: 10.374015808105469
2025-12-09 12:12:30.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.00029899672310758243 Training loss: 10.128114700317383
2025-12-09 12:12:30.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0002989861464507569 Training loss: 10.19479751586914
2025-12-09 12:12:30.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.0002989755145247613 Training loss: 10.092523574829102
2025-12-09 12:12:30.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.00029896482733353965 Training loss: 10.220696449279785
2025-12-09 12:12:30.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.00029895408488105665 Training loss: 10.186626434326172
2025-12-09 12:12:30.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0002989432871712973 Training loss: 10.002731323242188
2025-12-09 12:12:31.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.0002989324342082673 Training loss: 10.087414741516113
2025-12-09 12:12:31.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.00029892152599599275 Training loss: 10.085741996765137
2025-12-09 12:12:31.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.00029891056253852026 Training loss: 10.335282325744629
2025-12-09 12:12:31.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.0002988995438399169 Training loss: 9.97880744934082
2025-12-09 12:12:31.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0002988884699042702 Training loss: 10.162528991699219
2025-12-09 12:12:31.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0002988773407356884 Training loss: 10.124772071838379
2025-12-09 12:12:31.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.0002988661563382999 Training loss: 10.199373245239258
2025-12-09 12:12:31.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0002988549167162539 Training loss: 10.070443153381348
2025-12-09 12:12:31.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.00029884362187371986 Training loss: 10.056851387023926
2025-12-09 12:12:31.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0002988322718148878 Training loss: 10.41404914855957
2025-12-09 12:12:31.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0002988208665439683 Training loss: 10.091659545898438
2025-12-09 12:12:31.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.0002988094060651923 Training loss: 10.053655624389648
2025-12-09 12:12:31.953 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0002987978903828114 Training loss: 10.519944190979004
2025-12-09 12:12:32.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.00029878631950109734 Training loss: 10.071942329406738
2025-12-09 12:12:32.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.0002987746934243427 Training loss: 10.089301109313965
2025-12-09 12:12:32.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0002987630121568604 Training loss: 10.569732666015625
2025-12-09 12:12:32.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.00029875127570298376 Training loss: 10.064719200134277
2025-12-09 12:12:32.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0002987394840670666 Training loss: 10.22564697265625
2025-12-09 12:12:32.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0002987276372534834 Training loss: 10.127655029296875
2025-12-09 12:12:32.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.0002987157352666288 Training loss: 10.191116333007812
2025-12-09 12:12:32.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0002987037781109182 Training loss: 10.253289222717285
2025-12-09 12:12:32.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.00029869176579078714 Training loss: 10.065923690795898
2025-12-09 12:12:32.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.000298679698310692 Training loss: 10.13968563079834
2025-12-09 12:12:32.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.00029866757567510927 Training loss: 10.406425476074219
2025-12-09 12:12:32.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0002986553978885362 Training loss: 10.073702812194824
2025-12-09 12:12:32.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.00029864316495549037 Training loss: 10.137594223022461
2025-12-09 12:12:33.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.0002986308768805097 Training loss: 10.142056465148926
2025-12-09 12:12:33.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.00029861853366815275 Training loss: 10.282981872558594
2025-12-09 12:12:33.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.00029860613532299845 Training loss: 10.221277236938477
2025-12-09 12:12:33.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.00029859368184964624 Training loss: 10.363560676574707
2025-12-09 12:12:33.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.00029858117325271585 Training loss: 10.196810722351074
2025-12-09 12:12:33.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.00029856860953684773 Training loss: 10.001590728759766
2025-12-09 12:12:33.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0002985559907067025 Training loss: 9.998418807983398
2025-12-09 12:12:33.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.00029854331676696137 Training loss: 10.184745788574219
2025-12-09 12:12:33.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.000298530587722326 Training loss: 9.832910537719727
2025-12-09 12:12:33.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.00029851780357751853 Training loss: 10.1554536819458
2025-12-09 12:12:33.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.00029850496433728136 Training loss: 10.126254081726074
2025-12-09 12:12:33.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0002984920700063775 Training loss: 10.014954566955566
2025-12-09 12:12:33.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.00029847912058959033 Training loss: 10.058953285217285
2025-12-09 12:12:34.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.00029846611609172363 Training loss: 10.312658309936523
2025-12-09 12:12:34.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.00029845305651760175 Training loss: 9.693077087402344
2025-12-09 12:12:34.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.00029843994187206933 Training loss: 10.272215843200684
2025-12-09 12:12:34.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.0002984267721599915 Training loss: 10.254924774169922
2025-12-09 12:12:34.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.0002984135473862538 Training loss: 9.990497589111328
2025-12-09 12:12:34.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.0002984002675557622 Training loss: 10.104690551757812
2025-12-09 12:12:34.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.0002983869326734432 Training loss: 10.012210845947266
2025-12-09 12:12:34.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.0002983735427442434 Training loss: 9.90909194946289
2025-12-09 12:12:34.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.00029836009777313026 Training loss: 10.10096549987793
2025-12-09 12:12:34.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.00029834659776509134 Training loss: 10.039717674255371
2025-12-09 12:12:34.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.0002983330427251347 Training loss: 9.980509757995605
2025-12-09 12:12:34.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.0002983194326582889 Training loss: 10.009613037109375
2025-12-09 12:12:34.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0002983057675696028 Training loss: 10.258275985717773
2025-12-09 12:12:34.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0002982920474641457 Training loss: 10.014641761779785
2025-12-09 12:12:35.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0002982782723470074 Training loss: 10.181526184082031
2025-12-09 12:12:35.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.000298264442223298 Training loss: 9.843101501464844
2025-12-09 12:12:35.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.00029825055709814795 Training loss: 9.840873718261719
2025-12-09 12:12:35.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.00029823661697670834 Training loss: 10.035858154296875
2025-12-09 12:12:35.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.00029822262186415046 Training loss: 9.899924278259277
2025-12-09 12:12:35.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.00029820857176566606 Training loss: 10.096449851989746
2025-12-09 12:12:35.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0002981944666864672 Training loss: 10.167098999023438
2025-12-09 12:12:35.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0002981803066317865 Training loss: 9.953062057495117
2025-12-09 12:12:35.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.00029816609160687697 Training loss: 10.209781646728516
2025-12-09 12:12:35.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.0002981518216170118 Training loss: 9.977590560913086
2025-12-09 12:12:35.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0002981374966674848 Training loss: 10.03300666809082
2025-12-09 12:12:35.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.00029812311676361003 Training loss: 9.98095417022705
2025-12-09 12:12:35.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.00029810868191072195 Training loss: 10.115490913391113
2025-12-09 12:12:36.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.00029809419211417553 Training loss: 10.125734329223633
2025-12-09 12:12:36.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.0002980796473793459 Training loss: 10.07544231414795
2025-12-09 12:12:36.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0002980650477116288 Training loss: 10.363219261169434
2025-12-09 12:12:36.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.00029805039311644023 Training loss: 10.005763053894043
2025-12-09 12:12:36.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.0002980356835992166 Training loss: 9.868036270141602
2025-12-09 12:12:36.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.0002980209191654146 Training loss: 9.805890083312988
2025-12-09 12:12:36.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.00029800609982051147 Training loss: 10.297268867492676
2025-12-09 12:12:36.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.0002979912255700046 Training loss: 10.076053619384766
2025-12-09 12:12:36.677 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.000297976296419412 Training loss: 10.030438423156738
2025-12-09 12:12:36.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.00029796131237427186 Training loss: 9.951580047607422
2025-12-09 12:12:36.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.00029794627344014276 Training loss: 9.992178916931152
2025-12-09 12:12:36.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.00029793117962260366 Training loss: 9.989237785339355
2025-12-09 12:12:36.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.000297916030927254 Training loss: 10.054617881774902
2025-12-09 12:12:37.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.0002979008273597133 Training loss: 9.871161460876465
2025-12-09 12:12:37.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.0002978855689256218 Training loss: 9.92967700958252
2025-12-09 12:12:37.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.00029787025563063975 Training loss: 9.8855619430542
2025-12-09 12:12:37.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.0002978548874804479 Training loss: 9.945246696472168
2025-12-09 12:12:37.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.0002978394644807475 Training loss: 10.086456298828125
2025-12-09 12:12:37.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.0002978239866372598 Training loss: 10.188660621643066
2025-12-09 12:12:37.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.00029780845395572673 Training loss: 10.00741958618164
2025-12-09 12:12:37.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.0002977928664419104 Training loss: 9.870856285095215
2025-12-09 12:12:37.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.0002977772241015933 Training loss: 9.979585647583008
2025-12-09 12:12:37.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.00029776152694057815 Training loss: 9.759254455566406
2025-12-09 12:12:37.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0002977457749646882 Training loss: 10.191426277160645
2025-12-09 12:12:37.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.00029772996817976693 Training loss: 9.966717720031738
2025-12-09 12:12:37.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.00029771410659167806 Training loss: 10.116772651672363
2025-12-09 12:12:38.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.00029769819020630594 Training loss: 10.331995010375977
2025-12-09 12:12:38.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0002976822190295548 Training loss: 9.995214462280273
2025-12-09 12:12:38.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.00029766619306734963 Training loss: 9.823144912719727
2025-12-09 12:12:38.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0002976501123256355 Training loss: 10.073469161987305
2025-12-09 12:12:38.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.00029763397681037787 Training loss: 9.941010475158691
2025-12-09 12:12:38.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.00029761778652756245 Training loss: 9.906798362731934
2025-12-09 12:12:38.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.00029760154148319534 Training loss: 9.9848051071167
2025-12-09 12:12:38.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.000297585241683303 Training loss: 9.978148460388184
2025-12-09 12:12:38.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.00029756888713393213 Training loss: 10.149748802185059
2025-12-09 12:12:38.739 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.00029755247784114976 Training loss: 9.861799240112305
2025-12-09 12:12:38.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.0002975360138110431 Training loss: 10.014798164367676
2025-12-09 12:12:38.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.00029751949504972 Training loss: 9.92918586730957
2025-12-09 12:12:38.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0002975029215633082 Training loss: 9.853584289550781
2025-12-09 12:12:39.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.000297486293357956 Training loss: 9.923810958862305
2025-12-09 12:12:39.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.00029746961043983206 Training loss: 10.318513870239258
2025-12-09 12:12:39.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.00029745287281512505 Training loss: 10.069185256958008
2025-12-09 12:12:39.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.0002974360804900442 Training loss: 10.094100952148438
2025-12-09 12:12:39.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.0002974192334708189 Training loss: 9.943717002868652
2025-12-09 12:12:39.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.00029740233176369887 Training loss: 10.030463218688965
2025-12-09 12:12:39.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.0002973853753749541 Training loss: 10.12269115447998
2025-12-09 12:12:39.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.00029736836431087493 Training loss: 10.3635892868042
2025-12-09 12:12:39.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.00029735129857777183 Training loss: 10.018526077270508
2025-12-09 12:12:39.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.00029733417818197575 Training loss: 10.199953079223633
2025-12-09 12:12:39.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.00029731700312983776 Training loss: 9.83073616027832
2025-12-09 12:12:39.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.0002972997734277293 Training loss: 9.901604652404785
2025-12-09 12:12:39.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.000297282489082042 Training loss: 9.795276641845703
2025-12-09 12:12:40.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.00029726515009918786 Training loss: 9.964009284973145
2025-12-09 12:12:40.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.0002972477564855991 Training loss: 9.914778709411621
2025-12-09 12:12:40.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0002972303082477281 Training loss: 9.893509864807129
2025-12-09 12:12:40.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.00029721280539204774 Training loss: 10.049592971801758
2025-12-09 12:12:40.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.0002971952479250509 Training loss: 9.93450927734375
2025-12-09 12:12:40.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.000297177635853251 Training loss: 9.93813705444336
2025-12-09 12:12:40.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.0002971599691831815 Training loss: 9.88200855255127
2025-12-09 12:12:40.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.00029714224792139605 Training loss: 10.116305351257324
2025-12-09 12:12:40.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.0002971244720744688 Training loss: 9.770888328552246
2025-12-09 12:12:40.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.00029710664164899413 Training loss: 10.063304901123047
2025-12-09 12:12:40.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.0002970887566515864 Training loss: 9.988494873046875
2025-12-09 12:12:40.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.0002970708170888804 Training loss: 10.046853065490723
2025-12-09 12:12:40.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.0002970528229675312 Training loss: 9.766763687133789
2025-12-09 12:12:41.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.0002970347742942141 Training loss: 9.468742370605469
2025-12-09 12:12:41.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.0002970166710756244 Training loss: 9.677972793579102
2025-12-09 12:12:41.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.0002969985133184781 Training loss: 9.823941230773926
2025-12-09 12:12:41.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0002969803010295109 Training loss: 10.363134384155273
2025-12-09 12:12:41.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0002969620342154791 Training loss: 10.021533966064453
2025-12-09 12:12:41.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.0002969437128831591 Training loss: 10.266617774963379
2025-12-09 12:12:41.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.00029692533703934757 Training loss: 9.945967674255371
2025-12-09 12:12:41.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.00029690690669086127 Training loss: 10.068029403686523
2025-12-09 12:12:41.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0002968884218445374 Training loss: 9.920591354370117
2025-12-09 12:12:41.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.0002968698825072332 Training loss: 9.987085342407227
2025-12-09 12:12:41.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.0002968512886858262 Training loss: 10.015768051147461
2025-12-09 12:12:41.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.00029683264038721414 Training loss: 9.93222713470459
2025-12-09 12:12:41.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.00029681393761831485 Training loss: 10.135669708251953
2025-12-09 12:12:42.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.0002967951803860665 Training loss: 10.057148933410645
2025-12-09 12:12:42.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.0002967763686974276 Training loss: 10.234457015991211
2025-12-09 12:12:42.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.00029675750255937647 Training loss: 9.891582489013672
2025-12-09 12:12:42.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.000296738581978912 Training loss: 10.289884567260742
2025-12-09 12:12:42.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.00029671960696305304 Training loss: 9.81190013885498
2025-12-09 12:12:42.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.00029670057751883874 Training loss: 9.884832382202148
2025-12-09 12:12:42.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.0002966814936533285 Training loss: 9.538235664367676
2025-12-09 12:12:42.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.00029666235537360175 Training loss: 9.729692459106445
2025-12-09 12:12:42.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.00029664316268675824 Training loss: 9.927912712097168
2025-12-09 12:12:42.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0002966239155999178 Training loss: 10.242748260498047
2025-12-09 12:12:42.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.0002966046141202205 Training loss: 9.847628593444824
2025-12-09 12:12:42.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.0002965852582548267 Training loss: 9.995469093322754
2025-12-09 12:12:42.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.00029656584801091663 Training loss: 10.101978302001953
2025-12-09 12:12:43.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.000296546383395691 Training loss: 9.898446083068848
2025-12-09 12:12:43.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.00029652686441637054 Training loss: 9.984335899353027
2025-12-09 12:12:43.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.00029650729108019624 Training loss: 9.77021312713623
2025-12-09 12:12:43.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.0002964876633944291 Training loss: 9.860706329345703
2025-12-09 12:12:43.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.00029646798136635034 Training loss: 9.695486068725586
2025-12-09 12:12:43.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.0002964482450032615 Training loss: 9.816991806030273
2025-12-09 12:12:43.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.00029642845431248406 Training loss: 9.984134674072266
2025-12-09 12:12:43.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.0002964086093013597 Training loss: 9.827773094177246
2025-12-09 12:12:43.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.00029638870997725046 Training loss: 9.91956901550293
2025-12-09 12:12:43.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.00029636875634753824 Training loss: 9.801152229309082
2025-12-09 12:12:43.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.00029634874841962525 Training loss: 10.236054420471191
2025-12-09 12:12:43.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.00029632868620093375 Training loss: 9.938858032226562
2025-12-09 12:12:43.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.0002963085696989063 Training loss: 10.299359321594238
2025-12-09 12:12:44.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.00029628839892100535 Training loss: 9.836743354797363
2025-12-09 12:12:44.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.00029626817387471365 Training loss: 9.88934326171875
2025-12-09 12:12:44.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.00029624789456753417 Training loss: 9.767144203186035
2025-12-09 12:12:44.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.00029622756100698976 Training loss: 9.736184120178223
2025-12-09 12:12:44.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.0002962071732006237 Training loss: 9.951154708862305
2025-12-09 12:12:44.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.00029618673115599896 Training loss: 9.948554039001465
2025-12-09 12:12:44.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.0002961662348806992 Training loss: 10.267561912536621
2025-12-09 12:12:44.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.00029614568438232766 Training loss: 9.946659088134766
2025-12-09 12:12:44.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.000296125079668508 Training loss: 9.903874397277832
2025-12-09 12:12:44.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.00029610442074688394 Training loss: 10.161697387695312
2025-12-09 12:12:44.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.00029608370762511935 Training loss: 9.820652961730957
2025-12-09 12:12:44.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.000296062940310898 Training loss: 9.987106323242188
2025-12-09 12:12:44.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.000296042118811924 Training loss: 10.04458999633789
2025-12-09 12:12:44.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.0002960212431359215 Training loss: 10.10774040222168
2025-12-09 12:12:45.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.00029600031329063463 Training loss: 9.849552154541016
2025-12-09 12:12:45.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.0002959793292838277 Training loss: 10.078547477722168
2025-12-09 12:12:45.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.0002959582911232853 Training loss: 10.314032554626465
2025-12-09 12:12:45.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.00029593719881681167 Training loss: 9.797734260559082
2025-12-09 12:12:45.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.00029591605237223157 Training loss: 10.049421310424805
2025-12-09 12:12:45.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0002958948517973896 Training loss: 9.827144622802734
2025-12-09 12:12:45.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0002958735971001505 Training loss: 9.969112396240234
2025-12-09 12:12:45.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.0002958522882883991 Training loss: 10.009438514709473
2025-12-09 12:12:45.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.0002958309253700404 Training loss: 10.098771095275879
2025-12-09 12:12:45.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.00029580950835299914 Training loss: 10.135249137878418
2025-12-09 12:12:45.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0002957880372452206 Training loss: 9.835610389709473
2025-12-09 12:12:45.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.0002957665120546697 Training loss: 9.854670524597168
2025-12-09 12:12:45.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.0002957449327893317 Training loss: 9.565245628356934
2025-12-09 12:12:46.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.00029572329945721186 Training loss: 9.858476638793945
2025-12-09 12:12:46.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.0002957016120663354 Training loss: 9.804207801818848
2025-12-09 12:12:46.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.00029567987062474767 Training loss: 9.80837631225586
2025-12-09 12:12:46.295 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.00029565807514051406 Training loss: 9.8768892288208
2025-12-09 12:12:46.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.0002956362256217201 Training loss: 9.888572692871094
2025-12-09 12:12:46.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.0002956143220764711 Training loss: 10.090165138244629
2025-12-09 12:12:46.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.0002955923645128927 Training loss: 9.966164588928223
2025-12-09 12:12:46.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.00029557035293913044 Training loss: 9.788026809692383
2025-12-09 12:12:46.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.00029554828736334994 Training loss: 9.982218742370605
2025-12-09 12:12:46.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0002955261677937368 Training loss: 9.505640029907227
2025-12-09 12:12:46.831 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.00029550399423849673 Training loss: 10.004497528076172
2025-12-09 12:12:46.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.0002954817667058554 Training loss: 9.748290061950684
2025-12-09 12:12:46.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.00029545948520405844 Training loss: 9.883732795715332
2025-12-09 12:12:47.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.00029543714974137177 Training loss: 9.696683883666992
2025-12-09 12:12:47.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.000295414760326081 Training loss: 9.841897964477539
2025-12-09 12:12:47.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.0002953923169664919 Training loss: 9.821382522583008
2025-12-09 12:12:47.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.00029536981967093033 Training loss: 9.81634521484375
2025-12-09 12:12:47.363 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.00029534726844774196 Training loss: 10.38624382019043
2025-12-09 12:12:47.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.00029532466330529277 Training loss: 9.8976469039917
2025-12-09 12:12:47.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.00029530200425196835 Training loss: 9.84871768951416
2025-12-09 12:12:47.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.00029527929129617464 Training loss: 9.748302459716797
2025-12-09 12:12:47.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.00029525652444633736 Training loss: 9.9818754196167
2025-12-09 12:12:47.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.0002952337037109023 Training loss: 10.00219440460205
2025-12-09 12:12:47.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.0002952108290983353 Training loss: 9.85032844543457
2025-12-09 12:12:47.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.00029518790061712204 Training loss: 9.651104927062988
2025-12-09 12:12:47.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.0002951649182757683 Training loss: 9.948134422302246
2025-12-09 12:12:48.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.00029514188208279977 Training loss: 10.191503524780273
2025-12-09 12:12:48.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.0002951187920467622 Training loss: 9.857748031616211
2025-12-09 12:12:48.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0002950956481762213 Training loss: 9.952203750610352
2025-12-09 12:12:48.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0002950724504797626 Training loss: 9.853635787963867
2025-12-09 12:12:48.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.0002950491989659918 Training loss: 9.920557975769043
2025-12-09 12:12:48.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.00029502589364353447 Training loss: 9.877180099487305
2025-12-09 12:12:48.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.00029500253452103615 Training loss: 9.935100555419922
2025-12-09 12:12:48.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.00029497912160716234 Training loss: 9.898710250854492
2025-12-09 12:12:48.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.0002949556549105985 Training loss: 9.926079750061035
2025-12-09 12:12:48.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.00029493213444005 Training loss: 9.792200088500977
2025-12-09 12:12:48.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.0002949085602042422 Training loss: 9.881258010864258
2025-12-09 12:12:48.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.00029488493221192043 Training loss: 9.807999610900879
2025-12-09 12:12:48.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.00029486125047184985 Training loss: 9.941967010498047
2025-12-09 12:12:49.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.0002948375149928158 Training loss: 9.583479881286621
2025-12-09 12:12:49.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.0002948137257836233 Training loss: 9.707866668701172
2025-12-09 12:12:49.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.0002947898828530974 Training loss: 9.867273330688477
2025-12-09 12:12:49.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.000294765986210083 Training loss: 9.869650840759277
2025-12-09 12:12:49.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0002947420358634451 Training loss: 9.806166648864746
2025-12-09 12:12:49.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.00029471803182206855 Training loss: 9.685612678527832
2025-12-09 12:12:49.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.000294693974094858 Training loss: 10.006243705749512
2025-12-09 12:12:49.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.0002946698626907382 Training loss: 9.90804672241211
2025-12-09 12:12:49.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.00029464569761865366 Training loss: 9.563207626342773
2025-12-09 12:12:49.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.0002946214788875689 Training loss: 9.993609428405762
2025-12-09 12:12:49.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.00029459720650646824 Training loss: 9.710834503173828
2025-12-09 12:12:49.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.00029457288048435605 Training loss: 9.792154312133789
2025-12-09 12:12:49.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.00029454850083025644 Training loss: 9.924492835998535
2025-12-09 12:12:50.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.0002945240675532136 Training loss: 9.689571380615234
2025-12-09 12:12:50.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.0002944995806622914 Training loss: 9.779256820678711
2025-12-09 12:12:50.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.0002944750401665738 Training loss: 9.86080551147461
2025-12-09 12:12:50.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.00029445044607516447 Training loss: 9.224464416503906
2025-12-09 12:12:50.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.00029442579839718703 Training loss: 9.947527885437012
2025-12-09 12:12:50.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.0002944010971417851 Training loss: 9.575003623962402
2025-12-09 12:12:50.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.000294376342318122 Training loss: 9.543170928955078
2025-12-09 12:12:50.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.000294351533935381 Training loss: 9.789997100830078
2025-12-09 12:12:50.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.00029432667200276515 Training loss: 9.838831901550293
2025-12-09 12:12:50.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0002943017565294976 Training loss: 9.757540702819824
2025-12-09 12:12:50.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.0002942767875248211 Training loss: 9.690091133117676
2025-12-09 12:12:50.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.0002942517649979984 Training loss: 9.818951606750488
2025-12-09 12:12:50.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.00029422668895831203 Training loss: 9.934748649597168
2025-12-09 12:12:51.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.00029420155941506447 Training loss: 9.890661239624023
2025-12-09 12:12:51.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.00029417637637757797 Training loss: 9.758182525634766
2025-12-09 12:12:51.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.00029415113985519463 Training loss: 9.829696655273438
2025-12-09 12:12:51.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.0002941258498572764 Training loss: 9.785337448120117
2025-12-09 12:12:51.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.0002941005063932051 Training loss: 9.910271644592285
2025-12-09 12:12:51.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.0002940751094723823 Training loss: 9.80529499053955
2025-12-09 12:12:51.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.00029404965910422953 Training loss: 10.300970077514648
2025-12-09 12:12:51.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.00029402415529818804 Training loss: 9.089458465576172
2025-12-09 12:12:51.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.00029399859806371895 Training loss: 9.783394813537598
2025-12-09 12:12:51.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.0002939729874103032 Training loss: 9.731389999389648
2025-12-09 12:12:51.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.00029394732334744146 Training loss: 9.594527244567871
2025-12-09 12:12:51.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.00029392160588465434 Training loss: 9.653002738952637
2025-12-09 12:12:51.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.0002938958350314823 Training loss: 9.690028190612793
2025-12-09 12:12:52.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.00029387001079748536 Training loss: 9.651650428771973
2025-12-09 12:12:52.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.0002938441331922436 Training loss: 9.812296867370605
2025-12-09 12:12:52.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.0002938182022253568 Training loss: 9.892922401428223
2025-12-09 12:12:52.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.0002937922179064445 Training loss: 10.049694061279297
2025-12-09 12:12:52.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.000293766180245146 Training loss: 9.760680198669434
2025-12-09 12:12:52.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.00029374008925112056 Training loss: 9.901992797851562
2025-12-09 12:12:52.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.00029371394493404705 Training loss: 9.853615760803223
2025-12-09 12:12:52.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.00029368774730362425 Training loss: 9.653948783874512
2025-12-09 12:12:52.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.0002936614963695706 Training loss: 10.02747917175293
2025-12-09 12:12:52.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.0002936351921416244 Training loss: 10.05627727508545
2025-12-09 12:12:52.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.0002936088346295436 Training loss: 9.689678192138672
2025-12-09 12:12:52.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.0002935824238431062 Training loss: 10.062873840332031
2025-12-09 12:12:52.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.0002935559597921096 Training loss: 9.825339317321777
2025-12-09 12:12:53.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.00029352944248637117 Training loss: 9.80571460723877
2025-12-09 12:12:53.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.00029350287193572806 Training loss: 10.104342460632324
2025-12-09 12:12:53.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.000293476248150037 Training loss: 9.651091575622559
2025-12-09 12:12:53.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.00029344957113917473 Training loss: 9.656389236450195
2025-12-09 12:12:53.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.0002934228409130374 Training loss: 9.684293746948242
2025-12-09 12:12:53.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.0002933960574815412 Training loss: 10.036836624145508
2025-12-09 12:12:53.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.0002933692208546219 Training loss: 9.849530220031738
2025-12-09 12:12:53.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.00029334233104223506 Training loss: 9.7698974609375
2025-12-09 12:12:53.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.00029331538805435595 Training loss: 9.75167465209961
2025-12-09 12:12:53.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.00029328839190097955 Training loss: 9.707232475280762
2025-12-09 12:12:53.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.00029326134259212064 Training loss: 9.660272598266602
2025-12-09 12:12:53.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.0002932342401378136 Training loss: 9.883474349975586
2025-12-09 12:12:53.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.0002932070845481126 Training loss: 9.94295597076416
2025-12-09 12:12:54.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.00029317987583309156 Training loss: 10.057422637939453
2025-12-09 12:12:54.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.00029315261400284404 Training loss: 9.874070167541504
2025-12-09 12:12:54.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0002931252990674832 Training loss: 9.974655151367188
2025-12-09 12:12:54.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.0002930979310371422 Training loss: 9.771224021911621
2025-12-09 12:12:54.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.0002930705099219736 Training loss: 9.780450820922852
2025-12-09 12:12:54.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.0002930430357321498 Training loss: 10.080830574035645
2025-12-09 12:12:54.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.0002930155084778629 Training loss: 9.665655136108398
2025-12-09 12:12:54.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.0002929879281693246 Training loss: 9.81897258758545
2025-12-09 12:12:54.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.0002929602948167663 Training loss: 9.739415168762207
2025-12-09 12:12:54.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.0002929326084304392 Training loss: 9.997560501098633
2025-12-09 12:12:54.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.00029290486902061396 Training loss: 9.633095741271973
2025-12-09 12:12:54.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0002928770765975811 Training loss: 9.498291969299316
2025-12-09 12:12:54.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.00029284923117165075 Training loss: 9.908316612243652
2025-12-09 12:12:55.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.0002928213327531526 Training loss: 9.756298065185547
2025-12-09 12:12:55.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.00029279338135243624 Training loss: 9.812602043151855
2025-12-09 12:12:55.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.0002927653769798706 Training loss: 10.01568603515625
2025-12-09 12:12:55.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.00029273731964584446 Training loss: 9.655289649963379
2025-12-09 12:12:55.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.00029270920936076624 Training loss: 9.578282356262207
2025-12-09 12:12:55.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.00029268104613506396 Training loss: 10.113606452941895
2025-12-09 12:12:55.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.00029265282997918533 Training loss: 9.981468200683594
2025-12-09 12:12:55.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.00029262456090359756 Training loss: 9.714166641235352
2025-12-09 12:12:55.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.0002925962389187877 Training loss: 9.97215747833252
2025-12-09 12:12:55.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.0002925678640352622 Training loss: 9.930206298828125
2025-12-09 12:12:55.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.00029253943626354734 Training loss: 9.56727123260498
2025-12-09 12:12:55.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0002925109556141889 Training loss: 9.744378089904785
2025-12-09 12:12:55.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0002924824220977523 Training loss: 9.88378620147705
2025-12-09 12:12:55.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.0002924538357248226 Training loss: 9.926321029663086
2025-12-09 12:12:56.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.00029242519650600436 Training loss: 9.984091758728027
2025-12-09 12:12:56.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.0002923965044519219 Training loss: 9.861323356628418
2025-12-09 12:12:56.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.0002923677595732191 Training loss: 9.760300636291504
2025-12-09 12:12:56.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0002923389618805593 Training loss: 9.273086547851562
2025-12-09 12:12:56.376 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.00029231011138462564 Training loss: 9.985840797424316
2025-12-09 12:12:56.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.0002922812080961207 Training loss: 9.662694931030273
2025-12-09 12:12:56.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.0002922522520257667 Training loss: 10.052870750427246
2025-12-09 12:12:56.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.0002922232431843054 Training loss: 9.62685775756836
2025-12-09 12:12:56.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.00029219418158249824 Training loss: 9.771490097045898
2025-12-09 12:12:56.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.0002921650672311261 Training loss: 9.81940746307373
2025-12-09 12:12:56.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.0002921359001409895 Training loss: 9.599472999572754
2025-12-09 12:12:56.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.0002921066803229085 Training loss: 9.570069313049316
2025-12-09 12:12:56.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.00029207740778772277 Training loss: 9.819734573364258
2025-12-09 12:12:57.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.00029204808254629146 Training loss: 9.657517433166504
2025-12-09 12:12:57.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.00029201870460949326 Training loss: 9.659159660339355
2025-12-09 12:12:57.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.00029198927398822657 Training loss: 9.623983383178711
2025-12-09 12:12:57.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.0002919597906934092 Training loss: 9.488609313964844
2025-12-09 12:12:57.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.0002919302547359785 Training loss: 9.979863166809082
2025-12-09 12:12:57.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0002919006661268914 Training loss: 9.868131637573242
2025-12-09 12:12:57.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0002918710248771243 Training loss: 9.82279109954834
2025-12-09 12:12:57.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.0002918413309976732 Training loss: 9.986673355102539
2025-12-09 12:12:57.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.00029181158449955363 Training loss: 10.037049293518066
2025-12-09 12:12:57.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.0002917817853938005 Training loss: 9.907958030700684
2025-12-09 12:12:57.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.0002917519336914684 Training loss: 9.83513355255127
2025-12-09 12:12:57.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.00029172202940363145 Training loss: 10.07021713256836
2025-12-09 12:12:57.982 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0002916920725413831 Training loss: 10.268266677856445
2025-12-09 12:12:58.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.00029166206311583644 Training loss: 9.4661865234375
2025-12-09 12:12:58.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.000291632001138124 Training loss: 9.446307182312012
2025-12-09 12:12:58.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0002916018866193978 Training loss: 9.500348091125488
2025-12-09 12:12:58.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.0002915717195708295 Training loss: 9.741212844848633
2025-12-09 12:12:58.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.00029154150000360995 Training loss: 9.790919303894043
2025-12-09 12:12:58.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.00029151122792894985 Training loss: 9.956823348999023
2025-12-09 12:12:58.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.000291480903358079 Training loss: 9.693615913391113
2025-12-09 12:12:58.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.00029145052630224696 Training loss: 9.861384391784668
2025-12-09 12:12:58.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0002914200967727227 Training loss: 9.684662818908691
2025-12-09 12:12:58.748 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.00029138961478079455 Training loss: 10.058381080627441
2025-12-09 12:12:58.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.00029135908033777033 Training loss: 9.797011375427246
2025-12-09 12:12:58.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.00029132849345497755 Training loss: 9.522604942321777
2025-12-09 12:12:58.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.00029129785414376276 Training loss: 9.818205833435059
2025-12-09 12:12:59.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.00029126716241549224 Training loss: 10.06199836730957
2025-12-09 12:12:59.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0002912364182815517 Training loss: 9.782411575317383
2025-12-09 12:12:59.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.00029120562175334624 Training loss: 9.577971458435059
2025-12-09 12:12:59.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0002911747728423004 Training loss: 9.799596786499023
2025-12-09 12:12:59.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.00029114387155985814 Training loss: 9.767776489257812
2025-12-09 12:12:59.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.0002911129179174828 Training loss: 9.701967239379883
2025-12-09 12:12:59.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.00029108191192665734 Training loss: 9.80141830444336
2025-12-09 12:12:59.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.00029105085359888396 Training loss: 9.669544219970703
2025-12-09 12:12:59.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.00029101974294568425 Training loss: 9.750006675720215
2025-12-09 12:12:59.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.0002909885799785993 Training loss: 9.937758445739746
2025-12-09 12:12:59.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.0002909573647091897 Training loss: 9.842612266540527
2025-12-09 12:12:59.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.00029092609714903523 Training loss: 9.728053092956543
2025-12-09 12:12:59.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.00029089477730973517 Training loss: 9.488540649414062
2025-12-09 12:13:00.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.0002908634052029083 Training loss: 9.722572326660156
2025-12-09 12:13:00.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.0002908319808401925 Training loss: 9.859066009521484
2025-12-09 12:13:00.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0002908005042332454 Training loss: 9.803285598754883
2025-12-09 12:13:00.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.00029076897539374375 Training loss: 9.846803665161133
2025-12-09 12:13:00.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.00029073739433338377 Training loss: 9.69784927368164
2025-12-09 12:13:00.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.000290705761063881 Training loss: 9.978041648864746
2025-12-09 12:13:00.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.00029067407559697046 Training loss: 9.738272666931152
2025-12-09 12:13:00.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.0002906423379444063 Training loss: 9.781319618225098
2025-12-09 12:13:00.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.00029061054811796243 Training loss: 9.56656551361084
2025-12-09 12:13:00.748 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.0002905787061294317 Training loss: 9.937498092651367
2025-12-09 12:13:00.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.00029054681199062657 Training loss: 9.617608070373535
2025-12-09 12:13:00.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.00029051486571337877 Training loss: 9.897047996520996
2025-12-09 12:13:00.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.00029048286730953924 Training loss: 9.715890884399414
2025-12-09 12:13:01.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.0002904508167909785 Training loss: 9.724297523498535
2025-12-09 12:13:01.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.00029041871416958623 Training loss: 9.602107048034668
2025-12-09 12:13:01.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.00029038655945727153 Training loss: 9.809417724609375
2025-12-09 12:13:01.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.0002903543526659628 Training loss: 9.62078857421875
2025-12-09 12:13:01.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.00029032209380760765 Training loss: 9.774953842163086
2025-12-09 12:13:01.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.0002902897828941732 Training loss: 9.62644100189209
2025-12-09 12:13:01.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.0002902574199376457 Training loss: 9.671622276306152
2025-12-09 12:13:01.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.00029022500495003086 Training loss: 9.720191955566406
2025-12-09 12:13:01.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.0002901925379433536 Training loss: 9.794181823730469
2025-12-09 12:13:01.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.0002901600189296581 Training loss: 9.782747268676758
2025-12-09 12:13:01.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.000290127447921008 Training loss: 10.346933364868164
2025-12-09 12:13:01.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.00029009482492948607 Training loss: 9.684854507446289
2025-12-09 12:13:01.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.00029006214996719437 Training loss: 9.732986450195312
2025-12-09 12:13:02.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.0002900294230462543 Training loss: 9.544829368591309
2025-12-09 12:13:02.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.00028999664417880654 Training loss: 9.867680549621582
2025-12-09 12:13:02.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.000289963813377011 Training loss: 9.834282875061035
2025-12-09 12:13:02.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.0002899309306530469 Training loss: 9.519745826721191
2025-12-09 12:13:02.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.0002898979960191127 Training loss: 9.617898941040039
2025-12-09 12:13:02.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.000289865009487426 Training loss: 9.513800621032715
2025-12-09 12:13:02.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.00028983197107022396 Training loss: 9.693925857543945
2025-12-09 12:13:02.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.0002897988807797627 Training loss: 9.574214935302734
2025-12-09 12:13:02.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.00028976573862831757 Training loss: 9.774344444274902
2025-12-09 12:13:02.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.0002897325446281834 Training loss: 9.882477760314941
2025-12-09 12:13:02.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.0002896992987916741 Training loss: 9.730926513671875
2025-12-09 12:13:02.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.00028966600113112276 Training loss: 9.746660232543945
2025-12-09 12:13:02.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.00028963265165888187 Training loss: 9.818414688110352
2025-12-09 12:13:03.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.00028959925038732294 Training loss: 9.677484512329102
2025-12-09 12:13:03.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.00028956579732883684 Training loss: 9.705652236938477
2025-12-09 12:13:03.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.00028953229249583355 Training loss: 9.65112018585205
2025-12-09 12:13:03.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.0002894987359007424 Training loss: 9.88802433013916
2025-12-09 12:13:03.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.00028946512755601174 Training loss: 9.226844787597656
2025-12-09 12:13:03.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.0002894314674741092 Training loss: 9.774798393249512
2025-12-09 12:13:03.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.00028939775566752177 Training loss: 9.191145896911621
2025-12-09 12:13:03.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.00028936399214875524 Training loss: 9.785577774047852
2025-12-09 12:13:03.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.000289330176930335 Training loss: 9.335333824157715
2025-12-09 12:13:03.734 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.0002892963100248053 Training loss: 9.829625129699707
2025-12-09 12:13:03.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.0002892623914447298 Training loss: 9.566803932189941
2025-12-09 12:13:03.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.00028922842120269115 Training loss: 9.647436141967773
