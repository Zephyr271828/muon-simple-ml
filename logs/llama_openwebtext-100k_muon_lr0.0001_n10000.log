2025-12-09 12:13:34.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 12.201460838317871
2025-12-09 12:13:34.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 12.198165893554688
2025-12-09 12:13:35.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 12.148820877075195
2025-12-09 12:13:35.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 12.130343437194824
2025-12-09 12:13:36.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 12.205236434936523
2025-12-09 12:13:36.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 12.147665977478027
2025-12-09 12:13:37.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 12.14795207977295
2025-12-09 12:13:37.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 12.15354061126709
2025-12-09 12:13:37.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 12.1448392868042
2025-12-09 12:13:38.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 12.139297485351562
2025-12-09 12:13:38.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 12.1558256149292
2025-12-09 12:13:39.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 12.144689559936523
2025-12-09 12:13:39.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 12.119601249694824
2025-12-09 12:13:40.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 12.113824844360352
2025-12-09 12:13:40.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 12.133066177368164
2025-12-09 12:13:41.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 12.171608924865723
2025-12-09 12:13:41.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 12.105823516845703
2025-12-09 12:13:42.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 12.133622169494629
2025-12-09 12:13:42.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 12.083449363708496
2025-12-09 12:13:43.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 12.036575317382812
2025-12-09 12:13:43.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 12.099519729614258
2025-12-09 12:13:44.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 12.097342491149902
2025-12-09 12:13:44.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 12.041513442993164
2025-12-09 12:13:45.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 12.081128120422363
2025-12-09 12:13:45.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 12.13351058959961
2025-12-09 12:13:46.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 12.010446548461914
2025-12-09 12:13:46.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 12.089242935180664
2025-12-09 12:13:47.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 11.981820106506348
2025-12-09 12:13:47.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 12.021293640136719
2025-12-09 12:13:48.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 12.038382530212402
2025-12-09 12:13:48.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 11.917837142944336
2025-12-09 12:13:49.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 12.017256736755371
2025-12-09 12:13:49.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 11.959402084350586
2025-12-09 12:13:50.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 12.026069641113281
2025-12-09 12:13:50.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 11.93464183807373
2025-12-09 12:13:51.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 11.86706256866455
2025-12-09 12:13:51.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 11.875059127807617
2025-12-09 12:13:52.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 11.861076354980469
2025-12-09 12:13:52.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 11.828588485717773
2025-12-09 12:13:53.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 11.875213623046875
2025-12-09 12:13:53.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 11.80467414855957
2025-12-09 12:13:54.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 11.856610298156738
2025-12-09 12:13:54.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 11.866037368774414
2025-12-09 12:13:55.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 11.745052337646484
2025-12-09 12:13:55.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 11.705772399902344
2025-12-09 12:13:56.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 11.649694442749023
2025-12-09 12:13:56.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 11.51529598236084
2025-12-09 12:13:57.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 11.591415405273438
2025-12-09 12:13:57.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 11.419876098632812
2025-12-09 12:13:58.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 11.57651424407959
2025-12-09 12:13:58.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 11.51744556427002
2025-12-09 12:13:59.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 11.562071800231934
2025-12-09 12:13:59.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 11.516592025756836
2025-12-09 12:14:00.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 11.346236228942871
2025-12-09 12:14:00.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 11.169846534729004
2025-12-09 12:14:01.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 11.13955307006836
2025-12-09 12:14:01.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 11.158439636230469
2025-12-09 12:14:02.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 11.04804801940918
2025-12-09 12:14:02.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 11.116479873657227
2025-12-09 12:14:03.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 10.704198837280273
2025-12-09 12:14:03.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 10.806921005249023
2025-12-09 12:14:04.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 10.731898307800293
2025-12-09 12:14:04.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 10.63736343383789
2025-12-09 12:14:05.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 10.36595344543457
2025-12-09 12:14:05.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 10.558974266052246
2025-12-09 12:14:06.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 10.674817085266113
2025-12-09 12:14:06.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 10.520334243774414
2025-12-09 12:14:07.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 9.962148666381836
2025-12-09 12:14:07.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 9.902466773986816
2025-12-09 12:14:08.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 9.816038131713867
2025-12-09 12:14:08.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 10.370506286621094
2025-12-09 12:14:09.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 9.88889217376709
2025-12-09 12:14:09.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 9.456573486328125
2025-12-09 12:14:10.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 9.507525444030762
2025-12-09 12:14:10.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 9.481301307678223
2025-12-09 12:14:11.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 9.606810569763184
2025-12-09 12:14:11.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 9.253793716430664
2025-12-09 12:14:12.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 9.286761283874512
2025-12-09 12:14:12.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 9.168549537658691
2025-12-09 12:14:13.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 9.341309547424316
2025-12-09 12:14:13.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 9.042522430419922
2025-12-09 12:14:14.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 8.909781455993652
2025-12-09 12:14:14.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 9.552318572998047
2025-12-09 12:14:15.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 8.46994686126709
2025-12-09 12:14:15.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 8.780956268310547
2025-12-09 12:14:16.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 8.721671104431152
2025-12-09 12:14:16.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 8.949548721313477
2025-12-09 12:14:17.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 8.747241973876953
2025-12-09 12:14:17.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 8.662983894348145
2025-12-09 12:14:18.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 8.558809280395508
2025-12-09 12:14:18.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 8.513489723205566
2025-12-09 12:14:19.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 8.818072319030762
2025-12-09 12:14:19.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 8.633659362792969
2025-12-09 12:14:20.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 8.545601844787598
2025-12-09 12:14:20.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 8.82810115814209
2025-12-09 12:14:21.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 8.468365669250488
2025-12-09 12:14:21.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 8.40158462524414
2025-12-09 12:14:22.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 8.300299644470215
2025-12-09 12:14:22.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 8.331571578979492
2025-12-09 12:14:23.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 8.064627647399902
2025-12-09 12:14:23.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.999999029798809e-05 Training loss: 8.010393142700195
2025-12-09 12:14:24.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 9.999996119195611e-05 Training loss: 7.958607196807861
2025-12-09 12:14:24.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 9.999991268191536e-05 Training loss: 8.007575035095215
2025-12-09 12:14:25.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 9.999984476788465e-05 Training loss: 8.197789192199707
2025-12-09 12:14:25.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 9.999975744989037e-05 Training loss: 7.820580005645752
2025-12-09 12:14:26.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 9.999965072796636e-05 Training loss: 7.927764892578125
2025-12-09 12:14:26.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 9.999952460215408e-05 Training loss: 7.815101623535156
2025-12-09 12:14:27.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 9.999937907250246e-05 Training loss: 8.320295333862305
2025-12-09 12:14:27.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 9.999921413906798e-05 Training loss: 7.654260635375977
2025-12-09 12:14:28.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 9.999902980191464e-05 Training loss: 7.923309803009033
2025-12-09 12:14:28.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 9.999882606111399e-05 Training loss: 7.884395599365234
2025-12-09 12:14:29.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 9.999860291674508e-05 Training loss: 7.997189998626709
2025-12-09 12:14:29.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 9.999836036889453e-05 Training loss: 8.025753021240234
2025-12-09 12:14:30.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 9.999809841765644e-05 Training loss: 7.697027683258057
2025-12-09 12:14:30.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 9.999781706313251e-05 Training loss: 7.967260837554932
2025-12-09 12:14:31.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 9.999751630543188e-05 Training loss: 8.057418823242188
2025-12-09 12:14:31.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 9.99971961446713e-05 Training loss: 8.087964057922363
2025-12-09 12:14:32.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 9.999685658097502e-05 Training loss: 8.03530502319336
2025-12-09 12:14:32.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 9.999649761447478e-05 Training loss: 7.931018352508545
2025-12-09 12:14:33.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 9.999611924530994e-05 Training loss: 7.93073034286499
2025-12-09 12:14:33.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 9.999572147362731e-05 Training loss: 7.892167568206787
2025-12-09 12:14:34.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 9.999530429958124e-05 Training loss: 8.222652435302734
2025-12-09 12:14:34.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 9.999486772333366e-05 Training loss: 8.195026397705078
2025-12-09 12:14:35.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 9.999441174505399e-05 Training loss: 8.005648612976074
2025-12-09 12:14:35.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 9.999393636491918e-05 Training loss: 7.802584171295166
2025-12-09 12:14:36.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 9.99934415831137e-05 Training loss: 7.846959590911865
2025-12-09 12:14:36.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 9.99929273998296e-05 Training loss: 7.72840690612793
2025-12-09 12:14:37.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 9.99923938152664e-05 Training loss: 8.02266788482666
2025-12-09 12:14:37.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 9.999184082963118e-05 Training loss: 8.07529354095459
2025-12-09 12:14:38.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 9.999126844313853e-05 Training loss: 7.938948631286621
2025-12-09 12:14:38.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 9.999067665601061e-05 Training loss: 7.783435821533203
2025-12-09 12:14:39.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 9.999006546847707e-05 Training loss: 7.889222145080566
2025-12-09 12:14:39.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 9.998943488077508e-05 Training loss: 7.8291778564453125
2025-12-09 12:14:40.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 9.998878489314938e-05 Training loss: 7.886870861053467
2025-12-09 12:14:40.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 9.99881155058522e-05 Training loss: 7.7832183837890625
2025-12-09 12:14:41.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 9.998742671914335e-05 Training loss: 8.177409172058105
2025-12-09 12:14:41.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 9.99867185332901e-05 Training loss: 7.955257892608643
2025-12-09 12:14:42.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 9.998599094856732e-05 Training loss: 7.900577545166016
2025-12-09 12:14:42.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 9.99852439652573e-05 Training loss: 8.43873405456543
2025-12-09 12:14:43.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 9.998447758365002e-05 Training loss: 7.633056163787842
2025-12-09 12:14:43.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 9.998369180404283e-05 Training loss: 7.281134128570557
2025-12-09 12:14:44.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 9.99828866267407e-05 Training loss: 8.001338005065918
2025-12-09 12:14:44.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 9.998206205205611e-05 Training loss: 8.01901912689209
2025-12-09 12:14:45.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 9.998121808030906e-05 Training loss: 8.415409088134766
2025-12-09 12:14:45.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 9.998035471182708e-05 Training loss: 7.539086818695068
2025-12-09 12:14:46.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 9.997947194694519e-05 Training loss: 7.834521293640137
2025-12-09 12:14:46.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 9.997856978600604e-05 Training loss: 7.5832133293151855
2025-12-09 12:14:47.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 9.997764822935967e-05 Training loss: 7.601181507110596
2025-12-09 12:14:47.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 9.997670727736378e-05 Training loss: 7.815179824829102
2025-12-09 12:14:48.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 9.99757469303835e-05 Training loss: 8.041348457336426
2025-12-09 12:14:48.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 9.997476718879153e-05 Training loss: 7.950033187866211
2025-12-09 12:14:49.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 9.99737680529681e-05 Training loss: 7.452704906463623
2025-12-09 12:14:49.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 9.997274952330094e-05 Training loss: 7.941738128662109
2025-12-09 12:14:50.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 9.997171160018531e-05 Training loss: 7.548715114593506
2025-12-09 12:14:50.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 9.997065428402403e-05 Training loss: 8.410324096679688
2025-12-09 12:14:51.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 9.996957757522742e-05 Training loss: 7.584394931793213
2025-12-09 12:14:51.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 9.996848147421334e-05 Training loss: 7.176816940307617
2025-12-09 12:14:52.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 9.996736598140714e-05 Training loss: 7.720573902130127
2025-12-09 12:14:52.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 9.996623109724174e-05 Training loss: 7.408543109893799
2025-12-09 12:14:53.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 9.996507682215754e-05 Training loss: 8.244821548461914
2025-12-09 12:14:53.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 9.996390315660253e-05 Training loss: 7.485951900482178
2025-12-09 12:14:54.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 9.996271010103216e-05 Training loss: 7.724372863769531
2025-12-09 12:14:54.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 9.996149765590946e-05 Training loss: 7.589991569519043
2025-12-09 12:14:55.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 9.99602658217049e-05 Training loss: 7.772660255432129
2025-12-09 12:14:55.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 9.995901459889658e-05 Training loss: 7.59696626663208
2025-12-09 12:14:56.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 9.995774398797007e-05 Training loss: 7.5380659103393555
2025-12-09 12:14:56.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 9.995645398941846e-05 Training loss: 7.441972732543945
2025-12-09 12:14:57.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 9.995514460374238e-05 Training loss: 7.782124996185303
2025-12-09 12:14:57.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 9.995381583144996e-05 Training loss: 7.607110977172852
2025-12-09 12:14:58.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 9.995246767305688e-05 Training loss: 7.973625659942627
2025-12-09 12:14:58.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 9.995110012908634e-05 Training loss: 7.308711528778076
2025-12-09 12:14:59.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 9.994971320006905e-05 Training loss: 7.476075649261475
2025-12-09 12:14:59.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 9.994830688654326e-05 Training loss: 7.528695583343506
2025-12-09 12:15:00.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 9.994688118905472e-05 Training loss: 7.1392998695373535
2025-12-09 12:15:00.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 9.994543610815671e-05 Training loss: 7.614917278289795
2025-12-09 12:15:01.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 9.994397164441007e-05 Training loss: 7.987492561340332
2025-12-09 12:15:01.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 9.994248779838311e-05 Training loss: 7.843216896057129
2025-12-09 12:15:02.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 9.994098457065166e-05 Training loss: 8.18347454071045
2025-12-09 12:15:02.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 9.993946196179913e-05 Training loss: 7.974472522735596
2025-12-09 12:15:03.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 9.993791997241639e-05 Training loss: 7.816973686218262
2025-12-09 12:15:03.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 9.993635860310187e-05 Training loss: 7.709012508392334
2025-12-09 12:15:04.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 9.99347778544615e-05 Training loss: 7.515712261199951
2025-12-09 12:15:04.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 9.993317772710874e-05 Training loss: 7.630693435668945
2025-12-09 12:15:05.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 9.993155822166457e-05 Training loss: 7.647212028503418
2025-12-09 12:15:05.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 9.992991933875748e-05 Training loss: 7.770523548126221
2025-12-09 12:15:06.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 9.99282610790235e-05 Training loss: 7.598071098327637
2025-12-09 12:15:06.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 9.992658344310614e-05 Training loss: 7.446518898010254
2025-12-09 12:15:07.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 9.992488643165651e-05 Training loss: 7.788105487823486
2025-12-09 12:15:07.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 9.992317004533313e-05 Training loss: 7.231708526611328
2025-12-09 12:15:08.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 9.992143428480214e-05 Training loss: 7.4229607582092285
2025-12-09 12:15:08.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 9.991967915073714e-05 Training loss: 7.648131370544434
2025-12-09 12:15:09.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 9.991790464381926e-05 Training loss: 7.309208393096924
2025-12-09 12:15:09.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 9.991611076473714e-05 Training loss: 7.604617595672607
2025-12-09 12:15:10.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 9.991429751418697e-05 Training loss: 7.410830974578857
2025-12-09 12:15:10.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 9.991246489287245e-05 Training loss: 7.276089668273926
2025-12-09 12:15:11.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 9.991061290150475e-05 Training loss: 7.119787693023682
2025-12-09 12:15:11.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 9.990874154080259e-05 Training loss: 7.473388671875
2025-12-09 12:15:12.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 9.990685081149222e-05 Training loss: 7.425786018371582
2025-12-09 12:15:12.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 9.990494071430742e-05 Training loss: 7.874197006225586
2025-12-09 12:15:13.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 9.990301124998945e-05 Training loss: 7.675078868865967
2025-12-09 12:15:13.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 9.990106241928706e-05 Training loss: 7.292667865753174
2025-12-09 12:15:14.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 9.989909422295659e-05 Training loss: 7.555862903594971
2025-12-09 12:15:14.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 9.989710666176186e-05 Training loss: 7.4891228675842285
2025-12-09 12:15:15.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 9.989509973647417e-05 Training loss: 7.14741325378418
2025-12-09 12:15:15.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 9.989307344787242e-05 Training loss: 7.3188652992248535
2025-12-09 12:15:16.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 9.989102779674293e-05 Training loss: 7.2083916664123535
2025-12-09 12:15:16.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 9.98889627838796e-05 Training loss: 7.315304756164551
2025-12-09 12:15:17.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 9.98868784100838e-05 Training loss: 7.329986572265625
2025-12-09 12:15:17.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 9.988477467616447e-05 Training loss: 7.46726131439209
2025-12-09 12:15:18.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 9.988265158293799e-05 Training loss: 7.705692291259766
2025-12-09 12:15:18.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 9.98805091312283e-05 Training loss: 7.646030426025391
2025-12-09 12:15:19.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 9.987834732186687e-05 Training loss: 7.006268501281738
2025-12-09 12:15:19.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 9.987616615569263e-05 Training loss: 7.44155216217041
2025-12-09 12:15:20.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 9.987396563355205e-05 Training loss: 7.203571796417236
2025-12-09 12:15:20.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 9.987174575629911e-05 Training loss: 7.1688947677612305
2025-12-09 12:15:21.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 9.986950652479532e-05 Training loss: 7.508630752563477
2025-12-09 12:15:21.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 9.986724793990966e-05 Training loss: 7.764993667602539
2025-12-09 12:15:22.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 9.986497000251866e-05 Training loss: 7.182361602783203
2025-12-09 12:15:22.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 9.986267271350633e-05 Training loss: 7.634476661682129
2025-12-09 12:15:23.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 9.98603560737642e-05 Training loss: 7.403061389923096
2025-12-09 12:15:23.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 9.985802008419131e-05 Training loss: 8.420363426208496
2025-12-09 12:15:24.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 9.985566474569424e-05 Training loss: 7.331049919128418
2025-12-09 12:15:24.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 9.985329005918702e-05 Training loss: 7.38128137588501
2025-12-09 12:15:25.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 9.985089602559125e-05 Training loss: 6.942327499389648
2025-12-09 12:15:25.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 9.984848264583597e-05 Training loss: 7.653675079345703
2025-12-09 12:15:26.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 9.98460499208578e-05 Training loss: 7.116410732269287
2025-12-09 12:15:26.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 9.98435978516008e-05 Training loss: 7.886065483093262
2025-12-09 12:15:27.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 9.98411264390166e-05 Training loss: 7.4708051681518555
2025-12-09 12:15:27.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 9.983863568406428e-05 Training loss: 7.416419982910156
2025-12-09 12:15:28.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 9.983612558771049e-05 Training loss: 7.105575084686279
2025-12-09 12:15:28.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 9.983359615092931e-05 Training loss: 7.48132848739624
2025-12-09 12:15:29.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 9.983104737470239e-05 Training loss: 7.697038650512695
2025-12-09 12:15:29.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 9.982847926001886e-05 Training loss: 7.230849266052246
2025-12-09 12:15:30.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 9.982589180787534e-05 Training loss: 7.549211502075195
2025-12-09 12:15:30.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 9.982328501927599e-05 Training loss: 8.271438598632812
2025-12-09 12:15:31.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 9.982065889523242e-05 Training loss: 6.983007907867432
2025-12-09 12:15:31.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 9.98180134367638e-05 Training loss: 7.109930038452148
2025-12-09 12:15:32.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 9.981534864489679e-05 Training loss: 7.964678764343262
2025-12-09 12:15:32.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 9.981266452066553e-05 Training loss: 7.827180862426758
2025-12-09 12:15:33.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 9.98099610651117e-05 Training loss: 7.91472053527832
2025-12-09 12:15:33.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 9.980723827928441e-05 Training loss: 7.126764297485352
2025-12-09 12:15:34.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 9.980449616424037e-05 Training loss: 7.601544380187988
2025-12-09 12:15:34.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 9.98017347210437e-05 Training loss: 6.980252742767334
2025-12-09 12:15:35.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 9.979895395076609e-05 Training loss: 7.883555889129639
2025-12-09 12:15:35.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 9.979615385448669e-05 Training loss: 7.490159511566162
2025-12-09 12:15:36.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 9.979333443329217e-05 Training loss: 7.287847995758057
2025-12-09 12:15:36.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 9.97904956882767e-05 Training loss: 7.42538595199585
2025-12-09 12:15:37.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 9.978763762054194e-05 Training loss: 7.087042808532715
2025-12-09 12:15:37.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 9.978476023119701e-05 Training loss: 7.159426212310791
2025-12-09 12:15:38.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 9.978186352135861e-05 Training loss: 6.763211250305176
2025-12-09 12:15:38.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 9.977894749215089e-05 Training loss: 7.780646800994873
2025-12-09 12:15:39.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 9.97760121447055e-05 Training loss: 7.106659412384033
2025-12-09 12:15:39.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 9.977305748016159e-05 Training loss: 7.082874774932861
2025-12-09 12:15:40.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 9.977008349966582e-05 Training loss: 7.426329612731934
2025-12-09 12:15:40.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 9.976709020437229e-05 Training loss: 7.241764068603516
2025-12-09 12:15:41.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 9.97640775954427e-05 Training loss: 7.395303249359131
2025-12-09 12:15:41.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 9.976104567404617e-05 Training loss: 6.991986274719238
2025-12-09 12:15:42.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 9.97579944413593e-05 Training loss: 7.837040901184082
2025-12-09 12:15:42.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 9.975492389856622e-05 Training loss: 7.158387660980225
2025-12-09 12:15:43.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 9.975183404685856e-05 Training loss: 7.238653659820557
2025-12-09 12:15:43.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 9.974872488743543e-05 Training loss: 6.943161487579346
2025-12-09 12:15:44.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 9.974559642150345e-05 Training loss: 7.462873935699463
2025-12-09 12:15:44.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 9.974244865027669e-05 Training loss: 7.811570644378662
2025-12-09 12:15:45.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 9.973928157497674e-05 Training loss: 7.234695911407471
2025-12-09 12:15:45.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 9.973609519683268e-05 Training loss: 6.998234748840332
2025-12-09 12:15:46.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 9.973288951708111e-05 Training loss: 7.206283092498779
2025-12-09 12:15:46.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 9.972966453696608e-05 Training loss: 7.179570198059082
2025-12-09 12:15:47.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 9.972642025773912e-05 Training loss: 7.368072032928467
2025-12-09 12:15:47.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 9.972315668065929e-05 Training loss: 7.110312461853027
2025-12-09 12:15:48.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 9.97198738069931e-05 Training loss: 7.489466667175293
2025-12-09 12:15:48.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 9.971657163801458e-05 Training loss: 7.018795967102051
2025-12-09 12:15:49.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 9.971325017500526e-05 Training loss: 7.566162586212158
2025-12-09 12:15:49.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 9.970990941925411e-05 Training loss: 8.517322540283203
2025-12-09 12:15:50.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 9.970654937205762e-05 Training loss: 8.184199333190918
2025-12-09 12:15:50.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 9.970317003471976e-05 Training loss: 7.605200290679932
2025-12-09 12:15:51.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 9.969977140855198e-05 Training loss: 7.5016045570373535
2025-12-09 12:15:51.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 9.969635349487321e-05 Training loss: 7.546253204345703
2025-12-09 12:15:52.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 9.969291629500991e-05 Training loss: 7.013237953186035
2025-12-09 12:15:52.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 9.968945981029596e-05 Training loss: 7.6832475662231445
2025-12-09 12:15:53.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 9.968598404207275e-05 Training loss: 7.134426593780518
2025-12-09 12:15:53.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 9.96824889916892e-05 Training loss: 7.283824920654297
2025-12-09 12:15:54.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 9.96789746605016e-05 Training loss: 7.824086666107178
2025-12-09 12:15:54.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 9.967544104987387e-05 Training loss: 7.303545951843262
2025-12-09 12:15:55.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 9.967188816117727e-05 Training loss: 7.016197681427002
2025-12-09 12:15:55.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 9.966831599579066e-05 Training loss: 7.604879856109619
2025-12-09 12:15:56.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 9.96647245551003e-05 Training loss: 7.314484119415283
2025-12-09 12:15:56.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 9.966111384049997e-05 Training loss: 7.809372901916504
2025-12-09 12:15:57.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 9.965748385339089e-05 Training loss: 7.022244453430176
2025-12-09 12:15:57.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 9.96538345951818e-05 Training loss: 7.1209845542907715
2025-12-09 12:15:58.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 9.965016606728894e-05 Training loss: 7.191397190093994
2025-12-09 12:15:58.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 9.964647827113595e-05 Training loss: 7.286648750305176
2025-12-09 12:15:59.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 9.964277120815401e-05 Training loss: 7.240849018096924
2025-12-09 12:15:59.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 9.963904487978177e-05 Training loss: 7.25460147857666
2025-12-09 12:16:00.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 9.963529928746534e-05 Training loss: 7.022228240966797
2025-12-09 12:16:00.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 9.963153443265828e-05 Training loss: 7.3609137535095215
2025-12-09 12:16:01.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 9.96277503168217e-05 Training loss: 7.30460786819458
2025-12-09 12:16:01.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 9.96239469414241e-05 Training loss: 6.758696556091309
2025-12-09 12:16:02.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 9.962012430794153e-05 Training loss: 8.226387023925781
2025-12-09 12:16:02.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 9.961628241785747e-05 Training loss: 7.243266582489014
2025-12-09 12:16:03.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 9.961242127266288e-05 Training loss: 6.924282073974609
2025-12-09 12:16:03.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 9.960854087385619e-05 Training loss: 7.130082607269287
2025-12-09 12:16:04.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 9.96046412229433e-05 Training loss: 7.284675121307373
2025-12-09 12:16:04.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 9.960072232143762e-05 Training loss: 7.282827377319336
2025-12-09 12:16:05.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 9.959678417085997e-05 Training loss: 6.762303829193115
2025-12-09 12:16:05.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 9.95928267727387e-05 Training loss: 7.430505275726318
2025-12-09 12:16:06.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 9.958885012860954e-05 Training loss: 7.027013301849365
2025-12-09 12:16:06.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 9.958485424001583e-05 Training loss: 7.307384490966797
2025-12-09 12:16:07.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 9.958083910850821e-05 Training loss: 6.853944301605225
2025-12-09 12:16:07.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 9.957680473564495e-05 Training loss: 7.052374839782715
2025-12-09 12:16:08.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 9.957275112299165e-05 Training loss: 7.018294811248779
2025-12-09 12:16:08.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 9.956867827212148e-05 Training loss: 7.644937038421631
2025-12-09 12:16:09.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 9.956458618461502e-05 Training loss: 7.135405540466309
2025-12-09 12:16:09.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 9.956047486206032e-05 Training loss: 7.026998043060303
2025-12-09 12:16:10.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 9.955634430605291e-05 Training loss: 7.554964065551758
2025-12-09 12:16:10.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 9.955219451819579e-05 Training loss: 6.918619155883789
2025-12-09 12:16:11.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 9.954802550009942e-05 Training loss: 7.025590419769287
2025-12-09 12:16:11.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 9.954383725338167e-05 Training loss: 6.821561336517334
2025-12-09 12:16:12.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 9.953962977966795e-05 Training loss: 6.973448753356934
2025-12-09 12:16:12.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 9.953540308059111e-05 Training loss: 7.462558269500732
2025-12-09 12:16:13.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 9.953115715779141e-05 Training loss: 6.693186283111572
2025-12-09 12:16:13.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 9.952689201291664e-05 Training loss: 6.989119052886963
2025-12-09 12:16:14.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 9.9522607647622e-05 Training loss: 7.8633294105529785
2025-12-09 12:16:14.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 9.951830406357019e-05 Training loss: 6.896899700164795
2025-12-09 12:16:15.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 9.951398126243134e-05 Training loss: 7.305821418762207
2025-12-09 12:16:15.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 9.950963924588303e-05 Training loss: 7.7399749755859375
2025-12-09 12:16:16.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 9.950527801561033e-05 Training loss: 7.74749231338501
2025-12-09 12:16:16.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 9.950089757330574e-05 Training loss: 7.357757568359375
2025-12-09 12:16:17.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 9.949649792066922e-05 Training loss: 6.831017017364502
2025-12-09 12:16:17.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 9.94920790594082e-05 Training loss: 7.239655017852783
2025-12-09 12:16:18.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 9.948764099123755e-05 Training loss: 7.0019145011901855
2025-12-09 12:16:18.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 9.94831837178796e-05 Training loss: 7.097341537475586
2025-12-09 12:16:19.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 9.947870724106412e-05 Training loss: 6.854701042175293
2025-12-09 12:16:19.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 9.947421156252836e-05 Training loss: 7.253712177276611
2025-12-09 12:16:20.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 9.946969668401697e-05 Training loss: 6.946214199066162
2025-12-09 12:16:20.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 9.946516260728214e-05 Training loss: 7.178765773773193
2025-12-09 12:16:21.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 9.946060933408341e-05 Training loss: 7.252036094665527
2025-12-09 12:16:21.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 9.945603686618785e-05 Training loss: 7.172789096832275
2025-12-09 12:16:22.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 9.945144520536992e-05 Training loss: 7.217391490936279
2025-12-09 12:16:22.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 9.944683435341155e-05 Training loss: 7.07758903503418
2025-12-09 12:16:23.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 9.944220431210216e-05 Training loss: 7.182199478149414
2025-12-09 12:16:23.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 9.943755508323855e-05 Training loss: 6.9811110496521
2025-12-09 12:16:24.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 9.943288666862498e-05 Training loss: 6.823312282562256
2025-12-09 12:16:24.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 9.942819907007321e-05 Training loss: 7.1427130699157715
2025-12-09 12:16:25.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 9.942349228940237e-05 Training loss: 7.144467830657959
2025-12-09 12:16:25.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 9.941876632843909e-05 Training loss: 7.233497619628906
2025-12-09 12:16:26.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 9.941402118901744e-05 Training loss: 6.887997150421143
2025-12-09 12:16:26.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 9.940925687297886e-05 Training loss: 7.7915425300598145
2025-12-09 12:16:27.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 9.940447338217234e-05 Training loss: 7.002638339996338
2025-12-09 12:16:27.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 9.939967071845423e-05 Training loss: 7.197865962982178
2025-12-09 12:16:28.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 9.939484888368838e-05 Training loss: 7.091440677642822
2025-12-09 12:16:28.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 9.939000787974602e-05 Training loss: 7.3059611320495605
2025-12-09 12:16:29.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 9.938514770850587e-05 Training loss: 6.761619567871094
2025-12-09 12:16:29.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 9.938026837185404e-05 Training loss: 7.4472455978393555
2025-12-09 12:16:30.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 9.937536987168413e-05 Training loss: 7.197834491729736
2025-12-09 12:16:30.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 9.937045220989715e-05 Training loss: 6.974542140960693
2025-12-09 12:16:31.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 9.936551538840155e-05 Training loss: 6.856101036071777
2025-12-09 12:16:31.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 9.93605594091132e-05 Training loss: 6.937452793121338
2025-12-09 12:16:32.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 9.935558427395542e-05 Training loss: 7.082546234130859
2025-12-09 12:16:32.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 9.935058998485897e-05 Training loss: 7.020440578460693
2025-12-09 12:16:33.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 9.934557654376205e-05 Training loss: 6.955607891082764
2025-12-09 12:16:33.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 9.934054395261026e-05 Training loss: 7.309118747711182
2025-12-09 12:16:34.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 9.933549221335664e-05 Training loss: 6.9603729248046875
2025-12-09 12:16:34.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 9.933042132796171e-05 Training loss: 6.848506927490234
2025-12-09 12:16:35.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 9.932533129839334e-05 Training loss: 6.985394477844238
2025-12-09 12:16:35.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 9.932022212662691e-05 Training loss: 7.105172157287598
2025-12-09 12:16:36.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 9.931509381464515e-05 Training loss: 7.142360210418701
2025-12-09 12:16:36.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 9.930994636443829e-05 Training loss: 6.798501491546631
2025-12-09 12:16:37.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 9.930477977800392e-05 Training loss: 7.017794609069824
2025-12-09 12:16:37.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 9.929959405734712e-05 Training loss: 6.960572719573975
2025-12-09 12:16:38.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 9.929438920448037e-05 Training loss: 6.394477367401123
2025-12-09 12:16:38.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 9.928916522142357e-05 Training loss: 6.960611343383789
2025-12-09 12:16:39.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 9.928392211020401e-05 Training loss: 7.207242965698242
2025-12-09 12:16:39.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.927865987285649e-05 Training loss: 6.971323013305664
2025-12-09 12:16:40.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 9.927337851142314e-05 Training loss: 6.843529224395752
2025-12-09 12:16:40.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 9.926807802795359e-05 Training loss: 7.014187812805176
2025-12-09 12:16:41.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 9.926275842450483e-05 Training loss: 7.254826068878174
2025-12-09 12:16:41.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 9.925741970314129e-05 Training loss: 7.079670429229736
2025-12-09 12:16:42.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 9.925206186593484e-05 Training loss: 6.928071022033691
2025-12-09 12:16:42.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 9.924668491496474e-05 Training loss: 6.267629623413086
2025-12-09 12:16:43.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 9.92412888523177e-05 Training loss: 6.572628498077393
2025-12-09 12:16:43.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 9.923587368008778e-05 Training loss: 7.02730131149292
2025-12-09 12:16:44.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 9.923043940037657e-05 Training loss: 6.384024620056152
2025-12-09 12:16:44.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 9.922498601529296e-05 Training loss: 6.691583156585693
2025-12-09 12:16:45.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 9.92195135269533e-05 Training loss: 7.019784450531006
2025-12-09 12:16:45.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 9.921402193748139e-05 Training loss: 6.854006767272949
2025-12-09 12:16:46.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 9.920851124900837e-05 Training loss: 7.668516159057617
2025-12-09 12:16:46.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 9.920298146367286e-05 Training loss: 6.859020709991455
2025-12-09 12:16:47.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 9.919743258362085e-05 Training loss: 6.933253288269043
2025-12-09 12:16:47.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 9.919186461100576e-05 Training loss: 6.83120059967041
2025-12-09 12:16:48.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 9.91862775479884e-05 Training loss: 6.897619724273682
2025-12-09 12:16:48.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 9.9180671396737e-05 Training loss: 6.981490135192871
2025-12-09 12:16:49.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 9.91750461594272e-05 Training loss: 6.9054646492004395
2025-12-09 12:16:49.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 9.916940183824206e-05 Training loss: 7.106533050537109
2025-12-09 12:16:50.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 9.916373843537201e-05 Training loss: 6.640992164611816
2025-12-09 12:16:50.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 9.915805595301491e-05 Training loss: 7.000094413757324
2025-12-09 12:16:51.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 9.915235439337603e-05 Training loss: 6.648430824279785
2025-12-09 12:16:51.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 9.914663375866804e-05 Training loss: 6.801923751831055
2025-12-09 12:16:52.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 9.914089405111098e-05 Training loss: 6.923483848571777
2025-12-09 12:16:52.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 9.913513527293235e-05 Training loss: 7.589090347290039
2025-12-09 12:16:53.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 9.912935742636698e-05 Training loss: 6.927874565124512
2025-12-09 12:16:53.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 9.912356051365718e-05 Training loss: 7.542843341827393
2025-12-09 12:16:54.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 9.911774453705258e-05 Training loss: 6.963726997375488
2025-12-09 12:16:54.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 9.91119094988103e-05 Training loss: 7.073121547698975
2025-12-09 12:16:55.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 9.910605540119475e-05 Training loss: 7.059233665466309
2025-12-09 12:16:55.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 9.91001822464778e-05 Training loss: 6.630779266357422
2025-12-09 12:16:56.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 9.909429003693876e-05 Training loss: 7.194968223571777
2025-12-09 12:16:56.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 9.908837877486423e-05 Training loss: 7.6617631912231445
2025-12-09 12:16:57.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 9.908244846254826e-05 Training loss: 6.990063190460205
2025-12-09 12:16:57.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 9.907649910229229e-05 Training loss: 6.744412899017334
2025-12-09 12:16:58.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 9.907053069640517e-05 Training loss: 7.140771865844727
2025-12-09 12:16:58.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 9.90645432472031e-05 Training loss: 7.141327857971191
2025-12-09 12:16:59.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 9.905853675700969e-05 Training loss: 7.198388576507568
2025-12-09 12:16:59.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 9.905251122815596e-05 Training loss: 6.673981189727783
2025-12-09 12:17:00.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 9.90464666629803e-05 Training loss: 6.679752349853516
2025-12-09 12:17:00.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 9.904040306382846e-05 Training loss: 6.8273210525512695
2025-12-09 12:17:01.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 9.903432043305365e-05 Training loss: 8.022760391235352
2025-12-09 12:17:01.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 9.902821877301637e-05 Training loss: 6.689763069152832
2025-12-09 12:17:02.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 9.90220980860846e-05 Training loss: 7.286319732666016
2025-12-09 12:17:02.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 9.901595837463363e-05 Training loss: 6.743813991546631
2025-12-09 12:17:03.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 9.900979964104617e-05 Training loss: 7.114931583404541
2025-12-09 12:17:03.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 9.900362188771231e-05 Training loss: 6.850356101989746
2025-12-09 12:17:04.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 9.899742511702951e-05 Training loss: 7.10296630859375
2025-12-09 12:17:04.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 9.89912093314026e-05 Training loss: 6.68695592880249
2025-12-09 12:17:05.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 9.898497453324384e-05 Training loss: 7.138900279998779
2025-12-09 12:17:05.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 9.897872072497281e-05 Training loss: 6.9122443199157715
2025-12-09 12:17:06.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 9.897244790901649e-05 Training loss: 6.822948932647705
2025-12-09 12:17:06.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 9.896615608780925e-05 Training loss: 6.970348358154297
2025-12-09 12:17:07.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 9.895984526379281e-05 Training loss: 7.132620334625244
2025-12-09 12:17:07.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 9.895351543941629e-05 Training loss: 6.81585168838501
2025-12-09 12:17:08.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 9.894716661713617e-05 Training loss: 6.97437047958374
2025-12-09 12:17:08.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 9.894079879941627e-05 Training loss: 7.044064521789551
2025-12-09 12:17:09.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 9.893441198872787e-05 Training loss: 6.905606746673584
2025-12-09 12:17:09.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 9.892800618754954e-05 Training loss: 7.011264801025391
2025-12-09 12:17:10.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 9.892158139836725e-05 Training loss: 7.133823871612549
2025-12-09 12:17:10.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 9.891513762367431e-05 Training loss: 7.826428413391113
2025-12-09 12:17:11.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 9.890867486597146e-05 Training loss: 6.887823581695557
2025-12-09 12:17:11.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 9.890219312776676e-05 Training loss: 6.57088565826416
2025-12-09 12:17:12.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 9.889569241157563e-05 Training loss: 7.023700714111328
2025-12-09 12:17:12.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 9.888917271992091e-05 Training loss: 7.203060150146484
2025-12-09 12:17:13.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 9.888263405533271e-05 Training loss: 6.67720365524292
2025-12-09 12:17:13.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 9.88760764203486e-05 Training loss: 6.971421718597412
2025-12-09 12:17:14.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 9.886949981751346e-05 Training loss: 6.338496685028076
2025-12-09 12:17:14.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 9.886290424937952e-05 Training loss: 6.704822540283203
2025-12-09 12:17:15.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 9.885628971850642e-05 Training loss: 6.611301422119141
2025-12-09 12:17:15.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 9.884965622746111e-05 Training loss: 7.146856784820557
2025-12-09 12:17:16.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 9.884300377881795e-05 Training loss: 7.070377349853516
2025-12-09 12:17:16.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 9.883633237515858e-05 Training loss: 7.096350193023682
2025-12-09 12:17:17.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 9.882964201907207e-05 Training loss: 6.910870552062988
2025-12-09 12:17:17.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 9.882293271315481e-05 Training loss: 6.676077365875244
2025-12-09 12:17:18.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 9.881620446001056e-05 Training loss: 7.206750869750977
2025-12-09 12:17:18.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 9.88094572622504e-05 Training loss: 7.442686557769775
2025-12-09 12:17:19.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 9.88026911224928e-05 Training loss: 6.703261852264404
2025-12-09 12:17:19.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 9.879590604336359e-05 Training loss: 6.702146053314209
2025-12-09 12:17:20.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 9.87891020274959e-05 Training loss: 6.989600658416748
2025-12-09 12:17:20.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 9.878227907753021e-05 Training loss: 6.8826680183410645
2025-12-09 12:17:21.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 9.877543719611444e-05 Training loss: 6.688409328460693
2025-12-09 12:17:21.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 9.876857638590373e-05 Training loss: 6.907704830169678
2025-12-09 12:17:22.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 9.876169664956067e-05 Training loss: 7.007709980010986
2025-12-09 12:17:22.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 9.875479798975512e-05 Training loss: 6.817147731781006
2025-12-09 12:17:23.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 9.874788040916432e-05 Training loss: 7.094610691070557
2025-12-09 12:17:23.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 9.874094391047289e-05 Training loss: 7.269367218017578
2025-12-09 12:17:24.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 9.873398849637268e-05 Training loss: 7.207357883453369
2025-12-09 12:17:24.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 9.872701416956299e-05 Training loss: 7.072795391082764
2025-12-09 12:17:25.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 9.872002093275042e-05 Training loss: 6.999342918395996
2025-12-09 12:17:25.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 9.871300878864891e-05 Training loss: 6.811472415924072
2025-12-09 12:17:26.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 9.870597773997972e-05 Training loss: 6.665997505187988
2025-12-09 12:17:26.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 9.869892778947148e-05 Training loss: 7.048861503601074
2025-12-09 12:17:27.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 9.869185893986012e-05 Training loss: 6.987733364105225
2025-12-09 12:17:27.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 9.868477119388896e-05 Training loss: 7.290078163146973
2025-12-09 12:17:28.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 9.867766455430857e-05 Training loss: 7.089778423309326
2025-12-09 12:17:28.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 9.867053902387693e-05 Training loss: 6.987163543701172
2025-12-09 12:17:29.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 9.86633946053593e-05 Training loss: 6.7960638999938965
2025-12-09 12:17:29.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 9.865623130152828e-05 Training loss: 6.929266929626465
2025-12-09 12:17:30.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 9.864904911516384e-05 Training loss: 7.037351131439209
2025-12-09 12:17:30.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 9.864184804905323e-05 Training loss: 6.976030349731445
2025-12-09 12:17:31.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 9.863462810599105e-05 Training loss: 7.885922431945801
2025-12-09 12:17:31.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 9.862738928877922e-05 Training loss: 7.070119380950928
2025-12-09 12:17:32.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 9.862013160022696e-05 Training loss: 7.120083808898926
2025-12-09 12:17:32.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 9.861285504315085e-05 Training loss: 6.833922863006592
2025-12-09 12:17:33.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 9.860555962037479e-05 Training loss: 7.344913482666016
2025-12-09 12:17:33.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 9.859824533472998e-05 Training loss: 6.788093566894531
2025-12-09 12:17:34.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 9.859091218905498e-05 Training loss: 6.9280781745910645
2025-12-09 12:17:34.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 9.85835601861956e-05 Training loss: 7.077279090881348
2025-12-09 12:17:35.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 9.857618932900503e-05 Training loss: 6.826587200164795
2025-12-09 12:17:35.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 9.856879962034374e-05 Training loss: 6.777883052825928
2025-12-09 12:17:36.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 9.856139106307955e-05 Training loss: 6.991292953491211
2025-12-09 12:17:36.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 9.855396366008758e-05 Training loss: 6.939033031463623
2025-12-09 12:17:37.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 9.854651741425023e-05 Training loss: 6.76240873336792
2025-12-09 12:17:37.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 9.853905232845728e-05 Training loss: 7.345029354095459
2025-12-09 12:17:38.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 9.853156840560575e-05 Training loss: 7.2232770919799805
2025-12-09 12:17:38.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 9.852406564860003e-05 Training loss: 7.413918972015381
2025-12-09 12:17:39.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 9.851654406035179e-05 Training loss: 6.967384338378906
2025-12-09 12:17:39.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 9.850900364378e-05 Training loss: 6.686665058135986
2025-12-09 12:17:40.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 9.850144440181096e-05 Training loss: 6.650005340576172
2025-12-09 12:17:40.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 9.849386633737825e-05 Training loss: 6.869967460632324
2025-12-09 12:17:41.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 9.848626945342278e-05 Training loss: 7.262928009033203
2025-12-09 12:17:41.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 9.847865375289275e-05 Training loss: 7.116573810577393
2025-12-09 12:17:42.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 9.847101923874367e-05 Training loss: 6.784945487976074
2025-12-09 12:17:42.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 9.846336591393833e-05 Training loss: 6.593211650848389
2025-12-09 12:17:43.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 9.845569378144686e-05 Training loss: 6.688342571258545
2025-12-09 12:17:43.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 9.844800284424664e-05 Training loss: 7.1148200035095215
2025-12-09 12:17:44.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 9.844029310532239e-05 Training loss: 7.076229572296143
2025-12-09 12:17:44.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 9.843256456766609e-05 Training loss: 7.130420207977295
2025-12-09 12:17:45.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 9.842481723427705e-05 Training loss: 6.65859842300415
2025-12-09 12:17:45.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 9.841705110816187e-05 Training loss: 6.803127288818359
2025-12-09 12:17:46.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 9.840926619233441e-05 Training loss: 6.775847911834717
2025-12-09 12:17:46.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 9.840146248981585e-05 Training loss: 6.911198616027832
2025-12-09 12:17:47.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 9.839364000363467e-05 Training loss: 7.251853942871094
2025-12-09 12:17:47.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 9.83857987368266e-05 Training loss: 6.777528762817383
2025-12-09 12:17:48.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 9.837793869243468e-05 Training loss: 7.120370864868164
2025-12-09 12:17:48.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 9.837005987350926e-05 Training loss: 6.818387985229492
2025-12-09 12:17:49.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 9.836216228310798e-05 Training loss: 6.927734375
2025-12-09 12:17:49.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 9.835424592429567e-05 Training loss: 6.497568130493164
2025-12-09 12:17:50.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 9.834631080014457e-05 Training loss: 7.123384952545166
2025-12-09 12:17:50.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 9.833835691373413e-05 Training loss: 7.887584686279297
2025-12-09 12:17:51.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 9.83303842681511e-05 Training loss: 6.761197566986084
2025-12-09 12:17:51.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 9.83223928664895e-05 Training loss: 6.374819278717041
2025-12-09 12:17:52.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 9.831438271185065e-05 Training loss: 6.970478057861328
2025-12-09 12:17:52.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 9.830635380734313e-05 Training loss: 6.7639851570129395
2025-12-09 12:17:53.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 9.82983061560828e-05 Training loss: 7.038540363311768
2025-12-09 12:17:53.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 9.829023976119279e-05 Training loss: 6.868737697601318
2025-12-09 12:17:54.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 9.828215462580353e-05 Training loss: 7.226618766784668
2025-12-09 12:17:54.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 9.827405075305267e-05 Training loss: 6.315864086151123
2025-12-09 12:17:55.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 9.826592814608518e-05 Training loss: 7.047847747802734
2025-12-09 12:17:55.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 9.825778680805331e-05 Training loss: 7.679070949554443
2025-12-09 12:17:56.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 9.824962674211653e-05 Training loss: 6.759533882141113
2025-12-09 12:17:56.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 9.824144795144159e-05 Training loss: 6.819834232330322
2025-12-09 12:17:57.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 9.823325043920254e-05 Training loss: 7.1888747215271
2025-12-09 12:17:57.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 9.822503420858069e-05 Training loss: 6.720859050750732
2025-12-09 12:17:58.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 9.821679926276456e-05 Training loss: 5.888225555419922
2025-12-09 12:17:58.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 9.820854560494999e-05 Training loss: 6.682766437530518
2025-12-09 12:17:59.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 9.820027323834006e-05 Training loss: 6.578769683837891
2025-12-09 12:17:59.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 9.819198216614512e-05 Training loss: 7.096408367156982
2025-12-09 12:18:00.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 9.818367239158278e-05 Training loss: 7.261899948120117
2025-12-09 12:18:00.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 9.817534391787789e-05 Training loss: 6.789036750793457
2025-12-09 12:18:01.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 9.816699674826255e-05 Training loss: 7.219666957855225
2025-12-09 12:18:01.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 9.815863088597618e-05 Training loss: 6.606621742248535
2025-12-09 12:18:02.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 9.815024633426538e-05 Training loss: 6.484560966491699
2025-12-09 12:18:02.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 9.814184309638402e-05 Training loss: 6.766353607177734
2025-12-09 12:18:03.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 9.813342117559323e-05 Training loss: 6.7219014167785645
2025-12-09 12:18:03.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 9.812498057516143e-05 Training loss: 6.833155632019043
2025-12-09 12:18:04.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 9.811652129836421e-05 Training loss: 6.9275922775268555
2025-12-09 12:18:04.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 9.810804334848449e-05 Training loss: 6.972350597381592
2025-12-09 12:18:05.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 9.809954672881238e-05 Training loss: 6.8293046951293945
2025-12-09 12:18:05.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 9.809103144264525e-05 Training loss: 7.207862377166748
2025-12-09 12:18:06.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 9.808249749328768e-05 Training loss: 7.583083629608154
2025-12-09 12:18:06.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 9.80739448840516e-05 Training loss: 6.534850120544434
2025-12-09 12:18:07.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 9.806537361825606e-05 Training loss: 6.758131504058838
2025-12-09 12:18:07.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 9.805678369922742e-05 Training loss: 6.65854549407959
2025-12-09 12:18:08.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 9.804817513029927e-05 Training loss: 6.709959983825684
2025-12-09 12:18:08.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 9.803954791481239e-05 Training loss: 7.081752300262451
2025-12-09 12:18:09.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 9.803090205611487e-05 Training loss: 7.017223834991455
2025-12-09 12:18:09.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 9.802223755756198e-05 Training loss: 6.629779815673828
2025-12-09 12:18:10.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 9.801355442251625e-05 Training loss: 6.967712879180908
2025-12-09 12:18:10.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 9.800485265434744e-05 Training loss: 7.09370756149292
2025-12-09 12:18:11.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 9.799613225643253e-05 Training loss: 6.977283477783203
2025-12-09 12:18:11.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 9.798739323215574e-05 Training loss: 7.8907294273376465
2025-12-09 12:18:12.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 9.797863558490849e-05 Training loss: 6.74324893951416
2025-12-09 12:18:12.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 9.79698593180895e-05 Training loss: 6.773463726043701
2025-12-09 12:18:13.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 9.796106443510462e-05 Training loss: 6.914499282836914
2025-12-09 12:18:13.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 9.795225093936702e-05 Training loss: 6.509944438934326
2025-12-09 12:18:14.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 9.794341883429699e-05 Training loss: 6.962883949279785
2025-12-09 12:18:14.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 9.793456812332215e-05 Training loss: 6.560309410095215
2025-12-09 12:18:15.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 9.792569880987726e-05 Training loss: 6.60616397857666
2025-12-09 12:18:15.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 9.791681089740432e-05 Training loss: 6.733482360839844
2025-12-09 12:18:16.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 9.790790438935256e-05 Training loss: 6.809152126312256
2025-12-09 12:18:16.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 9.789897928917847e-05 Training loss: 6.969155311584473
2025-12-09 12:18:17.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 9.789003560034561e-05 Training loss: 6.7805070877075195
2025-12-09 12:18:17.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 9.788107332632495e-05 Training loss: 7.05375862121582
2025-12-09 12:18:18.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 9.787209247059452e-05 Training loss: 7.034958839416504
2025-12-09 12:18:18.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 9.786309303663963e-05 Training loss: 6.722305774688721
2025-12-09 12:18:19.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 9.785407502795278e-05 Training loss: 7.021128177642822
2025-12-09 12:18:19.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 9.784503844803368e-05 Training loss: 6.631049633026123
2025-12-09 12:18:20.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 9.783598330038925e-05 Training loss: 6.558966159820557
2025-12-09 12:18:20.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 9.782690958853362e-05 Training loss: 7.0172600746154785
2025-12-09 12:18:21.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 9.781781731598812e-05 Training loss: 6.7465105056762695
2025-12-09 12:18:21.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 9.780870648628128e-05 Training loss: 6.845406532287598
2025-12-09 12:18:22.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 9.779957710294886e-05 Training loss: 6.585273742675781
2025-12-09 12:18:22.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 9.779042916953376e-05 Training loss: 6.624042510986328
2025-12-09 12:18:23.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 9.778126268958613e-05 Training loss: 7.107329368591309
2025-12-09 12:18:23.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 9.77720776666633e-05 Training loss: 6.843500137329102
2025-12-09 12:18:24.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 9.77628741043298e-05 Training loss: 7.076526165008545
2025-12-09 12:18:24.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 9.775365200615735e-05 Training loss: 7.856600284576416
2025-12-09 12:18:25.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 9.774441137572487e-05 Training loss: 6.534757614135742
2025-12-09 12:18:25.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 9.773515221661846e-05 Training loss: 6.443720817565918
2025-12-09 12:18:26.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 9.772587453243143e-05 Training loss: 7.1438493728637695
2025-12-09 12:18:26.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 9.771657832676427e-05 Training loss: 7.258294582366943
2025-12-09 12:18:27.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 9.770726360322463e-05 Training loss: 6.614674091339111
2025-12-09 12:18:27.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 9.769793036542741e-05 Training loss: 6.944258213043213
2025-12-09 12:18:28.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 9.768857861699463e-05 Training loss: 7.1230387687683105
2025-12-09 12:18:28.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 9.767920836155553e-05 Training loss: 6.974764347076416
2025-12-09 12:18:29.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 9.766981960274653e-05 Training loss: 6.517910957336426
2025-12-09 12:18:29.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 9.766041234421122e-05 Training loss: 7.131550312042236
2025-12-09 12:18:30.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 9.765098658960036e-05 Training loss: 6.874779224395752
2025-12-09 12:18:30.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 9.764154234257192e-05 Training loss: 6.5649309158325195
2025-12-09 12:18:31.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 9.763207960679101e-05 Training loss: 6.814658164978027
2025-12-09 12:18:31.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 9.762259838592994e-05 Training loss: 6.9639201164245605
2025-12-09 12:18:32.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 9.761309868366819e-05 Training loss: 6.847074031829834
2025-12-09 12:18:32.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 9.760358050369243e-05 Training loss: 6.764219284057617
2025-12-09 12:18:33.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 9.759404384969643e-05 Training loss: 6.7635178565979
2025-12-09 12:18:33.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 9.758448872538122e-05 Training loss: 6.6548237800598145
2025-12-09 12:18:34.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 9.757491513445493e-05 Training loss: 6.6668853759765625
2025-12-09 12:18:34.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 9.756532308063293e-05 Training loss: 6.586925029754639
2025-12-09 12:18:35.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 9.755571256763765e-05 Training loss: 6.630019664764404
2025-12-09 12:18:35.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 9.754608359919879e-05 Training loss: 6.773043632507324
2025-12-09 12:18:36.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 9.753643617905313e-05 Training loss: 6.987175464630127
2025-12-09 12:18:36.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 9.752677031094466e-05 Training loss: 6.683854103088379
2025-12-09 12:18:37.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 9.751708599862452e-05 Training loss: 6.910032749176025
2025-12-09 12:18:37.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 9.750738324585098e-05 Training loss: 7.4921183586120605
2025-12-09 12:18:38.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 9.749766205638952e-05 Training loss: 7.036288261413574
2025-12-09 12:18:38.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 9.748792243401273e-05 Training loss: 6.8856940269470215
2025-12-09 12:18:39.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 9.747816438250037e-05 Training loss: 6.98500394821167
2025-12-09 12:18:39.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 9.746838790563934e-05 Training loss: 7.417036056518555
2025-12-09 12:18:40.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 9.74585930072237e-05 Training loss: 6.825568675994873
2025-12-09 12:18:40.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 9.744877969105469e-05 Training loss: 7.112146854400635
2025-12-09 12:18:41.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 9.743894796094062e-05 Training loss: 6.7445268630981445
2025-12-09 12:18:41.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 9.742909782069701e-05 Training loss: 5.664857387542725
2025-12-09 12:18:42.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 9.741922927414651e-05 Training loss: 7.0383100509643555
2025-12-09 12:18:42.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 9.740934232511894e-05 Training loss: 6.997041702270508
2025-12-09 12:18:43.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 9.739943697745118e-05 Training loss: 6.863752365112305
2025-12-09 12:18:43.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 9.738951323498732e-05 Training loss: 6.773538112640381
2025-12-09 12:18:44.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 9.737957110157858e-05 Training loss: 7.103038787841797
2025-12-09 12:18:44.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 9.736961058108332e-05 Training loss: 6.645627498626709
2025-12-09 12:18:45.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 9.735963167736698e-05 Training loss: 7.199855804443359
2025-12-09 12:18:45.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 9.734963439430222e-05 Training loss: 7.4180989265441895
2025-12-09 12:18:46.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 9.733961873576878e-05 Training loss: 6.6369099617004395
2025-12-09 12:18:46.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 9.732958470565353e-05 Training loss: 5.934669494628906
2025-12-09 12:18:47.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 9.731953230785049e-05 Training loss: 6.681446075439453
2025-12-09 12:18:47.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 9.730946154626079e-05 Training loss: 6.809177398681641
2025-12-09 12:18:48.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 9.729937242479271e-05 Training loss: 6.466629505157471
2025-12-09 12:18:48.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 9.728926494736164e-05 Training loss: 6.649724960327148
2025-12-09 12:18:49.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 9.727913911789009e-05 Training loss: 6.602793216705322
2025-12-09 12:18:49.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 9.726899494030768e-05 Training loss: 6.516312122344971
2025-12-09 12:18:50.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 9.725883241855119e-05 Training loss: 6.77212381362915
2025-12-09 12:18:50.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 9.724865155656448e-05 Training loss: 6.67781400680542
2025-12-09 12:18:51.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 9.723845235829857e-05 Training loss: 6.60806131362915
2025-12-09 12:18:51.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 9.722823482771155e-05 Training loss: 6.498438358306885
2025-12-09 12:18:52.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 9.721799896876864e-05 Training loss: 6.708985805511475
2025-12-09 12:18:52.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 9.720774478544219e-05 Training loss: 6.767940521240234
2025-12-09 12:18:53.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 9.719747228171163e-05 Training loss: 6.515172958374023
2025-12-09 12:18:53.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 9.718718146156355e-05 Training loss: 6.70039176940918
2025-12-09 12:18:54.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 9.717687232899159e-05 Training loss: 7.291956424713135
2025-12-09 12:18:54.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 9.716654488799652e-05 Training loss: 6.736533164978027
2025-12-09 12:18:55.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 9.715619914258624e-05 Training loss: 6.991942882537842
2025-12-09 12:18:55.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 9.71458350967757e-05 Training loss: 6.724308013916016
2025-12-09 12:18:56.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 9.713545275458703e-05 Training loss: 6.736911296844482
2025-12-09 12:18:56.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 9.712505212004938e-05 Training loss: 6.713204860687256
2025-12-09 12:18:57.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 9.711463319719904e-05 Training loss: 6.3801960945129395
2025-12-09 12:18:57.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 9.710419599007939e-05 Training loss: 6.907357692718506
2025-12-09 12:18:58.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 9.70937405027409e-05 Training loss: 6.490434169769287
2025-12-09 12:18:58.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 9.708326673924115e-05 Training loss: 6.911360263824463
2025-12-09 12:18:59.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 9.707277470364482e-05 Training loss: 6.789649963378906
2025-12-09 12:18:59.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 9.706226440002363e-05 Training loss: 7.338633060455322
2025-12-09 12:19:00.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 9.705173583245645e-05 Training loss: 7.8845624923706055
2025-12-09 12:19:00.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 9.704118900502919e-05 Training loss: 6.933419227600098
2025-12-09 12:19:01.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 9.703062392183489e-05 Training loss: 6.741028308868408
2025-12-09 12:19:01.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 9.702004058697363e-05 Training loss: 6.409341812133789
2025-12-09 12:19:02.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 9.700943900455262e-05 Training loss: 6.963708877563477
2025-12-09 12:19:02.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 9.69988191786861e-05 Training loss: 6.992076873779297
2025-12-09 12:19:03.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 9.698818111349543e-05 Training loss: 6.975104331970215
2025-12-09 12:19:03.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 9.697752481310904e-05 Training loss: 7.095663070678711
2025-12-09 12:19:04.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 9.696685028166244e-05 Training loss: 6.868760585784912
2025-12-09 12:19:04.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 9.69561575232982e-05 Training loss: 6.934168338775635
2025-12-09 12:19:05.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 9.694544654216596e-05 Training loss: 6.933757305145264
2025-12-09 12:19:05.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 9.693471734242243e-05 Training loss: 6.40122127532959
2025-12-09 12:19:06.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 9.692396992823145e-05 Training loss: 6.782092571258545
2025-12-09 12:19:06.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 9.691320430376385e-05 Training loss: 7.765603065490723
2025-12-09 12:19:07.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 9.690242047319755e-05 Training loss: 6.828197479248047
2025-12-09 12:19:07.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 9.689161844071757e-05 Training loss: 6.285799503326416
2025-12-09 12:19:08.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 9.688079821051595e-05 Training loss: 6.898669242858887
2025-12-09 12:19:08.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 9.68699597867918e-05 Training loss: 6.846005916595459
2025-12-09 12:19:09.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 9.685910317375134e-05 Training loss: 6.684167861938477
2025-12-09 12:19:09.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 9.684822837560776e-05 Training loss: 6.3616790771484375
2025-12-09 12:19:10.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 9.683733539658139e-05 Training loss: 7.244637966156006
2025-12-09 12:19:10.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 9.682642424089958e-05 Training loss: 6.4165449142456055
2025-12-09 12:19:11.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 9.681549491279674e-05 Training loss: 6.817345142364502
2025-12-09 12:19:11.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 9.68045474165143e-05 Training loss: 6.505551338195801
2025-12-09 12:19:12.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 9.679358175630081e-05 Training loss: 6.459743976593018
2025-12-09 12:19:12.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 9.67825979364118e-05 Training loss: 6.952930450439453
2025-12-09 12:19:13.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 9.677159596110987e-05 Training loss: 6.716345310211182
2025-12-09 12:19:13.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 9.676057583466472e-05 Training loss: 6.879832744598389
2025-12-09 12:19:14.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 9.674953756135298e-05 Training loss: 6.665195465087891
2025-12-09 12:19:14.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 9.673848114545843e-05 Training loss: 6.415004253387451
2025-12-09 12:19:15.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 9.672740659127184e-05 Training loss: 6.692310810089111
2025-12-09 12:19:15.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 9.671631390309102e-05 Training loss: 6.939666271209717
2025-12-09 12:19:16.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 9.670520308522084e-05 Training loss: 6.704211235046387
2025-12-09 12:19:16.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 9.66940741419732e-05 Training loss: 6.74124813079834
2025-12-09 12:19:17.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 9.668292707766699e-05 Training loss: 6.298605442047119
2025-12-09 12:19:17.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 9.667176189662818e-05 Training loss: 6.580564022064209
2025-12-09 12:19:18.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 9.666057860318979e-05 Training loss: 6.8371663093566895
2025-12-09 12:19:18.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 9.66493772016918e-05 Training loss: 6.847355365753174
2025-12-09 12:19:19.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 9.663815769648129e-05 Training loss: 6.2148823738098145
2025-12-09 12:19:19.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 9.66269200919123e-05 Training loss: 6.283356189727783
2025-12-09 12:19:20.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 9.661566439234593e-05 Training loss: 6.715173244476318
2025-12-09 12:19:20.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 9.660439060215031e-05 Training loss: 6.8908514976501465
2025-12-09 12:19:21.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 9.659309872570058e-05 Training loss: 6.744766712188721
2025-12-09 12:19:21.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 9.658178876737886e-05 Training loss: 5.823761463165283
2025-12-09 12:19:22.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 9.657046073157436e-05 Training loss: 6.515230655670166
2025-12-09 12:19:22.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 9.655911462268327e-05 Training loss: 6.687621116638184
2025-12-09 12:19:23.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 9.65477504451088e-05 Training loss: 7.555334091186523
2025-12-09 12:19:23.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 9.653636820326113e-05 Training loss: 6.749786376953125
2025-12-09 12:19:24.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 9.652496790155751e-05 Training loss: 6.429986476898193
2025-12-09 12:19:24.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 9.651354954442218e-05 Training loss: 6.9612274169921875
2025-12-09 12:19:25.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 9.650211313628637e-05 Training loss: 6.69189453125
2025-12-09 12:19:25.775 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 9.649065868158832e-05 Training loss: 6.454546928405762
2025-12-09 12:19:26.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 9.64791861847733e-05 Training loss: 6.341172218322754
2025-12-09 12:19:26.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 9.646769565029354e-05 Training loss: 6.666464328765869
2025-12-09 12:19:27.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 9.64561870826083e-05 Training loss: 6.115477561950684
2025-12-09 12:19:27.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 9.644466048618385e-05 Training loss: 6.510224342346191
2025-12-09 12:19:28.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 9.643311586549342e-05 Training loss: 7.1062397956848145
2025-12-09 12:19:28.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 9.642155322501725e-05 Training loss: 6.871111869812012
2025-12-09 12:19:29.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 9.640997256924257e-05 Training loss: 6.659710884094238
2025-12-09 12:19:29.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 9.639837390266361e-05 Training loss: 6.645952224731445
2025-12-09 12:19:30.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 9.638675722978161e-05 Training loss: 7.334997177124023
2025-12-09 12:19:30.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 9.637512255510475e-05 Training loss: 6.842645168304443
2025-12-09 12:19:31.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 9.63634698831482e-05 Training loss: 6.4908952713012695
2025-12-09 12:19:31.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 9.635179921843418e-05 Training loss: 6.5238189697265625
2025-12-09 12:19:32.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 9.634011056549182e-05 Training loss: 6.366976737976074
2025-12-09 12:19:32.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 9.632840392885727e-05 Training loss: 6.804482936859131
2025-12-09 12:19:33.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 9.631667931307364e-05 Training loss: 6.846884250640869
2025-12-09 12:19:33.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 9.630493672269102e-05 Training loss: 6.7610321044921875
2025-12-09 12:19:34.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 9.629317616226649e-05 Training loss: 6.822249889373779
2025-12-09 12:19:34.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 9.628139763636408e-05 Training loss: 6.7115325927734375
2025-12-09 12:19:35.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 9.626960114955483e-05 Training loss: 6.740397930145264
2025-12-09 12:19:35.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 9.62577867064167e-05 Training loss: 6.4956512451171875
2025-12-09 12:19:36.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 9.624595431153467e-05 Training loss: 6.6793084144592285
2025-12-09 12:19:36.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 726 LR: 9.623410396950064e-05 Training loss: 7.453585624694824
2025-12-09 12:19:37.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 727 LR: 9.62222356849135e-05 Training loss: 6.977187156677246
2025-12-09 12:19:37.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 728 LR: 9.621034946237911e-05 Training loss: 6.743869781494141
2025-12-09 12:19:38.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 729 LR: 9.619844530651027e-05 Training loss: 6.827457904815674
2025-12-09 12:19:38.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 730 LR: 9.618652322192675e-05 Training loss: 6.459737300872803
2025-12-09 12:19:39.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 731 LR: 9.61745832132553e-05 Training loss: 6.208218574523926
2025-12-09 12:19:39.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 732 LR: 9.616262528512957e-05 Training loss: 6.6135687828063965
2025-12-09 12:19:40.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 733 LR: 9.615064944219022e-05 Training loss: 6.315272331237793
2025-12-09 12:19:40.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 734 LR: 9.613865568908485e-05 Training loss: 6.715641975402832
2025-12-09 12:19:41.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 735 LR: 9.612664403046797e-05 Training loss: 6.316501617431641
