2025-12-09 12:02:30.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.036738395690918
2025-12-09 12:02:30.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.02636432647705
2025-12-09 12:02:30.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.018957138061523
2025-12-09 12:02:30.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 12.01760196685791
2025-12-09 12:02:30.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 12.037823677062988
2025-12-09 12:02:30.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 12.0309476852417
2025-12-09 12:02:30.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 11.991897583007812
2025-12-09 12:02:31.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 11.987770080566406
2025-12-09 12:02:31.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 11.986248016357422
2025-12-09 12:02:31.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 11.993215560913086
2025-12-09 12:02:31.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 12.000655174255371
2025-12-09 12:02:31.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 11.919689178466797
2025-12-09 12:02:31.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 11.95062255859375
2025-12-09 12:02:31.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 11.895785331726074
2025-12-09 12:02:31.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 11.834922790527344
2025-12-09 12:02:32.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 11.837024688720703
2025-12-09 12:02:32.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 11.860803604125977
2025-12-09 12:02:32.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 11.792881965637207
2025-12-09 12:02:32.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 11.659875869750977
2025-12-09 12:02:32.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 11.634784698486328
2025-12-09 12:02:32.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 11.56049919128418
2025-12-09 12:02:32.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 11.453001976013184
2025-12-09 12:02:32.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 11.292013168334961
2025-12-09 12:02:33.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 11.25639820098877
2025-12-09 12:02:33.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 11.1045503616333
2025-12-09 12:02:33.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 10.975249290466309
2025-12-09 12:02:33.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 11.030375480651855
2025-12-09 12:02:33.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 10.757047653198242
2025-12-09 12:02:33.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 10.614514350891113
2025-12-09 12:02:33.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 10.483620643615723
2025-12-09 12:02:33.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 10.360397338867188
2025-12-09 12:02:34.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 10.395875930786133
2025-12-09 12:02:34.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 10.118990898132324
2025-12-09 12:02:34.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 9.899840354919434
2025-12-09 12:02:34.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 9.773759841918945
2025-12-09 12:02:34.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 9.82335376739502
2025-12-09 12:02:34.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 9.529322624206543
2025-12-09 12:02:34.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 9.801416397094727
2025-12-09 12:02:34.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 9.269388198852539
2025-12-09 12:02:35.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 9.103315353393555
2025-12-09 12:02:35.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 9.104509353637695
2025-12-09 12:02:35.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 8.767719268798828
2025-12-09 12:02:35.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 8.628226280212402
2025-12-09 12:02:35.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 8.666290283203125
2025-12-09 12:02:35.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 8.34058952331543
2025-12-09 12:02:35.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 8.234347343444824
2025-12-09 12:02:35.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 8.425394058227539
2025-12-09 12:02:36.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 7.940915584564209
2025-12-09 12:02:36.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 8.199346542358398
2025-12-09 12:02:36.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 7.914145469665527
2025-12-09 12:02:36.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 7.928239345550537
2025-12-09 12:02:36.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 8.227005958557129
2025-12-09 12:02:36.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 8.675325393676758
2025-12-09 12:02:36.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 8.032774925231934
2025-12-09 12:02:36.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 7.828540325164795
2025-12-09 12:02:37.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 7.708550453186035
2025-12-09 12:02:37.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 7.577162742614746
2025-12-09 12:02:37.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 7.897932052612305
2025-12-09 12:02:37.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 7.851442337036133
2025-12-09 12:02:37.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 8.068791389465332
2025-12-09 12:02:37.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 7.603549480438232
2025-12-09 12:02:37.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 7.741434574127197
2025-12-09 12:02:37.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 7.835379600524902
2025-12-09 12:02:38.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 7.887382984161377
2025-12-09 12:02:38.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 7.909825325012207
2025-12-09 12:02:38.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 7.296028137207031
2025-12-09 12:02:38.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 8.836092948913574
2025-12-09 12:02:38.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 7.792585372924805
2025-12-09 12:02:38.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 7.784920692443848
2025-12-09 12:02:38.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 7.1685333251953125
2025-12-09 12:02:39.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 7.522121429443359
2025-12-09 12:02:39.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 7.726876258850098
2025-12-09 12:02:39.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 7.613091468811035
2025-12-09 12:02:39.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 7.4364333152771
2025-12-09 12:02:39.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 7.757497787475586
2025-12-09 12:02:39.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 7.767163276672363
2025-12-09 12:02:39.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 7.890933513641357
2025-12-09 12:02:39.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 7.639053821563721
2025-12-09 12:02:40.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 7.800591468811035
2025-12-09 12:02:40.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 7.693432331085205
2025-12-09 12:02:40.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 8.238616943359375
2025-12-09 12:02:40.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 7.626345157623291
2025-12-09 12:02:40.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 7.510646343231201
2025-12-09 12:02:40.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 7.437651634216309
2025-12-09 12:02:40.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 7.579714775085449
2025-12-09 12:02:40.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 8.069463729858398
2025-12-09 12:02:41.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 7.801568508148193
2025-12-09 12:02:41.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 7.333349704742432
2025-12-09 12:02:41.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 7.359031677246094
2025-12-09 12:02:41.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 7.200258255004883
2025-12-09 12:02:41.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 7.886744976043701
2025-12-09 12:02:41.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 6.820188999176025
2025-12-09 12:02:41.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 7.892992973327637
2025-12-09 12:02:41.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 7.521602630615234
2025-12-09 12:02:42.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 7.365626811981201
2025-12-09 12:02:42.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 7.669881820678711
2025-12-09 12:02:42.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 7.361945629119873
2025-12-09 12:02:42.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 7.155930519104004
2025-12-09 12:02:42.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 7.18398904800415
2025-12-09 12:02:42.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 6.31261682510376
2025-12-09 12:02:42.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0009999999072578703 Training loss: 7.514684200286865
2025-12-09 12:02:42.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.0009999996290315154 Training loss: 7.555935382843018
2025-12-09 12:02:43.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0009999991653210384 Training loss: 7.120645523071289
2025-12-09 12:02:43.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0009999985161266117 Training loss: 7.374326229095459
2025-12-09 12:02:43.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0009999976814484759 Training loss: 7.324737548828125
2025-12-09 12:02:43.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0009999966612869405 Training loss: 7.482791900634766
2025-12-09 12:02:43.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0009999954556423843 Training loss: 7.2624711990356445
2025-12-09 12:02:43.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0009999940645152542 Training loss: 7.3493781089782715
2025-12-09 12:02:43.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0009999924879060664 Training loss: 7.205756664276123
2025-12-09 12:02:43.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.000999990725815406 Training loss: 7.00725793838501
2025-12-09 12:02:44.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.0009999887782439264 Training loss: 7.390416622161865
2025-12-09 12:02:44.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.00099998664519235 Training loss: 7.263221263885498
2025-12-09 12:02:44.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0009999843266614685 Training loss: 7.034301280975342
2025-12-09 12:02:44.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0009999818226521416 Training loss: 7.4698662757873535
2025-12-09 12:02:44.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.0009999791331652982 Training loss: 7.288463592529297
2025-12-09 12:02:44.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0009999762582019365 Training loss: 6.652538299560547
2025-12-09 12:02:44.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.0009999731977631226 Training loss: 7.2399115562438965
2025-12-09 12:02:44.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.0009999699518499921 Training loss: 6.98307466506958
2025-12-09 12:02:45.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0009999665204637486 Training loss: 7.082936763763428
2025-12-09 12:02:45.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.0009999629036056656 Training loss: 7.420849800109863
2025-12-09 12:02:45.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.0009999591012770847 Training loss: 7.248884677886963
2025-12-09 12:02:45.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.0009999551134794165 Training loss: 6.9309234619140625
2025-12-09 12:02:45.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.00099995094021414 Training loss: 6.948024749755859
2025-12-09 12:02:45.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.0009999465814828036 Training loss: 7.3201446533203125
2025-12-09 12:02:45.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0009999420372870244 Training loss: 7.280089855194092
2025-12-09 12:02:45.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.0009999373076284876 Training loss: 7.564404487609863
2025-12-09 12:02:46.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.0009999323925089486 Training loss: 7.216577529907227
2025-12-09 12:02:46.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.00099992729193023 Training loss: 7.2674689292907715
2025-12-09 12:02:46.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0009999220058942244 Training loss: 7.557126045227051
2025-12-09 12:02:46.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.0009999165344028926 Training loss: 7.2423930168151855
2025-12-09 12:02:46.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.0009999108774582644 Training loss: 7.150573253631592
2025-12-09 12:02:46.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.0009999050350624381 Training loss: 7.539736747741699
2025-12-09 12:02:46.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0009998990072175814 Training loss: 7.04423189163208
2025-12-09 12:02:47.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.0009998927939259303 Training loss: 6.621234893798828
2025-12-09 12:02:47.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.0009998863951897897 Training loss: 7.258621692657471
2025-12-09 12:02:47.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0009998798110115333 Training loss: 7.264430522918701
2025-12-09 12:02:47.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0009998730413936037 Training loss: 7.03380012512207
2025-12-09 12:02:47.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.0009998660863385124 Training loss: 7.172884941101074
2025-12-09 12:02:47.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.0009998589458488389 Training loss: 7.309265613555908
2025-12-09 12:02:47.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0009998516199272328 Training loss: 6.357180118560791
2025-12-09 12:02:47.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0009998441085764113 Training loss: 6.89383602142334
2025-12-09 12:02:48.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.0009998364117991612 Training loss: 7.134244918823242
2025-12-09 12:02:48.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0009998285295983375 Training loss: 7.007519245147705
2025-12-09 12:02:48.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.0009998204619768645 Training loss: 7.323397636413574
2025-12-09 12:02:48.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0009998122089377348 Training loss: 7.029985427856445
2025-12-09 12:02:48.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.0009998037704840102 Training loss: 6.964159965515137
2025-12-09 12:02:48.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.000999795146618821 Training loss: 7.127078056335449
2025-12-09 12:02:48.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0009997863373453664 Training loss: 7.4188127517700195
2025-12-09 12:02:48.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.000999777342666914 Training loss: 7.1843109130859375
2025-12-09 12:02:49.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0009997681625868013 Training loss: 6.838796615600586
2025-12-09 12:02:49.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0009997587971084334 Training loss: 7.101072311401367
2025-12-09 12:02:49.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.0009997492462352846 Training loss: 7.141707897186279
2025-12-09 12:02:49.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0009997395099708981 Training loss: 6.897332668304443
2025-12-09 12:02:49.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.0009997295883188856 Training loss: 7.053903579711914
2025-12-09 12:02:49.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.0009997194812829276 Training loss: 6.880746841430664
2025-12-09 12:02:49.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0009997091888667737 Training loss: 6.995784759521484
2025-12-09 12:02:49.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.000999698711074242 Training loss: 6.873544216156006
2025-12-09 12:02:50.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0009996880479092197 Training loss: 7.023534774780273
2025-12-09 12:02:50.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.000999677199375662 Training loss: 6.821414470672607
2025-12-09 12:02:50.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0009996661654775938 Training loss: 6.832840919494629
2025-12-09 12:02:50.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.000999654946219108 Training loss: 7.055845260620117
2025-12-09 12:02:50.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.000999643541604367 Training loss: 6.89979362487793
2025-12-09 12:02:50.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.000999631951637601 Training loss: 7.099783420562744
2025-12-09 12:02:50.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.0009996201763231099 Training loss: 7.677933692932129
2025-12-09 12:02:50.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0009996082156652618 Training loss: 6.602964878082275
2025-12-09 12:02:51.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.000999596069668494 Training loss: 6.865091800689697
2025-12-09 12:02:51.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.000999583738337312 Training loss: 6.913546562194824
2025-12-09 12:02:51.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0009995712216762903 Training loss: 6.180954456329346
2025-12-09 12:02:51.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.0009995585196900722 Training loss: 7.060033321380615
2025-12-09 12:02:51.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.00099954563238337 Training loss: 6.950040817260742
2025-12-09 12:02:51.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0009995325597609644 Training loss: 6.660050868988037
2025-12-09 12:02:51.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.000999519301827705 Training loss: 7.143718242645264
2025-12-09 12:02:51.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0009995058585885095 Training loss: 6.540797710418701
2025-12-09 12:02:52.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.0009994922300483656 Training loss: 6.557721138000488
2025-12-09 12:02:52.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.000999478416212329 Training loss: 6.888328552246094
2025-12-09 12:02:52.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.0009994644170855237 Training loss: 6.574862957000732
2025-12-09 12:02:52.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0009994502326731434 Training loss: 5.484664440155029
2025-12-09 12:02:52.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0009994358629804498 Training loss: 7.277833938598633
2025-12-09 12:02:52.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.0009994213080127738 Training loss: 7.047826290130615
2025-12-09 12:02:52.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.0009994065677755147 Training loss: 7.049299716949463
2025-12-09 12:02:53.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0009993916422741409 Training loss: 7.0731916427612305
2025-12-09 12:02:53.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.000999376531514189 Training loss: 7.2615065574646
2025-12-09 12:02:53.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.0009993612355012646 Training loss: 7.214653015136719
2025-12-09 12:02:53.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.0009993457542410422 Training loss: 6.9679694175720215
2025-12-09 12:02:53.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.000999330087739265 Training loss: 6.694363594055176
2025-12-09 12:02:53.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0009993142360017445 Training loss: 6.91012716293335
2025-12-09 12:02:53.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.0009992981990343613 Training loss: 7.116302013397217
2025-12-09 12:02:53.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.0009992819768430649 Training loss: 7.042596340179443
2025-12-09 12:02:54.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0009992655694338725 Training loss: 6.5011091232299805
2025-12-09 12:02:54.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.0009992489768128714 Training loss: 6.840176105499268
2025-12-09 12:02:54.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0009992321989862165 Training loss: 7.073214530944824
2025-12-09 12:02:54.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0009992152359601322 Training loss: 6.88706636428833
2025-12-09 12:02:54.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.000999198087740911 Training loss: 6.853440284729004
2025-12-09 12:02:54.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.0009991807543349145 Training loss: 7.084873676300049
2025-12-09 12:02:54.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.000999163235748573 Training loss: 6.971322059631348
2025-12-09 12:02:54.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0009991455319883849 Training loss: 6.7652812004089355
2025-12-09 12:02:55.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0009991276430609181 Training loss: 6.711162090301514
2025-12-09 12:02:55.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.0009991095689728087 Training loss: 7.068493843078613
2025-12-09 12:02:55.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0009990913097307613 Training loss: 7.03703498840332
2025-12-09 12:02:55.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0009990728653415503 Training loss: 6.979121208190918
2025-12-09 12:02:55.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0009990542358120174 Training loss: 6.697172164916992
2025-12-09 12:02:55.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0009990354211490736 Training loss: 6.676518440246582
2025-12-09 12:02:55.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0009990164213596986 Training loss: 7.258223056793213
2025-12-09 12:02:55.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0009989972364509408 Training loss: 7.310309886932373
2025-12-09 12:02:56.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0009989778664299172 Training loss: 6.819150447845459
2025-12-09 12:02:56.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0009989583113038133 Training loss: 7.311183452606201
2025-12-09 12:02:56.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.0009989385710798837 Training loss: 7.003556251525879
2025-12-09 12:02:56.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.0009989186457654514 Training loss: 7.473839282989502
2025-12-09 12:02:56.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.0009988985353679076 Training loss: 7.069533348083496
2025-12-09 12:02:56.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0009988782398947132 Training loss: 6.571652889251709
2025-12-09 12:02:56.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.0009988577593533967 Training loss: 6.988352298736572
2025-12-09 12:02:56.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.000998837093751556 Training loss: 6.62106466293335
2025-12-09 12:02:57.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0009988162430968576 Training loss: 7.119531154632568
2025-12-09 12:02:57.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.000998795207397036 Training loss: 7.450992107391357
2025-12-09 12:02:57.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.000998773986659895 Training loss: 6.72132682800293
2025-12-09 12:02:57.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.0009987525808933069 Training loss: 6.98527717590332
2025-12-09 12:02:57.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0009987309901052122 Training loss: 6.761155128479004
2025-12-09 12:02:57.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.000998709214303621 Training loss: 6.796388149261475
2025-12-09 12:02:57.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.000998687253496611 Training loss: 6.541527271270752
2025-12-09 12:02:57.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0009986651076923287 Training loss: 6.850901126861572
2025-12-09 12:02:58.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.0009986427768989903 Training loss: 6.703541278839111
2025-12-09 12:02:58.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0009986202611248793 Training loss: 7.034614562988281
2025-12-09 12:02:58.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0009985975603783483 Training loss: 6.966471195220947
2025-12-09 12:02:58.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.000998574674667819 Training loss: 6.786764621734619
2025-12-09 12:02:58.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0009985516040017807 Training loss: 6.825815200805664
2025-12-09 12:02:58.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.0009985283483887923 Training loss: 6.788971900939941
2025-12-09 12:02:58.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.0009985049078374806 Training loss: 6.663442134857178
2025-12-09 12:02:58.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.0009984812823565416 Training loss: 6.878453254699707
2025-12-09 12:02:59.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0009984574719547395 Training loss: 6.833503723144531
2025-12-09 12:02:59.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.000998433476640907 Training loss: 6.888825416564941
2025-12-09 12:02:59.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0009984092964239462 Training loss: 7.331724643707275
2025-12-09 12:02:59.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.0009983849313128263 Training loss: 6.2507710456848145
2025-12-09 12:02:59.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0009983603813165868 Training loss: 6.723475933074951
2025-12-09 12:02:59.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0009983356464443346 Training loss: 7.062877655029297
2025-12-09 12:02:59.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.0009983107267052458 Training loss: 6.658452987670898
2025-12-09 12:03:00.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0009982856221085643 Training loss: 7.55913782119751
2025-12-09 12:03:00.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.0009982603326636036 Training loss: 7.175309658050537
2025-12-09 12:03:00.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0009982348583797453 Training loss: 6.67604923248291
2025-12-09 12:03:00.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.0009982091992664392 Training loss: 6.451696395874023
2025-12-09 12:03:00.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0009981833553332044 Training loss: 6.896419525146484
2025-12-09 12:03:00.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.0009981573265896281 Training loss: 6.506529808044434
2025-12-09 12:03:00.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.000998131113045366 Training loss: 6.5095906257629395
2025-12-09 12:03:00.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.0009981047147101425 Training loss: 6.88517427444458
2025-12-09 12:03:01.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.0009980781315937506 Training loss: 7.00541877746582
2025-12-09 12:03:01.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.000998051363706052 Training loss: 6.661247253417969
2025-12-09 12:03:01.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0009980244110569766 Training loss: 6.756035327911377
2025-12-09 12:03:01.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.0009979972736565226 Training loss: 6.5670270919799805
2025-12-09 12:03:01.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0009979699515147579 Training loss: 6.104981422424316
2025-12-09 12:03:01.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0009979424446418172 Training loss: 6.921023368835449
2025-12-09 12:03:01.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.0009979147530479056 Training loss: 6.740763187408447
2025-12-09 12:03:01.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0009978868767432953 Training loss: 6.626884937286377
2025-12-09 12:03:02.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.0009978588157383277 Training loss: 6.661087512969971
2025-12-09 12:03:02.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0009978305700434125 Training loss: 6.886436939239502
2025-12-09 12:03:02.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.000997802139669028 Training loss: 7.256704330444336
2025-12-09 12:03:02.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.0009977735246257209 Training loss: 6.624797821044922
2025-12-09 12:03:02.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.0009977447249241065 Training loss: 6.65022611618042
2025-12-09 12:03:02.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.0009977157405748687 Training loss: 6.744448661804199
2025-12-09 12:03:02.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0009976865715887596 Training loss: 7.167446136474609
2025-12-09 12:03:02.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.0009976572179766 Training loss: 6.879934787750244
2025-12-09 12:03:03.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.0009976276797492793 Training loss: 6.565054893493652
2025-12-09 12:03:03.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0009975979569177551 Training loss: 7.115324974060059
2025-12-09 12:03:03.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0009975680494930539 Training loss: 7.355686664581299
2025-12-09 12:03:03.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00099753795748627 Training loss: 6.6200690269470215
2025-12-09 12:03:03.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0009975076809085669 Training loss: 6.771648406982422
2025-12-09 12:03:03.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.0009974772197711762 Training loss: 7.137760162353516
2025-12-09 12:03:03.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.000997446574085398 Training loss: 6.4746503829956055
2025-12-09 12:03:03.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0009974157438626008 Training loss: 5.891612529754639
2025-12-09 12:03:04.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.0009973847291142217 Training loss: 6.957813262939453
2025-12-09 12:03:04.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.0009973535298517663 Training loss: 6.72880220413208
2025-12-09 12:03:04.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0009973221460868086 Training loss: 6.754021167755127
2025-12-09 12:03:04.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.0009972905778309906 Training loss: 7.253818988800049
2025-12-09 12:03:04.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0009972588250960234 Training loss: 6.7972846031188965
2025-12-09 12:03:04.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.0009972268878936862 Training loss: 6.838903903961182
2025-12-09 12:03:04.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.000997194766235827 Training loss: 7.057294845581055
2025-12-09 12:03:04.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0009971624601343614 Training loss: 6.346435070037842
2025-12-09 12:03:05.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.0009971299696012743 Training loss: 6.321258544921875
2025-12-09 12:03:05.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0009970972946486186 Training loss: 6.602957248687744
2025-12-09 12:03:05.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.0009970644352885157 Training loss: 6.617111682891846
2025-12-09 12:03:05.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0009970313915331553 Training loss: 6.549430847167969
2025-12-09 12:03:05.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0009969981633947955 Training loss: 6.563640594482422
2025-12-09 12:03:05.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0009969647508857632 Training loss: 6.743109703063965
2025-12-09 12:03:05.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.000996931154018453 Training loss: 6.758645057678223
2025-12-09 12:03:06.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0009968973728053288 Training loss: 6.976416110992432
2025-12-09 12:03:06.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0009968634072589219 Training loss: 7.179847240447998
2025-12-09 12:03:06.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0009968292573918325 Training loss: 6.568514347076416
2025-12-09 12:03:06.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.0009967949232167295 Training loss: 6.834122657775879
2025-12-09 12:03:06.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0009967604047463492 Training loss: 6.69897985458374
2025-12-09 12:03:06.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0009967257019934974 Training loss: 6.484487056732178
2025-12-09 12:03:06.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0009966908149710476 Training loss: 6.756567478179932
2025-12-09 12:03:06.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0009966557436919415 Training loss: 6.572447776794434
2025-12-09 12:03:07.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.00099662048816919 Training loss: 6.504932403564453
2025-12-09 12:03:07.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.000996585048415871 Training loss: 6.9161152839660645
2025-12-09 12:03:07.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.0009965494244451323 Training loss: 6.706542491912842
2025-12-09 12:03:07.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0009965136162701888 Training loss: 7.468760013580322
2025-12-09 12:03:07.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0009964776239043244 Training loss: 6.756986618041992
2025-12-09 12:03:07.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.0009964414473608912 Training loss: 6.908231258392334
2025-12-09 12:03:07.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.0009964050866533092 Training loss: 6.390747547149658
2025-12-09 12:03:07.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.0009963685417950677 Training loss: 6.681149959564209
2025-12-09 12:03:08.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.000996331812799723 Training loss: 7.193514347076416
2025-12-09 12:03:08.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0009962948996809007 Training loss: 6.610032081604004
2025-12-09 12:03:08.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0009962578024522947 Training loss: 6.553871154785156
2025-12-09 12:03:08.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.0009962205211276665 Training loss: 6.729949474334717
2025-12-09 12:03:08.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0009961830557208464 Training loss: 6.4343438148498535
2025-12-09 12:03:08.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.000996145406245733 Training loss: 7.115503311157227
2025-12-09 12:03:08.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0009961075727162928 Training loss: 6.810252666473389
2025-12-09 12:03:08.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0009960695551465611 Training loss: 6.6158552169799805
2025-12-09 12:03:09.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.000996031353550641 Training loss: 6.8779473304748535
2025-12-09 12:03:09.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0009959929679427047 Training loss: 6.637306213378906
2025-12-09 12:03:09.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0009959543983369913 Training loss: 6.6347336769104
2025-12-09 12:03:09.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.000995915644747809 Training loss: 6.637045860290527
2025-12-09 12:03:09.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0009958767071895347 Training loss: 6.737940311431885
2025-12-09 12:03:09.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.0009958375856766127 Training loss: 6.74445104598999
2025-12-09 12:03:09.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0009957982802235555 Training loss: 6.655014991760254
2025-12-09 12:03:09.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0009957587908449449 Training loss: 6.346701145172119
2025-12-09 12:03:10.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.0009957191175554295 Training loss: 6.980985641479492
2025-12-09 12:03:10.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0009956792603697273 Training loss: 6.929077625274658
2025-12-09 12:03:10.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.000995639219302624 Training loss: 6.7176361083984375
2025-12-09 12:03:10.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.0009955989943689733 Training loss: 6.87581205368042
2025-12-09 12:03:10.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.0009955585855836978 Training loss: 6.929023742675781
2025-12-09 12:03:10.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0009955179929617875 Training loss: 6.689305782318115
2025-12-09 12:03:10.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.0009954772165183012 Training loss: 6.791595935821533
2025-12-09 12:03:11.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.0009954362562683658 Training loss: 7.045203685760498
2025-12-09 12:03:11.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.000995395112227176 Training loss: 6.652148246765137
2025-12-09 12:03:11.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.000995353784409995 Training loss: 5.790577411651611
2025-12-09 12:03:11.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.0009953122728321542 Training loss: 6.926495552062988
2025-12-09 12:03:11.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.0009952705775090529 Training loss: 6.6461381912231445
2025-12-09 12:03:11.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0009952286984561591 Training loss: 6.465615749359131
2025-12-09 12:03:11.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0009951866356890083 Training loss: 6.742863178253174
2025-12-09 12:03:11.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.0009951443892232048 Training loss: 7.383542537689209
2025-12-09 12:03:12.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.0009951019590744203 Training loss: 7.826157569885254
2025-12-09 12:03:12.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.0009950593452583952 Training loss: 6.987085819244385
2025-12-09 12:03:12.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.0009950165477909379 Training loss: 6.665283679962158
2025-12-09 12:03:12.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0009949735666879252 Training loss: 6.912450790405273
2025-12-09 12:03:12.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.000994930401965301 Training loss: 6.783586502075195
2025-12-09 12:03:12.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.000994887053639079 Training loss: 6.82138204574585
2025-12-09 12:03:12.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.0009948435217253394 Training loss: 6.612948417663574
2025-12-09 12:03:12.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.0009947998062402312 Training loss: 6.449861526489258
2025-12-09 12:03:13.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.000994755907199972 Training loss: 5.801375389099121
2025-12-09 12:03:13.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.0009947118246208461 Training loss: 6.454620361328125
2025-12-09 12:03:13.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.0009946675585192075 Training loss: 6.646521091461182
2025-12-09 12:03:13.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.0009946231089114773 Training loss: 6.713217735290527
2025-12-09 12:03:13.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.000994578475814145 Training loss: 6.851408004760742
2025-12-09 12:03:13.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.0009945336592437678 Training loss: 7.60982084274292
2025-12-09 12:03:13.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.0009944886592169711 Training loss: 7.006700038909912
2025-12-09 12:03:13.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.000994443475750449 Training loss: 6.617615699768066
2025-12-09 12:03:14.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.000994398108860963 Training loss: 6.445258617401123
2025-12-09 12:03:14.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0009943525585653428 Training loss: 6.739959239959717
2025-12-09 12:03:14.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0009943068248804859 Training loss: 6.099700450897217
2025-12-09 12:03:14.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.000994260907823358 Training loss: 6.741822719573975
2025-12-09 12:03:14.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.0009942148074109933 Training loss: 6.836730480194092
2025-12-09 12:03:14.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.0009941685236604934 Training loss: 6.84077262878418
2025-12-09 12:03:14.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.0009941220565890278 Training loss: 6.596435070037842
2025-12-09 12:03:14.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.000994075406213835 Training loss: 6.433582305908203
2025-12-09 12:03:15.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.0009940285725522201 Training loss: 6.747947692871094
2025-12-09 12:03:15.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0009939815556215576 Training loss: 6.598106861114502
2025-12-09 12:03:15.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0009939343554392886 Training loss: 6.798794269561768
2025-12-09 12:03:15.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.0009938869720229233 Training loss: 6.68513822555542
2025-12-09 12:03:15.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.0009938394053900395 Training loss: 6.300459384918213
2025-12-09 12:03:15.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0009937916555582827 Training loss: 6.6517815589904785
2025-12-09 12:03:15.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.000993743722545367 Training loss: 6.703118801116943
2025-12-09 12:03:15.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.0009936956063690734 Training loss: 6.3554229736328125
2025-12-09 12:03:16.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.0009936473070472518 Training loss: 6.882552146911621
2025-12-09 12:03:16.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.0009935988245978198 Training loss: 6.703530788421631
2025-12-09 12:03:16.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0009935501590387628 Training loss: 6.910624027252197
2025-12-09 12:03:16.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.0009935013103881344 Training loss: 6.729982376098633
2025-12-09 12:03:16.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.0009934522786640555 Training loss: 6.500086784362793
2025-12-09 12:03:16.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.0009934030638847156 Training loss: 6.846634387969971
2025-12-09 12:03:16.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.0009933536660683717 Training loss: 7.3070878982543945
2025-12-09 12:03:16.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.0009933040852333488 Training loss: 7.087226867675781
2025-12-09 12:03:17.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.00099325432139804 Training loss: 7.150514602661133
2025-12-09 12:03:17.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.0009932043745809064 Training loss: 6.274015426635742
2025-12-09 12:03:17.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.000993154244800476 Training loss: 6.670828819274902
2025-12-09 12:03:17.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.0009931039320753457 Training loss: 6.832633972167969
2025-12-09 12:03:17.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.00099305343642418 Training loss: 6.2933149337768555
2025-12-09 12:03:17.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.0009930027578657114 Training loss: 6.556875705718994
2025-12-09 12:03:17.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.0009929518964187393 Training loss: 6.5515313148498535
2025-12-09 12:03:17.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.0009929008521021325 Training loss: 6.835233211517334
2025-12-09 12:03:18.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.0009928496249348266 Training loss: 7.311041355133057
2025-12-09 12:03:18.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.000992798214935825 Training loss: 7.048940181732178
2025-12-09 12:03:18.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.0009927466221241995 Training loss: 6.962950706481934
2025-12-09 12:03:18.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.0009926948465190893 Training loss: 6.581498146057129
2025-12-09 12:03:18.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.0009926428881397015 Training loss: 6.305028915405273
2025-12-09 12:03:18.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.0009925907470053111 Training loss: 6.422947406768799
2025-12-09 12:03:18.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.0009925384231352606 Training loss: 6.871475696563721
2025-12-09 12:03:19.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0009924859165489608 Training loss: 6.6776814460754395
2025-12-09 12:03:19.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.0009924332272658897 Training loss: 6.732749938964844
2025-12-09 12:03:19.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.0009923803553055937 Training loss: 6.423061847686768
2025-12-09 12:03:19.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.0009923273006876864 Training loss: 6.569746971130371
2025-12-09 12:03:19.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0009922740634318494 Training loss: 7.094375133514404
2025-12-09 12:03:19.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.0009922206435578323 Training loss: 6.990843296051025
2025-12-09 12:03:19.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0009921670410854518 Training loss: 6.835886001586914
2025-12-09 12:03:19.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.0009921132560345928 Training loss: 6.617934703826904
2025-12-09 12:03:20.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.0009920592884252082 Training loss: 6.589437007904053
2025-12-09 12:03:20.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.0009920051382773178 Training loss: 7.052041053771973
2025-12-09 12:03:20.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.00099195080561101 Training loss: 6.554508209228516
2025-12-09 12:03:20.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.0009918962904464407 Training loss: 7.179710388183594
2025-12-09 12:03:20.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.0009918415928038325 Training loss: 6.453556537628174
2025-12-09 12:03:20.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.000991786712703477 Training loss: 6.961930274963379
2025-12-09 12:03:20.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.0009917316501657334 Training loss: 6.633442401885986
2025-12-09 12:03:20.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0009916764052110274 Training loss: 6.538117408752441
2025-12-09 12:03:21.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.0009916209778598536 Training loss: 6.53241491317749
2025-12-09 12:03:21.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.0009915653681327736 Training loss: 6.836720943450928
2025-12-09 12:03:21.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.000991509576050417 Training loss: 6.298804759979248
2025-12-09 12:03:21.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.0009914536016334807 Training loss: 6.660128593444824
2025-12-09 12:03:21.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.0009913974449027297 Training loss: 6.573736667633057
2025-12-09 12:03:21.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.0009913411058789963 Training loss: 6.468829154968262
2025-12-09 12:03:21.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.0009912845845831805 Training loss: 6.0087971687316895
2025-12-09 12:03:21.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.00099122788103625 Training loss: 6.561327934265137
2025-12-09 12:03:22.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.0009911709952592396 Training loss: 6.72817850112915
2025-12-09 12:03:22.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.0009911139272732526 Training loss: 6.421874046325684
2025-12-09 12:03:22.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.0009910566770994593 Training loss: 6.9131598472595215
2025-12-09 12:03:22.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.0009909992447590978 Training loss: 7.801738739013672
2025-12-09 12:03:22.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.0009909416302734736 Training loss: 6.818877696990967
2025-12-09 12:03:22.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.0009908838336639598 Training loss: 6.745377063751221
2025-12-09 12:03:22.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.000990825854951997 Training loss: 6.232327461242676
2025-12-09 12:03:22.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0009907676941590937 Training loss: 6.878891944885254
2025-12-09 12:03:23.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.0009907093513068259 Training loss: 6.4163126945495605
2025-12-09 12:03:23.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.0009906508264168365 Training loss: 6.347307205200195
2025-12-09 12:03:23.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.0009905921195108368 Training loss: 6.593333721160889
2025-12-09 12:03:23.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.0009905332306106049 Training loss: 6.610775470733643
2025-12-09 12:03:23.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.000990474159737987 Training loss: 6.1939496994018555
2025-12-09 12:03:23.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.0009904149069148963 Training loss: 6.496598720550537
2025-12-09 12:03:23.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.000990355472163314 Training loss: 6.78249454498291
2025-12-09 12:03:23.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.0009902958555052881 Training loss: 6.616597652435303
2025-12-09 12:03:24.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.0009902360569629348 Training loss: 6.598101615905762
2025-12-09 12:03:24.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.0009901760765584375 Training loss: 7.046745777130127
2025-12-09 12:03:24.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.000990115914314047 Training loss: 6.718498229980469
2025-12-09 12:03:24.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.0009900555702520816 Training loss: 6.860625743865967
2025-12-09 12:03:24.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.000989995044394927 Training loss: 7.100838661193848
2025-12-09 12:03:24.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0009899343367650365 Training loss: 6.6148905754089355
2025-12-09 12:03:24.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0009898734473849304 Training loss: 6.536470890045166
2025-12-09 12:03:25.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.0009898123762771972 Training loss: 7.065069675445557
2025-12-09 12:03:25.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.000989751123464492 Training loss: 6.761075973510742
2025-12-09 12:03:25.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.0009896896889695376 Training loss: 6.513956546783447
2025-12-09 12:03:25.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0009896280728151248 Training loss: 6.822356700897217
2025-12-09 12:03:25.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.0009895662750241108 Training loss: 6.746079444885254
2025-12-09 12:03:25.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.0009895042956194209 Training loss: 6.603967189788818
2025-12-09 12:03:25.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.0009894421346240473 Training loss: 6.528581142425537
2025-12-09 12:03:25.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.0009893797920610496 Training loss: 6.723762035369873
2025-12-09 12:03:26.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.0009893172679535552 Training loss: 6.841834545135498
2025-12-09 12:03:26.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.0009892545623247585 Training loss: 7.47447395324707
2025-12-09 12:03:26.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.0009891916751979218 Training loss: 6.604770660400391
2025-12-09 12:03:26.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.0009891286065963733 Training loss: 6.616488456726074
2025-12-09 12:03:26.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0009890653565435101 Training loss: 6.409182548522949
2025-12-09 12:03:26.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.0009890019250627959 Training loss: 7.317986011505127
2025-12-09 12:03:26.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.0009889383121777617 Training loss: 7.12453556060791
2025-12-09 12:03:26.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.000988874517912006 Training loss: 6.842548370361328
2025-12-09 12:03:27.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.0009888105422891941 Training loss: 6.871623992919922
2025-12-09 12:03:27.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0009887463853330593 Training loss: 7.00991153717041
2025-12-09 12:03:27.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.000988682047067402 Training loss: 6.517697334289551
2025-12-09 12:03:27.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.000988617527516089 Training loss: 6.929253578186035
2025-12-09 12:03:27.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.0009885528267030556 Training loss: 6.830944538116455
2025-12-09 12:03:27.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.0009884879446523036 Training loss: 6.434349060058594
2025-12-09 12:03:27.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.000988422881387902 Training loss: 6.710525035858154
2025-12-09 12:03:27.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.0009883576369339876 Training loss: 6.806839942932129
2025-12-09 12:03:28.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.0009882922113147636 Training loss: 6.444363594055176
2025-12-09 12:03:28.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.0009882266045545011 Training loss: 6.238527297973633
2025-12-09 12:03:28.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.0009881608166775384 Training loss: 6.811755657196045
2025-12-09 12:03:28.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.0009880948477082802 Training loss: 6.66322135925293
2025-12-09 12:03:28.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.0009880286976711992 Training loss: 6.434731483459473
2025-12-09 12:03:28.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.000987962366590835 Training loss: 6.579520225524902
2025-12-09 12:03:28.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.0009878958544917943 Training loss: 6.265983581542969
2025-12-09 12:03:28.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.0009878291613987509 Training loss: 6.5606536865234375
2025-12-09 12:03:29.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.000987762287336446 Training loss: 6.626275539398193
2025-12-09 12:03:29.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.0009876952323296876 Training loss: 6.556122303009033
2025-12-09 12:03:29.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.0009876279964033511 Training loss: 6.401126384735107
2025-12-09 12:03:29.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.000987560579582379 Training loss: 6.600388526916504
2025-12-09 12:03:29.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.0009874929818917805 Training loss: 6.612752437591553
2025-12-09 12:03:29.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.0009874252033566326 Training loss: 5.4670257568359375
2025-12-09 12:03:29.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.000987357244002079 Training loss: 6.899438381195068
2025-12-09 12:03:29.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.00098728910385333 Training loss: 6.511354446411133
2025-12-09 12:03:30.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.000987220782935664 Training loss: 6.437246322631836
2025-12-09 12:03:30.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.0009871522812744257 Training loss: 6.566300868988037
2025-12-09 12:03:30.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.0009870835988950268 Training loss: 6.104409694671631
2025-12-09 12:03:30.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.0009870147358229467 Training loss: 6.538071632385254
2025-12-09 12:03:30.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.0009869456920837312 Training loss: 6.752614974975586
2025-12-09 12:03:30.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.0009868764677029933 Training loss: 6.431708812713623
2025-12-09 12:03:30.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.0009868070627064133 Training loss: 6.329833030700684
2025-12-09 12:03:31.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.0009867374771197384 Training loss: 6.782079219818115
2025-12-09 12:03:31.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.0009866677109687822 Training loss: 6.5290632247924805
2025-12-09 12:03:31.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.0009865977642794259 Training loss: 6.717098236083984
2025-12-09 12:03:31.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.0009865276370776177 Training loss: 6.334634780883789
2025-12-09 12:03:31.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.0009864573293893724 Training loss: 6.339054107666016
2025-12-09 12:03:31.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.000986386841240772 Training loss: 6.514306545257568
2025-12-09 12:03:31.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0009863161726579655 Training loss: 6.447267532348633
2025-12-09 12:03:31.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0009862453236671685 Training loss: 6.696974754333496
2025-12-09 12:03:32.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.000986174294294664 Training loss: 6.915733337402344
2025-12-09 12:03:32.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.0009861030845668014 Training loss: 6.37598991394043
2025-12-09 12:03:32.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.0009860316945099973 Training loss: 6.434442520141602
2025-12-09 12:03:32.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0009859601241507354 Training loss: 6.6362833976745605
2025-12-09 12:03:32.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.0009858883735155658 Training loss: 6.5298237800598145
2025-12-09 12:03:32.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.0009858164426311058 Training loss: 6.831437587738037
2025-12-09 12:03:32.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.0009857443315240395 Training loss: 5.808970928192139
2025-12-09 12:03:32.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.000985672040221118 Training loss: 6.654963493347168
2025-12-09 12:03:33.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.000985599568749159 Training loss: 6.431772232055664
2025-12-09 12:03:33.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.000985526917135047 Training loss: 6.516060829162598
2025-12-09 12:03:33.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.0009854540854057337 Training loss: 6.624401569366455
2025-12-09 12:03:33.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.000985381073588237 Training loss: 6.5749030113220215
2025-12-09 12:03:33.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.0009853078817096423 Training loss: 7.427049160003662
2025-12-09 12:03:33.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.0009852345097971016 Training loss: 6.764505863189697
2025-12-09 12:03:33.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.0009851609578778332 Training loss: 6.568978309631348
2025-12-09 12:03:33.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0009850872259791227 Training loss: 6.3745198249816895
2025-12-09 12:03:34.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.0009850133141283226 Training loss: 7.027958869934082
2025-12-09 12:03:34.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.0009849392223528514 Training loss: 6.478643417358398
2025-12-09 12:03:34.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.000984864950680195 Training loss: 6.716550350189209
2025-12-09 12:03:34.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.000984790499137906 Training loss: 6.354851722717285
2025-12-09 12:03:34.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.0009847158677536033 Training loss: 6.483170032501221
2025-12-09 12:03:34.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.000984641056554973 Training loss: 6.2334184646606445
2025-12-09 12:03:34.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.0009845660655697678 Training loss: 6.58173942565918
2025-12-09 12:03:34.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.0009844908948258067 Training loss: 6.46934175491333
2025-12-09 12:03:35.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.000984415544350976 Training loss: 6.366387367248535
2025-12-09 12:03:35.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.000984340014173228 Training loss: 6.232658863067627
2025-12-09 12:03:35.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.0009842643043205823 Training loss: 6.900472164154053
2025-12-09 12:03:35.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.0009841884148211247 Training loss: 6.818996906280518
2025-12-09 12:03:35.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.000984112345703008 Training loss: 6.374688625335693
2025-12-09 12:03:35.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.000984036096994451 Training loss: 6.73113489151001
2025-12-09 12:03:35.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.0009839596687237402 Training loss: 6.496989727020264
2025-12-09 12:03:35.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.0009838830609192278 Training loss: 6.607463359832764
2025-12-09 12:03:36.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.0009838062736093327 Training loss: 6.716217517852783
2025-12-09 12:03:36.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.0009837293068225407 Training loss: 6.12101936340332
2025-12-09 12:03:36.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0009836521605874043 Training loss: 6.792470932006836
2025-12-09 12:03:36.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0009835748349325422 Training loss: 7.698047161102295
2025-12-09 12:03:36.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.0009834973298866393 Training loss: 6.68784761428833
2025-12-09 12:03:36.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.0009834196454784484 Training loss: 6.585480690002441
2025-12-09 12:03:36.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.0009833417817367873 Training loss: 6.361832618713379
2025-12-09 12:03:36.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.0009832637386905413 Training loss: 6.376302719116211
2025-12-09 12:03:37.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.0009831855163686617 Training loss: 6.359853744506836
2025-12-09 12:03:37.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.0009831071148001668 Training loss: 6.45081901550293
2025-12-09 12:03:37.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.0009830285340141408 Training loss: 5.481302738189697
2025-12-09 12:03:37.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.0009829497740397348 Training loss: 6.5897345542907715
2025-12-09 12:03:37.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.0009828708349061664 Training loss: 7.659575462341309
2025-12-09 12:03:37.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.0009827917166427196 Training loss: 6.7214860916137695
2025-12-09 12:03:37.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.0009827124192787445 Training loss: 6.700921535491943
2025-12-09 12:03:38.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.000982632942843658 Training loss: 6.8971734046936035
2025-12-09 12:03:38.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.0009825532873669433 Training loss: 6.096462249755859
2025-12-09 12:03:38.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0009824734528781505 Training loss: 6.854891777038574
2025-12-09 12:03:38.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.0009823934394068952 Training loss: 6.454542636871338
2025-12-09 12:03:38.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.0009823132469828602 Training loss: 6.471283435821533
2025-12-09 12:03:38.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.000982232875635794 Training loss: 6.587871074676514
2025-12-09 12:03:38.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.0009821523253955122 Training loss: 6.9285197257995605
2025-12-09 12:03:38.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.0009820715962918964 Training loss: 6.332165241241455
2025-12-09 12:03:39.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.0009819906883548942 Training loss: 6.723578453063965
2025-12-09 12:03:39.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.0009819096016145203 Training loss: 7.062783241271973
2025-12-09 12:03:39.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.000981828336100855 Training loss: 6.3791375160217285
2025-12-09 12:03:39.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.0009817468918440454 Training loss: 6.393143177032471
2025-12-09 12:03:39.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.0009816652688743048 Training loss: 6.718340873718262
2025-12-09 12:03:39.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.0009815834672219127 Training loss: 6.040677070617676
2025-12-09 12:03:39.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.000981501486917215 Training loss: 6.389911651611328
2025-12-09 12:03:39.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.0009814193279906237 Training loss: 6.158276557922363
2025-12-09 12:03:40.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.000981336990472617 Training loss: 6.454792499542236
2025-12-09 12:03:40.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.00098125447439374 Training loss: 6.271609783172607
2025-12-09 12:03:40.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.0009811717797846033 Training loss: 6.8715057373046875
2025-12-09 12:03:40.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.000981088906675884 Training loss: 6.241182327270508
2025-12-09 12:03:40.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0009810058550983253 Training loss: 5.875990867614746
2025-12-09 12:03:40.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.000980922625082737 Training loss: 7.108219146728516
2025-12-09 12:03:40.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.0009808392166599947 Training loss: 6.455345153808594
2025-12-09 12:03:40.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.0009807556298610403 Training loss: 6.829875946044922
2025-12-09 12:03:41.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.0009806718647168817 Training loss: 6.9094557762146
2025-12-09 12:03:41.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.0009805879212585933 Training loss: 6.791544437408447
2025-12-09 12:03:41.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.0009805037995173154 Training loss: 6.530855655670166
2025-12-09 12:03:41.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.0009804194995242548 Training loss: 6.286531925201416
2025-12-09 12:03:41.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.0009803350213106836 Training loss: 5.172741413116455
2025-12-09 12:03:41.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.000980250364907941 Training loss: 6.398804187774658
2025-12-09 12:03:41.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.0009801655303474318 Training loss: 6.6673383712768555
2025-12-09 12:03:41.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.000980080517660627 Training loss: 6.169914245605469
2025-12-09 12:03:42.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.0009799953268790633 Training loss: 6.4816107749938965
2025-12-09 12:03:42.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.000979909958034344 Training loss: 6.407988548278809
2025-12-09 12:03:42.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.0009798244111581382 Training loss: 6.297486782073975
2025-12-09 12:03:42.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.0009797386862821812 Training loss: 6.447037696838379
2025-12-09 12:03:42.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.0009796527834382745 Training loss: 6.216250896453857
2025-12-09 12:03:42.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.0009795667026582847 Training loss: 6.63519811630249
2025-12-09 12:03:42.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.0009794804439741454 Training loss: 6.792272090911865
2025-12-09 12:03:43.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.000979394007417856 Training loss: 6.628424644470215
2025-12-09 12:03:43.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.0009793073930214817 Training loss: 7.024183750152588
2025-12-09 12:03:43.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.0009792206008171535 Training loss: 6.265568733215332
2025-12-09 12:03:43.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.0009791336308370687 Training loss: 6.3925251960754395
2025-12-09 12:03:43.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.0009790464831134903 Training loss: 6.29970645904541
2025-12-09 12:03:43.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.0009789591576787476 Training loss: 6.51332950592041
2025-12-09 12:03:43.786 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.0009788716545652352 Training loss: 6.366156578063965
2025-12-09 12:03:43.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.0009787839738054146 Training loss: 6.510836124420166
2025-12-09 12:03:44.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.0009786961154318121 Training loss: 6.486940860748291
2025-12-09 12:03:44.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.0009786080794770206 Training loss: 6.471288681030273
2025-12-09 12:03:44.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.0009785198659736987 Training loss: 6.464500427246094
2025-12-09 12:03:44.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.0009784314749545706 Training loss: 6.460035800933838
2025-12-09 12:03:44.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.0009783429064524269 Training loss: 6.706320285797119
2025-12-09 12:03:44.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.0009782541605001234 Training loss: 6.1624860763549805
2025-12-09 12:03:44.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.0009781652371305826 Training loss: 6.392887115478516
2025-12-09 12:03:44.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.0009780761363767914 Training loss: 5.668431758880615
2025-12-09 12:03:45.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.000977986858271804 Training loss: 5.888003826141357
2025-12-09 12:03:45.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.0009778974028487398 Training loss: 6.439932823181152
2025-12-09 12:03:45.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.0009778077701407836 Training loss: 6.4065327644348145
2025-12-09 12:03:45.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.0009777179601811866 Training loss: 6.697622776031494
2025-12-09 12:03:45.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.0009776279730032654 Training loss: 6.546161651611328
2025-12-09 12:03:45.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.0009775378086404024 Training loss: 6.404727935791016
2025-12-09 12:03:45.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.0009774474671260455 Training loss: 6.410513877868652
2025-12-09 12:03:45.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.000977356948493709 Training loss: 6.660482883453369
2025-12-09 12:03:46.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.000977266252776972 Training loss: 6.481603145599365
2025-12-09 12:03:46.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.0009771753800094803 Training loss: 6.51197624206543
2025-12-09 12:03:46.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0009770843302249442 Training loss: 5.965072154998779
2025-12-09 12:03:46.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.0009769931034571409 Training loss: 5.990983963012695
2025-12-09 12:03:46.623 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.0009769016997399121 Training loss: 6.268945217132568
2025-12-09 12:03:46.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.000976810119107166 Training loss: 6.4428558349609375
2025-12-09 12:03:46.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.0009767183615928764 Training loss: 6.5886969566345215
2025-12-09 12:03:47.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.000976626427231082 Training loss: 6.14658260345459
2025-12-09 12:03:47.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.0009765343160558879 Training loss: 6.5717058181762695
2025-12-09 12:03:47.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.0009764420281014641 Training loss: 6.20658016204834
2025-12-09 12:03:47.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.0009763495634020466 Training loss: 7.0991997718811035
2025-12-09 12:03:47.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0009762569219919371 Training loss: 6.461499214172363
2025-12-09 12:03:47.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.0009761641039055025 Training loss: 6.7398200035095215
2025-12-09 12:03:47.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.0009760711091771755 Training loss: 6.706345081329346
2025-12-09 12:03:47.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.0009759779378414542 Training loss: 5.737017631530762
2025-12-09 12:03:48.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.0009758845899329021 Training loss: 6.1762919425964355
2025-12-09 12:03:48.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.0009757910654861482 Training loss: 7.0765485763549805
2025-12-09 12:03:48.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.0009756973645358876 Training loss: 6.635476112365723
2025-12-09 12:03:48.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.0009756034871168799 Training loss: 6.2325286865234375
2025-12-09 12:03:48.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.0009755094332639511 Training loss: 6.036492824554443
2025-12-09 12:03:48.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.0009754152030119921 Training loss: 6.118531227111816
2025-12-09 12:03:48.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.0009753207963959591 Training loss: 6.420346736907959
2025-12-09 12:03:48.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.0009752262134508741 Training loss: 6.549444675445557
2025-12-09 12:03:49.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.0009751314542118246 Training loss: 7.0090179443359375
2025-12-09 12:03:49.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0009750365187139631 Training loss: 6.332983493804932
2025-12-09 12:03:49.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0009749414069925077 Training loss: 6.655776023864746
2025-12-09 12:03:49.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.0009748461190827421 Training loss: 6.58729362487793
2025-12-09 12:03:49.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.0009747506550200146 Training loss: 6.607231140136719
2025-12-09 12:03:49.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.0009746550148397397 Training loss: 6.578985691070557
2025-12-09 12:03:49.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.0009745591985773971 Training loss: 6.663816452026367
2025-12-09 12:03:49.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0009744632062685312 Training loss: 5.973597526550293
2025-12-09 12:03:50.064 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.0009743670379487523 Training loss: 6.869509220123291
2025-12-09 12:03:50.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.0009742706936537357 Training loss: 6.368684768676758
2025-12-09 12:03:50.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.0009741741734192224 Training loss: 7.446974754333496
2025-12-09 12:03:50.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.0009740774772810182 Training loss: 6.31230354309082
2025-12-09 12:03:50.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.0009739806052749942 Training loss: 6.295523166656494
2025-12-09 12:03:50.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.0009738835574370871 Training loss: 6.206315994262695
2025-12-09 12:03:50.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.0009737863338032984 Training loss: 6.16643762588501
2025-12-09 12:03:50.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.0009736889344096951 Training loss: 6.316180229187012
2025-12-09 12:03:51.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.0009735913592924093 Training loss: 6.139079570770264
2025-12-09 12:03:51.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.0009734936084876383 Training loss: 6.252739429473877
2025-12-09 12:03:51.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.0009733956820316443 Training loss: 7.315304756164551
2025-12-09 12:03:51.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.0009732975799607554 Training loss: 6.714629173278809
2025-12-09 12:03:51.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.0009731993023113641 Training loss: 6.46361780166626
2025-12-09 12:03:51.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.0009731008491199284 Training loss: 6.249499320983887
2025-12-09 12:03:51.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0009730022204229714 Training loss: 6.591714382171631
2025-12-09 12:03:51.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0009729034162570811 Training loss: 6.546329498291016
2025-12-09 12:03:52.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.0009728044366589108 Training loss: 6.791184902191162
2025-12-09 12:03:52.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.0009727052816651788 Training loss: 6.547806739807129
2025-12-09 12:03:52.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.0009726059513126685 Training loss: 6.521251201629639
2025-12-09 12:03:52.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.0009725064456382282 Training loss: 6.15297794342041
2025-12-09 12:03:52.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.0009724067646787717 Training loss: 6.5335211753845215
2025-12-09 12:03:52.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0009723069084712771 Training loss: 6.502094745635986
2025-12-09 12:03:52.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.0009722068770527882 Training loss: 6.454440593719482
2025-12-09 12:03:53.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.0009721066704604133 Training loss: 6.202004432678223
2025-12-09 12:03:53.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0009720062887313262 Training loss: 5.766631603240967
2025-12-09 12:03:53.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.000971905731902765 Training loss: 6.461292266845703
2025-12-09 12:03:53.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.0009718050000120333 Training loss: 6.213130950927734
2025-12-09 12:03:53.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.0009717040930964996 Training loss: 6.608403205871582
2025-12-09 12:03:53.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.0009716030111935968 Training loss: 6.170299053192139
2025-12-09 12:03:53.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.0009715017543408234 Training loss: 6.081792831420898
2025-12-09 12:03:53.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0009714003225757424 Training loss: 7.25713586807251
2025-12-09 12:03:54.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.0009712987159359818 Training loss: 6.605785846710205
2025-12-09 12:03:54.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.0009711969344592346 Training loss: 6.485659122467041
2025-12-09 12:03:54.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.0009710949781832585 Training loss: 6.735185146331787
2025-12-09 12:03:54.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.0009709928471458759 Training loss: 6.64725923538208
2025-12-09 12:03:54.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.0009708905413849743 Training loss: 6.357053756713867
2025-12-09 12:03:54.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0009707880609385058 Training loss: 6.333167552947998
2025-12-09 12:03:54.794 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.0009706854058444876 Training loss: 6.217065334320068
2025-12-09 12:03:54.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0009705825761410014 Training loss: 6.37624979019165
2025-12-09 12:03:55.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.0009704795718661938 Training loss: 6.2714972496032715
2025-12-09 12:03:55.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.000970376393058276 Training loss: 6.4054999351501465
2025-12-09 12:03:55.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.0009702730397555246 Training loss: 6.570096969604492
2025-12-09 12:03:55.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.0009701695119962799 Training loss: 6.004060745239258
2025-12-09 12:03:55.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.0009700658098189476 Training loss: 6.496342182159424
2025-12-09 12:03:55.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.0009699619332619979 Training loss: 6.663668155670166
2025-12-09 12:03:55.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.0009698578823639658 Training loss: 6.240267753601074
2025-12-09 12:03:55.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.0009697536571634509 Training loss: 5.968716144561768
2025-12-09 12:03:56.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.0009696492576991174 Training loss: 6.512424468994141
2025-12-09 12:03:56.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.0009695446840096944 Training loss: 6.470773696899414
2025-12-09 12:03:56.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.0009694399361339751 Training loss: 6.281362533569336
2025-12-09 12:03:56.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0009693350141108182 Training loss: 6.877420425415039
2025-12-09 12:03:56.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.000969229917979146 Training loss: 5.347050189971924
2025-12-09 12:03:56.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.000969124647777946 Training loss: 6.491990089416504
2025-12-09 12:03:56.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.0009690192035462701 Training loss: 6.284433364868164
2025-12-09 12:03:56.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.0009689135853232349 Training loss: 6.214897632598877
2025-12-09 12:03:57.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.0009688077931480212 Training loss: 6.217370986938477
2025-12-09 12:03:57.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.0009687018270598749 Training loss: 6.146960258483887
2025-12-09 12:03:57.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.0009685956870981059 Training loss: 6.185265064239502
2025-12-09 12:03:57.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.0009684893733020888 Training loss: 6.552245616912842
2025-12-09 12:03:57.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.0009683828857112626 Training loss: 6.986239433288574
2025-12-09 12:03:57.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.0009682762243651309 Training loss: 7.167060852050781
2025-12-09 12:03:57.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.0009681693893032617 Training loss: 6.203007221221924
2025-12-09 12:03:57.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.0009680623805652876 Training loss: 6.72571325302124
2025-12-09 12:03:58.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.0009679551981909053 Training loss: 6.186853408813477
2025-12-09 12:03:58.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.000967847842219876 Training loss: 6.282524108886719
2025-12-09 12:03:58.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.0009677403126920255 Training loss: 6.351428031921387
2025-12-09 12:03:58.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.0009676326096472441 Training loss: 6.617810249328613
2025-12-09 12:03:58.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.0009675247331254858 Training loss: 5.6135711669921875
2025-12-09 12:03:58.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.0009674166831667697 Training loss: 6.246216773986816
2025-12-09 12:03:58.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.0009673084598111788 Training loss: 6.3827362060546875
2025-12-09 12:03:59.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.0009672000630988605 Training loss: 6.292949199676514
2025-12-09 12:03:59.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.0009670914930700268 Training loss: 6.364292144775391
2025-12-09 12:03:59.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.0009669827497649536 Training loss: 6.628636837005615
2025-12-09 12:03:59.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.0009668738332239813 Training loss: 6.250635623931885
2025-12-09 12:03:59.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.0009667647434875144 Training loss: 6.63932991027832
2025-12-09 12:03:59.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.0009666554805960219 Training loss: 6.331051349639893
2025-12-09 12:03:59.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.0009665460445900368 Training loss: 6.329664707183838
2025-12-09 12:03:59.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.0009664364355101565 Training loss: 6.075947284698486
2025-12-09 12:04:00.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.0009663266533970423 Training loss: 6.295769214630127
2025-12-09 12:04:00.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.0009662166982914202 Training loss: 5.876245498657227
2025-12-09 12:04:00.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.00096610657023408 Training loss: 6.127959728240967
2025-12-09 12:04:00.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.0009659962692658757 Training loss: 6.027772903442383
2025-12-09 12:04:00.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.0009658857954277254 Training loss: 6.833125591278076
2025-12-09 12:04:00.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.0009657751487606115 Training loss: 6.274590015411377
2025-12-09 12:04:00.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.0009656643293055805 Training loss: 6.136888027191162
2025-12-09 12:04:00.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.0009655533371037426 Training loss: 6.1777472496032715
2025-12-09 12:04:01.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.0009654421721962729 Training loss: 6.400061130523682
2025-12-09 12:04:01.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.0009653308346244099 Training loss: 5.823729038238525
2025-12-09 12:04:01.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.0009652193244294562 Training loss: 6.394837856292725
2025-12-09 12:04:01.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.0009651076416527786 Training loss: 6.328973770141602
2025-12-09 12:04:01.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.000964995786335808 Training loss: 6.716628551483154
2025-12-09 12:04:01.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.0009648837585200391 Training loss: 5.863666534423828
2025-12-09 12:04:01.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.0009647715582470309 Training loss: 6.745628833770752
2025-12-09 12:04:01.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.000964659185558406 Training loss: 6.315053939819336
2025-12-09 12:04:02.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.000964546640495851 Training loss: 6.107921123504639
2025-12-09 12:04:02.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.0009644339231011168 Training loss: 6.061578750610352
2025-12-09 12:04:02.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.0009643210334160178 Training loss: 6.147593975067139
2025-12-09 12:04:02.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.0009642079714824328 Training loss: 5.984225273132324
2025-12-09 12:04:02.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.0009640947373423039 Training loss: 5.943513870239258
