2025-12-09 12:07:33.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 0.0001 Training loss: 12.068840980529785
2025-12-09 12:07:33.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 0.0002 Training loss: 12.02260684967041
2025-12-09 12:07:33.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 0.0003 Training loss: 12.026599884033203
2025-12-09 12:07:33.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.0004 Training loss: 12.004720687866211
2025-12-09 12:07:33.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.0005 Training loss: 11.88783073425293
2025-12-09 12:07:33.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.0006 Training loss: 11.86867904663086
2025-12-09 12:07:33.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.0007000000000000001 Training loss: 11.766304969787598
2025-12-09 12:07:34.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.0008 Training loss: 11.51852798461914
2025-12-09 12:07:34.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.0009 Training loss: 11.287763595581055
2025-12-09 12:07:34.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.001 Training loss: 11.013116836547852
2025-12-09 12:07:34.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.0011 Training loss: 10.738701820373535
2025-12-09 12:07:34.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.0012 Training loss: 10.292537689208984
2025-12-09 12:07:34.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.0013000000000000002 Training loss: 9.728489875793457
2025-12-09 12:07:34.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.0014000000000000002 Training loss: 9.249190330505371
2025-12-09 12:07:34.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.0015 Training loss: 9.052129745483398
2025-12-09 12:07:35.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.0016 Training loss: 8.963780403137207
2025-12-09 12:07:35.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.0017000000000000001 Training loss: 8.617135047912598
2025-12-09 12:07:35.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.0018 Training loss: 8.00594711303711
2025-12-09 12:07:35.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.0019 Training loss: 7.99178409576416
2025-12-09 12:07:35.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.002 Training loss: 8.255762100219727
2025-12-09 12:07:35.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.0021 Training loss: 8.177886962890625
2025-12-09 12:07:35.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.0022 Training loss: 8.573063850402832
2025-12-09 12:07:36.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0023 Training loss: 8.141733169555664
2025-12-09 12:07:36.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0024 Training loss: 8.074204444885254
2025-12-09 12:07:36.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.0025 Training loss: 7.922895908355713
2025-12-09 12:07:36.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0026000000000000003 Training loss: 8.313508033752441
2025-12-09 12:07:36.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0027 Training loss: 8.23602294921875
2025-12-09 12:07:36.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0028000000000000004 Training loss: 8.101274490356445
2025-12-09 12:07:36.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.0029 Training loss: 7.795276165008545
2025-12-09 12:07:36.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.003 Training loss: 8.094681739807129
2025-12-09 12:07:37.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.0031 Training loss: 8.112197875976562
2025-12-09 12:07:37.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.0032 Training loss: 7.788909912109375
2025-12-09 12:07:37.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.0033000000000000004 Training loss: 7.734545707702637
2025-12-09 12:07:37.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.0034000000000000002 Training loss: 7.904723644256592
2025-12-09 12:07:37.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.0034999999999999996 Training loss: 8.141336441040039
2025-12-09 12:07:37.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.0036 Training loss: 7.900674343109131
2025-12-09 12:07:37.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.0037 Training loss: 8.333357810974121
2025-12-09 12:07:37.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.0038 Training loss: 7.748377799987793
2025-12-09 12:07:38.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.0039000000000000003 Training loss: 7.6838579177856445
2025-12-09 12:07:38.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.004 Training loss: 7.821983337402344
2025-12-09 12:07:38.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.0040999999999999995 Training loss: 7.82401180267334
2025-12-09 12:07:38.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.0042 Training loss: 7.7646307945251465
2025-12-09 12:07:38.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.0043 Training loss: 7.946351051330566
2025-12-09 12:07:38.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.0044 Training loss: 8.469719886779785
2025-12-09 12:07:38.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.0045000000000000005 Training loss: 7.5404133796691895
2025-12-09 12:07:39.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0046 Training loss: 7.640711307525635
2025-12-09 12:07:39.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.0047 Training loss: 7.739111423492432
2025-12-09 12:07:39.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0048 Training loss: 7.634212970733643
2025-12-09 12:07:39.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.0049 Training loss: 7.528499603271484
2025-12-09 12:07:39.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.005 Training loss: 7.67531156539917
2025-12-09 12:07:39.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0051 Training loss: 7.800546169281006
2025-12-09 12:07:39.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.005200000000000001 Training loss: 7.776494979858398
2025-12-09 12:07:39.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0053 Training loss: 7.610541343688965
2025-12-09 12:07:40.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0054 Training loss: 7.7797040939331055
2025-12-09 12:07:40.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0055000000000000005 Training loss: 6.835300445556641
2025-12-09 12:07:40.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.005600000000000001 Training loss: 7.320685386657715
2025-12-09 12:07:40.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.005699999999999999 Training loss: 8.274541854858398
2025-12-09 12:07:40.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.0058 Training loss: 7.443312644958496
2025-12-09 12:07:40.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0059 Training loss: 7.969785690307617
2025-12-09 12:07:40.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.006 Training loss: 7.639789581298828
2025-12-09 12:07:41.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.0061 Training loss: 7.474161148071289
2025-12-09 12:07:41.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.0062 Training loss: 7.884998321533203
2025-12-09 12:07:41.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.0063 Training loss: 7.425140380859375
2025-12-09 12:07:41.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.0064 Training loss: 7.69309139251709
2025-12-09 12:07:41.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.006500000000000001 Training loss: 7.225432395935059
2025-12-09 12:07:41.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.006600000000000001 Training loss: 6.72602653503418
2025-12-09 12:07:41.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.0067 Training loss: 7.163479804992676
2025-12-09 12:07:42.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.0068000000000000005 Training loss: 7.487659454345703
2025-12-09 12:07:42.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.0069 Training loss: 7.409610748291016
2025-12-09 12:07:42.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.006999999999999999 Training loss: 7.688326358795166
2025-12-09 12:07:42.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.0070999999999999995 Training loss: 7.7820868492126465
2025-12-09 12:07:42.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0072 Training loss: 7.711095809936523
2025-12-09 12:07:42.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.0073 Training loss: 7.455517292022705
2025-12-09 12:07:42.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.0074 Training loss: 7.6629486083984375
2025-12-09 12:07:42.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0075 Training loss: 7.5943217277526855
2025-12-09 12:07:43.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.0076 Training loss: 7.601009368896484
2025-12-09 12:07:43.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0077 Training loss: 8.897843360900879
2025-12-09 12:07:43.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0078000000000000005 Training loss: 7.483178615570068
2025-12-09 12:07:43.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.0079 Training loss: 7.707221984863281
2025-12-09 12:07:43.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.008 Training loss: 7.410747051239014
2025-12-09 12:07:43.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.008100000000000001 Training loss: 8.559602737426758
2025-12-09 12:07:43.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.008199999999999999 Training loss: 7.762932300567627
2025-12-09 12:07:44.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.0083 Training loss: 7.817702770233154
2025-12-09 12:07:44.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.0084 Training loss: 7.659909248352051
2025-12-09 12:07:44.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.0085 Training loss: 7.594141483306885
2025-12-09 12:07:44.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.0086 Training loss: 8.687628746032715
2025-12-09 12:07:44.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.0087 Training loss: 7.5960493087768555
2025-12-09 12:07:44.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.0088 Training loss: 7.510204315185547
2025-12-09 12:07:44.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0089 Training loss: 7.095714092254639
2025-12-09 12:07:44.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.009000000000000001 Training loss: 6.660184383392334
2025-12-09 12:07:45.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0091 Training loss: 7.4977569580078125
2025-12-09 12:07:45.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0092 Training loss: 7.382529258728027
2025-12-09 12:07:45.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.009300000000000001 Training loss: 7.625558376312256
2025-12-09 12:07:45.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.0094 Training loss: 6.860884666442871
2025-12-09 12:07:45.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.0095 Training loss: 7.274074077606201
2025-12-09 12:07:45.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0096 Training loss: 7.371702671051025
2025-12-09 12:07:45.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0097 Training loss: 7.528745174407959
2025-12-09 12:07:46.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.0098 Training loss: 7.5378642082214355
2025-12-09 12:07:46.175 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.0099 Training loss: 7.2867937088012695
2025-12-09 12:07:46.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.01 Training loss: 7.272467136383057
2025-12-09 12:07:46.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.009999999072578702 Training loss: 6.572204113006592
2025-12-09 12:07:46.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.009999996290315153 Training loss: 6.760834693908691
2025-12-09 12:07:46.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.009999991653210385 Training loss: 7.008298397064209
2025-12-09 12:07:46.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.009999985161266116 Training loss: 7.420165538787842
2025-12-09 12:07:46.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.009999976814484758 Training loss: 6.557229995727539
2025-12-09 12:07:47.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.009999966612869405 Training loss: 7.22451639175415
2025-12-09 12:07:47.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.009999954556423843 Training loss: 7.309723377227783
2025-12-09 12:07:47.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.009999940645152541 Training loss: 7.19513463973999
2025-12-09 12:07:47.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.009999924879060665 Training loss: 7.662733554840088
2025-12-09 12:07:47.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.00999990725815406 Training loss: 7.355587005615234
2025-12-09 12:07:47.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.009999887782439263 Training loss: 7.448657035827637
2025-12-09 12:07:47.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0099998664519235 Training loss: 7.410080432891846
2025-12-09 12:07:48.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.009999843266614685 Training loss: 7.501899242401123
2025-12-09 12:07:48.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.009999818226521415 Training loss: 7.165841102600098
2025-12-09 12:07:48.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.009999791331652984 Training loss: 7.106850624084473
2025-12-09 12:07:48.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.009999762582019366 Training loss: 7.002358913421631
2025-12-09 12:07:48.574 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.009999731977631227 Training loss: 7.3983283042907715
2025-12-09 12:07:48.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.00999969951849992 Training loss: 7.245190143585205
2025-12-09 12:07:48.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.009999665204637487 Training loss: 7.340131759643555
2025-12-09 12:07:48.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.009999629036056657 Training loss: 7.302378177642822
2025-12-09 12:07:49.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.009999591012770847 Training loss: 7.169332981109619
2025-12-09 12:07:49.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.009999551134794164 Training loss: 7.2034525871276855
2025-12-09 12:07:49.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.0099995094021414 Training loss: 7.109748363494873
2025-12-09 12:07:49.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.009999465814828036 Training loss: 7.138673305511475
2025-12-09 12:07:49.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.009999420372870242 Training loss: 7.06169319152832
2025-12-09 12:07:49.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.009999373076284877 Training loss: 7.2944512367248535
2025-12-09 12:07:49.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.009999323925089485 Training loss: 7.11116886138916
2025-12-09 12:07:50.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.009999272919302301 Training loss: 7.545513153076172
2025-12-09 12:07:50.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.009999220058942245 Training loss: 7.217156887054443
2025-12-09 12:07:50.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.009999165344028926 Training loss: 7.084878444671631
2025-12-09 12:07:50.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.009999108774582644 Training loss: 7.222248554229736
2025-12-09 12:07:50.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.009999050350624381 Training loss: 6.913064002990723
2025-12-09 12:07:50.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.009998990072175813 Training loss: 7.469227313995361
2025-12-09 12:07:50.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.009998927939259302 Training loss: 7.2413859367370605
2025-12-09 12:07:50.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.009998863951897896 Training loss: 7.29779577255249
2025-12-09 12:07:51.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.009998798110115333 Training loss: 6.9896087646484375
2025-12-09 12:07:51.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.009998730413936037 Training loss: 6.977590560913086
2025-12-09 12:07:51.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.009998660863385123 Training loss: 6.816384792327881
2025-12-09 12:07:51.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.00999858945848839 Training loss: 7.253718376159668
2025-12-09 12:07:51.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.009998516199272327 Training loss: 6.762037754058838
2025-12-09 12:07:51.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.009998441085764113 Training loss: 6.791608810424805
2025-12-09 12:07:51.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.009998364117991612 Training loss: 7.514488220214844
2025-12-09 12:07:52.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.009998285295983376 Training loss: 7.3405914306640625
2025-12-09 12:07:52.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.009998204619768645 Training loss: 7.113119125366211
2025-12-09 12:07:52.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.00999812208937735 Training loss: 7.178669452667236
2025-12-09 12:07:52.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.009998037704840102 Training loss: 7.142597675323486
2025-12-09 12:07:52.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.00999795146618821 Training loss: 7.262045860290527
2025-12-09 12:07:52.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.009997863373453663 Training loss: 7.244924068450928
2025-12-09 12:07:52.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.00999777342666914 Training loss: 7.167050361633301
2025-12-09 12:07:52.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.009997681625868013 Training loss: 7.032390594482422
2025-12-09 12:07:53.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.009997587971084335 Training loss: 7.048050403594971
2025-12-09 12:07:53.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.009997492462352845 Training loss: 7.082368850708008
2025-12-09 12:07:53.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.009997395099708982 Training loss: 6.95436429977417
2025-12-09 12:07:53.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.009997295883188855 Training loss: 6.782889366149902
2025-12-09 12:07:53.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.009997194812829277 Training loss: 7.279543399810791
2025-12-09 12:07:53.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.009997091888667738 Training loss: 6.9621992111206055
2025-12-09 12:07:53.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.009996987110742421 Training loss: 6.819182872772217
2025-12-09 12:07:54.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.009996880479092198 Training loss: 6.774692535400391
2025-12-09 12:07:54.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.009996771993756622 Training loss: 7.047635555267334
2025-12-09 12:07:54.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.009996661654775939 Training loss: 7.071662902832031
2025-12-09 12:07:54.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.009996549462191081 Training loss: 6.884219169616699
2025-12-09 12:07:54.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.00999643541604367 Training loss: 6.885129451751709
2025-12-09 12:07:54.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.00999631951637601 Training loss: 7.00908088684082
2025-12-09 12:07:54.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.009996201763231098 Training loss: 7.444464206695557
2025-12-09 12:07:54.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.009996082156652618 Training loss: 6.799189567565918
2025-12-09 12:07:55.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.009995960696684939 Training loss: 7.476241111755371
2025-12-09 12:07:55.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.009995837383373118 Training loss: 7.048361778259277
2025-12-09 12:07:55.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.009995712216762901 Training loss: 6.862912178039551
2025-12-09 12:07:55.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.009995585196900723 Training loss: 7.046309471130371
2025-12-09 12:07:55.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.009995456323833701 Training loss: 7.146768093109131
2025-12-09 12:07:55.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.009995325597609645 Training loss: 7.1847076416015625
2025-12-09 12:07:55.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.00999519301827705 Training loss: 7.102998733520508
2025-12-09 12:07:56.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.009995058585885095 Training loss: 7.6591477394104
2025-12-09 12:07:56.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.009994922300483657 Training loss: 7.084669589996338
2025-12-09 12:07:56.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.00999478416212329 Training loss: 7.2329607009887695
2025-12-09 12:07:56.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.009994644170855237 Training loss: 6.903466701507568
2025-12-09 12:07:56.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.009994502326731434 Training loss: 6.671261310577393
2025-12-09 12:07:56.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.009994358629804499 Training loss: 7.0196709632873535
2025-12-09 12:07:56.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.009994213080127738 Training loss: 6.843265056610107
2025-12-09 12:07:56.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.009994065677755147 Training loss: 7.047752857208252
2025-12-09 12:07:57.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.00999391642274141 Training loss: 6.861800670623779
2025-12-09 12:07:57.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.00999376531514189 Training loss: 6.939489841461182
2025-12-09 12:07:57.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.009993612355012647 Training loss: 7.17892599105835
2025-12-09 12:07:57.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.009993457542410423 Training loss: 7.004901885986328
2025-12-09 12:07:57.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.00999330087739265 Training loss: 6.904743194580078
2025-12-09 12:07:57.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.009993142360017445 Training loss: 6.731201171875
2025-12-09 12:07:57.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.009992981990343614 Training loss: 6.959482192993164
2025-12-09 12:07:58.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.009992819768430647 Training loss: 7.115710735321045
2025-12-09 12:07:58.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.009992655694338725 Training loss: 7.127700328826904
2025-12-09 12:07:58.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.009992489768128714 Training loss: 6.997066497802734
2025-12-09 12:07:58.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.009992321989862165 Training loss: 6.689940929412842
2025-12-09 12:07:58.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.009992152359601322 Training loss: 6.980851650238037
2025-12-09 12:07:58.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.00999198087740911 Training loss: 7.064992427825928
2025-12-09 12:07:58.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.009991807543349147 Training loss: 6.865890979766846
2025-12-09 12:07:58.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.009991632357485729 Training loss: 6.967036724090576
2025-12-09 12:07:59.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.009991455319883848 Training loss: 6.950840950012207
2025-12-09 12:07:59.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.00999127643060918 Training loss: 7.034242630004883
2025-12-09 12:07:59.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.009991095689728087 Training loss: 6.694693565368652
2025-12-09 12:07:59.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.009990913097307614 Training loss: 6.664931774139404
2025-12-09 12:07:59.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.009990728653415505 Training loss: 7.149901390075684
2025-12-09 12:07:59.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.009990542358120174 Training loss: 7.019759178161621
2025-12-09 12:07:59.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.009990354211490735 Training loss: 6.950501441955566
2025-12-09 12:08:00.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.009990164213596987 Training loss: 6.8844218254089355
2025-12-09 12:08:00.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.009989972364509407 Training loss: 6.801263809204102
2025-12-09 12:08:00.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.009989778664299172 Training loss: 6.561446189880371
2025-12-09 12:08:00.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.009989583113038134 Training loss: 6.851664066314697
2025-12-09 12:08:00.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.009989385710798838 Training loss: 7.557477951049805
2025-12-09 12:08:00.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.009989186457654514 Training loss: 6.8050408363342285
2025-12-09 12:08:00.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.009988985353679076 Training loss: 6.8399271965026855
2025-12-09 12:08:01.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.009988782398947132 Training loss: 6.626336574554443
2025-12-09 12:08:01.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.009988577593533967 Training loss: 6.478717803955078
2025-12-09 12:08:01.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.00998837093751556 Training loss: 5.89055871963501
2025-12-09 12:08:01.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.009988162430968575 Training loss: 6.7928786277771
2025-12-09 12:08:01.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.009987952073970359 Training loss: 7.168625831604004
2025-12-09 12:08:01.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.00998773986659895 Training loss: 7.275319576263428
2025-12-09 12:08:01.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.009987525808933069 Training loss: 6.994012355804443
2025-12-09 12:08:01.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.009987309901052122 Training loss: 7.041020393371582
2025-12-09 12:08:02.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.009987092143036209 Training loss: 6.723902225494385
2025-12-09 12:08:02.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.009986872534966109 Training loss: 6.988259315490723
2025-12-09 12:08:02.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.009986651076923288 Training loss: 6.694704532623291
2025-12-09 12:08:02.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.009986427768989904 Training loss: 7.187310695648193
2025-12-09 12:08:02.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.009986202611248794 Training loss: 6.57732629776001
2025-12-09 12:08:02.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.009985975603783484 Training loss: 6.667487621307373
2025-12-09 12:08:02.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.00998574674667819 Training loss: 6.950439453125
2025-12-09 12:08:03.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.009985516040017807 Training loss: 6.904449462890625
2025-12-09 12:08:03.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.009985283483887922 Training loss: 6.578742027282715
2025-12-09 12:08:03.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.009985049078374806 Training loss: 7.190900802612305
2025-12-09 12:08:03.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.009984812823565416 Training loss: 6.769802570343018
2025-12-09 12:08:03.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.009984574719547395 Training loss: 7.206991672515869
2025-12-09 12:08:03.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.00998433476640907 Training loss: 7.0008416175842285
2025-12-09 12:08:03.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.00998409296423946 Training loss: 6.909497261047363
2025-12-09 12:08:03.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.009983849313128264 Training loss: 7.4279303550720215
2025-12-09 12:08:04.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.009983603813165869 Training loss: 6.962609767913818
2025-12-09 12:08:04.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.009983356464443347 Training loss: 6.8223795890808105
2025-12-09 12:08:04.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.009983107267052456 Training loss: 6.7518486976623535
2025-12-09 12:08:04.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.009982856221085643 Training loss: 6.5444135665893555
2025-12-09 12:08:04.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.009982603326636037 Training loss: 7.348174095153809
2025-12-09 12:08:04.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.009982348583797453 Training loss: 7.006933689117432
2025-12-09 12:08:04.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.009982091992664392 Training loss: 6.655892848968506
2025-12-09 12:08:05.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.009981833553332044 Training loss: 6.883561611175537
2025-12-09 12:08:05.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.009981573265896281 Training loss: 7.180989742279053
2025-12-09 12:08:05.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.00998131113045366 Training loss: 6.777850151062012
2025-12-09 12:08:05.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.009981047147101425 Training loss: 6.207882404327393
2025-12-09 12:08:05.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.009980781315937506 Training loss: 6.5651774406433105
2025-12-09 12:08:05.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.00998051363706052 Training loss: 7.130690574645996
2025-12-09 12:08:05.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.009980244110569764 Training loss: 6.7978692054748535
2025-12-09 12:08:05.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.009979972736565226 Training loss: 7.322526931762695
2025-12-09 12:08:06.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.009979699515147577 Training loss: 6.687015533447266
2025-12-09 12:08:06.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.009979424446418172 Training loss: 7.044014930725098
2025-12-09 12:08:06.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.009979147530479055 Training loss: 6.94110631942749
2025-12-09 12:08:06.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.009978868767432954 Training loss: 6.781683444976807
2025-12-09 12:08:06.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.009978588157383277 Training loss: 7.111745834350586
2025-12-09 12:08:06.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.009978305700434125 Training loss: 6.6356706619262695
2025-12-09 12:08:06.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.00997802139669028 Training loss: 6.642664432525635
2025-12-09 12:08:07.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.009977735246257209 Training loss: 7.345240592956543
2025-12-09 12:08:07.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.009977447249241066 Training loss: 7.15781831741333
2025-12-09 12:08:07.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.009977157405748687 Training loss: 6.935877323150635
2025-12-09 12:08:07.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.009976865715887595 Training loss: 6.799764633178711
2025-12-09 12:08:07.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.009976572179765998 Training loss: 6.811060428619385
2025-12-09 12:08:07.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.009976276797492793 Training loss: 7.739269256591797
2025-12-09 12:08:07.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.009975979569177552 Training loss: 6.677379131317139
2025-12-09 12:08:07.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.009975680494930538 Training loss: 7.4922871589660645
2025-12-09 12:08:08.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.0099753795748627 Training loss: 7.454557418823242
2025-12-09 12:08:08.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.00997507680908567 Training loss: 6.879276752471924
2025-12-09 12:08:08.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.009974772197711762 Training loss: 6.374277114868164
2025-12-09 12:08:08.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.009974465740853979 Training loss: 7.156674861907959
2025-12-09 12:08:08.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.009974157438626008 Training loss: 7.0208353996276855
2025-12-09 12:08:08.786 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.009973847291142217 Training loss: 6.957695960998535
2025-12-09 12:08:08.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.009973535298517662 Training loss: 6.725693702697754
2025-12-09 12:08:09.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.009973221460868084 Training loss: 6.961019039154053
2025-12-09 12:08:09.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.009972905778309905 Training loss: 6.858501434326172
2025-12-09 12:08:09.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.009972588250960234 Training loss: 5.924248695373535
2025-12-09 12:08:09.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.009972268878936864 Training loss: 6.887411594390869
2025-12-09 12:08:09.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.009971947662358269 Training loss: 6.764411449432373
2025-12-09 12:08:09.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.009971624601343614 Training loss: 6.968844890594482
2025-12-09 12:08:09.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.009971299696012743 Training loss: 6.781720161437988
2025-12-09 12:08:09.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.009970972946486186 Training loss: 7.039689540863037
2025-12-09 12:08:10.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.009970644352885156 Training loss: 6.693514823913574
2025-12-09 12:08:10.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.009970313915331553 Training loss: 6.856912136077881
2025-12-09 12:08:10.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.009969981633947956 Training loss: 7.030015468597412
2025-12-09 12:08:10.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.009969647508857631 Training loss: 6.853391170501709
2025-12-09 12:08:10.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.00996931154018453 Training loss: 7.045505523681641
2025-12-09 12:08:10.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.009968973728053289 Training loss: 6.574999809265137
2025-12-09 12:08:10.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.009968634072589218 Training loss: 7.343296527862549
2025-12-09 12:08:11.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.009968292573918324 Training loss: 6.882440090179443
2025-12-09 12:08:11.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.009967949232167294 Training loss: 6.7375311851501465
2025-12-09 12:08:11.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.009967604047463493 Training loss: 6.861779689788818
2025-12-09 12:08:11.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.009967257019934974 Training loss: 7.012475490570068
2025-12-09 12:08:11.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.009966908149710475 Training loss: 6.454311370849609
2025-12-09 12:08:11.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.009966557436919416 Training loss: 6.7954277992248535
2025-12-09 12:08:11.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.009966204881691898 Training loss: 6.758236408233643
2025-12-09 12:08:12.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.00996585048415871 Training loss: 6.630969047546387
2025-12-09 12:08:12.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.009965494244451324 Training loss: 6.829540729522705
2025-12-09 12:08:12.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.00996513616270189 Training loss: 6.6797966957092285
2025-12-09 12:08:12.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.009964776239043245 Training loss: 6.9043450355529785
2025-12-09 12:08:12.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.009964414473608912 Training loss: 6.518424987792969
2025-12-09 12:08:12.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.009964050866533094 Training loss: 6.32871150970459
2025-12-09 12:08:12.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.009963685417950676 Training loss: 6.529360294342041
2025-12-09 12:08:12.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.00996331812799723 Training loss: 7.706552505493164
2025-12-09 12:08:13.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.009962948996809008 Training loss: 6.8440775871276855
2025-12-09 12:08:13.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.009962578024522948 Training loss: 6.663963317871094
2025-12-09 12:08:13.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.009962205211276665 Training loss: 7.38213586807251
2025-12-09 12:08:13.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.009961830557208463 Training loss: 6.665764808654785
2025-12-09 12:08:13.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.009961454062457329 Training loss: 7.3640851974487305
2025-12-09 12:08:13.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.009961075727162927 Training loss: 6.447863578796387
2025-12-09 12:08:13.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.009960695551465611 Training loss: 6.902159214019775
2025-12-09 12:08:14.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.009960313535506412 Training loss: 6.732865810394287
2025-12-09 12:08:14.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.009959929679427047 Training loss: 6.826725482940674
2025-12-09 12:08:14.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.009959543983369913 Training loss: 7.037285327911377
2025-12-09 12:08:14.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.009959156447478091 Training loss: 6.80013370513916
2025-12-09 12:08:14.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.009958767071895348 Training loss: 6.8972249031066895
2025-12-09 12:08:14.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.009958375856766127 Training loss: 6.7561774253845215
2025-12-09 12:08:14.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.009957982802235556 Training loss: 6.771286487579346
2025-12-09 12:08:14.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.009957587908449448 Training loss: 6.732707500457764
2025-12-09 12:08:15.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.009957191175554294 Training loss: 7.07874059677124
2025-12-09 12:08:15.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.009956792603697273 Training loss: 6.776334762573242
2025-12-09 12:08:15.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.009956392193026239 Training loss: 7.612469673156738
2025-12-09 12:08:15.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.009955989943689734 Training loss: 6.795159339904785
2025-12-09 12:08:15.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.009955585855836977 Training loss: 6.499397277832031
2025-12-09 12:08:15.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.009955179929617875 Training loss: 7.129858493804932
2025-12-09 12:08:15.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.009954772165183012 Training loss: 6.849942207336426
2025-12-09 12:08:16.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.009954362562683658 Training loss: 6.603510856628418
2025-12-09 12:08:16.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.00995395112227176 Training loss: 6.3835015296936035
2025-12-09 12:08:16.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.00995353784409995 Training loss: 6.774927616119385
2025-12-09 12:08:16.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.009953122728321542 Training loss: 7.023837089538574
2025-12-09 12:08:16.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.00995270577509053 Training loss: 6.852781295776367
2025-12-09 12:08:16.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.009952286984561591 Training loss: 6.611172199249268
2025-12-09 12:08:16.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.009951866356890084 Training loss: 7.284759998321533
2025-12-09 12:08:16.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.009951443892232048 Training loss: 7.192677021026611
2025-12-09 12:08:17.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.009951019590744202 Training loss: 6.58676815032959
2025-12-09 12:08:17.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.009950593452583952 Training loss: 6.270585536956787
2025-12-09 12:08:17.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.00995016547790938 Training loss: 6.765294551849365
2025-12-09 12:08:17.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.009949735666879251 Training loss: 7.042377471923828
2025-12-09 12:08:17.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.009949304019653011 Training loss: 6.481563568115234
2025-12-09 12:08:17.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.00994887053639079 Training loss: 6.781949520111084
2025-12-09 12:08:17.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.009948435217253393 Training loss: 7.036929607391357
2025-12-09 12:08:18.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.009947998062402312 Training loss: 6.666540622711182
2025-12-09 12:08:18.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.009947559071999719 Training loss: 6.750131607055664
2025-12-09 12:08:18.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.009947118246208461 Training loss: 6.950690746307373
2025-12-09 12:08:18.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.009946675585192076 Training loss: 7.11681604385376
2025-12-09 12:08:18.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.009946231089114773 Training loss: 6.969967365264893
2025-12-09 12:08:18.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.009945784758141448 Training loss: 6.729570388793945
2025-12-09 12:08:18.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.009945336592437678 Training loss: 6.726468086242676
2025-12-09 12:08:18.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.009944886592169713 Training loss: 6.627646446228027
2025-12-09 12:08:19.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.009944434757504492 Training loss: 6.969018459320068
2025-12-09 12:08:19.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.009943981088609631 Training loss: 7.571821689605713
2025-12-09 12:08:19.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.009943525585653428 Training loss: 7.174222469329834
2025-12-09 12:08:19.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.009943068248804858 Training loss: 6.9564032554626465
2025-12-09 12:08:19.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.009942609078233581 Training loss: 6.8608479499816895
2025-12-09 12:08:19.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.009942148074109933 Training loss: 6.473161697387695
2025-12-09 12:08:19.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.009941685236604934 Training loss: 6.774484634399414
2025-12-09 12:08:20.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.009941220565890278 Training loss: 6.598858833312988
2025-12-09 12:08:20.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.00994075406213835 Training loss: 6.60795783996582
2025-12-09 12:08:20.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.009940285725522203 Training loss: 6.859521389007568
2025-12-09 12:08:20.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.009939815556215575 Training loss: 7.081836223602295
2025-12-09 12:08:20.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.009939343554392886 Training loss: 6.7040205001831055
2025-12-09 12:08:20.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.009938869720229233 Training loss: 6.948998928070068
2025-12-09 12:08:20.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.009938394053900394 Training loss: 6.988515853881836
2025-12-09 12:08:20.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.009937916555582828 Training loss: 6.865485191345215
2025-12-09 12:08:21.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.009937437225453668 Training loss: 6.589911460876465
2025-12-09 12:08:21.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.009936956063690734 Training loss: 7.359358310699463
2025-12-09 12:08:21.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.009936473070472518 Training loss: 7.180293083190918
2025-12-09 12:08:21.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.009935988245978198 Training loss: 6.800931453704834
2025-12-09 12:08:21.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.009935501590387627 Training loss: 6.842100143432617
2025-12-09 12:08:21.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.009935013103881342 Training loss: 6.473936557769775
2025-12-09 12:08:21.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.009934522786640554 Training loss: 6.8957414627075195
2025-12-09 12:08:22.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.009934030638847154 Training loss: 6.725762367248535
2025-12-09 12:08:22.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.009933536660683716 Training loss: 6.730216979980469
2025-12-09 12:08:22.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.009933040852333487 Training loss: 6.511056423187256
2025-12-09 12:08:22.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.009932543213980401 Training loss: 6.499095916748047
2025-12-09 12:08:22.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.009932043745809064 Training loss: 6.504152297973633
2025-12-09 12:08:22.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.009931542448004758 Training loss: 7.478404998779297
2025-12-09 12:08:22.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.009931039320753456 Training loss: 6.693082332611084
2025-12-09 12:08:22.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.0099305343642418 Training loss: 6.86342716217041
2025-12-09 12:08:23.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.009930027578657113 Training loss: 6.451340675354004
2025-12-09 12:08:23.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.009929518964187393 Training loss: 7.126231670379639
2025-12-09 12:08:23.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.009929008521021325 Training loss: 7.516251087188721
2025-12-09 12:08:23.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.009928496249348266 Training loss: 6.5705084800720215
2025-12-09 12:08:23.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.00992798214935825 Training loss: 6.877208709716797
2025-12-09 12:08:23.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.009927466221241995 Training loss: 7.244980812072754
2025-12-09 12:08:23.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.009926948465190892 Training loss: 6.896451473236084
2025-12-09 12:08:24.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.009926428881397015 Training loss: 7.153913497924805
2025-12-09 12:08:24.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.00992590747005311 Training loss: 7.009307861328125
2025-12-09 12:08:24.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.009925384231352606 Training loss: 6.662200927734375
2025-12-09 12:08:24.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.009924859165489608 Training loss: 6.514883041381836
2025-12-09 12:08:24.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.009924332272658898 Training loss: 6.48444938659668
2025-12-09 12:08:24.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.009923803553055936 Training loss: 6.7733283042907715
2025-12-09 12:08:24.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.009923273006876865 Training loss: 6.505600452423096
2025-12-09 12:08:24.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.009922740634318495 Training loss: 6.702679634094238
2025-12-09 12:08:25.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.009922206435578323 Training loss: 6.781561374664307
2025-12-09 12:08:25.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.009921670410854518 Training loss: 6.689470291137695
2025-12-09 12:08:25.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.009921132560345929 Training loss: 6.739403247833252
2025-12-09 12:08:25.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.009920592884252082 Training loss: 6.849154949188232
2025-12-09 12:08:25.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.009920051382773179 Training loss: 6.836354732513428
2025-12-09 12:08:25.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.009919508056110101 Training loss: 6.77110481262207
2025-12-09 12:08:25.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.009918962904464406 Training loss: 6.694324970245361
2025-12-09 12:08:26.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.009918415928038325 Training loss: 6.79633092880249
2025-12-09 12:08:26.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.009917867127034772 Training loss: 7.3155951499938965
2025-12-09 12:08:26.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.009917316501657334 Training loss: 6.98588752746582
2025-12-09 12:08:26.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.009916764052110274 Training loss: 7.012304306030273
2025-12-09 12:08:26.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.009916209778598535 Training loss: 6.288936138153076
2025-12-09 12:08:26.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.009915653681327737 Training loss: 6.866219520568848
2025-12-09 12:08:26.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.009915095760504169 Training loss: 6.958688735961914
2025-12-09 12:08:27.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.009914536016334808 Training loss: 7.041754722595215
2025-12-09 12:08:27.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.009913974449027297 Training loss: 6.477917671203613
2025-12-09 12:08:27.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.009913411058789963 Training loss: 6.746083736419678
2025-12-09 12:08:27.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.009912845845831806 Training loss: 6.106548309326172
2025-12-09 12:08:27.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.009912278810362498 Training loss: 6.348630428314209
2025-12-09 12:08:27.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.009911709952592397 Training loss: 6.758655548095703
2025-12-09 12:08:27.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.009911139272732527 Training loss: 5.559207439422607
2025-12-09 12:08:27.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.009910566770994594 Training loss: 6.7939558029174805
2025-12-09 12:08:28.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.00990999244759098 Training loss: 6.515869140625
2025-12-09 12:08:28.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.009909416302734736 Training loss: 6.972872257232666
2025-12-09 12:08:28.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.009908838336639598 Training loss: 7.781882286071777
2025-12-09 12:08:28.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.00990825854951997 Training loss: 6.553752899169922
2025-12-09 12:08:28.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.009907676941590938 Training loss: 6.991635799407959
2025-12-09 12:08:28.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.009907093513068259 Training loss: 7.088854789733887
2025-12-09 12:08:28.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.009906508264168366 Training loss: 7.085658550262451
2025-12-09 12:08:29.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.009905921195108367 Training loss: 6.584487438201904
2025-12-09 12:08:29.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.00990533230610605 Training loss: 6.90223503112793
2025-12-09 12:08:29.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.00990474159737987 Training loss: 6.5904459953308105
2025-12-09 12:08:29.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.009904149069148962 Training loss: 6.771214962005615
2025-12-09 12:08:29.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.009903554721633139 Training loss: 6.68637752532959
2025-12-09 12:08:29.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.00990295855505288 Training loss: 6.648433208465576
2025-12-09 12:08:29.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.009902360569629348 Training loss: 6.724135398864746
2025-12-09 12:08:29.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.009901760765584376 Training loss: 6.524781227111816
2025-12-09 12:08:30.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.00990115914314047 Training loss: 6.581480503082275
2025-12-09 12:08:30.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.009900555702520816 Training loss: 6.807405948638916
2025-12-09 12:08:30.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.00989995044394927 Training loss: 7.112631797790527
2025-12-09 12:08:30.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.009899343367650365 Training loss: 6.628777027130127
2025-12-09 12:08:30.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.009898734473849305 Training loss: 6.590308666229248
2025-12-09 12:08:30.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.00989812376277197 Training loss: 6.567853927612305
2025-12-09 12:08:30.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.00989751123464492 Training loss: 6.5913190841674805
2025-12-09 12:08:31.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.009896896889695377 Training loss: 6.728925704956055
2025-12-09 12:08:31.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.009896280728151248 Training loss: 6.560935974121094
2025-12-09 12:08:31.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.009895662750241108 Training loss: 6.693058013916016
2025-12-09 12:08:31.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.009895042956194209 Training loss: 6.9183855056762695
2025-12-09 12:08:31.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.009894421346240473 Training loss: 6.9643449783325195
2025-12-09 12:08:31.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.009893797920610495 Training loss: 7.120804309844971
2025-12-09 12:08:31.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.009893172679535553 Training loss: 6.797580718994141
2025-12-09 12:08:31.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.009892545623247586 Training loss: 6.460376739501953
2025-12-09 12:08:32.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.009891916751979217 Training loss: 7.106161117553711
2025-12-09 12:08:32.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.009891286065963734 Training loss: 7.238894462585449
2025-12-09 12:08:32.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0098906535654351 Training loss: 6.854647636413574
2025-12-09 12:08:32.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.00989001925062796 Training loss: 6.8708319664001465
2025-12-09 12:08:32.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.009889383121777617 Training loss: 6.549482345581055
2025-12-09 12:08:32.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.00988874517912006 Training loss: 6.797246932983398
2025-12-09 12:08:32.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.009888105422891941 Training loss: 6.4989118576049805
2025-12-09 12:08:33.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.009887463853330595 Training loss: 6.496575832366943
2025-12-09 12:08:33.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.009886820470674018 Training loss: 6.5009236335754395
2025-12-09 12:08:33.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.00988617527516089 Training loss: 6.780055999755859
2025-12-09 12:08:33.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.009885528267030555 Training loss: 6.660881042480469
2025-12-09 12:08:33.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.009884879446523035 Training loss: 6.606099605560303
2025-12-09 12:08:33.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.00988422881387902 Training loss: 6.8248772621154785
2025-12-09 12:08:33.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.009883576369339874 Training loss: 6.904320240020752
2025-12-09 12:08:33.982 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.009882922113147636 Training loss: 7.341379642486572
2025-12-09 12:08:34.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.009882266045545011 Training loss: 6.4415364265441895
2025-12-09 12:08:34.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.009881608166775383 Training loss: 6.523916721343994
2025-12-09 12:08:34.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.009880948477082803 Training loss: 6.831442356109619
2025-12-09 12:08:34.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.009880286976711991 Training loss: 6.5638298988342285
2025-12-09 12:08:34.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.00987962366590835 Training loss: 6.211339473724365
2025-12-09 12:08:34.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.009878958544917943 Training loss: 6.521543502807617
2025-12-09 12:08:34.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.00987829161398751 Training loss: 6.740270137786865
2025-12-09 12:08:35.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.00987762287336446 Training loss: 6.630337715148926
2025-12-09 12:08:35.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.009876952323296877 Training loss: 6.910219192504883
2025-12-09 12:08:35.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.009876279964033513 Training loss: 6.794439792633057
2025-12-09 12:08:35.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.00987560579582379 Training loss: 6.472777366638184
2025-12-09 12:08:35.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.009874929818917806 Training loss: 6.799317359924316
2025-12-09 12:08:35.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.009874252033566327 Training loss: 7.209147930145264
2025-12-09 12:08:35.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.009873572440020791 Training loss: 6.987101078033447
2025-12-09 12:08:36.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.0098728910385333 Training loss: 6.496164798736572
2025-12-09 12:08:36.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.009872207829356642 Training loss: 6.583715915679932
2025-12-09 12:08:36.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.009871522812744256 Training loss: 6.557833194732666
2025-12-09 12:08:36.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.009870835988950269 Training loss: 6.575080394744873
2025-12-09 12:08:36.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.009870147358229466 Training loss: 6.749377250671387
2025-12-09 12:08:36.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.009869456920837311 Training loss: 6.612781047821045
2025-12-09 12:08:36.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.009868764677029934 Training loss: 6.824190616607666
2025-12-09 12:08:36.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.009868070627064135 Training loss: 6.510495662689209
2025-12-09 12:08:37.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.009867374771197384 Training loss: 7.783288478851318
2025-12-09 12:08:37.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.009866677109687822 Training loss: 6.549577713012695
2025-12-09 12:08:37.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.009865977642794259 Training loss: 6.55304479598999
2025-12-09 12:08:37.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.009865276370776178 Training loss: 6.830275535583496
2025-12-09 12:08:37.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.009864573293893723 Training loss: 6.665699005126953
2025-12-09 12:08:37.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.00986386841240772 Training loss: 6.940836429595947
2025-12-09 12:08:37.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.009863161726579655 Training loss: 6.720981121063232
2025-12-09 12:08:38.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.009862453236671684 Training loss: 6.477381229400635
2025-12-09 12:08:38.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.009861742942946639 Training loss: 7.046326160430908
2025-12-09 12:08:38.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.009861030845668013 Training loss: 6.458734035491943
2025-12-09 12:08:38.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.009860316945099973 Training loss: 6.306370258331299
2025-12-09 12:08:38.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.009859601241507353 Training loss: 6.572041034698486
2025-12-09 12:08:38.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.009858883735155657 Training loss: 6.546146869659424
2025-12-09 12:08:38.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.009858164426311058 Training loss: 6.761453151702881
2025-12-09 12:08:38.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.009857443315240397 Training loss: 6.871712684631348
2025-12-09 12:08:39.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.00985672040221118 Training loss: 6.702463626861572
2025-12-09 12:08:39.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.00985599568749159 Training loss: 6.717737674713135
2025-12-09 12:08:39.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.00985526917135047 Training loss: 6.7900190353393555
2025-12-09 12:08:39.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.009854540854057337 Training loss: 6.3940887451171875
2025-12-09 12:08:39.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.00985381073588237 Training loss: 7.13010311126709
2025-12-09 12:08:39.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.009853078817096423 Training loss: 6.416250228881836
2025-12-09 12:08:39.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.009852345097971017 Training loss: 7.98431396484375
2025-12-09 12:08:40.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.009851609578778332 Training loss: 6.7832865715026855
2025-12-09 12:08:40.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.009850872259791229 Training loss: 6.851373195648193
2025-12-09 12:08:40.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.009850133141283225 Training loss: 7.177769660949707
2025-12-09 12:08:40.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.009849392223528514 Training loss: 7.701266765594482
2025-12-09 12:08:40.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.00984864950680195 Training loss: 6.761897563934326
2025-12-09 12:08:40.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.00984790499137906 Training loss: 7.005186080932617
2025-12-09 12:08:40.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.009847158677536034 Training loss: 6.882162570953369
2025-12-09 12:08:40.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.00984641056554973 Training loss: 6.689735412597656
2025-12-09 12:08:41.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.009845660655697678 Training loss: 6.517639636993408
2025-12-09 12:08:41.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.009844908948258067 Training loss: 6.509895324707031
2025-12-09 12:08:41.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.009844155443509759 Training loss: 7.030264854431152
2025-12-09 12:08:41.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.009843400141732279 Training loss: 6.414584636688232
2025-12-09 12:08:41.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.009842643043205822 Training loss: 6.285444736480713
2025-12-09 12:08:41.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.009841884148211246 Training loss: 6.729576110839844
2025-12-09 12:08:41.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.009841123457030079 Training loss: 6.643771648406982
2025-12-09 12:08:42.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.009840360969944511 Training loss: 7.695133209228516
2025-12-09 12:08:42.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.009839596687237401 Training loss: 6.528184413909912
2025-12-09 12:08:42.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.009838830609192278 Training loss: 6.729249477386475
2025-12-09 12:08:42.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.009838062736093327 Training loss: 6.581391334533691
2025-12-09 12:08:42.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.009837293068225408 Training loss: 6.357097148895264
2025-12-09 12:08:42.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.009836521605874044 Training loss: 6.77377462387085
2025-12-09 12:08:42.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.009835748349325421 Training loss: 7.195592403411865
2025-12-09 12:08:42.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.009834973298866394 Training loss: 6.322962284088135
2025-12-09 12:08:43.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.009834196454784484 Training loss: 6.914031982421875
2025-12-09 12:08:43.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.009833417817367874 Training loss: 6.6714186668396
2025-12-09 12:08:43.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.009832637386905412 Training loss: 7.762450218200684
2025-12-09 12:08:43.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.009831855163686617 Training loss: 6.235714435577393
2025-12-09 12:08:43.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.009831071148001667 Training loss: 6.915584087371826
2025-12-09 12:08:43.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.009830285340141407 Training loss: 6.988616943359375
2025-12-09 12:08:43.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.009829497740397349 Training loss: 6.954751968383789
2025-12-09 12:08:44.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.009828708349061663 Training loss: 7.926614761352539
2025-12-09 12:08:44.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.009827917166427195 Training loss: 6.56548547744751
2025-12-09 12:08:44.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.009827124192787444 Training loss: 6.432253360748291
2025-12-09 12:08:44.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.00982632942843658 Training loss: 6.414690017700195
2025-12-09 12:08:44.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.009825532873669433 Training loss: 6.734241008758545
2025-12-09 12:08:44.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.009824734528781505 Training loss: 6.759487628936768
2025-12-09 12:08:44.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.009823934394068952 Training loss: 6.330987453460693
2025-12-09 12:08:44.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.009823132469828601 Training loss: 6.620509624481201
2025-12-09 12:08:45.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.009822328756357942 Training loss: 7.395278453826904
2025-12-09 12:08:45.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.009821523253955123 Training loss: 6.644076347351074
2025-12-09 12:08:45.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.009820715962918964 Training loss: 6.850991249084473
2025-12-09 12:08:45.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.009819906883548942 Training loss: 6.569371700286865
2025-12-09 12:08:45.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.009819096016145203 Training loss: 6.719439506530762
2025-12-09 12:08:45.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.00981828336100855 Training loss: 6.767709732055664
2025-12-09 12:08:45.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.009817468918440455 Training loss: 6.357865333557129
2025-12-09 12:08:46.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.009816652688743049 Training loss: 6.855771541595459
2025-12-09 12:08:46.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.009815834672219127 Training loss: 6.813036918640137
2025-12-09 12:08:46.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.00981501486917215 Training loss: 6.611138343811035
2025-12-09 12:08:46.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.009814193279906236 Training loss: 6.894766807556152
2025-12-09 12:08:46.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.00981336990472617 Training loss: 5.887566566467285
2025-12-09 12:08:46.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.0098125447439374 Training loss: 6.229372978210449
2025-12-09 12:08:46.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.009811717797846033 Training loss: 6.685842514038086
2025-12-09 12:08:47.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.00981088906675884 Training loss: 6.751376152038574
2025-12-09 12:08:47.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.009810058550983254 Training loss: 6.366332054138184
2025-12-09 12:08:47.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.009809226250827372 Training loss: 6.824065208435059
2025-12-09 12:08:47.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.009808392166599948 Training loss: 6.687029838562012
2025-12-09 12:08:47.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.009807556298610402 Training loss: 6.598841190338135
2025-12-09 12:08:47.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.009806718647168818 Training loss: 6.625784397125244
2025-12-09 12:08:47.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.009805879212585933 Training loss: 6.861649990081787
2025-12-09 12:08:47.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.009805037995173155 Training loss: 6.685739040374756
2025-12-09 12:08:48.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.009804194995242549 Training loss: 6.905912399291992
2025-12-09 12:08:48.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.009803350213106837 Training loss: 6.766468524932861
2025-12-09 12:08:48.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.00980250364907941 Training loss: 6.574820041656494
2025-12-09 12:08:48.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.009801655303474318 Training loss: 6.381176948547363
2025-12-09 12:08:48.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.009800805176606269 Training loss: 6.664783477783203
2025-12-09 12:08:48.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.009799953268790632 Training loss: 6.537549018859863
2025-12-09 12:08:48.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.00979909958034344 Training loss: 6.432698726654053
2025-12-09 12:08:49.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.009798244111581382 Training loss: 6.922760963439941
2025-12-09 12:08:49.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.009797386862821814 Training loss: 6.3246002197265625
2025-12-09 12:08:49.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.009796527834382745 Training loss: 6.4424662590026855
2025-12-09 12:08:49.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.009795667026582846 Training loss: 6.450649738311768
2025-12-09 12:08:49.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.009794804439741454 Training loss: 6.539015769958496
2025-12-09 12:08:49.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.00979394007417856 Training loss: 7.049798011779785
2025-12-09 12:08:49.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.009793073930214816 Training loss: 6.57327127456665
2025-12-09 12:08:49.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.009792206008171534 Training loss: 6.456254959106445
2025-12-09 12:08:50.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.009791336308370686 Training loss: 6.508340358734131
2025-12-09 12:08:50.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.009790464831134903 Training loss: 7.004909038543701
2025-12-09 12:08:50.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.009789591576787476 Training loss: 6.635045051574707
2025-12-09 12:08:50.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.009788716545652353 Training loss: 6.387712001800537
2025-12-09 12:08:50.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.009787839738054147 Training loss: 6.730361461639404
2025-12-09 12:08:50.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.009786961154318121 Training loss: 6.5340704917907715
2025-12-09 12:08:50.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.009786080794770207 Training loss: 6.941072463989258
2025-12-09 12:08:51.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.009785198659736987 Training loss: 6.351048946380615
2025-12-09 12:08:51.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.009784314749545706 Training loss: 6.270993232727051
2025-12-09 12:08:51.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.00978342906452427 Training loss: 6.622349262237549
2025-12-09 12:08:51.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.009782541605001235 Training loss: 6.541226863861084
2025-12-09 12:08:51.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.009781652371305825 Training loss: 6.3982110023498535
2025-12-09 12:08:51.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.009780761363767914 Training loss: 6.393101692199707
2025-12-09 12:08:51.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.009779868582718041 Training loss: 6.582632064819336
2025-12-09 12:08:51.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.009778974028487398 Training loss: 6.089515686035156
2025-12-09 12:08:52.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.009778077701407838 Training loss: 6.4507341384887695
2025-12-09 12:08:52.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.009777179601811866 Training loss: 6.476016044616699
2025-12-09 12:08:52.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.009776279730032653 Training loss: 6.573533535003662
2025-12-09 12:08:52.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.009775378086404022 Training loss: 7.024589538574219
2025-12-09 12:08:52.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.009774474671260455 Training loss: 6.818474292755127
2025-12-09 12:08:52.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.00977356948493709 Training loss: 6.530781269073486
2025-12-09 12:08:52.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.00977266252776972 Training loss: 6.843957901000977
2025-12-09 12:08:53.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.009771753800094802 Training loss: 6.493797779083252
2025-12-09 12:08:53.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.009770843302249442 Training loss: 6.397099494934082
2025-12-09 12:08:53.290 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.009769931034571407 Training loss: 6.583032131195068
2025-12-09 12:08:53.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.00976901699739912 Training loss: 7.582807540893555
2025-12-09 12:08:53.556 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.009768101191071661 Training loss: 6.5025763511657715
2025-12-09 12:08:53.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.009767183615928763 Training loss: 6.8968424797058105
2025-12-09 12:08:53.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.009766264272310822 Training loss: 6.426103115081787
2025-12-09 12:08:53.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.009765343160558878 Training loss: 7.293953895568848
2025-12-09 12:08:54.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.009764420281014641 Training loss: 6.955187797546387
2025-12-09 12:08:54.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.009763495634020467 Training loss: 6.332810401916504
2025-12-09 12:08:54.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.009762569219919371 Training loss: 6.554468631744385
2025-12-09 12:08:54.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.009761641039055026 Training loss: 6.46536922454834
2025-12-09 12:08:54.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.009760711091771755 Training loss: 6.432880878448486
2025-12-09 12:08:54.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.009759779378414542 Training loss: 6.799166679382324
2025-12-09 12:08:54.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.009758845899329021 Training loss: 6.775013446807861
2025-12-09 12:08:55.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.009757910654861483 Training loss: 6.617191791534424
2025-12-09 12:08:55.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.009756973645358876 Training loss: 6.559113025665283
2025-12-09 12:08:55.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.009756034871168799 Training loss: 6.717047691345215
2025-12-09 12:08:55.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.009755094332639512 Training loss: 6.660333156585693
2025-12-09 12:08:55.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.00975415203011992 Training loss: 6.475316524505615
2025-12-09 12:08:55.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.00975320796395959 Training loss: 6.67305326461792
2025-12-09 12:08:55.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.009752262134508742 Training loss: 6.677375316619873
2025-12-09 12:08:55.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.009751314542118247 Training loss: 6.6840596199035645
2025-12-09 12:08:56.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.009750365187139632 Training loss: 6.592565536499023
2025-12-09 12:08:56.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.009749414069925078 Training loss: 6.8610124588012695
2025-12-09 12:08:56.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.00974846119082742 Training loss: 6.7560648918151855
2025-12-09 12:08:56.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.009747506550200145 Training loss: 7.043131351470947
2025-12-09 12:08:56.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.009746550148397396 Training loss: 6.430453777313232
2025-12-09 12:08:56.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.00974559198577397 Training loss: 7.014657974243164
2025-12-09 12:08:56.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.009744632062685311 Training loss: 6.608686923980713
2025-12-09 12:08:57.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.009743670379487522 Training loss: 6.7747578620910645
2025-12-09 12:08:57.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.009742706936537358 Training loss: 6.774240016937256
2025-12-09 12:08:57.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.009741741734192224 Training loss: 6.4782938957214355
2025-12-09 12:08:57.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.009740774772810181 Training loss: 6.509241580963135
2025-12-09 12:08:57.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.009739806052749942 Training loss: 6.721220016479492
2025-12-09 12:08:57.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.009738835574370872 Training loss: 6.717033863067627
2025-12-09 12:08:57.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.009737863338032985 Training loss: 6.712897300720215
2025-12-09 12:08:57.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.009736889344096951 Training loss: 6.62851095199585
2025-12-09 12:08:58.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.009735913592924092 Training loss: 6.7002105712890625
2025-12-09 12:08:58.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.009734936084876382 Training loss: 6.730133533477783
2025-12-09 12:08:58.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.009733956820316443 Training loss: 6.620143890380859
2025-12-09 12:08:58.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.009732975799607553 Training loss: 6.6481451988220215
2025-12-09 12:08:58.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.00973199302311364 Training loss: 6.750279426574707
2025-12-09 12:08:58.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.009731008491199285 Training loss: 6.698187828063965
2025-12-09 12:08:58.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.009730022204229714 Training loss: 6.376865386962891
2025-12-09 12:08:59.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.009729034162570812 Training loss: 6.470648765563965
2025-12-09 12:08:59.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.009728044366589108 Training loss: 6.897624969482422
2025-12-09 12:08:59.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.009727052816651788 Training loss: 6.612435340881348
2025-12-09 12:08:59.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.009726059513126686 Training loss: 6.607030391693115
2025-12-09 12:08:59.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.009725064456382283 Training loss: 6.513270854949951
2025-12-09 12:08:59.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.009724067646787717 Training loss: 6.790168762207031
2025-12-09 12:08:59.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.00972306908471277 Training loss: 6.264499664306641
2025-12-09 12:08:59.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.009722068770527881 Training loss: 6.592294692993164
2025-12-09 12:09:00.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.009721066704604134 Training loss: 6.519721031188965
2025-12-09 12:09:00.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.00972006288731326 Training loss: 6.237661838531494
2025-12-09 12:09:00.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.00971905731902765 Training loss: 6.794955253601074
2025-12-09 12:09:00.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.009718050000120333 Training loss: 6.536647796630859
2025-12-09 12:09:00.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.009717040930964996 Training loss: 6.733771324157715
2025-12-09 12:09:00.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.009716030111935968 Training loss: 6.520160675048828
2025-12-09 12:09:00.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.009715017543408233 Training loss: 6.717585563659668
2025-12-09 12:09:01.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.009714003225757424 Training loss: 6.4487786293029785
2025-12-09 12:09:01.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.009712987159359818 Training loss: 6.836394786834717
2025-12-09 12:09:01.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.009711969344592347 Training loss: 6.657700061798096
2025-12-09 12:09:01.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.009710949781832585 Training loss: 6.626388072967529
2025-12-09 12:09:01.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.009709928471458759 Training loss: 6.42011833190918
2025-12-09 12:09:01.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.009708905413849743 Training loss: 6.267456531524658
2025-12-09 12:09:01.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.009707880609385058 Training loss: 6.347795486450195
2025-12-09 12:09:01.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.009706854058444877 Training loss: 6.186948299407959
2025-12-09 12:09:02.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.009705825761410014 Training loss: 6.868524551391602
2025-12-09 12:09:02.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.009704795718661938 Training loss: 6.740872859954834
2025-12-09 12:09:02.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.00970376393058276 Training loss: 6.5814127922058105
2025-12-09 12:09:02.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.009702730397555245 Training loss: 6.843767166137695
2025-12-09 12:09:02.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.009701695119962798 Training loss: 6.690139293670654
2025-12-09 12:09:02.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.009700658098189475 Training loss: 6.1951165199279785
2025-12-09 12:09:02.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.009699619332619978 Training loss: 6.429620265960693
2025-12-09 12:09:03.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.009698578823639658 Training loss: 6.761087417602539
2025-12-09 12:09:03.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.009697536571634508 Training loss: 6.550556182861328
2025-12-09 12:09:03.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.009696492576991175 Training loss: 6.422069549560547
2025-12-09 12:09:03.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.009695446840096945 Training loss: 6.485523223876953
2025-12-09 12:09:03.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.009694399361339753 Training loss: 6.369103908538818
2025-12-09 12:09:03.745 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.009693350141108182 Training loss: 6.725902557373047
2025-12-09 12:09:03.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.00969229917979146 Training loss: 6.947174072265625
2025-12-09 12:09:04.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.009691246477779459 Training loss: 6.451821327209473
2025-12-09 12:09:04.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.0096901920354627 Training loss: 6.709645748138428
2025-12-09 12:09:04.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.009689135853232349 Training loss: 6.8299689292907715
2025-12-09 12:09:04.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.009688077931480212 Training loss: 6.941962242126465
2025-12-09 12:09:04.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.009687018270598749 Training loss: 6.429923057556152
2025-12-09 12:09:04.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.009685956870981059 Training loss: 6.640658378601074
2025-12-09 12:09:04.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.009684893733020887 Training loss: 6.4688334465026855
2025-12-09 12:09:04.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.009683828857112626 Training loss: 6.7475080490112305
2025-12-09 12:09:05.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.009682762243651308 Training loss: 5.867447376251221
2025-12-09 12:09:05.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.009681693893032617 Training loss: 6.129164218902588
2025-12-09 12:09:05.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.009680623805652875 Training loss: 6.940500736236572
2025-12-09 12:09:05.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.009679551981909052 Training loss: 6.750192165374756
2025-12-09 12:09:05.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.00967847842219876 Training loss: 5.952862739562988
2025-12-09 12:09:05.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.009677403126920255 Training loss: 6.6299824714660645
2025-12-09 12:09:05.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.00967632609647244 Training loss: 6.820544719696045
2025-12-09 12:09:06.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.009675247331254857 Training loss: 6.690580368041992
2025-12-09 12:09:06.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.009674166831667696 Training loss: 6.40915584564209
2025-12-09 12:09:06.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.009673084598111788 Training loss: 6.873575687408447
2025-12-09 12:09:06.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.009672000630988605 Training loss: 6.376134872436523
2025-12-09 12:09:06.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.009670914930700268 Training loss: 7.093797206878662
2025-12-09 12:09:06.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.009669827497649537 Training loss: 6.361751079559326
2025-12-09 12:09:06.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.009668738332239813 Training loss: 6.747757911682129
2025-12-09 12:09:06.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.009667647434875144 Training loss: 6.855175495147705
2025-12-09 12:09:07.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.00966655480596022 Training loss: 6.620063781738281
2025-12-09 12:09:07.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.009665460445900368 Training loss: 6.472957611083984
2025-12-09 12:09:07.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.009664364355101564 Training loss: 6.656523704528809
2025-12-09 12:09:07.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.009663266533970424 Training loss: 6.645740509033203
2025-12-09 12:09:07.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.009662166982914203 Training loss: 6.545040607452393
2025-12-09 12:09:07.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.0096610657023408 Training loss: 6.4658918380737305
2025-12-09 12:09:07.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.009659962692658756 Training loss: 7.291782379150391
2025-12-09 12:09:08.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.009658857954277254 Training loss: 6.852299213409424
2025-12-09 12:09:08.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.009657751487606114 Training loss: 5.509487628936768
2025-12-09 12:09:08.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.009656643293055805 Training loss: 6.753030776977539
2025-12-09 12:09:08.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.009655533371037426 Training loss: 6.526644229888916
2025-12-09 12:09:08.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.009654421721962729 Training loss: 6.220489025115967
2025-12-09 12:09:08.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.009653308346244099 Training loss: 6.460282802581787
2025-12-09 12:09:08.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.009652193244294562 Training loss: 6.053178310394287
2025-12-09 12:09:09.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.009651076416527786 Training loss: 6.833230972290039
2025-12-09 12:09:09.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.00964995786335808 Training loss: 6.566738128662109
2025-12-09 12:09:09.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.009648837585200392 Training loss: 6.476998329162598
2025-12-09 12:09:09.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.00964771558247031 Training loss: 6.470883369445801
2025-12-09 12:09:09.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.00964659185558406 Training loss: 7.117226600646973
2025-12-09 12:09:09.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.00964546640495851 Training loss: 7.232943058013916
2025-12-09 12:09:09.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.009644339231011169 Training loss: 6.451460838317871
2025-12-09 12:09:09.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.009643210334160178 Training loss: 6.526371955871582
2025-12-09 12:09:10.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.009642079714824328 Training loss: 6.312585830688477
2025-12-09 12:09:10.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.00964094737342304 Training loss: 6.919478416442871
