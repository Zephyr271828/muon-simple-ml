2025-12-09 12:08:05.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 0.0001 Training loss: 4.964031219482422
2025-12-09 12:08:05.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 0.0002 Training loss: 4.920886516571045
2025-12-09 12:08:05.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 0.0003 Training loss: 4.867537021636963
2025-12-09 12:08:05.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.0004 Training loss: 4.74768590927124
2025-12-09 12:08:05.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.0005 Training loss: 4.790375709533691
2025-12-09 12:08:05.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.0006 Training loss: 4.520353317260742
2025-12-09 12:08:05.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.0007000000000000001 Training loss: 4.726772785186768
2025-12-09 12:08:05.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.0008 Training loss: 4.708503246307373
2025-12-09 12:08:05.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.0009 Training loss: 4.577335834503174
2025-12-09 12:08:05.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.001 Training loss: 4.390108108520508
2025-12-09 12:08:05.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.0011 Training loss: 4.48075008392334
2025-12-09 12:08:05.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.0012 Training loss: 4.487858295440674
2025-12-09 12:08:05.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.0013000000000000002 Training loss: 4.5411696434021
2025-12-09 12:08:06.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.0014000000000000002 Training loss: 4.509962558746338
2025-12-09 12:08:06.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.0015 Training loss: 4.470780372619629
2025-12-09 12:08:06.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.0016 Training loss: 4.439901351928711
2025-12-09 12:08:06.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.0017000000000000001 Training loss: 4.492313385009766
2025-12-09 12:08:06.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.0018 Training loss: 4.353745460510254
2025-12-09 12:08:06.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.0019 Training loss: 4.371682167053223
2025-12-09 12:08:06.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.002 Training loss: 4.548332214355469
2025-12-09 12:08:06.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.0021 Training loss: 4.352470874786377
2025-12-09 12:08:06.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.0022 Training loss: 4.238433837890625
2025-12-09 12:08:06.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0023 Training loss: 4.166964530944824
2025-12-09 12:08:06.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0024 Training loss: 4.344674587249756
2025-12-09 12:08:06.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.0025 Training loss: 4.0654683113098145
2025-12-09 12:08:06.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0026000000000000003 Training loss: 4.377280235290527
2025-12-09 12:08:06.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0027 Training loss: 4.332311630249023
2025-12-09 12:08:06.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0028000000000000004 Training loss: 4.134580612182617
2025-12-09 12:08:06.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.0029 Training loss: 4.546237945556641
2025-12-09 12:08:06.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.003 Training loss: 4.274167060852051
2025-12-09 12:08:06.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.0031 Training loss: 4.218870639801025
2025-12-09 12:08:06.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.0032 Training loss: 4.270751476287842
2025-12-09 12:08:06.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.0033000000000000004 Training loss: 4.174614906311035
2025-12-09 12:08:06.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.0034000000000000002 Training loss: 4.156720161437988
2025-12-09 12:08:06.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.0034999999999999996 Training loss: 4.2336106300354
2025-12-09 12:08:06.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.0036 Training loss: 4.240270137786865
2025-12-09 12:08:06.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.0037 Training loss: 4.175465106964111
2025-12-09 12:08:06.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.0038 Training loss: 4.201331615447998
2025-12-09 12:08:06.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.0039000000000000003 Training loss: 4.630127429962158
2025-12-09 12:08:06.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.004 Training loss: 4.447897434234619
2025-12-09 12:08:06.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.0040999999999999995 Training loss: 4.183568000793457
2025-12-09 12:08:06.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.0042 Training loss: 4.270409107208252
2025-12-09 12:08:06.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.0043 Training loss: 4.305760383605957
2025-12-09 12:08:06.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.0044 Training loss: 4.094882011413574
2025-12-09 12:08:06.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.0045000000000000005 Training loss: 4.185548305511475
2025-12-09 12:08:06.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0046 Training loss: 3.9459304809570312
2025-12-09 12:08:06.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.0047 Training loss: 4.113375186920166
2025-12-09 12:08:06.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0048 Training loss: 4.355465888977051
2025-12-09 12:08:06.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.0049 Training loss: 4.125142574310303
2025-12-09 12:08:06.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.005 Training loss: 4.05518913269043
2025-12-09 12:08:06.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0051 Training loss: 4.163570404052734
2025-12-09 12:08:06.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.005200000000000001 Training loss: 4.268872261047363
2025-12-09 12:08:06.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0053 Training loss: 4.1108527183532715
2025-12-09 12:08:06.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0054 Training loss: 3.8671607971191406
2025-12-09 12:08:06.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0055000000000000005 Training loss: 4.105704307556152
2025-12-09 12:08:06.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.005600000000000001 Training loss: 4.055304527282715
2025-12-09 12:08:06.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.005699999999999999 Training loss: 4.247432708740234
2025-12-09 12:08:06.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.0058 Training loss: 3.946279525756836
2025-12-09 12:08:06.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0059 Training loss: 4.032462120056152
2025-12-09 12:08:06.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.006 Training loss: 4.004905700683594
2025-12-09 12:08:06.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.0061 Training loss: 4.1150922775268555
2025-12-09 12:08:06.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.0062 Training loss: 4.061941146850586
2025-12-09 12:08:06.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.0063 Training loss: 4.075565814971924
2025-12-09 12:08:06.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.0064 Training loss: 4.225064277648926
2025-12-09 12:08:06.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.006500000000000001 Training loss: 4.074202060699463
2025-12-09 12:08:06.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.006600000000000001 Training loss: 4.1024298667907715
2025-12-09 12:08:06.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.0067 Training loss: 4.112710952758789
2025-12-09 12:08:06.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.0068000000000000005 Training loss: 4.057206153869629
2025-12-09 12:08:06.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.0069 Training loss: 4.210938930511475
2025-12-09 12:08:06.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.006999999999999999 Training loss: 4.734240531921387
2025-12-09 12:08:06.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.0070999999999999995 Training loss: 4.301483154296875
2025-12-09 12:08:06.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0072 Training loss: 4.171261787414551
2025-12-09 12:08:06.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.0073 Training loss: 4.048961639404297
2025-12-09 12:08:06.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.0074 Training loss: 3.9773144721984863
2025-12-09 12:08:06.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0075 Training loss: 4.237824440002441
2025-12-09 12:08:06.574 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.0076 Training loss: 4.287691593170166
2025-12-09 12:08:06.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0077 Training loss: 4.072853088378906
2025-12-09 12:08:06.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0078000000000000005 Training loss: 4.278404235839844
2025-12-09 12:08:06.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.0079 Training loss: 4.3817458152771
2025-12-09 12:08:06.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.008 Training loss: 4.484127044677734
2025-12-09 12:08:06.623 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.008100000000000001 Training loss: 4.053979396820068
2025-12-09 12:08:06.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.008199999999999999 Training loss: 3.9456863403320312
2025-12-09 12:08:06.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.0083 Training loss: 4.202836036682129
2025-12-09 12:08:06.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.0084 Training loss: 4.2553510665893555
2025-12-09 12:08:06.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.0085 Training loss: 4.121187686920166
2025-12-09 12:08:06.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.0086 Training loss: 4.673640251159668
2025-12-09 12:08:06.677 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.0087 Training loss: 4.514811038970947
2025-12-09 12:08:06.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.0088 Training loss: 4.536930084228516
2025-12-09 12:08:06.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0089 Training loss: 4.489092826843262
2025-12-09 12:08:06.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.009000000000000001 Training loss: 4.302606582641602
2025-12-09 12:08:06.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0091 Training loss: 4.5816264152526855
2025-12-09 12:08:06.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0092 Training loss: 4.411131858825684
2025-12-09 12:08:06.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.009300000000000001 Training loss: 4.292599678039551
2025-12-09 12:08:06.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.0094 Training loss: 4.29238748550415
2025-12-09 12:08:06.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.0095 Training loss: 4.079727649688721
2025-12-09 12:08:06.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0096 Training loss: 4.328945159912109
2025-12-09 12:08:06.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0097 Training loss: 4.143002033233643
2025-12-09 12:08:06.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.0098 Training loss: 4.302794456481934
2025-12-09 12:08:06.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.0099 Training loss: 4.033949375152588
2025-12-09 12:08:06.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.01 Training loss: 4.08897590637207
2025-12-09 12:08:06.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.009999708626830616 Training loss: 4.355571269989014
2025-12-09 12:08:06.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.009998834541281799 Training loss: 4.295639991760254
2025-12-09 12:08:06.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.009997377845227575 Training loss: 4.243244647979736
2025-12-09 12:08:06.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.009995338708444804 Training loss: 4.687609672546387
2025-12-09 12:08:06.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.009992717368593385 Training loss: 4.041380405426025
2025-12-09 12:08:06.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.009989514131188558 Training loss: 4.899167537689209
2025-12-09 12:08:06.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.009985729369565299 Training loss: 4.04181432723999
2025-12-09 12:08:06.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0099813635248348 Training loss: 4.433789253234863
2025-12-09 12:08:06.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.00997641710583307 Training loss: 4.390942096710205
2025-12-09 12:08:06.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.009970890689061622 Training loss: 4.350428581237793
2025-12-09 12:08:06.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.009964784918620281 Training loss: 4.206364631652832
2025-12-09 12:08:06.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.009958100506132127 Training loss: 4.029748916625977
2025-12-09 12:08:06.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.009950838230660534 Training loss: 4.242629051208496
2025-12-09 12:08:06.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.009942998938618395 Training loss: 4.402425289154053
2025-12-09 12:08:06.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.009934583543669454 Training loss: 4.1653218269348145
2025-12-09 12:08:06.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.009925593026621833 Training loss: 4.261630535125732
2025-12-09 12:08:06.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.009916028435313709 Training loss: 3.9592783451080322
2025-12-09 12:08:06.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.009905890884491196 Training loss: 4.326292514801025
2025-12-09 12:08:06.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.00989518155567842 Training loss: 4.436776161193848
2025-12-09 12:08:06.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.009883901697039808 Training loss: 3.993624687194824
2025-12-09 12:08:06.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.009872052623234632 Training loss: 4.232292652130127
2025-12-09 12:08:06.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.00985963571526376 Training loss: 4.045760154724121
2025-12-09 12:08:07.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.009846652420308728 Training loss: 3.980534315109253
2025-12-09 12:08:07.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.009833104251563056 Training loss: 3.933861494064331
2025-12-09 12:08:07.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.00981899278805589 Training loss: 3.984405994415283
2025-12-09 12:08:07.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.009804319674467968 Training loss: 4.030821323394775
2025-12-09 12:08:07.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.009789086620939936 Training loss: 4.160632610321045
2025-12-09 12:08:07.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.009773295402873026 Training loss: 4.01830530166626
2025-12-09 12:08:07.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.009756947860722143 Training loss: 4.099470615386963
2025-12-09 12:08:07.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.009740045899781353 Training loss: 3.988734245300293
2025-12-09 12:08:07.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.009722591489961827 Training loss: 4.058880805969238
2025-12-09 12:08:07.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.009704586665562249 Training loss: 4.080212593078613
2025-12-09 12:08:07.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.00968603352503172 Training loss: 3.8112478256225586
2025-12-09 12:08:07.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.009666934230725179 Training loss: 3.977064609527588
2025-12-09 12:08:07.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.009647291008651398 Training loss: 3.7647006511688232
2025-12-09 12:08:07.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.009627106148213521 Training loss: 3.8220467567443848
2025-12-09 12:08:07.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.009606382001942255 Training loss: 3.987565279006958
2025-12-09 12:08:07.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.00958512098522167 Training loss: 4.1046013832092285
2025-12-09 12:08:07.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.0095633255760077 Training loss: 3.819007158279419
2025-12-09 12:08:07.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.009540998314539327 Training loss: 3.8456501960754395
2025-12-09 12:08:07.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.009518141803042527 Training loss: 4.14857816696167
2025-12-09 12:08:07.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.009494758705426976 Training loss: 3.924873113632202
2025-12-09 12:08:07.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.009470851746975581 Training loss: 3.9046967029571533
2025-12-09 12:08:07.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.009446423714026845 Training loss: 3.9580461978912354
2025-12-09 12:08:07.212 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.009421477453650118 Training loss: 3.958885908126831
2025-12-09 12:08:07.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.009396015873313781 Training loss: 4.161806106567383
2025-12-09 12:08:07.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.00937004194054638 Training loss: 3.9708642959594727
2025-12-09 12:08:07.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.009343558682590757 Training loss: 3.9767374992370605
2025-12-09 12:08:07.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.009316569186051234 Training loss: 3.966686964035034
2025-12-09 12:08:07.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.009289076596533871 Training loss: 3.950759172439575
2025-12-09 12:08:07.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.009261084118279847 Training loss: 3.942756175994873
2025-12-09 12:08:07.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.009232595013792002 Training loss: 3.983461618423462
2025-12-09 12:08:07.290 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.009203612603454604 Training loss: 3.7666962146759033
2025-12-09 12:08:07.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.009174140265146355 Training loss: 3.728516101837158
2025-12-09 12:08:07.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.009144181433846706 Training loss: 3.991407632827759
2025-12-09 12:08:07.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.009113739601235507 Training loss: 3.8842859268188477
2025-12-09 12:08:07.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.009082818315286054 Training loss: 3.837867498397827
2025-12-09 12:08:07.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.009051421179851587 Training loss: 3.734846353530884
2025-12-09 12:08:07.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.00901955185424525 Training loss: 3.935180187225342
2025-12-09 12:08:07.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.008987214052813604 Training loss: 3.939822196960449
2025-12-09 12:08:07.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.00895441154450373 Training loss: 3.8627185821533203
2025-12-09 12:08:07.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.008921148152423945 Training loss: 3.9923183917999268
2025-12-09 12:08:07.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.008887427753398248 Training loss: 3.9145307540893555
2025-12-09 12:08:07.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.008853254277514447 Training loss: 3.8311026096343994
2025-12-09 12:08:07.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.008818631707666134 Training loss: 3.698424816131592
2025-12-09 12:08:07.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.008783564079088476 Training loss: 3.7428462505340576
2025-12-09 12:08:07.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.008748055478887904 Training loss: 3.7172036170959473
2025-12-09 12:08:07.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.008712110045565767 Training loss: 3.8676986694335938
2025-12-09 12:08:07.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.008675731968536002 Training loss: 3.5496506690979004
2025-12-09 12:08:07.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.008638925487636848 Training loss: 3.932173490524292
2025-12-09 12:08:07.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0086016948926367 Training loss: 3.999241828918457
2025-12-09 12:08:07.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.008564044522734147 Training loss: 3.916696548461914
2025-12-09 12:08:07.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.008525978766052229 Training loss: 3.7447242736816406
2025-12-09 12:08:07.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.008487502059127015 Training loss: 3.645946979522705
2025-12-09 12:08:07.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.008448618886390521 Training loss: 3.917273759841919
2025-12-09 12:08:07.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.00840933377964806 Training loss: 3.5373523235321045
2025-12-09 12:08:07.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.008369651317550054 Training loss: 4.111636638641357
2025-12-09 12:08:07.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.008329576125058406 Training loss: 4.271346569061279
2025-12-09 12:08:07.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.008289112872907454 Training loss: 3.939560651779175
2025-12-09 12:08:07.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.008248266277059607 Training loss: 3.725374937057495
2025-12-09 12:08:07.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0082070410981557 Training loss: 3.5894367694854736
2025-12-09 12:08:07.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.00816544214096015 Training loss: 3.975665330886841
2025-12-09 12:08:07.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.008123474253800956 Training loss: 3.8159921169281006
2025-12-09 12:08:07.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.008081142328004637 Training loss: 3.8124866485595703
2025-12-09 12:08:07.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.008038451297326145 Training loss: 3.867389440536499
2025-12-09 12:08:07.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.007995406137373847 Training loss: 3.8258984088897705
2025-12-09 12:08:07.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.007952011865029614 Training loss: 3.7601795196533203
2025-12-09 12:08:07.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.007908273537864113 Training loss: 3.7580037117004395
2025-12-09 12:08:07.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.007864196253547348 Training loss: 3.7203054428100586
2025-12-09 12:08:07.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.007819785149254532 Training loss: 3.7311806678771973
2025-12-09 12:08:07.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.00777504540106735 Training loss: 3.612208127975464
2025-12-09 12:08:07.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.007729982223370691 Training loss: 3.9780163764953613
2025-12-09 12:08:07.662 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.00768460086824492 Training loss: 3.7632503509521484
2025-12-09 12:08:07.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.007638906624853743 Training loss: 3.741607904434204
2025-12-09 12:08:07.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.007592904818827774 Training loss: 3.8846967220306396
2025-12-09 12:08:07.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.007546600811643816 Training loss: 3.7135846614837646
2025-12-09 12:08:07.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0075 Training loss: 3.8395676612854004
2025-12-09 12:08:07.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.007453107815186802 Training loss: 3.878628969192505
2025-12-09 12:08:07.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.007405929722454026 Training loss: 3.7882494926452637
2025-12-09 12:08:07.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.007358471220373831 Training loss: 3.477409839630127
2025-12-09 12:08:07.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.007310737840199885 Training loss: 3.7476189136505127
2025-12-09 12:08:07.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.007262735145222695 Training loss: 3.761913776397705
2025-12-09 12:08:07.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.007214468730121208 Training loss: 3.7920243740081787
2025-12-09 12:08:07.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.007165944220310766 Training loss: 3.88323712348938
2025-12-09 12:08:07.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.007117167271287452 Training loss: 3.7832114696502686
2025-12-09 12:08:07.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.007068143567968957 Training loss: 3.604858160018921
2025-12-09 12:08:07.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.0070188788240320085 Training loss: 3.6523821353912354
2025-12-09 12:08:07.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.006969378781246436 Training loss: 3.6422693729400635
2025-12-09 12:08:07.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.006919649208805981 Training loss: 3.699244976043701
2025-12-09 12:08:07.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0068696959026558965 Training loss: 3.8413069248199463
2025-12-09 12:08:07.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.006819524684817438 Training loss: 3.6826364994049072
2025-12-09 12:08:07.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.0067691414027093045 Training loss: 3.553469657897949
2025-12-09 12:08:07.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.006718551928466133 Training loss: 3.8524248600006104
2025-12-09 12:08:07.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.006667762158254104 Training loss: 3.6983840465545654
2025-12-09 12:08:07.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.006616778011583743 Training loss: 3.748141288757324
2025-12-09 12:08:07.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.006565605430620013 Training loss: 3.765688896179199
2025-12-09 12:08:07.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.006514250379489753 Training loss: 3.7307372093200684
2025-12-09 12:08:07.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.006462718843586571 Training loss: 3.728634834289551
2025-12-09 12:08:07.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.0064110168288732386 Training loss: 3.803635358810425
2025-12-09 12:08:07.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.006359150361181715 Training loss: 3.8110415935516357
2025-12-09 12:08:07.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.006307125485510829 Training loss: 3.7982640266418457
2025-12-09 12:08:07.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0062549482653217435 Training loss: 3.618145227432251
2025-12-09 12:08:07.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0062026247818312685 Training loss: 3.51385498046875
2025-12-09 12:08:07.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0061501611333030885 Training loss: 3.5782346725463867
2025-12-09 12:08:07.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.006097563434337026 Training loss: 3.56891131401062
2025-12-09 12:08:07.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.006044837815156376 Training loss: 3.3781228065490723
2025-12-09 12:08:07.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.005991990420893449 Training loss: 3.725404739379883
2025-12-09 12:08:07.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.005939027410873351 Training loss: 3.533642292022705
2025-12-09 12:08:07.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0058859549578961145 Training loss: 3.695100784301758
2025-12-09 12:08:08.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.005832779247517273 Training loss: 3.789862871170044
2025-12-09 12:08:08.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0057795064773269325 Training loss: 3.822359800338745
2025-12-09 12:08:08.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.005726142856227452 Training loss: 3.5691146850585938
2025-12-09 12:08:08.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.005672694603709794 Training loss: 3.606661796569824
2025-12-09 12:08:08.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.005619167949128652 Training loss: 3.651599168777466
2025-12-09 12:08:08.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.005565569130976423 Training loss: 3.8377068042755127
2025-12-09 12:08:08.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.005511904396156113 Training loss: 3.5475616455078125
2025-12-09 12:08:08.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.005458179999253274 Training loss: 3.5323143005371094
2025-12-09 12:08:08.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.005404402201807022 Training loss: 3.519440174102783
2025-12-09 12:08:08.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.00535057727158027 Training loss: 3.488731861114502
2025-12-09 12:08:08.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.005296711481829226 Training loss: 3.668745756149292
2025-12-09 12:08:08.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.005242811110572242 Training loss: 3.7320878505706787
2025-12-09 12:08:08.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.005188882439858117 Training loss: 3.4119462966918945
2025-12-09 12:08:08.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.005134931755033936 Training loss: 3.579960346221924
2025-12-09 12:08:08.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.005080965344012508 Training loss: 3.561310291290283
2025-12-09 12:08:08.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.005026989496539522 Training loss: 3.3746659755706787
2025-12-09 12:08:08.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.004973010503460479 Training loss: 3.6181137561798096
2025-12-09 12:08:08.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.004919034655987493 Training loss: 3.461945056915283
2025-12-09 12:08:08.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.004865068244966066 Training loss: 3.566275119781494
2025-12-09 12:08:08.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0048111175601418844 Training loss: 3.5142834186553955
2025-12-09 12:08:08.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.0047571888894277605 Training loss: 3.6237871646881104
2025-12-09 12:08:08.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0047032885181707736 Training loss: 3.5322763919830322
2025-12-09 12:08:08.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.004649422728419729 Training loss: 3.66679310798645
2025-12-09 12:08:08.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0045955977981929795 Training loss: 3.54617977142334
2025-12-09 12:08:08.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.004541820000746727 Training loss: 3.5433602333068848
2025-12-09 12:08:08.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.004488095603843887 Training loss: 3.6932992935180664
2025-12-09 12:08:08.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.004434430869023579 Training loss: 3.562283992767334
2025-12-09 12:08:08.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.00438083205087135 Training loss: 3.7345168590545654
2025-12-09 12:08:08.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.004327305396290207 Training loss: 3.655421495437622
2025-12-09 12:08:08.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.00427385714377255 Training loss: 3.5548651218414307
2025-12-09 12:08:08.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.004220493522673068 Training loss: 3.817049980163574
2025-12-09 12:08:08.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.004167220752482727 Training loss: 3.671358823776245
2025-12-09 12:08:08.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0041140450421038866 Training loss: 3.5207037925720215
2025-12-09 12:08:08.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00406097258912665 Training loss: 3.451143980026245
2025-12-09 12:08:08.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.004008009579106551 Training loss: 3.2644565105438232
2025-12-09 12:08:08.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.003955162184843625 Training loss: 3.3671908378601074
2025-12-09 12:08:08.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.003902436565662977 Training loss: 3.5309669971466064
2025-12-09 12:08:08.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.003849838866696913 Training loss: 3.567234754562378
2025-12-09 12:08:08.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.003797375218168733 Training loss: 3.3663036823272705
2025-12-09 12:08:08.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.0037450517346782563 Training loss: 3.3669731616973877
2025-12-09 12:08:08.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0036928745144891727 Training loss: 3.4110286235809326
2025-12-09 12:08:08.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.0036408496388182854 Training loss: 3.208122491836548
2025-12-09 12:08:08.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0035889831711267616 Training loss: 3.6078221797943115
2025-12-09 12:08:08.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.00353728115641343 Training loss: 3.8069021701812744
2025-12-09 12:08:08.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.003485749620510247 Training loss: 3.5232067108154297
2025-12-09 12:08:08.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0034343945693799884 Training loss: 3.7145049571990967
2025-12-09 12:08:08.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.0033832219884162586 Training loss: 3.566326141357422
2025-12-09 12:08:08.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0033322378417458983 Training loss: 3.4138333797454834
2025-12-09 12:08:08.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.0032814480715338667 Training loss: 3.2611474990844727
2025-12-09 12:08:08.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0032308585972906966 Training loss: 3.2878410816192627
2025-12-09 12:08:08.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0031804753151825627 Training loss: 3.4729793071746826
2025-12-09 12:08:08.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0031303040973441033 Training loss: 3.533477306365967
2025-12-09 12:08:08.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.003080350791194019 Training loss: 3.637805938720703
2025-12-09 12:08:08.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0030306212187535654 Training loss: 3.6500678062438965
2025-12-09 12:08:08.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0029811211759679926 Training loss: 3.5412025451660156
2025-12-09 12:08:08.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0029318564320310442 Training loss: 3.464329481124878
2025-12-09 12:08:08.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.002882832728712551 Training loss: 3.419491767883301
2025-12-09 12:08:08.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0028340557796892353 Training loss: 3.420792579650879
2025-12-09 12:08:08.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0027855312698787903 Training loss: 3.5235707759857178
2025-12-09 12:08:08.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.002737264854777306 Training loss: 3.4033334255218506
2025-12-09 12:08:08.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0026892621598001154 Training loss: 3.437715530395508
2025-12-09 12:08:08.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0026415287796261707 Training loss: 3.5131239891052246
2025-12-09 12:08:08.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.0025940702775459745 Training loss: 3.448634386062622
2025-12-09 12:08:08.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.002546892184813198 Training loss: 3.3307416439056396
2025-12-09 12:08:08.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0025000000000000014 Training loss: 3.368478298187256
2025-12-09 12:08:08.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0024533991883561868 Training loss: 3.439700126647949
2025-12-09 12:08:08.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.002407095181172227 Training loss: 3.478945255279541
2025-12-09 12:08:08.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.0023610933751462555 Training loss: 3.5967588424682617
2025-12-09 12:08:08.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.002315399131755081 Training loss: 3.3542566299438477
2025-12-09 12:08:08.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.0022700177766293095 Training loss: 3.4293503761291504
2025-12-09 12:08:08.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.002224954598932651 Training loss: 3.3736634254455566
2025-12-09 12:08:08.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0021802148507454673 Training loss: 3.5010640621185303
2025-12-09 12:08:08.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.0021358037464526513 Training loss: 3.4960579872131348
2025-12-09 12:08:08.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0020917264621358876 Training loss: 3.3447768688201904
2025-12-09 12:08:08.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.0020479881349703883 Training loss: 3.69101619720459
2025-12-09 12:08:08.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0020045938626261544 Training loss: 3.2765350341796875
2025-12-09 12:08:08.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0019615487026738545 Training loss: 3.3825254440307617
2025-12-09 12:08:08.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.0019188576719953632 Training loss: 3.2843170166015625
2025-12-09 12:08:08.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0018765257461990442 Training loss: 3.1289284229278564
2025-12-09 12:08:08.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0018345578590398509 Training loss: 3.283207416534424
2025-12-09 12:08:08.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.0017929589018443016 Training loss: 3.408074378967285
2025-12-09 12:08:08.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0017517337229403945 Training loss: 3.2520956993103027
2025-12-09 12:08:08.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.001710887127092548 Training loss: 3.3220791816711426
2025-12-09 12:08:08.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0016704238749415956 Training loss: 3.696371078491211
2025-12-09 12:08:08.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0016303486824499457 Training loss: 3.527463436126709
2025-12-09 12:08:08.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.0015906662203519412 Training loss: 3.4340617656707764
2025-12-09 12:08:08.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0015513811136094785 Training loss: 3.2714250087738037
2025-12-09 12:08:08.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.001512497940872986 Training loss: 3.2375686168670654
2025-12-09 12:08:08.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.001474021233947772 Training loss: 3.540729522705078
2025-12-09 12:08:08.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.0014359554772658551 Training loss: 3.202730417251587
2025-12-09 12:08:08.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0013983051073632995 Training loss: 3.254734516143799
2025-12-09 12:08:08.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.0013610745123631535 Training loss: 3.41575026512146
2025-12-09 12:08:08.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.0013242680314639993 Training loss: 3.131587505340576
2025-12-09 12:08:08.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.0012878899544342326 Training loss: 3.4599039554595947
2025-12-09 12:08:08.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.0012519445211120978 Training loss: 3.314317226409912
2025-12-09 12:08:08.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.0012164359209115233 Training loss: 3.2766544818878174
2025-12-09 12:08:08.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.0011813682923338654 Training loss: 3.462484836578369
2025-12-09 12:08:08.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0011467457224855543 Training loss: 3.0834298133850098
2025-12-09 12:08:08.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0011125722466017547 Training loss: 3.1120641231536865
2025-12-09 12:08:08.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.0010788518475760545 Training loss: 3.288184642791748
2025-12-09 12:08:08.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.0010455884554962725 Training loss: 3.4704935550689697
2025-12-09 12:08:08.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.001012785947186397 Training loss: 3.2029101848602295
2025-12-09 12:08:08.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.00098044814575475 Training loss: 3.4544358253479004
2025-12-09 12:08:08.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0009485788201484125 Training loss: 3.4737982749938965
2025-12-09 12:08:08.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.0009171816847139447 Training loss: 3.327972888946533
2025-12-09 12:08:08.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.000886260398764494 Training loss: 3.427408218383789
2025-12-09 12:08:08.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.0008558185661532941 Training loss: 3.339169502258301
2025-12-09 12:08:08.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.000825859734853645 Training loss: 3.190932512283325
2025-12-09 12:08:08.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.0007963873965453961 Training loss: 3.4352970123291016
2025-12-09 12:08:09.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.000767404986207999 Training loss: 3.1937711238861084
2025-12-09 12:08:09.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.0007389158817201541 Training loss: 3.3900628089904785
2025-12-09 12:08:09.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.0007109234034661288 Training loss: 3.3397722244262695
2025-12-09 12:08:09.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.0006834308139487672 Training loss: 3.302309274673462
2025-12-09 12:08:09.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.0006564413174092443 Training loss: 3.26257061958313
2025-12-09 12:08:09.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.0006299580594536214 Training loss: 3.2695116996765137
2025-12-09 12:08:09.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.0006039841266862189 Training loss: 3.3314905166625977
2025-12-09 12:08:09.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.0005785225463498828 Training loss: 3.293365240097046
2025-12-09 12:08:09.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0005535762859731547 Training loss: 3.1905267238616943
2025-12-09 12:08:09.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0005291482530244179 Training loss: 3.165823221206665
2025-12-09 12:08:09.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0005052412945730239 Training loss: 3.2929370403289795
2025-12-09 12:08:09.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.00048185819695747425 Training loss: 3.292713165283203
2025-12-09 12:08:09.113 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.00045900168546067266 Training loss: 3.059622049331665
2025-12-09 12:08:09.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.00043667442399229983 Training loss: 3.363856792449951
2025-12-09 12:08:09.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.0004148790147783288 Training loss: 3.1582274436950684
2025-12-09 12:08:09.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.00039361799805774536 Training loss: 3.4371519088745117
2025-12-09 12:08:09.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0003728938517864794 Training loss: 3.0630486011505127
2025-12-09 12:08:09.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.00035270899134860366 Training loss: 3.291480541229248
2025-12-09 12:08:09.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.00033306576927482126 Training loss: 3.673159599304199
2025-12-09 12:08:09.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.0003139664749682825 Training loss: 3.4410462379455566
2025-12-09 12:08:09.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0002954133344377524 Training loss: 3.2366089820861816
2025-12-09 12:08:09.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.00027740851003817346 Training loss: 3.4090051651000977
2025-12-09 12:08:09.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.00025995410021864785 Training loss: 3.2357420921325684
2025-12-09 12:08:09.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.0002430521392778573 Training loss: 3.4421942234039307
2025-12-09 12:08:09.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.00022670459712697378 Training loss: 3.363827705383301
2025-12-09 12:08:09.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0002109133790600648 Training loss: 3.0903944969177246
2025-12-09 12:08:09.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.00019568032553203218 Training loss: 3.258955240249634
2025-12-09 12:08:09.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.0001810072119441103 Training loss: 3.159600019454956
2025-12-09 12:08:09.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.00016689574843694433 Training loss: 3.1479291915893555
2025-12-09 12:08:09.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.000153347579691272 Training loss: 3.482670545578003
2025-12-09 12:08:09.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.0001403642847362402 Training loss: 3.07517671585083
2025-12-09 12:08:09.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.00012794737676536993 Training loss: 3.3514034748077393
2025-12-09 12:08:09.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.00011609830296019141 Training loss: 3.2653348445892334
2025-12-09 12:08:09.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.0001048184443215816 Training loss: 3.3275539875030518
2025-12-09 12:08:09.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.410911550880474e-05 Training loss: 3.0299437046051025
2025-12-09 12:08:09.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 8.397156468629208e-05 Training loss: 3.389298439025879
2025-12-09 12:08:09.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 7.44069733781677e-05 Training loss: 3.301534414291382
2025-12-09 12:08:09.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 6.54164563305465e-05 Training loss: 3.3059160709381104
2025-12-09 12:08:09.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 5.7001061381606875e-05 Training loss: 3.2984073162078857
2025-12-09 12:08:09.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 4.916176933946692e-05 Training loss: 3.447613477706909
2025-12-09 12:08:09.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 4.1899493867874615e-05 Training loss: 3.113941192626953
2025-12-09 12:08:09.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 3.521508137971807e-05 Training loss: 3.2886950969696045
2025-12-09 12:08:09.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 2.9109310938378874e-05 Training loss: 3.530226230621338
2025-12-09 12:08:09.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 2.358289416693027e-05 Training loss: 3.1239380836486816
2025-12-09 12:08:09.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 1.863647516520017e-05 Training loss: 3.1706597805023193
2025-12-09 12:08:09.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 1.4270630434701781e-05 Training loss: 3.431967258453369
2025-12-09 12:08:09.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 1.0485868811441756e-05 Training loss: 3.190851926803589
2025-12-09 12:08:09.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 7.2826314066154475e-06 Training loss: 3.2001609802246094
2025-12-09 12:08:09.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 4.661291555196345e-06 Training loss: 3.443293809890747
2025-12-09 12:08:09.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 2.6221547724253337e-06 Training loss: 3.0633840560913086
2025-12-09 12:08:09.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 1.1654587182013953e-06 Training loss: 3.0223968029022217
2025-12-09 12:08:09.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 2.9137316938265825e-07 Training loss: 3.330233335494995
2025-12-09 12:08:09.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0 Training loss: 3.3531951904296875
