2025-12-09 05:56:52.515 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.138830184936523
2025-12-09 05:56:52.979 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.131416320800781
2025-12-09 05:56:53.441 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.093184471130371
2025-12-09 05:56:53.905 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 11.959711074829102
2025-12-09 05:56:54.368 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 11.917709350585938
2025-12-09 05:56:54.832 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 11.722247123718262
2025-12-09 05:56:55.295 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 11.457603454589844
2025-12-09 05:56:55.759 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 11.060884475708008
2025-12-09 05:56:56.222 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 10.840106964111328
2025-12-09 05:56:56.685 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 10.696357727050781
2025-12-09 05:56:57.148 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 10.505109786987305
2025-12-09 05:56:57.609 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 10.42165756225586
2025-12-09 05:56:58.074 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 10.380617141723633
2025-12-09 05:56:58.535 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 10.2649507522583
2025-12-09 05:56:58.998 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 10.064146995544434
2025-12-09 05:56:59.460 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 9.963886260986328
2025-12-09 05:56:59.921 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 9.782242774963379
2025-12-09 05:57:00.383 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 9.665675163269043
2025-12-09 05:57:00.845 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 9.518426895141602
2025-12-09 05:57:01.307 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 9.50363540649414
2025-12-09 05:57:01.769 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 9.118291854858398
2025-12-09 05:57:02.232 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 9.05728816986084
2025-12-09 05:57:02.694 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 8.91187572479248
2025-12-09 05:57:03.156 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 8.70649528503418
2025-12-09 05:57:03.618 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 8.597301483154297
2025-12-09 05:57:04.081 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 8.49035358428955
2025-12-09 05:57:04.543 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 8.350979804992676
2025-12-09 05:57:05.005 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 8.192752838134766
2025-12-09 05:57:05.467 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 8.098400115966797
2025-12-09 05:57:05.928 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 8.004668235778809
2025-12-09 05:57:06.391 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 7.954916477203369
2025-12-09 05:57:06.852 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 7.960662841796875
2025-12-09 05:57:07.314 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 7.942877769470215
2025-12-09 05:57:07.777 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 8.124550819396973
2025-12-09 05:57:08.237 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 7.787310600280762
2025-12-09 05:57:08.699 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 7.834356784820557
2025-12-09 05:57:09.160 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 7.901200294494629
2025-12-09 05:57:09.621 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 7.641921520233154
2025-12-09 05:57:10.082 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 7.748408794403076
2025-12-09 05:57:10.544 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 7.678308010101318
2025-12-09 05:57:11.005 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 7.893919467926025
2025-12-09 05:57:11.466 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 7.743935585021973
2025-12-09 05:57:11.928 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 7.944040775299072
2025-12-09 05:57:12.390 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 7.975707054138184
2025-12-09 05:57:12.851 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 7.9713311195373535
2025-12-09 05:57:13.313 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 7.9415812492370605
2025-12-09 05:57:13.775 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 7.79318904876709
2025-12-09 05:57:14.236 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 7.813141822814941
2025-12-09 05:57:14.698 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 7.821073532104492
2025-12-09 05:57:15.159 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 7.784881114959717
2025-12-09 05:57:15.621 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 7.981028079986572
2025-12-09 05:57:16.082 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 7.763937950134277
2025-12-09 05:57:16.545 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 7.77996301651001
2025-12-09 05:57:17.007 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 7.832265377044678
2025-12-09 05:57:17.468 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 7.7733306884765625
2025-12-09 05:57:17.930 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 7.657732009887695
2025-12-09 05:57:18.391 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 7.7975263595581055
2025-12-09 05:57:18.853 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 8.077718734741211
2025-12-09 05:57:19.315 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 7.759905815124512
2025-12-09 05:57:19.776 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 7.7664618492126465
2025-12-09 05:57:20.238 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 7.833444595336914
2025-12-09 05:57:20.700 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 7.883871078491211
2025-12-09 05:57:21.163 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 7.730949878692627
2025-12-09 05:57:21.625 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 7.7676615715026855
2025-12-09 05:57:22.087 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 7.798233985900879
2025-12-09 05:57:22.551 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 7.872000217437744
2025-12-09 05:57:23.014 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 7.834483623504639
2025-12-09 05:57:23.479 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 7.762511253356934
2025-12-09 05:57:23.942 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 7.681267261505127
2025-12-09 05:57:24.408 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 7.797359943389893
2025-12-09 05:57:24.874 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 7.647003650665283
2025-12-09 05:57:25.338 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 7.559525012969971
2025-12-09 05:57:25.803 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 7.738737106323242
2025-12-09 05:57:26.268 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 7.5919318199157715
2025-12-09 05:57:26.734 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 7.480964183807373
2025-12-09 05:57:27.199 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 7.5462422370910645
2025-12-09 05:57:27.665 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 7.37327241897583
2025-12-09 05:57:28.131 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 7.579308032989502
2025-12-09 05:57:28.598 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 7.518777370452881
2025-12-09 05:57:29.064 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 7.7009477615356445
2025-12-09 05:57:29.531 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 7.435162544250488
2025-12-09 05:57:29.999 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 7.9416584968566895
2025-12-09 05:57:30.465 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 7.397346496582031
2025-12-09 05:57:30.931 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 7.550065517425537
2025-12-09 05:57:31.398 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 7.3971734046936035
2025-12-09 05:57:31.863 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 7.419666290283203
2025-12-09 05:57:32.328 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 7.557296276092529
2025-12-09 05:57:32.793 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 7.501204490661621
2025-12-09 05:57:33.259 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 7.217158317565918
2025-12-09 05:57:33.724 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 7.329641819000244
2025-12-09 05:57:34.191 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 7.396427154541016
2025-12-09 05:57:34.655 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 7.461900234222412
2025-12-09 05:57:35.121 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 7.382055759429932
2025-12-09 05:57:35.586 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 7.333996295928955
2025-12-09 05:57:36.051 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 7.291985034942627
2025-12-09 05:57:36.516 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 7.452083110809326
2025-12-09 05:57:36.982 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 7.356354236602783
2025-12-09 05:57:37.447 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 7.273241996765137
2025-12-09 05:57:37.912 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 7.157466888427734
2025-12-09 05:57:38.378 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 7.190920829772949
2025-12-09 05:57:38.842 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 100 LR: 0.0009977359612865424 Training loss: 7.474333763122559
2025-12-09 05:57:39.307 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 101 LR: 0.0009909643486313534 Training loss: 7.424356460571289
2025-12-09 05:57:39.772 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 102 LR: 0.0009797464868072487 Training loss: 6.964235305786133
2025-12-09 05:57:40.237 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 103 LR: 0.0009641839665080363 Training loss: 7.043886184692383
2025-12-09 05:57:40.703 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 104 LR: 0.0009444177243274617 Training loss: 7.243587493896484
2025-12-09 05:57:41.168 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 105 LR: 0.0009206267664155906 Training loss: 7.3771562576293945
2025-12-09 05:57:41.632 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 106 LR: 0.0008930265473713938 Training loss: 7.280465126037598
2025-12-09 05:57:42.100 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 107 LR: 0.000861867019052535 Training loss: 7.316275596618652
2025-12-09 05:57:42.564 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 108 LR: 0.0008274303669726426 Training loss: 7.295342922210693
2025-12-09 05:57:43.029 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 109 LR: 0.0007900284547855992 Training loss: 7.102758884429932
2025-12-09 05:57:43.495 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 110 LR: 0.00075 Training loss: 7.209003448486328
2025-12-09 05:57:43.960 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 111 LR: 0.0007077075065009433 Training loss: 7.016461372375488
2025-12-09 05:57:44.425 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 112 LR: 0.0006635339816587109 Training loss: 7.536776065826416
2025-12-09 05:57:44.892 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 113 LR: 0.0006178794677547138 Training loss: 7.13894510269165
2025-12-09 05:57:45.358 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 114 LR: 0.0005711574191366427 Training loss: 7.135972499847412
2025-12-09 05:57:45.823 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 115 LR: 0.0005237909579118712 Training loss: 7.098046779632568
2025-12-09 05:57:46.291 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 116 LR: 0.0004762090420881289 Training loss: 7.040587425231934
2025-12-09 05:57:46.756 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 117 LR: 0.0004288425808633575 Training loss: 6.946961879730225
2025-12-09 05:57:47.222 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 118 LR: 0.0003821205322452863 Training loss: 7.031798839569092
2025-12-09 05:57:47.688 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 119 LR: 0.0003364660183412892 Training loss: 7.040205955505371
2025-12-09 05:57:48.154 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 120 LR: 0.0002922924934990568 Training loss: 7.061891555786133
2025-12-09 05:57:48.619 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 121 LR: 0.0002500000000000001 Training loss: 6.91802453994751
2025-12-09 05:57:49.085 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 122 LR: 0.00020997154521440098 Training loss: 7.089978218078613
2025-12-09 05:57:49.551 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 123 LR: 0.0001725696330273575 Training loss: 7.178049087524414
2025-12-09 05:57:50.017 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 124 LR: 0.0001381329809474649 Training loss: 6.952697277069092
2025-12-09 05:57:50.482 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 125 LR: 0.00010697345262860636 Training loss: 6.805054187774658
2025-12-09 05:57:50.948 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 126 LR: 7.937323358440934e-05 Training loss: 7.1251301765441895
2025-12-09 05:57:51.413 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 127 LR: 5.5582275672538315e-05 Training loss: 6.9265570640563965
2025-12-09 05:57:51.879 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 128 LR: 3.5816033491963716e-05 Training loss: 6.9845452308654785
2025-12-09 05:57:52.344 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 129 LR: 2.025351319275137e-05 Training loss: 6.710256099700928
2025-12-09 05:57:52.811 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 130 LR: 9.035651368646646e-06 Training loss: 7.118675231933594
2025-12-09 05:57:53.277 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 131 LR: 2.2640387134577057e-06 Training loss: 7.11130952835083
2025-12-09 05:57:53.564 | INFO     | __main__:<module>:358 - Epoch: 0 Step: 132 LR: 0.0 Training loss: 7.3006510734558105
