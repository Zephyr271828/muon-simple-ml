2025-12-09 09:43:54.341 | INFO     | __main__:train:20 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.031149864196777
2025-12-09 09:43:54.651 | INFO     | __main__:train:20 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.043649673461914
2025-12-09 09:43:54.951 | INFO     | __main__:train:20 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.03417682647705
2025-12-09 09:43:55.252 | INFO     | __main__:train:20 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 12.021768569946289
2025-12-09 09:43:55.551 | INFO     | __main__:train:20 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 12.006113052368164
2025-12-09 09:43:55.852 | INFO     | __main__:train:20 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 12.021726608276367
2025-12-09 09:43:56.152 | INFO     | __main__:train:20 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 11.988579750061035
2025-12-09 09:43:56.453 | INFO     | __main__:train:20 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 11.979491233825684
2025-12-09 09:43:56.753 | INFO     | __main__:train:20 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 11.947403907775879
2025-12-09 09:43:57.054 | INFO     | __main__:train:20 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 11.928671836853027
2025-12-09 09:43:57.356 | INFO     | __main__:train:20 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 11.906457901000977
2025-12-09 09:43:57.658 | INFO     | __main__:train:20 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 11.86854076385498
2025-12-09 09:43:57.956 | INFO     | __main__:train:20 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 11.817358016967773
2025-12-09 09:43:58.258 | INFO     | __main__:train:20 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 11.791651725769043
2025-12-09 09:43:58.558 | INFO     | __main__:train:20 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 11.742637634277344
2025-12-09 09:43:58.859 | INFO     | __main__:train:20 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 11.642239570617676
2025-12-09 09:43:59.159 | INFO     | __main__:train:20 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 11.638704299926758
2025-12-09 09:43:59.460 | INFO     | __main__:train:20 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 11.524093627929688
2025-12-09 09:43:59.761 | INFO     | __main__:train:20 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 11.429754257202148
2025-12-09 09:44:00.060 | INFO     | __main__:train:20 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 11.359803199768066
2025-12-09 09:44:00.362 | INFO     | __main__:train:20 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 11.263158798217773
2025-12-09 09:44:00.665 | INFO     | __main__:train:20 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 11.107612609863281
2025-12-09 09:44:00.964 | INFO     | __main__:train:20 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 11.019728660583496
2025-12-09 09:44:01.266 | INFO     | __main__:train:20 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 10.867624282836914
2025-12-09 09:44:01.565 | INFO     | __main__:train:20 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 10.757023811340332
2025-12-09 09:44:01.867 | INFO     | __main__:train:20 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 10.573115348815918
2025-12-09 09:44:02.167 | INFO     | __main__:train:20 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 10.43379020690918
2025-12-09 09:44:02.468 | INFO     | __main__:train:20 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 10.250927925109863
2025-12-09 09:44:02.767 | INFO     | __main__:train:20 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 10.158700942993164
2025-12-09 09:44:03.066 | INFO     | __main__:train:20 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 10.11605453491211
2025-12-09 09:44:03.364 | INFO     | __main__:train:20 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 9.768335342407227
2025-12-09 09:44:03.663 | INFO     | __main__:train:20 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 9.723798751831055
2025-12-09 09:44:03.963 | INFO     | __main__:train:20 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 9.490263938903809
2025-12-09 09:44:04.263 | INFO     | __main__:train:20 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 9.3432035446167
2025-12-09 09:44:04.563 | INFO     | __main__:train:20 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 9.157979011535645
2025-12-09 09:44:04.864 | INFO     | __main__:train:20 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 9.008380889892578
2025-12-09 09:44:05.163 | INFO     | __main__:train:20 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 8.864178657531738
2025-12-09 09:44:05.463 | INFO     | __main__:train:20 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 8.795960426330566
2025-12-09 09:44:05.763 | INFO     | __main__:train:20 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 8.61191177368164
2025-12-09 09:44:06.063 | INFO     | __main__:train:20 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 8.527717590332031
2025-12-09 09:44:06.364 | INFO     | __main__:train:20 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 8.324392318725586
2025-12-09 09:44:06.663 | INFO     | __main__:train:20 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 8.342537879943848
2025-12-09 09:44:06.962 | INFO     | __main__:train:20 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 8.163269996643066
2025-12-09 09:44:07.262 | INFO     | __main__:train:20 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 8.096793174743652
2025-12-09 09:44:07.560 | INFO     | __main__:train:20 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 7.936666011810303
2025-12-09 09:44:07.860 | INFO     | __main__:train:20 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 7.93773889541626
2025-12-09 09:44:08.160 | INFO     | __main__:train:20 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 7.887250900268555
2025-12-09 09:44:08.461 | INFO     | __main__:train:20 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 7.987195014953613
2025-12-09 09:44:08.762 | INFO     | __main__:train:20 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 7.756390571594238
2025-12-09 09:44:09.062 | INFO     | __main__:train:20 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 7.746644496917725
2025-12-09 09:44:09.363 | INFO     | __main__:train:20 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 7.587798118591309
2025-12-09 09:44:09.662 | INFO     | __main__:train:20 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 7.755577564239502
2025-12-09 09:44:09.963 | INFO     | __main__:train:20 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 7.718163013458252
2025-12-09 09:44:10.263 | INFO     | __main__:train:20 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 7.524160861968994
2025-12-09 09:44:10.564 | INFO     | __main__:train:20 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 7.7024359703063965
2025-12-09 09:44:10.864 | INFO     | __main__:train:20 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 7.809640407562256
2025-12-09 09:44:11.165 | INFO     | __main__:train:20 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 7.668298244476318
2025-12-09 09:44:11.464 | INFO     | __main__:train:20 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 7.664586067199707
2025-12-09 09:44:11.765 | INFO     | __main__:train:20 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 7.678311347961426
2025-12-09 09:44:12.066 | INFO     | __main__:train:20 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 7.662423610687256
2025-12-09 09:44:12.365 | INFO     | __main__:train:20 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 7.602526664733887
2025-12-09 09:44:12.667 | INFO     | __main__:train:20 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 7.523068904876709
2025-12-09 09:44:12.968 | INFO     | __main__:train:20 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 7.429410934448242
2025-12-09 09:44:13.268 | INFO     | __main__:train:20 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 7.454160690307617
2025-12-09 09:44:13.568 | INFO     | __main__:train:20 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 7.558780193328857
2025-12-09 09:44:13.868 | INFO     | __main__:train:20 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 7.566534996032715
2025-12-09 09:44:14.168 | INFO     | __main__:train:20 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 7.19977331161499
2025-12-09 09:44:14.468 | INFO     | __main__:train:20 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 7.418868064880371
2025-12-09 09:44:14.769 | INFO     | __main__:train:20 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 7.275230407714844
2025-12-09 09:44:15.071 | INFO     | __main__:train:20 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 7.4354329109191895
2025-12-09 09:44:15.371 | INFO     | __main__:train:20 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 7.365881443023682
2025-12-09 09:44:15.670 | INFO     | __main__:train:20 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 7.254827976226807
2025-12-09 09:44:15.971 | INFO     | __main__:train:20 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 7.300846576690674
2025-12-09 09:44:16.273 | INFO     | __main__:train:20 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 7.209657669067383
2025-12-09 09:44:16.575 | INFO     | __main__:train:20 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 7.155815601348877
2025-12-09 09:44:16.877 | INFO     | __main__:train:20 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 7.2556281089782715
2025-12-09 09:44:17.178 | INFO     | __main__:train:20 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 7.186323642730713
2025-12-09 09:44:17.480 | INFO     | __main__:train:20 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 7.188762187957764
2025-12-09 09:44:17.782 | INFO     | __main__:train:20 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 7.516094207763672
2025-12-09 09:44:18.082 | INFO     | __main__:train:20 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 7.034078598022461
2025-12-09 09:44:18.384 | INFO     | __main__:train:20 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 7.4586029052734375
2025-12-09 09:44:18.685 | INFO     | __main__:train:20 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 7.185951232910156
2025-12-09 09:44:18.986 | INFO     | __main__:train:20 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 7.193045616149902
2025-12-09 09:44:19.287 | INFO     | __main__:train:20 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 7.1000447273254395
2025-12-09 09:44:19.587 | INFO     | __main__:train:20 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 7.155610084533691
2025-12-09 09:44:19.888 | INFO     | __main__:train:20 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 7.0614166259765625
2025-12-09 09:44:20.189 | INFO     | __main__:train:20 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 7.13726806640625
2025-12-09 09:44:20.491 | INFO     | __main__:train:20 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 7.039006233215332
2025-12-09 09:44:20.790 | INFO     | __main__:train:20 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 6.904111385345459
2025-12-09 09:44:21.091 | INFO     | __main__:train:20 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 7.174794673919678
2025-12-09 09:44:21.393 | INFO     | __main__:train:20 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 7.042640686035156
2025-12-09 09:44:21.695 | INFO     | __main__:train:20 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 7.08282470703125
2025-12-09 09:44:21.996 | INFO     | __main__:train:20 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 6.8557000160217285
2025-12-09 09:44:22.297 | INFO     | __main__:train:20 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 7.157932281494141
2025-12-09 09:44:22.598 | INFO     | __main__:train:20 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 7.0382513999938965
2025-12-09 09:44:22.900 | INFO     | __main__:train:20 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 6.9155731201171875
2025-12-09 09:44:23.202 | INFO     | __main__:train:20 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 6.714320659637451
2025-12-09 09:44:23.503 | INFO     | __main__:train:20 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 6.868265628814697
2025-12-09 09:44:23.804 | INFO     | __main__:train:20 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 6.963508129119873
2025-12-09 09:44:24.105 | INFO     | __main__:train:20 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 6.864006519317627
2025-12-09 09:44:24.405 | INFO     | __main__:train:20 - Epoch: 0 Step: 100 LR: 0.0009977359612865424 Training loss: 6.722002983093262
2025-12-09 09:44:24.706 | INFO     | __main__:train:20 - Epoch: 0 Step: 101 LR: 0.0009909643486313534 Training loss: 6.725827693939209
2025-12-09 09:44:25.008 | INFO     | __main__:train:20 - Epoch: 0 Step: 102 LR: 0.0009797464868072487 Training loss: 6.920344352722168
2025-12-09 09:44:25.309 | INFO     | __main__:train:20 - Epoch: 0 Step: 103 LR: 0.0009641839665080363 Training loss: 6.559845924377441
2025-12-09 09:44:25.609 | INFO     | __main__:train:20 - Epoch: 0 Step: 104 LR: 0.0009444177243274617 Training loss: 6.668750762939453
2025-12-09 09:44:25.911 | INFO     | __main__:train:20 - Epoch: 0 Step: 105 LR: 0.0009206267664155906 Training loss: 6.5192670822143555
2025-12-09 09:44:26.211 | INFO     | __main__:train:20 - Epoch: 0 Step: 106 LR: 0.0008930265473713938 Training loss: 6.621874809265137
2025-12-09 09:44:26.512 | INFO     | __main__:train:20 - Epoch: 0 Step: 107 LR: 0.000861867019052535 Training loss: 6.942894458770752
2025-12-09 09:44:26.814 | INFO     | __main__:train:20 - Epoch: 0 Step: 108 LR: 0.0008274303669726426 Training loss: 6.915970802307129
2025-12-09 09:44:27.116 | INFO     | __main__:train:20 - Epoch: 0 Step: 109 LR: 0.0007900284547855992 Training loss: 6.650951385498047
2025-12-09 09:44:27.416 | INFO     | __main__:train:20 - Epoch: 0 Step: 110 LR: 0.00075 Training loss: 6.853719234466553
2025-12-09 09:44:27.717 | INFO     | __main__:train:20 - Epoch: 0 Step: 111 LR: 0.0007077075065009433 Training loss: 6.853113651275635
2025-12-09 09:44:28.019 | INFO     | __main__:train:20 - Epoch: 0 Step: 112 LR: 0.0006635339816587109 Training loss: 6.638988971710205
2025-12-09 09:44:28.319 | INFO     | __main__:train:20 - Epoch: 0 Step: 113 LR: 0.0006178794677547138 Training loss: 6.5518670082092285
2025-12-09 09:44:28.621 | INFO     | __main__:train:20 - Epoch: 0 Step: 114 LR: 0.0005711574191366427 Training loss: 6.580446720123291
2025-12-09 09:44:28.922 | INFO     | __main__:train:20 - Epoch: 0 Step: 115 LR: 0.0005237909579118712 Training loss: 6.7736124992370605
2025-12-09 09:44:29.223 | INFO     | __main__:train:20 - Epoch: 0 Step: 116 LR: 0.0004762090420881289 Training loss: 6.793610572814941
2025-12-09 09:44:29.521 | INFO     | __main__:train:20 - Epoch: 0 Step: 117 LR: 0.0004288425808633575 Training loss: 6.195863723754883
2025-12-09 09:44:29.822 | INFO     | __main__:train:20 - Epoch: 0 Step: 118 LR: 0.0003821205322452863 Training loss: 6.673046112060547
2025-12-09 09:44:30.123 | INFO     | __main__:train:20 - Epoch: 0 Step: 119 LR: 0.0003364660183412892 Training loss: 6.971700668334961
2025-12-09 09:44:30.422 | INFO     | __main__:train:20 - Epoch: 0 Step: 120 LR: 0.0002922924934990568 Training loss: 6.421215534210205
2025-12-09 09:44:30.723 | INFO     | __main__:train:20 - Epoch: 0 Step: 121 LR: 0.0002500000000000001 Training loss: 6.417243003845215
2025-12-09 09:44:31.023 | INFO     | __main__:train:20 - Epoch: 0 Step: 122 LR: 0.00020997154521440098 Training loss: 6.51731538772583
2025-12-09 09:44:31.323 | INFO     | __main__:train:20 - Epoch: 0 Step: 123 LR: 0.0001725696330273575 Training loss: 6.580524444580078
2025-12-09 09:44:31.623 | INFO     | __main__:train:20 - Epoch: 0 Step: 124 LR: 0.0001381329809474649 Training loss: 6.763363361358643
2025-12-09 09:44:31.923 | INFO     | __main__:train:20 - Epoch: 0 Step: 125 LR: 0.00010697345262860636 Training loss: 6.640010833740234
2025-12-09 09:44:32.223 | INFO     | __main__:train:20 - Epoch: 0 Step: 126 LR: 7.937323358440934e-05 Training loss: 6.693624496459961
2025-12-09 09:44:32.524 | INFO     | __main__:train:20 - Epoch: 0 Step: 127 LR: 5.5582275672538315e-05 Training loss: 6.540246963500977
2025-12-09 09:44:32.824 | INFO     | __main__:train:20 - Epoch: 0 Step: 128 LR: 3.5816033491963716e-05 Training loss: 6.68919563293457
2025-12-09 09:44:33.125 | INFO     | __main__:train:20 - Epoch: 0 Step: 129 LR: 2.025351319275137e-05 Training loss: 6.608168601989746
2025-12-09 09:44:33.425 | INFO     | __main__:train:20 - Epoch: 0 Step: 130 LR: 9.035651368646646e-06 Training loss: 6.377466678619385
2025-12-09 09:44:33.727 | INFO     | __main__:train:20 - Epoch: 0 Step: 131 LR: 2.2640387134577057e-06 Training loss: 6.605996608734131
2025-12-09 09:44:33.937 | INFO     | __main__:train:20 - Epoch: 0 Step: 132 LR: 0.0 Training loss: 6.665361404418945
