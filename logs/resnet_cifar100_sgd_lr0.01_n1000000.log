2025-12-09 12:11:31.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 0.0001 Training loss: 4.862654209136963
2025-12-09 12:11:31.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 0.0002 Training loss: 4.721698760986328
2025-12-09 12:11:31.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 0.0003 Training loss: 4.969914436340332
2025-12-09 12:11:31.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.0004 Training loss: 4.924443244934082
2025-12-09 12:11:31.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.0005 Training loss: 4.905307292938232
2025-12-09 12:11:31.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.0006 Training loss: 4.857205390930176
2025-12-09 12:11:31.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.0007000000000000001 Training loss: 4.911686897277832
2025-12-09 12:11:31.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.0008 Training loss: 4.9668049812316895
2025-12-09 12:11:31.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.0009 Training loss: 4.875638484954834
2025-12-09 12:11:31.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.001 Training loss: 4.87880802154541
2025-12-09 12:11:31.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.0011 Training loss: 4.728329658508301
2025-12-09 12:11:31.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.0012 Training loss: 4.811370372772217
2025-12-09 12:11:31.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.0013000000000000002 Training loss: 4.927544593811035
2025-12-09 12:11:31.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.0014000000000000002 Training loss: 4.795581340789795
2025-12-09 12:11:31.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.0015 Training loss: 4.891586780548096
2025-12-09 12:11:31.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.0016 Training loss: 4.785671234130859
2025-12-09 12:11:31.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.0017000000000000001 Training loss: 4.739665985107422
2025-12-09 12:11:31.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.0018 Training loss: 4.747305870056152
2025-12-09 12:11:31.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.0019 Training loss: 4.695624828338623
2025-12-09 12:11:31.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.002 Training loss: 4.755557060241699
2025-12-09 12:11:31.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.0021 Training loss: 4.767401218414307
2025-12-09 12:11:31.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.0022 Training loss: 4.668264865875244
2025-12-09 12:11:31.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0023 Training loss: 4.6385416984558105
2025-12-09 12:11:31.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0024 Training loss: 4.745790004730225
2025-12-09 12:11:31.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.0025 Training loss: 4.727835178375244
2025-12-09 12:11:31.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0026000000000000003 Training loss: 4.595595359802246
2025-12-09 12:11:31.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0027 Training loss: 4.644693374633789
2025-12-09 12:11:31.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0028000000000000004 Training loss: 4.682067394256592
2025-12-09 12:11:31.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.0029 Training loss: 4.639716625213623
2025-12-09 12:11:31.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.003 Training loss: 4.526797294616699
2025-12-09 12:11:31.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.0031 Training loss: 4.484350204467773
2025-12-09 12:11:31.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.0032 Training loss: 4.586214542388916
2025-12-09 12:11:31.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.0033000000000000004 Training loss: 4.644262313842773
2025-12-09 12:11:31.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.0034000000000000002 Training loss: 4.515822410583496
2025-12-09 12:11:31.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.0034999999999999996 Training loss: 4.501793384552002
2025-12-09 12:11:31.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.0036 Training loss: 4.590963840484619
2025-12-09 12:11:31.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.0037 Training loss: 4.5852580070495605
2025-12-09 12:11:31.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.0038 Training loss: 4.629395008087158
2025-12-09 12:11:31.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.0039000000000000003 Training loss: 4.412075042724609
2025-12-09 12:11:31.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.004 Training loss: 4.4919538497924805
2025-12-09 12:11:31.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.0040999999999999995 Training loss: 4.5680131912231445
2025-12-09 12:11:31.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.0042 Training loss: 4.437747478485107
2025-12-09 12:11:31.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.0043 Training loss: 4.5107316970825195
2025-12-09 12:11:31.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.0044 Training loss: 4.375293731689453
2025-12-09 12:11:31.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.0045000000000000005 Training loss: 4.487929821014404
2025-12-09 12:11:31.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0046 Training loss: 4.5067620277404785
2025-12-09 12:11:31.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.0047 Training loss: 4.519905090332031
2025-12-09 12:11:31.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0048 Training loss: 4.478378772735596
2025-12-09 12:11:31.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.0049 Training loss: 4.287261486053467
2025-12-09 12:11:31.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.005 Training loss: 4.419903755187988
2025-12-09 12:11:31.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0051 Training loss: 4.412005424499512
2025-12-09 12:11:31.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.005200000000000001 Training loss: 4.422255992889404
2025-12-09 12:11:31.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0053 Training loss: 4.322958469390869
2025-12-09 12:11:31.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0054 Training loss: 4.327676773071289
2025-12-09 12:11:31.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0055000000000000005 Training loss: 4.196472644805908
2025-12-09 12:11:31.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.005600000000000001 Training loss: 4.43166971206665
2025-12-09 12:11:31.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.005699999999999999 Training loss: 4.2722272872924805
2025-12-09 12:11:31.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.0058 Training loss: 4.35259485244751
2025-12-09 12:11:31.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0059 Training loss: 4.324082374572754
2025-12-09 12:11:31.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.006 Training loss: 4.236082553863525
2025-12-09 12:11:31.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.0061 Training loss: 4.299930572509766
2025-12-09 12:11:31.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.0062 Training loss: 4.306300640106201
2025-12-09 12:11:31.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.0063 Training loss: 4.182985305786133
2025-12-09 12:11:31.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.0064 Training loss: 4.296854019165039
2025-12-09 12:11:31.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.006500000000000001 Training loss: 4.183943271636963
2025-12-09 12:11:31.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.006600000000000001 Training loss: 4.17283296585083
2025-12-09 12:11:31.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.0067 Training loss: 4.201562881469727
2025-12-09 12:11:31.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.0068000000000000005 Training loss: 4.273834228515625
2025-12-09 12:11:31.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.0069 Training loss: 4.310874938964844
2025-12-09 12:11:31.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.006999999999999999 Training loss: 4.190938949584961
2025-12-09 12:11:31.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.0070999999999999995 Training loss: 4.231650352478027
2025-12-09 12:11:31.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0072 Training loss: 4.04066276550293
2025-12-09 12:11:31.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.0073 Training loss: 4.151917457580566
2025-12-09 12:11:31.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.0074 Training loss: 4.239709377288818
2025-12-09 12:11:31.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0075 Training loss: 4.177313804626465
2025-12-09 12:11:32.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.0076 Training loss: 4.175087928771973
2025-12-09 12:11:32.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0077 Training loss: 4.090084552764893
2025-12-09 12:11:32.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0078000000000000005 Training loss: 4.188939094543457
2025-12-09 12:11:32.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.0079 Training loss: 4.159921169281006
2025-12-09 12:11:32.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.008 Training loss: 4.05527400970459
2025-12-09 12:11:32.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.008100000000000001 Training loss: 4.191657543182373
2025-12-09 12:11:32.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.008199999999999999 Training loss: 4.026464939117432
2025-12-09 12:11:32.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.0083 Training loss: 4.099954128265381
2025-12-09 12:11:32.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.0084 Training loss: 4.021544456481934
2025-12-09 12:11:32.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.0085 Training loss: 4.079756736755371
2025-12-09 12:11:32.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.0086 Training loss: 3.988640785217285
2025-12-09 12:11:32.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.0087 Training loss: 4.019314289093018
2025-12-09 12:11:32.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.0088 Training loss: 3.9952590465545654
2025-12-09 12:11:32.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0089 Training loss: 4.053541660308838
2025-12-09 12:11:32.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.009000000000000001 Training loss: 4.08223295211792
2025-12-09 12:11:32.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0091 Training loss: 4.098720550537109
2025-12-09 12:11:32.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0092 Training loss: 4.05739688873291
2025-12-09 12:11:32.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.009300000000000001 Training loss: 4.086058616638184
2025-12-09 12:11:32.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.0094 Training loss: 3.9477956295013428
2025-12-09 12:11:32.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.0095 Training loss: 4.193170070648193
2025-12-09 12:11:32.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0096 Training loss: 4.015628814697266
2025-12-09 12:11:32.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0097 Training loss: 3.8913424015045166
2025-12-09 12:11:32.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.0098 Training loss: 4.031365871429443
2025-12-09 12:11:32.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.0099 Training loss: 3.8871357440948486
2025-12-09 12:11:32.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.01 Training loss: 4.076841831207275
2025-12-09 12:11:32.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.009999708626830616 Training loss: 4.098217487335205
2025-12-09 12:11:32.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.009998834541281799 Training loss: 4.044252872467041
2025-12-09 12:11:32.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.009997377845227575 Training loss: 4.103930950164795
2025-12-09 12:11:32.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.009995338708444804 Training loss: 4.0360283851623535
2025-12-09 12:11:32.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.009992717368593385 Training loss: 3.9324235916137695
2025-12-09 12:11:32.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.009989514131188558 Training loss: 3.8838694095611572
2025-12-09 12:11:32.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.009985729369565299 Training loss: 3.9518728256225586
2025-12-09 12:11:32.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0099813635248348 Training loss: 4.035652160644531
2025-12-09 12:11:32.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.00997641710583307 Training loss: 3.983050584793091
2025-12-09 12:11:32.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.009970890689061622 Training loss: 3.9074456691741943
2025-12-09 12:11:32.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.009964784918620281 Training loss: 3.833235740661621
2025-12-09 12:11:32.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.009958100506132127 Training loss: 3.9820804595947266
2025-12-09 12:11:32.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.009950838230660534 Training loss: 3.9679923057556152
2025-12-09 12:11:32.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.009942998938618395 Training loss: 3.8568732738494873
2025-12-09 12:11:32.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.009934583543669454 Training loss: 3.898693084716797
2025-12-09 12:11:32.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.009925593026621833 Training loss: 3.773484468460083
2025-12-09 12:11:32.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.009916028435313709 Training loss: 3.80088210105896
2025-12-09 12:11:32.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.009905890884491196 Training loss: 3.8615643978118896
2025-12-09 12:11:32.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.00989518155567842 Training loss: 3.8784496784210205
2025-12-09 12:11:32.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.009883901697039808 Training loss: 3.7996814250946045
2025-12-09 12:11:32.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.009872052623234632 Training loss: 3.9008889198303223
2025-12-09 12:11:32.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.00985963571526376 Training loss: 3.992875576019287
2025-12-09 12:11:32.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.009846652420308728 Training loss: 3.972672939300537
2025-12-09 12:11:32.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.009833104251563056 Training loss: 4.089195251464844
2025-12-09 12:11:32.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.00981899278805589 Training loss: 3.973763942718506
2025-12-09 12:11:32.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.009804319674467968 Training loss: 3.9818267822265625
2025-12-09 12:11:32.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.009789086620939936 Training loss: 3.9627599716186523
2025-12-09 12:11:32.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.009773295402873026 Training loss: 3.9199695587158203
2025-12-09 12:11:32.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.009756947860722143 Training loss: 3.7752280235290527
2025-12-09 12:11:32.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.009740045899781353 Training loss: 3.8157455921173096
2025-12-09 12:11:32.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.009722591489961827 Training loss: 3.9317028522491455
2025-12-09 12:11:32.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.009704586665562249 Training loss: 3.832310914993286
2025-12-09 12:11:32.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.00968603352503172 Training loss: 3.838536500930786
2025-12-09 12:11:32.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.009666934230725179 Training loss: 3.8432419300079346
2025-12-09 12:11:32.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.009647291008651398 Training loss: 3.946479558944702
2025-12-09 12:11:32.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.009627106148213521 Training loss: 3.8278565406799316
2025-12-09 12:11:32.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.009606382001942255 Training loss: 3.837176561355591
2025-12-09 12:11:32.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.00958512098522167 Training loss: 3.7752645015716553
2025-12-09 12:11:32.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.0095633255760077 Training loss: 3.876997232437134
2025-12-09 12:11:32.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.009540998314539327 Training loss: 3.799747943878174
2025-12-09 12:11:32.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.009518141803042527 Training loss: 3.902280569076538
2025-12-09 12:11:32.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.009494758705426976 Training loss: 3.7510015964508057
2025-12-09 12:11:32.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.009470851746975581 Training loss: 3.851285457611084
2025-12-09 12:11:32.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.009446423714026845 Training loss: 3.93859601020813
2025-12-09 12:11:32.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.009421477453650118 Training loss: 3.791714906692505
2025-12-09 12:11:32.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.009396015873313781 Training loss: 3.931658983230591
2025-12-09 12:11:32.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.00937004194054638 Training loss: 3.971956968307495
2025-12-09 12:11:32.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.009343558682590757 Training loss: 3.920332193374634
2025-12-09 12:11:32.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.009316569186051234 Training loss: 4.01720666885376
2025-12-09 12:11:32.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.009289076596533871 Training loss: 3.8473055362701416
2025-12-09 12:11:32.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.009261084118279847 Training loss: 3.701213836669922
2025-12-09 12:11:32.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.009232595013792002 Training loss: 3.8348889350891113
2025-12-09 12:11:32.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.009203612603454604 Training loss: 3.7391135692596436
2025-12-09 12:11:32.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.009174140265146355 Training loss: 3.8918018341064453
2025-12-09 12:11:32.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.009144181433846706 Training loss: 3.833735942840576
2025-12-09 12:11:32.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.009113739601235507 Training loss: 3.9575021266937256
2025-12-09 12:11:32.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.009082818315286054 Training loss: 3.9917266368865967
2025-12-09 12:11:32.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.009051421179851587 Training loss: 3.9493062496185303
2025-12-09 12:11:32.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.00901955185424525 Training loss: 3.891906499862671
2025-12-09 12:11:32.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.008987214052813604 Training loss: 3.801133155822754
2025-12-09 12:11:32.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.00895441154450373 Training loss: 3.788966417312622
2025-12-09 12:11:32.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.008921148152423945 Training loss: 3.9665262699127197
2025-12-09 12:11:32.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.008887427753398248 Training loss: 3.7710320949554443
2025-12-09 12:11:32.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.008853254277514447 Training loss: 3.7717249393463135
2025-12-09 12:11:32.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.008818631707666134 Training loss: 3.8564321994781494
2025-12-09 12:11:32.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.008783564079088476 Training loss: 3.8475704193115234
2025-12-09 12:11:32.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.008748055478887904 Training loss: 3.802943229675293
2025-12-09 12:11:32.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.008712110045565767 Training loss: 3.893688917160034
2025-12-09 12:11:32.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.008675731968536002 Training loss: 4.012231349945068
2025-12-09 12:11:32.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.008638925487636848 Training loss: 3.7744903564453125
2025-12-09 12:11:32.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0086016948926367 Training loss: 3.740689754486084
2025-12-09 12:11:32.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.008564044522734147 Training loss: 3.7097160816192627
2025-12-09 12:11:32.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.008525978766052229 Training loss: 3.7699060440063477
2025-12-09 12:11:32.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.008487502059127015 Training loss: 3.8364624977111816
2025-12-09 12:11:32.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.008448618886390521 Training loss: 3.77376651763916
2025-12-09 12:11:32.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.00840933377964806 Training loss: 3.9062561988830566
2025-12-09 12:11:32.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.008369651317550054 Training loss: 3.8237380981445312
2025-12-09 12:11:32.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.008329576125058406 Training loss: 3.937168598175049
2025-12-09 12:11:32.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.008289112872907454 Training loss: 3.7132492065429688
2025-12-09 12:11:32.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.008248266277059607 Training loss: 3.85089373588562
2025-12-09 12:11:32.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0082070410981557 Training loss: 3.9408817291259766
2025-12-09 12:11:32.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.00816544214096015 Training loss: 3.9082353115081787
2025-12-09 12:11:32.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.008123474253800956 Training loss: 3.9722323417663574
2025-12-09 12:11:32.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.008081142328004637 Training loss: 3.9065396785736084
2025-12-09 12:11:32.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.008038451297326145 Training loss: 3.952177047729492
2025-12-09 12:11:32.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.007995406137373847 Training loss: 3.7601816654205322
2025-12-09 12:11:32.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.007952011865029614 Training loss: 3.7707784175872803
2025-12-09 12:11:32.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.007908273537864113 Training loss: 3.8210134506225586
2025-12-09 12:11:33.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.007864196253547348 Training loss: 3.9829063415527344
2025-12-09 12:11:33.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.007819785149254532 Training loss: 3.908796787261963
2025-12-09 12:11:33.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.00777504540106735 Training loss: 3.9035048484802246
2025-12-09 12:11:33.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.007729982223370691 Training loss: 3.909440755844116
2025-12-09 12:11:33.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.00768460086824492 Training loss: 3.7268006801605225
2025-12-09 12:11:33.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.007638906624853743 Training loss: 3.982117176055908
2025-12-09 12:11:33.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.007592904818827774 Training loss: 3.8920631408691406
2025-12-09 12:11:33.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.007546600811643816 Training loss: 3.99932861328125
2025-12-09 12:11:33.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0075 Training loss: 3.8728384971618652
2025-12-09 12:11:33.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.007453107815186802 Training loss: 3.882960557937622
2025-12-09 12:11:33.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.007405929722454026 Training loss: 3.858671188354492
2025-12-09 12:11:33.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.007358471220373831 Training loss: 3.8291189670562744
2025-12-09 12:11:33.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.007310737840199885 Training loss: 3.8449020385742188
2025-12-09 12:11:33.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.007262735145222695 Training loss: 3.9609317779541016
2025-12-09 12:11:33.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.007214468730121208 Training loss: 3.9249985218048096
2025-12-09 12:11:33.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.007165944220310766 Training loss: 3.8906047344207764
2025-12-09 12:11:33.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.007117167271287452 Training loss: 3.9052555561065674
2025-12-09 12:11:33.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.007068143567968957 Training loss: 3.8469834327697754
2025-12-09 12:11:33.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.0070188788240320085 Training loss: 3.8811252117156982
2025-12-09 12:11:33.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.006969378781246436 Training loss: 3.8949191570281982
2025-12-09 12:11:33.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.006919649208805981 Training loss: 3.917062759399414
2025-12-09 12:11:33.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0068696959026558965 Training loss: 3.9057724475860596
2025-12-09 12:11:33.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.006819524684817438 Training loss: 3.928098440170288
2025-12-09 12:11:33.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.0067691414027093045 Training loss: 3.9533424377441406
2025-12-09 12:11:33.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.006718551928466133 Training loss: 3.960625171661377
2025-12-09 12:11:33.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.006667762158254104 Training loss: 3.9195752143859863
2025-12-09 12:11:33.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.006616778011583743 Training loss: 3.945659637451172
2025-12-09 12:11:33.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.006565605430620013 Training loss: 3.888101100921631
2025-12-09 12:11:33.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.006514250379489753 Training loss: 3.8216516971588135
2025-12-09 12:11:33.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.006462718843586571 Training loss: 3.922191619873047
2025-12-09 12:11:33.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.0064110168288732386 Training loss: 3.828227996826172
2025-12-09 12:11:33.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.006359150361181715 Training loss: 3.7989819049835205
2025-12-09 12:11:33.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.006307125485510829 Training loss: 3.8461391925811768
2025-12-09 12:11:33.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0062549482653217435 Training loss: 3.9375855922698975
2025-12-09 12:11:33.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0062026247818312685 Training loss: 3.9012951850891113
2025-12-09 12:11:33.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0061501611333030885 Training loss: 3.7938294410705566
2025-12-09 12:11:33.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.006097563434337026 Training loss: 3.860767364501953
2025-12-09 12:11:33.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.006044837815156376 Training loss: 3.8050098419189453
2025-12-09 12:11:33.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.005991990420893449 Training loss: 3.9085919857025146
2025-12-09 12:11:33.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.005939027410873351 Training loss: 3.9429352283477783
2025-12-09 12:11:33.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0058859549578961145 Training loss: 3.878110885620117
2025-12-09 12:11:33.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.005832779247517273 Training loss: 3.7897520065307617
2025-12-09 12:11:33.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0057795064773269325 Training loss: 3.9077813625335693
2025-12-09 12:11:33.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.005726142856227452 Training loss: 3.849391460418701
2025-12-09 12:11:33.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.005672694603709794 Training loss: 3.919929265975952
2025-12-09 12:11:33.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.005619167949128652 Training loss: 3.9092259407043457
2025-12-09 12:11:33.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.005565569130976423 Training loss: 3.8333356380462646
2025-12-09 12:11:33.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.005511904396156113 Training loss: 3.8947973251342773
2025-12-09 12:11:33.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.005458179999253274 Training loss: 3.7952513694763184
2025-12-09 12:11:33.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.005404402201807022 Training loss: 3.902158498764038
2025-12-09 12:11:33.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.00535057727158027 Training loss: 3.963897228240967
2025-12-09 12:11:33.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.005296711481829226 Training loss: 3.9625351428985596
2025-12-09 12:11:33.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.005242811110572242 Training loss: 3.986726760864258
2025-12-09 12:11:33.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.005188882439858117 Training loss: 3.782170534133911
2025-12-09 12:11:33.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.005134931755033936 Training loss: 3.913926601409912
2025-12-09 12:11:33.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.005080965344012508 Training loss: 3.8284809589385986
2025-12-09 12:11:33.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.005026989496539522 Training loss: 3.9078915119171143
2025-12-09 12:11:33.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.004973010503460479 Training loss: 3.890385150909424
2025-12-09 12:11:33.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.004919034655987493 Training loss: 3.9408814907073975
2025-12-09 12:11:33.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.004865068244966066 Training loss: 3.933562755584717
2025-12-09 12:11:33.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0048111175601418844 Training loss: 3.893522262573242
2025-12-09 12:11:33.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.0047571888894277605 Training loss: 3.865877866744995
2025-12-09 12:11:33.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0047032885181707736 Training loss: 3.9430980682373047
2025-12-09 12:11:33.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.004649422728419729 Training loss: 3.903740406036377
2025-12-09 12:11:33.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0045955977981929795 Training loss: 3.7563443183898926
2025-12-09 12:11:33.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.004541820000746727 Training loss: 3.9440009593963623
2025-12-09 12:11:33.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.004488095603843887 Training loss: 3.9523515701293945
2025-12-09 12:11:33.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.004434430869023579 Training loss: 3.9414052963256836
2025-12-09 12:11:33.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.00438083205087135 Training loss: 3.9192235469818115
2025-12-09 12:11:33.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.004327305396290207 Training loss: 3.916205883026123
2025-12-09 12:11:33.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.00427385714377255 Training loss: 3.912727117538452
2025-12-09 12:11:33.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.004220493522673068 Training loss: 3.9411745071411133
2025-12-09 12:11:33.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.004167220752482727 Training loss: 3.916149854660034
2025-12-09 12:11:33.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0041140450421038866 Training loss: 3.986769437789917
2025-12-09 12:11:33.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00406097258912665 Training loss: 3.9621918201446533
2025-12-09 12:11:33.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.004008009579106551 Training loss: 3.941664934158325
2025-12-09 12:11:33.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.003955162184843625 Training loss: 4.070698261260986
2025-12-09 12:11:33.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.003902436565662977 Training loss: 3.9918408393859863
2025-12-09 12:11:33.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.003849838866696913 Training loss: 3.9952499866485596
2025-12-09 12:11:33.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.003797375218168733 Training loss: 3.938755512237549
2025-12-09 12:11:33.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.0037450517346782563 Training loss: 3.990736722946167
2025-12-09 12:11:33.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0036928745144891727 Training loss: 3.9722604751586914
2025-12-09 12:11:33.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.0036408496388182854 Training loss: 3.8684351444244385
2025-12-09 12:11:33.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0035889831711267616 Training loss: 3.8545961380004883
2025-12-09 12:11:33.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.00353728115641343 Training loss: 4.054102420806885
2025-12-09 12:11:33.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.003485749620510247 Training loss: 3.942277669906616
2025-12-09 12:11:33.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0034343945693799884 Training loss: 4.013033866882324
2025-12-09 12:11:33.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.0033832219884162586 Training loss: 3.9333646297454834
2025-12-09 12:11:33.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0033322378417458983 Training loss: 3.873056173324585
2025-12-09 12:11:33.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.0032814480715338667 Training loss: 3.894305944442749
2025-12-09 12:11:33.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0032308585972906966 Training loss: 3.9368066787719727
2025-12-09 12:11:33.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0031804753151825627 Training loss: 3.870872974395752
2025-12-09 12:11:33.831 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0031303040973441033 Training loss: 3.9965274333953857
2025-12-09 12:11:33.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.003080350791194019 Training loss: 3.879369020462036
2025-12-09 12:11:33.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0030306212187535654 Training loss: 4.049580097198486
2025-12-09 12:11:33.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0029811211759679926 Training loss: 3.919034719467163
2025-12-09 12:11:33.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0029318564320310442 Training loss: 3.973761558532715
2025-12-09 12:11:33.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.002882832728712551 Training loss: 4.031489849090576
2025-12-09 12:11:33.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0028340557796892353 Training loss: 3.980501651763916
2025-12-09 12:11:33.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0027855312698787903 Training loss: 3.8006439208984375
2025-12-09 12:11:33.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.002737264854777306 Training loss: 3.944746732711792
2025-12-09 12:11:33.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0026892621598001154 Training loss: 3.9156999588012695
2025-12-09 12:11:33.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0026415287796261707 Training loss: 3.902442693710327
2025-12-09 12:11:33.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.0025940702775459745 Training loss: 4.028079986572266
2025-12-09 12:11:33.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.002546892184813198 Training loss: 3.9284791946411133
2025-12-09 12:11:33.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0025000000000000014 Training loss: 3.90989351272583
2025-12-09 12:11:33.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0024533991883561868 Training loss: 3.9583487510681152
2025-12-09 12:11:33.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.002407095181172227 Training loss: 3.9241085052490234
2025-12-09 12:11:33.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.0023610933751462555 Training loss: 3.830796718597412
2025-12-09 12:11:33.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.002315399131755081 Training loss: 4.122804641723633
2025-12-09 12:11:33.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.0022700177766293095 Training loss: 3.9318158626556396
2025-12-09 12:11:34.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.002224954598932651 Training loss: 3.9008328914642334
2025-12-09 12:11:34.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0021802148507454673 Training loss: 3.932372570037842
2025-12-09 12:11:34.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.0021358037464526513 Training loss: 3.9924678802490234
2025-12-09 12:11:34.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0020917264621358876 Training loss: 3.7409842014312744
2025-12-09 12:11:34.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.0020479881349703883 Training loss: 3.8990533351898193
2025-12-09 12:11:34.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0020045938626261544 Training loss: 3.9349300861358643
2025-12-09 12:11:34.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0019615487026738545 Training loss: 3.800612688064575
2025-12-09 12:11:34.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.0019188576719953632 Training loss: 3.9569833278656006
2025-12-09 12:11:34.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0018765257461990442 Training loss: 3.9225854873657227
2025-12-09 12:11:34.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0018345578590398509 Training loss: 3.91028094291687
2025-12-09 12:11:34.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.0017929589018443016 Training loss: 3.9152793884277344
2025-12-09 12:11:34.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0017517337229403945 Training loss: 3.902869701385498
2025-12-09 12:11:34.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.001710887127092548 Training loss: 3.9113223552703857
2025-12-09 12:11:34.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0016704238749415956 Training loss: 3.9429147243499756
2025-12-09 12:11:34.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0016303486824499457 Training loss: 3.9565155506134033
2025-12-09 12:11:34.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.0015906662203519412 Training loss: 3.9254329204559326
2025-12-09 12:11:34.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0015513811136094785 Training loss: 3.939687490463257
2025-12-09 12:11:34.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.001512497940872986 Training loss: 3.9328417778015137
2025-12-09 12:11:34.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.001474021233947772 Training loss: 4.05983304977417
2025-12-09 12:11:34.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.0014359554772658551 Training loss: 3.8749053478240967
2025-12-09 12:11:34.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0013983051073632995 Training loss: 3.938941717147827
2025-12-09 12:11:34.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.0013610745123631535 Training loss: 3.8913333415985107
2025-12-09 12:11:34.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.0013242680314639993 Training loss: 3.917250394821167
2025-12-09 12:11:34.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.0012878899544342326 Training loss: 3.9330332279205322
2025-12-09 12:11:34.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.0012519445211120978 Training loss: 3.917512893676758
2025-12-09 12:11:34.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.0012164359209115233 Training loss: 3.9962706565856934
2025-12-09 12:11:34.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.0011813682923338654 Training loss: 4.017280578613281
2025-12-09 12:11:34.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0011467457224855543 Training loss: 3.9850916862487793
2025-12-09 12:11:34.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0011125722466017547 Training loss: 3.916255474090576
2025-12-09 12:11:34.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.0010788518475760545 Training loss: 3.990952968597412
2025-12-09 12:11:34.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.0010455884554962725 Training loss: 3.8530120849609375
2025-12-09 12:11:34.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.001012785947186397 Training loss: 3.9510042667388916
2025-12-09 12:11:34.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.00098044814575475 Training loss: 3.885038375854492
2025-12-09 12:11:34.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0009485788201484125 Training loss: 3.8682806491851807
2025-12-09 12:11:34.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.0009171816847139447 Training loss: 3.881326675415039
2025-12-09 12:11:34.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.000886260398764494 Training loss: 3.9488165378570557
2025-12-09 12:11:34.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.0008558185661532941 Training loss: 3.9613871574401855
2025-12-09 12:11:34.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.000825859734853645 Training loss: 3.905569553375244
2025-12-09 12:11:34.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.0007963873965453961 Training loss: 3.942383289337158
2025-12-09 12:11:34.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.000767404986207999 Training loss: 3.8871045112609863
2025-12-09 12:11:34.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.0007389158817201541 Training loss: 3.868868827819824
2025-12-09 12:11:34.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.0007109234034661288 Training loss: 3.8949484825134277
2025-12-09 12:11:34.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.0006834308139487672 Training loss: 3.8463385105133057
2025-12-09 12:11:34.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.0006564413174092443 Training loss: 3.992729902267456
2025-12-09 12:11:34.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.0006299580594536214 Training loss: 3.9357361793518066
2025-12-09 12:11:34.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.0006039841266862189 Training loss: 3.9334776401519775
2025-12-09 12:11:34.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.0005785225463498828 Training loss: 3.7592787742614746
2025-12-09 12:11:34.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0005535762859731547 Training loss: 3.9143030643463135
2025-12-09 12:11:34.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0005291482530244179 Training loss: 3.927861213684082
2025-12-09 12:11:34.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0005052412945730239 Training loss: 3.942962884902954
2025-12-09 12:11:34.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.00048185819695747425 Training loss: 3.9304752349853516
2025-12-09 12:11:34.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.00045900168546067266 Training loss: 3.964097023010254
2025-12-09 12:11:34.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.00043667442399229983 Training loss: 3.8872013092041016
2025-12-09 12:11:34.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.0004148790147783288 Training loss: 3.9013235569000244
2025-12-09 12:11:34.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.00039361799805774536 Training loss: 3.797542095184326
2025-12-09 12:11:34.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0003728938517864794 Training loss: 3.9449353218078613
2025-12-09 12:11:34.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.00035270899134860366 Training loss: 3.894970178604126
2025-12-09 12:11:34.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.00033306576927482126 Training loss: 3.9375550746917725
2025-12-09 12:11:34.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.0003139664749682825 Training loss: 3.915729284286499
2025-12-09 12:11:34.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0002954133344377524 Training loss: 4.051356315612793
2025-12-09 12:11:34.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.00027740851003817346 Training loss: 3.8921754360198975
2025-12-09 12:11:34.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.00025995410021864785 Training loss: 4.056573390960693
2025-12-09 12:11:34.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.0002430521392778573 Training loss: 4.006616592407227
2025-12-09 12:11:34.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.00022670459712697378 Training loss: 3.9521312713623047
2025-12-09 12:11:34.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0002109133790600648 Training loss: 3.9455838203430176
2025-12-09 12:11:34.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.00019568032553203218 Training loss: 3.8730010986328125
2025-12-09 12:11:34.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.0001810072119441103 Training loss: 4.015859603881836
2025-12-09 12:11:34.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.00016689574843694433 Training loss: 3.9601869583129883
2025-12-09 12:11:34.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.000153347579691272 Training loss: 3.9517340660095215
2025-12-09 12:11:34.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.0001403642847362402 Training loss: 3.7733254432678223
2025-12-09 12:11:34.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.00012794737676536993 Training loss: 3.9681990146636963
2025-12-09 12:11:34.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.00011609830296019141 Training loss: 3.886141777038574
2025-12-09 12:11:34.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.0001048184443215816 Training loss: 4.091668128967285
2025-12-09 12:11:34.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.410911550880474e-05 Training loss: 3.928171157836914
2025-12-09 12:11:34.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 8.397156468629208e-05 Training loss: 3.9110515117645264
2025-12-09 12:11:34.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 7.44069733781677e-05 Training loss: 3.8733232021331787
2025-12-09 12:11:34.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 6.54164563305465e-05 Training loss: 3.89414644241333
2025-12-09 12:11:34.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 5.7001061381606875e-05 Training loss: 3.958062171936035
2025-12-09 12:11:34.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 4.916176933946692e-05 Training loss: 3.9129767417907715
2025-12-09 12:11:34.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 4.1899493867874615e-05 Training loss: 3.9523539543151855
2025-12-09 12:11:34.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 3.521508137971807e-05 Training loss: 3.8005762100219727
2025-12-09 12:11:34.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 2.9109310938378874e-05 Training loss: 3.9646689891815186
2025-12-09 12:11:34.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 2.358289416693027e-05 Training loss: 3.847015142440796
2025-12-09 12:11:34.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 1.863647516520017e-05 Training loss: 3.8909761905670166
2025-12-09 12:11:34.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 1.4270630434701781e-05 Training loss: 3.9198834896087646
2025-12-09 12:11:34.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 1.0485868811441756e-05 Training loss: 3.9823365211486816
2025-12-09 12:11:34.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 7.2826314066154475e-06 Training loss: 3.8539812564849854
2025-12-09 12:11:34.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 4.661291555196345e-06 Training loss: 3.9627573490142822
2025-12-09 12:11:34.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 2.6221547724253337e-06 Training loss: 3.8935186862945557
2025-12-09 12:11:34.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 1.1654587182013953e-06 Training loss: 3.9624314308166504
2025-12-09 12:11:34.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 2.9137316938265825e-07 Training loss: 3.9579694271087646
2025-12-09 12:11:34.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0 Training loss: 3.942992687225342
