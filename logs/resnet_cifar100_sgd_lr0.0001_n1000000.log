2025-12-09 12:10:23.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 4.907971382141113
2025-12-09 12:10:24.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 4.957444190979004
2025-12-09 12:10:24.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 4.860047817230225
2025-12-09 12:10:24.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 4.812797546386719
2025-12-09 12:10:24.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 4.787594795227051
2025-12-09 12:10:24.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 4.766610145568848
2025-12-09 12:10:24.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 4.905178070068359
2025-12-09 12:10:24.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 4.8737993240356445
2025-12-09 12:10:24.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 4.873974800109863
2025-12-09 12:10:24.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 4.973836898803711
2025-12-09 12:10:24.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 4.882420063018799
2025-12-09 12:10:24.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 4.875424385070801
2025-12-09 12:10:24.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 4.886445999145508
2025-12-09 12:10:24.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 4.794862270355225
2025-12-09 12:10:24.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 4.873569965362549
2025-12-09 12:10:24.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 4.9359331130981445
2025-12-09 12:10:24.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 4.936360836029053
2025-12-09 12:10:24.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 4.909849643707275
2025-12-09 12:10:24.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 4.868920803070068
2025-12-09 12:10:24.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 4.84190034866333
2025-12-09 12:10:24.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 4.921121597290039
2025-12-09 12:10:24.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 4.852879047393799
2025-12-09 12:10:24.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 4.8064866065979
2025-12-09 12:10:24.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 4.8459272384643555
2025-12-09 12:10:24.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 4.865230083465576
2025-12-09 12:10:24.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 4.869145393371582
2025-12-09 12:10:24.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 4.963872909545898
2025-12-09 12:10:24.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 4.909871578216553
2025-12-09 12:10:24.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 4.998039245605469
2025-12-09 12:10:24.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 4.832668304443359
2025-12-09 12:10:24.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 4.767815113067627
2025-12-09 12:10:24.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 4.8122477531433105
2025-12-09 12:10:24.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 4.96865701675415
2025-12-09 12:10:24.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 4.926826477050781
2025-12-09 12:10:24.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 4.875787258148193
2025-12-09 12:10:24.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 4.922014236450195
2025-12-09 12:10:24.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 4.908091068267822
2025-12-09 12:10:24.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 4.743923187255859
2025-12-09 12:10:24.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 4.972306251525879
2025-12-09 12:10:24.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 4.8860931396484375
2025-12-09 12:10:24.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 4.810646057128906
2025-12-09 12:10:24.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 4.908370494842529
2025-12-09 12:10:24.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 4.816158294677734
2025-12-09 12:10:24.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 4.862439155578613
2025-12-09 12:10:24.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 4.916985034942627
2025-12-09 12:10:24.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 4.819779872894287
2025-12-09 12:10:24.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 4.842116832733154
2025-12-09 12:10:24.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 4.789724826812744
2025-12-09 12:10:24.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 4.933648109436035
2025-12-09 12:10:24.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 4.885436534881592
2025-12-09 12:10:24.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 4.8044915199279785
2025-12-09 12:10:24.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 4.865243911743164
2025-12-09 12:10:24.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 4.76973819732666
2025-12-09 12:10:24.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 4.860470294952393
2025-12-09 12:10:24.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 4.819348335266113
2025-12-09 12:10:24.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 4.7875189781188965
2025-12-09 12:10:24.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 4.818707466125488
2025-12-09 12:10:24.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 4.819823741912842
2025-12-09 12:10:24.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 4.7914509773254395
2025-12-09 12:10:24.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 4.771718502044678
2025-12-09 12:10:24.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 4.8953680992126465
2025-12-09 12:10:24.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 4.774362564086914
2025-12-09 12:10:24.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 4.898242950439453
2025-12-09 12:10:24.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 4.780333518981934
2025-12-09 12:10:24.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 4.8127899169921875
2025-12-09 12:10:24.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 4.782648086547852
2025-12-09 12:10:24.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 4.788565158843994
2025-12-09 12:10:24.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 4.861630439758301
2025-12-09 12:10:24.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 4.780557155609131
2025-12-09 12:10:24.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 4.912302017211914
2025-12-09 12:10:24.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 4.89421272277832
2025-12-09 12:10:24.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 4.800652503967285
2025-12-09 12:10:24.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 4.7626519203186035
2025-12-09 12:10:24.662 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 4.815915107727051
2025-12-09 12:10:24.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 4.8003644943237305
2025-12-09 12:10:24.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 4.97343635559082
2025-12-09 12:10:24.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 4.841297149658203
2025-12-09 12:10:24.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 4.858682632446289
2025-12-09 12:10:24.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 4.8419718742370605
2025-12-09 12:10:24.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 4.8026604652404785
2025-12-09 12:10:24.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 4.761198997497559
2025-12-09 12:10:24.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 4.759632110595703
2025-12-09 12:10:24.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 4.846512794494629
2025-12-09 12:10:24.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 4.883699417114258
2025-12-09 12:10:24.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 4.714009761810303
2025-12-09 12:10:24.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 4.820606708526611
2025-12-09 12:10:24.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 4.845696449279785
2025-12-09 12:10:24.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 4.815609455108643
2025-12-09 12:10:24.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 4.821203231811523
2025-12-09 12:10:24.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 4.8105058670043945
2025-12-09 12:10:24.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 4.743127346038818
2025-12-09 12:10:24.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 4.82726526260376
2025-12-09 12:10:24.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 4.778238773345947
2025-12-09 12:10:24.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 4.829257965087891
2025-12-09 12:10:24.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 4.665696144104004
2025-12-09 12:10:24.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 4.808218002319336
2025-12-09 12:10:24.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 4.847850799560547
2025-12-09 12:10:24.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 4.774447917938232
2025-12-09 12:10:24.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 4.919154644012451
2025-12-09 12:10:24.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 4.86950159072876
2025-12-09 12:10:24.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.999708626830618e-05 Training loss: 4.836139678955078
2025-12-09 12:10:24.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 9.998834541281798e-05 Training loss: 4.779212951660156
2025-12-09 12:10:24.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 9.997377845227576e-05 Training loss: 4.680291652679443
2025-12-09 12:10:24.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 9.995338708444804e-05 Training loss: 4.763490200042725
2025-12-09 12:10:24.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 9.992717368593385e-05 Training loss: 4.742900848388672
2025-12-09 12:10:24.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 9.989514131188559e-05 Training loss: 4.715579986572266
2025-12-09 12:10:24.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 9.985729369565299e-05 Training loss: 4.853318214416504
2025-12-09 12:10:24.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 9.9813635248348e-05 Training loss: 4.80556583404541
2025-12-09 12:10:24.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 9.97641710583307e-05 Training loss: 4.703510761260986
2025-12-09 12:10:24.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 9.970890689061622e-05 Training loss: 4.742842197418213
2025-12-09 12:10:24.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 9.964784918620282e-05 Training loss: 4.698842525482178
2025-12-09 12:10:25.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 9.958100506132127e-05 Training loss: 4.804790019989014
2025-12-09 12:10:25.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 9.950838230660534e-05 Training loss: 4.837248802185059
2025-12-09 12:10:25.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 9.942998938618394e-05 Training loss: 4.775973796844482
2025-12-09 12:10:25.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 9.934583543669453e-05 Training loss: 4.633072853088379
2025-12-09 12:10:25.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 9.925593026621833e-05 Training loss: 4.870121479034424
2025-12-09 12:10:25.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 9.916028435313708e-05 Training loss: 4.6728997230529785
2025-12-09 12:10:25.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 9.905890884491195e-05 Training loss: 4.803297519683838
2025-12-09 12:10:25.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 9.895181555678418e-05 Training loss: 4.78734827041626
2025-12-09 12:10:25.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 9.883901697039808e-05 Training loss: 4.7867817878723145
2025-12-09 12:10:25.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 9.872052623234632e-05 Training loss: 4.791261196136475
2025-12-09 12:10:25.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 9.85963571526376e-05 Training loss: 4.752967834472656
2025-12-09 12:10:25.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 9.846652420308728e-05 Training loss: 4.685964584350586
2025-12-09 12:10:25.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 9.833104251563056e-05 Training loss: 4.652489185333252
2025-12-09 12:10:25.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 9.818992788055889e-05 Training loss: 4.677829265594482
2025-12-09 12:10:25.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 9.80431967446797e-05 Training loss: 4.766981601715088
2025-12-09 12:10:25.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 9.789086620939936e-05 Training loss: 4.801562786102295
2025-12-09 12:10:25.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 9.773295402873026e-05 Training loss: 4.734707832336426
2025-12-09 12:10:25.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 9.756947860722143e-05 Training loss: 4.710258483886719
2025-12-09 12:10:25.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 9.740045899781352e-05 Training loss: 4.816636085510254
2025-12-09 12:10:25.175 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 9.722591489961827e-05 Training loss: 4.819004058837891
2025-12-09 12:10:25.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 9.70458666556225e-05 Training loss: 4.784666538238525
2025-12-09 12:10:25.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 9.686033525031719e-05 Training loss: 4.77259635925293
2025-12-09 12:10:25.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 9.66693423072518e-05 Training loss: 4.678206443786621
2025-12-09 12:10:25.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 9.647291008651398e-05 Training loss: 4.707163333892822
2025-12-09 12:10:25.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 9.627106148213522e-05 Training loss: 4.866433143615723
2025-12-09 12:10:25.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 9.606382001942255e-05 Training loss: 4.712533473968506
2025-12-09 12:10:25.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 9.585120985221671e-05 Training loss: 4.6754560470581055
2025-12-09 12:10:25.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 9.563325576007701e-05 Training loss: 4.6743059158325195
2025-12-09 12:10:25.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 9.540998314539328e-05 Training loss: 4.748734951019287
2025-12-09 12:10:25.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 9.518141803042527e-05 Training loss: 4.7048258781433105
2025-12-09 12:10:25.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 9.494758705426978e-05 Training loss: 4.583733558654785
2025-12-09 12:10:25.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 9.470851746975582e-05 Training loss: 4.688715934753418
2025-12-09 12:10:25.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 9.446423714026846e-05 Training loss: 4.661032676696777
2025-12-09 12:10:25.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 9.421477453650118e-05 Training loss: 4.718573570251465
2025-12-09 12:10:25.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 9.396015873313781e-05 Training loss: 4.734680652618408
2025-12-09 12:10:25.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 9.37004194054638e-05 Training loss: 4.615506649017334
2025-12-09 12:10:25.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 9.343558682590756e-05 Training loss: 4.74954891204834
2025-12-09 12:10:25.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 9.316569186051234e-05 Training loss: 4.6720075607299805
2025-12-09 12:10:25.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 9.289076596533872e-05 Training loss: 4.754241943359375
2025-12-09 12:10:25.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 9.261084118279847e-05 Training loss: 4.637587547302246
2025-12-09 12:10:25.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 9.232595013792002e-05 Training loss: 4.7117791175842285
2025-12-09 12:10:25.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 9.203612603454604e-05 Training loss: 4.792900085449219
2025-12-09 12:10:25.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 9.174140265146356e-05 Training loss: 4.7995195388793945
2025-12-09 12:10:25.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 9.144181433846707e-05 Training loss: 4.756005764007568
2025-12-09 12:10:25.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 9.113739601235507e-05 Training loss: 4.661434650421143
2025-12-09 12:10:25.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 9.082818315286055e-05 Training loss: 4.6773905754089355
2025-12-09 12:10:25.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 9.051421179851588e-05 Training loss: 4.694996356964111
2025-12-09 12:10:25.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 9.01955185424525e-05 Training loss: 4.65143346786499
2025-12-09 12:10:25.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 8.987214052813604e-05 Training loss: 4.758235931396484
2025-12-09 12:10:25.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 8.954411544503729e-05 Training loss: 4.612920761108398
2025-12-09 12:10:25.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 8.921148152423946e-05 Training loss: 4.688267230987549
2025-12-09 12:10:25.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 8.887427753398248e-05 Training loss: 4.7402729988098145
2025-12-09 12:10:25.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 8.853254277514446e-05 Training loss: 4.722153663635254
2025-12-09 12:10:25.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 8.818631707666135e-05 Training loss: 4.748049736022949
2025-12-09 12:10:25.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 8.783564079088477e-05 Training loss: 4.675985336303711
2025-12-09 12:10:25.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 8.748055478887904e-05 Training loss: 4.7215962409973145
2025-12-09 12:10:25.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 8.712110045565768e-05 Training loss: 4.645313739776611
2025-12-09 12:10:25.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 8.675731968536002e-05 Training loss: 4.783406734466553
2025-12-09 12:10:25.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 8.638925487636848e-05 Training loss: 4.615962982177734
2025-12-09 12:10:25.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 8.6016948926367e-05 Training loss: 4.695751190185547
2025-12-09 12:10:25.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 8.564044522734147e-05 Training loss: 4.677157878875732
2025-12-09 12:10:25.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 8.52597876605223e-05 Training loss: 4.736030101776123
2025-12-09 12:10:25.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 8.487502059127015e-05 Training loss: 4.676167964935303
2025-12-09 12:10:25.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 8.448618886390522e-05 Training loss: 4.761224746704102
2025-12-09 12:10:25.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 8.40933377964806e-05 Training loss: 4.604290962219238
2025-12-09 12:10:25.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 8.369651317550054e-05 Training loss: 4.641727924346924
2025-12-09 12:10:25.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 8.329576125058406e-05 Training loss: 4.6582112312316895
2025-12-09 12:10:25.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 8.289112872907454e-05 Training loss: 4.688159942626953
2025-12-09 12:10:25.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 8.248266277059607e-05 Training loss: 4.746052265167236
2025-12-09 12:10:25.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 8.2070410981557e-05 Training loss: 4.784171104431152
2025-12-09 12:10:25.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 8.16544214096015e-05 Training loss: 4.748006343841553
2025-12-09 12:10:25.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 8.123474253800957e-05 Training loss: 4.7680888175964355
2025-12-09 12:10:25.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 8.081142328004637e-05 Training loss: 4.617072582244873
2025-12-09 12:10:25.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 8.038451297326145e-05 Training loss: 4.602840423583984
2025-12-09 12:10:25.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 7.995406137373846e-05 Training loss: 4.603789329528809
2025-12-09 12:10:25.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 7.952011865029614e-05 Training loss: 4.646778106689453
2025-12-09 12:10:25.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 7.908273537864113e-05 Training loss: 4.648396968841553
2025-12-09 12:10:25.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 7.86419625354735e-05 Training loss: 4.671241760253906
2025-12-09 12:10:25.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 7.819785149254532e-05 Training loss: 4.669809341430664
2025-12-09 12:10:25.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 7.77504540106735e-05 Training loss: 4.6280107498168945
2025-12-09 12:10:25.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 7.729982223370691e-05 Training loss: 4.659243106842041
2025-12-09 12:10:25.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 7.68460086824492e-05 Training loss: 4.730655193328857
2025-12-09 12:10:25.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 7.638906624853743e-05 Training loss: 4.659505844116211
2025-12-09 12:10:25.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 7.592904818827775e-05 Training loss: 4.689550399780273
2025-12-09 12:10:25.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 7.546600811643816e-05 Training loss: 4.658249855041504
2025-12-09 12:10:25.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 7.500000000000001e-05 Training loss: 4.814933776855469
2025-12-09 12:10:25.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 7.453107815186803e-05 Training loss: 4.679050445556641
2025-12-09 12:10:25.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 7.405929722454026e-05 Training loss: 4.591284275054932
2025-12-09 12:10:25.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 7.358471220373832e-05 Training loss: 4.5713582038879395
2025-12-09 12:10:25.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 7.310737840199885e-05 Training loss: 4.732172966003418
2025-12-09 12:10:25.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 7.262735145222696e-05 Training loss: 4.599201679229736
2025-12-09 12:10:25.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 7.214468730121208e-05 Training loss: 4.688650131225586
2025-12-09 12:10:25.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 7.165944220310767e-05 Training loss: 4.648667335510254
2025-12-09 12:10:25.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 7.117167271287453e-05 Training loss: 4.586517810821533
2025-12-09 12:10:25.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 7.068143567968957e-05 Training loss: 4.62443208694458
2025-12-09 12:10:25.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 7.018878824032009e-05 Training loss: 4.59727144241333
2025-12-09 12:10:25.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 6.969378781246436e-05 Training loss: 4.623604774475098
2025-12-09 12:10:25.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 6.919649208805981e-05 Training loss: 4.6200432777404785
2025-12-09 12:10:25.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 6.869695902655897e-05 Training loss: 4.647836208343506
2025-12-09 12:10:25.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 6.819524684817438e-05 Training loss: 4.652505874633789
2025-12-09 12:10:25.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 6.769141402709305e-05 Training loss: 4.689259052276611
2025-12-09 12:10:25.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 6.718551928466132e-05 Training loss: 4.654417991638184
2025-12-09 12:10:25.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 6.667762158254104e-05 Training loss: 4.692049980163574
2025-12-09 12:10:25.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 6.616778011583743e-05 Training loss: 4.641163349151611
2025-12-09 12:10:25.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 6.565605430620013e-05 Training loss: 4.6899847984313965
2025-12-09 12:10:25.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 6.514250379489753e-05 Training loss: 4.682065486907959
2025-12-09 12:10:25.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 6.462718843586571e-05 Training loss: 4.6492018699646
2025-12-09 12:10:25.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 6.411016828873239e-05 Training loss: 4.649108409881592
2025-12-09 12:10:25.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 6.359150361181715e-05 Training loss: 4.617119312286377
2025-12-09 12:10:25.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 6.307125485510828e-05 Training loss: 4.6674394607543945
2025-12-09 12:10:26.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 6.254948265321744e-05 Training loss: 4.628439426422119
2025-12-09 12:10:26.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 6.202624781831268e-05 Training loss: 4.673192977905273
2025-12-09 12:10:26.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 6.150161133303089e-05 Training loss: 4.620997428894043
2025-12-09 12:10:26.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 6.0975634343370256e-05 Training loss: 4.73552942276001
2025-12-09 12:10:26.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 6.044837815156377e-05 Training loss: 4.614482402801514
2025-12-09 12:10:26.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 5.99199042089345e-05 Training loss: 4.7403998374938965
2025-12-09 12:10:26.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 5.939027410873351e-05 Training loss: 4.59008264541626
2025-12-09 12:10:26.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 5.885954957896115e-05 Training loss: 4.627496719360352
2025-12-09 12:10:26.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 5.832779247517273e-05 Training loss: 4.60443639755249
2025-12-09 12:10:26.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 5.779506477326933e-05 Training loss: 4.622897624969482
2025-12-09 12:10:26.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 5.726142856227452e-05 Training loss: 4.680037021636963
2025-12-09 12:10:26.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 5.672694603709794e-05 Training loss: 4.591458320617676
2025-12-09 12:10:26.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 5.619167949128652e-05 Training loss: 4.5417656898498535
2025-12-09 12:10:26.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 5.565569130976422e-05 Training loss: 4.714883327484131
2025-12-09 12:10:26.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 5.5119043961561136e-05 Training loss: 4.604859352111816
2025-12-09 12:10:26.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 5.458179999253275e-05 Training loss: 4.662763595581055
2025-12-09 12:10:26.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 5.4044022018070214e-05 Training loss: 4.610616683959961
2025-12-09 12:10:26.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 5.3505772715802704e-05 Training loss: 4.750649452209473
2025-12-09 12:10:26.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 5.296711481829226e-05 Training loss: 4.608469486236572
2025-12-09 12:10:26.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 5.242811110572242e-05 Training loss: 4.633726596832275
2025-12-09 12:10:26.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 5.188882439858117e-05 Training loss: 4.669454574584961
2025-12-09 12:10:26.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 5.134931755033936e-05 Training loss: 4.705146312713623
2025-12-09 12:10:26.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 5.080965344012508e-05 Training loss: 4.589592456817627
2025-12-09 12:10:26.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 5.0269894965395225e-05 Training loss: 4.667049407958984
2025-12-09 12:10:26.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 4.973010503460479e-05 Training loss: 4.696052551269531
2025-12-09 12:10:26.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 4.919034655987493e-05 Training loss: 4.647568702697754
2025-12-09 12:10:26.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 4.865068244966066e-05 Training loss: 4.681477069854736
2025-12-09 12:10:26.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 4.8111175601418844e-05 Training loss: 4.618325710296631
2025-12-09 12:10:26.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 4.7571888894277604e-05 Training loss: 4.627194404602051
2025-12-09 12:10:26.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 4.703288518170774e-05 Training loss: 4.585501194000244
2025-12-09 12:10:26.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 4.6494227284197294e-05 Training loss: 4.612973213195801
2025-12-09 12:10:26.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 4.59559779819298e-05 Training loss: 4.610203266143799
2025-12-09 12:10:26.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 4.541820000746727e-05 Training loss: 4.603785037994385
2025-12-09 12:10:26.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 4.4880956038438876e-05 Training loss: 4.627879619598389
2025-12-09 12:10:26.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 4.434430869023579e-05 Training loss: 4.599803924560547
2025-12-09 12:10:26.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 4.38083205087135e-05 Training loss: 4.544999599456787
2025-12-09 12:10:26.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 4.3273053962902076e-05 Training loss: 4.562901020050049
2025-12-09 12:10:26.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 4.27385714377255e-05 Training loss: 4.708462715148926
2025-12-09 12:10:26.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 4.220493522673067e-05 Training loss: 4.721587181091309
2025-12-09 12:10:26.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 4.1672207524827275e-05 Training loss: 4.671030521392822
2025-12-09 12:10:26.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 4.114045042103887e-05 Training loss: 4.648709774017334
2025-12-09 12:10:26.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 4.06097258912665e-05 Training loss: 4.767886638641357
2025-12-09 12:10:26.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 4.0080095791065505e-05 Training loss: 4.655065059661865
2025-12-09 12:10:26.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 3.955162184843625e-05 Training loss: 4.7029290199279785
2025-12-09 12:10:26.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 3.902436565662977e-05 Training loss: 4.620434761047363
2025-12-09 12:10:26.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 3.849838866696913e-05 Training loss: 4.644344806671143
2025-12-09 12:10:26.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 3.7973752181687335e-05 Training loss: 4.581216812133789
2025-12-09 12:10:26.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 3.745051734678256e-05 Training loss: 4.595482349395752
2025-12-09 12:10:26.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 3.692874514489173e-05 Training loss: 4.55275821685791
2025-12-09 12:10:26.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 3.640849638818286e-05 Training loss: 4.641238689422607
2025-12-09 12:10:26.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 3.588983171126762e-05 Training loss: 4.717303276062012
2025-12-09 12:10:26.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 3.53728115641343e-05 Training loss: 4.582077980041504
2025-12-09 12:10:26.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 3.4857496205102474e-05 Training loss: 4.605231761932373
2025-12-09 12:10:26.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 3.434394569379988e-05 Training loss: 4.609257698059082
2025-12-09 12:10:26.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 3.3832219884162585e-05 Training loss: 4.606118202209473
2025-12-09 12:10:26.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 3.332237841745898e-05 Training loss: 4.614644527435303
2025-12-09 12:10:26.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 3.281448071533867e-05 Training loss: 4.670120716094971
2025-12-09 12:10:26.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 3.2308585972906966e-05 Training loss: 4.637135982513428
2025-12-09 12:10:26.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 3.180475315182563e-05 Training loss: 4.616158485412598
2025-12-09 12:10:26.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 3.130304097344103e-05 Training loss: 4.685121059417725
2025-12-09 12:10:26.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 3.080350791194019e-05 Training loss: 4.731886386871338
2025-12-09 12:10:26.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 3.0306212187535653e-05 Training loss: 4.5429253578186035
2025-12-09 12:10:26.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 2.9811211759679924e-05 Training loss: 4.6024651527404785
2025-12-09 12:10:26.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 2.9318564320310444e-05 Training loss: 4.540170192718506
2025-12-09 12:10:26.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 2.882832728712551e-05 Training loss: 4.618969917297363
2025-12-09 12:10:26.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 2.8340557796892354e-05 Training loss: 4.617508888244629
2025-12-09 12:10:26.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 2.7855312698787904e-05 Training loss: 4.699535846710205
2025-12-09 12:10:26.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 2.737264854777306e-05 Training loss: 4.618800163269043
2025-12-09 12:10:26.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 2.6892621598001156e-05 Training loss: 4.586756706237793
2025-12-09 12:10:26.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 2.6415287796261706e-05 Training loss: 4.5034284591674805
2025-12-09 12:10:26.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 2.5940702775459747e-05 Training loss: 4.695474624633789
2025-12-09 12:10:26.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 2.5468921848131983e-05 Training loss: 4.563948631286621
2025-12-09 12:10:26.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 2.500000000000001e-05 Training loss: 4.628469944000244
2025-12-09 12:10:26.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 2.4533991883561868e-05 Training loss: 4.701230049133301
2025-12-09 12:10:26.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 2.407095181172227e-05 Training loss: 4.503653049468994
2025-12-09 12:10:26.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 2.3610933751462553e-05 Training loss: 4.602452754974365
2025-12-09 12:10:26.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 2.315399131755081e-05 Training loss: 4.569428443908691
2025-12-09 12:10:26.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 2.2700177766293096e-05 Training loss: 4.643949031829834
2025-12-09 12:10:26.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 2.2249545989326514e-05 Training loss: 4.5848870277404785
2025-12-09 12:10:26.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 2.180214850745467e-05 Training loss: 4.583914756774902
2025-12-09 12:10:26.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 2.1358037464526515e-05 Training loss: 4.646420955657959
2025-12-09 12:10:26.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 2.091726462135888e-05 Training loss: 4.602053642272949
2025-12-09 12:10:26.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 2.0479881349703883e-05 Training loss: 4.509942531585693
2025-12-09 12:10:26.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 2.0045938626261546e-05 Training loss: 4.668471336364746
2025-12-09 12:10:26.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 1.9615487026738543e-05 Training loss: 4.669211387634277
2025-12-09 12:10:26.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 1.9188576719953633e-05 Training loss: 4.755727291107178
2025-12-09 12:10:26.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 1.8765257461990442e-05 Training loss: 4.592434883117676
2025-12-09 12:10:26.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 1.834557859039851e-05 Training loss: 4.642806053161621
2025-12-09 12:10:26.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 1.7929589018443016e-05 Training loss: 4.635798931121826
2025-12-09 12:10:26.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 1.7517337229403946e-05 Training loss: 4.597878456115723
2025-12-09 12:10:26.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 1.710887127092548e-05 Training loss: 4.6483259201049805
2025-12-09 12:10:26.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 1.6704238749415957e-05 Training loss: 4.577254295349121
2025-12-09 12:10:26.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 1.6303486824499458e-05 Training loss: 4.620059490203857
2025-12-09 12:10:26.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 1.5906662203519412e-05 Training loss: 4.671082019805908
2025-12-09 12:10:26.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 1.5513811136094787e-05 Training loss: 4.605955600738525
2025-12-09 12:10:26.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 1.5124979408729861e-05 Training loss: 4.6059794425964355
2025-12-09 12:10:26.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 1.4740212339477721e-05 Training loss: 4.576930046081543
2025-12-09 12:10:26.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 1.4359554772658552e-05 Training loss: 4.648825645446777
2025-12-09 12:10:26.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 1.3983051073632997e-05 Training loss: 4.65449333190918
2025-12-09 12:10:26.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 1.3610745123631535e-05 Training loss: 4.529854774475098
2025-12-09 12:10:26.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 1.3242680314639993e-05 Training loss: 4.583434581756592
2025-12-09 12:10:26.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 1.2878899544342327e-05 Training loss: 4.615452289581299
2025-12-09 12:10:26.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 1.2519445211120979e-05 Training loss: 4.6322407722473145
2025-12-09 12:10:26.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 1.2164359209115234e-05 Training loss: 4.610702037811279
2025-12-09 12:10:26.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 1.1813682923338653e-05 Training loss: 4.517981052398682
2025-12-09 12:10:26.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 1.1467457224855544e-05 Training loss: 4.627261161804199
2025-12-09 12:10:26.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 1.1125722466017547e-05 Training loss: 4.587721347808838
2025-12-09 12:10:26.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 1.0788518475760545e-05 Training loss: 4.629973888397217
2025-12-09 12:10:26.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 1.0455884554962725e-05 Training loss: 4.560359954833984
2025-12-09 12:10:26.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 1.012785947186397e-05 Training loss: 4.530886650085449
2025-12-09 12:10:26.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 9.804481457547498e-06 Training loss: 4.648863315582275
2025-12-09 12:10:26.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 9.485788201484126e-06 Training loss: 4.7101030349731445
2025-12-09 12:10:27.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 9.171816847139448e-06 Training loss: 4.626212120056152
2025-12-09 12:10:27.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 8.86260398764494e-06 Training loss: 4.713550090789795
2025-12-09 12:10:27.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 8.558185661532941e-06 Training loss: 4.639843463897705
2025-12-09 12:10:27.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 8.25859734853645e-06 Training loss: 4.659512042999268
2025-12-09 12:10:27.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 7.96387396545396e-06 Training loss: 4.585109710693359
2025-12-09 12:10:27.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 7.67404986207999e-06 Training loss: 4.500757217407227
2025-12-09 12:10:27.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 7.389158817201542e-06 Training loss: 4.655235290527344
2025-12-09 12:10:27.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 7.109234034661289e-06 Training loss: 4.594937324523926
2025-12-09 12:10:27.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 6.8343081394876715e-06 Training loss: 4.579573631286621
2025-12-09 12:10:27.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 6.564413174092443e-06 Training loss: 4.648648262023926
2025-12-09 12:10:27.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 6.299580594536214e-06 Training loss: 4.7948384284973145
2025-12-09 12:10:27.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 6.0398412668621895e-06 Training loss: 4.654236793518066
2025-12-09 12:10:27.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 5.785225463498828e-06 Training loss: 4.674225807189941
2025-12-09 12:10:27.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 5.535762859731547e-06 Training loss: 4.661069393157959
2025-12-09 12:10:27.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 5.291482530244179e-06 Training loss: 4.595643043518066
2025-12-09 12:10:27.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 5.05241294573024e-06 Training loss: 4.613334655761719
2025-12-09 12:10:27.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 4.818581969574742e-06 Training loss: 4.636871814727783
2025-12-09 12:10:27.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 4.590016854606727e-06 Training loss: 4.503238201141357
2025-12-09 12:10:27.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 4.366744239922998e-06 Training loss: 4.564212799072266
2025-12-09 12:10:27.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 4.148790147783288e-06 Training loss: 4.568807601928711
2025-12-09 12:10:27.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 3.936179980577453e-06 Training loss: 4.500736713409424
2025-12-09 12:10:27.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 3.728938517864794e-06 Training loss: 4.598309516906738
2025-12-09 12:10:27.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 3.527089913486037e-06 Training loss: 4.732204437255859
2025-12-09 12:10:27.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 3.3306576927482126e-06 Training loss: 4.569018840789795
2025-12-09 12:10:27.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 3.1396647496828247e-06 Training loss: 4.59356164932251
2025-12-09 12:10:27.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 2.9541333443775243e-06 Training loss: 4.637939453125
2025-12-09 12:10:27.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 2.774085100381735e-06 Training loss: 4.660507678985596
2025-12-09 12:10:27.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 2.5995410021864787e-06 Training loss: 4.59423303604126
2025-12-09 12:10:27.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 2.430521392778573e-06 Training loss: 4.625412940979004
2025-12-09 12:10:27.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 2.2670459712697377e-06 Training loss: 4.6414570808410645
2025-12-09 12:10:27.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 2.1091337906006482e-06 Training loss: 4.566089153289795
2025-12-09 12:10:27.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 1.956803255320322e-06 Training loss: 4.572930812835693
2025-12-09 12:10:27.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 1.810072119441103e-06 Training loss: 4.632882118225098
2025-12-09 12:10:27.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 1.6689574843694433e-06 Training loss: 4.558849334716797
2025-12-09 12:10:27.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 1.53347579691272e-06 Training loss: 4.64373254776001
2025-12-09 12:10:27.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 1.4036428473624019e-06 Training loss: 4.705921649932861
2025-12-09 12:10:27.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 1.2794737676536994e-06 Training loss: 4.617335319519043
2025-12-09 12:10:27.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 1.1609830296019143e-06 Training loss: 4.634812355041504
2025-12-09 12:10:27.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 1.0481844432158161e-06 Training loss: 4.667198181152344
2025-12-09 12:10:27.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.410911550880475e-07 Training loss: 4.675706386566162
2025-12-09 12:10:27.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 8.397156468629208e-07 Training loss: 4.683103084564209
2025-12-09 12:10:27.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 7.44069733781677e-07 Training loss: 4.584011077880859
2025-12-09 12:10:27.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 6.54164563305465e-07 Training loss: 4.677125930786133
2025-12-09 12:10:27.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 5.700106138160688e-07 Training loss: 4.628673553466797
2025-12-09 12:10:27.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 4.916176933946693e-07 Training loss: 4.544559955596924
2025-12-09 12:10:27.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 4.189949386787462e-07 Training loss: 4.642754554748535
2025-12-09 12:10:27.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 3.5215081379718074e-07 Training loss: 4.682863235473633
2025-12-09 12:10:27.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 2.9109310938378877e-07 Training loss: 4.6006388664245605
2025-12-09 12:10:27.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 2.3582894166930268e-07 Training loss: 4.572535514831543
2025-12-09 12:10:27.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 1.8636475165200174e-07 Training loss: 4.512269496917725
2025-12-09 12:10:27.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 1.427063043470178e-07 Training loss: 4.5580267906188965
2025-12-09 12:10:27.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 1.0485868811441757e-07 Training loss: 4.680985927581787
2025-12-09 12:10:27.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 7.282631406615447e-08 Training loss: 4.583568096160889
2025-12-09 12:10:27.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 4.661291555196345e-08 Training loss: 4.613864421844482
2025-12-09 12:10:27.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 2.6221547724253337e-08 Training loss: 4.658463478088379
2025-12-09 12:10:27.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 1.1654587182013953e-08 Training loss: 4.633259296417236
2025-12-09 12:10:27.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 2.9137316938265825e-09 Training loss: 4.598299980163574
2025-12-09 12:10:27.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0 Training loss: 4.527580738067627
