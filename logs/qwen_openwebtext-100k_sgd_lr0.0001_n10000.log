2025-12-09 12:10:11.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 12.022470474243164
2025-12-09 12:10:11.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 12.024420738220215
2025-12-09 12:10:11.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 12.017550468444824
2025-12-09 12:10:11.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 12.058804512023926
2025-12-09 12:10:11.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 12.057635307312012
2025-12-09 12:10:11.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 12.053874015808105
2025-12-09 12:10:11.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 12.048155784606934
2025-12-09 12:10:11.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 12.033495903015137
2025-12-09 12:10:12.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 12.020997047424316
2025-12-09 12:10:12.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 12.054067611694336
2025-12-09 12:10:12.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 12.018692970275879
2025-12-09 12:10:12.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 12.044845581054688
2025-12-09 12:10:12.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 12.035110473632812
2025-12-09 12:10:12.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 12.03701400756836
2025-12-09 12:10:12.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 12.011531829833984
2025-12-09 12:10:12.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 12.032957077026367
2025-12-09 12:10:12.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 12.04356861114502
2025-12-09 12:10:12.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 12.025691986083984
2025-12-09 12:10:12.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 12.00849437713623
2025-12-09 12:10:12.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 12.067388534545898
2025-12-09 12:10:12.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 12.028495788574219
2025-12-09 12:10:13.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 11.984912872314453
2025-12-09 12:10:13.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 12.025358200073242
2025-12-09 12:10:13.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 12.04796028137207
2025-12-09 12:10:13.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 12.053857803344727
2025-12-09 12:10:13.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 12.000388145446777
2025-12-09 12:10:13.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 12.06914234161377
2025-12-09 12:10:13.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 12.055463790893555
2025-12-09 12:10:13.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 12.05499267578125
2025-12-09 12:10:13.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 12.059199333190918
2025-12-09 12:10:13.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 12.013541221618652
2025-12-09 12:10:13.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 12.038371086120605
2025-12-09 12:10:13.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 12.036580085754395
2025-12-09 12:10:13.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 12.032655715942383
2025-12-09 12:10:14.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 11.99233341217041
2025-12-09 12:10:14.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 12.044118881225586
2025-12-09 12:10:14.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 12.049951553344727
2025-12-09 12:10:14.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 12.03101634979248
2025-12-09 12:10:14.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 12.0649995803833
2025-12-09 12:10:14.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 12.047680854797363
2025-12-09 12:10:14.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 12.019879341125488
2025-12-09 12:10:14.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 12.009567260742188
2025-12-09 12:10:14.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 12.005314826965332
2025-12-09 12:10:14.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 12.026283264160156
2025-12-09 12:10:14.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 12.054891586303711
2025-12-09 12:10:14.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 12.057329177856445
2025-12-09 12:10:14.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 12.029622077941895
2025-12-09 12:10:15.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 12.037625312805176
2025-12-09 12:10:15.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 12.031719207763672
2025-12-09 12:10:15.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 12.028987884521484
2025-12-09 12:10:15.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 12.059114456176758
2025-12-09 12:10:15.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 12.007692337036133
2025-12-09 12:10:15.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 11.997940063476562
2025-12-09 12:10:15.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 12.023649215698242
2025-12-09 12:10:15.556 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 12.004486083984375
2025-12-09 12:10:15.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 12.028648376464844
2025-12-09 12:10:15.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 12.015265464782715
2025-12-09 12:10:15.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 12.030165672302246
2025-12-09 12:10:15.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 12.018102645874023
2025-12-09 12:10:15.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 12.011122703552246
2025-12-09 12:10:16.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 12.002437591552734
2025-12-09 12:10:16.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 12.02529525756836
2025-12-09 12:10:16.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 11.991121292114258
2025-12-09 12:10:16.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 12.019968032836914
2025-12-09 12:10:16.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 12.004965782165527
2025-12-09 12:10:16.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 12.00721549987793
2025-12-09 12:10:16.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 11.97265338897705
2025-12-09 12:10:16.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 12.014328002929688
2025-12-09 12:10:16.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 12.0042724609375
2025-12-09 12:10:16.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 11.981664657592773
2025-12-09 12:10:16.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 12.002824783325195
2025-12-09 12:10:16.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 11.997543334960938
2025-12-09 12:10:16.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 12.02537727355957
2025-12-09 12:10:17.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 11.982466697692871
2025-12-09 12:10:17.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 11.978203773498535
2025-12-09 12:10:17.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 11.98340129852295
2025-12-09 12:10:17.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 12.010320663452148
2025-12-09 12:10:17.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 11.984570503234863
2025-12-09 12:10:17.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 11.951943397521973
2025-12-09 12:10:17.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 12.023876190185547
2025-12-09 12:10:17.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 11.956451416015625
2025-12-09 12:10:17.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 12.006675720214844
2025-12-09 12:10:17.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 11.993728637695312
2025-12-09 12:10:17.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 11.977484703063965
2025-12-09 12:10:17.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 11.960177421569824
2025-12-09 12:10:17.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 11.994820594787598
2025-12-09 12:10:17.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 11.989387512207031
2025-12-09 12:10:18.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 11.954575538635254
2025-12-09 12:10:18.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 11.95726490020752
2025-12-09 12:10:18.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 11.953269958496094
2025-12-09 12:10:18.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 11.956336975097656
2025-12-09 12:10:18.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 11.956291198730469
2025-12-09 12:10:18.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 11.99058723449707
2025-12-09 12:10:18.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 11.948129653930664
2025-12-09 12:10:18.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 11.987183570861816
2025-12-09 12:10:18.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 11.969348907470703
2025-12-09 12:10:18.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 11.966141700744629
2025-12-09 12:10:18.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 11.969522476196289
2025-12-09 12:10:18.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 11.935869216918945
2025-12-09 12:10:18.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 11.950881958007812
2025-12-09 12:10:19.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.999999072578703e-05 Training loss: 11.916707992553711
2025-12-09 12:10:19.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 9.999996290315153e-05 Training loss: 11.949678421020508
2025-12-09 12:10:19.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 9.999991653210385e-05 Training loss: 11.917821884155273
2025-12-09 12:10:19.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 9.999985161266117e-05 Training loss: 11.923672676086426
2025-12-09 12:10:19.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 9.999976814484758e-05 Training loss: 11.868951797485352
2025-12-09 12:10:19.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 9.999966612869405e-05 Training loss: 11.942273139953613
2025-12-09 12:10:19.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 9.999954556423843e-05 Training loss: 11.951508522033691
2025-12-09 12:10:19.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 9.999940645152541e-05 Training loss: 11.92813491821289
2025-12-09 12:10:19.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 9.999924879060665e-05 Training loss: 11.938146591186523
2025-12-09 12:10:19.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 9.999907258154059e-05 Training loss: 11.912071228027344
2025-12-09 12:10:19.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 9.999887782439263e-05 Training loss: 11.937402725219727
2025-12-09 12:10:19.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 9.999866451923501e-05 Training loss: 11.917580604553223
2025-12-09 12:10:19.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 9.999843266614685e-05 Training loss: 11.873620986938477
2025-12-09 12:10:20.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 9.999818226521415e-05 Training loss: 11.897353172302246
2025-12-09 12:10:20.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 9.999791331652984e-05 Training loss: 11.931138038635254
2025-12-09 12:10:20.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 9.999762582019365e-05 Training loss: 11.845487594604492
2025-12-09 12:10:20.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 9.999731977631227e-05 Training loss: 11.897744178771973
2025-12-09 12:10:20.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 9.999699518499921e-05 Training loss: 11.9109468460083
2025-12-09 12:10:20.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 9.999665204637487e-05 Training loss: 11.89481258392334
2025-12-09 12:10:20.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 9.999629036056657e-05 Training loss: 11.916727066040039
2025-12-09 12:10:20.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 9.999591012770848e-05 Training loss: 11.891340255737305
2025-12-09 12:10:20.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 9.999551134794164e-05 Training loss: 11.869600296020508
2025-12-09 12:10:20.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 9.999509402141401e-05 Training loss: 11.836764335632324
2025-12-09 12:10:20.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 9.999465814828036e-05 Training loss: 11.849803924560547
2025-12-09 12:10:20.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 9.999420372870242e-05 Training loss: 11.909147262573242
2025-12-09 12:10:21.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 9.999373076284877e-05 Training loss: 11.816278457641602
2025-12-09 12:10:21.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 9.999323925089486e-05 Training loss: 11.858147621154785
2025-12-09 12:10:21.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 9.999272919302301e-05 Training loss: 11.861292839050293
2025-12-09 12:10:21.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 9.999220058942245e-05 Training loss: 11.8413724899292
2025-12-09 12:10:21.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 9.999165344028926e-05 Training loss: 11.814852714538574
2025-12-09 12:10:21.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 9.999108774582645e-05 Training loss: 11.911050796508789
2025-12-09 12:10:21.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 9.999050350624382e-05 Training loss: 11.883712768554688
2025-12-09 12:10:21.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 9.998990072175813e-05 Training loss: 11.875548362731934
2025-12-09 12:10:21.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 9.998927939259303e-05 Training loss: 11.917344093322754
2025-12-09 12:10:21.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 9.998863951897897e-05 Training loss: 11.82629680633545
2025-12-09 12:10:21.819 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 9.998798110115333e-05 Training loss: 11.798593521118164
2025-12-09 12:10:21.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 9.998730413936037e-05 Training loss: 11.862112998962402
2025-12-09 12:10:21.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 9.998660863385123e-05 Training loss: 11.767922401428223
2025-12-09 12:10:22.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 9.99858945848839e-05 Training loss: 11.795578956604004
2025-12-09 12:10:22.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 9.998516199272327e-05 Training loss: 11.809335708618164
2025-12-09 12:10:22.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 9.998441085764113e-05 Training loss: 11.809372901916504
2025-12-09 12:10:22.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 9.998364117991612e-05 Training loss: 11.809435844421387
2025-12-09 12:10:22.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 9.998285295983376e-05 Training loss: 11.760931015014648
2025-12-09 12:10:22.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 9.998204619768646e-05 Training loss: 11.769194602966309
2025-12-09 12:10:22.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 9.998122089377349e-05 Training loss: 11.788714408874512
2025-12-09 12:10:22.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 9.998037704840102e-05 Training loss: 11.807096481323242
2025-12-09 12:10:22.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 9.99795146618821e-05 Training loss: 11.8131685256958
2025-12-09 12:10:22.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 9.997863373453663e-05 Training loss: 11.819453239440918
2025-12-09 12:10:22.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 9.997773426669142e-05 Training loss: 11.72299575805664
2025-12-09 12:10:22.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 9.997681625868013e-05 Training loss: 11.865621566772461
2025-12-09 12:10:22.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 9.997587971084335e-05 Training loss: 11.630027770996094
2025-12-09 12:10:23.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 9.997492462352846e-05 Training loss: 11.762415885925293
2025-12-09 12:10:23.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 9.997395099708982e-05 Training loss: 11.833487510681152
2025-12-09 12:10:23.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 9.997295883188856e-05 Training loss: 11.775360107421875
2025-12-09 12:10:23.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 9.997194812829276e-05 Training loss: 11.645721435546875
2025-12-09 12:10:23.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 9.997091888667738e-05 Training loss: 11.809316635131836
2025-12-09 12:10:23.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 9.996987110742422e-05 Training loss: 11.683401107788086
2025-12-09 12:10:23.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 9.996880479092198e-05 Training loss: 11.738852500915527
2025-12-09 12:10:23.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 9.996771993756621e-05 Training loss: 11.685229301452637
2025-12-09 12:10:23.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 9.996661654775938e-05 Training loss: 11.78377628326416
2025-12-09 12:10:23.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 9.996549462191082e-05 Training loss: 11.644624710083008
2025-12-09 12:10:23.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 9.99643541604367e-05 Training loss: 11.806143760681152
2025-12-09 12:10:23.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 9.99631951637601e-05 Training loss: 11.667323112487793
2025-12-09 12:10:23.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 9.996201763231099e-05 Training loss: 11.750166893005371
2025-12-09 12:10:24.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 9.996082156652618e-05 Training loss: 11.704590797424316
2025-12-09 12:10:24.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 9.995960696684939e-05 Training loss: 11.638922691345215
2025-12-09 12:10:24.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 9.995837383373119e-05 Training loss: 11.656618118286133
2025-12-09 12:10:24.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 9.995712216762902e-05 Training loss: 11.650559425354004
2025-12-09 12:10:24.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 9.995585196900723e-05 Training loss: 11.727387428283691
2025-12-09 12:10:24.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 9.9954563238337e-05 Training loss: 11.66995620727539
2025-12-09 12:10:24.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 9.995325597609645e-05 Training loss: 11.653281211853027
2025-12-09 12:10:24.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 9.99519301827705e-05 Training loss: 11.669978141784668
2025-12-09 12:10:24.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 9.995058585885095e-05 Training loss: 11.735312461853027
2025-12-09 12:10:24.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 9.994922300483656e-05 Training loss: 11.662168502807617
2025-12-09 12:10:24.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 9.99478416212329e-05 Training loss: 11.683852195739746
2025-12-09 12:10:24.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 9.994644170855237e-05 Training loss: 11.573963165283203
2025-12-09 12:10:24.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 9.994502326731434e-05 Training loss: 11.580606460571289
2025-12-09 12:10:25.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 9.994358629804499e-05 Training loss: 11.54646110534668
2025-12-09 12:10:25.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 9.994213080127739e-05 Training loss: 11.555031776428223
2025-12-09 12:10:25.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 9.994065677755147e-05 Training loss: 11.613447189331055
2025-12-09 12:10:25.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 9.993916422741409e-05 Training loss: 11.556954383850098
2025-12-09 12:10:25.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 9.99376531514189e-05 Training loss: 11.637733459472656
2025-12-09 12:10:25.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 9.993612355012647e-05 Training loss: 11.526470184326172
2025-12-09 12:10:25.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 9.993457542410424e-05 Training loss: 11.518278121948242
2025-12-09 12:10:25.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 9.993300877392651e-05 Training loss: 11.643256187438965
2025-12-09 12:10:25.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 9.993142360017446e-05 Training loss: 11.698448181152344
2025-12-09 12:10:25.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 9.992981990343614e-05 Training loss: 11.610673904418945
2025-12-09 12:10:25.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 9.992819768430647e-05 Training loss: 11.63674259185791
2025-12-09 12:10:25.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 9.992655694338725e-05 Training loss: 11.565428733825684
2025-12-09 12:10:25.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 9.992489768128713e-05 Training loss: 11.612225532531738
2025-12-09 12:10:26.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 9.992321989862166e-05 Training loss: 11.53821086883545
2025-12-09 12:10:26.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 9.992152359601322e-05 Training loss: 11.550450325012207
2025-12-09 12:10:26.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 9.99198087740911e-05 Training loss: 11.58596134185791
2025-12-09 12:10:26.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 9.991807543349146e-05 Training loss: 11.541131973266602
2025-12-09 12:10:26.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 9.99163235748573e-05 Training loss: 11.513006210327148
2025-12-09 12:10:26.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 9.99145531988385e-05 Training loss: 11.383098602294922
2025-12-09 12:10:26.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 9.99127643060918e-05 Training loss: 11.37060832977295
2025-12-09 12:10:26.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 9.991095689728087e-05 Training loss: 11.34981632232666
2025-12-09 12:10:26.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 9.990913097307614e-05 Training loss: 11.513809204101562
2025-12-09 12:10:26.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 9.990728653415504e-05 Training loss: 11.553871154785156
2025-12-09 12:10:26.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 9.990542358120174e-05 Training loss: 11.520008087158203
2025-12-09 12:10:26.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 9.990354211490735e-05 Training loss: 11.503327369689941
2025-12-09 12:10:26.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 9.990164213596986e-05 Training loss: 11.470121383666992
2025-12-09 12:10:27.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 9.989972364509408e-05 Training loss: 11.372611045837402
2025-12-09 12:10:27.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 9.989778664299172e-05 Training loss: 11.560148239135742
2025-12-09 12:10:27.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 9.989583113038135e-05 Training loss: 11.484755516052246
2025-12-09 12:10:27.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 9.989385710798837e-05 Training loss: 11.529316902160645
2025-12-09 12:10:27.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 9.989186457654513e-05 Training loss: 11.375419616699219
2025-12-09 12:10:27.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 9.988985353679077e-05 Training loss: 11.513303756713867
2025-12-09 12:10:27.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 9.988782398947131e-05 Training loss: 11.4281587600708
2025-12-09 12:10:27.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 9.988577593533967e-05 Training loss: 11.331336975097656
2025-12-09 12:10:27.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 9.988370937515561e-05 Training loss: 11.374975204467773
2025-12-09 12:10:27.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 9.988162430968575e-05 Training loss: 11.358022689819336
2025-12-09 12:10:27.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 9.987952073970359e-05 Training loss: 11.421931266784668
2025-12-09 12:10:27.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 9.98773986659895e-05 Training loss: 11.411975860595703
2025-12-09 12:10:27.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 9.987525808933068e-05 Training loss: 11.356632232666016
2025-12-09 12:10:28.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 9.987309901052121e-05 Training loss: 11.405474662780762
2025-12-09 12:10:28.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 9.98709214303621e-05 Training loss: 11.396510124206543
2025-12-09 12:10:28.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 9.986872534966109e-05 Training loss: 11.364960670471191
2025-12-09 12:10:28.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 9.986651076923288e-05 Training loss: 11.525280952453613
2025-12-09 12:10:28.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 9.986427768989903e-05 Training loss: 11.398951530456543
2025-12-09 12:10:28.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 9.986202611248793e-05 Training loss: 11.401939392089844
2025-12-09 12:10:28.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 9.985975603783484e-05 Training loss: 11.478934288024902
2025-12-09 12:10:28.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 9.98574674667819e-05 Training loss: 11.30064582824707
2025-12-09 12:10:28.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 9.985516040017807e-05 Training loss: 11.176070213317871
2025-12-09 12:10:28.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 9.985283483887923e-05 Training loss: 11.374584197998047
2025-12-09 12:10:28.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 9.985049078374806e-05 Training loss: 11.536046028137207
2025-12-09 12:10:28.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 9.984812823565417e-05 Training loss: 11.363007545471191
2025-12-09 12:10:28.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 9.984574719547395e-05 Training loss: 11.402167320251465
2025-12-09 12:10:29.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 9.984334766409071e-05 Training loss: 11.395577430725098
2025-12-09 12:10:29.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 9.98409296423946e-05 Training loss: 11.289190292358398
2025-12-09 12:10:29.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 9.983849313128264e-05 Training loss: 11.300948143005371
2025-12-09 12:10:29.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 9.983603813165869e-05 Training loss: 11.367548942565918
2025-12-09 12:10:29.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 9.983356464443347e-05 Training loss: 11.242788314819336
2025-12-09 12:10:29.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 9.983107267052457e-05 Training loss: 11.332818031311035
2025-12-09 12:10:29.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 9.982856221085644e-05 Training loss: 11.232608795166016
2025-12-09 12:10:29.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 9.982603326636037e-05 Training loss: 11.265122413635254
2025-12-09 12:10:29.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 9.982348583797454e-05 Training loss: 11.147777557373047
2025-12-09 12:10:29.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 9.982091992664392e-05 Training loss: 11.142679214477539
2025-12-09 12:10:29.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 9.981833553332045e-05 Training loss: 11.270607948303223
2025-12-09 12:10:29.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 9.981573265896281e-05 Training loss: 11.440084457397461
2025-12-09 12:10:29.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 9.981311130453659e-05 Training loss: 11.252274513244629
2025-12-09 12:10:30.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 9.981047147101426e-05 Training loss: 11.31112289428711
2025-12-09 12:10:30.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 9.980781315937507e-05 Training loss: 11.29645824432373
2025-12-09 12:10:30.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 9.98051363706052e-05 Training loss: 11.19350814819336
2025-12-09 12:10:30.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 9.980244110569765e-05 Training loss: 11.262394905090332
2025-12-09 12:10:30.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 9.979972736565226e-05 Training loss: 11.09550666809082
2025-12-09 12:10:30.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 9.979699515147578e-05 Training loss: 11.291608810424805
2025-12-09 12:10:30.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 9.979424446418173e-05 Training loss: 11.351851463317871
2025-12-09 12:10:30.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 9.979147530479056e-05 Training loss: 11.198613166809082
2025-12-09 12:10:30.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 9.978868767432954e-05 Training loss: 11.310866355895996
2025-12-09 12:10:30.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 9.978588157383277e-05 Training loss: 11.209403991699219
2025-12-09 12:10:30.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 9.978305700434125e-05 Training loss: 11.162301063537598
2025-12-09 12:10:30.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 9.97802139669028e-05 Training loss: 11.298272132873535
2025-12-09 12:10:30.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 9.97773524625721e-05 Training loss: 11.239218711853027
2025-12-09 12:10:30.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 9.977447249241066e-05 Training loss: 11.12024974822998
2025-12-09 12:10:31.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 9.977157405748687e-05 Training loss: 11.242238998413086
2025-12-09 12:10:31.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 9.976865715887595e-05 Training loss: 11.279422760009766
2025-12-09 12:10:31.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 9.976572179765999e-05 Training loss: 11.119996070861816
2025-12-09 12:10:31.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 9.976276797492793e-05 Training loss: 11.138323783874512
2025-12-09 12:10:31.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 9.975979569177552e-05 Training loss: 11.103217124938965
2025-12-09 12:10:31.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 9.975680494930538e-05 Training loss: 11.212929725646973
2025-12-09 12:10:31.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 9.9753795748627e-05 Training loss: 11.1092529296875
2025-12-09 12:10:31.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 9.975076809085669e-05 Training loss: 11.355557441711426
2025-12-09 12:10:31.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 9.974772197711761e-05 Training loss: 11.144861221313477
2025-12-09 12:10:31.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 9.97446574085398e-05 Training loss: 11.359477043151855
2025-12-09 12:10:31.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 9.974157438626008e-05 Training loss: 11.17542839050293
2025-12-09 12:10:31.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 9.973847291142218e-05 Training loss: 11.12736701965332
2025-12-09 12:10:31.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 9.973535298517663e-05 Training loss: 11.142688751220703
2025-12-09 12:10:32.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 9.973221460868086e-05 Training loss: 11.140735626220703
2025-12-09 12:10:32.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 9.972905778309906e-05 Training loss: 11.089943885803223
2025-12-09 12:10:32.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 9.972588250960234e-05 Training loss: 11.083270072937012
2025-12-09 12:10:32.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 9.972268878936863e-05 Training loss: 11.05602741241455
2025-12-09 12:10:32.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 9.97194766235827e-05 Training loss: 11.120074272155762
2025-12-09 12:10:32.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 9.971624601343615e-05 Training loss: 11.088461875915527
2025-12-09 12:10:32.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 9.971299696012743e-05 Training loss: 11.071653366088867
2025-12-09 12:10:32.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 9.970972946486185e-05 Training loss: 11.272936820983887
2025-12-09 12:10:32.677 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 9.970644352885157e-05 Training loss: 11.068013191223145
2025-12-09 12:10:32.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 9.970313915331553e-05 Training loss: 11.186118125915527
2025-12-09 12:10:32.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 9.969981633947956e-05 Training loss: 11.127511978149414
2025-12-09 12:10:32.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 9.969647508857631e-05 Training loss: 11.053886413574219
2025-12-09 12:10:32.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 9.969311540184532e-05 Training loss: 11.14184856414795
2025-12-09 12:10:33.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 9.968973728053288e-05 Training loss: 11.02656364440918
2025-12-09 12:10:33.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 9.968634072589218e-05 Training loss: 11.19555950164795
2025-12-09 12:10:33.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 9.968292573918325e-05 Training loss: 11.000077247619629
2025-12-09 12:10:33.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 9.967949232167294e-05 Training loss: 11.187084197998047
2025-12-09 12:10:33.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 9.967604047463493e-05 Training loss: 11.028182029724121
2025-12-09 12:10:33.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 9.967257019934975e-05 Training loss: 11.003657341003418
2025-12-09 12:10:33.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 9.966908149710476e-05 Training loss: 11.09396743774414
2025-12-09 12:10:33.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 9.966557436919416e-05 Training loss: 11.137202262878418
2025-12-09 12:10:33.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 9.966204881691898e-05 Training loss: 11.113310813903809
2025-12-09 12:10:33.748 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 9.965850484158711e-05 Training loss: 11.060324668884277
2025-12-09 12:10:33.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 9.965494244451324e-05 Training loss: 11.218955039978027
2025-12-09 12:10:33.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 9.96513616270189e-05 Training loss: 11.107355117797852
2025-12-09 12:10:33.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 9.964776239043246e-05 Training loss: 11.036310195922852
2025-12-09 12:10:34.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 9.964414473608912e-05 Training loss: 10.919681549072266
2025-12-09 12:10:34.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 9.964050866533094e-05 Training loss: 11.16622257232666
2025-12-09 12:10:34.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 9.963685417950677e-05 Training loss: 11.062568664550781
2025-12-09 12:10:34.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 9.96331812799723e-05 Training loss: 11.043081283569336
2025-12-09 12:10:34.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 9.962948996809008e-05 Training loss: 11.103498458862305
2025-12-09 12:10:34.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 9.962578024522948e-05 Training loss: 11.008072853088379
2025-12-09 12:10:34.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 9.962205211276665e-05 Training loss: 10.938817977905273
2025-12-09 12:10:34.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 9.961830557208464e-05 Training loss: 11.037747383117676
2025-12-09 12:10:34.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 9.961454062457329e-05 Training loss: 11.133991241455078
2025-12-09 12:10:34.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 9.961075727162928e-05 Training loss: 11.068883895874023
2025-12-09 12:10:34.819 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 9.960695551465611e-05 Training loss: 11.027877807617188
2025-12-09 12:10:34.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 9.960313535506411e-05 Training loss: 11.040704727172852
2025-12-09 12:10:34.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 9.959929679427047e-05 Training loss: 11.077591896057129
2025-12-09 12:10:35.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 9.959543983369912e-05 Training loss: 11.123663902282715
2025-12-09 12:10:35.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 9.959156447478091e-05 Training loss: 10.962389945983887
2025-12-09 12:10:35.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 9.958767071895347e-05 Training loss: 11.102049827575684
2025-12-09 12:10:35.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 9.958375856766127e-05 Training loss: 10.918949127197266
2025-12-09 12:10:35.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 9.957982802235556e-05 Training loss: 11.038817405700684
2025-12-09 12:10:35.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 9.957587908449448e-05 Training loss: 11.06484317779541
2025-12-09 12:10:35.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 9.957191175554294e-05 Training loss: 10.935270309448242
2025-12-09 12:10:35.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 9.956792603697273e-05 Training loss: 11.035805702209473
2025-12-09 12:10:35.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 9.956392193026239e-05 Training loss: 11.13508415222168
2025-12-09 12:10:35.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 9.955989943689734e-05 Training loss: 11.0183687210083
2025-12-09 12:10:35.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 9.955585855836978e-05 Training loss: 10.826730728149414
2025-12-09 12:10:35.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 9.955179929617875e-05 Training loss: 11.103569030761719
2025-12-09 12:10:35.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 9.954772165183013e-05 Training loss: 10.9910306930542
2025-12-09 12:10:36.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 9.954362562683658e-05 Training loss: 11.020405769348145
2025-12-09 12:10:36.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 9.95395112227176e-05 Training loss: 10.855096817016602
2025-12-09 12:10:36.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 9.95353784409995e-05 Training loss: 11.044817924499512
2025-12-09 12:10:36.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 9.953122728321542e-05 Training loss: 10.938458442687988
2025-12-09 12:10:36.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 9.952705775090529e-05 Training loss: 10.86618709564209
2025-12-09 12:10:36.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 9.952286984561592e-05 Training loss: 10.939502716064453
2025-12-09 12:10:36.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 9.951866356890084e-05 Training loss: 10.878260612487793
2025-12-09 12:10:36.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 9.951443892232047e-05 Training loss: 10.922262191772461
2025-12-09 12:10:36.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 9.951019590744203e-05 Training loss: 10.888561248779297
2025-12-09 12:10:36.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 9.950593452583952e-05 Training loss: 11.01523208618164
2025-12-09 12:10:36.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 9.95016547790938e-05 Training loss: 11.042248725891113
2025-12-09 12:10:36.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 9.949735666879252e-05 Training loss: 10.894701957702637
2025-12-09 12:10:36.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 9.949304019653012e-05 Training loss: 10.906238555908203
2025-12-09 12:10:37.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 9.94887053639079e-05 Training loss: 10.980313301086426
2025-12-09 12:10:37.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 9.948435217253393e-05 Training loss: 10.879924774169922
2025-12-09 12:10:37.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 9.947998062402313e-05 Training loss: 11.076577186584473
2025-12-09 12:10:37.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 9.947559071999719e-05 Training loss: 10.982869148254395
2025-12-09 12:10:37.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 9.947118246208462e-05 Training loss: 11.00661849975586
2025-12-09 12:10:37.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 9.946675585192075e-05 Training loss: 10.968931198120117
2025-12-09 12:10:37.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 9.946231089114774e-05 Training loss: 10.925580978393555
2025-12-09 12:10:37.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 9.945784758141448e-05 Training loss: 10.834830284118652
2025-12-09 12:10:37.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 9.945336592437678e-05 Training loss: 11.07140827178955
2025-12-09 12:10:37.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 9.944886592169713e-05 Training loss: 10.754196166992188
2025-12-09 12:10:37.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 9.944434757504492e-05 Training loss: 10.803857803344727
2025-12-09 12:10:37.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 9.94398108860963e-05 Training loss: 10.809263229370117
2025-12-09 12:10:37.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 9.943525585653428e-05 Training loss: 10.87425708770752
2025-12-09 12:10:38.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 9.94306824880486e-05 Training loss: 10.966246604919434
2025-12-09 12:10:38.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 9.942609078233581e-05 Training loss: 10.893988609313965
2025-12-09 12:10:38.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 9.942148074109934e-05 Training loss: 10.939480781555176
2025-12-09 12:10:38.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 9.941685236604934e-05 Training loss: 10.833643913269043
2025-12-09 12:10:38.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 9.941220565890279e-05 Training loss: 10.915162086486816
2025-12-09 12:10:38.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 9.94075406213835e-05 Training loss: 10.820796966552734
2025-12-09 12:10:38.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 9.940285725522203e-05 Training loss: 10.900782585144043
2025-12-09 12:10:38.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 9.939815556215575e-05 Training loss: 11.002467155456543
2025-12-09 12:10:38.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 9.939343554392886e-05 Training loss: 11.014647483825684
2025-12-09 12:10:38.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 9.938869720229234e-05 Training loss: 10.901679039001465
2025-12-09 12:10:38.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 9.938394053900395e-05 Training loss: 10.788182258605957
2025-12-09 12:10:38.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 9.937916555582828e-05 Training loss: 10.761419296264648
2025-12-09 12:10:38.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 9.937437225453669e-05 Training loss: 10.846794128417969
2025-12-09 12:10:39.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 9.936956063690733e-05 Training loss: 10.890034675598145
2025-12-09 12:10:39.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 9.936473070472518e-05 Training loss: 10.812575340270996
2025-12-09 12:10:39.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 9.935988245978199e-05 Training loss: 10.912626266479492
2025-12-09 12:10:39.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 9.935501590387628e-05 Training loss: 10.756498336791992
2025-12-09 12:10:39.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 9.935013103881343e-05 Training loss: 10.963181495666504
2025-12-09 12:10:39.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 9.934522786640555e-05 Training loss: 10.865066528320312
2025-12-09 12:10:39.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 9.934030638847155e-05 Training loss: 10.946229934692383
2025-12-09 12:10:39.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 9.933536660683717e-05 Training loss: 10.824027061462402
2025-12-09 12:10:39.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 9.933040852333488e-05 Training loss: 10.953389167785645
2025-12-09 12:10:39.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 9.9325432139804e-05 Training loss: 10.78428840637207
2025-12-09 12:10:39.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 9.932043745809063e-05 Training loss: 10.737635612487793
2025-12-09 12:10:39.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 9.93154244800476e-05 Training loss: 10.807642936706543
2025-12-09 12:10:39.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.931039320753456e-05 Training loss: 10.91079330444336
2025-12-09 12:10:40.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 9.9305343642418e-05 Training loss: 10.717241287231445
2025-12-09 12:10:40.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 9.930027578657113e-05 Training loss: 10.779099464416504
2025-12-09 12:10:40.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 9.929518964187395e-05 Training loss: 10.97531509399414
2025-12-09 12:10:40.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 9.929008521021325e-05 Training loss: 11.152636528015137
2025-12-09 12:10:40.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 9.928496249348265e-05 Training loss: 10.845479011535645
2025-12-09 12:10:40.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 9.92798214935825e-05 Training loss: 10.836627960205078
2025-12-09 12:10:40.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 9.927466221241996e-05 Training loss: 10.867136001586914
2025-12-09 12:10:40.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 9.926948465190892e-05 Training loss: 10.928436279296875
2025-12-09 12:10:40.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 9.926428881397015e-05 Training loss: 10.671375274658203
2025-12-09 12:10:40.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 9.925907470053111e-05 Training loss: 10.7754545211792
2025-12-09 12:10:40.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 9.925384231352606e-05 Training loss: 10.863398551940918
2025-12-09 12:10:40.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 9.924859165489608e-05 Training loss: 11.032941818237305
2025-12-09 12:10:40.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 9.924332272658898e-05 Training loss: 10.61700439453125
2025-12-09 12:10:41.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 9.923803553055937e-05 Training loss: 10.718684196472168
2025-12-09 12:10:41.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 9.923273006876865e-05 Training loss: 10.716558456420898
2025-12-09 12:10:41.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 9.922740634318495e-05 Training loss: 10.969812393188477
2025-12-09 12:10:41.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 9.922206435578323e-05 Training loss: 10.675753593444824
2025-12-09 12:10:41.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 9.921670410854518e-05 Training loss: 10.86523151397705
2025-12-09 12:10:41.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 9.92113256034593e-05 Training loss: 11.008240699768066
2025-12-09 12:10:41.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 9.920592884252082e-05 Training loss: 10.746679306030273
2025-12-09 12:10:41.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 9.920051382773179e-05 Training loss: 10.746978759765625
2025-12-09 12:10:41.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 9.919508056110102e-05 Training loss: 10.644325256347656
2025-12-09 12:10:41.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 9.918962904464407e-05 Training loss: 10.681894302368164
2025-12-09 12:10:41.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 9.918415928038325e-05 Training loss: 10.938432693481445
2025-12-09 12:10:41.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 9.917867127034772e-05 Training loss: 10.961153984069824
2025-12-09 12:10:41.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 9.917316501657334e-05 Training loss: 10.712449073791504
2025-12-09 12:10:42.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 9.916764052110274e-05 Training loss: 10.612203598022461
2025-12-09 12:10:42.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 9.916209778598535e-05 Training loss: 10.59600830078125
2025-12-09 12:10:42.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 9.915653681327737e-05 Training loss: 10.72482681274414
2025-12-09 12:10:42.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 9.915095760504169e-05 Training loss: 10.931723594665527
2025-12-09 12:10:42.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 9.914536016334808e-05 Training loss: 10.877005577087402
2025-12-09 12:10:42.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 9.913974449027298e-05 Training loss: 10.7151517868042
2025-12-09 12:10:42.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 9.913411058789963e-05 Training loss: 10.839138984680176
2025-12-09 12:10:42.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 9.912845845831805e-05 Training loss: 10.686741828918457
2025-12-09 12:10:42.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 9.912278810362498e-05 Training loss: 11.037922859191895
2025-12-09 12:10:42.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 9.911709952592397e-05 Training loss: 10.69286060333252
2025-12-09 12:10:42.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 9.911139272732526e-05 Training loss: 10.716821670532227
2025-12-09 12:10:42.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 9.910566770994594e-05 Training loss: 10.701249122619629
2025-12-09 12:10:42.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 9.909992447590979e-05 Training loss: 10.8328857421875
2025-12-09 12:10:43.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 9.909416302734736e-05 Training loss: 10.854757308959961
2025-12-09 12:10:43.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 9.908838336639597e-05 Training loss: 10.731467247009277
2025-12-09 12:10:43.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 9.908258549519971e-05 Training loss: 10.690872192382812
2025-12-09 12:10:43.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 9.907676941590939e-05 Training loss: 10.647581100463867
2025-12-09 12:10:43.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 9.907093513068259e-05 Training loss: 10.698710441589355
2025-12-09 12:10:43.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 9.906508264168366e-05 Training loss: 11.018040657043457
2025-12-09 12:10:43.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 9.905921195108368e-05 Training loss: 10.607071876525879
2025-12-09 12:10:43.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 9.90533230610605e-05 Training loss: 10.77277660369873
2025-12-09 12:10:43.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 9.90474159737987e-05 Training loss: 10.643946647644043
2025-12-09 12:10:43.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 9.904149069148963e-05 Training loss: 10.592546463012695
2025-12-09 12:10:43.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 9.903554721633139e-05 Training loss: 10.698202133178711
2025-12-09 12:10:43.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 9.902958555052882e-05 Training loss: 10.641928672790527
2025-12-09 12:10:43.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 9.902360569629349e-05 Training loss: 10.731019973754883
2025-12-09 12:10:44.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 9.901760765584375e-05 Training loss: 10.634678840637207
2025-12-09 12:10:44.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 9.901159143140471e-05 Training loss: 10.79497241973877
2025-12-09 12:10:44.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 9.900555702520816e-05 Training loss: 10.892112731933594
2025-12-09 12:10:44.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 9.89995044394927e-05 Training loss: 10.769485473632812
2025-12-09 12:10:44.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 9.899343367650365e-05 Training loss: 10.720817565917969
2025-12-09 12:10:44.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 9.898734473849305e-05 Training loss: 10.93765640258789
2025-12-09 12:10:44.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 9.898123762771971e-05 Training loss: 10.533571243286133
2025-12-09 12:10:44.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 9.89751123464492e-05 Training loss: 10.885892868041992
2025-12-09 12:10:44.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 9.896896889695378e-05 Training loss: 11.071900367736816
2025-12-09 12:10:44.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 9.896280728151248e-05 Training loss: 10.765266418457031
2025-12-09 12:10:44.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 9.895662750241108e-05 Training loss: 10.652480125427246
2025-12-09 12:10:44.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 9.89504295619421e-05 Training loss: 10.898207664489746
2025-12-09 12:10:44.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 9.894421346240473e-05 Training loss: 10.876635551452637
2025-12-09 12:10:45.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 9.893797920610496e-05 Training loss: 10.668200492858887
2025-12-09 12:10:45.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 9.893172679535553e-05 Training loss: 10.70363712310791
2025-12-09 12:10:45.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 9.892545623247586e-05 Training loss: 10.599995613098145
2025-12-09 12:10:45.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 9.891916751979218e-05 Training loss: 10.660184860229492
2025-12-09 12:10:45.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 9.891286065963734e-05 Training loss: 10.841784477233887
2025-12-09 12:10:45.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 9.890653565435101e-05 Training loss: 10.982141494750977
2025-12-09 12:10:45.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 9.89001925062796e-05 Training loss: 10.643482208251953
2025-12-09 12:10:45.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 9.889383121777617e-05 Training loss: 10.513687133789062
2025-12-09 12:10:45.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 9.88874517912006e-05 Training loss: 10.7587308883667
2025-12-09 12:10:45.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 9.888105422891943e-05 Training loss: 10.633163452148438
2025-12-09 12:10:45.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 9.887463853330594e-05 Training loss: 10.62476921081543
2025-12-09 12:10:45.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 9.886820470674018e-05 Training loss: 10.685291290283203
2025-12-09 12:10:45.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 9.88617527516089e-05 Training loss: 10.79131031036377
2025-12-09 12:10:46.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 9.885528267030557e-05 Training loss: 10.67408561706543
2025-12-09 12:10:46.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 9.884879446523035e-05 Training loss: 10.67605209350586
2025-12-09 12:10:46.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 9.88422881387902e-05 Training loss: 10.662304878234863
2025-12-09 12:10:46.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 9.883576369339875e-05 Training loss: 10.596434593200684
2025-12-09 12:10:46.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 9.882922113147637e-05 Training loss: 10.654742240905762
2025-12-09 12:10:46.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 9.882266045545012e-05 Training loss: 10.681097030639648
2025-12-09 12:10:46.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 9.881608166775383e-05 Training loss: 10.647310256958008
2025-12-09 12:10:46.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 9.880948477082804e-05 Training loss: 10.513432502746582
2025-12-09 12:10:46.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 9.880286976711992e-05 Training loss: 10.685638427734375
2025-12-09 12:10:46.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 9.87962366590835e-05 Training loss: 10.81798267364502
2025-12-09 12:10:46.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 9.878958544917942e-05 Training loss: 10.629335403442383
2025-12-09 12:10:46.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 9.87829161398751e-05 Training loss: 10.516854286193848
2025-12-09 12:10:46.927 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 9.87762287336446e-05 Training loss: 10.565435409545898
2025-12-09 12:10:47.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 9.876952323296877e-05 Training loss: 10.64048957824707
2025-12-09 12:10:47.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 9.876279964033512e-05 Training loss: 10.359559059143066
2025-12-09 12:10:47.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 9.87560579582379e-05 Training loss: 10.970967292785645
2025-12-09 12:10:47.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 9.874929818917806e-05 Training loss: 10.682259559631348
2025-12-09 12:10:47.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 9.874252033566327e-05 Training loss: 10.762001991271973
2025-12-09 12:10:47.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 9.87357244002079e-05 Training loss: 10.919625282287598
2025-12-09 12:10:47.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 9.8728910385333e-05 Training loss: 10.701066017150879
2025-12-09 12:10:47.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 9.872207829356641e-05 Training loss: 10.54670524597168
2025-12-09 12:10:47.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 9.871522812744256e-05 Training loss: 10.787574768066406
2025-12-09 12:10:47.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 9.870835988950268e-05 Training loss: 10.48807430267334
2025-12-09 12:10:47.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 9.870147358229467e-05 Training loss: 10.586912155151367
2025-12-09 12:10:47.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 9.869456920837312e-05 Training loss: 10.422399520874023
2025-12-09 12:10:47.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 9.868764677029934e-05 Training loss: 10.604862213134766
2025-12-09 12:10:48.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 9.868070627064135e-05 Training loss: 10.536519050598145
2025-12-09 12:10:48.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 9.867374771197383e-05 Training loss: 10.462255477905273
2025-12-09 12:10:48.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 9.866677109687822e-05 Training loss: 10.673965454101562
2025-12-09 12:10:48.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 9.86597764279426e-05 Training loss: 10.586030960083008
2025-12-09 12:10:48.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 9.865276370776177e-05 Training loss: 10.40990924835205
2025-12-09 12:10:48.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 9.864573293893725e-05 Training loss: 10.605765342712402
2025-12-09 12:10:48.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 9.863868412407721e-05 Training loss: 10.533113479614258
2025-12-09 12:10:48.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 9.863161726579655e-05 Training loss: 10.399259567260742
2025-12-09 12:10:48.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 9.862453236671685e-05 Training loss: 10.410653114318848
2025-12-09 12:10:48.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 9.861742942946639e-05 Training loss: 10.448796272277832
2025-12-09 12:10:48.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 9.861030845668014e-05 Training loss: 10.565292358398438
2025-12-09 12:10:48.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 9.860316945099973e-05 Training loss: 10.519129753112793
2025-12-09 12:10:48.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 9.859601241507353e-05 Training loss: 10.933095932006836
2025-12-09 12:10:48.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 9.858883735155657e-05 Training loss: 10.519013404846191
2025-12-09 12:10:49.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 9.858164426311059e-05 Training loss: 10.72181510925293
2025-12-09 12:10:49.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 9.857443315240397e-05 Training loss: 10.547866821289062
2025-12-09 12:10:49.224 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 9.856720402211182e-05 Training loss: 10.759135246276855
2025-12-09 12:10:49.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 9.855995687491591e-05 Training loss: 10.529008865356445
2025-12-09 12:10:49.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 9.855269171350471e-05 Training loss: 10.704930305480957
2025-12-09 12:10:49.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 9.854540854057337e-05 Training loss: 10.540860176086426
2025-12-09 12:10:49.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 9.85381073588237e-05 Training loss: 10.706048011779785
2025-12-09 12:10:49.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 9.853078817096424e-05 Training loss: 10.448266983032227
2025-12-09 12:10:49.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 9.852345097971016e-05 Training loss: 10.446516990661621
2025-12-09 12:10:49.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 9.851609578778332e-05 Training loss: 10.51284122467041
2025-12-09 12:10:49.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 9.850872259791228e-05 Training loss: 10.493452072143555
2025-12-09 12:10:49.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 9.850133141283226e-05 Training loss: 10.335041046142578
2025-12-09 12:10:49.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 9.849392223528514e-05 Training loss: 10.580329895019531
2025-12-09 12:10:50.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 9.84864950680195e-05 Training loss: 10.392882347106934
2025-12-09 12:10:50.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 9.84790499137906e-05 Training loss: 10.6460599899292
2025-12-09 12:10:50.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 9.847158677536034e-05 Training loss: 10.397265434265137
2025-12-09 12:10:50.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 9.84641056554973e-05 Training loss: 10.625651359558105
2025-12-09 12:10:50.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 9.845660655697679e-05 Training loss: 10.504347801208496
2025-12-09 12:10:50.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 9.844908948258067e-05 Training loss: 10.620368003845215
2025-12-09 12:10:50.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 9.844155443509759e-05 Training loss: 10.607305526733398
2025-12-09 12:10:50.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 9.84340014173228e-05 Training loss: 10.641826629638672
2025-12-09 12:10:50.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 9.842643043205822e-05 Training loss: 10.473735809326172
2025-12-09 12:10:50.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 9.841884148211247e-05 Training loss: 10.53507137298584
2025-12-09 12:10:50.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 9.84112345703008e-05 Training loss: 10.493447303771973
2025-12-09 12:10:50.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 9.84036096994451e-05 Training loss: 10.571264266967773
2025-12-09 12:10:50.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 9.839596687237403e-05 Training loss: 10.416379928588867
2025-12-09 12:10:51.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 9.838830609192277e-05 Training loss: 10.618063926696777
2025-12-09 12:10:51.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 9.838062736093328e-05 Training loss: 10.518926620483398
2025-12-09 12:10:51.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 9.837293068225408e-05 Training loss: 10.531153678894043
2025-12-09 12:10:51.295 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 9.836521605874044e-05 Training loss: 10.541139602661133
2025-12-09 12:10:51.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 9.835748349325422e-05 Training loss: 10.187667846679688
2025-12-09 12:10:51.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 9.834973298866395e-05 Training loss: 10.324583053588867
2025-12-09 12:10:51.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 9.834196454784485e-05 Training loss: 10.45665454864502
2025-12-09 12:10:51.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 9.833417817367874e-05 Training loss: 10.592376708984375
2025-12-09 12:10:51.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 9.832637386905412e-05 Training loss: 10.58388614654541
2025-12-09 12:10:51.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 9.831855163686618e-05 Training loss: 10.64742374420166
2025-12-09 12:10:51.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 9.831071148001667e-05 Training loss: 10.61267375946045
2025-12-09 12:10:51.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 9.830285340141408e-05 Training loss: 10.54119873046875
2025-12-09 12:10:51.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 9.829497740397349e-05 Training loss: 10.654678344726562
2025-12-09 12:10:52.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 9.828708349061664e-05 Training loss: 10.445222854614258
2025-12-09 12:10:52.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 9.827917166427195e-05 Training loss: 10.732365608215332
2025-12-09 12:10:52.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 9.827124192787444e-05 Training loss: 10.461564064025879
2025-12-09 12:10:52.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 9.82632942843658e-05 Training loss: 10.409892082214355
2025-12-09 12:10:52.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 9.825532873669435e-05 Training loss: 10.455578804016113
2025-12-09 12:10:52.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 9.824734528781505e-05 Training loss: 10.322160720825195
2025-12-09 12:10:52.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 9.823934394068952e-05 Training loss: 10.544295310974121
2025-12-09 12:10:52.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 9.823132469828601e-05 Training loss: 10.37078857421875
2025-12-09 12:10:52.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 9.822328756357942e-05 Training loss: 10.437601089477539
2025-12-09 12:10:52.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 9.821523253955122e-05 Training loss: 10.531698226928711
2025-12-09 12:10:52.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 9.820715962918964e-05 Training loss: 10.465985298156738
2025-12-09 12:10:52.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 9.819906883548943e-05 Training loss: 10.587518692016602
2025-12-09 12:10:52.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 9.819096016145203e-05 Training loss: 10.435622215270996
2025-12-09 12:10:53.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 9.81828336100855e-05 Training loss: 10.400256156921387
2025-12-09 12:10:53.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 9.817468918440454e-05 Training loss: 10.476333618164062
2025-12-09 12:10:53.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 9.816652688743049e-05 Training loss: 10.407844543457031
2025-12-09 12:10:53.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 9.815834672219127e-05 Training loss: 10.681536674499512
2025-12-09 12:10:53.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 9.815014869172149e-05 Training loss: 10.464223861694336
2025-12-09 12:10:53.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 9.814193279906237e-05 Training loss: 10.487334251403809
2025-12-09 12:10:53.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 9.81336990472617e-05 Training loss: 10.370026588439941
2025-12-09 12:10:53.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 9.8125447439374e-05 Training loss: 10.390451431274414
2025-12-09 12:10:53.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 9.811717797846033e-05 Training loss: 10.378984451293945
2025-12-09 12:10:53.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 9.81088906675884e-05 Training loss: 10.54079532623291
2025-12-09 12:10:53.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 9.810058550983254e-05 Training loss: 10.476152420043945
2025-12-09 12:10:53.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 9.809226250827371e-05 Training loss: 10.440242767333984
2025-12-09 12:10:53.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 9.808392166599948e-05 Training loss: 10.513203620910645
2025-12-09 12:10:54.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 9.807556298610404e-05 Training loss: 10.611153602600098
2025-12-09 12:10:54.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 9.806718647168818e-05 Training loss: 10.529951095581055
2025-12-09 12:10:54.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 9.805879212585933e-05 Training loss: 10.468125343322754
2025-12-09 12:10:54.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 9.805037995173155e-05 Training loss: 10.306828498840332
2025-12-09 12:10:54.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 9.804194995242548e-05 Training loss: 10.45527172088623
2025-12-09 12:10:54.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 9.803350213106836e-05 Training loss: 10.291545867919922
2025-12-09 12:10:54.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 9.802503649079411e-05 Training loss: 10.456341743469238
2025-12-09 12:10:54.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 9.801655303474318e-05 Training loss: 10.48349666595459
2025-12-09 12:10:54.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 9.80080517660627e-05 Training loss: 10.484519958496094
2025-12-09 12:10:54.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 9.799953268790633e-05 Training loss: 10.399151802062988
2025-12-09 12:10:54.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 9.799099580343441e-05 Training loss: 10.457603454589844
2025-12-09 12:10:54.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 9.798244111581382e-05 Training loss: 10.120800018310547
2025-12-09 12:10:54.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 9.797386862821813e-05 Training loss: 10.331511497497559
2025-12-09 12:10:55.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 9.796527834382745e-05 Training loss: 10.41930103302002
2025-12-09 12:10:55.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 9.795667026582847e-05 Training loss: 10.357555389404297
2025-12-09 12:10:55.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 9.794804439741456e-05 Training loss: 10.536484718322754
2025-12-09 12:10:55.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 9.79394007417856e-05 Training loss: 10.340365409851074
2025-12-09 12:10:55.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 9.793073930214817e-05 Training loss: 10.481019020080566
2025-12-09 12:10:55.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 9.792206008171533e-05 Training loss: 10.37424373626709
2025-12-09 12:10:55.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 9.791336308370687e-05 Training loss: 10.383172988891602
2025-12-09 12:10:55.597 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 9.790464831134903e-05 Training loss: 10.386346817016602
2025-12-09 12:10:55.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 9.789591576787476e-05 Training loss: 10.589258193969727
2025-12-09 12:10:55.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 9.788716545652353e-05 Training loss: 10.452025413513184
2025-12-09 12:10:55.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 9.787839738054146e-05 Training loss: 10.441094398498535
2025-12-09 12:10:55.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 9.786961154318121e-05 Training loss: 10.381579399108887
2025-12-09 12:10:55.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 9.786080794770207e-05 Training loss: 10.509641647338867
2025-12-09 12:10:56.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 9.785198659736988e-05 Training loss: 10.290582656860352
2025-12-09 12:10:56.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 9.784314749545707e-05 Training loss: 10.440030097961426
2025-12-09 12:10:56.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 9.78342906452427e-05 Training loss: 10.181086540222168
2025-12-09 12:10:56.290 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 9.782541605001235e-05 Training loss: 10.798103332519531
2025-12-09 12:10:56.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 9.781652371305824e-05 Training loss: 10.399683952331543
2025-12-09 12:10:56.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 9.780761363767914e-05 Training loss: 10.612390518188477
2025-12-09 12:10:56.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 9.779868582718041e-05 Training loss: 10.565367698669434
2025-12-09 12:10:56.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 9.778974028487398e-05 Training loss: 10.312777519226074
2025-12-09 12:10:56.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 9.778077701407837e-05 Training loss: 10.436214447021484
2025-12-09 12:10:56.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 9.777179601811867e-05 Training loss: 10.251147270202637
2025-12-09 12:10:56.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 9.776279730032654e-05 Training loss: 10.279513359069824
2025-12-09 12:10:56.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 9.775378086404023e-05 Training loss: 10.313570022583008
2025-12-09 12:10:56.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 9.774474671260457e-05 Training loss: 10.479825019836426
2025-12-09 12:10:57.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 9.77356948493709e-05 Training loss: 10.468968391418457
2025-12-09 12:10:57.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 9.77266252776972e-05 Training loss: 10.196012496948242
2025-12-09 12:10:57.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 9.771753800094803e-05 Training loss: 10.55333423614502
2025-12-09 12:10:57.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 9.770843302249443e-05 Training loss: 10.31752872467041
2025-12-09 12:10:57.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 9.769931034571408e-05 Training loss: 10.103849411010742
2025-12-09 12:10:57.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 9.76901699739912e-05 Training loss: 10.468789100646973
2025-12-09 12:10:57.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 9.768101191071661e-05 Training loss: 10.364760398864746
2025-12-09 12:10:57.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 9.767183615928765e-05 Training loss: 10.733831405639648
2025-12-09 12:10:57.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 9.766264272310822e-05 Training loss: 10.294078826904297
2025-12-09 12:10:57.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 9.765343160558879e-05 Training loss: 10.346559524536133
2025-12-09 12:10:57.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 9.764420281014642e-05 Training loss: 10.32013988494873
2025-12-09 12:10:57.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 9.763495634020467e-05 Training loss: 10.368712425231934
2025-12-09 12:10:57.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 9.762569219919372e-05 Training loss: 10.351436614990234
2025-12-09 12:10:58.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 9.761641039055026e-05 Training loss: 10.479459762573242
2025-12-09 12:10:58.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 9.760711091771755e-05 Training loss: 10.49051284790039
2025-12-09 12:10:58.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 9.759779378414542e-05 Training loss: 10.348984718322754
2025-12-09 12:10:58.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 9.758845899329021e-05 Training loss: 10.301118850708008
2025-12-09 12:10:58.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 9.757910654861483e-05 Training loss: 10.276748657226562
2025-12-09 12:10:58.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 9.756973645358876e-05 Training loss: 10.366838455200195
2025-12-09 12:10:58.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 9.7560348711688e-05 Training loss: 10.299324989318848
2025-12-09 12:10:58.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 9.755094332639512e-05 Training loss: 10.248188972473145
2025-12-09 12:10:58.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 9.754152030119921e-05 Training loss: 10.37624454498291
2025-12-09 12:10:58.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 9.75320796395959e-05 Training loss: 10.254812240600586
2025-12-09 12:10:58.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 9.752262134508742e-05 Training loss: 10.3710355758667
2025-12-09 12:10:58.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 9.751314542118246e-05 Training loss: 10.549720764160156
2025-12-09 12:10:58.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 9.750365187139632e-05 Training loss: 10.240046501159668
2025-12-09 12:10:59.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 9.749414069925078e-05 Training loss: 10.194406509399414
2025-12-09 12:10:59.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 9.74846119082742e-05 Training loss: 10.234050750732422
2025-12-09 12:10:59.207 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 9.747506550200146e-05 Training loss: 10.20343017578125
2025-12-09 12:10:59.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 9.746550148397398e-05 Training loss: 10.505426406860352
2025-12-09 12:10:59.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 9.745591985773971e-05 Training loss: 10.47496509552002
2025-12-09 12:10:59.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 9.744632062685311e-05 Training loss: 10.477557182312012
2025-12-09 12:10:59.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 9.743670379487522e-05 Training loss: 10.32265853881836
2025-12-09 12:10:59.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 9.742706936537358e-05 Training loss: 10.346272468566895
2025-12-09 12:10:59.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 9.741741734192224e-05 Training loss: 10.072893142700195
2025-12-09 12:10:59.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 9.740774772810182e-05 Training loss: 10.445380210876465
2025-12-09 12:10:59.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 9.739806052749943e-05 Training loss: 10.34713363647461
2025-12-09 12:10:59.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 9.738835574370871e-05 Training loss: 10.29249382019043
2025-12-09 12:10:59.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 9.737863338032985e-05 Training loss: 10.634635925292969
2025-12-09 12:11:00.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 9.736889344096952e-05 Training loss: 10.414458274841309
2025-12-09 12:11:00.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 9.735913592924093e-05 Training loss: 10.463173866271973
2025-12-09 12:11:00.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 9.734936084876383e-05 Training loss: 10.23762321472168
2025-12-09 12:11:00.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 9.733956820316444e-05 Training loss: 10.445034980773926
2025-12-09 12:11:00.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 9.732975799607555e-05 Training loss: 10.276115417480469
2025-12-09 12:11:00.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 9.731993023113642e-05 Training loss: 10.412034034729004
2025-12-09 12:11:00.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 9.731008491199284e-05 Training loss: 10.111591339111328
2025-12-09 12:11:00.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 9.730022204229714e-05 Training loss: 10.264484405517578
2025-12-09 12:11:00.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 9.729034162570811e-05 Training loss: 10.159788131713867
2025-12-09 12:11:00.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 9.728044366589108e-05 Training loss: 10.261483192443848
2025-12-09 12:11:00.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 9.727052816651788e-05 Training loss: 10.410380363464355
2025-12-09 12:11:00.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 9.726059513126685e-05 Training loss: 10.18440055847168
2025-12-09 12:11:00.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 9.725064456382283e-05 Training loss: 10.410931587219238
2025-12-09 12:11:01.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 9.724067646787717e-05 Training loss: 10.19076919555664
2025-12-09 12:11:01.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 9.723069084712772e-05 Training loss: 10.305022239685059
2025-12-09 12:11:01.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 9.722068770527883e-05 Training loss: 10.343817710876465
2025-12-09 12:11:01.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 9.721066704604134e-05 Training loss: 10.469804763793945
2025-12-09 12:11:01.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 9.720062887313261e-05 Training loss: 10.355177879333496
2025-12-09 12:11:01.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 9.71905731902765e-05 Training loss: 10.423357009887695
2025-12-09 12:11:01.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 9.718050000120334e-05 Training loss: 10.438175201416016
2025-12-09 12:11:01.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 9.717040930964995e-05 Training loss: 10.276130676269531
2025-12-09 12:11:01.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 9.716030111935967e-05 Training loss: 10.155543327331543
2025-12-09 12:11:01.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 9.715017543408233e-05 Training loss: 10.348359107971191
2025-12-09 12:11:01.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 9.714003225757424e-05 Training loss: 10.459002494812012
2025-12-09 12:11:01.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 9.712987159359818e-05 Training loss: 10.307426452636719
2025-12-09 12:11:01.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 9.711969344592346e-05 Training loss: 10.38453483581543
2025-12-09 12:11:02.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 9.710949781832585e-05 Training loss: 10.19151496887207
2025-12-09 12:11:02.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 9.709928471458759e-05 Training loss: 10.349971771240234
2025-12-09 12:11:02.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 9.708905413849743e-05 Training loss: 10.56131649017334
2025-12-09 12:11:02.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 9.707880609385059e-05 Training loss: 10.34528923034668
2025-12-09 12:11:02.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 9.706854058444876e-05 Training loss: 10.32632827758789
2025-12-09 12:11:02.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 9.705825761410014e-05 Training loss: 10.34040641784668
2025-12-09 12:11:02.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 9.704795718661939e-05 Training loss: 10.084909439086914
2025-12-09 12:11:02.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 9.703763930582761e-05 Training loss: 10.556686401367188
2025-12-09 12:11:02.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 9.702730397555247e-05 Training loss: 10.57402515411377
2025-12-09 12:11:02.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 9.7016951199628e-05 Training loss: 10.246817588806152
2025-12-09 12:11:02.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 9.700658098189475e-05 Training loss: 10.242149353027344
2025-12-09 12:11:02.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 9.69961933261998e-05 Training loss: 10.255813598632812
2025-12-09 12:11:02.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 9.698578823639659e-05 Training loss: 10.242137908935547
2025-12-09 12:11:03.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 9.697536571634509e-05 Training loss: 10.31680679321289
2025-12-09 12:11:03.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 9.696492576991174e-05 Training loss: 10.33475112915039
2025-12-09 12:11:03.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 9.695446840096944e-05 Training loss: 10.201888084411621
2025-12-09 12:11:03.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 9.694399361339752e-05 Training loss: 10.245059967041016
2025-12-09 12:11:03.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 9.693350141108182e-05 Training loss: 10.260161399841309
2025-12-09 12:11:03.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 9.692299179791459e-05 Training loss: 10.560257911682129
2025-12-09 12:11:03.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 9.69124647777946e-05 Training loss: 10.135507583618164
2025-12-09 12:11:03.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 9.690192035462702e-05 Training loss: 10.486656188964844
2025-12-09 12:11:03.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 9.689135853232349e-05 Training loss: 10.301101684570312
2025-12-09 12:11:03.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 9.688077931480212e-05 Training loss: 10.251380920410156
2025-12-09 12:11:03.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 9.687018270598749e-05 Training loss: 10.237093925476074
2025-12-09 12:11:03.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 9.685956870981058e-05 Training loss: 10.214325904846191
2025-12-09 12:11:03.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 9.684893733020888e-05 Training loss: 10.142095565795898
2025-12-09 12:11:04.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 9.683828857112627e-05 Training loss: 10.279361724853516
2025-12-09 12:11:04.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 9.682762243651308e-05 Training loss: 10.289223670959473
2025-12-09 12:11:04.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 9.681693893032618e-05 Training loss: 10.195623397827148
2025-12-09 12:11:04.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 9.680623805652876e-05 Training loss: 10.541671752929688
2025-12-09 12:11:04.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 9.679551981909053e-05 Training loss: 10.174699783325195
2025-12-09 12:11:04.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 9.67847842219876e-05 Training loss: 10.141902923583984
2025-12-09 12:11:04.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 9.677403126920256e-05 Training loss: 10.308605194091797
2025-12-09 12:11:04.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 9.676326096472441e-05 Training loss: 10.312880516052246
2025-12-09 12:11:04.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 9.675247331254858e-05 Training loss: 10.274697303771973
2025-12-09 12:11:04.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 9.674166831667697e-05 Training loss: 10.376041412353516
2025-12-09 12:11:04.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 9.673084598111789e-05 Training loss: 10.309718132019043
2025-12-09 12:11:04.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 9.672000630988605e-05 Training loss: 10.322115898132324
2025-12-09 12:11:04.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 9.670914930700267e-05 Training loss: 10.219110488891602
2025-12-09 12:11:05.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 9.669827497649536e-05 Training loss: 10.355547904968262
2025-12-09 12:11:05.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 9.668738332239813e-05 Training loss: 10.111917495727539
2025-12-09 12:11:05.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 9.667647434875145e-05 Training loss: 10.2658052444458
2025-12-09 12:11:05.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 9.66655480596022e-05 Training loss: 10.208574295043945
2025-12-09 12:11:05.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 9.665460445900368e-05 Training loss: 10.221205711364746
2025-12-09 12:11:05.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 9.664364355101565e-05 Training loss: 10.21484375
2025-12-09 12:11:05.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 9.663266533970424e-05 Training loss: 10.186376571655273
2025-12-09 12:11:05.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 9.662166982914203e-05 Training loss: 10.31956672668457
2025-12-09 12:11:05.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 9.661065702340801e-05 Training loss: 10.176342010498047
2025-12-09 12:11:05.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 9.659962692658758e-05 Training loss: 10.092905044555664
2025-12-09 12:11:05.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 9.658857954277254e-05 Training loss: 10.034130096435547
2025-12-09 12:11:05.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 9.657751487606115e-05 Training loss: 10.253608703613281
2025-12-09 12:11:05.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 9.656643293055804e-05 Training loss: 10.210362434387207
2025-12-09 12:11:06.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 9.655533371037426e-05 Training loss: 10.389552116394043
2025-12-09 12:11:06.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 9.65442172196273e-05 Training loss: 10.28951644897461
2025-12-09 12:11:06.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 9.653308346244098e-05 Training loss: 10.439753532409668
2025-12-09 12:11:06.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 9.652193244294562e-05 Training loss: 10.508787155151367
2025-12-09 12:11:06.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 9.651076416527787e-05 Training loss: 10.082972526550293
2025-12-09 12:11:06.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 9.64995786335808e-05 Training loss: 10.295344352722168
2025-12-09 12:11:06.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 9.648837585200393e-05 Training loss: 10.349627494812012
2025-12-09 12:11:06.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 9.64771558247031e-05 Training loss: 10.583346366882324
2025-12-09 12:11:06.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 9.64659185558406e-05 Training loss: 10.138968467712402
2025-12-09 12:11:06.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 9.64546640495851e-05 Training loss: 10.312275886535645
2025-12-09 12:11:06.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 9.644339231011168e-05 Training loss: 10.214496612548828
2025-12-09 12:11:06.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 9.643210334160177e-05 Training loss: 10.172677993774414
2025-12-09 12:11:06.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 9.642079714824328e-05 Training loss: 10.452247619628906
2025-12-09 12:11:07.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 9.64094737342304e-05 Training loss: 10.316688537597656
