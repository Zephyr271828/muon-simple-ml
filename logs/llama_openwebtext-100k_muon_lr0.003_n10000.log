2025-12-09 12:34:23.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 3e-05 Training loss: 12.156133651733398
2025-12-09 12:34:24.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 6e-05 Training loss: 12.227204322814941
2025-12-09 12:34:24.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 8.999999999999999e-05 Training loss: 12.133179664611816
2025-12-09 12:34:25.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.00012 Training loss: 12.122483253479004
2025-12-09 12:34:25.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.00015000000000000001 Training loss: 12.11731243133545
2025-12-09 12:34:26.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.00017999999999999998 Training loss: 12.008040428161621
2025-12-09 12:34:26.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.00021000000000000004 Training loss: 12.050204277038574
2025-12-09 12:34:27.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.00024 Training loss: 12.009781837463379
2025-12-09 12:34:27.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.00027 Training loss: 11.89918041229248
2025-12-09 12:34:28.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.00030000000000000003 Training loss: 11.73050308227539
2025-12-09 12:34:28.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00033 Training loss: 11.668466567993164
2025-12-09 12:34:29.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00035999999999999997 Training loss: 11.518242835998535
2025-12-09 12:34:29.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00039000000000000005 Training loss: 11.369324684143066
2025-12-09 12:34:30.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00042000000000000007 Training loss: 10.718974113464355
2025-12-09 12:34:30.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00045 Training loss: 10.417250633239746
2025-12-09 12:34:31.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00048 Training loss: 10.021615028381348
2025-12-09 12:34:31.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00051 Training loss: 9.61592960357666
2025-12-09 12:34:32.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00054 Training loss: 9.317426681518555
2025-12-09 12:34:32.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00057 Training loss: 8.808305740356445
2025-12-09 12:34:33.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0006000000000000001 Training loss: 8.84554672241211
2025-12-09 12:34:33.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00063 Training loss: 8.455891609191895
2025-12-09 12:34:34.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00066 Training loss: 8.669471740722656
2025-12-09 12:34:34.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0006900000000000001 Training loss: 8.71632194519043
2025-12-09 12:34:35.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0007199999999999999 Training loss: 8.83128833770752
2025-12-09 12:34:35.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00075 Training loss: 8.436091423034668
2025-12-09 12:34:36.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0007800000000000001 Training loss: 8.191953659057617
2025-12-09 12:34:36.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0008100000000000001 Training loss: 8.55809497833252
2025-12-09 12:34:37.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0008400000000000001 Training loss: 8.344534873962402
2025-12-09 12:34:37.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00087 Training loss: 8.43994426727295
2025-12-09 12:34:38.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0009 Training loss: 9.091907501220703
2025-12-09 12:34:38.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00093 Training loss: 8.133210182189941
2025-12-09 12:34:39.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00096 Training loss: 8.253171920776367
2025-12-09 12:34:39.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00099 Training loss: 8.268258094787598
2025-12-09 12:34:40.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00102 Training loss: 8.02462387084961
2025-12-09 12:34:40.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00105 Training loss: 7.971012115478516
2025-12-09 12:34:41.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00108 Training loss: 8.363921165466309
2025-12-09 12:34:41.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00111 Training loss: 8.211222648620605
2025-12-09 12:34:42.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00114 Training loss: 8.07450008392334
2025-12-09 12:34:42.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00117 Training loss: 8.625041007995605
2025-12-09 12:34:43.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0012000000000000001 Training loss: 8.130413055419922
2025-12-09 12:34:43.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00123 Training loss: 8.197694778442383
2025-12-09 12:34:44.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00126 Training loss: 8.182013511657715
2025-12-09 12:34:44.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00129 Training loss: 8.662130355834961
2025-12-09 12:34:45.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00132 Training loss: 8.115169525146484
2025-12-09 12:34:45.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00135 Training loss: 8.122876167297363
2025-12-09 12:34:46.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0013800000000000002 Training loss: 8.006805419921875
2025-12-09 12:34:46.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00141 Training loss: 7.996810436248779
2025-12-09 12:34:47.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0014399999999999999 Training loss: 8.020381927490234
2025-12-09 12:34:47.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00147 Training loss: 7.998865604400635
2025-12-09 12:34:48.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0015 Training loss: 7.803746700286865
2025-12-09 12:34:48.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0015300000000000001 Training loss: 7.758841037750244
2025-12-09 12:34:49.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0015600000000000002 Training loss: 7.977068901062012
2025-12-09 12:34:49.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.00159 Training loss: 8.326897621154785
2025-12-09 12:34:50.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0016200000000000001 Training loss: 7.920353412628174
2025-12-09 12:34:50.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0016500000000000002 Training loss: 8.112835884094238
2025-12-09 12:34:51.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0016800000000000003 Training loss: 8.540976524353027
2025-12-09 12:34:51.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00171 Training loss: 7.919071674346924
2025-12-09 12:34:52.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00174 Training loss: 7.512101173400879
2025-12-09 12:34:52.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0017699999999999999 Training loss: 7.844440460205078
2025-12-09 12:34:53.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0018 Training loss: 7.761053085327148
2025-12-09 12:34:53.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00183 Training loss: 8.642348289489746
2025-12-09 12:34:54.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00186 Training loss: 8.501410484313965
2025-12-09 12:34:54.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00189 Training loss: 8.361193656921387
2025-12-09 12:34:55.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00192 Training loss: 7.857713222503662
2025-12-09 12:34:55.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0019500000000000001 Training loss: 8.279860496520996
2025-12-09 12:34:56.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00198 Training loss: 7.557778358459473
2025-12-09 12:34:56.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00201 Training loss: 8.043546676635742
2025-12-09 12:34:57.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00204 Training loss: 7.857275485992432
2025-12-09 12:34:57.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00207 Training loss: 7.732184886932373
2025-12-09 12:34:58.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0021 Training loss: 8.431806564331055
2025-12-09 12:34:58.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00213 Training loss: 7.701671123504639
2025-12-09 12:34:59.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.00216 Training loss: 7.869660377502441
2025-12-09 12:34:59.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00219 Training loss: 8.073434829711914
2025-12-09 12:35:00.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00222 Training loss: 8.200453758239746
2025-12-09 12:35:00.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0022500000000000003 Training loss: 7.993516445159912
2025-12-09 12:35:01.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00228 Training loss: 8.318893432617188
2025-12-09 12:35:01.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.00231 Training loss: 8.110804557800293
2025-12-09 12:35:02.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.00234 Training loss: 8.016843795776367
2025-12-09 12:35:02.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00237 Training loss: 7.985482692718506
2025-12-09 12:35:03.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0024000000000000002 Training loss: 8.05436897277832
2025-12-09 12:35:03.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0024300000000000003 Training loss: 7.671065807342529
2025-12-09 12:35:04.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00246 Training loss: 8.386488914489746
2025-12-09 12:35:04.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00249 Training loss: 7.747321128845215
2025-12-09 12:35:05.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00252 Training loss: 7.8886494636535645
2025-12-09 12:35:05.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00255 Training loss: 8.36972427368164
2025-12-09 12:35:06.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00258 Training loss: 7.9163923263549805
2025-12-09 12:35:06.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00261 Training loss: 7.992992877960205
2025-12-09 12:35:07.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00264 Training loss: 7.8532328605651855
2025-12-09 12:35:07.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.00267 Training loss: 8.045341491699219
2025-12-09 12:35:08.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0027 Training loss: 7.704198837280273
2025-12-09 12:35:08.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0027300000000000002 Training loss: 7.600955963134766
2025-12-09 12:35:09.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0027600000000000003 Training loss: 8.670251846313477
2025-12-09 12:35:09.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.0027900000000000004 Training loss: 8.082326889038086
2025-12-09 12:35:10.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00282 Training loss: 7.9853739738464355
2025-12-09 12:35:10.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00285 Training loss: 7.847150802612305
2025-12-09 12:35:11.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0028799999999999997 Training loss: 7.828757286071777
2025-12-09 12:35:11.623 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.00291 Training loss: 8.023197174072266
2025-12-09 12:35:12.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00294 Training loss: 7.326354026794434
2025-12-09 12:35:12.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00297 Training loss: 7.949204444885254
2025-12-09 12:35:13.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.003 Training loss: 7.518075466156006
2025-12-09 12:35:13.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0029999997089396424 Training loss: 7.563284873962402
2025-12-09 12:35:14.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.002999998835758683 Training loss: 7.9802632331848145
2025-12-09 12:35:14.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0029999973804574606 Training loss: 8.041038513183594
2025-12-09 12:35:15.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0029999953430365394 Training loss: 7.432064056396484
2025-12-09 12:35:15.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.002999992723496711 Training loss: 7.673598766326904
2025-12-09 12:35:16.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.002999989521838991 Training loss: 7.846024990081787
2025-12-09 12:35:16.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0029999857380646226 Training loss: 7.948885440826416
2025-12-09 12:35:17.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.002999981372175074 Training loss: 8.158452033996582
2025-12-09 12:35:17.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0029999764241720396 Training loss: 7.42216157913208
2025-12-09 12:35:18.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.0029999708940574394 Training loss: 7.573969841003418
2025-12-09 12:35:18.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.0029999647818334195 Training loss: 7.47520112991333
2025-12-09 12:35:19.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.002999958087502352 Training loss: 7.448039531707764
2025-12-09 12:35:19.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0029999508110668356 Training loss: 7.380612373352051
2025-12-09 12:35:20.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0029999429525296934 Training loss: 7.768858432769775
2025-12-09 12:35:20.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.0029999345118939752 Training loss: 7.663100242614746
2025-12-09 12:35:21.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0029999254891629563 Training loss: 8.071245193481445
2025-12-09 12:35:21.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.002999915884340139 Training loss: 7.968743801116943
2025-12-09 12:35:22.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.0029999056974292504 Training loss: 8.346000671386719
2025-12-09 12:35:22.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0029998949284342435 Training loss: 7.839629173278809
2025-12-09 12:35:23.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.002999883577359298 Training loss: 8.003459930419922
2025-12-09 12:35:23.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.002999871644208819 Training loss: 7.675125598907471
2025-12-09 12:35:24.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.002999859128987437 Training loss: 7.52783727645874
2025-12-09 12:35:24.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.00299984603170001 Training loss: 7.4579267501831055
2025-12-09 12:35:25.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.0029998323523516197 Training loss: 7.409154415130615
2025-12-09 12:35:25.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0029998180909475754 Training loss: 7.323126316070557
2025-12-09 12:35:26.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.002999803247493411 Training loss: 7.956907749176025
2025-12-09 12:35:26.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.002999787821994888 Training loss: 7.826263904571533
2025-12-09 12:35:27.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.0029997718144579915 Training loss: 7.4815473556518555
2025-12-09 12:35:27.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0029997552248889354 Training loss: 7.747379302978516
2025-12-09 12:35:28.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.002999738053294156 Training loss: 8.228270530700684
2025-12-09 12:35:28.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.0029997202996803183 Training loss: 7.436271667480469
2025-12-09 12:35:29.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.002999701964054312 Training loss: 7.457459449768066
2025-12-09 12:35:29.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0029996830464232523 Training loss: 8.674250602722168
2025-12-09 12:35:30.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.0029996635467944813 Training loss: 7.701612949371338
2025-12-09 12:35:30.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.0029996434651755662 Training loss: 7.844590663909912
2025-12-09 12:35:31.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0029996228015743004 Training loss: 7.291225433349609
2025-12-09 12:35:31.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.002999601555998703 Training loss: 7.258176326751709
2025-12-09 12:35:32.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.002999579728457019 Training loss: 7.732066631317139
2025-12-09 12:35:32.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.002999557318957719 Training loss: 7.813348770141602
2025-12-09 12:35:33.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0029995343275095003 Training loss: 7.281991004943848
2025-12-09 12:35:33.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0029995107541212845 Training loss: 7.106618881225586
2025-12-09 12:35:34.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.002999486598802221 Training loss: 7.4172282218933105
2025-12-09 12:35:34.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0029994618615616832 Training loss: 7.6154584884643555
2025-12-09 12:35:35.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.002999436542409272 Training loss: 7.580666542053223
2025-12-09 12:35:35.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0029994106413548122 Training loss: 7.960174083709717
2025-12-09 12:35:36.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.0029993841584083558 Training loss: 7.428039073944092
2025-12-09 12:35:36.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.002999357093580181 Training loss: 7.2521820068359375
2025-12-09 12:35:37.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0029993294468807904 Training loss: 7.210601329803467
2025-12-09 12:35:37.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.0029993012183209137 Training loss: 7.335565090179443
2025-12-09 12:35:38.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0029992724079115052 Training loss: 7.670980453491211
2025-12-09 12:35:38.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.002999243015663746 Training loss: 7.460160732269287
2025-12-09 12:35:39.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.0029992130415890427 Training loss: 6.940673351287842
2025-12-09 12:35:39.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.002999182485699028 Training loss: 8.019207000732422
2025-12-09 12:35:40.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.0029991513480055595 Training loss: 7.497653484344482
2025-12-09 12:35:40.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.002999119628520721 Training loss: 6.969456672668457
2025-12-09 12:35:41.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0029990873272568224 Training loss: 7.237069606781006
2025-12-09 12:35:41.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.0029990544442264 Training loss: 7.301672458648682
2025-12-09 12:35:42.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.002999020979442214 Training loss: 7.628939628601074
2025-12-09 12:35:42.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.002998986932917252 Training loss: 7.463438987731934
2025-12-09 12:35:43.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.002998952304664726 Training loss: 7.6451334953308105
2025-12-09 12:35:43.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.002998917094698076 Training loss: 7.865772247314453
2025-12-09 12:35:44.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.002998881303030965 Training loss: 7.857181072235107
2025-12-09 12:35:44.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.0029988449296772836 Training loss: 7.232583045959473
2025-12-09 12:35:45.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.002998807974651147 Training loss: 7.468986511230469
2025-12-09 12:35:45.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0029987704379668976 Training loss: 7.8957648277282715
2025-12-09 12:35:46.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.002998732319639102 Training loss: 7.342176914215088
2025-12-09 12:35:46.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.0029986936196825537 Training loss: 7.711145401000977
2025-12-09 12:35:47.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.002998654338112271 Training loss: 7.612067222595215
2025-12-09 12:35:47.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.0029986144749434987 Training loss: 7.091088771820068
2025-12-09 12:35:48.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.0029985740301917063 Training loss: 7.435986042022705
2025-12-09 12:35:48.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.00299853300387259 Training loss: 7.521569728851318
2025-12-09 12:35:49.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.0029984913960020712 Training loss: 8.230520248413086
2025-12-09 12:35:49.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0029984492065962976 Training loss: 7.605867385864258
2025-12-09 12:35:50.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.0029984064356716415 Training loss: 7.751553535461426
2025-12-09 12:35:50.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.0029983630832447015 Training loss: 7.733783721923828
2025-12-09 12:35:51.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.002998319149332302 Training loss: 7.258194923400879
2025-12-09 12:35:51.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0029982746339514933 Training loss: 7.711668968200684
2025-12-09 12:35:52.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0029982295371195496 Training loss: 7.547277450561523
2025-12-09 12:35:52.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.002998183858853974 Training loss: 7.47218132019043
2025-12-09 12:35:53.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.0029981375991724917 Training loss: 7.5282182693481445
2025-12-09 12:35:53.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0029980907580930563 Training loss: 7.407065391540527
2025-12-09 12:35:54.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.002998043335633845 Training loss: 7.253798961639404
2025-12-09 12:35:54.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.002997995331813262 Training loss: 7.652093410491943
2025-12-09 12:35:55.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.002997946746649937 Training loss: 7.0485076904296875
2025-12-09 12:35:55.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.0029978975801627245 Training loss: 7.444953441619873
2025-12-09 12:35:56.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0029978478323707046 Training loss: 7.5709309577941895
2025-12-09 12:35:56.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.0029977975032931844 Training loss: 7.394115447998047
2025-12-09 12:35:57.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.002997746592949695 Training loss: 7.6234259605407715
2025-12-09 12:35:57.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.002997695101359994 Training loss: 7.978821277618408
2025-12-09 12:35:58.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.002997643028544064 Training loss: 7.769648551940918
2025-12-09 12:35:58.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0029975903745221143 Training loss: 7.611551761627197
2025-12-09 12:35:59.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.002997537139314578 Training loss: 6.955480575561523
2025-12-09 12:35:59.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.0029974833229421145 Training loss: 7.9598259925842285
2025-12-09 12:36:00.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.002997428925425609 Training loss: 7.281016826629639
2025-12-09 12:36:00.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.0029973739467861736 Training loss: 8.397321701049805
2025-12-09 12:36:01.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.002997318387045142 Training loss: 7.77268648147583
2025-12-09 12:36:01.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0029972622462240777 Training loss: 7.8747029304504395
2025-12-09 12:36:02.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.0029972055243447666 Training loss: 8.013182640075684
2025-12-09 12:36:02.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.002997148221429223 Training loss: 7.085651874542236
2025-12-09 12:36:03.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.002997090337499683 Training loss: 7.461136341094971
2025-12-09 12:36:03.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0029970318725786116 Training loss: 7.576071739196777
2025-12-09 12:36:04.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0029969728266886976 Training loss: 8.232529640197754
2025-12-09 12:36:04.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0029969131998528555 Training loss: 7.890774726867676
2025-12-09 12:36:05.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0029968529920942253 Training loss: 7.675462245941162
2025-12-09 12:36:05.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0029967922034361727 Training loss: 6.810453414916992
2025-12-09 12:36:06.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.002996730833902288 Training loss: 7.427056312561035
2025-12-09 12:36:06.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.002996668883516388 Training loss: 7.174643039703369
2025-12-09 12:36:07.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.002996606352302514 Training loss: 7.246232032775879
2025-12-09 12:36:07.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.002996543240284934 Training loss: 7.397884845733643
2025-12-09 12:36:08.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0029964795474881397 Training loss: 7.336134910583496
2025-12-09 12:36:08.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.002996415273936849 Training loss: 7.172075271606445
2025-12-09 12:36:09.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.002996350419656006 Training loss: 7.206644058227539
2025-12-09 12:36:09.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0029962849846707786 Training loss: 7.363614559173584
2025-12-09 12:36:10.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.0029962189690065613 Training loss: 8.136932373046875
2025-12-09 12:36:10.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.0029961523726889736 Training loss: 7.192973613739014
2025-12-09 12:36:11.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.0029960851957438594 Training loss: 7.290044784545898
2025-12-09 12:36:11.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.00299601743819729 Training loss: 7.245914459228516
2025-12-09 12:36:12.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.0029959491000755597 Training loss: 6.804122447967529
2025-12-09 12:36:12.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.0029958801814051897 Training loss: 7.928483486175537
2025-12-09 12:36:13.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.002995810682212926 Training loss: 6.980862140655518
2025-12-09 12:36:13.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.0029957406025257396 Training loss: 7.799705982208252
2025-12-09 12:36:14.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.002995669942370827 Training loss: 7.27365255355835
2025-12-09 12:36:14.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0029955987017756106 Training loss: 6.974376201629639
2025-12-09 12:36:15.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0029955268807677375 Training loss: 6.976175308227539
2025-12-09 12:36:15.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.002995454479375079 Training loss: 7.552326202392578
2025-12-09 12:36:16.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.0029953814976257337 Training loss: 7.305262088775635
2025-12-09 12:36:16.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.002995307935548024 Training loss: 8.285120964050293
2025-12-09 12:36:17.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.002995233793170498 Training loss: 7.247173309326172
2025-12-09 12:36:17.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0029951590705219284 Training loss: 8.075826644897461
2025-12-09 12:36:18.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0029950837676313144 Training loss: 7.327878952026367
2025-12-09 12:36:18.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0029950078845278794 Training loss: 8.078453063964844
2025-12-09 12:36:19.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.0029949314212410717 Training loss: 6.960271835327148
2025-12-09 12:36:19.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0029948543778005655 Training loss: 7.218355178833008
2025-12-09 12:36:20.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.00299477675423626 Training loss: 7.751616477966309
2025-12-09 12:36:20.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.002994698550578279 Training loss: 7.668755054473877
2025-12-09 12:36:21.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0029946197668569725 Training loss: 7.356481552124023
2025-12-09 12:36:21.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.002994540403102914 Training loss: 8.381908416748047
2025-12-09 12:36:22.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0029944604593469034 Training loss: 7.334590435028076
2025-12-09 12:36:22.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.0029943799356199658 Training loss: 7.2896833419799805
2025-12-09 12:36:23.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0029942988319533507 Training loss: 6.822766304016113
2025-12-09 12:36:23.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.002994217148378532 Training loss: 6.966688632965088
2025-12-09 12:36:24.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.002994134884927211 Training loss: 7.383446216583252
2025-12-09 12:36:24.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.002994052041631311 Training loss: 7.677572727203369
2025-12-09 12:36:25.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.0029939686185229825 Training loss: 7.32232666015625
2025-12-09 12:36:25.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.0029938846156346006 Training loss: 7.720403671264648
2025-12-09 12:36:26.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.002993800032998765 Training loss: 7.266273498535156
2025-12-09 12:36:26.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.002993714870648301 Training loss: 7.292321681976318
2025-12-09 12:36:27.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0029936291286162577 Training loss: 7.183983325958252
2025-12-09 12:36:27.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.00299354280693591 Training loss: 8.337530136108398
2025-12-09 12:36:28.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.002993455905640758 Training loss: 6.967970371246338
2025-12-09 12:36:28.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0029933684247645267 Training loss: 7.072299957275391
2025-12-09 12:36:29.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.002993280364341165 Training loss: 6.988829135894775
2025-12-09 12:36:29.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.002993191724404848 Training loss: 7.221435070037842
2025-12-09 12:36:30.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.0029931025049899744 Training loss: 7.181130409240723
2025-12-09 12:36:30.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.002993012706131169 Training loss: 7.546276092529297
2025-12-09 12:36:31.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.002992922327863281 Training loss: 7.299635410308838
2025-12-09 12:36:31.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.002992831370221385 Training loss: 7.055481910705566
2025-12-09 12:36:32.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.002992739833240779 Training loss: 6.953155040740967
2025-12-09 12:36:32.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.0029926477169569866 Training loss: 6.811448574066162
2025-12-09 12:36:33.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.0029925550214057565 Training loss: 6.928567886352539
2025-12-09 12:36:33.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.002992461746623063 Training loss: 7.635134220123291
2025-12-09 12:36:34.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0029923678926451034 Training loss: 7.177014350891113
2025-12-09 12:36:34.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.0029922734595083005 Training loss: 7.184389114379883
2025-12-09 12:36:35.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.002992178447249302 Training loss: 7.3639912605285645
2025-12-09 12:36:35.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.0029920828559049806 Training loss: 7.029836177825928
2025-12-09 12:36:36.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.0029919866855124336 Training loss: 7.199979305267334
2025-12-09 12:36:36.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0029918899361089826 Training loss: 7.808544158935547
2025-12-09 12:36:37.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.0029917926077321732 Training loss: 6.742968559265137
2025-12-09 12:36:37.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.002991694700419778 Training loss: 7.350744247436523
2025-12-09 12:36:38.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.002991596214209793 Training loss: 6.90786075592041
2025-12-09 12:36:38.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.0029914971491404375 Training loss: 7.155825614929199
2025-12-09 12:36:39.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0029913975052501575 Training loss: 7.449651718139648
2025-12-09 12:36:39.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.002991297282577623 Training loss: 7.417242527008057
2025-12-09 12:36:40.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.0029911964811617287 Training loss: 7.256302833557129
2025-12-09 12:36:40.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0029910951010415927 Training loss: 7.131447792053223
2025-12-09 12:36:41.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.0029909931422565593 Training loss: 7.201226711273193
2025-12-09 12:36:41.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0029908906048461965 Training loss: 6.861081600189209
2025-12-09 12:36:42.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.002990787488850297 Training loss: 7.743654251098633
2025-12-09 12:36:42.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0029906837943088787 Training loss: 7.705829620361328
2025-12-09 12:36:43.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0029905795212621824 Training loss: 7.069291591644287
2025-12-09 12:36:43.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.002990474669750676 Training loss: 7.282191276550293
2025-12-09 12:36:44.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.002990369239815048 Training loss: 6.797283172607422
2025-12-09 12:36:44.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.002990263231496216 Training loss: 7.23510217666626
2025-12-09 12:36:45.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0029901566448353183 Training loss: 7.447329521179199
2025-12-09 12:36:45.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0029900494798737196 Training loss: 7.90653657913208
2025-12-09 12:36:46.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.002989941736653009 Training loss: 7.078420639038086
2025-12-09 12:36:46.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.002989833415214999 Training loss: 6.6799540519714355
2025-12-09 12:36:47.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0029897245156017267 Training loss: 7.002367973327637
2025-12-09 12:36:47.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.002989615037855454 Training loss: 7.284544944763184
2025-12-09 12:36:48.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0029895049820186682 Training loss: 7.192999839782715
2025-12-09 12:36:48.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0029893943481340787 Training loss: 7.028484344482422
2025-12-09 12:36:49.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.0029892831362446203 Training loss: 6.94254732131958
2025-12-09 12:36:49.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.002989171346393453 Training loss: 7.01826286315918
2025-12-09 12:36:50.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.00298905897862396 Training loss: 7.147156238555908
2025-12-09 12:36:50.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0029889460329797484 Training loss: 7.430874824523926
2025-12-09 12:36:51.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.0029888325095046506 Training loss: 7.057380676269531
2025-12-09 12:36:51.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.0029887184082427226 Training loss: 6.98240852355957
2025-12-09 12:36:52.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.002988603729238246 Training loss: 7.252293109893799
2025-12-09 12:36:52.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.0029884884725357237 Training loss: 7.571056842803955
2025-12-09 12:36:53.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0029883726381798865 Training loss: 6.947271347045898
2025-12-09 12:36:53.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0029882562262156854 Training loss: 7.080585956573486
2025-12-09 12:36:54.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.002988139236688299 Training loss: 7.116509437561035
2025-12-09 12:36:54.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0029880216696431287 Training loss: 7.093214988708496
2025-12-09 12:36:55.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.0029879035251257993 Training loss: 7.151116847991943
2025-12-09 12:36:55.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.002987784803182161 Training loss: 7.063230514526367
2025-12-09 12:36:56.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0029876655038582863 Training loss: 7.160028457641602
2025-12-09 12:36:56.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.0029875456272004746 Training loss: 7.30150032043457
2025-12-09 12:36:57.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0029874251732552462 Training loss: 7.775661468505859
2025-12-09 12:36:57.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.002987304142069348 Training loss: 6.943418025970459
2025-12-09 12:36:58.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.002987182533689749 Training loss: 7.195211887359619
2025-12-09 12:36:58.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0029870603481636443 Training loss: 6.998470306396484
2025-12-09 12:36:59.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.0029869375855384505 Training loss: 6.981747150421143
2025-12-09 12:36:59.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0029868142458618096 Training loss: 7.1367950439453125
2025-12-09 12:37:00.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0029866903291815875 Training loss: 6.916213512420654
2025-12-09 12:37:00.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.002986565835545874 Training loss: 6.988048076629639
2025-12-09 12:37:01.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0029864407650029823 Training loss: 6.323390007019043
2025-12-09 12:37:01.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.00298631511760145 Training loss: 6.805907249450684
2025-12-09 12:37:02.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.0029861888933900385 Training loss: 7.108670234680176
2025-12-09 12:37:02.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.002986062092417733 Training loss: 6.9833173751831055
2025-12-09 12:37:03.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0029859347147337422 Training loss: 6.81965970993042
2025-12-09 12:37:03.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.002985806760387499 Training loss: 6.9066643714904785
2025-12-09 12:37:04.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.00298567822942866 Training loss: 6.796511173248291
2025-12-09 12:37:04.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.0029855491219071056 Training loss: 6.976408958435059
2025-12-09 12:37:05.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.00298541943787294 Training loss: 6.420199394226074
2025-12-09 12:37:05.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.002985289177376491 Training loss: 7.918447017669678
2025-12-09 12:37:06.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.00298515834046831 Training loss: 7.101349830627441
2025-12-09 12:37:06.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.002985026927199172 Training loss: 7.186498641967773
2025-12-09 12:37:07.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0029848949376200767 Training loss: 7.123830318450928
2025-12-09 12:37:07.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.0029847623717822462 Training loss: 7.005001544952393
2025-12-09 12:37:08.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.0029846292297371264 Training loss: 6.638638496398926
2025-12-09 12:37:08.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.002984495511536388 Training loss: 6.769707679748535
2025-12-09 12:37:09.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.0029843612172319235 Training loss: 6.929978370666504
2025-12-09 12:37:09.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.002984226346875851 Training loss: 7.360756874084473
2025-12-09 12:37:10.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.0029840909005205093 Training loss: 7.3398051261901855
2025-12-09 12:37:10.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.002983954878218464 Training loss: 7.21536922454834
2025-12-09 12:37:11.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.002983818280022502 Training loss: 6.614010334014893
2025-12-09 12:37:11.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.0029836811059856354 Training loss: 7.402873992919922
2025-12-09 12:37:12.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.0029835433561610975 Training loss: 6.690492153167725
2025-12-09 12:37:12.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.0029834050306023468 Training loss: 7.767541885375977
2025-12-09 12:37:13.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.0029832661293630646 Training loss: 6.904040336608887
2025-12-09 12:37:13.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.002983126652497156 Training loss: 6.9857001304626465
2025-12-09 12:37:14.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.002982986600058749 Training loss: 7.071020603179932
2025-12-09 12:37:14.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.0029828459721021965 Training loss: 6.769723415374756
2025-12-09 12:37:15.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.002982704768682071 Training loss: 6.535689830780029
2025-12-09 12:37:15.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.0029825629898531728 Training loss: 7.510522365570068
2025-12-09 12:37:16.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.002982420635670523 Training loss: 7.032610893249512
2025-12-09 12:37:16.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.002982277706189366 Training loss: 6.984041213989258
2025-12-09 12:37:17.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.00298213420146517 Training loss: 7.0957441329956055
2025-12-09 12:37:17.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0029819901215536273 Training loss: 6.36883544921875
2025-12-09 12:37:18.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.002981845466510651 Training loss: 7.046177864074707
2025-12-09 12:37:18.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.0029817002363923804 Training loss: 6.86103630065918
2025-12-09 12:37:19.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.002981554431255176 Training loss: 6.921699047088623
2025-12-09 12:37:19.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.002981408051155621 Training loss: 6.6835832595825195
2025-12-09 12:37:20.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.002981261096150524 Training loss: 6.43231725692749
2025-12-09 12:37:20.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.002981113566296915 Training loss: 7.461329936981201
2025-12-09 12:37:21.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0029809654616520464 Training loss: 6.918179035186768
2025-12-09 12:37:21.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.0029808167822733956 Training loss: 6.90882682800293
2025-12-09 12:37:22.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.0029806675282186626 Training loss: 7.204232215881348
2025-12-09 12:37:22.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.002980517699545769 Training loss: 7.2528157234191895
2025-12-09 12:37:23.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.0029803672963128617 Training loss: 6.852258682250977
2025-12-09 12:37:23.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.0029802163185783073 Training loss: 7.1095499992370605
2025-12-09 12:37:24.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.0029800647664006996 Training loss: 7.465506076812744
2025-12-09 12:37:24.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.002979912639838851 Training loss: 6.4128007888793945
2025-12-09 12:37:25.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0029797599389518002 Training loss: 6.882584571838379
2025-12-09 12:37:25.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.0029796066637988072 Training loss: 6.519912242889404
2025-12-09 12:37:26.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.002979452814439354 Training loss: 7.327162265777588
2025-12-09 12:37:26.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.0029792983909331487 Training loss: 6.829402446746826
2025-12-09 12:37:27.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.0029791433933401175 Training loss: 6.839085102081299
2025-12-09 12:37:27.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.0029789878217204137 Training loss: 7.273695945739746
2025-12-09 12:37:28.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.0029788316761344114 Training loss: 7.142333984375
2025-12-09 12:37:28.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.0029786749566427066 Training loss: 6.433525085449219
2025-12-09 12:37:29.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.00297851766330612 Training loss: 6.939318656921387
2025-12-09 12:37:29.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.002978359796185695 Training loss: 7.122011184692383
2025-12-09 12:37:30.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.0029782013553426943 Training loss: 7.008528232574463
2025-12-09 12:37:30.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.0029780423408386075 Training loss: 6.703464984893799
2025-12-09 12:37:31.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.0029778827527351445 Training loss: 6.903643608093262
2025-12-09 12:37:31.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.0029777225910942386 Training loss: 6.734084129333496
2025-12-09 12:37:32.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.002977561855978045 Training loss: 6.804619312286377
2025-12-09 12:37:32.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.002977400547448942 Training loss: 6.803740501403809
2025-12-09 12:37:33.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.0029772386655695306 Training loss: 6.807707786560059
2025-12-09 12:37:33.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.0029770762104026336 Training loss: 6.837757110595703
2025-12-09 12:37:34.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.002976913182011297 Training loss: 6.632287502288818
2025-12-09 12:37:34.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.0029767495804587886 Training loss: 6.893893241882324
2025-12-09 12:37:35.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.002976585405808599 Training loss: 6.5727386474609375
2025-12-09 12:37:35.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0029764206581244412 Training loss: 7.26678991317749
2025-12-09 12:37:36.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.002976255337470251 Training loss: 6.958654880523682
2025-12-09 12:37:36.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.002976089443910186 Training loss: 7.9936065673828125
2025-12-09 12:37:37.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.0029759229775086255 Training loss: 7.02994441986084
2025-12-09 12:37:37.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0029757559383301727 Training loss: 6.691374778747559
2025-12-09 12:37:38.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.0029755883264396517 Training loss: 6.58582067489624
2025-12-09 12:37:38.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.00297542014190211 Training loss: 6.790731906890869
2025-12-09 12:37:39.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.0029752513847828162 Training loss: 6.95964241027832
2025-12-09 12:37:39.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.0029750820551472617 Training loss: 6.954017162322998
2025-12-09 12:37:40.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.0029749121530611602 Training loss: 7.008285045623779
2025-12-09 12:37:40.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.0029747416785904472 Training loss: 8.700797080993652
2025-12-09 12:37:41.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.002974570631801281 Training loss: 7.1125102043151855
2025-12-09 12:37:41.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.0029743990127600413 Training loss: 7.087706089019775
2025-12-09 12:37:42.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.002974226821533329 Training loss: 7.003636360168457
2025-12-09 12:37:42.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.0029740540581879703 Training loss: 6.9135942459106445
2025-12-09 12:37:43.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0029738807227910093 Training loss: 6.1534881591796875
2025-12-09 12:37:43.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.002973706815409715 Training loss: 6.785772800445557
2025-12-09 12:37:44.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.0029735323361115775 Training loss: 6.801372528076172
2025-12-09 12:37:44.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.002973357284964309 Training loss: 6.649014949798584
2025-12-09 12:37:45.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.0029731816620358425 Training loss: 7.086587905883789
2025-12-09 12:37:45.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.002973005467394334 Training loss: 6.706903457641602
2025-12-09 12:37:46.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.0029728287011081627 Training loss: 6.618128299713135
2025-12-09 12:37:46.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.002972651363245927 Training loss: 7.428765773773193
2025-12-09 12:37:47.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.002972473453876448 Training loss: 6.6439619064331055
2025-12-09 12:37:47.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.0029722949730687687 Training loss: 6.677760124206543
2025-12-09 12:37:48.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.0029721159208921546 Training loss: 7.00337553024292
2025-12-09 12:37:48.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.0029719362974160927 Training loss: 6.575199127197266
2025-12-09 12:37:49.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.0029717561027102907 Training loss: 7.038753032684326
2025-12-09 12:37:49.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.002971575336844679 Training loss: 6.997184753417969
2025-12-09 12:37:50.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.002971393999889409 Training loss: 7.592228889465332
2025-12-09 12:37:50.794 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.002971212091914854 Training loss: 6.936263561248779
2025-12-09 12:37:51.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0029710296129916093 Training loss: 6.748647689819336
2025-12-09 12:37:51.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.0029708465631904913 Training loss: 6.81915807723999
2025-12-09 12:37:52.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.002970662942582538 Training loss: 6.620545864105225
2025-12-09 12:37:52.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.002970478751239009 Training loss: 6.957313060760498
2025-12-09 12:37:53.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.0029702939892313853 Training loss: 7.762955665588379
2025-12-09 12:37:53.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.002970108656631369 Training loss: 6.698115348815918
2025-12-09 12:37:54.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.002969922753510885 Training loss: 7.333410739898682
2025-12-09 12:37:54.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.002969736279942078 Training loss: 6.837406635284424
2025-12-09 12:37:55.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.002969549235997315 Training loss: 6.744839668273926
2025-12-09 12:37:55.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.002969361621749184 Training loss: 6.8378987312316895
2025-12-09 12:37:56.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.002969173437270495 Training loss: 6.629708766937256
2025-12-09 12:37:56.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.0029689846826342773 Training loss: 6.974034786224365
2025-12-09 12:37:57.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.002968795357913784 Training loss: 6.874568462371826
2025-12-09 12:37:57.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.0029686054631824885 Training loss: 6.707359790802002
2025-12-09 12:37:58.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0029684149985140847 Training loss: 6.7080864906311035
2025-12-09 12:37:58.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0029682239639824883 Training loss: 7.887223720550537
2025-12-09 12:37:59.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.002968032359661836 Training loss: 7.660674095153809
2025-12-09 12:37:59.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.002967840185626486 Training loss: 7.206418991088867
2025-12-09 12:38:00.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.0029676474419510174 Training loss: 7.124353885650635
2025-12-09 12:38:00.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0029674541287102296 Training loss: 6.769044876098633
2025-12-09 12:38:01.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.002967260245979144 Training loss: 6.578869819641113
2025-12-09 12:38:01.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.002967065793833003 Training loss: 6.832899570465088
2025-12-09 12:38:02.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.002966870772347269 Training loss: 6.9586052894592285
2025-12-09 12:38:02.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.0029666751815976273 Training loss: 6.806642055511475
2025-12-09 12:38:03.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.0029664790216599813 Training loss: 6.776961803436279
2025-12-09 12:38:03.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.0029662822926104578 Training loss: 6.831850051879883
2025-12-09 12:38:04.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.0029660849945254038 Training loss: 6.9903645515441895
2025-12-09 12:38:04.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.0029658871274813856 Training loss: 7.433866500854492
2025-12-09 12:38:05.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0029656886915551926 Training loss: 6.566164493560791
2025-12-09 12:38:05.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.0029654896868238335 Training loss: 6.949564456939697
2025-12-09 12:38:06.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.0029652901133645384 Training loss: 6.544183731079102
2025-12-09 12:38:06.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.0029650899712547574 Training loss: 6.439774990081787
2025-12-09 12:38:07.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.0029648892605721624 Training loss: 6.6423516273498535
2025-12-09 12:38:07.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0029646879813946445 Training loss: 6.686071395874023
2025-12-09 12:38:08.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.002964486133800317 Training loss: 7.162867069244385
2025-12-09 12:38:08.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.0029642837178675122 Training loss: 6.811307907104492
2025-12-09 12:38:09.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.002964080733674784 Training loss: 6.939168930053711
2025-12-09 12:38:09.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.0029638771813009076 Training loss: 6.66300106048584
2025-12-09 12:38:10.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.002963673060824877 Training loss: 6.423875331878662
2025-12-09 12:38:10.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.0029634683723259066 Training loss: 7.169328212738037
2025-12-09 12:38:11.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.0029632631158834333 Training loss: 7.231806755065918
2025-12-09 12:38:11.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.0029630572915771117 Training loss: 6.6983489990234375
2025-12-09 12:38:12.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.00296285089948682 Training loss: 6.7316575050354
2025-12-09 12:38:12.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.0029626439396926536 Training loss: 6.884973049163818
2025-12-09 12:38:13.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.0029624364122749296 Training loss: 6.809420108795166
2025-12-09 12:38:13.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.0029622283173141866 Training loss: 7.123557090759277
2025-12-09 12:38:14.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.00296201965489118 Training loss: 7.013304710388184
2025-12-09 12:38:14.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.00296181042508689 Training loss: 7.219738006591797
2025-12-09 12:38:15.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.0029616006279825128 Training loss: 6.57124662399292
2025-12-09 12:38:15.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.002961390263659467 Training loss: 7.200765132904053
2025-12-09 12:38:16.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.0029611793321993912 Training loss: 6.881858825683594
2025-12-09 12:38:16.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.0029609678336841444 Training loss: 6.73156213760376
2025-12-09 12:38:17.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.0029607557681958037 Training loss: 6.840055465698242
2025-12-09 12:38:17.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.0029605431358166686 Training loss: 6.751256942749023
2025-12-09 12:38:18.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.002960329936629257 Training loss: 6.8547282218933105
2025-12-09 12:38:18.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.002960116170716308 Training loss: 6.606610298156738
2025-12-09 12:38:19.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.0029599018381607787 Training loss: 6.895498275756836
2025-12-09 12:38:19.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.0029596869390458485 Training loss: 6.400299072265625
2025-12-09 12:38:20.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.002959471473454915 Training loss: 6.948471546173096
2025-12-09 12:38:20.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.0029592554414715967 Training loss: 6.668764591217041
2025-12-09 12:38:21.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.002959038843179731 Training loss: 6.665197849273682
2025-12-09 12:38:21.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.0029588216786633763 Training loss: 7.633956432342529
2025-12-09 12:38:22.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.0029586039480068087 Training loss: 6.521892070770264
2025-12-09 12:38:22.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.0029583856512945257 Training loss: 6.637174129486084
2025-12-09 12:38:23.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.0029581667886112435 Training loss: 7.057545185089111
2025-12-09 12:38:23.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.0029579473600418998 Training loss: 6.81433629989624
2025-12-09 12:38:24.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.0029577273656716495 Training loss: 6.692862510681152
2025-12-09 12:38:24.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.0029575068055858675 Training loss: 7.2000651359558105
2025-12-09 12:38:25.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.0029572856798701507 Training loss: 6.900725364685059
2025-12-09 12:38:25.841 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0029570639886103123 Training loss: 6.882081508636475
2025-12-09 12:38:26.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0029568417318923865 Training loss: 6.7578043937683105
2025-12-09 12:38:26.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.002956618909802627 Training loss: 6.776646137237549
2025-12-09 12:38:27.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.0029563955224275068 Training loss: 8.183306694030762
2025-12-09 12:38:27.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.0029561715698537185 Training loss: 6.944852828979492
2025-12-09 12:38:28.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0029559470521681726 Training loss: 6.794253826141357
2025-12-09 12:38:28.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.002955721969458001 Training loss: 6.882577419281006
2025-12-09 12:38:29.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.0029554963218105536 Training loss: 6.814934730529785
2025-12-09 12:38:29.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.0029552701093133998 Training loss: 6.5126953125
2025-12-09 12:38:30.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.0029550433320543286 Training loss: 6.43874454498291
2025-12-09 12:38:30.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.0029548159901213473 Training loss: 6.6571574211120605
2025-12-09 12:38:31.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.0029545880836026835 Training loss: 6.974604606628418
2025-12-09 12:38:31.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.0029543596125867827 Training loss: 6.627739429473877
2025-12-09 12:38:32.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.00295413057716231 Training loss: 6.822383403778076
2025-12-09 12:38:32.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.00295390097741815 Training loss: 6.724428653717041
2025-12-09 12:38:33.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.0029536708134434058 Training loss: 6.50963020324707
2025-12-09 12:38:33.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.002953440085327399 Training loss: 6.650629997253418
2025-12-09 12:38:34.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0029532087931596718 Training loss: 6.979325771331787
2025-12-09 12:38:34.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.0029529769370299826 Training loss: 6.9570393562316895
2025-12-09 12:38:35.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.0029527445170283114 Training loss: 7.357726097106934
2025-12-09 12:38:35.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.002952511533244856 Training loss: 6.760787010192871
2025-12-09 12:38:36.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.0029522779857700326 Training loss: 7.033881664276123
2025-12-09 12:38:36.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.0029520438746944754 Training loss: 7.388489246368408
2025-12-09 12:38:37.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.00295180920010904 Training loss: 6.303997993469238
2025-12-09 12:38:37.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.0029515739621047976 Training loss: 6.9268364906311035
2025-12-09 12:38:38.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.0029513381607730402 Training loss: 6.815152645111084
2025-12-09 12:38:38.873 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.002951101796205278 Training loss: 6.741970062255859
2025-12-09 12:38:39.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.0029508648684932392 Training loss: 6.633419036865234
2025-12-09 12:38:39.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.0029506273777288703 Training loss: 7.198648452758789
2025-12-09 12:38:40.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.002950389324004337 Training loss: 6.433346271514893
2025-12-09 12:38:40.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.002950150707412024 Training loss: 6.720265865325928
2025-12-09 12:38:41.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.002949911528044533 Training loss: 6.816489219665527
2025-12-09 12:38:41.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.0029496717859946848 Training loss: 6.293900966644287
2025-12-09 12:38:42.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.0029494314813555194 Training loss: 6.863730430603027
2025-12-09 12:38:42.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.002949190614220294 Training loss: 6.492696285247803
2025-12-09 12:38:43.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.002948949184682484 Training loss: 6.945675849914551
2025-12-09 12:38:43.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0029487071928357834 Training loss: 6.776034832000732
2025-12-09 12:38:44.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0029484646387741057 Training loss: 6.680861949920654
2025-12-09 12:38:44.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.0029482215225915803 Training loss: 7.314239501953125
2025-12-09 12:38:45.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.0029479778443825553 Training loss: 7.203658103942871
2025-12-09 12:38:45.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.002947733604241599 Training loss: 6.773258209228516
2025-12-09 12:38:46.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.002947488802263496 Training loss: 6.556902885437012
2025-12-09 12:38:46.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.0029472434385432477 Training loss: 6.769341945648193
2025-12-09 12:38:47.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.0029469975131760765 Training loss: 6.948805809020996
2025-12-09 12:38:47.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.0029467510262574203 Training loss: 6.69655179977417
2025-12-09 12:38:48.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.0029465039778829366 Training loss: 7.1875901222229
2025-12-09 12:38:48.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.0029462563681484995 Training loss: 6.670177936553955
2025-12-09 12:38:49.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.002946008197150202 Training loss: 7.32779598236084
2025-12-09 12:38:49.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.0029457594649843536 Training loss: 7.497650623321533
2025-12-09 12:38:50.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.0029455101717474836 Training loss: 7.024377822875977
2025-12-09 12:38:50.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.0029452603175363365 Training loss: 6.8800554275512695
2025-12-09 12:38:51.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0029450099024478766 Training loss: 6.701206207275391
2025-12-09 12:38:51.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.002944758926579285 Training loss: 6.64777946472168
2025-12-09 12:38:52.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.002944507390027961 Training loss: 6.462193965911865
2025-12-09 12:38:52.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.0029442552928915203 Training loss: 6.796241760253906
2025-12-09 12:38:53.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.002944002635267797 Training loss: 6.478754997253418
2025-12-09 12:38:53.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.002943749417254843 Training loss: 6.521158218383789
2025-12-09 12:38:54.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.0029434956389509264 Training loss: 7.124505519866943
2025-12-09 12:38:54.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.0029432413004545346 Training loss: 6.608340740203857
2025-12-09 12:38:55.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.002942986401864371 Training loss: 6.965118408203125
2025-12-09 12:38:55.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.002942730943279357 Training loss: 6.665293216705322
2025-12-09 12:38:56.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.0029424749247986305 Training loss: 6.513140678405762
2025-12-09 12:38:56.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.002942218346521548 Training loss: 6.560479640960693
2025-12-09 12:38:57.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.0029419612085476816 Training loss: 6.494155406951904
2025-12-09 12:38:57.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.0029417035109768224 Training loss: 6.778360366821289
2025-12-09 12:38:58.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.002941445253908978 Training loss: 6.668017387390137
2025-12-09 12:38:58.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.0029411864374443717 Training loss: 6.670901775360107
2025-12-09 12:38:59.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.002940927061683446 Training loss: 7.537123680114746
2025-12-09 12:38:59.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.002940667126726859 Training loss: 6.589272975921631
2025-12-09 12:39:00.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0029404066326754875 Training loss: 6.531635761260986
2025-12-09 12:39:00.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.0029401455796304234 Training loss: 6.877689361572266
2025-12-09 12:39:01.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.0029398839676929756 Training loss: 7.01445198059082
2025-12-09 12:39:01.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.002939621796964672 Training loss: 7.210219383239746
2025-12-09 12:39:02.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.002939359067547255 Training loss: 6.912619113922119
2025-12-09 12:39:02.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.002939095779542685 Training loss: 6.652957439422607
2025-12-09 12:39:03.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.0029388319330531385 Training loss: 7.162081241607666
2025-12-09 12:39:03.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.0029385675281810106 Training loss: 6.568964958190918
2025-12-09 12:39:04.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.00293830256502891 Training loss: 6.588897228240967
2025-12-09 12:39:04.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.0029380370436996642 Training loss: 5.9884233474731445
2025-12-09 12:39:05.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.0029377709642963174 Training loss: 6.9790167808532715
2025-12-09 12:39:05.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.0029375043269221296 Training loss: 6.8766560554504395
2025-12-09 12:39:06.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.002937237131680577 Training loss: 7.125431537628174
2025-12-09 12:39:06.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.002936969378675354 Training loss: 6.790423393249512
2025-12-09 12:39:07.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.0029367010680103685 Training loss: 7.119289398193359
2025-12-09 12:39:07.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.0029364321997897482 Training loss: 6.169449329376221
2025-12-09 12:39:08.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.0029361627741178358 Training loss: 6.7724528312683105
2025-12-09 12:39:08.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.002935892791099189 Training loss: 6.91564416885376
2025-12-09 12:39:09.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.002935622250838583 Training loss: 6.958348751068115
2025-12-09 12:39:09.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.0029353511534410104 Training loss: 6.818078517913818
2025-12-09 12:39:10.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.002935079499011677 Training loss: 6.5077338218688965
2025-12-09 12:39:10.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.0029348072876560086 Training loss: 6.7684125900268555
2025-12-09 12:39:11.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.0029345345194796437 Training loss: 6.776096820831299
2025-12-09 12:39:11.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.0029342611945884388 Training loss: 6.69453763961792
2025-12-09 12:39:12.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.0029339873130884656 Training loss: 7.012258052825928
2025-12-09 12:39:12.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.0029337128750860125 Training loss: 6.732998847961426
2025-12-09 12:39:13.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.0029334378806875837 Training loss: 6.895816326141357
2025-12-09 12:39:13.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.002933162329999899 Training loss: 7.049030303955078
2025-12-09 12:39:14.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.002932886223129894 Training loss: 6.48617696762085
2025-12-09 12:39:14.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.0029326095601847203 Training loss: 7.391583442687988
2025-12-09 12:39:15.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.0029323323412717463 Training loss: 6.214669704437256
2025-12-09 12:39:15.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.0029320545664985537 Training loss: 6.508408546447754
2025-12-09 12:39:16.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.0029317762359729427 Training loss: 6.680190563201904
2025-12-09 12:39:16.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.002931497349802928 Training loss: 6.536350727081299
2025-12-09 12:39:17.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.002931217908096739 Training loss: 6.5452375411987305
2025-12-09 12:39:17.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.0029309379109628223 Training loss: 6.714616775512695
2025-12-09 12:39:18.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.0029306573585098387 Training loss: 6.722191333770752
2025-12-09 12:39:18.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.0029303762508466656 Training loss: 7.076136112213135
2025-12-09 12:39:19.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.0029300945880823956 Training loss: 6.355973243713379
2025-12-09 12:39:19.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.0029298123703263364 Training loss: 6.594247341156006
2025-12-09 12:39:20.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.002929529597688011 Training loss: 6.593389987945557
2025-12-09 12:39:20.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.0029292462702771574 Training loss: 6.64848518371582
2025-12-09 12:39:21.491 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.0029289623882037302 Training loss: 6.90720272064209
2025-12-09 12:39:21.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.0029286779515778983 Training loss: 7.0003886222839355
2025-12-09 12:39:22.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.0029283929605100458 Training loss: 6.83302640914917
2025-12-09 12:39:22.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0029281074151107727 Training loss: 6.658051013946533
2025-12-09 12:39:23.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.002927821315490893 Training loss: 6.630795955657959
2025-12-09 12:39:23.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.0029275346617614363 Training loss: 6.514383316040039
2025-12-09 12:39:24.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.002927247454033648 Training loss: 6.695343017578125
2025-12-09 12:39:24.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.002926959692418988 Training loss: 6.870854377746582
2025-12-09 12:39:25.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.0029266713770291293 Training loss: 6.871775150299072
2025-12-09 12:39:26.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.0029263825079759638 Training loss: 6.98901891708374
2025-12-09 12:39:26.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.0029260930853715937 Training loss: 6.6783647537231445
2025-12-09 12:39:27.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.0029258031093283396 Training loss: 6.986059188842773
2025-12-09 12:39:27.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0029255125799587355 Training loss: 6.992969512939453
2025-12-09 12:39:28.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.002925221497375529 Training loss: 7.036327838897705
2025-12-09 12:39:28.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.0029249298616916856 Training loss: 6.266313552856445
2025-12-09 12:39:29.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.002924637673020382 Training loss: 6.653051853179932
2025-12-09 12:39:29.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.002924344931475011 Training loss: 7.093968391418457
2025-12-09 12:39:30.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.0029240516371691803 Training loss: 6.80993127822876
2025-12-09 12:39:30.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.002923757790216711 Training loss: 6.2562456130981445
2025-12-09 12:39:31.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.0029234633907316405 Training loss: 6.774490833282471
2025-12-09 12:39:31.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.0029231684388282184 Training loss: 6.726069927215576
2025-12-09 12:39:32.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.00292287293462091 Training loss: 6.645171642303467
2025-12-09 12:39:32.536 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.0029225768782243956 Training loss: 6.831369400024414
2025-12-09 12:39:33.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.0029222802697535678 Training loss: 7.307094097137451
2025-12-09 12:39:33.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.002921983109323535 Training loss: 7.31612491607666
2025-12-09 12:39:34.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0029216853970496196 Training loss: 6.951561450958252
2025-12-09 12:39:34.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0029213871330473575 Training loss: 6.4504618644714355
2025-12-09 12:39:35.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.002921088317432499 Training loss: 6.382967948913574
2025-12-09 12:39:35.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.0029207889503210095 Training loss: 6.603499412536621
2025-12-09 12:39:36.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.002920489031829067 Training loss: 6.756002426147461
2025-12-09 12:39:36.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.002920188562073063 Training loss: 6.83304500579834
2025-12-09 12:39:37.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0029198875411696056 Training loss: 6.501041889190674
2025-12-09 12:39:37.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.0029195859692355145 Training loss: 6.282521724700928
2025-12-09 12:39:38.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.002919283846387824 Training loss: 7.052137851715088
2025-12-09 12:39:38.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.0029189811727437813 Training loss: 6.50005578994751
2025-12-09 12:39:39.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.002918677948420849 Training loss: 7.853137969970703
2025-12-09 12:39:39.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.0029183741735367024 Training loss: 6.588970184326172
2025-12-09 12:39:40.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.0029180698482092304 Training loss: 6.546586036682129
2025-12-09 12:39:40.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.0029177649725565355 Training loss: 6.558159351348877
2025-12-09 12:39:41.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.0029174595466969345 Training loss: 6.303953170776367
2025-12-09 12:39:41.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.0029171535707489572 Training loss: 7.106457710266113
2025-12-09 12:39:42.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.0029168470448313463 Training loss: 6.632439613342285
2025-12-09 12:39:42.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.002916539969063059 Training loss: 6.854753017425537
2025-12-09 12:39:43.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.0029162323435632654 Training loss: 6.632949352264404
2025-12-09 12:39:43.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.002915924168451349 Training loss: 6.618130683898926
2025-12-09 12:39:44.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.002915615443846906 Training loss: 6.761684417724609
2025-12-09 12:39:44.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0029153061698697475 Training loss: 6.305741786956787
2025-12-09 12:39:45.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0029149963466398956 Training loss: 6.553879261016846
2025-12-09 12:39:45.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.002914685974277587 Training loss: 6.633080959320068
2025-12-09 12:39:46.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.002914375052903271 Training loss: 6.975075721740723
2025-12-09 12:39:46.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.002914063582637611 Training loss: 7.526063919067383
2025-12-09 12:39:47.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.002913751563601481 Training loss: 6.293928146362305
2025-12-09 12:39:47.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.0029134389959159708 Training loss: 6.794498443603516
2025-12-09 12:39:48.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0029131258797023816 Training loss: 6.401054859161377
2025-12-09 12:39:48.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.0029128122150822266 Training loss: 6.6570329666137695
2025-12-09 12:39:49.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.0029124980021772344 Training loss: 7.192142009735107
2025-12-09 12:39:49.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0029121832411093443 Training loss: 6.719921112060547
2025-12-09 12:39:50.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.0029118679320007087 Training loss: 7.010032653808594
2025-12-09 12:39:50.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.0029115520749736935 Training loss: 7.00280237197876
2025-12-09 12:39:51.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.0029112356701508756 Training loss: 6.795374870300293
2025-12-09 12:39:51.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.0029109187176550463 Training loss: 7.066009044647217
2025-12-09 12:39:52.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.0029106012176092085 Training loss: 7.212573528289795
2025-12-09 12:39:52.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0029102831701365785 Training loss: 6.565499305725098
2025-12-09 12:39:53.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.0029099645753605827 Training loss: 7.900394439697266
2025-12-09 12:39:53.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.002909645433404863 Training loss: 6.6616129875183105
2025-12-09 12:39:54.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.0029093257443932713 Training loss: 6.961087226867676
2025-12-09 12:39:54.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.0029090055084498734 Training loss: 6.35503625869751
2025-12-09 12:39:55.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.0029086847256989457 Training loss: 6.698184013366699
2025-12-09 12:39:55.623 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0029083633962649785 Training loss: 6.639029502868652
2025-12-09 12:39:56.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.0029080415202726727 Training loss: 6.50530481338501
2025-12-09 12:39:56.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0029077190978469432 Training loss: 6.560400009155273
2025-12-09 12:39:57.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.0029073961291129153 Training loss: 7.127096176147461
2025-12-09 12:39:57.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.0029070726141959265 Training loss: 6.615300178527832
2025-12-09 12:39:58.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.002906748553221527 Training loss: 7.103059768676758
2025-12-09 12:39:58.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.0029064239463154782 Training loss: 6.558083534240723
2025-12-09 12:39:59.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.002906098793603754 Training loss: 6.948427677154541
2025-12-09 12:39:59.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.00290577309521254 Training loss: 6.6057353019714355
2025-12-09 12:40:00.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.002905446851268233 Training loss: 6.519852161407471
2025-12-09 12:40:00.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.002905120061897442 Training loss: 6.774648189544678
2025-12-09 12:40:01.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.002904792727226987 Training loss: 6.489950180053711
2025-12-09 12:40:01.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.002904464847383902 Training loss: 6.545602798461914
2025-12-09 12:40:02.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.002904136422495429 Training loss: 6.567081451416016
2025-12-09 12:40:02.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0029038074526890243 Training loss: 6.539454460144043
2025-12-09 12:40:03.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.002903477938092354 Training loss: 7.093264579772949
2025-12-09 12:40:03.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.002903147878833296 Training loss: 6.701242923736572
2025-12-09 12:40:04.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.002902817275039941 Training loss: 6.875256538391113
2025-12-09 12:40:04.662 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.0029024861268405894 Training loss: 6.484633922576904
2025-12-09 12:40:05.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.0029021544343637525 Training loss: 6.320034027099609
2025-12-09 12:40:05.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.0029018221977381554 Training loss: 6.436117172241211
2025-12-09 12:40:06.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.0029014894170927307 Training loss: 6.794443130493164
2025-12-09 12:40:06.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.0029011560925566253 Training loss: 6.554365158081055
2025-12-09 12:40:07.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.002900822224259196 Training loss: 6.6497483253479
2025-12-09 12:40:07.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.0029004878123300095 Training loss: 6.412826061248779
2025-12-09 12:40:08.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.0029001528568988457 Training loss: 6.993167400360107
2025-12-09 12:40:08.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.0028998173580956936 Training loss: 6.7214226722717285
2025-12-09 12:40:09.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.002899481316050754 Training loss: 6.256387710571289
2025-12-09 12:40:09.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.0028991447308944385 Training loss: 6.82022762298584
2025-12-09 12:40:10.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.002898807602757369 Training loss: 6.663837909698486
2025-12-09 12:40:10.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.0028984699317703777 Training loss: 6.661301612854004
2025-12-09 12:40:11.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.0028981317180645093 Training loss: 7.111856460571289
2025-12-09 12:40:11.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.002897792961771017 Training loss: 6.805153846740723
2025-12-09 12:40:12.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.002897453663021366 Training loss: 6.574553966522217
2025-12-09 12:40:12.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.002897113821947231 Training loss: 6.717278480529785
2025-12-09 12:40:13.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.0028967734386804982 Training loss: 6.4227142333984375
2025-12-09 12:40:13.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.002896432513353264 Training loss: 6.592960834503174
2025-12-09 12:40:14.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.002896091046097834 Training loss: 6.316410064697266
2025-12-09 12:40:14.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.0028957490370467255 Training loss: 6.56683349609375
2025-12-09 12:40:15.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.0028954064863326652 Training loss: 6.743598461151123
2025-12-09 12:40:15.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.002895063394088591 Training loss: 7.205443382263184
2025-12-09 12:40:16.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.0028947197604476493 Training loss: 6.4570088386535645
2025-12-09 12:40:16.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.002894375585543199 Training loss: 6.493547439575195
2025-12-09 12:40:17.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.0028940308695088062 Training loss: 7.190380096435547
2025-12-09 12:40:17.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.002893685612478249 Training loss: 6.648975372314453
2025-12-09 12:40:18.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.0028933398145855158 Training loss: 6.552767276763916
2025-12-09 12:40:18.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.0028929934759648022 Training loss: 7.376919746398926
2025-12-09 12:40:19.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.0028926465967505175 Training loss: 6.416475772857666
2025-12-09 12:40:19.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.002892299177077277 Training loss: 6.026702404022217
2025-12-09 12:40:20.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.0028919512170799085 Training loss: 6.801113128662109
2025-12-09 12:40:20.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.0028916027168934483 Training loss: 6.985145568847656
2025-12-09 12:40:21.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.0028912536766531423 Training loss: 6.595853328704834
2025-12-09 12:40:21.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.0028909040964944462 Training loss: 6.681329250335693
2025-12-09 12:40:22.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.002890553976553025 Training loss: 6.955514430999756
2025-12-09 12:40:22.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.002890203316964755 Training loss: 6.3320465087890625
2025-12-09 12:40:23.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.002889852117865718 Training loss: 6.70095157623291
2025-12-09 12:40:23.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.002889500379392209 Training loss: 6.809141635894775
2025-12-09 12:40:24.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.0028891481016807305 Training loss: 6.555219650268555
2025-12-09 12:40:24.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.0028887952848679946 Training loss: 6.810851573944092
2025-12-09 12:40:25.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.002888441929090922 Training loss: 6.509577751159668
2025-12-09 12:40:25.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.002888088034486645 Training loss: 6.851680755615234
2025-12-09 12:40:26.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.0028877336011925007 Training loss: 6.532039642333984
2025-12-09 12:40:26.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.00288737862934604 Training loss: 7.507720947265625
2025-12-09 12:40:27.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 726 LR: 0.002887023119085019 Training loss: 6.798548698425293
2025-12-09 12:40:27.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 727 LR: 0.002886667070547405 Training loss: 7.1508612632751465
2025-12-09 12:40:28.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 728 LR: 0.002886310483871373 Training loss: 6.9926981925964355
2025-12-09 12:40:28.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 729 LR: 0.0028859533591953077 Training loss: 6.188762664794922
2025-12-09 12:40:29.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 730 LR: 0.0028855956966578025 Training loss: 6.445092678070068
2025-12-09 12:40:29.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 731 LR: 0.002885237496397659 Training loss: 6.565018177032471
2025-12-09 12:40:30.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 732 LR: 0.0028848787585538872 Training loss: 6.2560625076293945
2025-12-09 12:40:30.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 733 LR: 0.0028845194832657064 Training loss: 6.556583881378174
2025-12-09 12:40:31.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 734 LR: 0.002884159670672545 Training loss: 6.6207380294799805
2025-12-09 12:40:31.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 735 LR: 0.002883799320914039 Training loss: 6.391359329223633
