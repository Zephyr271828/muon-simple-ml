2025-12-09 12:09:35.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 3e-05 Training loss: 4.923840522766113
2025-12-09 12:09:35.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 6e-05 Training loss: 4.878653049468994
2025-12-09 12:09:35.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 8.999999999999999e-05 Training loss: 4.7015910148620605
2025-12-09 12:09:35.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.00012 Training loss: 4.927030563354492
2025-12-09 12:09:35.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.00015000000000000001 Training loss: 4.923947334289551
2025-12-09 12:09:35.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.00017999999999999998 Training loss: 4.854702949523926
2025-12-09 12:09:35.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.00021000000000000004 Training loss: 4.95744514465332
2025-12-09 12:09:35.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.00024 Training loss: 4.833139419555664
2025-12-09 12:09:35.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.00027 Training loss: 4.952014923095703
2025-12-09 12:09:35.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.00030000000000000003 Training loss: 4.889257907867432
2025-12-09 12:09:35.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00033 Training loss: 4.946124076843262
2025-12-09 12:09:35.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00035999999999999997 Training loss: 4.855247497558594
2025-12-09 12:09:35.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00039000000000000005 Training loss: 4.914652347564697
2025-12-09 12:09:35.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00042000000000000007 Training loss: 4.802492141723633
2025-12-09 12:09:35.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00045 Training loss: 4.796213626861572
2025-12-09 12:09:35.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00048 Training loss: 4.863239288330078
2025-12-09 12:09:35.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00051 Training loss: 4.81233549118042
2025-12-09 12:09:35.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00054 Training loss: 4.912334442138672
2025-12-09 12:09:35.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00057 Training loss: 4.825279712677002
2025-12-09 12:09:35.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0006000000000000001 Training loss: 4.568806171417236
2025-12-09 12:09:35.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00063 Training loss: 4.9300150871276855
2025-12-09 12:09:35.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00066 Training loss: 4.780421257019043
2025-12-09 12:09:35.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0006900000000000001 Training loss: 4.755265712738037
2025-12-09 12:09:35.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0007199999999999999 Training loss: 4.698812961578369
2025-12-09 12:09:35.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00075 Training loss: 4.6635003089904785
2025-12-09 12:09:35.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0007800000000000001 Training loss: 4.659378528594971
2025-12-09 12:09:35.848 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0008100000000000001 Training loss: 4.577142715454102
2025-12-09 12:09:35.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0008400000000000001 Training loss: 4.613121509552002
2025-12-09 12:09:35.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00087 Training loss: 4.575951099395752
2025-12-09 12:09:35.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0009 Training loss: 4.554028511047363
2025-12-09 12:09:35.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00093 Training loss: 4.5075764656066895
2025-12-09 12:09:35.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00096 Training loss: 4.574678897857666
2025-12-09 12:09:36.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00099 Training loss: 4.42556619644165
2025-12-09 12:09:36.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00102 Training loss: 4.521207809448242
2025-12-09 12:09:36.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00105 Training loss: 4.466638088226318
2025-12-09 12:09:36.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00108 Training loss: 4.458279132843018
2025-12-09 12:09:36.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00111 Training loss: 4.35275936126709
2025-12-09 12:09:36.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00114 Training loss: 4.492370128631592
2025-12-09 12:09:36.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00117 Training loss: 4.332821369171143
2025-12-09 12:09:36.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0012000000000000001 Training loss: 4.394385814666748
2025-12-09 12:09:36.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00123 Training loss: 4.366175174713135
2025-12-09 12:09:36.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00126 Training loss: 4.370734214782715
2025-12-09 12:09:36.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00129 Training loss: 4.3082709312438965
2025-12-09 12:09:36.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00132 Training loss: 4.108285903930664
2025-12-09 12:09:36.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00135 Training loss: 4.264075756072998
2025-12-09 12:09:36.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0013800000000000002 Training loss: 4.266147136688232
2025-12-09 12:09:36.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00141 Training loss: 4.236865997314453
2025-12-09 12:09:36.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0014399999999999999 Training loss: 4.240080833435059
2025-12-09 12:09:36.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00147 Training loss: 4.2355451583862305
2025-12-09 12:09:36.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0015 Training loss: 4.126309871673584
2025-12-09 12:09:36.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0015300000000000001 Training loss: 4.146917819976807
2025-12-09 12:09:36.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0015600000000000002 Training loss: 4.329170227050781
2025-12-09 12:09:36.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.00159 Training loss: 4.186344623565674
2025-12-09 12:09:36.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0016200000000000001 Training loss: 4.135413646697998
2025-12-09 12:09:36.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0016500000000000002 Training loss: 4.23691463470459
2025-12-09 12:09:36.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0016800000000000003 Training loss: 4.124946594238281
2025-12-09 12:09:36.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00171 Training loss: 3.950423240661621
2025-12-09 12:09:36.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00174 Training loss: 4.20054292678833
2025-12-09 12:09:36.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0017699999999999999 Training loss: 3.9687798023223877
2025-12-09 12:09:36.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0018 Training loss: 4.117016792297363
2025-12-09 12:09:36.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00183 Training loss: 3.996483564376831
2025-12-09 12:09:36.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00186 Training loss: 4.181003570556641
2025-12-09 12:09:36.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00189 Training loss: 4.0851240158081055
2025-12-09 12:09:36.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00192 Training loss: 4.0237226486206055
2025-12-09 12:09:36.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0019500000000000001 Training loss: 3.953470230102539
2025-12-09 12:09:36.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00198 Training loss: 4.149335861206055
2025-12-09 12:09:36.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00201 Training loss: 4.200077056884766
2025-12-09 12:09:36.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00204 Training loss: 3.975933313369751
2025-12-09 12:09:36.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00207 Training loss: 3.794203996658325
2025-12-09 12:09:36.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0021 Training loss: 3.926321268081665
2025-12-09 12:09:36.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00213 Training loss: 3.693568706512451
2025-12-09 12:09:37.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.00216 Training loss: 3.9956607818603516
2025-12-09 12:09:37.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00219 Training loss: 4.07109260559082
2025-12-09 12:09:37.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00222 Training loss: 3.886039972305298
2025-12-09 12:09:37.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0022500000000000003 Training loss: 3.9603614807128906
2025-12-09 12:09:37.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00228 Training loss: 4.161355495452881
2025-12-09 12:09:37.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.00231 Training loss: 3.8795723915100098
2025-12-09 12:09:37.175 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.00234 Training loss: 3.90464448928833
2025-12-09 12:09:37.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00237 Training loss: 3.9734816551208496
2025-12-09 12:09:37.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0024000000000000002 Training loss: 3.7363264560699463
2025-12-09 12:09:37.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0024300000000000003 Training loss: 3.871445894241333
2025-12-09 12:09:37.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00246 Training loss: 3.7236404418945312
2025-12-09 12:09:37.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00249 Training loss: 3.727752208709717
2025-12-09 12:09:37.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00252 Training loss: 3.959074020385742
2025-12-09 12:09:37.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00255 Training loss: 3.5647802352905273
2025-12-09 12:09:37.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00258 Training loss: 3.711250066757202
2025-12-09 12:09:37.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00261 Training loss: 3.9737517833709717
2025-12-09 12:09:37.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00264 Training loss: 3.4828789234161377
2025-12-09 12:09:37.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.00267 Training loss: 3.649932622909546
2025-12-09 12:09:37.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0027 Training loss: 3.865278959274292
2025-12-09 12:09:37.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0027300000000000002 Training loss: 3.5720324516296387
2025-12-09 12:09:37.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0027600000000000003 Training loss: 3.845717430114746
2025-12-09 12:09:37.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.0027900000000000004 Training loss: 3.5411970615386963
2025-12-09 12:09:37.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00282 Training loss: 3.540647506713867
2025-12-09 12:09:37.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00285 Training loss: 3.8607163429260254
2025-12-09 12:09:37.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0028799999999999997 Training loss: 3.700941562652588
2025-12-09 12:09:37.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.00291 Training loss: 3.6051793098449707
2025-12-09 12:09:37.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00294 Training loss: 3.859027147293091
2025-12-09 12:09:37.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00297 Training loss: 3.6391780376434326
2025-12-09 12:09:37.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.003 Training loss: 3.509237051010132
2025-12-09 12:09:37.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0029999125880491853 Training loss: 3.5537185668945312
2025-12-09 12:09:37.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.0029996503623845394 Training loss: 3.847893238067627
2025-12-09 12:09:37.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0029992133535682725 Training loss: 3.6919569969177246
2025-12-09 12:09:37.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.002998601612533441 Training loss: 3.5895020961761475
2025-12-09 12:09:37.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0029978152105780156 Training loss: 3.860852003097534
2025-12-09 12:09:37.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0029968542393565677 Training loss: 3.9038877487182617
2025-12-09 12:09:37.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0029957188108695894 Training loss: 3.6476645469665527
2025-12-09 12:09:37.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.00299440905745044 Training loss: 3.6206631660461426
2025-12-09 12:09:37.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.002992925131749921 Training loss: 3.64192533493042
2025-12-09 12:09:38.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.0029912672067184862 Training loss: 3.4459705352783203
2025-12-09 12:09:38.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.0029894354755860848 Training loss: 3.703874349594116
2025-12-09 12:09:38.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0029874301518396378 Training loss: 3.8924853801727295
2025-12-09 12:09:38.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0029852514691981603 Training loss: 3.6055502891540527
2025-12-09 12:09:38.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0029828996815855183 Training loss: 3.5867345333099365
2025-12-09 12:09:38.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.002980375063100836 Training loss: 3.6495914459228516
2025-12-09 12:09:38.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.00297767790798655 Training loss: 3.6307291984558105
2025-12-09 12:09:38.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.0029748085305941127 Training loss: 3.8905577659606934
2025-12-09 12:09:38.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.002971767265347359 Training loss: 3.6857242584228516
2025-12-09 12:09:38.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0029685544667035256 Training loss: 3.7084338665008545
2025-12-09 12:09:38.265 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.0029651705091119423 Training loss: 3.7946105003356934
2025-12-09 12:09:38.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.0029616157869703894 Training loss: 3.6394834518432617
2025-12-09 12:09:38.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.002957890714579128 Training loss: 3.7623848915100098
2025-12-09 12:09:38.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.0029539957260926184 Training loss: 3.7587320804595947
2025-12-09 12:09:38.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.002949931275468917 Training loss: 3.7453744411468506
2025-12-09 12:09:38.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0029456978364167667 Training loss: 3.4409561157226562
2025-12-09 12:09:38.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.0029412959023403904 Training loss: 3.5212302207946777
2025-12-09 12:09:38.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.002936725986281981 Training loss: 3.722450017929077
2025-12-09 12:09:38.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.002931988620861908 Training loss: 3.809114933013916
2025-12-09 12:09:38.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.002927084358216643 Training loss: 3.5855696201324463
2025-12-09 12:09:38.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.0029220137699344055 Training loss: 3.543316125869751
2025-12-09 12:09:38.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.0029167774469885483 Training loss: 3.7855305671691895
2025-12-09 12:09:38.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.002911375999668675 Training loss: 3.7140486240386963
2025-12-09 12:09:38.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.002905810057509516 Training loss: 3.502523899078369
2025-12-09 12:09:38.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.002900080269217554 Training loss: 3.765103816986084
2025-12-09 12:09:38.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.002894187302595419 Training loss: 3.731943130493164
2025-12-09 12:09:38.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0028881318444640564 Training loss: 3.5025429725646973
2025-12-09 12:09:38.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0028819146005826766 Training loss: 3.7730798721313477
2025-12-09 12:09:38.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.0028755362955665015 Training loss: 3.647186279296875
2025-12-09 12:09:38.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.0028689976728023103 Training loss: 3.678227424621582
2025-12-09 12:09:38.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0028622994943617985 Training loss: 3.3890206813812256
2025-12-09 12:09:38.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0028554425409127583 Training loss: 3.470898151397705
2025-12-09 12:09:38.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.002848427611628093 Training loss: 3.7437257766723633
2025-12-09 12:09:38.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0028412555240926746 Training loss: 3.8191263675689697
2025-12-09 12:09:38.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.002833927114208054 Training loss: 3.4686038494110107
2025-12-09 12:09:38.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0028264432360950355 Training loss: 3.5452489852905273
2025-12-09 12:09:38.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.0028188047619941343 Training loss: 3.2753593921661377
2025-12-09 12:09:38.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0028110125821639137 Training loss: 3.5916976928710938
2025-12-09 12:09:38.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.002803067604777227 Training loss: 3.8012876510620117
2025-12-09 12:09:39.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.0027949707558153703 Training loss: 3.4969658851623535
2025-12-09 12:09:39.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.002786722978960162 Training loss: 3.4961588382720947
2025-12-09 12:09:39.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.002778325235483954 Training loss: 3.3785288333892822
2025-12-09 12:09:39.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.0027697785041376007 Training loss: 3.9486608505249023
2025-12-09 12:09:39.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.002761083781036381 Training loss: 3.5863149166107178
2025-12-09 12:09:39.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.002752242079543907 Training loss: 3.365023612976074
2025-12-09 12:09:39.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.002743254430154012 Training loss: 3.4632790088653564
2025-12-09 12:09:39.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.002734121880370652 Training loss: 3.4236648082733154
2025-12-09 12:09:39.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.0027248454945858164 Training loss: 3.416590452194214
2025-12-09 12:09:39.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0027154263539554764 Training loss: 3.7196686267852783
2025-12-09 12:09:39.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.002705865556273575 Training loss: 3.489264726638794
2025-12-09 12:09:39.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.002696164215844081 Training loss: 3.413600444793701
2025-12-09 12:09:39.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.0026863234633511188 Training loss: 3.3347995281219482
2025-12-09 12:09:39.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.0026763444457271837 Training loss: 3.628021240234375
2025-12-09 12:09:39.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.002666228326019474 Training loss: 3.448188543319702
2025-12-09 12:09:39.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.002655976283254334 Training loss: 3.3065388202667236
2025-12-09 12:09:39.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0026455895122998404 Training loss: 3.484581708908081
2025-12-09 12:09:39.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.002635069223726543 Training loss: 3.4177489280700684
2025-12-09 12:09:39.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.002624416643666371 Training loss: 3.5092813968658447
2025-12-09 12:09:39.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0026136330136697305 Training loss: 3.2869908809661865
2025-12-09 12:09:39.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.0026027195905608006 Training loss: 3.8249239921569824
2025-12-09 12:09:39.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.0025916776462910542 Training loss: 3.1798930168151855
2025-12-09 12:09:39.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.00258050846779101 Training loss: 3.364429235458374
2025-12-09 12:09:39.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.0025692133568202442 Training loss: 3.620304584503174
2025-12-09 12:09:39.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.002557793629815669 Training loss: 3.4330501556396484
2025-12-09 12:09:39.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.0025462506177381045 Training loss: 3.668865203857422
2025-12-09 12:09:39.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.0025345856659171567 Training loss: 3.2132742404937744
2025-12-09 12:09:39.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.002522800133894418 Training loss: 3.2419652938842773
2025-12-09 12:09:39.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0025108953952650164 Training loss: 3.3809213638305664
2025-12-09 12:09:39.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0024988728375175216 Training loss: 3.2413041591644287
2025-12-09 12:09:39.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.002486733861872236 Training loss: 3.4544644355773926
2025-12-09 12:09:39.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.0024744798831178817 Training loss: 3.1036782264709473
2025-12-09 12:09:39.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0024621123294467097 Training loss: 3.536487579345703
2025-12-09 12:09:39.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.002449632642288045 Training loss: 3.636887550354004
2025-12-09 12:09:39.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.002437042276140287 Training loss: 3.1078455448150635
2025-12-09 12:09:39.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.0024243426984013913 Training loss: 3.04699444770813
2025-12-09 12:09:39.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.0024115353891978435 Training loss: 3.402841567993164
2025-12-09 12:09:39.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.002398621841212154 Training loss: 3.4338207244873047
2025-12-09 12:09:40.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.002385603559508884 Training loss: 3.3752570152282715
2025-12-09 12:09:40.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.002372482061359234 Training loss: 3.2614855766296387
2025-12-09 12:09:40.064 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0023592588760642046 Training loss: 3.4980874061584473
2025-12-09 12:09:40.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.00234593554477636 Training loss: 3.5336155891418457
2025-12-09 12:09:40.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.002332513620320205 Training loss: 3.3822426795959473
2025-12-09 12:09:40.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.002318994667011207 Training loss: 3.1870131492614746
2025-12-09 12:09:40.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.002305380260473476 Training loss: 3.200725793838501
2025-12-09 12:09:40.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.002291671987456123 Training loss: 3.3044021129608154
2025-12-09 12:09:40.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.0022778714456483324 Training loss: 3.345193386077881
2025-12-09 12:09:40.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0022639802434931446 Training loss: 3.3241498470306396
2025-12-09 12:09:40.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0022500000000000003 Training loss: 3.3823232650756836
2025-12-09 12:09:40.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.0022359323445560408 Training loss: 3.3028464317321777
2025-12-09 12:09:40.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0022217789167362076 Training loss: 3.515592336654663
2025-12-09 12:09:40.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.002207541366112149 Training loss: 3.417271375656128
2025-12-09 12:09:40.376 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0021932213520599654 Training loss: 3.2743959426879883
2025-12-09 12:09:40.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0021788205435668085 Training loss: 3.1796696186065674
2025-12-09 12:09:40.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0021643406190363624 Training loss: 3.2600293159484863
2025-12-09 12:09:40.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0021497832660932296 Training loss: 3.125781536102295
2025-12-09 12:09:40.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0021351501813862356 Training loss: 3.228538990020752
2025-12-09 12:09:40.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0021204430703906873 Training loss: 3.20013689994812
2025-12-09 12:09:40.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.0021056636472096026 Training loss: 3.152590036392212
2025-12-09 12:09:40.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.002090813634373931 Training loss: 2.9720633029937744
2025-12-09 12:09:40.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.0020758947626417943 Training loss: 2.984464168548584
2025-12-09 12:09:40.611 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.002060908770796769 Training loss: 3.4554343223571777
2025-12-09 12:09:40.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.0020458574054452315 Training loss: 3.1232829093933105
2025-12-09 12:09:40.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.002030742420812791 Training loss: 3.102217435836792
2025-12-09 12:09:40.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0020155655785398397 Training loss: 3.429144859313965
2025-12-09 12:09:40.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.002000328647476231 Training loss: 3.153921604156494
2025-12-09 12:09:40.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.001985033403475123 Training loss: 3.1851861476898193
2025-12-09 12:09:40.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.001969681629186004 Training loss: 3.13974928855896
2025-12-09 12:09:40.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.001954275113846926 Training loss: 3.4642107486724854
2025-12-09 12:09:40.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.0019388156530759713 Training loss: 3.1835014820098877
2025-12-09 12:09:40.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.0019233050486619715 Training loss: 3.1920459270477295
2025-12-09 12:09:40.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0019077451083545144 Training loss: 3.2410824298858643
2025-12-09 12:09:40.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.0018921376456532484 Training loss: 2.822206974029541
2025-12-09 12:09:40.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0018764844795965232 Training loss: 3.207975387573242
2025-12-09 12:09:40.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0018607874345493807 Training loss: 3.120133638381958
2025-12-09 12:09:40.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0018450483399909264 Training loss: 3.1213669776916504
2025-12-09 12:09:41.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0018292690303011077 Training loss: 2.9919774532318115
2025-12-09 12:09:41.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.001813451344546913 Training loss: 3.042710781097412
2025-12-09 12:09:41.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.0017975971262680348 Training loss: 3.188671588897705
2025-12-09 12:09:41.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.0017817082232620054 Training loss: 3.414771556854248
2025-12-09 12:09:41.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0017657864873688344 Training loss: 3.1789650917053223
2025-12-09 12:09:41.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0017498337742551818 Training loss: 3.0368082523345947
2025-12-09 12:09:41.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0017338519431980798 Training loss: 3.10540771484375
2025-12-09 12:09:41.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.0017178428568682357 Training loss: 3.0279343128204346
2025-12-09 12:09:41.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.001701808381112938 Training loss: 3.3605332374572754
2025-12-09 12:09:41.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0016857503847385955 Training loss: 3.252774238586426
2025-12-09 12:09:41.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.0016696707392929266 Training loss: 2.998605489730835
2025-12-09 12:09:41.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.001653571318846834 Training loss: 3.0774686336517334
2025-12-09 12:09:41.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.0016374539997759824 Training loss: 2.9950289726257324
2025-12-09 12:09:41.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0016213206605421066 Training loss: 3.2886803150177
2025-12-09 12:09:41.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.001605173181474081 Training loss: 2.9908483028411865
2025-12-09 12:09:41.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0015890134445487678 Training loss: 3.0213844776153564
2025-12-09 12:09:41.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.0015728433331716725 Training loss: 3.1614584922790527
2025-12-09 12:09:41.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.0015566647319574351 Training loss: 3.1150412559509277
2025-12-09 12:09:41.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.0015404795265101807 Training loss: 3.173187732696533
2025-12-09 12:09:41.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.0015242896032037524 Training loss: 3.043447256088257
2025-12-09 12:09:41.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.0015080968489618568 Training loss: 3.0792157649993896
2025-12-09 12:09:41.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0014919031510381437 Training loss: 3.073824405670166
2025-12-09 12:09:41.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.0014757103967962479 Training loss: 3.292358875274658
2025-12-09 12:09:41.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0014595204734898198 Training loss: 3.0019800662994385
2025-12-09 12:09:41.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0014433352680425654 Training loss: 3.0233535766601562
2025-12-09 12:09:41.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.0014271566668283282 Training loss: 3.0847256183624268
2025-12-09 12:09:41.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.001410986555451232 Training loss: 3.2810590267181396
2025-12-09 12:09:41.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.0013948268185259188 Training loss: 3.0732996463775635
2025-12-09 12:09:41.731 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.001378679339457894 Training loss: 3.182689666748047
2025-12-09 12:09:41.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.0013625460002240181 Training loss: 2.8567392826080322
2025-12-09 12:09:41.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.0013464286811531662 Training loss: 2.973587989807129
2025-12-09 12:09:41.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.0013303292607070737 Training loss: 3.2135090827941895
2025-12-09 12:09:41.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.001314249615261405 Training loss: 2.8326823711395264
2025-12-09 12:09:41.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0012981916188870622 Training loss: 2.710895538330078
2025-12-09 12:09:41.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.001282157143131765 Training loss: 2.925565004348755
2025-12-09 12:09:41.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.00126614805680192 Training loss: 2.607431650161743
2025-12-09 12:09:41.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0012501662257448183 Training loss: 3.1204662322998047
2025-12-09 12:09:41.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.001234213512631166 Training loss: 2.7175049781799316
2025-12-09 12:09:41.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.001218291776737995 Training loss: 3.1607909202575684
2025-12-09 12:09:42.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0012024028737319652 Training loss: 2.860107898712158
2025-12-09 12:09:42.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.0011865486554530874 Training loss: 2.763814687728882
2025-12-09 12:09:42.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.001170730969698893 Training loss: 2.888667583465576
2025-12-09 12:09:42.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0011549516600090739 Training loss: 2.954587459564209
2025-12-09 12:09:42.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.00113921256545062 Training loss: 2.8766860961914062
2025-12-09 12:09:42.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.0011235155204034769 Training loss: 3.0659937858581543
2025-12-09 12:09:42.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0011078623543467519 Training loss: 3.0512685775756836
2025-12-09 12:09:42.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.0010922548916454857 Training loss: 2.800318479537964
2025-12-09 12:09:42.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0010766949513380285 Training loss: 3.0067853927612305
2025-12-09 12:09:42.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.001061184346924029 Training loss: 2.931057929992676
2025-12-09 12:09:42.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.0010457248861530741 Training loss: 2.928330659866333
2025-12-09 12:09:42.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0010303183708139964 Training loss: 2.8434395790100098
2025-12-09 12:09:42.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.0010149665965248776 Training loss: 3.141514539718628
2025-12-09 12:09:42.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0009996713525237694 Training loss: 3.131199598312378
2025-12-09 12:09:42.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.0009844344214601601 Training loss: 2.8903961181640625
2025-12-09 12:09:42.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.000969257579187209 Training loss: 2.937819004058838
2025-12-09 12:09:42.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0009541425945547689 Training loss: 3.0185904502868652
2025-12-09 12:09:42.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.000939091229203231 Training loss: 3.0160324573516846
2025-12-09 12:09:42.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.0009241052373582058 Training loss: 2.904252290725708
2025-12-09 12:09:42.514 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0009091863656260695 Training loss: 2.8807168006896973
2025-12-09 12:09:42.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0008943363527903977 Training loss: 2.7725448608398438
2025-12-09 12:09:42.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0008795569296093132 Training loss: 2.9344642162323
2025-12-09 12:09:42.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.0008648498186137653 Training loss: 2.99066424369812
2025-12-09 12:09:42.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0008502167339067705 Training loss: 2.977346420288086
2025-12-09 12:09:42.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0008356593809636371 Training loss: 3.027559518814087
2025-12-09 12:09:42.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0008211794564331918 Training loss: 2.665647268295288
2025-12-09 12:09:42.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0008067786479400346 Training loss: 3.0259604454040527
2025-12-09 12:09:42.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0007924586338878512 Training loss: 2.9461793899536133
2025-12-09 12:09:42.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.0007782210832637924 Training loss: 2.8269307613372803
2025-12-09 12:09:42.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.0007640676554439594 Training loss: 2.840070962905884
2025-12-09 12:09:42.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0007500000000000003 Training loss: 2.647841215133667
2025-12-09 12:09:42.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.000736019756506856 Training loss: 2.7590041160583496
2025-12-09 12:09:42.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.000722128554351668 Training loss: 2.64890718460083
2025-12-09 12:09:42.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.0007083280125438767 Training loss: 2.6339595317840576
2025-12-09 12:09:42.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.0006946197395265243 Training loss: 2.974273920059204
2025-12-09 12:09:42.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.0006810053329887928 Training loss: 2.742279052734375
2025-12-09 12:09:42.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0006674863796797954 Training loss: 2.8418939113616943
2025-12-09 12:09:42.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0006540644552236401 Training loss: 2.981637716293335
2025-12-09 12:09:43.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.0006407411239357954 Training loss: 2.623563289642334
2025-12-09 12:09:43.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0006275179386407663 Training loss: 2.869741916656494
2025-12-09 12:09:43.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.0006143964404911165 Training loss: 3.1564383506774902
2025-12-09 12:09:43.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0006013781587878463 Training loss: 2.8441834449768066
2025-12-09 12:09:43.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0005884646108021563 Training loss: 2.6580240726470947
2025-12-09 12:09:43.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.000575657301598609 Training loss: 2.642543315887451
2025-12-09 12:09:43.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0005629577238597133 Training loss: 3.1259357929229736
2025-12-09 12:09:43.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0005503673577119553 Training loss: 3.0628111362457275
2025-12-09 12:09:43.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.0005378876705532904 Training loss: 2.458674669265747
2025-12-09 12:09:43.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0005255201168821184 Training loss: 3.0853006839752197
2025-12-09 12:09:43.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.0005132661381277644 Training loss: 2.776233673095703
2025-12-09 12:09:43.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0005011271624824787 Training loss: 2.744112491607666
2025-12-09 12:09:43.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0004891046047349837 Training loss: 3.1098179817199707
2025-12-09 12:09:43.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.00047719986610558236 Training loss: 3.028801441192627
2025-12-09 12:09:43.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.00046541433408284357 Training loss: 3.0743722915649414
2025-12-09 12:09:43.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.00045374938226189584 Training loss: 2.767472982406616
2025-12-09 12:09:43.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.00044220637018433165 Training loss: 2.678732395172119
2025-12-09 12:09:43.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.00043078664317975653 Training loss: 2.7579309940338135
2025-12-09 12:09:43.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0004194915322089899 Training loss: 3.149806022644043
2025-12-09 12:09:43.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.00040832235370894606 Training loss: 2.5932884216308594
2025-12-09 12:09:43.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.0003972804094391998 Training loss: 2.7277560234069824
2025-12-09 12:09:43.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.0003863669863302698 Training loss: 2.9827568531036377
2025-12-09 12:09:43.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.00037558335633362935 Training loss: 2.8395884037017822
2025-12-09 12:09:43.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.000364930776273457 Training loss: 2.4770050048828125
2025-12-09 12:09:43.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.0003544104877001596 Training loss: 2.831569194793701
2025-12-09 12:09:43.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0003440237167456663 Training loss: 2.719374895095825
2025-12-09 12:09:43.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0003337716739805264 Training loss: 2.5892388820648193
2025-12-09 12:09:43.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.00032365555427281634 Training loss: 2.967301845550537
2025-12-09 12:09:43.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.00031367653664888173 Training loss: 2.714531898498535
2025-12-09 12:09:43.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.0003038357841559191 Training loss: 2.727421283721924
2025-12-09 12:09:43.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.00029413444372642495 Training loss: 2.5843088626861572
2025-12-09 12:09:43.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.00028457364604452375 Training loss: 2.9751064777374268
2025-12-09 12:09:43.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.00027515450541418343 Training loss: 2.78802227973938
2025-12-09 12:09:43.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.0002658781196293482 Training loss: 2.8227946758270264
2025-12-09 12:09:43.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.0002567455698459882 Training loss: 2.6167922019958496
2025-12-09 12:09:43.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.00024775792045609354 Training loss: 3.013664722442627
2025-12-09 12:09:43.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.00023891621896361882 Training loss: 2.6747748851776123
2025-12-09 12:09:43.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.00023022149586239971 Training loss: 2.893693208694458
2025-12-09 12:09:43.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.00022167476451604625 Training loss: 2.748284339904785
2025-12-09 12:09:44.009 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.00021327702103983865 Training loss: 2.8010518550872803
2025-12-09 12:09:44.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.00020502924418463014 Training loss: 2.6890406608581543
2025-12-09 12:09:44.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.0001969323952227733 Training loss: 2.7097318172454834
2025-12-09 12:09:44.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.00018898741783608642 Training loss: 2.5405819416046143
2025-12-09 12:09:44.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.00018119523800586568 Training loss: 2.7766294479370117
2025-12-09 12:09:44.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.00017355676390496484 Training loss: 2.421110153198242
2025-12-09 12:09:44.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0001660728857919464 Training loss: 2.5985095500946045
2025-12-09 12:09:44.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.00015874447590732537 Training loss: 2.8296396732330322
2025-12-09 12:09:44.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0001515723883719072 Training loss: 2.730746269226074
2025-12-09 12:09:44.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.00014455745908724228 Training loss: 2.748819351196289
2025-12-09 12:09:44.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.0001377005056382018 Training loss: 2.8608081340789795
2025-12-09 12:09:44.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.00013100232719768994 Training loss: 2.705702781677246
2025-12-09 12:09:44.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.00012446370443349862 Training loss: 2.9217963218688965
2025-12-09 12:09:44.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.0001180853994173236 Training loss: 2.811530113220215
2025-12-09 12:09:44.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.00011186815553594382 Training loss: 2.6527035236358643
2025-12-09 12:09:44.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0001058126974045811 Training loss: 2.6284353733062744
2025-12-09 12:09:44.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 9.991973078244637e-05 Training loss: 2.8730053901672363
2025-12-09 12:09:44.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 9.418994249048473e-05 Training loss: 2.7395427227020264
2025-12-09 12:09:44.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 8.862400033132573e-05 Training loss: 2.6825106143951416
2025-12-09 12:09:44.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 8.322255301145204e-05 Training loss: 2.8855841159820557
2025-12-09 12:09:44.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 7.798623006559435e-05 Training loss: 2.8155734539031982
2025-12-09 12:09:44.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 7.291564178335719e-05 Training loss: 2.767254114151001
2025-12-09 12:09:44.574 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 6.801137913809213e-05 Training loss: 2.715932846069336
2025-12-09 12:09:44.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 6.327401371801944e-05 Training loss: 2.461841106414795
2025-12-09 12:09:44.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 5.870409765960966e-05 Training loss: 2.8565237522125244
2025-12-09 12:09:44.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 5.430216358323309e-05 Training loss: 2.935590982437134
2025-12-09 12:09:44.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 5.00687245310833e-05 Training loss: 2.7078590393066406
2025-12-09 12:09:44.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 4.60042739073816e-05 Training loss: 2.673067092895508
2025-12-09 12:09:44.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 4.2109285420872056e-05 Training loss: 2.7648892402648926
2025-12-09 12:09:44.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 3.8384213029610984e-05 Training loss: 2.7153637409210205
2025-12-09 12:09:44.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 3.4829490888057425e-05 Training loss: 2.694042921066284
2025-12-09 12:09:44.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 3.144553329647448e-05 Training loss: 2.7035810947418213
2025-12-09 12:09:44.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 2.823273465264142e-05 Training loss: 2.5590834617614746
2025-12-09 12:09:44.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 2.5191469405887624e-05 Training loss: 2.6136252880096436
2025-12-09 12:09:44.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 2.2322092013450313e-05 Training loss: 2.654212236404419
2025-12-09 12:09:44.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 1.9624936899163947e-05 Training loss: 2.8757925033569336
2025-12-09 12:09:44.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 1.7100318414482063e-05 Training loss: 2.614724636077881
2025-12-09 12:09:44.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 1.4748530801840077e-05 Training loss: 2.640151023864746
2025-12-09 12:09:44.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 1.2569848160362384e-05 Training loss: 2.645998954772949
2025-12-09 12:09:45.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 1.0564524413915422e-05 Training loss: 2.5440399646759033
2025-12-09 12:09:45.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 8.732793281513663e-06 Training loss: 2.737574338912964
2025-12-09 12:09:45.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 7.07486825007908e-06 Training loss: 2.497730255126953
2025-12-09 12:09:45.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 5.590942549560052e-06 Training loss: 2.7085866928100586
2025-12-09 12:09:45.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 4.281189130410535e-06 Training loss: 2.410207748413086
2025-12-09 12:09:45.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 3.145760643432527e-06 Training loss: 2.667987823486328
2025-12-09 12:09:45.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 2.184789421984634e-06 Training loss: 2.9026124477386475
2025-12-09 12:09:45.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 1.3983874665589036e-06 Training loss: 2.516084909439087
2025-12-09 12:09:45.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 7.866464317276001e-07 Training loss: 2.5713179111480713
2025-12-09 12:09:45.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 3.496376154604186e-07 Training loss: 2.573791742324829
2025-12-09 12:09:45.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 8.741195081479747e-08 Training loss: 2.395939350128174
2025-12-09 12:09:45.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0 Training loss: 2.7812044620513916
