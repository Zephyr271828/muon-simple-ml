2025-12-09 10:23:29.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 0.0
2025-12-09 10:23:29.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 0.0
2025-12-09 10:23:29.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 0.0
2025-12-09 10:23:29.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 0.0
2025-12-09 10:23:29.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 0.0
2025-12-09 10:23:29.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 0.0
2025-12-09 10:23:29.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 0.0
2025-12-09 10:23:29.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 0.0
2025-12-09 10:23:29.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 0.0
2025-12-09 10:23:29.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 0.0
2025-12-09 10:23:29.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 0.0
2025-12-09 10:23:29.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 0.0
2025-12-09 10:23:29.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 0.0
2025-12-09 10:23:29.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 0.0
2025-12-09 10:23:29.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 0.0
2025-12-09 10:23:29.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 0.0
2025-12-09 10:23:29.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 0.0
2025-12-09 10:23:29.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 0.0
2025-12-09 10:23:29.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 0.0
2025-12-09 10:23:29.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 0.0
2025-12-09 10:23:29.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 0.0
2025-12-09 10:23:29.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 0.0
2025-12-09 10:23:29.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 0.0
2025-12-09 10:23:29.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 0.0
2025-12-09 10:23:29.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 0.0
2025-12-09 10:23:29.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 0.0
2025-12-09 10:23:29.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 0.0
2025-12-09 10:23:29.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 0.0
2025-12-09 10:23:29.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 0.0
2025-12-09 10:23:29.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 0.0
2025-12-09 10:23:29.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 0.0
2025-12-09 10:23:29.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 0.0
2025-12-09 10:23:29.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 0.0
2025-12-09 10:23:29.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 0.0
2025-12-09 10:23:29.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 0.0
2025-12-09 10:23:29.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 0.0
2025-12-09 10:23:29.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 0.0
2025-12-09 10:23:29.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 0.0
2025-12-09 10:23:29.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 0.0
2025-12-09 10:23:29.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 0.0
2025-12-09 10:23:29.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 0.0
2025-12-09 10:23:29.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 0.0
2025-12-09 10:23:29.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 0.0
2025-12-09 10:23:29.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 0.0
2025-12-09 10:23:29.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 0.0
2025-12-09 10:23:29.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 0.0
2025-12-09 10:23:29.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 0.0
2025-12-09 10:23:29.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 0.0
2025-12-09 10:23:29.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 0.0
2025-12-09 10:23:29.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 0.0
2025-12-09 10:23:29.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 0.0
2025-12-09 10:23:29.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 0.0
2025-12-09 10:23:29.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 0.0
2025-12-09 10:23:29.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 0.0
2025-12-09 10:23:29.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 0.0
2025-12-09 10:23:29.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 0.0
2025-12-09 10:23:29.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 0.0
2025-12-09 10:23:29.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 0.0
2025-12-09 10:23:29.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 0.0
2025-12-09 10:23:29.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 0.0
2025-12-09 10:23:29.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 0.0
2025-12-09 10:23:29.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 0.0
2025-12-09 10:23:29.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 0.0
2025-12-09 10:23:29.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 0.0
2025-12-09 10:23:29.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 0.0
2025-12-09 10:23:29.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 0.0
2025-12-09 10:23:29.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 0.0
2025-12-09 10:23:29.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 0.0
2025-12-09 10:23:29.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 0.0
2025-12-09 10:23:29.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 0.0
2025-12-09 10:23:29.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 0.0
2025-12-09 10:23:29.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 0.0
2025-12-09 10:23:29.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 0.0
2025-12-09 10:23:29.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 0.0
2025-12-09 10:23:29.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 0.0
2025-12-09 10:23:29.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 0.0
2025-12-09 10:23:29.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 0.0
2025-12-09 10:23:29.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 0.0
2025-12-09 10:23:29.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 0.0
2025-12-09 10:23:29.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 0.0
2025-12-09 10:23:29.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 0.0
2025-12-09 10:23:29.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 0.0
2025-12-09 10:23:29.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 0.0
2025-12-09 10:23:29.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 0.0
2025-12-09 10:23:29.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 0.0
2025-12-09 10:23:29.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 0.0
2025-12-09 10:23:29.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 0.0
2025-12-09 10:23:29.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 0.0
2025-12-09 10:23:29.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 0.0
2025-12-09 10:23:29.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 0.0
2025-12-09 10:23:29.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 0.0
2025-12-09 10:23:29.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 0.0
2025-12-09 10:23:29.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 0.0
2025-12-09 10:23:29.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 0.0
2025-12-09 10:23:29.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 0.0
2025-12-09 10:23:29.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 0.0
2025-12-09 10:23:29.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 0.0
2025-12-09 10:23:29.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 0.0
2025-12-09 10:23:29.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 0.0
2025-12-09 10:23:29.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 0.0
2025-12-09 10:23:29.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 100 LR: 0.0009999999999975322 Training loss: 0.0
2025-12-09 10:23:29.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 101 LR: 0.0009999999999901284 Training loss: 0.0
2025-12-09 10:23:29.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 102 LR: 0.0009999999999777888 Training loss: 0.0
2025-12-09 10:23:29.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 103 LR: 0.0009999999999605138 Training loss: 0.0
2025-12-09 10:23:29.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 104 LR: 0.0009999999999383026 Training loss: 0.0
2025-12-09 10:23:29.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 105 LR: 0.0009999999999111557 Training loss: 0.0
2025-12-09 10:23:29.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 106 LR: 0.000999999999879073 Training loss: 0.0
2025-12-09 10:23:29.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 107 LR: 0.0009999999998420547 Training loss: 0.0
2025-12-09 10:23:29.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 108 LR: 0.0009999999998001007 Training loss: 0.0
2025-12-09 10:23:29.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 109 LR: 0.0009999999997532105 Training loss: 0.0
2025-12-09 10:23:29.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 110 LR: 0.0009999999997013847 Training loss: 0.0
2025-12-09 10:23:29.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 111 LR: 0.0009999999996446233 Training loss: 0.0
2025-12-09 10:23:29.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 112 LR: 0.0009999999995829259 Training loss: 0.0
2025-12-09 10:23:29.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 113 LR: 0.0009999999995162928 Training loss: 0.0
2025-12-09 10:23:29.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 114 LR: 0.0009999999994447237 Training loss: 0.0
2025-12-09 10:23:29.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 115 LR: 0.000999999999368219 Training loss: 0.0
2025-12-09 10:23:29.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 116 LR: 0.0009999999992867784 Training loss: 0.0
2025-12-09 10:23:29.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 117 LR: 0.000999999999200402 Training loss: 0.0
2025-12-09 10:23:29.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 118 LR: 0.00099999999910909 Training loss: 0.0
2025-12-09 10:23:29.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 119 LR: 0.0009999999990128422 Training loss: 0.0
2025-12-09 10:23:29.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 120 LR: 0.0009999999989116586 Training loss: 0.0
2025-12-09 10:23:29.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 121 LR: 0.000999999998805539 Training loss: 0.0
2025-12-09 10:23:29.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 122 LR: 0.0009999999986944838 Training loss: 0.0
2025-12-09 10:23:29.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 123 LR: 0.0009999999985784926 Training loss: 0.0
2025-12-09 10:23:29.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 124 LR: 0.0009999999984575659 Training loss: 0.0
2025-12-09 10:23:29.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 125 LR: 0.0009999999983317032 Training loss: 0.0
2025-12-09 10:23:29.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 126 LR: 0.0009999999982009049 Training loss: 0.0
2025-12-09 10:23:29.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 127 LR: 0.0009999999980651706 Training loss: 0.0
2025-12-09 10:23:29.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 128 LR: 0.0009999999979245007 Training loss: 0.0
2025-12-09 10:23:29.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 129 LR: 0.0009999999977788948 Training loss: 0.0
2025-12-09 10:23:29.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 130 LR: 0.0009999999976283533 Training loss: 0.0
2025-12-09 10:23:29.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 131 LR: 0.000999999997472876 Training loss: 0.0
2025-12-09 10:23:29.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 132 LR: 0.0009999999973124628 Training loss: 0.0
2025-12-09 10:23:29.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 133 LR: 0.000999999997147114 Training loss: 0.0
2025-12-09 10:23:29.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 134 LR: 0.0009999999969768291 Training loss: 0.0
2025-12-09 10:23:29.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 135 LR: 0.0009999999968016084 Training loss: 0.0
2025-12-09 10:23:29.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 136 LR: 0.0009999999966214521 Training loss: 0.0
2025-12-09 10:23:29.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 137 LR: 0.0009999999964363602 Training loss: 0.0
2025-12-09 10:23:29.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 138 LR: 0.0009999999962463323 Training loss: 0.0
2025-12-09 10:23:29.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 139 LR: 0.0009999999960513687 Training loss: 0.0
2025-12-09 10:23:29.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 140 LR: 0.0009999999958514691 Training loss: 0.0
2025-12-09 10:23:29.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 141 LR: 0.0009999999956466338 Training loss: 0.0
2025-12-09 10:23:29.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 142 LR: 0.0009999999954368628 Training loss: 0.0
2025-12-09 10:23:29.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 143 LR: 0.0009999999952221559 Training loss: 0.0
2025-12-09 10:23:29.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 144 LR: 0.0009999999950025134 Training loss: 0.0
2025-12-09 10:23:29.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 145 LR: 0.000999999994777935 Training loss: 0.0
2025-12-09 10:23:29.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 146 LR: 0.0009999999945484207 Training loss: 0.0
2025-12-09 10:23:29.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 147 LR: 0.000999999994313971 Training loss: 0.0
2025-12-09 10:23:29.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 148 LR: 0.000999999994074585 Training loss: 0.0
2025-12-09 10:23:29.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 149 LR: 0.0009999999938302634 Training loss: 0.0
2025-12-09 10:23:29.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 150 LR: 0.000999999993581006 Training loss: 0.0
2025-12-09 10:23:29.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 151 LR: 0.0009999999933268128 Training loss: 0.0
2025-12-09 10:23:29.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 152 LR: 0.000999999993067684 Training loss: 0.0
2025-12-09 10:23:29.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 153 LR: 0.0009999999928036192 Training loss: 0.0
2025-12-09 10:23:29.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 154 LR: 0.0009999999925346186 Training loss: 0.0
2025-12-09 10:23:29.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 155 LR: 0.0009999999922606824 Training loss: 0.0
2025-12-09 10:23:29.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 156 LR: 0.0009999999919818104 Training loss: 0.0
2025-12-09 10:23:29.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 157 LR: 0.0009999999916980025 Training loss: 0.0
2025-12-09 10:23:29.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 158 LR: 0.0009999999914092588 Training loss: 0.0
2025-12-09 10:23:29.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 159 LR: 0.0009999999911155793 Training loss: 0.0
2025-12-09 10:23:29.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 160 LR: 0.000999999990816964 Training loss: 0.0
2025-12-09 10:23:29.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 161 LR: 0.000999999990513413 Training loss: 0.0
2025-12-09 10:23:29.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 162 LR: 0.0009999999902049262 Training loss: 0.0
2025-12-09 10:23:29.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 163 LR: 0.0009999999898915035 Training loss: 0.0
2025-12-09 10:23:29.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 164 LR: 0.0009999999895731451 Training loss: 0.0
2025-12-09 10:23:29.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 165 LR: 0.000999999989249851 Training loss: 0.0
2025-12-09 10:23:29.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 166 LR: 0.000999999988921621 Training loss: 0.0
2025-12-09 10:23:29.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 167 LR: 0.0009999999885884551 Training loss: 0.0
2025-12-09 10:23:29.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 168 LR: 0.0009999999882503536 Training loss: 0.0
2025-12-09 10:23:29.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 169 LR: 0.0009999999879073162 Training loss: 0.0
2025-12-09 10:23:29.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 170 LR: 0.000999999987559343 Training loss: 0.0
2025-12-09 10:23:29.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 171 LR: 0.0009999999872064343 Training loss: 0.0
2025-12-09 10:23:29.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 172 LR: 0.0009999999868485893 Training loss: 0.0
2025-12-09 10:23:29.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 173 LR: 0.000999999986485809 Training loss: 0.0
2025-12-09 10:23:30.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 174 LR: 0.0009999999861180927 Training loss: 0.0
2025-12-09 10:23:30.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 175 LR: 0.0009999999857454405 Training loss: 0.0
2025-12-09 10:23:30.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 176 LR: 0.0009999999853678527 Training loss: 0.0
2025-12-09 10:23:30.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 177 LR: 0.0009999999849853289 Training loss: 0.0
2025-12-09 10:23:30.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 178 LR: 0.0009999999845978695 Training loss: 0.0
2025-12-09 10:23:30.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 179 LR: 0.0009999999842054744 Training loss: 0.0
2025-12-09 10:23:30.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 180 LR: 0.0009999999838081434 Training loss: 0.0
2025-12-09 10:23:30.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 181 LR: 0.0009999999834058764 Training loss: 0.0
2025-12-09 10:23:30.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 182 LR: 0.000999999982998674 Training loss: 0.0
2025-12-09 10:23:30.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 183 LR: 0.0009999999825865355 Training loss: 0.0
2025-12-09 10:23:30.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 184 LR: 0.0009999999821694611 Training loss: 0.0
2025-12-09 10:23:30.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 185 LR: 0.0009999999817474512 Training loss: 0.0
2025-12-09 10:23:30.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 186 LR: 0.0009999999813205054 Training loss: 0.0
2025-12-09 10:23:30.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 187 LR: 0.000999999980888624 Training loss: 0.0
2025-12-09 10:23:30.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 188 LR: 0.0009999999804518064 Training loss: 0.0
2025-12-09 10:23:30.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 189 LR: 0.0009999999800100535 Training loss: 0.0
2025-12-09 10:23:30.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 190 LR: 0.0009999999795633646 Training loss: 0.0
2025-12-09 10:23:30.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 191 LR: 0.0009999999791117397 Training loss: 0.0
2025-12-09 10:23:30.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 192 LR: 0.0009999999786551794 Training loss: 0.0
2025-12-09 10:23:30.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 193 LR: 0.000999999978193683 Training loss: 0.0
2025-12-09 10:23:30.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 194 LR: 0.0009999999777272508 Training loss: 0.0
2025-12-09 10:23:30.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 195 LR: 0.0009999999772558829 Training loss: 0.0
2025-12-09 10:23:30.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 196 LR: 0.0009999999767795794 Training loss: 0.0
2025-12-09 10:23:30.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 197 LR: 0.00099999997629834 Training loss: 0.0
2025-12-09 10:23:30.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 198 LR: 0.0009999999758121647 Training loss: 0.0
2025-12-09 10:23:30.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 199 LR: 0.0009999999753210536 Training loss: 0.0
2025-12-09 10:23:30.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 200 LR: 0.0009999999748250069 Training loss: 0.0
2025-12-09 10:23:30.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 201 LR: 0.0009999999743240241 Training loss: 0.0
2025-12-09 10:23:30.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 202 LR: 0.000999999973818106 Training loss: 0.0
2025-12-09 10:23:30.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 203 LR: 0.0009999999733072517 Training loss: 0.0
2025-12-09 10:23:30.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 204 LR: 0.0009999999727914616 Training loss: 0.0
2025-12-09 10:23:30.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 205 LR: 0.0009999999722707358 Training loss: 0.0
2025-12-09 10:23:30.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 206 LR: 0.0009999999717450745 Training loss: 0.0
2025-12-09 10:23:30.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 207 LR: 0.000999999971214477 Training loss: 0.0
2025-12-09 10:23:30.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 208 LR: 0.000999999970678944 Training loss: 0.0
2025-12-09 10:23:30.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 209 LR: 0.000999999970138475 Training loss: 0.0
2025-12-09 10:23:30.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 210 LR: 0.0009999999695930702 Training loss: 0.0
2025-12-09 10:23:30.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 211 LR: 0.0009999999690427296 Training loss: 0.0
2025-12-09 10:23:30.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 212 LR: 0.0009999999684874535 Training loss: 0.0
2025-12-09 10:23:30.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 213 LR: 0.0009999999679272415 Training loss: 0.0
2025-12-09 10:23:30.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 214 LR: 0.0009999999673620935 Training loss: 0.0
2025-12-09 10:23:30.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 215 LR: 0.0009999999667920098 Training loss: 0.0
2025-12-09 10:23:30.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 216 LR: 0.0009999999662169904 Training loss: 0.0
2025-12-09 10:23:30.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 217 LR: 0.0009999999656370353 Training loss: 0.0
2025-12-09 10:23:30.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 218 LR: 0.0009999999650521442 Training loss: 0.0
2025-12-09 10:23:30.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 219 LR: 0.0009999999644623174 Training loss: 0.0
2025-12-09 10:23:30.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 220 LR: 0.0009999999638675547 Training loss: 0.0
2025-12-09 10:23:30.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 221 LR: 0.0009999999632678564 Training loss: 0.0
2025-12-09 10:23:30.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 222 LR: 0.0009999999626632223 Training loss: 0.0
2025-12-09 10:23:30.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 223 LR: 0.0009999999620536524 Training loss: 0.0
2025-12-09 10:23:30.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 224 LR: 0.0009999999614391467 Training loss: 0.0
2025-12-09 10:23:30.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 225 LR: 0.000999999960819705 Training loss: 0.0
2025-12-09 10:23:30.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 226 LR: 0.0009999999601953277 Training loss: 0.0
2025-12-09 10:23:30.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 227 LR: 0.0009999999595660144 Training loss: 0.0
2025-12-09 10:23:30.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 228 LR: 0.0009999999589317657 Training loss: 0.0
2025-12-09 10:23:30.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 229 LR: 0.000999999958292581 Training loss: 0.0
2025-12-09 10:23:30.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 230 LR: 0.0009999999576484604 Training loss: 0.0
2025-12-09 10:23:30.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 231 LR: 0.000999999956999404 Training loss: 0.0
2025-12-09 10:23:30.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 232 LR: 0.000999999956345412 Training loss: 0.0
2025-12-09 10:23:30.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 233 LR: 0.0009999999556864843 Training loss: 0.0
2025-12-09 10:23:30.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 234 LR: 0.0009999999550226206 Training loss: 0.0
2025-12-09 10:23:30.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 235 LR: 0.0009999999543538211 Training loss: 0.0
2025-12-09 10:23:30.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 236 LR: 0.000999999953680086 Training loss: 0.0
2025-12-09 10:23:30.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 237 LR: 0.000999999953001415 Training loss: 0.0
2025-12-09 10:23:30.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 238 LR: 0.000999999952317808 Training loss: 0.0
2025-12-09 10:23:30.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 239 LR: 0.0009999999516292655 Training loss: 0.0
2025-12-09 10:23:30.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 240 LR: 0.0009999999509357873 Training loss: 0.0
2025-12-09 10:23:30.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 241 LR: 0.000999999950237373 Training loss: 0.0
2025-12-09 10:23:30.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 242 LR: 0.0009999999495340231 Training loss: 0.0
2025-12-09 10:23:30.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 243 LR: 0.0009999999488257375 Training loss: 0.0
2025-12-09 10:23:30.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 244 LR: 0.000999999948112516 Training loss: 0.0
2025-12-09 10:23:30.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 245 LR: 0.0009999999473943586 Training loss: 0.0
2025-12-09 10:23:30.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 246 LR: 0.0009999999466712654 Training loss: 0.0
2025-12-09 10:23:30.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 247 LR: 0.0009999999459432366 Training loss: 0.0
2025-12-09 10:23:30.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 248 LR: 0.000999999945210272 Training loss: 0.0
2025-12-09 10:23:30.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 249 LR: 0.0009999999444723713 Training loss: 0.0
2025-12-09 10:23:30.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 250 LR: 0.0009999999437295352 Training loss: 0.0
2025-12-09 10:23:30.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 251 LR: 0.000999999942981763 Training loss: 0.0
2025-12-09 10:23:30.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 252 LR: 0.000999999942229055 Training loss: 0.0
2025-12-09 10:23:30.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 253 LR: 0.0009999999414714116 Training loss: 0.0
2025-12-09 10:23:30.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 254 LR: 0.0009999999407088321 Training loss: 0.0
2025-12-09 10:23:30.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 255 LR: 0.000999999939941317 Training loss: 0.0
2025-12-09 10:23:30.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 256 LR: 0.0009999999391688658 Training loss: 0.0
2025-12-09 10:23:30.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 257 LR: 0.000999999938391479 Training loss: 0.0
2025-12-09 10:23:30.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 258 LR: 0.0009999999376091567 Training loss: 0.0
2025-12-09 10:23:30.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 259 LR: 0.0009999999368218982 Training loss: 0.0
2025-12-09 10:23:30.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 260 LR: 0.0009999999360297042 Training loss: 0.0
2025-12-09 10:23:30.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 261 LR: 0.0009999999352325742 Training loss: 0.0
2025-12-09 10:23:30.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 262 LR: 0.0009999999344305083 Training loss: 0.0
2025-12-09 10:23:30.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 263 LR: 0.0009999999336235067 Training loss: 0.0
2025-12-09 10:23:30.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 264 LR: 0.0009999999328115696 Training loss: 0.0
2025-12-09 10:23:30.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 265 LR: 0.0009999999319946964 Training loss: 0.0
2025-12-09 10:23:30.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 266 LR: 0.0009999999311728876 Training loss: 0.0
2025-12-09 10:23:30.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 267 LR: 0.000999999930346143 Training loss: 0.0
2025-12-09 10:23:30.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 268 LR: 0.0009999999295144625 Training loss: 0.0
2025-12-09 10:23:30.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 269 LR: 0.0009999999286778463 Training loss: 0.0
2025-12-09 10:23:30.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 270 LR: 0.000999999927836294 Training loss: 0.0
2025-12-09 10:23:30.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 271 LR: 0.0009999999269898064 Training loss: 0.0
2025-12-09 10:23:30.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 272 LR: 0.0009999999261383827 Training loss: 0.0
2025-12-09 10:23:30.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 273 LR: 0.0009999999252820234 Training loss: 0.0
2025-12-09 10:23:30.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 274 LR: 0.000999999924420728 Training loss: 0.0
2025-12-09 10:23:30.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 275 LR: 0.000999999923554497 Training loss: 0.0
2025-12-09 10:23:30.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 276 LR: 0.0009999999226833305 Training loss: 0.0
2025-12-09 10:23:30.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 277 LR: 0.0009999999218072277 Training loss: 0.0
2025-12-09 10:23:30.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 278 LR: 0.0009999999209261894 Training loss: 0.0
2025-12-09 10:23:30.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 279 LR: 0.0009999999200402154 Training loss: 0.0
2025-12-09 10:23:30.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 280 LR: 0.0009999999191493054 Training loss: 0.0
2025-12-09 10:23:30.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 281 LR: 0.0009999999182534597 Training loss: 0.0
2025-12-09 10:23:30.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 282 LR: 0.000999999917352678 Training loss: 0.0
2025-12-09 10:23:30.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 283 LR: 0.000999999916446961 Training loss: 0.0
2025-12-09 10:23:30.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 284 LR: 0.000999999915536308 Training loss: 0.0
2025-12-09 10:23:30.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 285 LR: 0.0009999999146207191 Training loss: 0.0
2025-12-09 10:23:30.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 286 LR: 0.0009999999137001942 Training loss: 0.0
2025-12-09 10:23:30.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 287 LR: 0.000999999912774734 Training loss: 0.0
2025-12-09 10:23:30.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 288 LR: 0.0009999999118443378 Training loss: 0.0
2025-12-09 10:23:30.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 289 LR: 0.0009999999109090057 Training loss: 0.0
2025-12-09 10:23:30.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 290 LR: 0.0009999999099687378 Training loss: 0.0
2025-12-09 10:23:30.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 291 LR: 0.0009999999090235343 Training loss: 0.0
2025-12-09 10:23:30.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 292 LR: 0.0009999999080733948 Training loss: 0.0
2025-12-09 10:23:30.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 293 LR: 0.0009999999071183196 Training loss: 0.0
2025-12-09 10:23:30.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 294 LR: 0.0009999999061583087 Training loss: 0.0
2025-12-09 10:23:30.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 295 LR: 0.000999999905193362 Training loss: 0.0
2025-12-09 10:23:30.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 296 LR: 0.0009999999042234794 Training loss: 0.0
2025-12-09 10:23:30.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 297 LR: 0.000999999903248661 Training loss: 0.0
2025-12-09 10:23:30.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 298 LR: 0.000999999902268907 Training loss: 0.0
2025-12-09 10:23:30.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 299 LR: 0.000999999901284217 Training loss: 0.0
2025-12-09 10:23:30.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 300 LR: 0.0009999999002945914 Training loss: 0.0
2025-12-09 10:23:30.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 301 LR: 0.00099999989930003 Training loss: 0.0
2025-12-09 10:23:30.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 302 LR: 0.0009999998983005328 Training loss: 0.0
2025-12-09 10:23:30.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 303 LR: 0.0009999998972960995 Training loss: 0.0
2025-12-09 10:23:30.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 304 LR: 0.0009999998962867307 Training loss: 0.0
2025-12-09 10:23:30.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 305 LR: 0.000999999895272426 Training loss: 0.0
2025-12-09 10:23:30.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 306 LR: 0.0009999998942531857 Training loss: 0.0
2025-12-09 10:23:30.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 307 LR: 0.0009999998932290095 Training loss: 0.0
2025-12-09 10:23:30.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 308 LR: 0.0009999998921998974 Training loss: 0.0
2025-12-09 10:23:30.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 309 LR: 0.0009999998911658496 Training loss: 0.0
2025-12-09 10:23:30.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 310 LR: 0.000999999890126866 Training loss: 0.0
2025-12-09 10:23:30.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 311 LR: 0.0009999998890829467 Training loss: 0.0
2025-12-09 10:23:30.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 312 LR: 0.0009999998880340917 Training loss: 0.0
2025-12-09 10:23:30.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 313 LR: 0.0009999998869803007 Training loss: 0.0
2025-12-09 10:23:30.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 314 LR: 0.000999999885921574 Training loss: 0.0
2025-12-09 10:23:30.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 315 LR: 0.0009999998848579114 Training loss: 0.0
2025-12-09 10:23:30.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 316 LR: 0.0009999998837893131 Training loss: 0.0
2025-12-09 10:23:30.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 317 LR: 0.000999999882715779 Training loss: 0.0
2025-12-09 10:23:30.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 318 LR: 0.000999999881637309 Training loss: 0.0
2025-12-09 10:23:30.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 319 LR: 0.0009999998805539033 Training loss: 0.0
2025-12-09 10:23:30.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 320 LR: 0.0009999998794655621 Training loss: 0.0
2025-12-09 10:23:30.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 321 LR: 0.0009999998783722847 Training loss: 0.0
2025-12-09 10:23:30.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 322 LR: 0.0009999998772740716 Training loss: 0.0
2025-12-09 10:23:30.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 323 LR: 0.000999999876170923 Training loss: 0.0
2025-12-09 10:23:30.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 324 LR: 0.0009999998750628383 Training loss: 0.0
2025-12-09 10:23:30.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 325 LR: 0.000999999873949818 Training loss: 0.0
2025-12-09 10:23:30.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 326 LR: 0.0009999998728318618 Training loss: 0.0
2025-12-09 10:23:30.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 327 LR: 0.0009999998717089699 Training loss: 0.0
2025-12-09 10:23:30.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 328 LR: 0.000999999870581142 Training loss: 0.0
2025-12-09 10:23:30.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 329 LR: 0.0009999998694483784 Training loss: 0.0
2025-12-09 10:23:30.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 330 LR: 0.0009999998683106791 Training loss: 0.0
2025-12-09 10:23:30.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 331 LR: 0.000999999867168044 Training loss: 0.0
2025-12-09 10:23:30.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 332 LR: 0.0009999998660204731 Training loss: 0.0
2025-12-09 10:23:30.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 333 LR: 0.0009999998648679664 Training loss: 0.0
2025-12-09 10:23:30.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 334 LR: 0.0009999998637105238 Training loss: 0.0
2025-12-09 10:23:30.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 335 LR: 0.0009999998625481457 Training loss: 0.0
2025-12-09 10:23:30.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 336 LR: 0.0009999998613808316 Training loss: 0.0
2025-12-09 10:23:30.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 337 LR: 0.0009999998602085818 Training loss: 0.0
2025-12-09 10:23:30.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 338 LR: 0.000999999859031396 Training loss: 0.0
2025-12-09 10:23:30.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 339 LR: 0.0009999998578492746 Training loss: 0.0
2025-12-09 10:23:30.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 340 LR: 0.0009999998566622174 Training loss: 0.0
2025-12-09 10:23:30.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 341 LR: 0.0009999998554702245 Training loss: 0.0
2025-12-09 10:23:30.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 342 LR: 0.0009999998542732957 Training loss: 0.0
2025-12-09 10:23:30.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 343 LR: 0.000999999853071431 Training loss: 0.0
2025-12-09 10:23:30.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 344 LR: 0.0009999998518646308 Training loss: 0.0
2025-12-09 10:23:30.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 345 LR: 0.0009999998506528946 Training loss: 0.0
2025-12-09 10:23:30.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 346 LR: 0.0009999998494362226 Training loss: 0.0
2025-12-09 10:23:30.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 347 LR: 0.000999999848214615 Training loss: 0.0
2025-12-09 10:23:30.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 348 LR: 0.0009999998469880714 Training loss: 0.0
2025-12-09 10:23:30.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 349 LR: 0.000999999845756592 Training loss: 0.0
2025-12-09 10:23:30.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 350 LR: 0.000999999844520177 Training loss: 0.0
2025-12-09 10:23:30.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 351 LR: 0.000999999843278826 Training loss: 0.0
2025-12-09 10:23:30.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 352 LR: 0.0009999998420325393 Training loss: 0.0
2025-12-09 10:23:30.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 353 LR: 0.0009999998407813169 Training loss: 0.0
2025-12-09 10:23:30.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 354 LR: 0.0009999998395251587 Training loss: 0.0
2025-12-09 10:23:30.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 355 LR: 0.0009999998382640646 Training loss: 0.0
2025-12-09 10:23:30.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 356 LR: 0.0009999998369980348 Training loss: 0.0
2025-12-09 10:23:30.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 357 LR: 0.0009999998357270693 Training loss: 0.0
2025-12-09 10:23:30.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 358 LR: 0.0009999998344511678 Training loss: 0.0
2025-12-09 10:23:30.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 359 LR: 0.0009999998331703306 Training loss: 0.0
2025-12-09 10:23:30.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 360 LR: 0.0009999998318845577 Training loss: 0.0
2025-12-09 10:23:30.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 361 LR: 0.000999999830593849 Training loss: 0.0
2025-12-09 10:23:30.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 362 LR: 0.0009999998292982044 Training loss: 0.0
2025-12-09 10:23:30.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 363 LR: 0.0009999998279976241 Training loss: 0.0
2025-12-09 10:23:30.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 364 LR: 0.000999999826692108 Training loss: 0.0
2025-12-09 10:23:30.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 365 LR: 0.000999999825381656 Training loss: 0.0
2025-12-09 10:23:30.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 366 LR: 0.0009999998240662682 Training loss: 0.0
2025-12-09 10:23:30.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 367 LR: 0.0009999998227459448 Training loss: 0.0
2025-12-09 10:23:30.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 368 LR: 0.0009999998214206855 Training loss: 0.0
2025-12-09 10:23:30.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 369 LR: 0.0009999998200904904 Training loss: 0.0
2025-12-09 10:23:30.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 370 LR: 0.0009999998187553596 Training loss: 0.0
2025-12-09 10:23:30.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 371 LR: 0.000999999817415293 Training loss: 0.0
2025-12-09 10:23:30.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 372 LR: 0.0009999998160702905 Training loss: 0.0
2025-12-09 10:23:30.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 373 LR: 0.0009999998147203525 Training loss: 0.0
2025-12-09 10:23:30.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 374 LR: 0.0009999998133654784 Training loss: 0.0
2025-12-09 10:23:30.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 375 LR: 0.0009999998120056685 Training loss: 0.0
2025-12-09 10:23:30.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 376 LR: 0.000999999810640923 Training loss: 0.0
2025-12-09 10:23:30.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 377 LR: 0.0009999998092712417 Training loss: 0.0
2025-12-09 10:23:30.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 378 LR: 0.0009999998078966245 Training loss: 0.0
2025-12-09 10:23:30.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 379 LR: 0.0009999998065170716 Training loss: 0.0
2025-12-09 10:23:30.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 380 LR: 0.000999999805132583 Training loss: 0.0
2025-12-09 10:23:30.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 381 LR: 0.0009999998037431583 Training loss: 0.0
2025-12-09 10:23:30.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 382 LR: 0.000999999802348798 Training loss: 0.0
2025-12-09 10:23:30.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 383 LR: 0.000999999800949502 Training loss: 0.0
2025-12-09 10:23:30.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 384 LR: 0.0009999997995452702 Training loss: 0.0
2025-12-09 10:23:30.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 385 LR: 0.0009999997981361025 Training loss: 0.0
2025-12-09 10:23:30.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 386 LR: 0.0009999997967219988 Training loss: 0.0
2025-12-09 10:23:30.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 387 LR: 0.0009999997953029599 Training loss: 0.0
2025-12-09 10:23:30.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 388 LR: 0.0009999997938789848 Training loss: 0.0
2025-12-09 10:23:30.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 389 LR: 0.000999999792450074 Training loss: 0.0
2025-12-09 10:23:30.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 390 LR: 0.0009999997910162272 Training loss: 0.0
2025-12-09 10:23:30.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 391 LR: 0.000999999789577445 Training loss: 0.0
2025-12-09 10:23:30.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 392 LR: 0.0009999997881337268 Training loss: 0.0
2025-12-09 10:23:30.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 393 LR: 0.0009999997866850729 Training loss: 0.0
2025-12-09 10:23:30.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 394 LR: 0.000999999785231483 Training loss: 0.0
2025-12-09 10:23:30.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 395 LR: 0.0009999997837729575 Training loss: 0.0
2025-12-09 10:23:30.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 396 LR: 0.0009999997823094962 Training loss: 0.0
2025-12-09 10:23:30.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 397 LR: 0.0009999997808410991 Training loss: 0.0
2025-12-09 10:23:30.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 398 LR: 0.0009999997793677662 Training loss: 0.0
2025-12-09 10:23:30.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 399 LR: 0.0009999997778894975 Training loss: 0.0
2025-12-09 10:23:30.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 400 LR: 0.000999999776406293 Training loss: 0.0
2025-12-09 10:23:30.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 401 LR: 0.0009999997749181528 Training loss: 0.0
2025-12-09 10:23:30.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 402 LR: 0.0009999997734250767 Training loss: 0.0
2025-12-09 10:23:30.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 403 LR: 0.0009999997719270651 Training loss: 0.0
2025-12-09 10:23:30.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 404 LR: 0.0009999997704241172 Training loss: 0.0
2025-12-09 10:23:30.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 405 LR: 0.000999999768916234 Training loss: 0.0
2025-12-09 10:23:30.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 406 LR: 0.0009999997674034148 Training loss: 0.0
2025-12-09 10:23:30.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 407 LR: 0.0009999997658856597 Training loss: 0.0
2025-12-09 10:23:30.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 408 LR: 0.000999999764362969 Training loss: 0.0
2025-12-09 10:23:30.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 409 LR: 0.0009999997628353425 Training loss: 0.0
2025-12-09 10:23:30.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 410 LR: 0.00099999976130278 Training loss: 0.0
2025-12-09 10:23:30.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 411 LR: 0.000999999759765282 Training loss: 0.0
2025-12-09 10:23:30.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 412 LR: 0.0009999997582228481 Training loss: 0.0
2025-12-09 10:23:30.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 413 LR: 0.0009999997566754785 Training loss: 0.0
2025-12-09 10:23:30.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 414 LR: 0.000999999755123173 Training loss: 0.0
2025-12-09 10:23:30.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 415 LR: 0.0009999997535659316 Training loss: 0.0
2025-12-09 10:23:30.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 416 LR: 0.0009999997520037545 Training loss: 0.0
2025-12-09 10:23:30.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 417 LR: 0.0009999997504366418 Training loss: 0.0
2025-12-09 10:23:30.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 418 LR: 0.000999999748864593 Training loss: 0.0
2025-12-09 10:23:30.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 419 LR: 0.0009999997472876086 Training loss: 0.0
2025-12-09 10:23:30.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 420 LR: 0.0009999997457056885 Training loss: 0.0
2025-12-09 10:23:30.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 421 LR: 0.0009999997441188324 Training loss: 0.0
2025-12-09 10:23:30.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 422 LR: 0.0009999997425270406 Training loss: 0.0
2025-12-09 10:23:30.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 423 LR: 0.0009999997409303133 Training loss: 0.0
2025-12-09 10:23:30.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 424 LR: 0.0009999997393286496 Training loss: 0.0
2025-12-09 10:23:30.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 425 LR: 0.0009999997377220507 Training loss: 0.0
2025-12-09 10:23:30.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 426 LR: 0.0009999997361105158 Training loss: 0.0
2025-12-09 10:23:30.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 427 LR: 0.0009999997344940451 Training loss: 0.0
2025-12-09 10:23:30.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 428 LR: 0.0009999997328726386 Training loss: 0.0
2025-12-09 10:23:30.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 429 LR: 0.0009999997312462963 Training loss: 0.0
2025-12-09 10:23:30.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 430 LR: 0.0009999997296150183 Training loss: 0.0
2025-12-09 10:23:30.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 431 LR: 0.0009999997279788043 Training loss: 0.0
2025-12-09 10:23:30.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 432 LR: 0.0009999997263376546 Training loss: 0.0
2025-12-09 10:23:30.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 433 LR: 0.0009999997246915692 Training loss: 0.0
2025-12-09 10:23:30.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 434 LR: 0.000999999723040548 Training loss: 0.0
2025-12-09 10:23:30.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 435 LR: 0.000999999721384591 Training loss: 0.0
2025-12-09 10:23:30.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 436 LR: 0.0009999997197236983 Training loss: 0.0
2025-12-09 10:23:30.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 437 LR: 0.0009999997180578696 Training loss: 0.0
2025-12-09 10:23:30.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 438 LR: 0.0009999997163871053 Training loss: 0.0
2025-12-09 10:23:30.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 439 LR: 0.000999999714711405 Training loss: 0.0
2025-12-09 10:23:30.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 440 LR: 0.000999999713030769 Training loss: 0.0
2025-12-09 10:23:30.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 441 LR: 0.0009999997113451975 Training loss: 0.0
2025-12-09 10:23:30.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 442 LR: 0.00099999970965469 Training loss: 0.0
2025-12-09 10:23:30.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 443 LR: 0.0009999997079592467 Training loss: 0.0
2025-12-09 10:23:30.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 444 LR: 0.0009999997062588675 Training loss: 0.0
2025-12-09 10:23:30.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 445 LR: 0.0009999997045535528 Training loss: 0.0
2025-12-09 10:23:30.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 446 LR: 0.000999999702843302 Training loss: 0.0
2025-12-09 10:23:30.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 447 LR: 0.0009999997011281155 Training loss: 0.0
2025-12-09 10:23:30.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 448 LR: 0.0009999996994079934 Training loss: 0.0
2025-12-09 10:23:30.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 449 LR: 0.0009999996976829354 Training loss: 0.0
2025-12-09 10:23:30.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 450 LR: 0.0009999996959529414 Training loss: 0.0
2025-12-09 10:23:30.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 451 LR: 0.0009999996942180117 Training loss: 0.0
2025-12-09 10:23:30.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 452 LR: 0.0009999996924781466 Training loss: 0.0
2025-12-09 10:23:30.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 453 LR: 0.0009999996907333454 Training loss: 0.0
2025-12-09 10:23:30.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 454 LR: 0.0009999996889836086 Training loss: 0.0
2025-12-09 10:23:30.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 455 LR: 0.0009999996872289355 Training loss: 0.0
2025-12-09 10:23:30.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 456 LR: 0.0009999996854693272 Training loss: 0.0
2025-12-09 10:23:30.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 457 LR: 0.0009999996837047828 Training loss: 0.0
2025-12-09 10:23:30.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 458 LR: 0.0009999996819353028 Training loss: 0.0
2025-12-09 10:23:30.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 459 LR: 0.000999999680160887 Training loss: 0.0
2025-12-09 10:23:30.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 460 LR: 0.0009999996783815353 Training loss: 0.0
2025-12-09 10:23:30.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 461 LR: 0.0009999996765972477 Training loss: 0.0
2025-12-09 10:23:30.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 462 LR: 0.0009999996748080245 Training loss: 0.0
2025-12-09 10:23:30.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 463 LR: 0.0009999996730138655 Training loss: 0.0
2025-12-09 10:23:30.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 464 LR: 0.0009999996712147707 Training loss: 0.0
2025-12-09 10:23:30.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 465 LR: 0.00099999966941074 Training loss: 0.0
2025-12-09 10:23:30.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 466 LR: 0.0009999996676017737 Training loss: 0.0
2025-12-09 10:23:30.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 467 LR: 0.0009999996657878716 Training loss: 0.0
2025-12-09 10:23:30.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 468 LR: 0.0009999996639690337 Training loss: 0.0
2025-12-09 10:23:30.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 469 LR: 0.0009999996621452597 Training loss: 0.0
2025-12-09 10:23:30.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 470 LR: 0.0009999996603165502 Training loss: 0.0
2025-12-09 10:23:30.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 471 LR: 0.000999999658482905 Training loss: 0.0
2025-12-09 10:23:30.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 472 LR: 0.0009999996566443239 Training loss: 0.0
2025-12-09 10:23:30.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 473 LR: 0.000999999654800807 Training loss: 0.0
2025-12-09 10:23:30.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 474 LR: 0.0009999996529523544 Training loss: 0.0
2025-12-09 10:23:30.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 475 LR: 0.0009999996510989659 Training loss: 0.0
2025-12-09 10:23:30.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 476 LR: 0.0009999996492406416 Training loss: 0.0
2025-12-09 10:23:30.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 477 LR: 0.0009999996473773816 Training loss: 0.0
2025-12-09 10:23:30.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 478 LR: 0.0009999996455091857 Training loss: 0.0
2025-12-09 10:23:30.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 479 LR: 0.0009999996436360543 Training loss: 0.0
2025-12-09 10:23:30.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 480 LR: 0.000999999641757987 Training loss: 0.0
2025-12-09 10:23:30.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 481 LR: 0.0009999996398749836 Training loss: 0.0
2025-12-09 10:23:30.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 482 LR: 0.0009999996379870448 Training loss: 0.0
2025-12-09 10:23:30.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 483 LR: 0.00099999963609417 Training loss: 0.0
2025-12-09 10:23:30.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 484 LR: 0.0009999996341963596 Training loss: 0.0
2025-12-09 10:23:30.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 485 LR: 0.0009999996322936132 Training loss: 0.0
2025-12-09 10:23:30.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 486 LR: 0.000999999630385931 Training loss: 0.0
2025-12-09 10:23:30.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 487 LR: 0.0009999996284733132 Training loss: 0.0
2025-12-09 10:23:30.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 488 LR: 0.0009999996265557594 Training loss: 0.0
2025-12-09 10:23:30.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 489 LR: 0.0009999996246332701 Training loss: 0.0
2025-12-09 10:23:30.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 490 LR: 0.0009999996227058447 Training loss: 0.0
2025-12-09 10:23:30.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 491 LR: 0.0009999996207734837 Training loss: 0.0
2025-12-09 10:23:30.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 492 LR: 0.000999999618836187 Training loss: 0.0
2025-12-09 10:23:30.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 493 LR: 0.0009999996168939544 Training loss: 0.0
2025-12-09 10:23:30.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 494 LR: 0.000999999614946786 Training loss: 0.0
2025-12-09 10:23:30.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 495 LR: 0.0009999996129946818 Training loss: 0.0
2025-12-09 10:23:30.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 496 LR: 0.0009999996110376418 Training loss: 0.0
2025-12-09 10:23:30.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 497 LR: 0.000999999609075666 Training loss: 0.0
2025-12-09 10:23:30.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 498 LR: 0.0009999996071087547 Training loss: 0.0
2025-12-09 10:23:30.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 499 LR: 0.0009999996051369073 Training loss: 0.0
2025-12-09 10:23:30.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 500 LR: 0.0009999996031601242 Training loss: 0.0
2025-12-09 10:23:30.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 501 LR: 0.0009999996011784053 Training loss: 0.0
2025-12-09 10:23:30.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 502 LR: 0.0009999995991917506 Training loss: 0.0
2025-12-09 10:23:30.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 503 LR: 0.00099999959720016 Training loss: 0.0
2025-12-09 10:23:30.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 504 LR: 0.0009999995952036339 Training loss: 0.0
2025-12-09 10:23:30.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 505 LR: 0.000999999593202172 Training loss: 0.0
2025-12-09 10:23:30.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 506 LR: 0.000999999591195774 Training loss: 0.0
2025-12-09 10:23:30.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 507 LR: 0.0009999995891844405 Training loss: 0.0
2025-12-09 10:23:30.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 508 LR: 0.000999999587168171 Training loss: 0.0
2025-12-09 10:23:30.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 509 LR: 0.000999999585146966 Training loss: 0.0
2025-12-09 10:23:30.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 510 LR: 0.000999999583120825 Training loss: 0.0
2025-12-09 10:23:30.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 511 LR: 0.0009999995810897483 Training loss: 0.0
2025-12-09 10:23:30.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 512 LR: 0.0009999995790537356 Training loss: 0.0
2025-12-09 10:23:30.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 513 LR: 0.0009999995770127875 Training loss: 0.0
2025-12-09 10:23:30.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 514 LR: 0.0009999995749669032 Training loss: 0.0
2025-12-09 10:23:30.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 515 LR: 0.0009999995729160836 Training loss: 0.0
2025-12-09 10:23:30.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 516 LR: 0.0009999995708603279 Training loss: 0.0
2025-12-09 10:23:30.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 517 LR: 0.0009999995687996364 Training loss: 0.0
2025-12-09 10:23:30.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 518 LR: 0.0009999995667340092 Training loss: 0.0
2025-12-09 10:23:30.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 519 LR: 0.000999999564663446 Training loss: 0.0
2025-12-09 10:23:30.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 520 LR: 0.0009999995625879473 Training loss: 0.0
2025-12-09 10:23:30.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 521 LR: 0.0009999995605075127 Training loss: 0.0
2025-12-09 10:23:30.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 522 LR: 0.0009999995584221424 Training loss: 0.0
2025-12-09 10:23:30.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 523 LR: 0.0009999995563318362 Training loss: 0.0
2025-12-09 10:23:30.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 524 LR: 0.0009999995542365942 Training loss: 0.0
2025-12-09 10:23:30.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 525 LR: 0.0009999995521364166 Training loss: 0.0
2025-12-09 10:23:30.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 526 LR: 0.000999999550031303 Training loss: 0.0
2025-12-09 10:23:30.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 527 LR: 0.0009999995479212538 Training loss: 0.0
2025-12-09 10:23:30.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 528 LR: 0.0009999995458062688 Training loss: 0.0
2025-12-09 10:23:30.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 529 LR: 0.0009999995436863478 Training loss: 0.0
2025-12-09 10:23:30.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 530 LR: 0.000999999541561491 Training loss: 0.0
2025-12-09 10:23:30.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 531 LR: 0.0009999995394316986 Training loss: 0.0
2025-12-09 10:23:30.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 532 LR: 0.0009999995372969705 Training loss: 0.0
2025-12-09 10:23:30.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 533 LR: 0.0009999995351573066 Training loss: 0.0
2025-12-09 10:23:30.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 534 LR: 0.0009999995330127068 Training loss: 0.0
2025-12-09 10:23:30.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 535 LR: 0.000999999530863171 Training loss: 0.0
2025-12-09 10:23:30.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 536 LR: 0.0009999995287086998 Training loss: 0.0
2025-12-09 10:23:30.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 537 LR: 0.0009999995265492928 Training loss: 0.0
2025-12-09 10:23:30.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 538 LR: 0.0009999995243849499 Training loss: 0.0
2025-12-09 10:23:30.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 539 LR: 0.000999999522215671 Training loss: 0.0
2025-12-09 10:23:30.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 540 LR: 0.0009999995200414564 Training loss: 0.0
2025-12-09 10:23:30.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 541 LR: 0.0009999995178623063 Training loss: 0.0
2025-12-09 10:23:30.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 542 LR: 0.0009999995156782203 Training loss: 0.0
2025-12-09 10:23:30.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 543 LR: 0.0009999995134891983 Training loss: 0.0
2025-12-09 10:23:30.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 544 LR: 0.0009999995112952406 Training loss: 0.0
2025-12-09 10:23:30.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 545 LR: 0.0009999995090963472 Training loss: 0.0
2025-12-09 10:23:30.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 546 LR: 0.000999999506892518 Training loss: 0.0
2025-12-09 10:23:30.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 547 LR: 0.000999999504683753 Training loss: 0.0
2025-12-09 10:23:30.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 548 LR: 0.0009999995024700524 Training loss: 0.0
2025-12-09 10:23:30.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 549 LR: 0.0009999995002514157 Training loss: 0.0
2025-12-09 10:23:30.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 550 LR: 0.0009999994980278435 Training loss: 0.0
2025-12-09 10:23:30.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 551 LR: 0.0009999994957993353 Training loss: 0.0
2025-12-09 10:23:30.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 552 LR: 0.0009999994935658914 Training loss: 0.0
2025-12-09 10:23:30.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 553 LR: 0.0009999994913275118 Training loss: 0.0
2025-12-09 10:23:30.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 554 LR: 0.0009999994890841962 Training loss: 0.0
2025-12-09 10:23:30.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 555 LR: 0.000999999486835945 Training loss: 0.0
2025-12-09 10:23:30.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 556 LR: 0.0009999994845827577 Training loss: 0.0
2025-12-09 10:23:30.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 557 LR: 0.000999999482324635 Training loss: 0.0
2025-12-09 10:23:30.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 558 LR: 0.0009999994800615763 Training loss: 0.0
2025-12-09 10:23:30.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 559 LR: 0.000999999477793582 Training loss: 0.0
2025-12-09 10:23:30.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 560 LR: 0.0009999994755206518 Training loss: 0.0
2025-12-09 10:23:30.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 561 LR: 0.000999999473242786 Training loss: 0.0
2025-12-09 10:23:30.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 562 LR: 0.000999999470959984 Training loss: 0.0
2025-12-09 10:23:30.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 563 LR: 0.0009999994686722465 Training loss: 0.0
2025-12-09 10:23:30.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 564 LR: 0.0009999994663795733 Training loss: 0.0
2025-12-09 10:23:30.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 565 LR: 0.0009999994640819642 Training loss: 0.0
2025-12-09 10:23:30.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 566 LR: 0.0009999994617794193 Training loss: 0.0
2025-12-09 10:23:30.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 567 LR: 0.0009999994594719387 Training loss: 0.0
2025-12-09 10:23:30.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 568 LR: 0.0009999994571595222 Training loss: 0.0
2025-12-09 10:23:30.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 569 LR: 0.00099999945484217 Training loss: 0.0
2025-12-09 10:23:30.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 570 LR: 0.000999999452519882 Training loss: 0.0
2025-12-09 10:23:30.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 571 LR: 0.0009999994501926582 Training loss: 0.0
2025-12-09 10:23:30.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 572 LR: 0.0009999994478604984 Training loss: 0.0
2025-12-09 10:23:30.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 573 LR: 0.0009999994455234032 Training loss: 0.0
2025-12-09 10:23:30.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 574 LR: 0.000999999443181372 Training loss: 0.0
2025-12-09 10:23:30.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 575 LR: 0.000999999440834405 Training loss: 0.0
2025-12-09 10:23:30.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 576 LR: 0.0009999994384825024 Training loss: 0.0
2025-12-09 10:23:30.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 577 LR: 0.0009999994361256637 Training loss: 0.0
2025-12-09 10:23:30.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 578 LR: 0.0009999994337638895 Training loss: 0.0
2025-12-09 10:23:30.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 579 LR: 0.0009999994313971794 Training loss: 0.0
2025-12-09 10:23:30.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 580 LR: 0.0009999994290255335 Training loss: 0.0
2025-12-09 10:23:30.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 581 LR: 0.0009999994266489517 Training loss: 0.0
2025-12-09 10:23:30.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 582 LR: 0.0009999994242674344 Training loss: 0.0
2025-12-09 10:23:30.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 583 LR: 0.0009999994218809812 Training loss: 0.0
2025-12-09 10:23:30.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 584 LR: 0.0009999994194895923 Training loss: 0.0
2025-12-09 10:23:30.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 585 LR: 0.0009999994170932674 Training loss: 0.0
2025-12-09 10:23:30.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 586 LR: 0.0009999994146920068 Training loss: 0.0
2025-12-09 10:23:30.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 587 LR: 0.0009999994122858104 Training loss: 0.0
2025-12-09 10:23:30.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 588 LR: 0.0009999994098746784 Training loss: 0.0
2025-12-09 10:23:30.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 589 LR: 0.0009999994074586106 Training loss: 0.0
2025-12-09 10:23:30.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 590 LR: 0.0009999994050376069 Training loss: 0.0
2025-12-09 10:23:30.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 591 LR: 0.0009999994026116674 Training loss: 0.0
2025-12-09 10:23:30.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 592 LR: 0.000999999400180792 Training loss: 0.0
2025-12-09 10:23:30.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 593 LR: 0.0009999993977449812 Training loss: 0.0
2025-12-09 10:23:30.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 594 LR: 0.0009999993953042341 Training loss: 0.0
2025-12-09 10:23:30.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 595 LR: 0.0009999993928585516 Training loss: 0.0
2025-12-09 10:23:30.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 596 LR: 0.000999999390407933 Training loss: 0.0
2025-12-09 10:23:30.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 597 LR: 0.0009999993879523789 Training loss: 0.0
2025-12-09 10:23:30.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 598 LR: 0.000999999385491889 Training loss: 0.0
2025-12-09 10:23:30.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 599 LR: 0.0009999993830264633 Training loss: 0.0
2025-12-09 10:23:30.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 600 LR: 0.0009999993805561017 Training loss: 0.0
2025-12-09 10:23:30.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 601 LR: 0.0009999993780808044 Training loss: 0.0
2025-12-09 10:23:30.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 602 LR: 0.0009999993756005714 Training loss: 0.0
2025-12-09 10:23:30.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 603 LR: 0.0009999993731154024 Training loss: 0.0
2025-12-09 10:23:30.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 604 LR: 0.0009999993706252977 Training loss: 0.0
2025-12-09 10:23:30.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 605 LR: 0.0009999993681302573 Training loss: 0.0
2025-12-09 10:23:30.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 606 LR: 0.000999999365630281 Training loss: 0.0
2025-12-09 10:23:30.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 607 LR: 0.000999999363125369 Training loss: 0.0
2025-12-09 10:23:30.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 608 LR: 0.0009999993606155213 Training loss: 0.0
2025-12-09 10:23:30.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 609 LR: 0.0009999993581007378 Training loss: 0.0
2025-12-09 10:23:30.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 610 LR: 0.0009999993555810183 Training loss: 0.0
2025-12-09 10:23:30.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 611 LR: 0.0009999993530563631 Training loss: 0.0
2025-12-09 10:23:30.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 612 LR: 0.0009999993505267722 Training loss: 0.0
2025-12-09 10:23:30.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 613 LR: 0.0009999993479922456 Training loss: 0.0
2025-12-09 10:23:30.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 614 LR: 0.0009999993454527832 Training loss: 0.0
2025-12-09 10:23:30.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 615 LR: 0.0009999993429083847 Training loss: 0.0
2025-12-09 10:23:30.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 616 LR: 0.0009999993403590507 Training loss: 0.0
2025-12-09 10:23:30.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 617 LR: 0.000999999337804781 Training loss: 0.0
2025-12-09 10:23:30.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 618 LR: 0.0009999993352455753 Training loss: 0.0
2025-12-09 10:23:30.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 619 LR: 0.0009999993326814337 Training loss: 0.0
2025-12-09 10:23:30.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 620 LR: 0.0009999993301123566 Training loss: 0.0
2025-12-09 10:23:30.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 621 LR: 0.0009999993275383436 Training loss: 0.0
2025-12-09 10:23:30.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 622 LR: 0.000999999324959395 Training loss: 0.0
2025-12-09 10:23:30.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 623 LR: 0.0009999993223755103 Training loss: 0.0
2025-12-09 10:23:30.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 624 LR: 0.00099999931978669 Training loss: 0.0
2025-12-09 10:23:30.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 625 LR: 0.000999999317192934 Training loss: 0.0
2025-12-09 10:23:30.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 626 LR: 0.000999999314594242 Training loss: 0.0
2025-12-09 10:23:30.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 627 LR: 0.0009999993119906144 Training loss: 0.0
2025-12-09 10:23:30.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 628 LR: 0.000999999309382051 Training loss: 0.0
2025-12-09 10:23:30.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 629 LR: 0.0009999993067685519 Training loss: 0.0
2025-12-09 10:23:30.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 630 LR: 0.0009999993041501167 Training loss: 0.0
2025-12-09 10:23:30.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 631 LR: 0.000999999301526746 Training loss: 0.0
2025-12-09 10:23:30.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 632 LR: 0.0009999992988984395 Training loss: 0.0
2025-12-09 10:23:30.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 633 LR: 0.000999999296265197 Training loss: 0.0
2025-12-09 10:23:30.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 634 LR: 0.0009999992936270189 Training loss: 0.0
2025-12-09 10:23:30.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 635 LR: 0.0009999992909839048 Training loss: 0.0
2025-12-09 10:23:30.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 636 LR: 0.0009999992883358553 Training loss: 0.0
2025-12-09 10:23:30.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 637 LR: 0.0009999992856828696 Training loss: 0.0
2025-12-09 10:23:30.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 638 LR: 0.0009999992830249484 Training loss: 0.0
2025-12-09 10:23:30.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 639 LR: 0.0009999992803620915 Training loss: 0.0
2025-12-09 10:23:30.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 640 LR: 0.0009999992776942984 Training loss: 0.0
2025-12-09 10:23:30.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 641 LR: 0.0009999992750215699 Training loss: 0.0
2025-12-09 10:23:30.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 642 LR: 0.0009999992723439056 Training loss: 0.0
2025-12-09 10:23:30.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 643 LR: 0.0009999992696613053 Training loss: 0.0
2025-12-09 10:23:30.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 644 LR: 0.0009999992669737694 Training loss: 0.0
2025-12-09 10:23:30.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 645 LR: 0.0009999992642812977 Training loss: 0.0
2025-12-09 10:23:30.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 646 LR: 0.00099999926158389 Training loss: 0.0
2025-12-09 10:23:30.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 647 LR: 0.0009999992588815467 Training loss: 0.0
2025-12-09 10:23:30.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 648 LR: 0.0009999992561742677 Training loss: 0.0
2025-12-09 10:23:30.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 649 LR: 0.0009999992534620527 Training loss: 0.0
2025-12-09 10:23:30.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 650 LR: 0.0009999992507449022 Training loss: 0.0
2025-12-09 10:23:30.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 651 LR: 0.0009999992480228157 Training loss: 0.0
2025-12-09 10:23:30.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 652 LR: 0.0009999992452957936 Training loss: 0.0
2025-12-09 10:23:30.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 653 LR: 0.0009999992425638355 Training loss: 0.0
2025-12-09 10:23:30.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 654 LR: 0.0009999992398269418 Training loss: 0.0
2025-12-09 10:23:30.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 655 LR: 0.000999999237085112 Training loss: 0.0
2025-12-09 10:23:30.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 656 LR: 0.0009999992343383468 Training loss: 0.0
2025-12-09 10:23:30.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 657 LR: 0.0009999992315866456 Training loss: 0.0
2025-12-09 10:23:30.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 658 LR: 0.0009999992288300087 Training loss: 0.0
2025-12-09 10:23:30.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 659 LR: 0.000999999226068436 Training loss: 0.0
2025-12-09 10:23:30.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 660 LR: 0.0009999992233019274 Training loss: 0.0
2025-12-09 10:23:30.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 661 LR: 0.0009999992205304833 Training loss: 0.0
2025-12-09 10:23:30.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 662 LR: 0.0009999992177541033 Training loss: 0.0
2025-12-09 10:23:30.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 663 LR: 0.0009999992149727875 Training loss: 0.0
2025-12-09 10:23:30.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 664 LR: 0.0009999992121865358 Training loss: 0.0
2025-12-09 10:23:30.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 665 LR: 0.0009999992093953484 Training loss: 0.0
2025-12-09 10:23:30.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 666 LR: 0.0009999992065992253 Training loss: 0.0
2025-12-09 10:23:30.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 667 LR: 0.0009999992037981664 Training loss: 0.0
2025-12-09 10:23:30.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 668 LR: 0.0009999992009921716 Training loss: 0.0
2025-12-09 10:23:30.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 669 LR: 0.000999999198181241 Training loss: 0.0
2025-12-09 10:23:30.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 670 LR: 0.0009999991953653748 Training loss: 0.0
2025-12-09 10:23:30.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 671 LR: 0.0009999991925445726 Training loss: 0.0
2025-12-09 10:23:30.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 672 LR: 0.000999999189718835 Training loss: 0.0
2025-12-09 10:23:30.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 673 LR: 0.0009999991868881613 Training loss: 0.0
2025-12-09 10:23:30.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 674 LR: 0.0009999991840525517 Training loss: 0.0
2025-12-09 10:23:30.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 675 LR: 0.0009999991812120067 Training loss: 0.0
2025-12-09 10:23:30.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 676 LR: 0.0009999991783665257 Training loss: 0.0
2025-12-09 10:23:30.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 677 LR: 0.000999999175516109 Training loss: 0.0
2025-12-09 10:23:30.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 678 LR: 0.0009999991726607562 Training loss: 0.0
2025-12-09 10:23:30.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 679 LR: 0.000999999169800468 Training loss: 0.0
2025-12-09 10:23:30.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 680 LR: 0.000999999166935244 Training loss: 0.0
2025-12-09 10:23:30.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 681 LR: 0.0009999991640650841 Training loss: 0.0
2025-12-09 10:23:30.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 682 LR: 0.0009999991611899883 Training loss: 0.0
2025-12-09 10:23:30.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 683 LR: 0.0009999991583099568 Training loss: 0.0
2025-12-09 10:23:30.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 684 LR: 0.0009999991554249896 Training loss: 0.0
2025-12-09 10:23:30.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 685 LR: 0.0009999991525350867 Training loss: 0.0
2025-12-09 10:23:30.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 686 LR: 0.0009999991496402478 Training loss: 0.0
2025-12-09 10:23:30.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 687 LR: 0.0009999991467404732 Training loss: 0.0
2025-12-09 10:23:30.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 688 LR: 0.0009999991438357629 Training loss: 0.0
2025-12-09 10:23:30.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 689 LR: 0.0009999991409261168 Training loss: 0.0
2025-12-09 10:23:30.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 690 LR: 0.0009999991380115348 Training loss: 0.0
2025-12-09 10:23:30.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 691 LR: 0.0009999991350920173 Training loss: 0.0
2025-12-09 10:23:30.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 692 LR: 0.0009999991321675637 Training loss: 0.0
2025-12-09 10:23:30.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 693 LR: 0.0009999991292381745 Training loss: 0.0
2025-12-09 10:23:30.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 694 LR: 0.0009999991263038494 Training loss: 0.0
2025-12-09 10:23:30.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 695 LR: 0.0009999991233645886 Training loss: 0.0
2025-12-09 10:23:30.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 696 LR: 0.000999999120420392 Training loss: 0.0
2025-12-09 10:23:30.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 697 LR: 0.0009999991174712596 Training loss: 0.0
2025-12-09 10:23:30.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 698 LR: 0.0009999991145171914 Training loss: 0.0
2025-12-09 10:23:30.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 699 LR: 0.0009999991115581875 Training loss: 0.0
2025-12-09 10:23:30.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 700 LR: 0.0009999991085942476 Training loss: 0.0
2025-12-09 10:23:30.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 701 LR: 0.0009999991056253723 Training loss: 0.0
2025-12-09 10:23:30.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 702 LR: 0.000999999102651561 Training loss: 0.0
2025-12-09 10:23:30.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 703 LR: 0.000999999099672814 Training loss: 0.0
2025-12-09 10:23:30.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 704 LR: 0.000999999096689131 Training loss: 0.0
2025-12-09 10:23:30.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 705 LR: 0.0009999990937005125 Training loss: 0.0
2025-12-09 10:23:30.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 706 LR: 0.0009999990907069581 Training loss: 0.0
2025-12-09 10:23:30.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 707 LR: 0.000999999087708468 Training loss: 0.0
2025-12-09 10:23:30.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 708 LR: 0.000999999084705042 Training loss: 0.0
2025-12-09 10:23:30.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 709 LR: 0.0009999990816966801 Training loss: 0.0
2025-12-09 10:23:30.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 710 LR: 0.0009999990786833826 Training loss: 0.0
2025-12-09 10:23:30.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 711 LR: 0.0009999990756651494 Training loss: 0.0
2025-12-09 10:23:30.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 712 LR: 0.0009999990726419802 Training loss: 0.0
2025-12-09 10:23:30.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 713 LR: 0.0009999990696138755 Training loss: 0.0
2025-12-09 10:23:30.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 714 LR: 0.0009999990665808347 Training loss: 0.0
2025-12-09 10:23:30.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 715 LR: 0.0009999990635428584 Training loss: 0.0
2025-12-09 10:23:30.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 716 LR: 0.000999999060499946 Training loss: 0.0
2025-12-09 10:23:30.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 717 LR: 0.000999999057452098 Training loss: 0.0
2025-12-09 10:23:30.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 718 LR: 0.0009999990543993144 Training loss: 0.0
2025-12-09 10:23:30.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 719 LR: 0.000999999051341595 Training loss: 0.0
2025-12-09 10:23:30.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 720 LR: 0.0009999990482789396 Training loss: 0.0
2025-12-09 10:23:30.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 721 LR: 0.0009999990452113482 Training loss: 0.0
2025-12-09 10:23:30.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 722 LR: 0.0009999990421388214 Training loss: 0.0
2025-12-09 10:23:30.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 723 LR: 0.0009999990390613589 Training loss: 0.0
2025-12-09 10:23:30.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 724 LR: 0.0009999990359789604 Training loss: 0.0
2025-12-09 10:23:30.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 725 LR: 0.0009999990328916262 Training loss: 0.0
2025-12-09 10:23:30.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 726 LR: 0.0009999990297993562 Training loss: 0.0
2025-12-09 10:23:30.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 727 LR: 0.0009999990267021504 Training loss: 0.0
2025-12-09 10:23:30.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 728 LR: 0.0009999990236000088 Training loss: 0.0
2025-12-09 10:23:30.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 729 LR: 0.0009999990204929315 Training loss: 0.0
2025-12-09 10:23:30.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 730 LR: 0.0009999990173809184 Training loss: 0.0
2025-12-09 10:23:30.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 731 LR: 0.0009999990142639695 Training loss: 0.0
2025-12-09 10:23:30.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 732 LR: 0.0009999990111420848 Training loss: 0.0
2025-12-09 10:23:30.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 733 LR: 0.0009999990080152643 Training loss: 0.0
2025-12-09 10:23:30.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 734 LR: 0.000999999004883508 Training loss: 0.0
2025-12-09 10:23:30.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 735 LR: 0.000999999001746816 Training loss: 0.0
2025-12-09 10:23:30.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 736 LR: 0.0009999989986051883 Training loss: 0.0
2025-12-09 10:23:30.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 737 LR: 0.0009999989954586246 Training loss: 0.0
2025-12-09 10:23:30.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 738 LR: 0.0009999989923071253 Training loss: 0.0
2025-12-09 10:23:30.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 739 LR: 0.0009999989891506902 Training loss: 0.0
2025-12-09 10:23:30.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 740 LR: 0.0009999989859893193 Training loss: 0.0
2025-12-09 10:23:30.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 741 LR: 0.0009999989828230124 Training loss: 0.0
2025-12-09 10:23:30.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 742 LR: 0.00099999897965177 Training loss: 0.0
2025-12-09 10:23:30.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 743 LR: 0.0009999989764755918 Training loss: 0.0
2025-12-09 10:23:30.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 744 LR: 0.0009999989732944778 Training loss: 0.0
2025-12-09 10:23:30.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 745 LR: 0.000999998970108428 Training loss: 0.0
2025-12-09 10:23:30.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 746 LR: 0.0009999989669174424 Training loss: 0.0
2025-12-09 10:23:30.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 747 LR: 0.000999998963721521 Training loss: 0.0
2025-12-09 10:23:30.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 748 LR: 0.0009999989605206639 Training loss: 0.0
2025-12-09 10:23:30.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 749 LR: 0.0009999989573148708 Training loss: 0.0
2025-12-09 10:23:30.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 750 LR: 0.000999998954104142 Training loss: 0.0
2025-12-09 10:23:30.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 751 LR: 0.0009999989508884778 Training loss: 0.0
2025-12-09 10:23:30.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 752 LR: 0.0009999989476678775 Training loss: 0.0
2025-12-09 10:23:30.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 753 LR: 0.0009999989444423414 Training loss: 0.0
2025-12-09 10:23:30.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 754 LR: 0.0009999989412118695 Training loss: 0.0
2025-12-09 10:23:30.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 755 LR: 0.000999998937976462 Training loss: 0.0
2025-12-09 10:23:30.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 756 LR: 0.0009999989347361186 Training loss: 0.0
2025-12-09 10:23:30.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 757 LR: 0.0009999989314908393 Training loss: 0.0
2025-12-09 10:23:30.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 758 LR: 0.0009999989282406245 Training loss: 0.0
2025-12-09 10:23:30.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 759 LR: 0.0009999989249854738 Training loss: 0.0
2025-12-09 10:23:30.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 760 LR: 0.0009999989217253874 Training loss: 0.0
2025-12-09 10:23:30.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 761 LR: 0.000999998918460365 Training loss: 0.0
2025-12-09 10:23:30.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 762 LR: 0.000999998915190407 Training loss: 0.0
2025-12-09 10:23:30.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 763 LR: 0.0009999989119155131 Training loss: 0.0
2025-12-09 10:23:30.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 764 LR: 0.0009999989086356834 Training loss: 0.0
2025-12-09 10:23:30.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 765 LR: 0.000999998905350918 Training loss: 0.0
2025-12-09 10:23:30.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 766 LR: 0.000999998902061217 Training loss: 0.0
2025-12-09 10:23:30.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 767 LR: 0.00099999889876658 Training loss: 0.0
2025-12-09 10:23:30.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 768 LR: 0.0009999988954670072 Training loss: 0.0
2025-12-09 10:23:30.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 769 LR: 0.0009999988921624988 Training loss: 0.0
2025-12-09 10:23:30.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 770 LR: 0.0009999988888530545 Training loss: 0.0
2025-12-09 10:23:30.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 771 LR: 0.0009999988855386743 Training loss: 0.0
2025-12-09 10:23:30.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 772 LR: 0.0009999988822193585 Training loss: 0.0
2025-12-09 10:23:30.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 773 LR: 0.0009999988788951069 Training loss: 0.0
2025-12-09 10:23:30.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 774 LR: 0.0009999988755659195 Training loss: 0.0
2025-12-09 10:23:30.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 775 LR: 0.0009999988722317963 Training loss: 0.0
2025-12-09 10:23:30.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 776 LR: 0.0009999988688927375 Training loss: 0.0
2025-12-09 10:23:30.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 777 LR: 0.0009999988655487427 Training loss: 0.0
2025-12-09 10:23:30.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 778 LR: 0.0009999988621998122 Training loss: 0.0
2025-12-09 10:23:30.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 779 LR: 0.000999998858845946 Training loss: 0.0
2025-12-09 10:23:30.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 780 LR: 0.0009999988554871438 Training loss: 0.0
2025-12-09 10:23:30.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 781 LR: 0.000999998852123406 Training loss: 0.0
2025-12-09 10:23:30.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 782 LR: 0.0009999988487547323 Training loss: 0.0
2025-12-09 10:23:30.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 783 LR: 0.000999998845381123 Training loss: 0.0
2025-12-09 10:23:30.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 784 LR: 0.0009999988420025777 Training loss: 0.0
2025-12-09 10:23:30.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 785 LR: 0.000999998838619097 Training loss: 0.0
2025-12-09 10:23:30.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 786 LR: 0.00099999883523068 Training loss: 0.0
2025-12-09 10:23:30.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 787 LR: 0.0009999988318373275 Training loss: 0.0
2025-12-09 10:23:30.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 788 LR: 0.0009999988284390394 Training loss: 0.0
2025-12-09 10:23:30.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 789 LR: 0.0009999988250358153 Training loss: 0.0
2025-12-09 10:23:30.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 790 LR: 0.0009999988216276552 Training loss: 0.0
2025-12-09 10:23:30.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 791 LR: 0.0009999988182145597 Training loss: 0.0
2025-12-09 10:23:30.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 792 LR: 0.0009999988147965284 Training loss: 0.0
2025-12-09 10:23:30.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 793 LR: 0.0009999988113735612 Training loss: 0.0
2025-12-09 10:23:30.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 794 LR: 0.000999998807945658 Training loss: 0.0
2025-12-09 10:23:30.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 795 LR: 0.0009999988045128194 Training loss: 0.0
2025-12-09 10:23:30.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 796 LR: 0.0009999988010750448 Training loss: 0.0
2025-12-09 10:23:30.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 797 LR: 0.0009999987976323345 Training loss: 0.0
2025-12-09 10:23:30.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 798 LR: 0.0009999987941846887 Training loss: 0.0
2025-12-09 10:23:30.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 799 LR: 0.0009999987907321067 Training loss: 0.0
2025-12-09 10:23:30.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 800 LR: 0.000999998787274589 Training loss: 0.0
2025-12-09 10:23:30.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 801 LR: 0.0009999987838121356 Training loss: 0.0
2025-12-09 10:23:30.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 802 LR: 0.0009999987803447465 Training loss: 0.0
2025-12-09 10:23:30.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 803 LR: 0.0009999987768724216 Training loss: 0.0
2025-12-09 10:23:30.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 804 LR: 0.0009999987733951608 Training loss: 0.0
2025-12-09 10:23:30.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 805 LR: 0.0009999987699129643 Training loss: 0.0
2025-12-09 10:23:30.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 806 LR: 0.000999998766425832 Training loss: 0.0
2025-12-09 10:23:30.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 807 LR: 0.0009999987629337641 Training loss: 0.0
2025-12-09 10:23:30.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 808 LR: 0.0009999987594367602 Training loss: 0.0
2025-12-09 10:23:30.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 809 LR: 0.0009999987559348206 Training loss: 0.0
2025-12-09 10:23:30.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 810 LR: 0.0009999987524279452 Training loss: 0.0
2025-12-09 10:23:30.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 811 LR: 0.000999998748916134 Training loss: 0.0
2025-12-09 10:23:30.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 812 LR: 0.0009999987453993872 Training loss: 0.0
2025-12-09 10:23:30.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 813 LR: 0.0009999987418777044 Training loss: 0.0
2025-12-09 10:23:30.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 814 LR: 0.0009999987383510858 Training loss: 0.0
2025-12-09 10:23:30.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 815 LR: 0.0009999987348195316 Training loss: 0.0
2025-12-09 10:23:30.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 816 LR: 0.0009999987312830415 Training loss: 0.0
2025-12-09 10:23:30.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 817 LR: 0.0009999987277416157 Training loss: 0.0
2025-12-09 10:23:30.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 818 LR: 0.000999998724195254 Training loss: 0.0
2025-12-09 10:23:30.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 819 LR: 0.0009999987206439566 Training loss: 0.0
2025-12-09 10:23:30.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 820 LR: 0.0009999987170877236 Training loss: 0.0
2025-12-09 10:23:30.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 821 LR: 0.0009999987135265547 Training loss: 0.0
2025-12-09 10:23:30.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 822 LR: 0.00099999870996045 Training loss: 0.0
2025-12-09 10:23:30.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 823 LR: 0.0009999987063894094 Training loss: 0.0
2025-12-09 10:23:30.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 824 LR: 0.000999998702813433 Training loss: 0.0
2025-12-09 10:23:30.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 825 LR: 0.000999998699232521 Training loss: 0.0
2025-12-09 10:23:30.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 826 LR: 0.0009999986956466733 Training loss: 0.0
2025-12-09 10:23:30.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 827 LR: 0.0009999986920558896 Training loss: 0.0
2025-12-09 10:23:30.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 828 LR: 0.0009999986884601704 Training loss: 0.0
2025-12-09 10:23:30.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 829 LR: 0.0009999986848595152 Training loss: 0.0
2025-12-09 10:23:30.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 830 LR: 0.0009999986812539241 Training loss: 0.0
2025-12-09 10:23:30.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 831 LR: 0.0009999986776433975 Training loss: 0.0
2025-12-09 10:23:30.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 832 LR: 0.000999998674027935 Training loss: 0.0
2025-12-09 10:23:30.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 833 LR: 0.0009999986704075368 Training loss: 0.0
2025-12-09 10:23:30.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 834 LR: 0.0009999986667822028 Training loss: 0.0
2025-12-09 10:23:30.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 835 LR: 0.0009999986631519329 Training loss: 0.0
2025-12-09 10:23:30.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 836 LR: 0.0009999986595167275 Training loss: 0.0
2025-12-09 10:23:30.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 837 LR: 0.000999998655876586 Training loss: 0.0
2025-12-09 10:23:30.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 838 LR: 0.0009999986522315088 Training loss: 0.0
2025-12-09 10:23:30.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 839 LR: 0.000999998648581496 Training loss: 0.0
2025-12-09 10:23:30.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 840 LR: 0.0009999986449265473 Training loss: 0.0
2025-12-09 10:23:30.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 841 LR: 0.0009999986412666628 Training loss: 0.0
2025-12-09 10:23:30.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 842 LR: 0.0009999986376018426 Training loss: 0.0
2025-12-09 10:23:30.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 843 LR: 0.0009999986339320865 Training loss: 0.0
2025-12-09 10:23:30.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 844 LR: 0.0009999986302573949 Training loss: 0.0
2025-12-09 10:23:30.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 845 LR: 0.000999998626577767 Training loss: 0.0
2025-12-09 10:23:30.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 846 LR: 0.0009999986228932038 Training loss: 0.0
2025-12-09 10:23:30.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 847 LR: 0.0009999986192037048 Training loss: 0.0
2025-12-09 10:23:30.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 848 LR: 0.00099999861550927 Training loss: 0.0
2025-12-09 10:23:30.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 849 LR: 0.0009999986118098992 Training loss: 0.0
2025-12-09 10:23:30.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 850 LR: 0.0009999986081055928 Training loss: 0.0
2025-12-09 10:23:30.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 851 LR: 0.0009999986043963504 Training loss: 0.0
2025-12-09 10:23:30.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 852 LR: 0.0009999986006821726 Training loss: 0.0
2025-12-09 10:23:30.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 853 LR: 0.0009999985969630586 Training loss: 0.0
2025-12-09 10:23:30.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 854 LR: 0.0009999985932390091 Training loss: 0.0
2025-12-09 10:23:30.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 855 LR: 0.000999998589510024 Training loss: 0.0
2025-12-09 10:23:30.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 856 LR: 0.0009999985857761027 Training loss: 0.0
2025-12-09 10:23:30.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 857 LR: 0.0009999985820372459 Training loss: 0.0
2025-12-09 10:23:30.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 858 LR: 0.0009999985782934533 Training loss: 0.0
2025-12-09 10:23:30.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 859 LR: 0.000999998574544725 Training loss: 0.0
2025-12-09 10:23:30.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 860 LR: 0.0009999985707910607 Training loss: 0.0
2025-12-09 10:23:30.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 861 LR: 0.0009999985670324607 Training loss: 0.0
2025-12-09 10:23:30.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 862 LR: 0.000999998563268925 Training loss: 0.0
2025-12-09 10:23:30.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 863 LR: 0.0009999985595004536 Training loss: 0.0
2025-12-09 10:23:30.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 864 LR: 0.0009999985557270462 Training loss: 0.0
2025-12-09 10:23:30.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 865 LR: 0.000999998551948703 Training loss: 0.0
2025-12-09 10:23:30.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 866 LR: 0.0009999985481654243 Training loss: 0.0
2025-12-09 10:23:30.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 867 LR: 0.0009999985443772095 Training loss: 0.0
2025-12-09 10:23:30.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 868 LR: 0.0009999985405840593 Training loss: 0.0
2025-12-09 10:23:30.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 869 LR: 0.0009999985367859729 Training loss: 0.0
2025-12-09 10:23:30.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 870 LR: 0.0009999985329829512 Training loss: 0.0
2025-12-09 10:23:30.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 871 LR: 0.0009999985291749933 Training loss: 0.0
2025-12-09 10:23:30.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 872 LR: 0.0009999985253620997 Training loss: 0.0
2025-12-09 10:23:30.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 873 LR: 0.0009999985215442707 Training loss: 0.0
2025-12-09 10:23:30.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 874 LR: 0.0009999985177215054 Training loss: 0.0
2025-12-09 10:23:30.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 875 LR: 0.0009999985138938047 Training loss: 0.0
2025-12-09 10:23:30.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 876 LR: 0.0009999985100611682 Training loss: 0.0
2025-12-09 10:23:30.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 877 LR: 0.0009999985062235956 Training loss: 0.0
2025-12-09 10:23:30.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 878 LR: 0.0009999985023810877 Training loss: 0.0
2025-12-09 10:23:30.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 879 LR: 0.0009999984985336436 Training loss: 0.0
2025-12-09 10:23:30.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 880 LR: 0.0009999984946812638 Training loss: 0.0
2025-12-09 10:23:30.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 881 LR: 0.0009999984908239485 Training loss: 0.0
2025-12-09 10:23:30.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 882 LR: 0.0009999984869616973 Training loss: 0.0
2025-12-09 10:23:30.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 883 LR: 0.0009999984830945103 Training loss: 0.0
2025-12-09 10:23:30.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 884 LR: 0.0009999984792223875 Training loss: 0.0
2025-12-09 10:23:30.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 885 LR: 0.0009999984753453288 Training loss: 0.0
2025-12-09 10:23:30.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 886 LR: 0.0009999984714633345 Training loss: 0.0
2025-12-09 10:23:30.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 887 LR: 0.0009999984675764045 Training loss: 0.0
2025-12-09 10:23:30.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 888 LR: 0.0009999984636845385 Training loss: 0.0
2025-12-09 10:23:30.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 889 LR: 0.000999998459787737 Training loss: 0.0
2025-12-09 10:23:30.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 890 LR: 0.0009999984558859995 Training loss: 0.0
2025-12-09 10:23:30.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 891 LR: 0.0009999984519793264 Training loss: 0.0
2025-12-09 10:23:30.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 892 LR: 0.0009999984480677173 Training loss: 0.0
2025-12-09 10:23:30.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 893 LR: 0.0009999984441511724 Training loss: 0.0
2025-12-09 10:23:30.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 894 LR: 0.000999998440229692 Training loss: 0.0
2025-12-09 10:23:30.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 895 LR: 0.0009999984363032756 Training loss: 0.0
2025-12-09 10:23:30.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 896 LR: 0.0009999984323719236 Training loss: 0.0
2025-12-09 10:23:30.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 897 LR: 0.0009999984284356357 Training loss: 0.0
2025-12-09 10:23:30.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 898 LR: 0.000999998424494412 Training loss: 0.0
2025-12-09 10:23:30.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 899 LR: 0.0009999984205482527 Training loss: 0.0
2025-12-09 10:23:30.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 900 LR: 0.0009999984165971576 Training loss: 0.0
2025-12-09 10:23:30.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 901 LR: 0.0009999984126411266 Training loss: 0.0
2025-12-09 10:23:30.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 902 LR: 0.0009999984086801598 Training loss: 0.0
2025-12-09 10:23:30.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 903 LR: 0.0009999984047142573 Training loss: 0.0
2025-12-09 10:23:30.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 904 LR: 0.0009999984007434191 Training loss: 0.0
2025-12-09 10:23:30.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 905 LR: 0.000999998396767645 Training loss: 0.0
2025-12-09 10:23:30.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 906 LR: 0.0009999983927869351 Training loss: 0.0
2025-12-09 10:23:30.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 907 LR: 0.0009999983888012895 Training loss: 0.0
2025-12-09 10:23:30.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 908 LR: 0.0009999983848107082 Training loss: 0.0
2025-12-09 10:23:30.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 909 LR: 0.0009999983808151912 Training loss: 0.0
2025-12-09 10:23:30.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 910 LR: 0.0009999983768147383 Training loss: 0.0
2025-12-09 10:23:30.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 911 LR: 0.0009999983728093496 Training loss: 0.0
2025-12-09 10:23:30.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 912 LR: 0.0009999983687990252 Training loss: 0.0
2025-12-09 10:23:30.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 913 LR: 0.0009999983647837648 Training loss: 0.0
2025-12-09 10:23:30.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 914 LR: 0.0009999983607635687 Training loss: 0.0
2025-12-09 10:23:30.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 915 LR: 0.000999998356738437 Training loss: 0.0
2025-12-09 10:23:30.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 916 LR: 0.0009999983527083694 Training loss: 0.0
2025-12-09 10:23:30.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 917 LR: 0.0009999983486733662 Training loss: 0.0
2025-12-09 10:23:30.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 918 LR: 0.000999998344633427 Training loss: 0.0
2025-12-09 10:23:30.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 919 LR: 0.0009999983405885521 Training loss: 0.0
2025-12-09 10:23:30.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 920 LR: 0.0009999983365387415 Training loss: 0.0
2025-12-09 10:23:30.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 921 LR: 0.0009999983324839952 Training loss: 0.0
2025-12-09 10:23:30.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 922 LR: 0.000999998328424313 Training loss: 0.0
2025-12-09 10:23:30.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 923 LR: 0.0009999983243596951 Training loss: 0.0
2025-12-09 10:23:30.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 924 LR: 0.0009999983202901412 Training loss: 0.0
2025-12-09 10:23:30.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 925 LR: 0.0009999983162156517 Training loss: 0.0
2025-12-09 10:23:30.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 926 LR: 0.0009999983121362266 Training loss: 0.0
2025-12-09 10:23:30.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 927 LR: 0.0009999983080518655 Training loss: 0.0
2025-12-09 10:23:30.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 928 LR: 0.0009999983039625686 Training loss: 0.0
2025-12-09 10:23:30.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 929 LR: 0.000999998299868336 Training loss: 0.0
2025-12-09 10:23:30.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 930 LR: 0.0009999982957691676 Training loss: 0.0
2025-12-09 10:23:30.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 931 LR: 0.0009999982916650634 Training loss: 0.0
2025-12-09 10:23:30.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 932 LR: 0.0009999982875560237 Training loss: 0.0
2025-12-09 10:23:30.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 933 LR: 0.0009999982834420478 Training loss: 0.0
2025-12-09 10:23:30.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 934 LR: 0.0009999982793231364 Training loss: 0.0
2025-12-09 10:23:30.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 935 LR: 0.0009999982751992891 Training loss: 0.0
2025-12-09 10:23:30.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 936 LR: 0.0009999982710705063 Training loss: 0.0
2025-12-09 10:23:30.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 937 LR: 0.0009999982669367873 Training loss: 0.0
2025-12-09 10:23:30.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 938 LR: 0.0009999982627981329 Training loss: 0.0
2025-12-09 10:23:30.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 939 LR: 0.0009999982586545424 Training loss: 0.0
2025-12-09 10:23:30.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 940 LR: 0.0009999982545060165 Training loss: 0.0
2025-12-09 10:23:30.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 941 LR: 0.0009999982503525546 Training loss: 0.0
2025-12-09 10:23:30.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 942 LR: 0.000999998246194157 Training loss: 0.0
2025-12-09 10:23:30.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 943 LR: 0.0009999982420308235 Training loss: 0.0
2025-12-09 10:23:30.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 944 LR: 0.0009999982378625543 Training loss: 0.0
2025-12-09 10:23:30.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 945 LR: 0.0009999982336893493 Training loss: 0.0
2025-12-09 10:23:30.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 946 LR: 0.0009999982295112086 Training loss: 0.0
2025-12-09 10:23:30.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 947 LR: 0.000999998225328132 Training loss: 0.0
2025-12-09 10:23:30.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 948 LR: 0.0009999982211401199 Training loss: 0.0
2025-12-09 10:23:30.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 949 LR: 0.000999998216947172 Training loss: 0.0
2025-12-09 10:23:30.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 950 LR: 0.0009999982127492882 Training loss: 0.0
2025-12-09 10:23:30.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 951 LR: 0.0009999982085464685 Training loss: 0.0
2025-12-09 10:23:30.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 952 LR: 0.000999998204338713 Training loss: 0.0
2025-12-09 10:23:30.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 953 LR: 0.0009999982001260219 Training loss: 0.0
2025-12-09 10:23:30.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 954 LR: 0.0009999981959083952 Training loss: 0.0
2025-12-09 10:23:30.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 955 LR: 0.0009999981916858326 Training loss: 0.0
2025-12-09 10:23:30.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 956 LR: 0.000999998187458334 Training loss: 0.0
2025-12-09 10:23:30.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 957 LR: 0.0009999981832258997 Training loss: 0.0
2025-12-09 10:23:30.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 958 LR: 0.0009999981789885297 Training loss: 0.0
2025-12-09 10:23:30.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 959 LR: 0.0009999981747462242 Training loss: 0.0
2025-12-09 10:23:30.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 960 LR: 0.0009999981704989825 Training loss: 0.0
2025-12-09 10:23:30.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 961 LR: 0.0009999981662468052 Training loss: 0.0
2025-12-09 10:23:30.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 962 LR: 0.0009999981619896923 Training loss: 0.0
2025-12-09 10:23:30.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 963 LR: 0.0009999981577276434 Training loss: 0.0
2025-12-09 10:23:30.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 964 LR: 0.0009999981534606587 Training loss: 0.0
2025-12-09 10:23:30.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 965 LR: 0.0009999981491887384 Training loss: 0.0
2025-12-09 10:23:30.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 966 LR: 0.0009999981449118822 Training loss: 0.0
2025-12-09 10:23:30.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 967 LR: 0.0009999981406300902 Training loss: 0.0
2025-12-09 10:23:30.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 968 LR: 0.0009999981363433626 Training loss: 0.0
2025-12-09 10:23:30.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 969 LR: 0.000999998132051699 Training loss: 0.0
2025-12-09 10:23:30.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 970 LR: 0.0009999981277550999 Training loss: 0.0
2025-12-09 10:23:30.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 971 LR: 0.0009999981234535649 Training loss: 0.0
2025-12-09 10:23:30.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 972 LR: 0.000999998119147094 Training loss: 0.0
2025-12-09 10:23:30.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 973 LR: 0.0009999981148356876 Training loss: 0.0
2025-12-09 10:23:30.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 974 LR: 0.0009999981105193452 Training loss: 0.0
2025-12-09 10:23:30.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 975 LR: 0.000999998106198067 Training loss: 0.0
2025-12-09 10:23:30.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 976 LR: 0.0009999981018718532 Training loss: 0.0
2025-12-09 10:23:30.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 977 LR: 0.0009999980975407036 Training loss: 0.0
2025-12-09 10:23:30.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 978 LR: 0.0009999980932046183 Training loss: 0.0
2025-12-09 10:23:30.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 979 LR: 0.000999998088863597 Training loss: 0.0
2025-12-09 10:23:30.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 980 LR: 0.00099999808451764 Training loss: 0.0
2025-12-09 10:23:30.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 981 LR: 0.0009999980801667474 Training loss: 0.0
2025-12-09 10:23:30.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 982 LR: 0.000999998075810919 Training loss: 0.0
2025-12-09 10:23:30.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 983 LR: 0.0009999980714501546 Training loss: 0.0
2025-12-09 10:23:30.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 984 LR: 0.0009999980670844545 Training loss: 0.0
2025-12-09 10:23:30.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 985 LR: 0.0009999980627138187 Training loss: 0.0
2025-12-09 10:23:30.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 986 LR: 0.0009999980583382472 Training loss: 0.0
2025-12-09 10:23:30.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 987 LR: 0.00099999805395774 Training loss: 0.0
2025-12-09 10:23:30.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 988 LR: 0.000999998049572297 Training loss: 0.0
2025-12-09 10:23:30.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 989 LR: 0.0009999980451819179 Training loss: 0.0
2025-12-09 10:23:30.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 990 LR: 0.0009999980407866033 Training loss: 0.0
2025-12-09 10:23:30.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 991 LR: 0.000999998036386353 Training loss: 0.0
2025-12-09 10:23:30.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 992 LR: 0.0009999980319811666 Training loss: 0.0
2025-12-09 10:23:30.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 993 LR: 0.0009999980275710448 Training loss: 0.0
2025-12-09 10:23:30.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 994 LR: 0.000999998023155987 Training loss: 0.0
2025-12-09 10:23:30.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 995 LR: 0.0009999980187359934 Training loss: 0.0
2025-12-09 10:23:30.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 996 LR: 0.0009999980143110643 Training loss: 0.0
2025-12-09 10:23:30.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 997 LR: 0.0009999980098811991 Training loss: 0.0
2025-12-09 10:23:30.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 998 LR: 0.0009999980054463983 Training loss: 0.0
2025-12-09 10:23:30.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 999 LR: 0.0009999980010066618 Training loss: 0.0
2025-12-09 10:23:30.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 1000 LR: 0.0009999979965619895 Training loss: 0.0
2025-12-09 10:23:30.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 1001 LR: 0.0009999979921123815 Training loss: 0.0
2025-12-09 10:23:30.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 1002 LR: 0.0009999979876578375 Training loss: 0.0
2025-12-09 10:23:30.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 1003 LR: 0.0009999979831983579 Training loss: 0.0
2025-12-09 10:23:30.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 1004 LR: 0.0009999979787339423 Training loss: 0.0
2025-12-09 10:23:30.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 1005 LR: 0.0009999979742645912 Training loss: 0.0
2025-12-09 10:23:30.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 1006 LR: 0.0009999979697903044 Training loss: 0.0
2025-12-09 10:23:30.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 1007 LR: 0.0009999979653110816 Training loss: 0.0
2025-12-09 10:23:30.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 1008 LR: 0.000999997960826923 Training loss: 0.0
2025-12-09 10:23:30.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 1009 LR: 0.0009999979563378287 Training loss: 0.0
2025-12-09 10:23:30.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 1010 LR: 0.0009999979518437987 Training loss: 0.0
2025-12-09 10:23:30.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 1011 LR: 0.0009999979473448329 Training loss: 0.0
2025-12-09 10:23:30.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 1012 LR: 0.0009999979428409313 Training loss: 0.0
2025-12-09 10:23:30.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 1013 LR: 0.000999997938332094 Training loss: 0.0
2025-12-09 10:23:30.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 1014 LR: 0.000999997933818321 Training loss: 0.0
2025-12-09 10:23:30.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 1015 LR: 0.000999997929299612 Training loss: 0.0
2025-12-09 10:23:30.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 1016 LR: 0.0009999979247759675 Training loss: 0.0
2025-12-09 10:23:30.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 1017 LR: 0.000999997920247387 Training loss: 0.0
2025-12-09 10:23:30.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 1018 LR: 0.0009999979157138707 Training loss: 0.0
2025-12-09 10:23:30.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 1019 LR: 0.0009999979111754188 Training loss: 0.0
2025-12-09 10:23:30.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 1020 LR: 0.000999997906632031 Training loss: 0.0
2025-12-09 10:23:30.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 1021 LR: 0.0009999979020837075 Training loss: 0.0
2025-12-09 10:23:30.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 1022 LR: 0.0009999978975304483 Training loss: 0.0
2025-12-09 10:23:30.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 1023 LR: 0.0009999978929722533 Training loss: 0.0
2025-12-09 10:23:30.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 1024 LR: 0.0009999978884091226 Training loss: 0.0
2025-12-09 10:23:30.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 1025 LR: 0.000999997883841056 Training loss: 0.0
2025-12-09 10:23:30.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 1026 LR: 0.0009999978792680536 Training loss: 0.0
2025-12-09 10:23:30.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 1027 LR: 0.0009999978746901156 Training loss: 0.0
2025-12-09 10:23:30.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 1028 LR: 0.0009999978701072415 Training loss: 0.0
2025-12-09 10:23:30.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 1029 LR: 0.000999997865519432 Training loss: 0.0
2025-12-09 10:23:30.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 1030 LR: 0.0009999978609266866 Training loss: 0.0
2025-12-09 10:23:30.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 1031 LR: 0.0009999978563290054 Training loss: 0.0
2025-12-09 10:23:30.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 1032 LR: 0.0009999978517263885 Training loss: 0.0
2025-12-09 10:23:30.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 1033 LR: 0.0009999978471188359 Training loss: 0.0
2025-12-09 10:23:30.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 1034 LR: 0.0009999978425063473 Training loss: 0.0
2025-12-09 10:23:30.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 1035 LR: 0.000999997837888923 Training loss: 0.0
2025-12-09 10:23:30.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 1036 LR: 0.000999997833266563 Training loss: 0.0
2025-12-09 10:23:30.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 1037 LR: 0.0009999978286392673 Training loss: 0.0
2025-12-09 10:23:30.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 1038 LR: 0.0009999978240070356 Training loss: 0.0
2025-12-09 10:23:30.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 1039 LR: 0.0009999978193698683 Training loss: 0.0
2025-12-09 10:23:30.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 1040 LR: 0.0009999978147277654 Training loss: 0.0
2025-12-09 10:23:30.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 1041 LR: 0.0009999978100807263 Training loss: 0.0
2025-12-09 10:23:30.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 1042 LR: 0.0009999978054287518 Training loss: 0.0
2025-12-09 10:23:30.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 1043 LR: 0.0009999978007718413 Training loss: 0.0
2025-12-09 10:23:30.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 1044 LR: 0.0009999977961099953 Training loss: 0.0
2025-12-09 10:23:30.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 1045 LR: 0.0009999977914432131 Training loss: 0.0
2025-12-09 10:23:30.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 1046 LR: 0.0009999977867714955 Training loss: 0.0
2025-12-09 10:23:30.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 1047 LR: 0.000999997782094842 Training loss: 0.0
2025-12-09 10:23:30.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 1048 LR: 0.000999997777413253 Training loss: 0.0
2025-12-09 10:23:30.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 1049 LR: 0.000999997772726728 Training loss: 0.0
2025-12-09 10:23:30.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 1050 LR: 0.0009999977680352672 Training loss: 0.0
2025-12-09 10:23:30.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 1051 LR: 0.0009999977633388707 Training loss: 0.0
2025-12-09 10:23:30.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 1052 LR: 0.0009999977586375383 Training loss: 0.0
2025-12-09 10:23:30.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 1053 LR: 0.0009999977539312701 Training loss: 0.0
2025-12-09 10:23:30.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 1054 LR: 0.0009999977492200665 Training loss: 0.0
2025-12-09 10:23:30.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 1055 LR: 0.0009999977445039267 Training loss: 0.0
2025-12-09 10:23:30.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 1056 LR: 0.0009999977397828514 Training loss: 0.0
2025-12-09 10:23:30.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 1057 LR: 0.0009999977350568403 Training loss: 0.0
2025-12-09 10:23:30.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 1058 LR: 0.0009999977303258934 Training loss: 0.0
2025-12-09 10:23:30.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 1059 LR: 0.0009999977255900107 Training loss: 0.0
2025-12-09 10:23:30.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 1060 LR: 0.0009999977208491923 Training loss: 0.0
2025-12-09 10:23:30.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 1061 LR: 0.0009999977161034381 Training loss: 0.0
2025-12-09 10:23:30.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 1062 LR: 0.000999997711352748 Training loss: 0.0
2025-12-09 10:23:30.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 1063 LR: 0.0009999977065971225 Training loss: 0.0
2025-12-09 10:23:30.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 1064 LR: 0.000999997701836561 Training loss: 0.0
2025-12-09 10:23:30.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 1065 LR: 0.0009999976970710635 Training loss: 0.0
2025-12-09 10:23:30.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 1066 LR: 0.0009999976923006307 Training loss: 0.0
2025-12-09 10:23:30.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 1067 LR: 0.0009999976875252618 Training loss: 0.0
2025-12-09 10:23:30.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 1068 LR: 0.0009999976827449572 Training loss: 0.0
2025-12-09 10:23:30.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 1069 LR: 0.0009999976779597169 Training loss: 0.0
2025-12-09 10:23:30.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 1070 LR: 0.0009999976731695408 Training loss: 0.0
2025-12-09 10:23:30.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 1071 LR: 0.000999997668374429 Training loss: 0.0
2025-12-09 10:23:30.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 1072 LR: 0.0009999976635743813 Training loss: 0.0
2025-12-09 10:23:30.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 1073 LR: 0.0009999976587693978 Training loss: 0.0
2025-12-09 10:23:30.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 1074 LR: 0.0009999976539594787 Training loss: 0.0
2025-12-09 10:23:30.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 1075 LR: 0.0009999976491446238 Training loss: 0.0
2025-12-09 10:23:30.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 1076 LR: 0.0009999976443248332 Training loss: 0.0
2025-12-09 10:23:30.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 1077 LR: 0.0009999976395001066 Training loss: 0.0
2025-12-09 10:23:30.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 1078 LR: 0.0009999976346704443 Training loss: 0.0
2025-12-09 10:23:30.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 1079 LR: 0.0009999976298358463 Training loss: 0.0
2025-12-09 10:23:30.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 1080 LR: 0.0009999976249963126 Training loss: 0.0
2025-12-09 10:23:30.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 1081 LR: 0.000999997620151843 Training loss: 0.0
2025-12-09 10:23:30.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 1082 LR: 0.0009999976153024378 Training loss: 0.0
2025-12-09 10:23:30.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 1083 LR: 0.0009999976104480969 Training loss: 0.0
2025-12-09 10:23:30.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 1084 LR: 0.0009999976055888198 Training loss: 0.0
2025-12-09 10:23:30.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 1085 LR: 0.0009999976007246073 Training loss: 0.0
2025-12-09 10:23:30.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 1086 LR: 0.000999997595855459 Training loss: 0.0
2025-12-09 10:23:30.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 1087 LR: 0.0009999975909813748 Training loss: 0.0
2025-12-09 10:23:30.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 1088 LR: 0.0009999975861023549 Training loss: 0.0
2025-12-09 10:23:30.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 1089 LR: 0.0009999975812183992 Training loss: 0.0
2025-12-09 10:23:30.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 1090 LR: 0.0009999975763295079 Training loss: 0.0
2025-12-09 10:23:30.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 1091 LR: 0.0009999975714356808 Training loss: 0.0
2025-12-09 10:23:30.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 1092 LR: 0.0009999975665369177 Training loss: 0.0
2025-12-09 10:23:30.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 1093 LR: 0.0009999975616332192 Training loss: 0.0
2025-12-09 10:23:30.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 1094 LR: 0.0009999975567245845 Training loss: 0.0
2025-12-09 10:23:30.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 1095 LR: 0.0009999975518110143 Training loss: 0.0
2025-12-09 10:23:30.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 1096 LR: 0.0009999975468925081 Training loss: 0.0
2025-12-09 10:23:30.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 1097 LR: 0.0009999975419690665 Training loss: 0.0
2025-12-09 10:23:30.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 1098 LR: 0.000999997537040689 Training loss: 0.0
2025-12-09 10:23:30.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 1099 LR: 0.0009999975321073756 Training loss: 0.0
2025-12-09 10:23:30.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 1100 LR: 0.0009999975271691266 Training loss: 0.0
2025-12-09 10:23:30.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 1101 LR: 0.0009999975222259418 Training loss: 0.0
2025-12-09 10:23:30.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 1102 LR: 0.0009999975172778211 Training loss: 0.0
2025-12-09 10:23:30.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 1103 LR: 0.0009999975123247647 Training loss: 0.0
2025-12-09 10:23:30.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 1104 LR: 0.0009999975073667726 Training loss: 0.0
2025-12-09 10:23:30.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 1105 LR: 0.0009999975024038447 Training loss: 0.0
2025-12-09 10:23:30.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 1106 LR: 0.0009999974974359812 Training loss: 0.0
2025-12-09 10:23:30.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 1107 LR: 0.0009999974924631816 Training loss: 0.0
2025-12-09 10:23:30.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 1108 LR: 0.0009999974874854464 Training loss: 0.0
2025-12-09 10:23:30.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 1109 LR: 0.0009999974825027757 Training loss: 0.0
2025-12-09 10:23:30.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 1110 LR: 0.0009999974775151688 Training loss: 0.0
2025-12-09 10:23:30.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 1111 LR: 0.0009999974725226264 Training loss: 0.0
2025-12-09 10:23:30.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 1112 LR: 0.000999997467525148 Training loss: 0.0
2025-12-09 10:23:30.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 1113 LR: 0.0009999974625227342 Training loss: 0.0
2025-12-09 10:23:30.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 1114 LR: 0.0009999974575153844 Training loss: 0.0
2025-12-09 10:23:30.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 1115 LR: 0.0009999974525030989 Training loss: 0.0
2025-12-09 10:23:30.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 1116 LR: 0.0009999974474858774 Training loss: 0.0
2025-12-09 10:23:30.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 1117 LR: 0.0009999974424637205 Training loss: 0.0
2025-12-09 10:23:30.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 1118 LR: 0.0009999974374366276 Training loss: 0.0
2025-12-09 10:23:30.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 1119 LR: 0.000999997432404599 Training loss: 0.0
2025-12-09 10:23:30.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 1120 LR: 0.0009999974273676346 Training loss: 0.0
2025-12-09 10:23:30.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 1121 LR: 0.0009999974223257344 Training loss: 0.0
2025-12-09 10:23:30.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 1122 LR: 0.0009999974172788986 Training loss: 0.0
2025-12-09 10:23:30.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 1123 LR: 0.0009999974122271269 Training loss: 0.0
2025-12-09 10:23:30.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 1124 LR: 0.0009999974071704196 Training loss: 0.0
2025-12-09 10:23:30.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 1125 LR: 0.0009999974021087763 Training loss: 0.0
2025-12-09 10:23:30.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 1126 LR: 0.0009999973970421974 Training loss: 0.0
2025-12-09 10:23:30.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 1127 LR: 0.0009999973919706828 Training loss: 0.0
2025-12-09 10:23:30.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 1128 LR: 0.0009999973868942322 Training loss: 0.0
2025-12-09 10:23:30.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 1129 LR: 0.000999997381812846 Training loss: 0.0
2025-12-09 10:23:30.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 1130 LR: 0.000999997376726524 Training loss: 0.0
2025-12-09 10:23:30.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 1131 LR: 0.0009999973716352663 Training loss: 0.0
2025-12-09 10:23:30.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 1132 LR: 0.0009999973665390726 Training loss: 0.0
2025-12-09 10:23:30.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 1133 LR: 0.0009999973614379435 Training loss: 0.0
2025-12-09 10:23:30.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 1134 LR: 0.0009999973563318784 Training loss: 0.0
2025-12-09 10:23:30.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 1135 LR: 0.0009999973512208776 Training loss: 0.0
2025-12-09 10:23:30.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 1136 LR: 0.000999997346104941 Training loss: 0.0
2025-12-09 10:23:30.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 1137 LR: 0.0009999973409840685 Training loss: 0.0
2025-12-09 10:23:30.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 1138 LR: 0.0009999973358582606 Training loss: 0.0
2025-12-09 10:23:30.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 1139 LR: 0.0009999973307275169 Training loss: 0.0
2025-12-09 10:23:30.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 1140 LR: 0.000999997325591837 Training loss: 0.0
2025-12-09 10:23:30.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 1141 LR: 0.0009999973204512216 Training loss: 0.0
2025-12-09 10:23:30.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 1142 LR: 0.0009999973153056705 Training loss: 0.0
2025-12-09 10:23:30.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 1143 LR: 0.0009999973101551835 Training loss: 0.0
2025-12-09 10:23:30.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 1144 LR: 0.000999997304999761 Training loss: 0.0
2025-12-09 10:23:30.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 1145 LR: 0.0009999972998394025 Training loss: 0.0
2025-12-09 10:23:30.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 1146 LR: 0.0009999972946741083 Training loss: 0.0
2025-12-09 10:23:30.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 1147 LR: 0.0009999972895038782 Training loss: 0.0
2025-12-09 10:23:30.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 1148 LR: 0.0009999972843287126 Training loss: 0.0
2025-12-09 10:23:30.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 1149 LR: 0.0009999972791486112 Training loss: 0.0
2025-12-09 10:23:30.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 1150 LR: 0.000999997273963574 Training loss: 0.0
2025-12-09 10:23:30.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 1151 LR: 0.0009999972687736007 Training loss: 0.0
2025-12-09 10:23:30.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 1152 LR: 0.000999997263578692 Training loss: 0.0
2025-12-09 10:23:30.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 1153 LR: 0.0009999972583788475 Training loss: 0.0
2025-12-09 10:23:30.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 1154 LR: 0.0009999972531740673 Training loss: 0.0
2025-12-09 10:23:30.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 1155 LR: 0.0009999972479643512 Training loss: 0.0
2025-12-09 10:23:30.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 1156 LR: 0.0009999972427496993 Training loss: 0.0
2025-12-09 10:23:30.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 1157 LR: 0.0009999972375301115 Training loss: 0.0
2025-12-09 10:23:30.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 1158 LR: 0.0009999972323055883 Training loss: 0.0
2025-12-09 10:23:30.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 1159 LR: 0.0009999972270761292 Training loss: 0.0
2025-12-09 10:23:30.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 1160 LR: 0.0009999972218417343 Training loss: 0.0
2025-12-09 10:23:30.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 1161 LR: 0.0009999972166024036 Training loss: 0.0
2025-12-09 10:23:30.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 1162 LR: 0.0009999972113581372 Training loss: 0.0
2025-12-09 10:23:30.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 1163 LR: 0.0009999972061089351 Training loss: 0.0
2025-12-09 10:23:30.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 1164 LR: 0.0009999972008547973 Training loss: 0.0
2025-12-09 10:23:30.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 1165 LR: 0.0009999971955957235 Training loss: 0.0
2025-12-09 10:23:30.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 1166 LR: 0.000999997190331714 Training loss: 0.0
2025-12-09 10:23:30.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 1167 LR: 0.000999997185062769 Training loss: 0.0
2025-12-09 10:23:30.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 1168 LR: 0.0009999971797888879 Training loss: 0.0
2025-12-09 10:23:30.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 1169 LR: 0.0009999971745100712 Training loss: 0.0
2025-12-09 10:23:30.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 1170 LR: 0.0009999971692263186 Training loss: 0.0
2025-12-09 10:23:30.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 1171 LR: 0.0009999971639376305 Training loss: 0.0
2025-12-09 10:23:30.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 1172 LR: 0.0009999971586440064 Training loss: 0.0
2025-12-09 10:23:30.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 1173 LR: 0.0009999971533454467 Training loss: 0.0
2025-12-09 10:23:30.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 1174 LR: 0.0009999971480419512 Training loss: 0.0
2025-12-09 10:23:30.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 1175 LR: 0.0009999971427335197 Training loss: 0.0
2025-12-09 10:23:30.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 1176 LR: 0.0009999971374201528 Training loss: 0.0
2025-12-09 10:23:30.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 1177 LR: 0.00099999713210185 Training loss: 0.0
2025-12-09 10:23:30.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 1178 LR: 0.0009999971267786113 Training loss: 0.0
2025-12-09 10:23:30.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 1179 LR: 0.000999997121450437 Training loss: 0.0
2025-12-09 10:23:30.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 1180 LR: 0.000999997116117327 Training loss: 0.0
2025-12-09 10:23:30.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 1181 LR: 0.000999997110779281 Training loss: 0.0
2025-12-09 10:23:30.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 1182 LR: 0.0009999971054362993 Training loss: 0.0
2025-12-09 10:23:30.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 1183 LR: 0.0009999971000883821 Training loss: 0.0
2025-12-09 10:23:30.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 1184 LR: 0.0009999970947355287 Training loss: 0.0
2025-12-09 10:23:30.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 1185 LR: 0.0009999970893777399 Training loss: 0.0
2025-12-09 10:23:30.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 1186 LR: 0.0009999970840150153 Training loss: 0.0
2025-12-09 10:23:30.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 1187 LR: 0.000999997078647355 Training loss: 0.0
2025-12-09 10:23:30.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 1188 LR: 0.0009999970732747587 Training loss: 0.0
2025-12-09 10:23:30.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 1189 LR: 0.0009999970678972268 Training loss: 0.0
2025-12-09 10:23:30.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 1190 LR: 0.000999997062514759 Training loss: 0.0
2025-12-09 10:23:30.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 1191 LR: 0.0009999970571273557 Training loss: 0.0
2025-12-09 10:23:30.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 1192 LR: 0.0009999970517350163 Training loss: 0.0
2025-12-09 10:23:30.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 1193 LR: 0.0009999970463377412 Training loss: 0.0
2025-12-09 10:23:30.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 1194 LR: 0.0009999970409355307 Training loss: 0.0
2025-12-09 10:23:30.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 1195 LR: 0.0009999970355283841 Training loss: 0.0
2025-12-09 10:23:30.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 1196 LR: 0.0009999970301163017 Training loss: 0.0
2025-12-09 10:23:30.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 1197 LR: 0.0009999970246992837 Training loss: 0.0
2025-12-09 10:23:30.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 1198 LR: 0.00099999701927733 Training loss: 0.0
2025-12-09 10:23:30.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 1199 LR: 0.0009999970138504404 Training loss: 0.0
2025-12-09 10:23:30.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 1200 LR: 0.0009999970084186153 Training loss: 0.0
2025-12-09 10:23:30.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 1201 LR: 0.000999997002981854 Training loss: 0.0
2025-12-09 10:23:30.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 1202 LR: 0.0009999969975401572 Training loss: 0.0
2025-12-09 10:23:30.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 1203 LR: 0.0009999969920935245 Training loss: 0.0
2025-12-09 10:23:30.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 1204 LR: 0.0009999969866419562 Training loss: 0.0
2025-12-09 10:23:30.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 1205 LR: 0.000999996981185452 Training loss: 0.0
2025-12-09 10:23:30.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 1206 LR: 0.0009999969757240122 Training loss: 0.0
2025-12-09 10:23:30.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 1207 LR: 0.0009999969702576366 Training loss: 0.0
2025-12-09 10:23:30.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 1208 LR: 0.0009999969647863252 Training loss: 0.0
2025-12-09 10:23:30.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 1209 LR: 0.0009999969593100782 Training loss: 0.0
2025-12-09 10:23:30.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 1210 LR: 0.0009999969538288952 Training loss: 0.0
2025-12-09 10:23:30.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 1211 LR: 0.0009999969483427764 Training loss: 0.0
2025-12-09 10:23:30.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 1212 LR: 0.0009999969428517222 Training loss: 0.0
2025-12-09 10:23:30.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 1213 LR: 0.0009999969373557318 Training loss: 0.0
2025-12-09 10:23:30.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 1214 LR: 0.000999996931854806 Training loss: 0.0
2025-12-09 10:23:30.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 1215 LR: 0.0009999969263489443 Training loss: 0.0
2025-12-09 10:23:30.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 1216 LR: 0.0009999969208381468 Training loss: 0.0
2025-12-09 10:23:30.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 1217 LR: 0.0009999969153224135 Training loss: 0.0
2025-12-09 10:23:30.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 1218 LR: 0.0009999969098017445 Training loss: 0.0
2025-12-09 10:23:30.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 1219 LR: 0.0009999969042761398 Training loss: 0.0
2025-12-09 10:23:30.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 1220 LR: 0.0009999968987455994 Training loss: 0.0
2025-12-09 10:23:30.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 1221 LR: 0.000999996893210123 Training loss: 0.0
2025-12-09 10:23:30.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 1222 LR: 0.0009999968876697111 Training loss: 0.0
2025-12-09 10:23:30.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 1223 LR: 0.0009999968821243633 Training loss: 0.0
2025-12-09 10:23:30.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 1224 LR: 0.00099999687657408 Training loss: 0.0
2025-12-09 10:23:30.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 1225 LR: 0.0009999968710188605 Training loss: 0.0
2025-12-09 10:23:30.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 1226 LR: 0.0009999968654587055 Training loss: 0.0
2025-12-09 10:23:30.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 1227 LR: 0.0009999968598936146 Training loss: 0.0
2025-12-09 10:23:30.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 1228 LR: 0.0009999968543235882 Training loss: 0.0
2025-12-09 10:23:30.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 1229 LR: 0.0009999968487486258 Training loss: 0.0
2025-12-09 10:23:30.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 1230 LR: 0.0009999968431687277 Training loss: 0.0
2025-12-09 10:23:30.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 1231 LR: 0.000999996837583894 Training loss: 0.0
2025-12-09 10:23:30.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 1232 LR: 0.0009999968319941244 Training loss: 0.0
2025-12-09 10:23:30.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 1233 LR: 0.000999996826399419 Training loss: 0.0
2025-12-09 10:23:30.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 1234 LR: 0.000999996820799778 Training loss: 0.0
2025-12-09 10:23:30.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 1235 LR: 0.000999996815195201 Training loss: 0.0
2025-12-09 10:23:30.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 1236 LR: 0.0009999968095856884 Training loss: 0.0
2025-12-09 10:23:30.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 1237 LR: 0.00099999680397124 Training loss: 0.0
2025-12-09 10:23:30.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 1238 LR: 0.0009999967983518557 Training loss: 0.0
2025-12-09 10:23:30.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 1239 LR: 0.000999996792727536 Training loss: 0.0
2025-12-09 10:23:30.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 1240 LR: 0.0009999967870982802 Training loss: 0.0
2025-12-09 10:23:30.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 1241 LR: 0.0009999967814640887 Training loss: 0.0
2025-12-09 10:23:30.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 1242 LR: 0.0009999967758249615 Training loss: 0.0
2025-12-09 10:23:30.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 1243 LR: 0.0009999967701808988 Training loss: 0.0
2025-12-09 10:23:30.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 1244 LR: 0.0009999967645319 Training loss: 0.0
2025-12-09 10:23:30.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 1245 LR: 0.0009999967588779654 Training loss: 0.0
2025-12-09 10:23:30.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 1246 LR: 0.0009999967532190953 Training loss: 0.0
2025-12-09 10:23:30.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 1247 LR: 0.0009999967475552893 Training loss: 0.0
2025-12-09 10:23:30.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 1248 LR: 0.0009999967418865476 Training loss: 0.0
2025-12-09 10:23:30.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 1249 LR: 0.0009999967362128701 Training loss: 0.0
2025-12-09 10:23:30.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 1250 LR: 0.000999996730534257 Training loss: 0.0
2025-12-09 10:23:30.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 1251 LR: 0.000999996724850708 Training loss: 0.0
2025-12-09 10:23:30.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 1252 LR: 0.0009999967191622232 Training loss: 0.0
2025-12-09 10:23:30.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 1253 LR: 0.0009999967134688027 Training loss: 0.0
2025-12-09 10:23:30.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 1254 LR: 0.0009999967077704464 Training loss: 0.0
2025-12-09 10:23:30.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 1255 LR: 0.0009999967020671544 Training loss: 0.0
2025-12-09 10:23:30.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 1256 LR: 0.0009999966963589266 Training loss: 0.0
2025-12-09 10:23:30.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 1257 LR: 0.0009999966906457632 Training loss: 0.0
2025-12-09 10:23:30.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 1258 LR: 0.0009999966849276638 Training loss: 0.0
2025-12-09 10:23:30.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 1259 LR: 0.0009999966792046287 Training loss: 0.0
2025-12-09 10:23:30.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 1260 LR: 0.000999996673476658 Training loss: 0.0
2025-12-09 10:23:30.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 1261 LR: 0.0009999966677437515 Training loss: 0.0
2025-12-09 10:23:30.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 1262 LR: 0.000999996662005909 Training loss: 0.0
2025-12-09 10:23:30.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 1263 LR: 0.000999996656263131 Training loss: 0.0
2025-12-09 10:23:30.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 1264 LR: 0.0009999966505154173 Training loss: 0.0
2025-12-09 10:23:30.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 1265 LR: 0.0009999966447627677 Training loss: 0.0
2025-12-09 10:23:30.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 1266 LR: 0.0009999966390051823 Training loss: 0.0
2025-12-09 10:23:30.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 1267 LR: 0.0009999966332426612 Training loss: 0.0
2025-12-09 10:23:30.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 1268 LR: 0.0009999966274752043 Training loss: 0.0
2025-12-09 10:23:30.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 1269 LR: 0.0009999966217028118 Training loss: 0.0
2025-12-09 10:23:30.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 1270 LR: 0.0009999966159254833 Training loss: 0.0
2025-12-09 10:23:30.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 1271 LR: 0.0009999966101432191 Training loss: 0.0
2025-12-09 10:23:30.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 1272 LR: 0.0009999966043560194 Training loss: 0.0
2025-12-09 10:23:30.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 1273 LR: 0.0009999965985638837 Training loss: 0.0
2025-12-09 10:23:30.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 1274 LR: 0.0009999965927668124 Training loss: 0.0
2025-12-09 10:23:30.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 1275 LR: 0.0009999965869648053 Training loss: 0.0
2025-12-09 10:23:30.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 1276 LR: 0.0009999965811578625 Training loss: 0.0
2025-12-09 10:23:30.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 1277 LR: 0.0009999965753459837 Training loss: 0.0
2025-12-09 10:23:30.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 1278 LR: 0.0009999965695291692 Training loss: 0.0
2025-12-09 10:23:30.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 1279 LR: 0.000999996563707419 Training loss: 0.0
2025-12-09 10:23:30.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 1280 LR: 0.000999996557880733 Training loss: 0.0
2025-12-09 10:23:30.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 1281 LR: 0.0009999965520491115 Training loss: 0.0
2025-12-09 10:23:30.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 1282 LR: 0.000999996546212554 Training loss: 0.0
2025-12-09 10:23:30.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 1283 LR: 0.000999996540371061 Training loss: 0.0
2025-12-09 10:23:30.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 1284 LR: 0.000999996534524632 Training loss: 0.0
2025-12-09 10:23:30.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 1285 LR: 0.0009999965286732672 Training loss: 0.0
2025-12-09 10:23:30.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 1286 LR: 0.0009999965228169668 Training loss: 0.0
2025-12-09 10:23:30.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 1287 LR: 0.0009999965169557306 Training loss: 0.0
2025-12-09 10:23:30.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 1288 LR: 0.0009999965110895587 Training loss: 0.0
2025-12-09 10:23:30.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 1289 LR: 0.000999996505218451 Training loss: 0.0
2025-12-09 10:23:30.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 1290 LR: 0.0009999964993424074 Training loss: 0.0
2025-12-09 10:23:30.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 1291 LR: 0.0009999964934614284 Training loss: 0.0
2025-12-09 10:23:30.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 1292 LR: 0.0009999964875755131 Training loss: 0.0
2025-12-09 10:23:30.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 1293 LR: 0.0009999964816846626 Training loss: 0.0
2025-12-09 10:23:30.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 1294 LR: 0.000999996475788876 Training loss: 0.0
2025-12-09 10:23:30.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 1295 LR: 0.000999996469888154 Training loss: 0.0
2025-12-09 10:23:30.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 1296 LR: 0.0009999964639824958 Training loss: 0.0
2025-12-09 10:23:30.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 1297 LR: 0.0009999964580719022 Training loss: 0.0
2025-12-09 10:23:30.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 1298 LR: 0.0009999964521563724 Training loss: 0.0
2025-12-09 10:23:30.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 1299 LR: 0.0009999964462359073 Training loss: 0.0
2025-12-09 10:23:30.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 1300 LR: 0.0009999964403105061 Training loss: 0.0
2025-12-09 10:23:30.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 1301 LR: 0.0009999964343801696 Training loss: 0.0
2025-12-09 10:23:30.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 1302 LR: 0.000999996428444897 Training loss: 0.0
2025-12-09 10:23:30.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 1303 LR: 0.0009999964225046887 Training loss: 0.0
2025-12-09 10:23:30.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 1304 LR: 0.0009999964165595446 Training loss: 0.0
2025-12-09 10:23:30.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 1305 LR: 0.0009999964106094648 Training loss: 0.0
2025-12-09 10:23:30.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 1306 LR: 0.0009999964046544492 Training loss: 0.0
2025-12-09 10:23:30.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 1307 LR: 0.000999996398694498 Training loss: 0.0
2025-12-09 10:23:31.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 1308 LR: 0.000999996392729611 Training loss: 0.0
2025-12-09 10:23:31.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 1309 LR: 0.000999996386759788 Training loss: 0.0
2025-12-09 10:23:31.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 1310 LR: 0.0009999963807850296 Training loss: 0.0
2025-12-09 10:23:31.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 1311 LR: 0.0009999963748053354 Training loss: 0.0
2025-12-09 10:23:31.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 1312 LR: 0.0009999963688207053 Training loss: 0.0
2025-12-09 10:23:31.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 1313 LR: 0.0009999963628311394 Training loss: 0.0
2025-12-09 10:23:31.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 1314 LR: 0.0009999963568366379 Training loss: 0.0
2025-12-09 10:23:31.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 1315 LR: 0.0009999963508372006 Training loss: 0.0
2025-12-09 10:23:31.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 1316 LR: 0.0009999963448328276 Training loss: 0.0
2025-12-09 10:23:31.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 1317 LR: 0.0009999963388235187 Training loss: 0.0
2025-12-09 10:23:31.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 1318 LR: 0.000999996332809274 Training loss: 0.0
2025-12-09 10:23:31.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 1319 LR: 0.0009999963267900939 Training loss: 0.0
2025-12-09 10:23:31.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 1320 LR: 0.0009999963207659778 Training loss: 0.0
2025-12-09 10:23:31.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 1321 LR: 0.0009999963147369257 Training loss: 0.0
2025-12-09 10:23:31.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 1322 LR: 0.0009999963087029382 Training loss: 0.0
2025-12-09 10:23:31.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 1323 LR: 0.000999996302664015 Training loss: 0.0
2025-12-09 10:23:31.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 1324 LR: 0.0009999962966201557 Training loss: 0.0
2025-12-09 10:23:31.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 1325 LR: 0.000999996290571361 Training loss: 0.0
2025-12-09 10:23:31.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 1326 LR: 0.0009999962845176303 Training loss: 0.0
2025-12-09 10:23:31.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 1327 LR: 0.000999996278458964 Training loss: 0.0
2025-12-09 10:23:31.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 1328 LR: 0.0009999962723953619 Training loss: 0.0
2025-12-09 10:23:31.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 1329 LR: 0.000999996266326824 Training loss: 0.0
2025-12-09 10:23:31.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 1330 LR: 0.0009999962602533503 Training loss: 0.0
2025-12-09 10:23:31.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 1331 LR: 0.000999996254174941 Training loss: 0.0
2025-12-09 10:23:31.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 1332 LR: 0.0009999962480915958 Training loss: 0.0
2025-12-09 10:23:31.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 1333 LR: 0.0009999962420033151 Training loss: 0.0
2025-12-09 10:23:31.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 1334 LR: 0.0009999962359100983 Training loss: 0.0
2025-12-09 10:23:31.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 1335 LR: 0.0009999962298119461 Training loss: 0.0
2025-12-09 10:23:31.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 1336 LR: 0.0009999962237088578 Training loss: 0.0
2025-12-09 10:23:31.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 1337 LR: 0.000999996217600834 Training loss: 0.0
2025-12-09 10:23:31.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 1338 LR: 0.0009999962114878743 Training loss: 0.0
2025-12-09 10:23:31.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 1339 LR: 0.000999996205369979 Training loss: 0.0
2025-12-09 10:23:31.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 1340 LR: 0.0009999961992471478 Training loss: 0.0
2025-12-09 10:23:31.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 1341 LR: 0.000999996193119381 Training loss: 0.0
2025-12-09 10:23:31.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 1342 LR: 0.0009999961869866783 Training loss: 0.0
2025-12-09 10:23:31.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 1343 LR: 0.00099999618084904 Training loss: 0.0
2025-12-09 10:23:31.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 1344 LR: 0.0009999961747064658 Training loss: 0.0
2025-12-09 10:23:31.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 1345 LR: 0.0009999961685589558 Training loss: 0.0
2025-12-09 10:23:31.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 1346 LR: 0.0009999961624065103 Training loss: 0.0
2025-12-09 10:23:31.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 1347 LR: 0.0009999961562491288 Training loss: 0.0
2025-12-09 10:23:31.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 1348 LR: 0.0009999961500868116 Training loss: 0.0
2025-12-09 10:23:31.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 1349 LR: 0.0009999961439195587 Training loss: 0.0
2025-12-09 10:23:31.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 1350 LR: 0.0009999961377473701 Training loss: 0.0
2025-12-09 10:23:31.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 1351 LR: 0.0009999961315702458 Training loss: 0.0
2025-12-09 10:23:31.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 1352 LR: 0.0009999961253881855 Training loss: 0.0
2025-12-09 10:23:31.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 1353 LR: 0.0009999961192011897 Training loss: 0.0
2025-12-09 10:23:31.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 1354 LR: 0.0009999961130092582 Training loss: 0.0
2025-12-09 10:23:31.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 1355 LR: 0.0009999961068123907 Training loss: 0.0
2025-12-09 10:23:31.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 1356 LR: 0.0009999961006105875 Training loss: 0.0
2025-12-09 10:23:31.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 1357 LR: 0.0009999960944038486 Training loss: 0.0
2025-12-09 10:23:31.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 1358 LR: 0.000999996088192174 Training loss: 0.0
2025-12-09 10:23:31.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 1359 LR: 0.0009999960819755634 Training loss: 0.0
2025-12-09 10:23:31.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 1360 LR: 0.0009999960757540174 Training loss: 0.0
2025-12-09 10:23:31.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 1361 LR: 0.0009999960695275354 Training loss: 0.0
2025-12-09 10:23:31.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 1362 LR: 0.0009999960632961179 Training loss: 0.0
2025-12-09 10:23:31.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 1363 LR: 0.0009999960570597644 Training loss: 0.0
2025-12-09 10:23:31.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 1364 LR: 0.000999996050818475 Training loss: 0.0
2025-12-09 10:23:31.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 1365 LR: 0.0009999960445722501 Training loss: 0.0
2025-12-09 10:23:31.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 1366 LR: 0.0009999960383210895 Training loss: 0.0
2025-12-09 10:23:31.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 1367 LR: 0.0009999960320649932 Training loss: 0.0
2025-12-09 10:23:31.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 1368 LR: 0.0009999960258039611 Training loss: 0.0
2025-12-09 10:23:31.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 1369 LR: 0.0009999960195379931 Training loss: 0.0
2025-12-09 10:23:31.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 1370 LR: 0.0009999960132670894 Training loss: 0.0
2025-12-09 10:23:31.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 1371 LR: 0.00099999600699125 Training loss: 0.0
2025-12-09 10:23:31.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 1372 LR: 0.0009999960007104748 Training loss: 0.0
2025-12-09 10:23:31.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 1373 LR: 0.000999995994424764 Training loss: 0.0
2025-12-09 10:23:31.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 1374 LR: 0.0009999959881341173 Training loss: 0.0
2025-12-09 10:23:31.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 1375 LR: 0.000999995981838535 Training loss: 0.0
2025-12-09 10:23:31.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 1376 LR: 0.0009999959755380167 Training loss: 0.0
2025-12-09 10:23:31.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 1377 LR: 0.000999995969232563 Training loss: 0.0
2025-12-09 10:23:31.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 1378 LR: 0.000999995962922173 Training loss: 0.0
2025-12-09 10:23:31.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 1379 LR: 0.0009999959566068478 Training loss: 0.0
2025-12-09 10:23:31.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 1380 LR: 0.0009999959502865865 Training loss: 0.0
2025-12-09 10:23:31.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 1381 LR: 0.0009999959439613898 Training loss: 0.0
2025-12-09 10:23:31.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 1382 LR: 0.000999995937631257 Training loss: 0.0
2025-12-09 10:23:31.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 1383 LR: 0.0009999959312961887 Training loss: 0.0
2025-12-09 10:23:31.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 1384 LR: 0.0009999959249561846 Training loss: 0.0
2025-12-09 10:23:31.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 1385 LR: 0.0009999959186112446 Training loss: 0.0
2025-12-09 10:23:31.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 1386 LR: 0.000999995912261369 Training loss: 0.0
2025-12-09 10:23:31.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 1387 LR: 0.0009999959059065575 Training loss: 0.0
2025-12-09 10:23:31.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 1388 LR: 0.0009999958995468104 Training loss: 0.0
2025-12-09 10:23:31.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 1389 LR: 0.0009999958931821273 Training loss: 0.0
2025-12-09 10:23:31.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 1390 LR: 0.0009999958868125087 Training loss: 0.0
2025-12-09 10:23:31.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 1391 LR: 0.0009999958804379544 Training loss: 0.0
2025-12-09 10:23:31.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 1392 LR: 0.0009999958740584643 Training loss: 0.0
2025-12-09 10:23:31.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 1393 LR: 0.0009999958676740384 Training loss: 0.0
2025-12-09 10:23:31.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 1394 LR: 0.0009999958612846767 Training loss: 0.0
2025-12-09 10:23:31.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 1395 LR: 0.0009999958548903795 Training loss: 0.0
2025-12-09 10:23:31.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 1396 LR: 0.0009999958484911463 Training loss: 0.0
2025-12-09 10:23:31.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 1397 LR: 0.0009999958420869772 Training loss: 0.0
2025-12-09 10:23:31.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 1398 LR: 0.0009999958356778727 Training loss: 0.0
2025-12-09 10:23:31.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 1399 LR: 0.0009999958292638323 Training loss: 0.0
2025-12-09 10:23:31.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 1400 LR: 0.000999995822844856 Training loss: 0.0
2025-12-09 10:23:31.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 1401 LR: 0.0009999958164209441 Training loss: 0.0
2025-12-09 10:23:31.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 1402 LR: 0.0009999958099920967 Training loss: 0.0
2025-12-09 10:23:31.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 1403 LR: 0.0009999958035583133 Training loss: 0.0
2025-12-09 10:23:31.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 1404 LR: 0.0009999957971195941 Training loss: 0.0
2025-12-09 10:23:31.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 1405 LR: 0.000999995790675939 Training loss: 0.0
2025-12-09 10:23:31.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 1406 LR: 0.0009999957842273487 Training loss: 0.0
2025-12-09 10:23:31.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 1407 LR: 0.0009999957777738222 Training loss: 0.0
2025-12-09 10:23:31.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 1408 LR: 0.00099999577131536 Training loss: 0.0
2025-12-09 10:23:31.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 1409 LR: 0.0009999957648519622 Training loss: 0.0
2025-12-09 10:23:31.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 1410 LR: 0.0009999957583836285 Training loss: 0.0
2025-12-09 10:23:31.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 1411 LR: 0.0009999957519103593 Training loss: 0.0
2025-12-09 10:23:31.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 1412 LR: 0.0009999957454321542 Training loss: 0.0
2025-12-09 10:23:31.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 1413 LR: 0.0009999957389490134 Training loss: 0.0
2025-12-09 10:23:31.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 1414 LR: 0.0009999957324609366 Training loss: 0.0
2025-12-09 10:23:31.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 1415 LR: 0.0009999957259679243 Training loss: 0.0
2025-12-09 10:23:31.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 1416 LR: 0.0009999957194699763 Training loss: 0.0
2025-12-09 10:23:31.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 1417 LR: 0.0009999957129670925 Training loss: 0.0
2025-12-09 10:23:31.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 1418 LR: 0.0009999957064592729 Training loss: 0.0
2025-12-09 10:23:31.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 1419 LR: 0.0009999956999465175 Training loss: 0.0
2025-12-09 10:23:31.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 1420 LR: 0.0009999956934288263 Training loss: 0.0
2025-12-09 10:23:31.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 1421 LR: 0.0009999956869061995 Training loss: 0.0
2025-12-09 10:23:31.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 1422 LR: 0.000999995680378637 Training loss: 0.0
2025-12-09 10:23:31.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 1423 LR: 0.0009999956738461387 Training loss: 0.0
2025-12-09 10:23:31.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 1424 LR: 0.0009999956673087047 Training loss: 0.0
2025-12-09 10:23:31.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 1425 LR: 0.0009999956607663347 Training loss: 0.0
2025-12-09 10:23:31.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 1426 LR: 0.0009999956542190293 Training loss: 0.0
2025-12-09 10:23:31.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 1427 LR: 0.0009999956476667879 Training loss: 0.0
2025-12-09 10:23:31.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 1428 LR: 0.0009999956411096108 Training loss: 0.0
2025-12-09 10:23:31.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 1429 LR: 0.0009999956345474981 Training loss: 0.0
2025-12-09 10:23:31.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 1430 LR: 0.0009999956279804494 Training loss: 0.0
2025-12-09 10:23:31.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 1431 LR: 0.000999995621408465 Training loss: 0.0
2025-12-09 10:23:31.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 1432 LR: 0.0009999956148315453 Training loss: 0.0
2025-12-09 10:23:31.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 1433 LR: 0.0009999956082496894 Training loss: 0.0
2025-12-09 10:23:31.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 1434 LR: 0.0009999956016628977 Training loss: 0.0
2025-12-09 10:23:31.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 1435 LR: 0.0009999955950711706 Training loss: 0.0
2025-12-09 10:23:31.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 1436 LR: 0.0009999955884745075 Training loss: 0.0
2025-12-09 10:23:31.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 1437 LR: 0.0009999955818729086 Training loss: 0.0
2025-12-09 10:23:31.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 1438 LR: 0.0009999955752663743 Training loss: 0.0
2025-12-09 10:23:31.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 1439 LR: 0.000999995568654904 Training loss: 0.0
2025-12-09 10:23:31.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 1440 LR: 0.000999995562038498 Training loss: 0.0
2025-12-09 10:23:31.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 1441 LR: 0.0009999955554171563 Training loss: 0.0
2025-12-09 10:23:31.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 1442 LR: 0.0009999955487908787 Training loss: 0.0
2025-12-09 10:23:31.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 1443 LR: 0.0009999955421596655 Training loss: 0.0
2025-12-09 10:23:31.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 1444 LR: 0.0009999955355235164 Training loss: 0.0
2025-12-09 10:23:31.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 1445 LR: 0.0009999955288824318 Training loss: 0.0
2025-12-09 10:23:31.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 1446 LR: 0.0009999955222364113 Training loss: 0.0
2025-12-09 10:23:31.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 1447 LR: 0.000999995515585455 Training loss: 0.0
2025-12-09 10:23:31.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 1448 LR: 0.000999995508929563 Training loss: 0.0
2025-12-09 10:23:31.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 1449 LR: 0.0009999955022687353 Training loss: 0.0
2025-12-09 10:23:31.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 1450 LR: 0.000999995495602972 Training loss: 0.0
2025-12-09 10:23:31.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 1451 LR: 0.0009999954889322728 Training loss: 0.0
2025-12-09 10:23:31.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 1452 LR: 0.0009999954822566377 Training loss: 0.0
2025-12-09 10:23:31.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 1453 LR: 0.000999995475576067 Training loss: 0.0
2025-12-09 10:23:31.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 1454 LR: 0.0009999954688905605 Training loss: 0.0
2025-12-09 10:23:31.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 1455 LR: 0.0009999954622001183 Training loss: 0.0
2025-12-09 10:23:31.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 1456 LR: 0.0009999954555047405 Training loss: 0.0
2025-12-09 10:23:31.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 1457 LR: 0.0009999954488044268 Training loss: 0.0
2025-12-09 10:23:31.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 1458 LR: 0.0009999954420991774 Training loss: 0.0
2025-12-09 10:23:31.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 1459 LR: 0.0009999954353889923 Training loss: 0.0
2025-12-09 10:23:31.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 1460 LR: 0.0009999954286738712 Training loss: 0.0
2025-12-09 10:23:31.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 1461 LR: 0.0009999954219538148 Training loss: 0.0
2025-12-09 10:23:31.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 1462 LR: 0.0009999954152288223 Training loss: 0.0
2025-12-09 10:23:31.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 1463 LR: 0.000999995408498894 Training loss: 0.0
2025-12-09 10:23:31.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 1464 LR: 0.0009999954017640303 Training loss: 0.0
2025-12-09 10:23:31.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 1465 LR: 0.0009999953950242306 Training loss: 0.0
2025-12-09 10:23:31.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 1466 LR: 0.0009999953882794952 Training loss: 0.0
2025-12-09 10:23:31.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 1467 LR: 0.000999995381529824 Training loss: 0.0
2025-12-09 10:23:31.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 1468 LR: 0.0009999953747752172 Training loss: 0.0
2025-12-09 10:23:31.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 1469 LR: 0.0009999953680156746 Training loss: 0.0
2025-12-09 10:23:31.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 1470 LR: 0.0009999953612511963 Training loss: 0.0
2025-12-09 10:23:31.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 1471 LR: 0.0009999953544817823 Training loss: 0.0
2025-12-09 10:23:31.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 1472 LR: 0.0009999953477074323 Training loss: 0.0
2025-12-09 10:23:31.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 1473 LR: 0.0009999953409281469 Training loss: 0.0
2025-12-09 10:23:31.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 1474 LR: 0.0009999953341439257 Training loss: 0.0
2025-12-09 10:23:31.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 1475 LR: 0.0009999953273547686 Training loss: 0.0
2025-12-09 10:23:31.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 1476 LR: 0.0009999953205606757 Training loss: 0.0
2025-12-09 10:23:31.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 1477 LR: 0.0009999953137616471 Training loss: 0.0
2025-12-09 10:23:31.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 1478 LR: 0.0009999953069576828 Training loss: 0.0
2025-12-09 10:23:31.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 1479 LR: 0.0009999953001487828 Training loss: 0.0
2025-12-09 10:23:31.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 1480 LR: 0.000999995293334947 Training loss: 0.0
2025-12-09 10:23:31.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 1481 LR: 0.0009999952865161756 Training loss: 0.0
2025-12-09 10:23:31.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 1482 LR: 0.0009999952796924682 Training loss: 0.0
2025-12-09 10:23:31.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 1483 LR: 0.0009999952728638253 Training loss: 0.0
2025-12-09 10:23:31.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 1484 LR: 0.0009999952660302465 Training loss: 0.0
2025-12-09 10:23:31.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 1485 LR: 0.0009999952591917321 Training loss: 0.0
2025-12-09 10:23:31.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 1486 LR: 0.0009999952523482819 Training loss: 0.0
2025-12-09 10:23:31.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 1487 LR: 0.0009999952454998959 Training loss: 0.0
2025-12-09 10:23:31.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 1488 LR: 0.0009999952386465741 Training loss: 0.0
2025-12-09 10:23:31.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 1489 LR: 0.0009999952317883167 Training loss: 0.0
2025-12-09 10:23:31.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 1490 LR: 0.0009999952249251235 Training loss: 0.0
2025-12-09 10:23:31.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 1491 LR: 0.0009999952180569944 Training loss: 0.0
2025-12-09 10:23:31.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 1492 LR: 0.00099999521118393 Training loss: 0.0
2025-12-09 10:23:31.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 1493 LR: 0.0009999952043059294 Training loss: 0.0
2025-12-09 10:23:31.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 1494 LR: 0.0009999951974229934 Training loss: 0.0
2025-12-09 10:23:31.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 1495 LR: 0.0009999951905351212 Training loss: 0.0
2025-12-09 10:23:31.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 1496 LR: 0.0009999951836423136 Training loss: 0.0
2025-12-09 10:23:31.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 1497 LR: 0.0009999951767445702 Training loss: 0.0
2025-12-09 10:23:31.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 1498 LR: 0.000999995169841891 Training loss: 0.0
2025-12-09 10:23:31.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 1499 LR: 0.0009999951629342764 Training loss: 0.0
2025-12-09 10:23:31.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 1500 LR: 0.0009999951560217255 Training loss: 0.0
2025-12-09 10:23:31.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 1501 LR: 0.0009999951491042392 Training loss: 0.0
2025-12-09 10:23:31.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 1502 LR: 0.0009999951421818172 Training loss: 0.0
2025-12-09 10:23:31.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 1503 LR: 0.0009999951352544594 Training loss: 0.0
2025-12-09 10:23:31.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 1504 LR: 0.0009999951283221659 Training loss: 0.0
2025-12-09 10:23:31.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 1505 LR: 0.0009999951213849364 Training loss: 0.0
2025-12-09 10:23:31.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 1506 LR: 0.0009999951144427713 Training loss: 0.0
2025-12-09 10:23:31.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 1507 LR: 0.0009999951074956706 Training loss: 0.0
2025-12-09 10:23:31.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 1508 LR: 0.000999995100543634 Training loss: 0.0
2025-12-09 10:23:31.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 1509 LR: 0.0009999950935866617 Training loss: 0.0
2025-12-09 10:23:31.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 1510 LR: 0.0009999950866247536 Training loss: 0.0
2025-12-09 10:23:31.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 1511 LR: 0.0009999950796579099 Training loss: 0.0
2025-12-09 10:23:31.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 1512 LR: 0.0009999950726861304 Training loss: 0.0
2025-12-09 10:23:31.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 1513 LR: 0.0009999950657094152 Training loss: 0.0
2025-12-09 10:23:31.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 1514 LR: 0.000999995058727764 Training loss: 0.0
2025-12-09 10:23:31.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 1515 LR: 0.0009999950517411774 Training loss: 0.0
2025-12-09 10:23:31.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 1516 LR: 0.0009999950447496548 Training loss: 0.0
2025-12-09 10:23:31.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 1517 LR: 0.0009999950377531967 Training loss: 0.0
2025-12-09 10:23:31.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 1518 LR: 0.0009999950307518026 Training loss: 0.0
2025-12-09 10:23:31.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 1519 LR: 0.000999995023745473 Training loss: 0.0
2025-12-09 10:23:31.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 1520 LR: 0.0009999950167342076 Training loss: 0.0
2025-12-09 10:23:31.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 1521 LR: 0.0009999950097180064 Training loss: 0.0
2025-12-09 10:23:31.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 1522 LR: 0.0009999950026968695 Training loss: 0.0
2025-12-09 10:23:31.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 1523 LR: 0.0009999949956707968 Training loss: 0.0
2025-12-09 10:23:31.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 1524 LR: 0.0009999949886397885 Training loss: 0.0
2025-12-09 10:23:31.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 1525 LR: 0.0009999949816038444 Training loss: 0.0
2025-12-09 10:23:31.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 1526 LR: 0.0009999949745629643 Training loss: 0.0
2025-12-09 10:23:31.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 1527 LR: 0.0009999949675171488 Training loss: 0.0
2025-12-09 10:23:31.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 1528 LR: 0.0009999949604663973 Training loss: 0.0
2025-12-09 10:23:31.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 1529 LR: 0.0009999949534107103 Training loss: 0.0
2025-12-09 10:23:31.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 1530 LR: 0.0009999949463500874 Training loss: 0.0
2025-12-09 10:23:31.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 1531 LR: 0.000999994939284529 Training loss: 0.0
2025-12-09 10:23:31.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 1532 LR: 0.0009999949322140346 Training loss: 0.0
2025-12-09 10:23:31.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 1533 LR: 0.0009999949251386045 Training loss: 0.0
2025-12-09 10:23:31.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 1534 LR: 0.0009999949180582387 Training loss: 0.0
2025-12-09 10:23:31.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 1535 LR: 0.0009999949109729372 Training loss: 0.0
2025-12-09 10:23:31.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 1536 LR: 0.0009999949038827 Training loss: 0.0
2025-12-09 10:23:31.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 1537 LR: 0.000999994896787527 Training loss: 0.0
2025-12-09 10:23:31.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 1538 LR: 0.0009999948896874183 Training loss: 0.0
2025-12-09 10:23:31.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 1539 LR: 0.0009999948825823736 Training loss: 0.0
2025-12-09 10:23:31.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 1540 LR: 0.0009999948754723935 Training loss: 0.0
2025-12-09 10:23:31.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 1541 LR: 0.0009999948683574776 Training loss: 0.0
2025-12-09 10:23:31.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 1542 LR: 0.0009999948612376258 Training loss: 0.0
2025-12-09 10:23:31.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 1543 LR: 0.0009999948541128383 Training loss: 0.0
2025-12-09 10:23:31.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 1544 LR: 0.0009999948469831153 Training loss: 0.0
2025-12-09 10:23:31.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 1545 LR: 0.0009999948398484563 Training loss: 0.0
2025-12-09 10:23:31.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 1546 LR: 0.0009999948327088616 Training loss: 0.0
2025-12-09 10:23:31.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 1547 LR: 0.0009999948255643312 Training loss: 0.0
2025-12-09 10:23:31.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 1548 LR: 0.000999994818414865 Training loss: 0.0
2025-12-09 10:23:31.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 1549 LR: 0.0009999948112604632 Training loss: 0.0
2025-12-09 10:23:31.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 1550 LR: 0.0009999948041011257 Training loss: 0.0
2025-12-09 10:23:31.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 1551 LR: 0.0009999947969368524 Training loss: 0.0
2025-12-09 10:23:31.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 1552 LR: 0.0009999947897676431 Training loss: 0.0
2025-12-09 10:23:31.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 1553 LR: 0.0009999947825934984 Training loss: 0.0
2025-12-09 10:23:31.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 1554 LR: 0.000999994775414418 Training loss: 0.0
2025-12-09 10:23:31.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 1555 LR: 0.0009999947682304015 Training loss: 0.0
2025-12-09 10:23:31.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 1556 LR: 0.0009999947610414494 Training loss: 0.0
2025-12-09 10:23:31.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 1557 LR: 0.0009999947538475618 Training loss: 0.0
2025-12-09 10:23:31.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 1558 LR: 0.0009999947466487382 Training loss: 0.0
2025-12-09 10:23:31.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 1559 LR: 0.000999994739444979 Training loss: 0.0
2025-12-09 10:23:31.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 1560 LR: 0.000999994732236284 Training loss: 0.0
2025-12-09 10:23:31.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 1561 LR: 0.0009999947250226532 Training loss: 0.0
2025-12-09 10:23:31.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 1562 LR: 0.0009999947178040867 Training loss: 0.0
2025-12-09 10:23:31.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 1563 LR: 0.0009999947105805845 Training loss: 0.0
2025-12-09 10:23:31.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 1564 LR: 0.0009999947033521466 Training loss: 0.0
2025-12-09 10:23:31.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 1565 LR: 0.000999994696118773 Training loss: 0.0
2025-12-09 10:23:31.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 1566 LR: 0.0009999946888804637 Training loss: 0.0
2025-12-09 10:23:31.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 1567 LR: 0.0009999946816372184 Training loss: 0.0
2025-12-09 10:23:31.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 1568 LR: 0.0009999946743890376 Training loss: 0.0
2025-12-09 10:23:31.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 1569 LR: 0.0009999946671359209 Training loss: 0.0
2025-12-09 10:23:31.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 1570 LR: 0.0009999946598778686 Training loss: 0.0
2025-12-09 10:23:31.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 1571 LR: 0.0009999946526148805 Training loss: 0.0
2025-12-09 10:23:31.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 1572 LR: 0.0009999946453469566 Training loss: 0.0
2025-12-09 10:23:31.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 1573 LR: 0.0009999946380740972 Training loss: 0.0
2025-12-09 10:23:31.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 1574 LR: 0.0009999946307963016 Training loss: 0.0
2025-12-09 10:23:31.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 1575 LR: 0.0009999946235135708 Training loss: 0.0
2025-12-09 10:23:31.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 1576 LR: 0.000999994616225904 Training loss: 0.0
2025-12-09 10:23:31.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 1577 LR: 0.0009999946089333015 Training loss: 0.0
2025-12-09 10:23:31.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 1578 LR: 0.0009999946016357633 Training loss: 0.0
2025-12-09 10:23:31.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 1579 LR: 0.000999994594333289 Training loss: 0.0
2025-12-09 10:23:31.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 1580 LR: 0.0009999945870258794 Training loss: 0.0
2025-12-09 10:23:31.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 1581 LR: 0.000999994579713534 Training loss: 0.0
2025-12-09 10:23:31.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 1582 LR: 0.0009999945723962527 Training loss: 0.0
2025-12-09 10:23:31.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 1583 LR: 0.0009999945650740359 Training loss: 0.0
2025-12-09 10:23:31.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 1584 LR: 0.0009999945577468831 Training loss: 0.0
2025-12-09 10:23:31.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 1585 LR: 0.0009999945504147948 Training loss: 0.0
2025-12-09 10:23:31.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 1586 LR: 0.0009999945430777706 Training loss: 0.0
2025-12-09 10:23:31.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 1587 LR: 0.000999994535735811 Training loss: 0.0
2025-12-09 10:23:31.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 1588 LR: 0.0009999945283889152 Training loss: 0.0
2025-12-09 10:23:31.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 1589 LR: 0.0009999945210370838 Training loss: 0.0
2025-12-09 10:23:31.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 1590 LR: 0.0009999945136803167 Training loss: 0.0
2025-12-09 10:23:31.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 1591 LR: 0.000999994506318614 Training loss: 0.0
2025-12-09 10:23:31.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 1592 LR: 0.0009999944989519754 Training loss: 0.0
2025-12-09 10:23:31.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 1593 LR: 0.000999994491580401 Training loss: 0.0
2025-12-09 10:23:31.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 1594 LR: 0.000999994484203891 Training loss: 0.0
2025-12-09 10:23:31.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 1595 LR: 0.0009999944768224454 Training loss: 0.0
2025-12-09 10:23:31.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 1596 LR: 0.000999994469436064 Training loss: 0.0
2025-12-09 10:23:31.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 1597 LR: 0.0009999944620447468 Training loss: 0.0
2025-12-09 10:23:31.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 1598 LR: 0.000999994454648494 Training loss: 0.0
2025-12-09 10:23:31.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 1599 LR: 0.000999994447247305 Training loss: 0.0
2025-12-09 10:23:31.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 1600 LR: 0.0009999944398411808 Training loss: 0.0
2025-12-09 10:23:31.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 1601 LR: 0.0009999944324301205 Training loss: 0.0
2025-12-09 10:23:31.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 1602 LR: 0.0009999944250141247 Training loss: 0.0
2025-12-09 10:23:31.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 1603 LR: 0.000999994417593193 Training loss: 0.0
2025-12-09 10:23:31.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 1604 LR: 0.0009999944101673256 Training loss: 0.0
2025-12-09 10:23:31.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 1605 LR: 0.0009999944027365224 Training loss: 0.0
2025-12-09 10:23:31.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 1606 LR: 0.0009999943953007838 Training loss: 0.0
2025-12-09 10:23:31.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 1607 LR: 0.0009999943878601092 Training loss: 0.0
2025-12-09 10:23:31.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 1608 LR: 0.0009999943804144989 Training loss: 0.0
2025-12-09 10:23:31.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 1609 LR: 0.0009999943729639528 Training loss: 0.0
2025-12-09 10:23:31.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 1610 LR: 0.000999994365508471 Training loss: 0.0
2025-12-09 10:23:31.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 1611 LR: 0.0009999943580480536 Training loss: 0.0
2025-12-09 10:23:31.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 1612 LR: 0.0009999943505827002 Training loss: 0.0
2025-12-09 10:23:31.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 1613 LR: 0.0009999943431124112 Training loss: 0.0
2025-12-09 10:23:31.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 1614 LR: 0.0009999943356371866 Training loss: 0.0
2025-12-09 10:23:31.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 1615 LR: 0.0009999943281570262 Training loss: 0.0
2025-12-09 10:23:31.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 1616 LR: 0.00099999432067193 Training loss: 0.0
2025-12-09 10:23:31.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 1617 LR: 0.000999994313181898 Training loss: 0.0
2025-12-09 10:23:31.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 1618 LR: 0.0009999943056869306 Training loss: 0.0
2025-12-09 10:23:31.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 1619 LR: 0.000999994298187027 Training loss: 0.0
2025-12-09 10:23:31.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 1620 LR: 0.000999994290682188 Training loss: 0.0
2025-12-09 10:23:31.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 1621 LR: 0.0009999942831724132 Training loss: 0.0
2025-12-09 10:23:31.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 1622 LR: 0.0009999942756577025 Training loss: 0.0
2025-12-09 10:23:31.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 1623 LR: 0.0009999942681380562 Training loss: 0.0
2025-12-09 10:23:31.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 1624 LR: 0.0009999942606134743 Training loss: 0.0
2025-12-09 10:23:31.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 1625 LR: 0.0009999942530839565 Training loss: 0.0
2025-12-09 10:23:31.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 1626 LR: 0.000999994245549503 Training loss: 0.0
2025-12-09 10:23:31.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 1627 LR: 0.000999994238010114 Training loss: 0.0
2025-12-09 10:23:31.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 1628 LR: 0.000999994230465789 Training loss: 0.0
2025-12-09 10:23:31.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 1629 LR: 0.0009999942229165283 Training loss: 0.0
2025-12-09 10:23:31.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 1630 LR: 0.0009999942153623318 Training loss: 0.0
2025-12-09 10:23:31.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 1631 LR: 0.0009999942078031997 Training loss: 0.0
2025-12-09 10:23:31.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 1632 LR: 0.0009999942002391318 Training loss: 0.0
2025-12-09 10:23:31.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 1633 LR: 0.000999994192670128 Training loss: 0.0
2025-12-09 10:23:31.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 1634 LR: 0.0009999941850961887 Training loss: 0.0
2025-12-09 10:23:31.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 1635 LR: 0.0009999941775173135 Training loss: 0.0
2025-12-09 10:23:31.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 1636 LR: 0.000999994169933503 Training loss: 0.0
2025-12-09 10:23:31.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 1637 LR: 0.0009999941623447563 Training loss: 0.0
2025-12-09 10:23:31.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 1638 LR: 0.000999994154751074 Training loss: 0.0
2025-12-09 10:23:31.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 1639 LR: 0.0009999941471524562 Training loss: 0.0
2025-12-09 10:23:31.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 1640 LR: 0.0009999941395489023 Training loss: 0.0
2025-12-09 10:23:31.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 1641 LR: 0.0009999941319404127 Training loss: 0.0
2025-12-09 10:23:31.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 1642 LR: 0.0009999941243269877 Training loss: 0.0
2025-12-09 10:23:31.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 1643 LR: 0.0009999941167086266 Training loss: 0.0
2025-12-09 10:23:31.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 1644 LR: 0.0009999941090853299 Training loss: 0.0
2025-12-09 10:23:31.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 1645 LR: 0.0009999941014570976 Training loss: 0.0
2025-12-09 10:23:31.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 1646 LR: 0.0009999940938239295 Training loss: 0.0
2025-12-09 10:23:31.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 1647 LR: 0.0009999940861858258 Training loss: 0.0
2025-12-09 10:23:31.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 1648 LR: 0.000999994078542786 Training loss: 0.0
2025-12-09 10:23:31.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 1649 LR: 0.0009999940708948106 Training loss: 0.0
2025-12-09 10:23:31.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 1650 LR: 0.0009999940632418995 Training loss: 0.0
2025-12-09 10:23:31.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 1651 LR: 0.0009999940555840527 Training loss: 0.0
2025-12-09 10:23:31.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 1652 LR: 0.0009999940479212704 Training loss: 0.0
2025-12-09 10:23:31.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 1653 LR: 0.0009999940402535522 Training loss: 0.0
2025-12-09 10:23:31.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 1654 LR: 0.000999994032580898 Training loss: 0.0
2025-12-09 10:23:31.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 1655 LR: 0.0009999940249033083 Training loss: 0.0
2025-12-09 10:23:31.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 1656 LR: 0.0009999940172207829 Training loss: 0.0
2025-12-09 10:23:31.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 1657 LR: 0.0009999940095333218 Training loss: 0.0
2025-12-09 10:23:31.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 1658 LR: 0.000999994001840925 Training loss: 0.0
2025-12-09 10:23:31.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 1659 LR: 0.0009999939941435923 Training loss: 0.0
2025-12-09 10:23:31.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 1660 LR: 0.0009999939864413238 Training loss: 0.0
2025-12-09 10:23:31.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 1661 LR: 0.0009999939787341198 Training loss: 0.0
2025-12-09 10:23:31.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 1662 LR: 0.00099999397102198 Training loss: 0.0
2025-12-09 10:23:31.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 1663 LR: 0.0009999939633049044 Training loss: 0.0
2025-12-09 10:23:31.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 1664 LR: 0.0009999939555828932 Training loss: 0.0
2025-12-09 10:23:31.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 1665 LR: 0.000999993947855946 Training loss: 0.0
2025-12-09 10:23:31.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 1666 LR: 0.0009999939401240635 Training loss: 0.0
2025-12-09 10:23:31.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 1667 LR: 0.000999993932387245 Training loss: 0.0
2025-12-09 10:23:31.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 1668 LR: 0.0009999939246454908 Training loss: 0.0
2025-12-09 10:23:31.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 1669 LR: 0.0009999939168988008 Training loss: 0.0
2025-12-09 10:23:31.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 1670 LR: 0.0009999939091471753 Training loss: 0.0
2025-12-09 10:23:31.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 1671 LR: 0.0009999939013906139 Training loss: 0.0
2025-12-09 10:23:31.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 1672 LR: 0.0009999938936291167 Training loss: 0.0
2025-12-09 10:23:31.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 1673 LR: 0.0009999938858626838 Training loss: 0.0
2025-12-09 10:23:31.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 1674 LR: 0.0009999938780913152 Training loss: 0.0
2025-12-09 10:23:31.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 1675 LR: 0.000999993870315011 Training loss: 0.0
2025-12-09 10:23:31.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 1676 LR: 0.000999993862533771 Training loss: 0.0
2025-12-09 10:23:31.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 1677 LR: 0.0009999938547475952 Training loss: 0.0
2025-12-09 10:23:31.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 1678 LR: 0.0009999938469564837 Training loss: 0.0
2025-12-09 10:23:31.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 1679 LR: 0.0009999938391604365 Training loss: 0.0
2025-12-09 10:23:31.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 1680 LR: 0.0009999938313594535 Training loss: 0.0
2025-12-09 10:23:31.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 1681 LR: 0.0009999938235535348 Training loss: 0.0
2025-12-09 10:23:31.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 1682 LR: 0.0009999938157426805 Training loss: 0.0
2025-12-09 10:23:31.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 1683 LR: 0.0009999938079268903 Training loss: 0.0
2025-12-09 10:23:31.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 1684 LR: 0.0009999938001061645 Training loss: 0.0
2025-12-09 10:23:31.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 1685 LR: 0.000999993792280503 Training loss: 0.0
2025-12-09 10:23:31.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 1686 LR: 0.0009999937844499057 Training loss: 0.0
2025-12-09 10:23:31.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 1687 LR: 0.0009999937766143724 Training loss: 0.0
2025-12-09 10:23:31.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 1688 LR: 0.0009999937687739037 Training loss: 0.0
2025-12-09 10:23:31.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 1689 LR: 0.0009999937609284993 Training loss: 0.0
2025-12-09 10:23:31.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 1690 LR: 0.000999993753078159 Training loss: 0.0
2025-12-09 10:23:31.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 1691 LR: 0.0009999937452228832 Training loss: 0.0
2025-12-09 10:23:31.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 1692 LR: 0.0009999937373626716 Training loss: 0.0
2025-12-09 10:23:31.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 1693 LR: 0.000999993729497524 Training loss: 0.0
2025-12-09 10:23:31.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 1694 LR: 0.0009999937216274408 Training loss: 0.0
2025-12-09 10:23:31.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 1695 LR: 0.000999993713752422 Training loss: 0.0
2025-12-09 10:23:31.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 1696 LR: 0.0009999937058724675 Training loss: 0.0
2025-12-09 10:23:31.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 1697 LR: 0.0009999936979875773 Training loss: 0.0
2025-12-09 10:23:31.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 1698 LR: 0.000999993690097751 Training loss: 0.0
2025-12-09 10:23:31.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 1699 LR: 0.0009999936822029894 Training loss: 0.0
2025-12-09 10:23:31.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 1700 LR: 0.0009999936743032918 Training loss: 0.0
2025-12-09 10:23:31.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 1701 LR: 0.0009999936663986587 Training loss: 0.0
2025-12-09 10:23:31.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 1702 LR: 0.0009999936584890897 Training loss: 0.0
2025-12-09 10:23:31.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 1703 LR: 0.000999993650574585 Training loss: 0.0
2025-12-09 10:23:31.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 1704 LR: 0.0009999936426551446 Training loss: 0.0
2025-12-09 10:23:31.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 1705 LR: 0.0009999936347307686 Training loss: 0.0
2025-12-09 10:23:31.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 1706 LR: 0.0009999936268014567 Training loss: 0.0
2025-12-09 10:23:31.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 1707 LR: 0.000999993618867209 Training loss: 0.0
2025-12-09 10:23:31.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 1708 LR: 0.0009999936109280256 Training loss: 0.0
2025-12-09 10:23:31.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 1709 LR: 0.0009999936029839067 Training loss: 0.0
2025-12-09 10:23:31.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 1710 LR: 0.000999993595034852 Training loss: 0.0
2025-12-09 10:23:31.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 1711 LR: 0.0009999935870808614 Training loss: 0.0
2025-12-09 10:23:31.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 1712 LR: 0.0009999935791219353 Training loss: 0.0
2025-12-09 10:23:31.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 1713 LR: 0.0009999935711580731 Training loss: 0.0
2025-12-09 10:23:31.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 1714 LR: 0.0009999935631892756 Training loss: 0.0
2025-12-09 10:23:31.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 1715 LR: 0.0009999935552155422 Training loss: 0.0
2025-12-09 10:23:31.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 1716 LR: 0.000999993547236873 Training loss: 0.0
2025-12-09 10:23:31.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 1717 LR: 0.0009999935392532681 Training loss: 0.0
2025-12-09 10:23:31.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 1718 LR: 0.0009999935312647278 Training loss: 0.0
2025-12-09 10:23:31.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 1719 LR: 0.0009999935232712514 Training loss: 0.0
2025-12-09 10:23:31.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 1720 LR: 0.0009999935152728394 Training loss: 0.0
2025-12-09 10:23:31.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 1721 LR: 0.0009999935072694916 Training loss: 0.0
2025-12-09 10:23:31.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 1722 LR: 0.0009999934992612081 Training loss: 0.0
2025-12-09 10:23:31.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 1723 LR: 0.000999993491247989 Training loss: 0.0
2025-12-09 10:23:31.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 1724 LR: 0.000999993483229834 Training loss: 0.0
2025-12-09 10:23:31.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 1725 LR: 0.0009999934752067435 Training loss: 0.0
2025-12-09 10:23:31.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 1726 LR: 0.000999993467178717 Training loss: 0.0
2025-12-09 10:23:31.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 1727 LR: 0.0009999934591457549 Training loss: 0.0
2025-12-09 10:23:31.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 1728 LR: 0.0009999934511078573 Training loss: 0.0
2025-12-09 10:23:31.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 1729 LR: 0.0009999934430650237 Training loss: 0.0
2025-12-09 10:23:31.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 1730 LR: 0.0009999934350172544 Training loss: 0.0
2025-12-09 10:23:31.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 1731 LR: 0.0009999934269645492 Training loss: 0.0
2025-12-09 10:23:31.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 1732 LR: 0.0009999934189069087 Training loss: 0.0
2025-12-09 10:23:31.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 1733 LR: 0.0009999934108443323 Training loss: 0.0
2025-12-09 10:23:31.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 1734 LR: 0.00099999340277682 Training loss: 0.0
2025-12-09 10:23:31.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 1735 LR: 0.000999993394704372 Training loss: 0.0
2025-12-09 10:23:31.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 1736 LR: 0.0009999933866269885 Training loss: 0.0
2025-12-09 10:23:31.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 1737 LR: 0.0009999933785446692 Training loss: 0.0
2025-12-09 10:23:31.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 1738 LR: 0.0009999933704574141 Training loss: 0.0
2025-12-09 10:23:31.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 1739 LR: 0.0009999933623652234 Training loss: 0.0
2025-12-09 10:23:31.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 1740 LR: 0.0009999933542680969 Training loss: 0.0
2025-12-09 10:23:31.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 1741 LR: 0.0009999933461660347 Training loss: 0.0
2025-12-09 10:23:31.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 1742 LR: 0.0009999933380590367 Training loss: 0.0
2025-12-09 10:23:31.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 1743 LR: 0.0009999933299471029 Training loss: 0.0
2025-12-09 10:23:31.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 1744 LR: 0.0009999933218302335 Training loss: 0.0
2025-12-09 10:23:31.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 1745 LR: 0.0009999933137084284 Training loss: 0.0
2025-12-09 10:23:31.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 1746 LR: 0.0009999933055816876 Training loss: 0.0
2025-12-09 10:23:31.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 1747 LR: 0.000999993297450011 Training loss: 0.0
2025-12-09 10:23:31.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 1748 LR: 0.0009999932893133988 Training loss: 0.0
2025-12-09 10:23:31.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 1749 LR: 0.0009999932811718506 Training loss: 0.0
2025-12-09 10:23:31.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 1750 LR: 0.0009999932730253669 Training loss: 0.0
2025-12-09 10:23:31.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 1751 LR: 0.0009999932648739474 Training loss: 0.0
2025-12-09 10:23:31.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 1752 LR: 0.0009999932567175923 Training loss: 0.0
2025-12-09 10:23:31.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 1753 LR: 0.0009999932485563014 Training loss: 0.0
2025-12-09 10:23:31.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 1754 LR: 0.0009999932403900746 Training loss: 0.0
2025-12-09 10:23:31.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 1755 LR: 0.0009999932322189123 Training loss: 0.0
2025-12-09 10:23:31.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 1756 LR: 0.0009999932240428143 Training loss: 0.0
2025-12-09 10:23:31.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 1757 LR: 0.0009999932158617805 Training loss: 0.0
2025-12-09 10:23:31.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 1758 LR: 0.000999993207675811 Training loss: 0.0
2025-12-09 10:23:31.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 1759 LR: 0.0009999931994849058 Training loss: 0.0
2025-12-09 10:23:31.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 1760 LR: 0.0009999931912890647 Training loss: 0.0
2025-12-09 10:23:31.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 1761 LR: 0.000999993183088288 Training loss: 0.0
2025-12-09 10:23:31.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 1762 LR: 0.0009999931748825757 Training loss: 0.0
2025-12-09 10:23:31.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 1763 LR: 0.0009999931666719276 Training loss: 0.0
2025-12-09 10:23:31.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 1764 LR: 0.0009999931584563438 Training loss: 0.0
2025-12-09 10:23:31.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 1765 LR: 0.0009999931502358242 Training loss: 0.0
2025-12-09 10:23:31.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 1766 LR: 0.0009999931420103688 Training loss: 0.0
2025-12-09 10:23:31.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 1767 LR: 0.0009999931337799778 Training loss: 0.0
2025-12-09 10:23:31.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 1768 LR: 0.000999993125544651 Training loss: 0.0
2025-12-09 10:23:31.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 1769 LR: 0.0009999931173043887 Training loss: 0.0
2025-12-09 10:23:31.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 1770 LR: 0.0009999931090591903 Training loss: 0.0
2025-12-09 10:23:31.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 1771 LR: 0.0009999931008090564 Training loss: 0.0
2025-12-09 10:23:31.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 1772 LR: 0.0009999930925539868 Training loss: 0.0
2025-12-09 10:23:31.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 1773 LR: 0.0009999930842939815 Training loss: 0.0
2025-12-09 10:23:31.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 1774 LR: 0.0009999930760290405 Training loss: 0.0
2025-12-09 10:23:31.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 1775 LR: 0.0009999930677591638 Training loss: 0.0
2025-12-09 10:23:31.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 1776 LR: 0.000999993059484351 Training loss: 0.0
2025-12-09 10:23:31.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 1777 LR: 0.0009999930512046029 Training loss: 0.0
2025-12-09 10:23:31.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 1778 LR: 0.000999993042919919 Training loss: 0.0
2025-12-09 10:23:31.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 1779 LR: 0.0009999930346302993 Training loss: 0.0
2025-12-09 10:23:31.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 1780 LR: 0.000999993026335744 Training loss: 0.0
2025-12-09 10:23:31.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 1781 LR: 0.0009999930180362528 Training loss: 0.0
2025-12-09 10:23:31.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 1782 LR: 0.000999993009731826 Training loss: 0.0
2025-12-09 10:23:31.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 1783 LR: 0.0009999930014224635 Training loss: 0.0
2025-12-09 10:23:31.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 1784 LR: 0.000999992993108165 Training loss: 0.0
2025-12-09 10:23:31.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 1785 LR: 0.000999992984788931 Training loss: 0.0
2025-12-09 10:23:31.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 1786 LR: 0.0009999929764647614 Training loss: 0.0
2025-12-09 10:23:31.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 1787 LR: 0.000999992968135656 Training loss: 0.0
2025-12-09 10:23:31.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 1788 LR: 0.0009999929598016148 Training loss: 0.0
2025-12-09 10:23:31.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 1789 LR: 0.000999992951462638 Training loss: 0.0
2025-12-09 10:23:31.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 1790 LR: 0.0009999929431187254 Training loss: 0.0
2025-12-09 10:23:31.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 1791 LR: 0.000999992934769877 Training loss: 0.0
2025-12-09 10:23:31.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 1792 LR: 0.000999992926416093 Training loss: 0.0
2025-12-09 10:23:31.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 1793 LR: 0.0009999929180573733 Training loss: 0.0
2025-12-09 10:23:31.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 1794 LR: 0.0009999929096937176 Training loss: 0.0
2025-12-09 10:23:31.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 1795 LR: 0.0009999929013251266 Training loss: 0.0
2025-12-09 10:23:31.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 1796 LR: 0.0009999928929515995 Training loss: 0.0
2025-12-09 10:23:31.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 1797 LR: 0.000999992884573137 Training loss: 0.0
2025-12-09 10:23:31.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 1798 LR: 0.0009999928761897387 Training loss: 0.0
2025-12-09 10:23:31.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 1799 LR: 0.0009999928678014046 Training loss: 0.0
2025-12-09 10:23:31.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 1800 LR: 0.0009999928594081348 Training loss: 0.0
2025-12-09 10:23:31.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 1801 LR: 0.0009999928510099293 Training loss: 0.0
2025-12-09 10:23:31.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 1802 LR: 0.000999992842606788 Training loss: 0.0
2025-12-09 10:23:31.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 1803 LR: 0.000999992834198711 Training loss: 0.0
2025-12-09 10:23:31.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 1804 LR: 0.0009999928257856984 Training loss: 0.0
2025-12-09 10:23:31.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 1805 LR: 0.0009999928173677502 Training loss: 0.0
2025-12-09 10:23:31.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 1806 LR: 0.000999992808944866 Training loss: 0.0
2025-12-09 10:23:31.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 1807 LR: 0.0009999928005170462 Training loss: 0.0
2025-12-09 10:23:31.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 1808 LR: 0.0009999927920842906 Training loss: 0.0
2025-12-09 10:23:31.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 1809 LR: 0.0009999927836465993 Training loss: 0.0
2025-12-09 10:23:31.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 1810 LR: 0.0009999927752039723 Training loss: 0.0
2025-12-09 10:23:31.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 1811 LR: 0.0009999927667564098 Training loss: 0.0
2025-12-09 10:23:31.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 1812 LR: 0.0009999927583039113 Training loss: 0.0
2025-12-09 10:23:31.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 1813 LR: 0.0009999927498464771 Training loss: 0.0
2025-12-09 10:23:31.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 1814 LR: 0.0009999927413841074 Training loss: 0.0
2025-12-09 10:23:31.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 1815 LR: 0.0009999927329168018 Training loss: 0.0
2025-12-09 10:23:31.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 1816 LR: 0.0009999927244445607 Training loss: 0.0
2025-12-09 10:23:31.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 1817 LR: 0.0009999927159673836 Training loss: 0.0
2025-12-09 10:23:31.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 1818 LR: 0.0009999927074852708 Training loss: 0.0
2025-12-09 10:23:31.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 1819 LR: 0.0009999926989982225 Training loss: 0.0
2025-12-09 10:23:31.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 1820 LR: 0.0009999926905062382 Training loss: 0.0
2025-12-09 10:23:31.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 1821 LR: 0.0009999926820093183 Training loss: 0.0
2025-12-09 10:23:31.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 1822 LR: 0.0009999926735074628 Training loss: 0.0
2025-12-09 10:23:31.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 1823 LR: 0.0009999926650006714 Training loss: 0.0
2025-12-09 10:23:31.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 1824 LR: 0.0009999926564889445 Training loss: 0.0
2025-12-09 10:23:31.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 1825 LR: 0.0009999926479722816 Training loss: 0.0
2025-12-09 10:23:31.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 1826 LR: 0.0009999926394506833 Training loss: 0.0
2025-12-09 10:23:31.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 1827 LR: 0.0009999926309241492 Training loss: 0.0
2025-12-09 10:23:31.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 1828 LR: 0.0009999926223926792 Training loss: 0.0
2025-12-09 10:23:31.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 1829 LR: 0.0009999926138562736 Training loss: 0.0
2025-12-09 10:23:31.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 1830 LR: 0.0009999926053149324 Training loss: 0.0
2025-12-09 10:23:31.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 1831 LR: 0.0009999925967686552 Training loss: 0.0
2025-12-09 10:23:31.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 1832 LR: 0.0009999925882174425 Training loss: 0.0
2025-12-09 10:23:31.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 1833 LR: 0.0009999925796612941 Training loss: 0.0
2025-12-09 10:23:31.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 1834 LR: 0.0009999925711002098 Training loss: 0.0
2025-12-09 10:23:31.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 1835 LR: 0.00099999256253419 Training loss: 0.0
2025-12-09 10:23:31.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 1836 LR: 0.0009999925539632343 Training loss: 0.0
2025-12-09 10:23:31.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 1837 LR: 0.000999992545387343 Training loss: 0.0
2025-12-09 10:23:31.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 1838 LR: 0.000999992536806516 Training loss: 0.0
2025-12-09 10:23:31.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 1839 LR: 0.000999992528220753 Training loss: 0.0
2025-12-09 10:23:31.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 1840 LR: 0.0009999925196300548 Training loss: 0.0
2025-12-09 10:23:31.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 1841 LR: 0.0009999925110344206 Training loss: 0.0
2025-12-09 10:23:31.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 1842 LR: 0.0009999925024338507 Training loss: 0.0
2025-12-09 10:23:31.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 1843 LR: 0.000999992493828345 Training loss: 0.0
2025-12-09 10:23:31.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 1844 LR: 0.0009999924852179037 Training loss: 0.0
2025-12-09 10:23:31.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 1845 LR: 0.0009999924766025267 Training loss: 0.0
2025-12-09 10:23:31.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 1846 LR: 0.0009999924679822139 Training loss: 0.0
2025-12-09 10:23:31.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 1847 LR: 0.0009999924593569653 Training loss: 0.0
2025-12-09 10:23:31.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 1848 LR: 0.0009999924507267813 Training loss: 0.0
2025-12-09 10:23:31.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 1849 LR: 0.0009999924420916614 Training loss: 0.0
2025-12-09 10:23:31.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 1850 LR: 0.0009999924334516057 Training loss: 0.0
2025-12-09 10:23:31.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 1851 LR: 0.0009999924248066143 Training loss: 0.0
2025-12-09 10:23:31.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 1852 LR: 0.0009999924161566871 Training loss: 0.0
2025-12-09 10:23:31.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 1853 LR: 0.0009999924075018245 Training loss: 0.0
2025-12-09 10:23:31.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 1854 LR: 0.000999992398842026 Training loss: 0.0
2025-12-09 10:23:31.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 1855 LR: 0.0009999923901772918 Training loss: 0.0
2025-12-09 10:23:31.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 1856 LR: 0.000999992381507622 Training loss: 0.0
2025-12-09 10:23:31.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 1857 LR: 0.0009999923728330163 Training loss: 0.0
2025-12-09 10:23:31.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 1858 LR: 0.0009999923641534748 Training loss: 0.0
2025-12-09 10:23:31.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 1859 LR: 0.0009999923554689979 Training loss: 0.0
2025-12-09 10:23:31.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 1860 LR: 0.000999992346779585 Training loss: 0.0
2025-12-09 10:23:31.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 1861 LR: 0.0009999923380852366 Training loss: 0.0
2025-12-09 10:23:31.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 1862 LR: 0.0009999923293859524 Training loss: 0.0
2025-12-09 10:23:31.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 1863 LR: 0.0009999923206817326 Training loss: 0.0
2025-12-09 10:23:31.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 1864 LR: 0.0009999923119725768 Training loss: 0.0
2025-12-09 10:23:31.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 1865 LR: 0.0009999923032584855 Training loss: 0.0
2025-12-09 10:23:31.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 1866 LR: 0.0009999922945394585 Training loss: 0.0
2025-12-09 10:23:31.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 1867 LR: 0.0009999922858154957 Training loss: 0.0
2025-12-09 10:23:31.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 1868 LR: 0.0009999922770865973 Training loss: 0.0
2025-12-09 10:23:31.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 1869 LR: 0.000999992268352763 Training loss: 0.0
2025-12-09 10:23:31.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 1870 LR: 0.0009999922596139932 Training loss: 0.0
2025-12-09 10:23:31.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 1871 LR: 0.0009999922508702875 Training loss: 0.0
2025-12-09 10:23:31.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 1872 LR: 0.0009999922421216462 Training loss: 0.0
2025-12-09 10:23:31.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 1873 LR: 0.0009999922333680691 Training loss: 0.0
2025-12-09 10:23:31.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 1874 LR: 0.0009999922246095563 Training loss: 0.0
2025-12-09 10:23:31.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 1875 LR: 0.0009999922158461078 Training loss: 0.0
2025-12-09 10:23:31.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 1876 LR: 0.0009999922070777238 Training loss: 0.0
2025-12-09 10:23:31.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 1877 LR: 0.0009999921983044038 Training loss: 0.0
2025-12-09 10:23:31.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 1878 LR: 0.0009999921895261484 Training loss: 0.0
2025-12-09 10:23:31.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 1879 LR: 0.000999992180742957 Training loss: 0.0
2025-12-09 10:23:31.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 1880 LR: 0.00099999217195483 Training loss: 0.0
2025-12-09 10:23:31.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 1881 LR: 0.0009999921631617672 Training loss: 0.0
2025-12-09 10:23:31.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 1882 LR: 0.0009999921543637686 Training loss: 0.0
2025-12-09 10:23:31.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 1883 LR: 0.0009999921455608345 Training loss: 0.0
2025-12-09 10:23:31.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 1884 LR: 0.0009999921367529647 Training loss: 0.0
2025-12-09 10:23:31.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 1885 LR: 0.0009999921279401592 Training loss: 0.0
2025-12-09 10:23:31.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 1886 LR: 0.0009999921191224178 Training loss: 0.0
2025-12-09 10:23:31.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 1887 LR: 0.0009999921102997408 Training loss: 0.0
2025-12-09 10:23:31.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 1888 LR: 0.0009999921014721281 Training loss: 0.0
2025-12-09 10:23:31.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 1889 LR: 0.0009999920926395797 Training loss: 0.0
2025-12-09 10:23:31.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 1890 LR: 0.0009999920838020956 Training loss: 0.0
2025-12-09 10:23:31.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 1891 LR: 0.0009999920749596755 Training loss: 0.0
2025-12-09 10:23:31.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 1892 LR: 0.0009999920661123202 Training loss: 0.0
2025-12-09 10:23:31.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 1893 LR: 0.0009999920572600289 Training loss: 0.0
2025-12-09 10:23:31.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 1894 LR: 0.0009999920484028018 Training loss: 0.0
2025-12-09 10:23:31.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 1895 LR: 0.000999992039540639 Training loss: 0.0
2025-12-09 10:23:31.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 1896 LR: 0.0009999920306735406 Training loss: 0.0
2025-12-09 10:23:31.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 1897 LR: 0.0009999920218015067 Training loss: 0.0
2025-12-09 10:23:31.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 1898 LR: 0.0009999920129245368 Training loss: 0.0
2025-12-09 10:23:31.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 1899 LR: 0.0009999920040426311 Training loss: 0.0
2025-12-09 10:23:31.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 1900 LR: 0.00099999199515579 Training loss: 0.0
2025-12-09 10:23:31.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 1901 LR: 0.000999991986264013 Training loss: 0.0
2025-12-09 10:23:31.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 1902 LR: 0.0009999919773673004 Training loss: 0.0
2025-12-09 10:23:31.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 1903 LR: 0.000999991968465652 Training loss: 0.0
2025-12-09 10:23:31.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 1904 LR: 0.0009999919595590678 Training loss: 0.0
2025-12-09 10:23:31.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 1905 LR: 0.000999991950647548 Training loss: 0.0
2025-12-09 10:23:31.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 1906 LR: 0.0009999919417310926 Training loss: 0.0
2025-12-09 10:23:31.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 1907 LR: 0.0009999919328097014 Training loss: 0.0
2025-12-09 10:23:31.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 1908 LR: 0.0009999919238833743 Training loss: 0.0
2025-12-09 10:23:31.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 1909 LR: 0.0009999919149521117 Training loss: 0.0
2025-12-09 10:23:31.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 1910 LR: 0.0009999919060159133 Training loss: 0.0
2025-12-09 10:23:31.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 1911 LR: 0.0009999918970747792 Training loss: 0.0
2025-12-09 10:23:31.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 1912 LR: 0.0009999918881287095 Training loss: 0.0
2025-12-09 10:23:31.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 1913 LR: 0.0009999918791777042 Training loss: 0.0
2025-12-09 10:23:31.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 1914 LR: 0.000999991870221763 Training loss: 0.0
2025-12-09 10:23:31.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 1915 LR: 0.000999991861260886 Training loss: 0.0
2025-12-09 10:23:31.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 1916 LR: 0.0009999918522950735 Training loss: 0.0
2025-12-09 10:23:31.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 1917 LR: 0.000999991843324325 Training loss: 0.0
2025-12-09 10:23:31.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 1918 LR: 0.000999991834348641 Training loss: 0.0
2025-12-09 10:23:31.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 1919 LR: 0.0009999918253680213 Training loss: 0.0
2025-12-09 10:23:31.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 1920 LR: 0.000999991816382466 Training loss: 0.0
2025-12-09 10:23:31.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 1921 LR: 0.0009999918073919747 Training loss: 0.0
2025-12-09 10:23:31.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 1922 LR: 0.0009999917983965479 Training loss: 0.0
2025-12-09 10:23:31.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 1923 LR: 0.0009999917893961853 Training loss: 0.0
2025-12-09 10:23:31.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 1924 LR: 0.000999991780390887 Training loss: 0.0
2025-12-09 10:23:31.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 1925 LR: 0.000999991771380653 Training loss: 0.0
2025-12-09 10:23:31.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 1926 LR: 0.0009999917623654834 Training loss: 0.0
2025-12-09 10:23:31.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 1927 LR: 0.000999991753345378 Training loss: 0.0
2025-12-09 10:23:31.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 1928 LR: 0.0009999917443203367 Training loss: 0.0
2025-12-09 10:23:31.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 1929 LR: 0.00099999173529036 Training loss: 0.0
2025-12-09 10:23:31.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 1930 LR: 0.0009999917262554475 Training loss: 0.0
2025-12-09 10:23:31.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 1931 LR: 0.0009999917172155992 Training loss: 0.0
2025-12-09 10:23:31.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 1932 LR: 0.0009999917081708154 Training loss: 0.0
2025-12-09 10:23:31.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 1933 LR: 0.0009999916991210959 Training loss: 0.0
2025-12-09 10:23:31.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 1934 LR: 0.0009999916900664404 Training loss: 0.0
2025-12-09 10:23:31.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 1935 LR: 0.0009999916810068494 Training loss: 0.0
2025-12-09 10:23:31.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 1936 LR: 0.0009999916719423225 Training loss: 0.0
2025-12-09 10:23:31.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 1937 LR: 0.00099999166287286 Training loss: 0.0
2025-12-09 10:23:31.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 1938 LR: 0.000999991653798462 Training loss: 0.0
2025-12-09 10:23:31.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 1939 LR: 0.000999991644719128 Training loss: 0.0
2025-12-09 10:23:31.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 1940 LR: 0.0009999916356348583 Training loss: 0.0
2025-12-09 10:23:31.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 1941 LR: 0.000999991626545653 Training loss: 0.0
2025-12-09 10:23:31.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 1942 LR: 0.0009999916174515122 Training loss: 0.0
2025-12-09 10:23:31.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 1943 LR: 0.0009999916083524355 Training loss: 0.0
2025-12-09 10:23:31.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 1944 LR: 0.000999991599248423 Training loss: 0.0
2025-12-09 10:23:31.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 1945 LR: 0.0009999915901394748 Training loss: 0.0
2025-12-09 10:23:31.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 1946 LR: 0.0009999915810255911 Training loss: 0.0
2025-12-09 10:23:31.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 1947 LR: 0.0009999915719067715 Training loss: 0.0
2025-12-09 10:23:31.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 1948 LR: 0.0009999915627830164 Training loss: 0.0
2025-12-09 10:23:31.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 1949 LR: 0.0009999915536543253 Training loss: 0.0
2025-12-09 10:23:31.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 1950 LR: 0.0009999915445206987 Training loss: 0.0
2025-12-09 10:23:31.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 1951 LR: 0.0009999915353821362 Training loss: 0.0
2025-12-09 10:23:31.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 1952 LR: 0.0009999915262386382 Training loss: 0.0
2025-12-09 10:23:31.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 1953 LR: 0.0009999915170902044 Training loss: 0.0
2025-12-09 10:23:31.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 1954 LR: 0.000999991507936835 Training loss: 0.0
2025-12-09 10:23:31.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 1955 LR: 0.0009999914987785298 Training loss: 0.0
2025-12-09 10:23:31.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 1956 LR: 0.0009999914896152888 Training loss: 0.0
2025-12-09 10:23:31.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 1957 LR: 0.0009999914804471122 Training loss: 0.0
2025-12-09 10:23:31.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 1958 LR: 0.0009999914712739998 Training loss: 0.0
2025-12-09 10:23:31.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 1959 LR: 0.000999991462095952 Training loss: 0.0
2025-12-09 10:23:31.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 1960 LR: 0.0009999914529129682 Training loss: 0.0
2025-12-09 10:23:31.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 1961 LR: 0.0009999914437250489 Training loss: 0.0
2025-12-09 10:23:31.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 1962 LR: 0.0009999914345321936 Training loss: 0.0
2025-12-09 10:23:31.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 1963 LR: 0.0009999914253344029 Training loss: 0.0
2025-12-09 10:23:31.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 1964 LR: 0.0009999914161316764 Training loss: 0.0
2025-12-09 10:23:31.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 1965 LR: 0.0009999914069240142 Training loss: 0.0
2025-12-09 10:23:31.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 1966 LR: 0.000999991397711416 Training loss: 0.0
2025-12-09 10:23:31.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 1967 LR: 0.0009999913884938825 Training loss: 0.0
2025-12-09 10:23:31.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 1968 LR: 0.000999991379271413 Training loss: 0.0
2025-12-09 10:23:31.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 1969 LR: 0.000999991370044008 Training loss: 0.0
2025-12-09 10:23:31.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 1970 LR: 0.0009999913608116672 Training loss: 0.0
2025-12-09 10:23:31.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 1971 LR: 0.000999991351574391 Training loss: 0.0
2025-12-09 10:23:31.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 1972 LR: 0.0009999913423321787 Training loss: 0.0
2025-12-09 10:23:31.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 1973 LR: 0.000999991333085031 Training loss: 0.0
2025-12-09 10:23:31.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 1974 LR: 0.0009999913238329472 Training loss: 0.0
2025-12-09 10:23:31.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 1975 LR: 0.000999991314575928 Training loss: 0.0
2025-12-09 10:23:31.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 1976 LR: 0.000999991305313973 Training loss: 0.0
2025-12-09 10:23:31.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 1977 LR: 0.0009999912960470822 Training loss: 0.0
2025-12-09 10:23:31.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 1978 LR: 0.0009999912867752559 Training loss: 0.0
2025-12-09 10:23:31.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 1979 LR: 0.0009999912774984938 Training loss: 0.0
2025-12-09 10:23:31.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 1980 LR: 0.000999991268216796 Training loss: 0.0
2025-12-09 10:23:31.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 1981 LR: 0.0009999912589301625 Training loss: 0.0
2025-12-09 10:23:31.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 1982 LR: 0.0009999912496385934 Training loss: 0.0
2025-12-09 10:23:31.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 1983 LR: 0.0009999912403420884 Training loss: 0.0
2025-12-09 10:23:31.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 1984 LR: 0.0009999912310406478 Training loss: 0.0
2025-12-09 10:23:31.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 1985 LR: 0.0009999912217342716 Training loss: 0.0
2025-12-09 10:23:31.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 1986 LR: 0.0009999912124229596 Training loss: 0.0
2025-12-09 10:23:31.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 1987 LR: 0.0009999912031067118 Training loss: 0.0
2025-12-09 10:23:31.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 1988 LR: 0.0009999911937855284 Training loss: 0.0
2025-12-09 10:23:31.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 1989 LR: 0.0009999911844594093 Training loss: 0.0
2025-12-09 10:23:31.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 1990 LR: 0.0009999911751283545 Training loss: 0.0
2025-12-09 10:23:31.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 1991 LR: 0.000999991165792364 Training loss: 0.0
2025-12-09 10:23:31.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 1992 LR: 0.0009999911564514377 Training loss: 0.0
2025-12-09 10:23:31.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 1993 LR: 0.0009999911471055758 Training loss: 0.0
2025-12-09 10:23:31.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 1994 LR: 0.000999991137754778 Training loss: 0.0
2025-12-09 10:23:31.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 1995 LR: 0.0009999911283990449 Training loss: 0.0
2025-12-09 10:23:31.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 1996 LR: 0.0009999911190383757 Training loss: 0.0
2025-12-09 10:23:31.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 1997 LR: 0.000999991109672771 Training loss: 0.0
2025-12-09 10:23:31.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 1998 LR: 0.0009999911003022307 Training loss: 0.0
2025-12-09 10:23:31.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 1999 LR: 0.0009999910909267544 Training loss: 0.0
2025-12-09 10:23:31.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 2000 LR: 0.0009999910815463426 Training loss: 0.0
2025-12-09 10:23:31.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 2001 LR: 0.000999991072160995 Training loss: 0.0
2025-12-09 10:23:31.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 2002 LR: 0.0009999910627707118 Training loss: 0.0
2025-12-09 10:23:31.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 2003 LR: 0.000999991053375493 Training loss: 0.0
2025-12-09 10:23:31.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 2004 LR: 0.0009999910439753383 Training loss: 0.0
2025-12-09 10:23:31.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 2005 LR: 0.000999991034570248 Training loss: 0.0
2025-12-09 10:23:31.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 2006 LR: 0.000999991025160222 Training loss: 0.0
2025-12-09 10:23:31.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 2007 LR: 0.0009999910157452601 Training loss: 0.0
2025-12-09 10:23:31.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 2008 LR: 0.0009999910063253627 Training loss: 0.0
2025-12-09 10:23:31.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 2009 LR: 0.0009999909969005297 Training loss: 0.0
2025-12-09 10:23:31.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 2010 LR: 0.0009999909874707606 Training loss: 0.0
2025-12-09 10:23:31.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 2011 LR: 0.0009999909780360563 Training loss: 0.0
2025-12-09 10:23:31.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 2012 LR: 0.0009999909685964158 Training loss: 0.0
2025-12-09 10:23:31.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 2013 LR: 0.00099999095915184 Training loss: 0.0
2025-12-09 10:23:31.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 2014 LR: 0.0009999909497023284 Training loss: 0.0
2025-12-09 10:23:31.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 2015 LR: 0.0009999909402478812 Training loss: 0.0
2025-12-09 10:23:31.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 2016 LR: 0.000999990930788498 Training loss: 0.0
2025-12-09 10:23:31.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 2017 LR: 0.0009999909213241791 Training loss: 0.0
2025-12-09 10:23:31.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 2018 LR: 0.0009999909118549248 Training loss: 0.0
2025-12-09 10:23:31.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 2019 LR: 0.0009999909023807345 Training loss: 0.0
2025-12-09 10:23:31.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 2020 LR: 0.0009999908929016089 Training loss: 0.0
2025-12-09 10:23:31.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 2021 LR: 0.0009999908834175473 Training loss: 0.0
2025-12-09 10:23:31.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 2022 LR: 0.0009999908739285498 Training loss: 0.0
2025-12-09 10:23:31.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 2023 LR: 0.0009999908644346168 Training loss: 0.0
2025-12-09 10:23:31.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 2024 LR: 0.0009999908549357484 Training loss: 0.0
2025-12-09 10:23:31.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 2025 LR: 0.000999990845431944 Training loss: 0.0
2025-12-09 10:23:31.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 2026 LR: 0.000999990835923204 Training loss: 0.0
2025-12-09 10:23:31.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 2027 LR: 0.0009999908264095283 Training loss: 0.0
2025-12-09 10:23:31.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 2028 LR: 0.000999990816890917 Training loss: 0.0
2025-12-09 10:23:31.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 2029 LR: 0.0009999908073673697 Training loss: 0.0
2025-12-09 10:23:31.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 2030 LR: 0.0009999907978388868 Training loss: 0.0
2025-12-09 10:23:31.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 2031 LR: 0.0009999907883054683 Training loss: 0.0
2025-12-09 10:23:31.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 2032 LR: 0.000999990778767114 Training loss: 0.0
2025-12-09 10:23:31.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 2033 LR: 0.000999990769223824 Training loss: 0.0
2025-12-09 10:23:31.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 2034 LR: 0.0009999907596755985 Training loss: 0.0
2025-12-09 10:23:31.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 2035 LR: 0.0009999907501224373 Training loss: 0.0
2025-12-09 10:23:31.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 2036 LR: 0.0009999907405643402 Training loss: 0.0
2025-12-09 10:23:31.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 2037 LR: 0.0009999907310013075 Training loss: 0.0
2025-12-09 10:23:31.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 2038 LR: 0.000999990721433339 Training loss: 0.0
2025-12-09 10:23:31.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 2039 LR: 0.0009999907118604348 Training loss: 0.0
2025-12-09 10:23:31.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 2040 LR: 0.0009999907022825952 Training loss: 0.0
2025-12-09 10:23:31.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 2041 LR: 0.0009999906926998197 Training loss: 0.0
2025-12-09 10:23:31.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 2042 LR: 0.0009999906831121084 Training loss: 0.0
2025-12-09 10:23:31.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 2043 LR: 0.0009999906735194614 Training loss: 0.0
2025-12-09 10:23:31.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 2044 LR: 0.000999990663921879 Training loss: 0.0
2025-12-09 10:23:31.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 2045 LR: 0.0009999906543193605 Training loss: 0.0
2025-12-09 10:23:31.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 2046 LR: 0.0009999906447119066 Training loss: 0.0
2025-12-09 10:23:31.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 2047 LR: 0.000999990635099517 Training loss: 0.0
2025-12-09 10:23:31.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 2048 LR: 0.0009999906254821915 Training loss: 0.0
2025-12-09 10:23:31.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 2049 LR: 0.0009999906158599304 Training loss: 0.0
2025-12-09 10:23:31.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 2050 LR: 0.0009999906062327336 Training loss: 0.0
2025-12-09 10:23:31.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 2051 LR: 0.000999990596600601 Training loss: 0.0
2025-12-09 10:23:31.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 2052 LR: 0.0009999905869635328 Training loss: 0.0
2025-12-09 10:23:31.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 2053 LR: 0.000999990577321529 Training loss: 0.0
2025-12-09 10:23:31.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 2054 LR: 0.0009999905676745895 Training loss: 0.0
2025-12-09 10:23:31.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 2055 LR: 0.0009999905580227143 Training loss: 0.0
2025-12-09 10:23:31.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 2056 LR: 0.0009999905483659033 Training loss: 0.0
2025-12-09 10:23:31.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 2057 LR: 0.0009999905387041567 Training loss: 0.0
2025-12-09 10:23:31.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 2058 LR: 0.0009999905290374743 Training loss: 0.0
2025-12-09 10:23:31.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 2059 LR: 0.0009999905193658562 Training loss: 0.0
2025-12-09 10:23:31.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 2060 LR: 0.0009999905096893023 Training loss: 0.0
2025-12-09 10:23:31.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 2061 LR: 0.0009999905000078128 Training loss: 0.0
2025-12-09 10:23:31.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 2062 LR: 0.000999990490321388 Training loss: 0.0
2025-12-09 10:23:31.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 2063 LR: 0.000999990480630027 Training loss: 0.0
2025-12-09 10:23:31.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 2064 LR: 0.0009999904709337305 Training loss: 0.0
2025-12-09 10:23:31.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 2065 LR: 0.0009999904612324982 Training loss: 0.0
2025-12-09 10:23:31.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 2066 LR: 0.0009999904515263303 Training loss: 0.0
2025-12-09 10:23:31.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 2067 LR: 0.0009999904418152266 Training loss: 0.0
2025-12-09 10:23:31.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 2068 LR: 0.0009999904320991875 Training loss: 0.0
2025-12-09 10:23:31.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 2069 LR: 0.0009999904223782123 Training loss: 0.0
2025-12-09 10:23:31.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 2070 LR: 0.0009999904126523015 Training loss: 0.0
2025-12-09 10:23:31.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 2071 LR: 0.0009999904029214552 Training loss: 0.0
2025-12-09 10:23:31.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 2072 LR: 0.0009999903931856731 Training loss: 0.0
2025-12-09 10:23:31.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 2073 LR: 0.0009999903834449553 Training loss: 0.0
2025-12-09 10:23:31.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 2074 LR: 0.0009999903736993018 Training loss: 0.0
2025-12-09 10:23:31.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 2075 LR: 0.0009999903639487126 Training loss: 0.0
2025-12-09 10:23:31.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 2076 LR: 0.0009999903541931879 Training loss: 0.0
2025-12-09 10:23:31.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 2077 LR: 0.0009999903444327274 Training loss: 0.0
2025-12-09 10:23:31.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 2078 LR: 0.000999990334667331 Training loss: 0.0
2025-12-09 10:23:31.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 2079 LR: 0.0009999903248969991 Training loss: 0.0
2025-12-09 10:23:31.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 2080 LR: 0.0009999903151217315 Training loss: 0.0
2025-12-09 10:23:31.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 2081 LR: 0.0009999903053415282 Training loss: 0.0
2025-12-09 10:23:31.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 2082 LR: 0.0009999902955563891 Training loss: 0.0
2025-12-09 10:23:31.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 2083 LR: 0.0009999902857663143 Training loss: 0.0
2025-12-09 10:23:31.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 2084 LR: 0.000999990275971304 Training loss: 0.0
2025-12-09 10:23:31.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 2085 LR: 0.0009999902661713578 Training loss: 0.0
2025-12-09 10:23:31.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 2086 LR: 0.000999990256366476 Training loss: 0.0
2025-12-09 10:23:31.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 2087 LR: 0.0009999902465566586 Training loss: 0.0
2025-12-09 10:23:31.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 2088 LR: 0.0009999902367419055 Training loss: 0.0
2025-12-09 10:23:31.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 2089 LR: 0.0009999902269222166 Training loss: 0.0
2025-12-09 10:23:31.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 2090 LR: 0.000999990217097592 Training loss: 0.0
2025-12-09 10:23:31.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 2091 LR: 0.0009999902072680316 Training loss: 0.0
2025-12-09 10:23:31.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 2092 LR: 0.0009999901974335357 Training loss: 0.0
2025-12-09 10:23:31.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 2093 LR: 0.000999990187594104 Training loss: 0.0
2025-12-09 10:23:31.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 2094 LR: 0.0009999901777497367 Training loss: 0.0
2025-12-09 10:23:31.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 2095 LR: 0.0009999901679004337 Training loss: 0.0
2025-12-09 10:23:31.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 2096 LR: 0.000999990158046195 Training loss: 0.0
2025-12-09 10:23:31.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 2097 LR: 0.0009999901481870205 Training loss: 0.0
2025-12-09 10:23:31.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 2098 LR: 0.0009999901383229105 Training loss: 0.0
2025-12-09 10:23:31.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 2099 LR: 0.0009999901284538646 Training loss: 0.0
2025-12-09 10:23:31.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 2100 LR: 0.0009999901185798832 Training loss: 0.0
2025-12-09 10:23:31.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 2101 LR: 0.000999990108700966 Training loss: 0.0
2025-12-09 10:23:31.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 2102 LR: 0.000999990098817113 Training loss: 0.0
2025-12-09 10:23:31.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 2103 LR: 0.0009999900889283244 Training loss: 0.0
2025-12-09 10:23:31.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 2104 LR: 0.0009999900790346001 Training loss: 0.0
2025-12-09 10:23:31.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 2105 LR: 0.0009999900691359403 Training loss: 0.0
2025-12-09 10:23:31.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 2106 LR: 0.0009999900592323446 Training loss: 0.0
2025-12-09 10:23:31.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 2107 LR: 0.0009999900493238131 Training loss: 0.0
2025-12-09 10:23:31.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 2108 LR: 0.0009999900394103462 Training loss: 0.0
2025-12-09 10:23:31.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 2109 LR: 0.0009999900294919435 Training loss: 0.0
2025-12-09 10:23:31.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 2110 LR: 0.000999990019568605 Training loss: 0.0
2025-12-09 10:23:31.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 2111 LR: 0.000999990009640331 Training loss: 0.0
2025-12-09 10:23:31.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 2112 LR: 0.000999989999707121 Training loss: 0.0
2025-12-09 10:23:31.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 2113 LR: 0.0009999899897689757 Training loss: 0.0
2025-12-09 10:23:31.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 2114 LR: 0.0009999899798258944 Training loss: 0.0
2025-12-09 10:23:31.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 2115 LR: 0.0009999899698778776 Training loss: 0.0
2025-12-09 10:23:31.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 2116 LR: 0.000999989959924925 Training loss: 0.0
2025-12-09 10:23:31.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 2117 LR: 0.0009999899499670368 Training loss: 0.0
2025-12-09 10:23:31.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 2118 LR: 0.0009999899400042129 Training loss: 0.0
2025-12-09 10:23:31.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 2119 LR: 0.0009999899300364532 Training loss: 0.0
2025-12-09 10:23:31.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 2120 LR: 0.000999989920063758 Training loss: 0.0
2025-12-09 10:23:31.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 2121 LR: 0.0009999899100861269 Training loss: 0.0
2025-12-09 10:23:31.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 2122 LR: 0.0009999899001035602 Training loss: 0.0
2025-12-09 10:23:31.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 2123 LR: 0.0009999898901160579 Training loss: 0.0
2025-12-09 10:23:31.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 2124 LR: 0.0009999898801236198 Training loss: 0.0
2025-12-09 10:23:31.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 2125 LR: 0.000999989870126246 Training loss: 0.0
2025-12-09 10:23:31.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 2126 LR: 0.0009999898601239367 Training loss: 0.0
2025-12-09 10:23:31.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 2127 LR: 0.0009999898501166914 Training loss: 0.0
2025-12-09 10:23:31.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 2128 LR: 0.0009999898401045107 Training loss: 0.0
2025-12-09 10:23:31.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 2129 LR: 0.0009999898300873942 Training loss: 0.0
2025-12-09 10:23:31.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 2130 LR: 0.000999989820065342 Training loss: 0.0
2025-12-09 10:23:31.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 2131 LR: 0.000999989810038354 Training loss: 0.0
2025-12-09 10:23:31.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 2132 LR: 0.0009999898000064304 Training loss: 0.0
2025-12-09 10:23:31.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 2133 LR: 0.000999989789969571 Training loss: 0.0
2025-12-09 10:23:31.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 2134 LR: 0.0009999897799277762 Training loss: 0.0
2025-12-09 10:23:31.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 2135 LR: 0.0009999897698810456 Training loss: 0.0
2025-12-09 10:23:31.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 2136 LR: 0.0009999897598293793 Training loss: 0.0
2025-12-09 10:23:31.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 2137 LR: 0.000999989749772777 Training loss: 0.0
2025-12-09 10:23:31.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 2138 LR: 0.0009999897397112395 Training loss: 0.0
2025-12-09 10:23:31.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 2139 LR: 0.000999989729644766 Training loss: 0.0
2025-12-09 10:23:31.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 2140 LR: 0.000999989719573357 Training loss: 0.0
2025-12-09 10:23:31.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 2141 LR: 0.000999989709497012 Training loss: 0.0
2025-12-09 10:23:31.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 2142 LR: 0.0009999896994157317 Training loss: 0.0
2025-12-09 10:23:31.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 2143 LR: 0.0009999896893295155 Training loss: 0.0
2025-12-09 10:23:31.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 2144 LR: 0.0009999896792383636 Training loss: 0.0
2025-12-09 10:23:31.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 2145 LR: 0.000999989669142276 Training loss: 0.0
2025-12-09 10:23:31.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 2146 LR: 0.000999989659041253 Training loss: 0.0
2025-12-09 10:23:31.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 2147 LR: 0.000999989648935294 Training loss: 0.0
2025-12-09 10:23:31.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 2148 LR: 0.0009999896388243994 Training loss: 0.0
2025-12-09 10:23:31.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 2149 LR: 0.000999989628708569 Training loss: 0.0
2025-12-09 10:23:31.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 2150 LR: 0.0009999896185878033 Training loss: 0.0
2025-12-09 10:23:31.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 2151 LR: 0.0009999896084621016 Training loss: 0.0
2025-12-09 10:23:31.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 2152 LR: 0.0009999895983314642 Training loss: 0.0
2025-12-09 10:23:31.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 2153 LR: 0.000999989588195891 Training loss: 0.0
2025-12-09 10:23:31.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 2154 LR: 0.0009999895780553824 Training loss: 0.0
2025-12-09 10:23:31.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 2155 LR: 0.000999989567909938 Training loss: 0.0
2025-12-09 10:23:31.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 2156 LR: 0.000999989557759558 Training loss: 0.0
2025-12-09 10:23:31.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 2157 LR: 0.0009999895476042423 Training loss: 0.0
2025-12-09 10:23:31.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 2158 LR: 0.0009999895374439907 Training loss: 0.0
2025-12-09 10:23:31.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 2159 LR: 0.0009999895272788035 Training loss: 0.0
2025-12-09 10:23:31.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 2160 LR: 0.0009999895171086807 Training loss: 0.0
2025-12-09 10:23:31.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 2161 LR: 0.0009999895069336222 Training loss: 0.0
2025-12-09 10:23:31.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 2162 LR: 0.000999989496753628 Training loss: 0.0
2025-12-09 10:23:31.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 2163 LR: 0.000999989486568698 Training loss: 0.0
2025-12-09 10:23:31.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 2164 LR: 0.0009999894763788326 Training loss: 0.0
2025-12-09 10:23:31.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 2165 LR: 0.0009999894661840312 Training loss: 0.0
2025-12-09 10:23:31.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 2166 LR: 0.0009999894559842943 Training loss: 0.0
2025-12-09 10:23:31.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 2167 LR: 0.0009999894457796217 Training loss: 0.0
2025-12-09 10:23:31.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 2168 LR: 0.0009999894355700134 Training loss: 0.0
2025-12-09 10:23:31.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 2169 LR: 0.0009999894253554693 Training loss: 0.0
2025-12-09 10:23:31.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 2170 LR: 0.0009999894151359898 Training loss: 0.0
2025-12-09 10:23:31.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 2171 LR: 0.0009999894049115743 Training loss: 0.0
2025-12-09 10:23:31.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 2172 LR: 0.0009999893946822235 Training loss: 0.0
2025-12-09 10:23:31.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 2173 LR: 0.0009999893844479365 Training loss: 0.0
2025-12-09 10:23:31.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 2174 LR: 0.000999989374208714 Training loss: 0.0
2025-12-09 10:23:31.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 2175 LR: 0.0009999893639645561 Training loss: 0.0
2025-12-09 10:23:31.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 2176 LR: 0.0009999893537154623 Training loss: 0.0
2025-12-09 10:23:31.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 2177 LR: 0.0009999893434614329 Training loss: 0.0
2025-12-09 10:23:31.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 2178 LR: 0.0009999893332024677 Training loss: 0.0
2025-12-09 10:23:31.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 2179 LR: 0.000999989322938567 Training loss: 0.0
2025-12-09 10:23:31.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 2180 LR: 0.0009999893126697303 Training loss: 0.0
2025-12-09 10:23:31.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 2181 LR: 0.000999989302395958 Training loss: 0.0
2025-12-09 10:23:31.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 2182 LR: 0.0009999892921172503 Training loss: 0.0
2025-12-09 10:23:31.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 2183 LR: 0.0009999892818336065 Training loss: 0.0
2025-12-09 10:23:31.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 2184 LR: 0.0009999892715450273 Training loss: 0.0
2025-12-09 10:23:31.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 2185 LR: 0.0009999892612515123 Training loss: 0.0
2025-12-09 10:23:31.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 2186 LR: 0.0009999892509530617 Training loss: 0.0
2025-12-09 10:23:31.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 2187 LR: 0.0009999892406496755 Training loss: 0.0
2025-12-09 10:23:31.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 2188 LR: 0.0009999892303413534 Training loss: 0.0
2025-12-09 10:23:31.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 2189 LR: 0.0009999892200280957 Training loss: 0.0
2025-12-09 10:23:31.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 2190 LR: 0.0009999892097099024 Training loss: 0.0
2025-12-09 10:23:31.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 2191 LR: 0.0009999891993867733 Training loss: 0.0
2025-12-09 10:23:31.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 2192 LR: 0.0009999891890587085 Training loss: 0.0
2025-12-09 10:23:31.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 2193 LR: 0.0009999891787257082 Training loss: 0.0
2025-12-09 10:23:31.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 2194 LR: 0.000999989168387772 Training loss: 0.0
2025-12-09 10:23:31.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 2195 LR: 0.0009999891580449003 Training loss: 0.0
2025-12-09 10:23:31.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 2196 LR: 0.0009999891476970928 Training loss: 0.0
2025-12-09 10:23:31.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 2197 LR: 0.0009999891373443496 Training loss: 0.0
2025-12-09 10:23:31.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 2198 LR: 0.000999989126986671 Training loss: 0.0
2025-12-09 10:23:31.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 2199 LR: 0.0009999891166240565 Training loss: 0.0
2025-12-09 10:23:31.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 2200 LR: 0.0009999891062565064 Training loss: 0.0
2025-12-09 10:23:31.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 2201 LR: 0.0009999890958840203 Training loss: 0.0
2025-12-09 10:23:31.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 2202 LR: 0.000999989085506599 Training loss: 0.0
2025-12-09 10:23:31.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 2203 LR: 0.0009999890751242416 Training loss: 0.0
2025-12-09 10:23:31.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 2204 LR: 0.0009999890647369488 Training loss: 0.0
2025-12-09 10:23:31.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 2205 LR: 0.00099998905434472 Training loss: 0.0
2025-12-09 10:23:31.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 2206 LR: 0.0009999890439475558 Training loss: 0.0
2025-12-09 10:23:31.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 2207 LR: 0.0009999890335454559 Training loss: 0.0
2025-12-09 10:23:31.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 2208 LR: 0.0009999890231384202 Training loss: 0.0
2025-12-09 10:23:31.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 2209 LR: 0.000999989012726449 Training loss: 0.0
2025-12-09 10:23:31.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 2210 LR: 0.0009999890023095418 Training loss: 0.0
2025-12-09 10:23:31.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 2211 LR: 0.0009999889918876992 Training loss: 0.0
2025-12-09 10:23:31.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 2212 LR: 0.0009999889814609208 Training loss: 0.0
2025-12-09 10:23:31.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 2213 LR: 0.0009999889710292067 Training loss: 0.0
2025-12-09 10:23:31.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 2214 LR: 0.0009999889605925572 Training loss: 0.0
2025-12-09 10:23:31.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 2215 LR: 0.0009999889501509716 Training loss: 0.0
2025-12-09 10:23:31.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 2216 LR: 0.0009999889397044506 Training loss: 0.0
2025-12-09 10:23:31.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 2217 LR: 0.0009999889292529938 Training loss: 0.0
2025-12-09 10:23:31.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 2218 LR: 0.0009999889187966014 Training loss: 0.0
2025-12-09 10:23:31.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 2219 LR: 0.0009999889083352734 Training loss: 0.0
2025-12-09 10:23:31.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 2220 LR: 0.0009999888978690094 Training loss: 0.0
2025-12-09 10:23:31.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 2221 LR: 0.00099998888739781 Training loss: 0.0
2025-12-09 10:23:31.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 2222 LR: 0.0009999888769216749 Training loss: 0.0
2025-12-09 10:23:31.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 2223 LR: 0.000999988866440604 Training loss: 0.0
2025-12-09 10:23:31.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 2224 LR: 0.0009999888559545976 Training loss: 0.0
2025-12-09 10:23:31.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 2225 LR: 0.0009999888454636553 Training loss: 0.0
2025-12-09 10:23:31.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 2226 LR: 0.0009999888349677775 Training loss: 0.0
2025-12-09 10:23:31.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 2227 LR: 0.000999988824466964 Training loss: 0.0
2025-12-09 10:23:31.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 2228 LR: 0.0009999888139612147 Training loss: 0.0
2025-12-09 10:23:31.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 2229 LR: 0.0009999888034505297 Training loss: 0.0
2025-12-09 10:23:31.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 2230 LR: 0.0009999887929349092 Training loss: 0.0
2025-12-09 10:23:31.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 2231 LR: 0.000999988782414353 Training loss: 0.0
2025-12-09 10:23:31.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 2232 LR: 0.000999988771888861 Training loss: 0.0
2025-12-09 10:23:31.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 2233 LR: 0.0009999887613584334 Training loss: 0.0
2025-12-09 10:23:31.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 2234 LR: 0.00099998875082307 Training loss: 0.0
2025-12-09 10:23:31.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 2235 LR: 0.000999988740282771 Training loss: 0.0
2025-12-09 10:23:31.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 2236 LR: 0.0009999887297375363 Training loss: 0.0
2025-12-09 10:23:31.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 2237 LR: 0.000999988719187366 Training loss: 0.0
2025-12-09 10:23:31.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 2238 LR: 0.00099998870863226 Training loss: 0.0
2025-12-09 10:23:31.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 2239 LR: 0.0009999886980722184 Training loss: 0.0
2025-12-09 10:23:31.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 2240 LR: 0.0009999886875072409 Training loss: 0.0
2025-12-09 10:23:31.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 2241 LR: 0.0009999886769373279 Training loss: 0.0
2025-12-09 10:23:31.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 2242 LR: 0.0009999886663624791 Training loss: 0.0
2025-12-09 10:23:31.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 2243 LR: 0.0009999886557826947 Training loss: 0.0
2025-12-09 10:23:31.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 2244 LR: 0.0009999886451979745 Training loss: 0.0
2025-12-09 10:23:31.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 2245 LR: 0.0009999886346083189 Training loss: 0.0
2025-12-09 10:23:31.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 2246 LR: 0.0009999886240137275 Training loss: 0.0
2025-12-09 10:23:31.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 2247 LR: 0.0009999886134142003 Training loss: 0.0
2025-12-09 10:23:31.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 2248 LR: 0.0009999886028097375 Training loss: 0.0
2025-12-09 10:23:31.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 2249 LR: 0.0009999885922003392 Training loss: 0.0
2025-12-09 10:23:31.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 2250 LR: 0.0009999885815860049 Training loss: 0.0
2025-12-09 10:23:31.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 2251 LR: 0.000999988570966735 Training loss: 0.0
2025-12-09 10:23:31.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 2252 LR: 0.0009999885603425296 Training loss: 0.0
2025-12-09 10:23:31.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 2253 LR: 0.0009999885497133884 Training loss: 0.0
2025-12-09 10:23:31.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 2254 LR: 0.0009999885390793116 Training loss: 0.0
2025-12-09 10:23:31.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 2255 LR: 0.000999988528440299 Training loss: 0.0
2025-12-09 10:23:31.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 2256 LR: 0.0009999885177963508 Training loss: 0.0
2025-12-09 10:23:31.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 2257 LR: 0.0009999885071474669 Training loss: 0.0
2025-12-09 10:23:31.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 2258 LR: 0.0009999884964936475 Training loss: 0.0
2025-12-09 10:23:31.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 2259 LR: 0.0009999884858348921 Training loss: 0.0
2025-12-09 10:23:31.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 2260 LR: 0.0009999884751712013 Training loss: 0.0
2025-12-09 10:23:31.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 2261 LR: 0.0009999884645025747 Training loss: 0.0
2025-12-09 10:23:31.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 2262 LR: 0.0009999884538290124 Training loss: 0.0
2025-12-09 10:23:31.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 2263 LR: 0.0009999884431505144 Training loss: 0.0
2025-12-09 10:23:31.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 2264 LR: 0.0009999884324670809 Training loss: 0.0
2025-12-09 10:23:31.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 2265 LR: 0.0009999884217787116 Training loss: 0.0
2025-12-09 10:23:31.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 2266 LR: 0.0009999884110854066 Training loss: 0.0
2025-12-09 10:23:31.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 2267 LR: 0.000999988400387166 Training loss: 0.0
2025-12-09 10:23:31.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 2268 LR: 0.0009999883896839896 Training loss: 0.0
2025-12-09 10:23:31.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 2269 LR: 0.0009999883789758776 Training loss: 0.0
2025-12-09 10:23:31.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 2270 LR: 0.00099998836826283 Training loss: 0.0
2025-12-09 10:23:31.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 2271 LR: 0.0009999883575448466 Training loss: 0.0
2025-12-09 10:23:31.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 2272 LR: 0.0009999883468219278 Training loss: 0.0
2025-12-09 10:23:31.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 2273 LR: 0.000999988336094073 Training loss: 0.0
2025-12-09 10:23:31.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 2274 LR: 0.0009999883253612827 Training loss: 0.0
2025-12-09 10:23:31.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 2275 LR: 0.0009999883146235566 Training loss: 0.0
2025-12-09 10:23:31.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 2276 LR: 0.0009999883038808949 Training loss: 0.0
2025-12-09 10:23:31.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 2277 LR: 0.0009999882931332976 Training loss: 0.0
2025-12-09 10:23:31.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 2278 LR: 0.0009999882823807644 Training loss: 0.0
2025-12-09 10:23:31.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 2279 LR: 0.0009999882716232957 Training loss: 0.0
2025-12-09 10:23:31.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 2280 LR: 0.0009999882608608913 Training loss: 0.0
2025-12-09 10:23:31.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 2281 LR: 0.0009999882500935514 Training loss: 0.0
2025-12-09 10:23:31.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 2282 LR: 0.0009999882393212755 Training loss: 0.0
2025-12-09 10:23:31.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 2283 LR: 0.0009999882285440641 Training loss: 0.0
2025-12-09 10:23:31.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 2284 LR: 0.000999988217761917 Training loss: 0.0
2025-12-09 10:23:31.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 2285 LR: 0.0009999882069748342 Training loss: 0.0
2025-12-09 10:23:31.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 2286 LR: 0.000999988196182816 Training loss: 0.0
2025-12-09 10:23:31.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 2287 LR: 0.0009999881853858617 Training loss: 0.0
2025-12-09 10:23:31.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 2288 LR: 0.000999988174583972 Training loss: 0.0
2025-12-09 10:23:31.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 2289 LR: 0.0009999881637771464 Training loss: 0.0
2025-12-09 10:23:31.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 2290 LR: 0.0009999881529653854 Training loss: 0.0
2025-12-09 10:23:31.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 2291 LR: 0.0009999881421486885 Training loss: 0.0
2025-12-09 10:23:31.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 2292 LR: 0.000999988131327056 Training loss: 0.0
2025-12-09 10:23:31.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 2293 LR: 0.000999988120500488 Training loss: 0.0
2025-12-09 10:23:31.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 2294 LR: 0.0009999881096689842 Training loss: 0.0
2025-12-09 10:23:31.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 2295 LR: 0.0009999880988325446 Training loss: 0.0
2025-12-09 10:23:31.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 2296 LR: 0.0009999880879911695 Training loss: 0.0
2025-12-09 10:23:31.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 2297 LR: 0.0009999880771448587 Training loss: 0.0
2025-12-09 10:23:31.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 2298 LR: 0.0009999880662936121 Training loss: 0.0
2025-12-09 10:23:31.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 2299 LR: 0.0009999880554374299 Training loss: 0.0
2025-12-09 10:23:31.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 2300 LR: 0.000999988044576312 Training loss: 0.0
2025-12-09 10:23:31.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 2301 LR: 0.0009999880337102586 Training loss: 0.0
2025-12-09 10:23:31.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 2302 LR: 0.0009999880228392694 Training loss: 0.0
2025-12-09 10:23:31.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 2303 LR: 0.0009999880119633446 Training loss: 0.0
2025-12-09 10:23:31.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 2304 LR: 0.000999988001082484 Training loss: 0.0
2025-12-09 10:23:31.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 2305 LR: 0.0009999879901966878 Training loss: 0.0
2025-12-09 10:23:31.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 2306 LR: 0.000999987979305956 Training loss: 0.0
2025-12-09 10:23:31.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 2307 LR: 0.0009999879684102883 Training loss: 0.0
2025-12-09 10:23:31.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 2308 LR: 0.0009999879575096852 Training loss: 0.0
2025-12-09 10:23:31.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 2309 LR: 0.0009999879466041463 Training loss: 0.0
2025-12-09 10:23:31.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 2310 LR: 0.0009999879356936718 Training loss: 0.0
2025-12-09 10:23:31.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 2311 LR: 0.0009999879247782615 Training loss: 0.0
2025-12-09 10:23:31.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 2312 LR: 0.0009999879138579155 Training loss: 0.0
2025-12-09 10:23:31.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 2313 LR: 0.000999987902932634 Training loss: 0.0
2025-12-09 10:23:31.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 2314 LR: 0.0009999878920024167 Training loss: 0.0
2025-12-09 10:23:31.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 2315 LR: 0.000999987881067264 Training loss: 0.0
2025-12-09 10:23:31.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 2316 LR: 0.0009999878701271753 Training loss: 0.0
2025-12-09 10:23:31.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 2317 LR: 0.0009999878591821511 Training loss: 0.0
2025-12-09 10:23:31.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 2318 LR: 0.0009999878482321912 Training loss: 0.0
2025-12-09 10:23:31.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 2319 LR: 0.0009999878372772956 Training loss: 0.0
2025-12-09 10:23:31.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 2320 LR: 0.0009999878263174642 Training loss: 0.0
2025-12-09 10:23:31.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 2321 LR: 0.0009999878153526974 Training loss: 0.0
2025-12-09 10:23:31.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 2322 LR: 0.0009999878043829948 Training loss: 0.0
2025-12-09 10:23:31.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 2323 LR: 0.0009999877934083565 Training loss: 0.0
2025-12-09 10:23:31.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 2324 LR: 0.0009999877824287827 Training loss: 0.0
2025-12-09 10:23:31.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 2325 LR: 0.0009999877714442732 Training loss: 0.0
2025-12-09 10:23:31.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 2326 LR: 0.0009999877604548277 Training loss: 0.0
2025-12-09 10:23:31.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 2327 LR: 0.0009999877494604468 Training loss: 0.0
2025-12-09 10:23:31.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 2328 LR: 0.0009999877384611303 Training loss: 0.0
2025-12-09 10:23:31.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 2329 LR: 0.000999987727456878 Training loss: 0.0
2025-12-09 10:23:31.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 2330 LR: 0.00099998771644769 Training loss: 0.0
2025-12-09 10:23:31.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 2331 LR: 0.0009999877054335665 Training loss: 0.0
2025-12-09 10:23:31.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 2332 LR: 0.0009999876944145072 Training loss: 0.0
2025-12-09 10:23:31.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 2333 LR: 0.000999987683390512 Training loss: 0.0
2025-12-09 10:23:31.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 2334 LR: 0.0009999876723615817 Training loss: 0.0
2025-12-09 10:23:31.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 2335 LR: 0.0009999876613277152 Training loss: 0.0
2025-12-09 10:23:31.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 2336 LR: 0.0009999876502889134 Training loss: 0.0
2025-12-09 10:23:31.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 2337 LR: 0.0009999876392451758 Training loss: 0.0
2025-12-09 10:23:31.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 2338 LR: 0.0009999876281965026 Training loss: 0.0
2025-12-09 10:23:31.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 2339 LR: 0.0009999876171428936 Training loss: 0.0
2025-12-09 10:23:31.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 2340 LR: 0.0009999876060843489 Training loss: 0.0
2025-12-09 10:23:31.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 2341 LR: 0.0009999875950208687 Training loss: 0.0
2025-12-09 10:23:31.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 2342 LR: 0.0009999875839524527 Training loss: 0.0
2025-12-09 10:23:31.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 2343 LR: 0.000999987572879101 Training loss: 0.0
2025-12-09 10:23:31.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 2344 LR: 0.000999987561800814 Training loss: 0.0
2025-12-09 10:23:31.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 2345 LR: 0.0009999875507175908 Training loss: 0.0
2025-12-09 10:23:31.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 2346 LR: 0.0009999875396294322 Training loss: 0.0
2025-12-09 10:23:31.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 2347 LR: 0.000999987528536338 Training loss: 0.0
2025-12-09 10:23:31.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 2348 LR: 0.000999987517438308 Training loss: 0.0
2025-12-09 10:23:31.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 2349 LR: 0.0009999875063353425 Training loss: 0.0
2025-12-09 10:23:31.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 2350 LR: 0.000999987495227441 Training loss: 0.0
2025-12-09 10:23:31.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 2351 LR: 0.0009999874841146042 Training loss: 0.0
2025-12-09 10:23:31.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 2352 LR: 0.0009999874729968315 Training loss: 0.0
2025-12-09 10:23:31.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 2353 LR: 0.0009999874618741233 Training loss: 0.0
2025-12-09 10:23:31.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 2354 LR: 0.0009999874507464793 Training loss: 0.0
2025-12-09 10:23:31.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 2355 LR: 0.0009999874396138997 Training loss: 0.0
2025-12-09 10:23:31.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 2356 LR: 0.0009999874284763845 Training loss: 0.0
2025-12-09 10:23:31.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 2357 LR: 0.0009999874173339334 Training loss: 0.0
2025-12-09 10:23:31.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 2358 LR: 0.000999987406186547 Training loss: 0.0
2025-12-09 10:23:31.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 2359 LR: 0.0009999873950342247 Training loss: 0.0
2025-12-09 10:23:31.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 2360 LR: 0.0009999873838769666 Training loss: 0.0
2025-12-09 10:23:31.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 2361 LR: 0.000999987372714773 Training loss: 0.0
2025-12-09 10:23:31.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 2362 LR: 0.0009999873615476437 Training loss: 0.0
2025-12-09 10:23:31.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 2363 LR: 0.000999987350375579 Training loss: 0.0
2025-12-09 10:23:31.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 2364 LR: 0.0009999873391985782 Training loss: 0.0
2025-12-09 10:23:31.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 2365 LR: 0.000999987328016642 Training loss: 0.0
2025-12-09 10:23:31.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 2366 LR: 0.0009999873168297702 Training loss: 0.0
2025-12-09 10:23:31.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 2367 LR: 0.0009999873056379626 Training loss: 0.0
2025-12-09 10:23:31.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 2368 LR: 0.0009999872944412194 Training loss: 0.0
2025-12-09 10:23:31.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 2369 LR: 0.0009999872832395405 Training loss: 0.0
2025-12-09 10:23:31.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 2370 LR: 0.0009999872720329258 Training loss: 0.0
2025-12-09 10:23:31.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 2371 LR: 0.0009999872608213755 Training loss: 0.0
2025-12-09 10:23:31.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 2372 LR: 0.0009999872496048896 Training loss: 0.0
2025-12-09 10:23:31.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 2373 LR: 0.000999987238383468 Training loss: 0.0
2025-12-09 10:23:31.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 2374 LR: 0.000999987227157111 Training loss: 0.0
2025-12-09 10:23:31.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 2375 LR: 0.0009999872159258182 Training loss: 0.0
2025-12-09 10:23:31.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 2376 LR: 0.0009999872046895894 Training loss: 0.0
2025-12-09 10:23:31.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 2377 LR: 0.0009999871934484252 Training loss: 0.0
2025-12-09 10:23:31.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 2378 LR: 0.0009999871822023254 Training loss: 0.0
2025-12-09 10:23:31.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 2379 LR: 0.0009999871709512897 Training loss: 0.0
2025-12-09 10:23:31.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 2380 LR: 0.0009999871596953185 Training loss: 0.0
2025-12-09 10:23:31.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 2381 LR: 0.0009999871484344118 Training loss: 0.0
2025-12-09 10:23:31.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 2382 LR: 0.0009999871371685692 Training loss: 0.0
2025-12-09 10:23:31.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 2383 LR: 0.000999987125897791 Training loss: 0.0
2025-12-09 10:23:31.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 2384 LR: 0.0009999871146220772 Training loss: 0.0
2025-12-09 10:23:31.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 2385 LR: 0.0009999871033414276 Training loss: 0.0
2025-12-09 10:23:31.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 2386 LR: 0.0009999870920558425 Training loss: 0.0
2025-12-09 10:23:31.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 2387 LR: 0.0009999870807653217 Training loss: 0.0
2025-12-09 10:23:31.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 2388 LR: 0.0009999870694698651 Training loss: 0.0
2025-12-09 10:23:31.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 2389 LR: 0.000999987058169473 Training loss: 0.0
2025-12-09 10:23:31.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 2390 LR: 0.000999987046864145 Training loss: 0.0
2025-12-09 10:23:31.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 2391 LR: 0.0009999870355538816 Training loss: 0.0
2025-12-09 10:23:31.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 2392 LR: 0.0009999870242386824 Training loss: 0.0
2025-12-09 10:23:31.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 2393 LR: 0.0009999870129185477 Training loss: 0.0
2025-12-09 10:23:31.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 2394 LR: 0.000999987001593477 Training loss: 0.0
2025-12-09 10:23:31.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 2395 LR: 0.000999986990263471 Training loss: 0.0
2025-12-09 10:23:31.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 2396 LR: 0.0009999869789285292 Training loss: 0.0
2025-12-09 10:23:31.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 2397 LR: 0.0009999869675886518 Training loss: 0.0
2025-12-09 10:23:31.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 2398 LR: 0.0009999869562438387 Training loss: 0.0
2025-12-09 10:23:31.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 2399 LR: 0.0009999869448940899 Training loss: 0.0
2025-12-09 10:23:31.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 2400 LR: 0.0009999869335394053 Training loss: 0.0
2025-12-09 10:23:31.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 2401 LR: 0.0009999869221797855 Training loss: 0.0
2025-12-09 10:23:31.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 2402 LR: 0.0009999869108152297 Training loss: 0.0
2025-12-09 10:23:31.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 2403 LR: 0.0009999868994457382 Training loss: 0.0
2025-12-09 10:23:31.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 2404 LR: 0.0009999868880713112 Training loss: 0.0
2025-12-09 10:23:31.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 2405 LR: 0.0009999868766919484 Training loss: 0.0
2025-12-09 10:23:31.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 2406 LR: 0.00099998686530765 Training loss: 0.0
2025-12-09 10:23:31.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 2407 LR: 0.000999986853918416 Training loss: 0.0
2025-12-09 10:23:31.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 2408 LR: 0.0009999868425242461 Training loss: 0.0
2025-12-09 10:23:31.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 2409 LR: 0.0009999868311251407 Training loss: 0.0
2025-12-09 10:23:31.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 2410 LR: 0.0009999868197210998 Training loss: 0.0
2025-12-09 10:23:31.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 2411 LR: 0.000999986808312123 Training loss: 0.0
2025-12-09 10:23:31.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 2412 LR: 0.0009999867968982108 Training loss: 0.0
2025-12-09 10:23:31.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 2413 LR: 0.0009999867854793628 Training loss: 0.0
2025-12-09 10:23:31.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 2414 LR: 0.000999986774055579 Training loss: 0.0
2025-12-09 10:23:31.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 2415 LR: 0.0009999867626268597 Training loss: 0.0
2025-12-09 10:23:31.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 2416 LR: 0.0009999867511932049 Training loss: 0.0
2025-12-09 10:23:31.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 2417 LR: 0.0009999867397546141 Training loss: 0.0
2025-12-09 10:23:31.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 2418 LR: 0.0009999867283110877 Training loss: 0.0
2025-12-09 10:23:31.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 2419 LR: 0.0009999867168626257 Training loss: 0.0
2025-12-09 10:23:31.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 2420 LR: 0.0009999867054092282 Training loss: 0.0
2025-12-09 10:23:31.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 2421 LR: 0.000999986693950895 Training loss: 0.0
2025-12-09 10:23:31.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 2422 LR: 0.0009999866824876261 Training loss: 0.0
2025-12-09 10:23:31.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 2423 LR: 0.0009999866710194215 Training loss: 0.0
2025-12-09 10:23:31.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 2424 LR: 0.000999986659546281 Training loss: 0.0
2025-12-09 10:23:31.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 2425 LR: 0.0009999866480682052 Training loss: 0.0
2025-12-09 10:23:31.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 2426 LR: 0.0009999866365851936 Training loss: 0.0
2025-12-09 10:23:31.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 2427 LR: 0.0009999866250972466 Training loss: 0.0
2025-12-09 10:23:31.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 2428 LR: 0.0009999866136043635 Training loss: 0.0
2025-12-09 10:23:31.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 2429 LR: 0.000999986602106545 Training loss: 0.0
2025-12-09 10:23:31.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 2430 LR: 0.0009999865906037907 Training loss: 0.0
2025-12-09 10:23:31.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 2431 LR: 0.000999986579096101 Training loss: 0.0
2025-12-09 10:23:31.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 2432 LR: 0.0009999865675834755 Training loss: 0.0
2025-12-09 10:23:31.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 2433 LR: 0.0009999865560659143 Training loss: 0.0
2025-12-09 10:23:31.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 2434 LR: 0.0009999865445434175 Training loss: 0.0
2025-12-09 10:23:31.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 2435 LR: 0.0009999865330159849 Training loss: 0.0
2025-12-09 10:23:31.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 2436 LR: 0.0009999865214836167 Training loss: 0.0
2025-12-09 10:23:31.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 2437 LR: 0.000999986509946313 Training loss: 0.0
2025-12-09 10:23:31.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 2438 LR: 0.0009999864984040737 Training loss: 0.0
2025-12-09 10:23:31.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 2439 LR: 0.0009999864868568983 Training loss: 0.0
2025-12-09 10:23:31.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 2440 LR: 0.0009999864753047877 Training loss: 0.0
2025-12-09 10:23:31.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 2441 LR: 0.0009999864637477414 Training loss: 0.0
2025-12-09 10:23:31.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 2442 LR: 0.0009999864521857593 Training loss: 0.0
2025-12-09 10:23:31.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 2443 LR: 0.0009999864406188416 Training loss: 0.0
2025-12-09 10:23:32.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 2444 LR: 0.000999986429046988 Training loss: 0.0
2025-12-09 10:23:32.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 2445 LR: 0.000999986417470199 Training loss: 0.0
2025-12-09 10:23:32.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 2446 LR: 0.0009999864058884745 Training loss: 0.0
2025-12-09 10:23:32.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 2447 LR: 0.000999986394301814 Training loss: 0.0
2025-12-09 10:23:32.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 2448 LR: 0.000999986382710218 Training loss: 0.0
2025-12-09 10:23:32.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 2449 LR: 0.0009999863711136865 Training loss: 0.0
2025-12-09 10:23:32.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 2450 LR: 0.000999986359512219 Training loss: 0.0
2025-12-09 10:23:32.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 2451 LR: 0.0009999863479058162 Training loss: 0.0
2025-12-09 10:23:32.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 2452 LR: 0.0009999863362944775 Training loss: 0.0
2025-12-09 10:23:32.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 2453 LR: 0.0009999863246782032 Training loss: 0.0
2025-12-09 10:23:32.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 2454 LR: 0.0009999863130569933 Training loss: 0.0
2025-12-09 10:23:32.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 2455 LR: 0.0009999863014308477 Training loss: 0.0
2025-12-09 10:23:32.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 2456 LR: 0.0009999862897997664 Training loss: 0.0
2025-12-09 10:23:32.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 2457 LR: 0.0009999862781637496 Training loss: 0.0
2025-12-09 10:23:32.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 2458 LR: 0.000999986266522797 Training loss: 0.0
2025-12-09 10:23:32.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 2459 LR: 0.0009999862548769087 Training loss: 0.0
2025-12-09 10:23:32.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 2460 LR: 0.000999986243226085 Training loss: 0.0
2025-12-09 10:23:32.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 2461 LR: 0.0009999862315703254 Training loss: 0.0
2025-12-09 10:23:32.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 2462 LR: 0.0009999862199096302 Training loss: 0.0
2025-12-09 10:23:32.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 2463 LR: 0.0009999862082439995 Training loss: 0.0
2025-12-09 10:23:32.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 2464 LR: 0.000999986196573433 Training loss: 0.0
2025-12-09 10:23:32.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 2465 LR: 0.0009999861848979308 Training loss: 0.0
2025-12-09 10:23:32.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 2466 LR: 0.000999986173217493 Training loss: 0.0
2025-12-09 10:23:32.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 2467 LR: 0.0009999861615321197 Training loss: 0.0
2025-12-09 10:23:32.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 2468 LR: 0.0009999861498418106 Training loss: 0.0
2025-12-09 10:23:32.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 2469 LR: 0.0009999861381465658 Training loss: 0.0
2025-12-09 10:23:32.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 2470 LR: 0.0009999861264463855 Training loss: 0.0
2025-12-09 10:23:32.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 2471 LR: 0.0009999861147412695 Training loss: 0.0
2025-12-09 10:23:32.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 2472 LR: 0.0009999861030312177 Training loss: 0.0
2025-12-09 10:23:32.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 2473 LR: 0.0009999860913162304 Training loss: 0.0
2025-12-09 10:23:32.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 2474 LR: 0.0009999860795963074 Training loss: 0.0
2025-12-09 10:23:32.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 2475 LR: 0.0009999860678714487 Training loss: 0.0
2025-12-09 10:23:32.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 2476 LR: 0.0009999860561416545 Training loss: 0.0
2025-12-09 10:23:32.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 2477 LR: 0.0009999860444069243 Training loss: 0.0
2025-12-09 10:23:32.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 2478 LR: 0.0009999860326672589 Training loss: 0.0
2025-12-09 10:23:32.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 2479 LR: 0.0009999860209226577 Training loss: 0.0
2025-12-09 10:23:32.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 2480 LR: 0.0009999860091731208 Training loss: 0.0
2025-12-09 10:23:32.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 2481 LR: 0.0009999859974186482 Training loss: 0.0
2025-12-09 10:23:32.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 2482 LR: 0.0009999859856592399 Training loss: 0.0
2025-12-09 10:23:32.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 2483 LR: 0.000999985973894896 Training loss: 0.0
2025-12-09 10:23:32.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 2484 LR: 0.0009999859621256167 Training loss: 0.0
2025-12-09 10:23:32.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 2485 LR: 0.0009999859503514014 Training loss: 0.0
2025-12-09 10:23:32.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 2486 LR: 0.0009999859385722506 Training loss: 0.0
2025-12-09 10:23:32.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 2487 LR: 0.0009999859267881641 Training loss: 0.0
2025-12-09 10:23:32.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 2488 LR: 0.000999985914999142 Training loss: 0.0
2025-12-09 10:23:32.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 2489 LR: 0.0009999859032051844 Training loss: 0.0
2025-12-09 10:23:32.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 2490 LR: 0.000999985891406291 Training loss: 0.0
2025-12-09 10:23:32.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 2491 LR: 0.0009999858796024617 Training loss: 0.0
2025-12-09 10:23:32.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 2492 LR: 0.000999985867793697 Training loss: 0.0
2025-12-09 10:23:32.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 2493 LR: 0.0009999858559799968 Training loss: 0.0
2025-12-09 10:23:32.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 2494 LR: 0.0009999858441613607 Training loss: 0.0
2025-12-09 10:23:32.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 2495 LR: 0.000999985832337789 Training loss: 0.0
2025-12-09 10:23:32.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 2496 LR: 0.0009999858205092817 Training loss: 0.0
2025-12-09 10:23:32.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 2497 LR: 0.0009999858086758389 Training loss: 0.0
2025-12-09 10:23:32.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 2498 LR: 0.00099998579683746 Training loss: 0.0
2025-12-09 10:23:32.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 2499 LR: 0.000999985784994146 Training loss: 0.0
2025-12-09 10:23:32.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 2500 LR: 0.000999985773145896 Training loss: 0.0
2025-12-09 10:23:32.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 2501 LR: 0.0009999857612927104 Training loss: 0.0
2025-12-09 10:23:32.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 2502 LR: 0.0009999857494345891 Training loss: 0.0
2025-12-09 10:23:32.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 2503 LR: 0.0009999857375715324 Training loss: 0.0
2025-12-09 10:23:32.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 2504 LR: 0.00099998572570354 Training loss: 0.0
2025-12-09 10:23:32.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 2505 LR: 0.0009999857138306117 Training loss: 0.0
2025-12-09 10:23:32.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 2506 LR: 0.000999985701952748 Training loss: 0.0
2025-12-09 10:23:32.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 2507 LR: 0.0009999856900699486 Training loss: 0.0
2025-12-09 10:23:32.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 2508 LR: 0.0009999856781822134 Training loss: 0.0
2025-12-09 10:23:32.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 2509 LR: 0.0009999856662895427 Training loss: 0.0
2025-12-09 10:23:32.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 2510 LR: 0.0009999856543919364 Training loss: 0.0
2025-12-09 10:23:32.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 2511 LR: 0.0009999856424893943 Training loss: 0.0
2025-12-09 10:23:32.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 2512 LR: 0.0009999856305819167 Training loss: 0.0
2025-12-09 10:23:32.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 2513 LR: 0.0009999856186695033 Training loss: 0.0
2025-12-09 10:23:32.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 2514 LR: 0.0009999856067521543 Training loss: 0.0
2025-12-09 10:23:32.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 2515 LR: 0.0009999855948298697 Training loss: 0.0
2025-12-09 10:23:32.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 2516 LR: 0.0009999855829026494 Training loss: 0.0
2025-12-09 10:23:32.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 2517 LR: 0.0009999855709704934 Training loss: 0.0
2025-12-09 10:23:32.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 2518 LR: 0.000999985559033402 Training loss: 0.0
2025-12-09 10:23:32.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 2519 LR: 0.0009999855470913747 Training loss: 0.0
2025-12-09 10:23:32.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 2520 LR: 0.0009999855351444117 Training loss: 0.0
2025-12-09 10:23:32.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 2521 LR: 0.0009999855231925133 Training loss: 0.0
2025-12-09 10:23:32.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 2522 LR: 0.0009999855112356791 Training loss: 0.0
2025-12-09 10:23:32.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 2523 LR: 0.0009999854992739094 Training loss: 0.0
2025-12-09 10:23:32.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 2524 LR: 0.0009999854873072038 Training loss: 0.0
2025-12-09 10:23:32.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 2525 LR: 0.000999985475335563 Training loss: 0.0
2025-12-09 10:23:32.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 2526 LR: 0.000999985463358986 Training loss: 0.0
2025-12-09 10:23:32.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 2527 LR: 0.0009999854513774737 Training loss: 0.0
2025-12-09 10:23:32.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 2528 LR: 0.0009999854393910256 Training loss: 0.0
2025-12-09 10:23:32.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 2529 LR: 0.000999985427399642 Training loss: 0.0
2025-12-09 10:23:32.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 2530 LR: 0.0009999854154033227 Training loss: 0.0
2025-12-09 10:23:32.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 2531 LR: 0.0009999854034020677 Training loss: 0.0
2025-12-09 10:23:32.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 2532 LR: 0.000999985391395877 Training loss: 0.0
2025-12-09 10:23:32.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 2533 LR: 0.000999985379384751 Training loss: 0.0
2025-12-09 10:23:32.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 2534 LR: 0.000999985367368689 Training loss: 0.0
2025-12-09 10:23:32.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 2535 LR: 0.0009999853553476915 Training loss: 0.0
2025-12-09 10:23:32.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 2536 LR: 0.000999985343321758 Training loss: 0.0
2025-12-09 10:23:32.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 2537 LR: 0.0009999853312908894 Training loss: 0.0
2025-12-09 10:23:32.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 2538 LR: 0.000999985319255085 Training loss: 0.0
2025-12-09 10:23:32.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 2539 LR: 0.0009999853072143448 Training loss: 0.0
2025-12-09 10:23:32.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 2540 LR: 0.000999985295168669 Training loss: 0.0
2025-12-09 10:23:32.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 2541 LR: 0.0009999852831180575 Training loss: 0.0
2025-12-09 10:23:32.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 2542 LR: 0.0009999852710625104 Training loss: 0.0
2025-12-09 10:23:32.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 2543 LR: 0.0009999852590020278 Training loss: 0.0
2025-12-09 10:23:32.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 2544 LR: 0.0009999852469366095 Training loss: 0.0
2025-12-09 10:23:32.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 2545 LR: 0.0009999852348662555 Training loss: 0.0
2025-12-09 10:23:32.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 2546 LR: 0.000999985222790966 Training loss: 0.0
2025-12-09 10:23:32.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 2547 LR: 0.0009999852107107406 Training loss: 0.0
2025-12-09 10:23:32.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 2548 LR: 0.0009999851986255796 Training loss: 0.0
2025-12-09 10:23:32.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 2549 LR: 0.000999985186535483 Training loss: 0.0
2025-12-09 10:23:32.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 2550 LR: 0.000999985174440451 Training loss: 0.0
2025-12-09 10:23:32.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 2551 LR: 0.000999985162340483 Training loss: 0.0
2025-12-09 10:23:32.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 2552 LR: 0.0009999851502355795 Training loss: 0.0
2025-12-09 10:23:32.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 2553 LR: 0.0009999851381257403 Training loss: 0.0
2025-12-09 10:23:32.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 2554 LR: 0.0009999851260109657 Training loss: 0.0
2025-12-09 10:23:32.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 2555 LR: 0.0009999851138912553 Training loss: 0.0
2025-12-09 10:23:32.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 2556 LR: 0.0009999851017666091 Training loss: 0.0
2025-12-09 10:23:32.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 2557 LR: 0.0009999850896370275 Training loss: 0.0
2025-12-09 10:23:32.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 2558 LR: 0.0009999850775025102 Training loss: 0.0
2025-12-09 10:23:32.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 2559 LR: 0.000999985065363057 Training loss: 0.0
2025-12-09 10:23:32.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 2560 LR: 0.0009999850532186685 Training loss: 0.0
2025-12-09 10:23:32.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 2561 LR: 0.0009999850410693442 Training loss: 0.0
2025-12-09 10:23:32.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 2562 LR: 0.0009999850289150842 Training loss: 0.0
2025-12-09 10:23:32.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 2563 LR: 0.0009999850167558887 Training loss: 0.0
2025-12-09 10:23:32.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 2564 LR: 0.0009999850045917576 Training loss: 0.0
2025-12-09 10:23:32.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 2565 LR: 0.0009999849924226907 Training loss: 0.0
2025-12-09 10:23:32.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 2566 LR: 0.0009999849802486882 Training loss: 0.0
2025-12-09 10:23:32.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 2567 LR: 0.0009999849680697502 Training loss: 0.0
2025-12-09 10:23:32.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 2568 LR: 0.0009999849558858763 Training loss: 0.0
2025-12-09 10:23:32.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 2569 LR: 0.0009999849436970669 Training loss: 0.0
2025-12-09 10:23:32.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 2570 LR: 0.0009999849315033217 Training loss: 0.0
2025-12-09 10:23:32.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 2571 LR: 0.0009999849193046413 Training loss: 0.0
2025-12-09 10:23:32.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 2572 LR: 0.000999984907101025 Training loss: 0.0
2025-12-09 10:23:32.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 2573 LR: 0.0009999848948924728 Training loss: 0.0
2025-12-09 10:23:32.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 2574 LR: 0.0009999848826789852 Training loss: 0.0
2025-12-09 10:23:32.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 2575 LR: 0.0009999848704605621 Training loss: 0.0
2025-12-09 10:23:32.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 2576 LR: 0.0009999848582372033 Training loss: 0.0
2025-12-09 10:23:32.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 2577 LR: 0.0009999848460089087 Training loss: 0.0
2025-12-09 10:23:32.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 2578 LR: 0.0009999848337756785 Training loss: 0.0
2025-12-09 10:23:32.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 2579 LR: 0.0009999848215375127 Training loss: 0.0
2025-12-09 10:23:32.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 2580 LR: 0.0009999848092944112 Training loss: 0.0
2025-12-09 10:23:32.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 2581 LR: 0.0009999847970463742 Training loss: 0.0
2025-12-09 10:23:32.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 2582 LR: 0.0009999847847934015 Training loss: 0.0
2025-12-09 10:23:32.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 2583 LR: 0.0009999847725354932 Training loss: 0.0
2025-12-09 10:23:32.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 2584 LR: 0.000999984760272649 Training loss: 0.0
2025-12-09 10:23:32.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 2585 LR: 0.0009999847480048694 Training loss: 0.0
2025-12-09 10:23:32.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 2586 LR: 0.0009999847357321542 Training loss: 0.0
2025-12-09 10:23:32.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 2587 LR: 0.000999984723454503 Training loss: 0.0
2025-12-09 10:23:32.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 2588 LR: 0.0009999847111719167 Training loss: 0.0
2025-12-09 10:23:32.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 2589 LR: 0.0009999846988843946 Training loss: 0.0
2025-12-09 10:23:32.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 2590 LR: 0.0009999846865919367 Training loss: 0.0
2025-12-09 10:23:32.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 2591 LR: 0.0009999846742945431 Training loss: 0.0
2025-12-09 10:23:32.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 2592 LR: 0.000999984661992214 Training loss: 0.0
2025-12-09 10:23:32.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 2593 LR: 0.0009999846496849495 Training loss: 0.0
2025-12-09 10:23:32.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 2594 LR: 0.000999984637372749 Training loss: 0.0
2025-12-09 10:23:32.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 2595 LR: 0.0009999846250556132 Training loss: 0.0
2025-12-09 10:23:32.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 2596 LR: 0.0009999846127335412 Training loss: 0.0
2025-12-09 10:23:32.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 2597 LR: 0.0009999846004065342 Training loss: 0.0
2025-12-09 10:23:32.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 2598 LR: 0.000999984588074591 Training loss: 0.0
2025-12-09 10:23:32.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 2599 LR: 0.0009999845757377125 Training loss: 0.0
2025-12-09 10:23:32.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 2600 LR: 0.0009999845633958983 Training loss: 0.0
2025-12-09 10:23:32.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 2601 LR: 0.0009999845510491486 Training loss: 0.0
2025-12-09 10:23:32.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 2602 LR: 0.000999984538697463 Training loss: 0.0
2025-12-09 10:23:32.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 2603 LR: 0.0009999845263408418 Training loss: 0.0
2025-12-09 10:23:32.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 2604 LR: 0.0009999845139792851 Training loss: 0.0
2025-12-09 10:23:32.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 2605 LR: 0.0009999845016127927 Training loss: 0.0
2025-12-09 10:23:32.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 2606 LR: 0.0009999844892413649 Training loss: 0.0
2025-12-09 10:23:32.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 2607 LR: 0.000999984476865001 Training loss: 0.0
2025-12-09 10:23:32.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 2608 LR: 0.0009999844644837017 Training loss: 0.0
2025-12-09 10:23:32.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 2609 LR: 0.0009999844520974669 Training loss: 0.0
2025-12-09 10:23:32.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 2610 LR: 0.0009999844397062963 Training loss: 0.0
2025-12-09 10:23:32.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 2611 LR: 0.00099998442731019 Training loss: 0.0
2025-12-09 10:23:32.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 2612 LR: 0.0009999844149091483 Training loss: 0.0
2025-12-09 10:23:32.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 2613 LR: 0.0009999844025031708 Training loss: 0.0
2025-12-09 10:23:32.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 2614 LR: 0.0009999843900922575 Training loss: 0.0
2025-12-09 10:23:32.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 2615 LR: 0.0009999843776764088 Training loss: 0.0
2025-12-09 10:23:32.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 2616 LR: 0.0009999843652556243 Training loss: 0.0
2025-12-09 10:23:32.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 2617 LR: 0.0009999843528299044 Training loss: 0.0
2025-12-09 10:23:32.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 2618 LR: 0.0009999843403992487 Training loss: 0.0
2025-12-09 10:23:32.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 2619 LR: 0.0009999843279636575 Training loss: 0.0
2025-12-09 10:23:32.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 2620 LR: 0.0009999843155231306 Training loss: 0.0
2025-12-09 10:23:32.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 2621 LR: 0.000999984303077668 Training loss: 0.0
2025-12-09 10:23:32.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 2622 LR: 0.0009999842906272698 Training loss: 0.0
2025-12-09 10:23:32.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 2623 LR: 0.000999984278171936 Training loss: 0.0
2025-12-09 10:23:32.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 2624 LR: 0.0009999842657116666 Training loss: 0.0
2025-12-09 10:23:32.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 2625 LR: 0.0009999842532464615 Training loss: 0.0
2025-12-09 10:23:32.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 2626 LR: 0.0009999842407763207 Training loss: 0.0
2025-12-09 10:23:32.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 2627 LR: 0.0009999842283012444 Training loss: 0.0
2025-12-09 10:23:32.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 2628 LR: 0.0009999842158212324 Training loss: 0.0
2025-12-09 10:23:32.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 2629 LR: 0.0009999842033362846 Training loss: 0.0
2025-12-09 10:23:32.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 2630 LR: 0.0009999841908464016 Training loss: 0.0
2025-12-09 10:23:32.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 2631 LR: 0.0009999841783515826 Training loss: 0.0
2025-12-09 10:23:32.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 2632 LR: 0.0009999841658518281 Training loss: 0.0
2025-12-09 10:23:32.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 2633 LR: 0.000999984153347138 Training loss: 0.0
2025-12-09 10:23:32.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 2634 LR: 0.000999984140837512 Training loss: 0.0
2025-12-09 10:23:32.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 2635 LR: 0.0009999841283229508 Training loss: 0.0
2025-12-09 10:23:32.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 2636 LR: 0.0009999841158034536 Training loss: 0.0
2025-12-09 10:23:32.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 2637 LR: 0.000999984103279021 Training loss: 0.0
2025-12-09 10:23:32.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 2638 LR: 0.0009999840907496528 Training loss: 0.0
2025-12-09 10:23:32.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 2639 LR: 0.0009999840782153487 Training loss: 0.0
2025-12-09 10:23:32.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 2640 LR: 0.000999984065676109 Training loss: 0.0
2025-12-09 10:23:32.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 2641 LR: 0.000999984053131934 Training loss: 0.0
2025-12-09 10:23:32.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 2642 LR: 0.0009999840405828231 Training loss: 0.0
2025-12-09 10:23:32.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 2643 LR: 0.0009999840280287766 Training loss: 0.0
2025-12-09 10:23:32.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 2644 LR: 0.0009999840154697945 Training loss: 0.0
2025-12-09 10:23:32.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 2645 LR: 0.0009999840029058767 Training loss: 0.0
2025-12-09 10:23:32.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 2646 LR: 0.0009999839903370234 Training loss: 0.0
2025-12-09 10:23:32.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 2647 LR: 0.0009999839777632342 Training loss: 0.0
2025-12-09 10:23:32.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 2648 LR: 0.0009999839651845097 Training loss: 0.0
2025-12-09 10:23:32.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 2649 LR: 0.0009999839526008494 Training loss: 0.0
2025-12-09 10:23:32.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 2650 LR: 0.0009999839400122534 Training loss: 0.0
2025-12-09 10:23:32.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 2651 LR: 0.000999983927418722 Training loss: 0.0
2025-12-09 10:23:32.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 2652 LR: 0.0009999839148202548 Training loss: 0.0
2025-12-09 10:23:32.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 2653 LR: 0.000999983902216852 Training loss: 0.0
2025-12-09 10:23:32.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 2654 LR: 0.0009999838896085137 Training loss: 0.0
2025-12-09 10:23:32.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 2655 LR: 0.0009999838769952395 Training loss: 0.0
2025-12-09 10:23:32.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 2656 LR: 0.0009999838643770299 Training loss: 0.0
2025-12-09 10:23:32.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 2657 LR: 0.0009999838517538845 Training loss: 0.0
2025-12-09 10:23:32.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 2658 LR: 0.0009999838391258036 Training loss: 0.0
2025-12-09 10:23:32.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 2659 LR: 0.000999983826492787 Training loss: 0.0
2025-12-09 10:23:32.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 2660 LR: 0.0009999838138548347 Training loss: 0.0
2025-12-09 10:23:32.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 2661 LR: 0.000999983801211947 Training loss: 0.0
2025-12-09 10:23:32.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 2662 LR: 0.0009999837885641234 Training loss: 0.0
2025-12-09 10:23:32.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 2663 LR: 0.0009999837759113643 Training loss: 0.0
2025-12-09 10:23:32.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 2664 LR: 0.0009999837632536698 Training loss: 0.0
2025-12-09 10:23:32.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 2665 LR: 0.0009999837505910395 Training loss: 0.0
2025-12-09 10:23:32.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 2666 LR: 0.0009999837379234733 Training loss: 0.0
2025-12-09 10:23:32.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 2667 LR: 0.0009999837252509718 Training loss: 0.0
2025-12-09 10:23:32.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 2668 LR: 0.0009999837125735345 Training loss: 0.0
2025-12-09 10:23:32.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 2669 LR: 0.0009999836998911616 Training loss: 0.0
2025-12-09 10:23:32.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 2670 LR: 0.0009999836872038531 Training loss: 0.0
2025-12-09 10:23:32.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 2671 LR: 0.0009999836745116092 Training loss: 0.0
2025-12-09 10:23:32.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 2672 LR: 0.0009999836618144293 Training loss: 0.0
2025-12-09 10:23:32.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 2673 LR: 0.0009999836491123139 Training loss: 0.0
2025-12-09 10:23:32.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 2674 LR: 0.000999983636405263 Training loss: 0.0
2025-12-09 10:23:32.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 2675 LR: 0.0009999836236932761 Training loss: 0.0
2025-12-09 10:23:32.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 2676 LR: 0.000999983610976354 Training loss: 0.0
2025-12-09 10:23:32.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 2677 LR: 0.000999983598254496 Training loss: 0.0
2025-12-09 10:23:32.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 2678 LR: 0.0009999835855277026 Training loss: 0.0
2025-12-09 10:23:32.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 2679 LR: 0.0009999835727959735 Training loss: 0.0
2025-12-09 10:23:32.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 2680 LR: 0.0009999835600593087 Training loss: 0.0
2025-12-09 10:23:32.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 2681 LR: 0.0009999835473177084 Training loss: 0.0
2025-12-09 10:23:32.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 2682 LR: 0.0009999835345711723 Training loss: 0.0
2025-12-09 10:23:32.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 2683 LR: 0.0009999835218197006 Training loss: 0.0
2025-12-09 10:23:32.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 2684 LR: 0.0009999835090632933 Training loss: 0.0
2025-12-09 10:23:32.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 2685 LR: 0.0009999834963019504 Training loss: 0.0
2025-12-09 10:23:32.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 2686 LR: 0.0009999834835356719 Training loss: 0.0
2025-12-09 10:23:32.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 2687 LR: 0.0009999834707644577 Training loss: 0.0
2025-12-09 10:23:32.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 2688 LR: 0.000999983457988308 Training loss: 0.0
2025-12-09 10:23:32.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 2689 LR: 0.0009999834452072225 Training loss: 0.0
2025-12-09 10:23:32.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 2690 LR: 0.0009999834324212016 Training loss: 0.0
2025-12-09 10:23:32.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 2691 LR: 0.000999983419630245 Training loss: 0.0
2025-12-09 10:23:32.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 2692 LR: 0.0009999834068343525 Training loss: 0.0
2025-12-09 10:23:32.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 2693 LR: 0.0009999833940335246 Training loss: 0.0
2025-12-09 10:23:32.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 2694 LR: 0.000999983381227761 Training loss: 0.0
2025-12-09 10:23:32.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 2695 LR: 0.000999983368417062 Training loss: 0.0
2025-12-09 10:23:32.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 2696 LR: 0.000999983355601427 Training loss: 0.0
2025-12-09 10:23:32.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 2697 LR: 0.0009999833427808567 Training loss: 0.0
2025-12-09 10:23:32.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 2698 LR: 0.0009999833299553507 Training loss: 0.0
2025-12-09 10:23:32.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 2699 LR: 0.000999983317124909 Training loss: 0.0
2025-12-09 10:23:32.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 2700 LR: 0.0009999833042895318 Training loss: 0.0
2025-12-09 10:23:32.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 2701 LR: 0.0009999832914492188 Training loss: 0.0
2025-12-09 10:23:32.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 2702 LR: 0.0009999832786039703 Training loss: 0.0
2025-12-09 10:23:32.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 2703 LR: 0.0009999832657537862 Training loss: 0.0
2025-12-09 10:23:32.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 2704 LR: 0.0009999832528986663 Training loss: 0.0
2025-12-09 10:23:32.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 2705 LR: 0.000999983240038611 Training loss: 0.0
2025-12-09 10:23:32.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 2706 LR: 0.0009999832271736198 Training loss: 0.0
2025-12-09 10:23:32.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 2707 LR: 0.0009999832143036934 Training loss: 0.0
2025-12-09 10:23:32.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 2708 LR: 0.000999983201428831 Training loss: 0.0
2025-12-09 10:23:32.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 2709 LR: 0.0009999831885490332 Training loss: 0.0
2025-12-09 10:23:32.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 2710 LR: 0.0009999831756642996 Training loss: 0.0
2025-12-09 10:23:32.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 2711 LR: 0.0009999831627746304 Training loss: 0.0
2025-12-09 10:23:32.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 2712 LR: 0.0009999831498800256 Training loss: 0.0
2025-12-09 10:23:32.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 2713 LR: 0.0009999831369804852 Training loss: 0.0
2025-12-09 10:23:32.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 2714 LR: 0.0009999831240760093 Training loss: 0.0
2025-12-09 10:23:32.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 2715 LR: 0.0009999831111665975 Training loss: 0.0
2025-12-09 10:23:32.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 2716 LR: 0.0009999830982522504 Training loss: 0.0
2025-12-09 10:23:32.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 2717 LR: 0.0009999830853329676 Training loss: 0.0
2025-12-09 10:23:32.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 2718 LR: 0.0009999830724087488 Training loss: 0.0
2025-12-09 10:23:32.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 2719 LR: 0.0009999830594795947 Training loss: 0.0
2025-12-09 10:23:32.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 2720 LR: 0.0009999830465455052 Training loss: 0.0
2025-12-09 10:23:32.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 2721 LR: 0.0009999830336064797 Training loss: 0.0
2025-12-09 10:23:32.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 2722 LR: 0.0009999830206625186 Training loss: 0.0
2025-12-09 10:23:32.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 2723 LR: 0.0009999830077136221 Training loss: 0.0
2025-12-09 10:23:32.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 2724 LR: 0.00099998299475979 Training loss: 0.0
2025-12-09 10:23:32.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 2725 LR: 0.000999982981801022 Training loss: 0.0
2025-12-09 10:23:32.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 2726 LR: 0.0009999829688373185 Training loss: 0.0
2025-12-09 10:23:32.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 2727 LR: 0.0009999829558686793 Training loss: 0.0
2025-12-09 10:23:32.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 2728 LR: 0.0009999829428951046 Training loss: 0.0
2025-12-09 10:23:32.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 2729 LR: 0.0009999829299165944 Training loss: 0.0
2025-12-09 10:23:32.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 2730 LR: 0.0009999829169331483 Training loss: 0.0
2025-12-09 10:23:32.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 2731 LR: 0.0009999829039447669 Training loss: 0.0
2025-12-09 10:23:32.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 2732 LR: 0.0009999828909514495 Training loss: 0.0
2025-12-09 10:23:32.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 2733 LR: 0.0009999828779531969 Training loss: 0.0
2025-12-09 10:23:32.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 2734 LR: 0.0009999828649500083 Training loss: 0.0
2025-12-09 10:23:32.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 2735 LR: 0.0009999828519418842 Training loss: 0.0
2025-12-09 10:23:32.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 2736 LR: 0.0009999828389288244 Training loss: 0.0
2025-12-09 10:23:32.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 2737 LR: 0.0009999828259108293 Training loss: 0.0
2025-12-09 10:23:32.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 2738 LR: 0.0009999828128878982 Training loss: 0.0
2025-12-09 10:23:32.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 2739 LR: 0.0009999827998600317 Training loss: 0.0
2025-12-09 10:23:32.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 2740 LR: 0.0009999827868272296 Training loss: 0.0
2025-12-09 10:23:32.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 2741 LR: 0.0009999827737894919 Training loss: 0.0
2025-12-09 10:23:32.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 2742 LR: 0.0009999827607468184 Training loss: 0.0
2025-12-09 10:23:32.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 2743 LR: 0.0009999827476992094 Training loss: 0.0
2025-12-09 10:23:32.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 2744 LR: 0.0009999827346466646 Training loss: 0.0
2025-12-09 10:23:32.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 2745 LR: 0.0009999827215891844 Training loss: 0.0
2025-12-09 10:23:32.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 2746 LR: 0.0009999827085267685 Training loss: 0.0
2025-12-09 10:23:32.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 2747 LR: 0.000999982695459417 Training loss: 0.0
2025-12-09 10:23:32.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 2748 LR: 0.0009999826823871298 Training loss: 0.0
2025-12-09 10:23:32.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 2749 LR: 0.0009999826693099071 Training loss: 0.0
2025-12-09 10:23:32.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 2750 LR: 0.0009999826562277487 Training loss: 0.0
2025-12-09 10:23:32.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 2751 LR: 0.0009999826431406548 Training loss: 0.0
2025-12-09 10:23:32.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 2752 LR: 0.0009999826300486252 Training loss: 0.0
2025-12-09 10:23:32.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 2753 LR: 0.00099998261695166 Training loss: 0.0
2025-12-09 10:23:32.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 2754 LR: 0.0009999826038497592 Training loss: 0.0
2025-12-09 10:23:32.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 2755 LR: 0.0009999825907429228 Training loss: 0.0
2025-12-09 10:23:32.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 2756 LR: 0.0009999825776311505 Training loss: 0.0
2025-12-09 10:23:32.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 2757 LR: 0.000999982564514443 Training loss: 0.0
2025-12-09 10:23:32.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 2758 LR: 0.0009999825513927996 Training loss: 0.0
2025-12-09 10:23:32.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 2759 LR: 0.0009999825382662208 Training loss: 0.0
2025-12-09 10:23:32.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 2760 LR: 0.0009999825251347063 Training loss: 0.0
2025-12-09 10:23:32.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 2761 LR: 0.0009999825119982562 Training loss: 0.0
2025-12-09 10:23:32.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 2762 LR: 0.0009999824988568705 Training loss: 0.0
2025-12-09 10:23:32.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 2763 LR: 0.000999982485710549 Training loss: 0.0
2025-12-09 10:23:32.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 2764 LR: 0.000999982472559292 Training loss: 0.0
2025-12-09 10:23:32.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 2765 LR: 0.0009999824594030993 Training loss: 0.0
2025-12-09 10:23:32.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 2766 LR: 0.000999982446241971 Training loss: 0.0
2025-12-09 10:23:32.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 2767 LR: 0.0009999824330759073 Training loss: 0.0
2025-12-09 10:23:32.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 2768 LR: 0.0009999824199049079 Training loss: 0.0
2025-12-09 10:23:32.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 2769 LR: 0.0009999824067289727 Training loss: 0.0
2025-12-09 10:23:32.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 2770 LR: 0.000999982393548102 Training loss: 0.0
2025-12-09 10:23:32.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 2771 LR: 0.0009999823803622957 Training loss: 0.0
2025-12-09 10:23:32.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 2772 LR: 0.0009999823671715537 Training loss: 0.0
2025-12-09 10:23:32.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 2773 LR: 0.0009999823539758763 Training loss: 0.0
2025-12-09 10:23:32.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 2774 LR: 0.000999982340775263 Training loss: 0.0
2025-12-09 10:23:32.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 2775 LR: 0.0009999823275697144 Training loss: 0.0
2025-12-09 10:23:32.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 2776 LR: 0.00099998231435923 Training loss: 0.0
2025-12-09 10:23:32.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 2777 LR: 0.00099998230114381 Training loss: 0.0
2025-12-09 10:23:32.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 2778 LR: 0.0009999822879234543 Training loss: 0.0
2025-12-09 10:23:32.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 2779 LR: 0.000999982274698163 Training loss: 0.0
2025-12-09 10:23:32.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 2780 LR: 0.0009999822614679364 Training loss: 0.0
2025-12-09 10:23:32.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 2781 LR: 0.000999982248232774 Training loss: 0.0
2025-12-09 10:23:32.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 2782 LR: 0.0009999822349926757 Training loss: 0.0
2025-12-09 10:23:32.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 2783 LR: 0.0009999822217476421 Training loss: 0.0
2025-12-09 10:23:32.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 2784 LR: 0.0009999822084976729 Training loss: 0.0
2025-12-09 10:23:32.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 2785 LR: 0.0009999821952427679 Training loss: 0.0
2025-12-09 10:23:32.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 2786 LR: 0.0009999821819829274 Training loss: 0.0
2025-12-09 10:23:32.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 2787 LR: 0.0009999821687181512 Training loss: 0.0
2025-12-09 10:23:32.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 2788 LR: 0.0009999821554484394 Training loss: 0.0
2025-12-09 10:23:32.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 2789 LR: 0.000999982142173792 Training loss: 0.0
2025-12-09 10:23:32.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 2790 LR: 0.000999982128894209 Training loss: 0.0
2025-12-09 10:23:32.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 2791 LR: 0.0009999821156096904 Training loss: 0.0
2025-12-09 10:23:32.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 2792 LR: 0.0009999821023202362 Training loss: 0.0
2025-12-09 10:23:32.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 2793 LR: 0.0009999820890258463 Training loss: 0.0
2025-12-09 10:23:32.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 2794 LR: 0.000999982075726521 Training loss: 0.0
2025-12-09 10:23:32.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 2795 LR: 0.00099998206242226 Training loss: 0.0
2025-12-09 10:23:32.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 2796 LR: 0.0009999820491130634 Training loss: 0.0
2025-12-09 10:23:32.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 2797 LR: 0.000999982035798931 Training loss: 0.0
2025-12-09 10:23:32.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 2798 LR: 0.0009999820224798632 Training loss: 0.0
2025-12-09 10:23:32.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 2799 LR: 0.0009999820091558598 Training loss: 0.0
2025-12-09 10:23:32.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 2800 LR: 0.0009999819958269205 Training loss: 0.0
2025-12-09 10:23:32.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 2801 LR: 0.0009999819824930457 Training loss: 0.0
2025-12-09 10:23:32.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 2802 LR: 0.0009999819691542356 Training loss: 0.0
2025-12-09 10:23:32.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 2803 LR: 0.0009999819558104896 Training loss: 0.0
2025-12-09 10:23:32.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 2804 LR: 0.000999981942461808 Training loss: 0.0
2025-12-09 10:23:32.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 2805 LR: 0.000999981929108191 Training loss: 0.0
2025-12-09 10:23:32.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 2806 LR: 0.000999981915749638 Training loss: 0.0
2025-12-09 10:23:32.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 2807 LR: 0.0009999819023861498 Training loss: 0.0
2025-12-09 10:23:32.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 2808 LR: 0.0009999818890177258 Training loss: 0.0
2025-12-09 10:23:32.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 2809 LR: 0.000999981875644366 Training loss: 0.0
2025-12-09 10:23:32.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 2810 LR: 0.000999981862266071 Training loss: 0.0
2025-12-09 10:23:32.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 2811 LR: 0.0009999818488828402 Training loss: 0.0
2025-12-09 10:23:32.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 2812 LR: 0.0009999818354946737 Training loss: 0.0
2025-12-09 10:23:32.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 2813 LR: 0.0009999818221015718 Training loss: 0.0
2025-12-09 10:23:32.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 2814 LR: 0.000999981808703534 Training loss: 0.0
2025-12-09 10:23:32.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 2815 LR: 0.0009999817953005607 Training loss: 0.0
2025-12-09 10:23:32.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 2816 LR: 0.000999981781892652 Training loss: 0.0
2025-12-09 10:23:32.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 2817 LR: 0.0009999817684798074 Training loss: 0.0
2025-12-09 10:23:32.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 2818 LR: 0.0009999817550620273 Training loss: 0.0
2025-12-09 10:23:32.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 2819 LR: 0.0009999817416393116 Training loss: 0.0
2025-12-09 10:23:32.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 2820 LR: 0.0009999817282116603 Training loss: 0.0
2025-12-09 10:23:32.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 2821 LR: 0.0009999817147790734 Training loss: 0.0
2025-12-09 10:23:32.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 2822 LR: 0.0009999817013415509 Training loss: 0.0
2025-12-09 10:23:32.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 2823 LR: 0.0009999816878990928 Training loss: 0.0
2025-12-09 10:23:32.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 2824 LR: 0.000999981674451699 Training loss: 0.0
2025-12-09 10:23:32.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 2825 LR: 0.0009999816609993697 Training loss: 0.0
2025-12-09 10:23:32.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 2826 LR: 0.0009999816475421046 Training loss: 0.0
2025-12-09 10:23:32.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 2827 LR: 0.000999981634079904 Training loss: 0.0
2025-12-09 10:23:32.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 2828 LR: 0.000999981620612768 Training loss: 0.0
2025-12-09 10:23:32.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 2829 LR: 0.0009999816071406963 Training loss: 0.0
2025-12-09 10:23:32.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 2830 LR: 0.0009999815936636888 Training loss: 0.0
2025-12-09 10:23:32.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 2831 LR: 0.0009999815801817458 Training loss: 0.0
2025-12-09 10:23:32.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 2832 LR: 0.000999981566694867 Training loss: 0.0
2025-12-09 10:23:32.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 2833 LR: 0.0009999815532030529 Training loss: 0.0
2025-12-09 10:23:32.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 2834 LR: 0.0009999815397063031 Training loss: 0.0
2025-12-09 10:23:32.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 2835 LR: 0.0009999815262046177 Training loss: 0.0
2025-12-09 10:23:32.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 2836 LR: 0.0009999815126979967 Training loss: 0.0
2025-12-09 10:23:32.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 2837 LR: 0.00099998149918644 Training loss: 0.0
2025-12-09 10:23:32.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 2838 LR: 0.0009999814856699479 Training loss: 0.0
2025-12-09 10:23:32.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 2839 LR: 0.0009999814721485198 Training loss: 0.0
2025-12-09 10:23:32.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 2840 LR: 0.0009999814586221566 Training loss: 0.0
2025-12-09 10:23:32.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 2841 LR: 0.0009999814450908574 Training loss: 0.0
2025-12-09 10:23:32.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 2842 LR: 0.0009999814315546228 Training loss: 0.0
2025-12-09 10:23:32.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 2843 LR: 0.0009999814180134525 Training loss: 0.0
2025-12-09 10:23:32.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 2844 LR: 0.0009999814044673466 Training loss: 0.0
2025-12-09 10:23:32.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 2845 LR: 0.0009999813909163052 Training loss: 0.0
2025-12-09 10:23:32.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 2846 LR: 0.000999981377360328 Training loss: 0.0
2025-12-09 10:23:32.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 2847 LR: 0.0009999813637994153 Training loss: 0.0
2025-12-09 10:23:32.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 2848 LR: 0.000999981350233567 Training loss: 0.0
2025-12-09 10:23:32.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 2849 LR: 0.000999981336662783 Training loss: 0.0
2025-12-09 10:23:32.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 2850 LR: 0.0009999813230870637 Training loss: 0.0
2025-12-09 10:23:32.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 2851 LR: 0.0009999813095064084 Training loss: 0.0
2025-12-09 10:23:32.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 2852 LR: 0.0009999812959208176 Training loss: 0.0
2025-12-09 10:23:32.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 2853 LR: 0.0009999812823302914 Training loss: 0.0
2025-12-09 10:23:32.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 2854 LR: 0.0009999812687348294 Training loss: 0.0
2025-12-09 10:23:32.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 2855 LR: 0.0009999812551344319 Training loss: 0.0
2025-12-09 10:23:32.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 2856 LR: 0.0009999812415290989 Training loss: 0.0
2025-12-09 10:23:32.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 2857 LR: 0.00099998122791883 Training loss: 0.0
2025-12-09 10:23:32.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 2858 LR: 0.0009999812143036255 Training loss: 0.0
2025-12-09 10:23:32.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 2859 LR: 0.0009999812006834857 Training loss: 0.0
2025-12-09 10:23:32.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 2860 LR: 0.00099998118705841 Training loss: 0.0
2025-12-09 10:23:32.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 2861 LR: 0.000999981173428399 Training loss: 0.0
2025-12-09 10:23:32.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 2862 LR: 0.0009999811597934522 Training loss: 0.0
2025-12-09 10:23:32.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 2863 LR: 0.0009999811461535698 Training loss: 0.0
2025-12-09 10:23:32.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 2864 LR: 0.0009999811325087518 Training loss: 0.0
2025-12-09 10:23:32.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 2865 LR: 0.0009999811188589982 Training loss: 0.0
2025-12-09 10:23:32.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 2866 LR: 0.000999981105204309 Training loss: 0.0
2025-12-09 10:23:32.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 2867 LR: 0.0009999810915446842 Training loss: 0.0
2025-12-09 10:23:32.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 2868 LR: 0.0009999810778801238 Training loss: 0.0
2025-12-09 10:23:32.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 2869 LR: 0.000999981064210628 Training loss: 0.0
2025-12-09 10:23:32.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 2870 LR: 0.0009999810505361964 Training loss: 0.0
2025-12-09 10:23:32.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 2871 LR: 0.0009999810368568293 Training loss: 0.0
2025-12-09 10:23:32.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 2872 LR: 0.0009999810231725264 Training loss: 0.0
2025-12-09 10:23:32.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 2873 LR: 0.000999981009483288 Training loss: 0.0
2025-12-09 10:23:32.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 2874 LR: 0.0009999809957891138 Training loss: 0.0
2025-12-09 10:23:32.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 2875 LR: 0.0009999809820900043 Training loss: 0.0
2025-12-09 10:23:32.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 2876 LR: 0.000999980968385959 Training loss: 0.0
2025-12-09 10:23:32.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 2877 LR: 0.0009999809546769782 Training loss: 0.0
2025-12-09 10:23:32.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 2878 LR: 0.000999980940963062 Training loss: 0.0
2025-12-09 10:23:32.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 2879 LR: 0.00099998092724421 Training loss: 0.0
2025-12-09 10:23:32.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 2880 LR: 0.0009999809135204222 Training loss: 0.0
2025-12-09 10:23:32.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 2881 LR: 0.000999980899791699 Training loss: 0.0
2025-12-09 10:23:32.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 2882 LR: 0.0009999808860580402 Training loss: 0.0
2025-12-09 10:23:32.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 2883 LR: 0.000999980872319446 Training loss: 0.0
2025-12-09 10:23:32.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 2884 LR: 0.0009999808585759158 Training loss: 0.0
2025-12-09 10:23:32.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 2885 LR: 0.0009999808448274503 Training loss: 0.0
2025-12-09 10:23:32.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 2886 LR: 0.0009999808310740491 Training loss: 0.0
2025-12-09 10:23:32.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 2887 LR: 0.0009999808173157122 Training loss: 0.0
2025-12-09 10:23:32.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 2888 LR: 0.0009999808035524398 Training loss: 0.0
2025-12-09 10:23:32.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 2889 LR: 0.0009999807897842319 Training loss: 0.0
2025-12-09 10:23:32.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 2890 LR: 0.0009999807760110882 Training loss: 0.0
2025-12-09 10:23:32.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 2891 LR: 0.000999980762233009 Training loss: 0.0
2025-12-09 10:23:32.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 2892 LR: 0.0009999807484499942 Training loss: 0.0
2025-12-09 10:23:32.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 2893 LR: 0.0009999807346620438 Training loss: 0.0
2025-12-09 10:23:32.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 2894 LR: 0.000999980720869158 Training loss: 0.0
2025-12-09 10:23:32.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 2895 LR: 0.000999980707071336 Training loss: 0.0
2025-12-09 10:23:32.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 2896 LR: 0.000999980693268579 Training loss: 0.0
2025-12-09 10:23:32.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 2897 LR: 0.0009999806794608861 Training loss: 0.0
2025-12-09 10:23:32.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 2898 LR: 0.0009999806656482578 Training loss: 0.0
2025-12-09 10:23:32.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 2899 LR: 0.0009999806518306937 Training loss: 0.0
2025-12-09 10:23:32.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 2900 LR: 0.0009999806380081942 Training loss: 0.0
2025-12-09 10:23:32.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 2901 LR: 0.0009999806241807589 Training loss: 0.0
2025-12-09 10:23:32.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 2902 LR: 0.000999980610348388 Training loss: 0.0
2025-12-09 10:23:32.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 2903 LR: 0.0009999805965110818 Training loss: 0.0
2025-12-09 10:23:32.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 2904 LR: 0.0009999805826688397 Training loss: 0.0
2025-12-09 10:23:32.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 2905 LR: 0.000999980568821662 Training loss: 0.0
2025-12-09 10:23:32.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 2906 LR: 0.000999980554969549 Training loss: 0.0
2025-12-09 10:23:32.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 2907 LR: 0.0009999805411125002 Training loss: 0.0
2025-12-09 10:23:32.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 2908 LR: 0.0009999805272505157 Training loss: 0.0
2025-12-09 10:23:32.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 2909 LR: 0.0009999805133835958 Training loss: 0.0
2025-12-09 10:23:32.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 2910 LR: 0.0009999804995117403 Training loss: 0.0
2025-12-09 10:23:32.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 2911 LR: 0.000999980485634949 Training loss: 0.0
2025-12-09 10:23:32.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 2912 LR: 0.0009999804717532223 Training loss: 0.0
2025-12-09 10:23:32.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 2913 LR: 0.00099998045786656 Training loss: 0.0
2025-12-09 10:23:32.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 2914 LR: 0.000999980443974962 Training loss: 0.0
2025-12-09 10:23:32.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 2915 LR: 0.0009999804300784285 Training loss: 0.0
2025-12-09 10:23:32.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 2916 LR: 0.0009999804161769591 Training loss: 0.0
2025-12-09 10:23:32.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 2917 LR: 0.0009999804022705545 Training loss: 0.0
2025-12-09 10:23:32.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 2918 LR: 0.0009999803883592143 Training loss: 0.0
2025-12-09 10:23:32.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 2919 LR: 0.0009999803744429382 Training loss: 0.0
2025-12-09 10:23:32.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 2920 LR: 0.0009999803605217268 Training loss: 0.0
2025-12-09 10:23:32.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 2921 LR: 0.0009999803465955796 Training loss: 0.0
2025-12-09 10:23:32.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 2922 LR: 0.0009999803326644968 Training loss: 0.0
2025-12-09 10:23:32.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 2923 LR: 0.0009999803187284784 Training loss: 0.0
2025-12-09 10:23:32.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 2924 LR: 0.0009999803047875246 Training loss: 0.0
2025-12-09 10:23:32.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 2925 LR: 0.0009999802908416352 Training loss: 0.0
2025-12-09 10:23:32.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 2926 LR: 0.00099998027689081 Training loss: 0.0
2025-12-09 10:23:32.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 2927 LR: 0.000999980262935049 Training loss: 0.0
2025-12-09 10:23:32.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 2928 LR: 0.000999980248974353 Training loss: 0.0
2025-12-09 10:23:32.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 2929 LR: 0.000999980235008721 Training loss: 0.0
2025-12-09 10:23:32.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 2930 LR: 0.0009999802210381536 Training loss: 0.0
2025-12-09 10:23:32.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 2931 LR: 0.0009999802070626504 Training loss: 0.0
2025-12-09 10:23:32.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 2932 LR: 0.0009999801930822118 Training loss: 0.0
2025-12-09 10:23:32.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 2933 LR: 0.0009999801790968375 Training loss: 0.0
2025-12-09 10:23:32.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 2934 LR: 0.0009999801651065278 Training loss: 0.0
2025-12-09 10:23:32.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 2935 LR: 0.0009999801511112823 Training loss: 0.0
2025-12-09 10:23:32.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 2936 LR: 0.0009999801371111013 Training loss: 0.0
2025-12-09 10:23:32.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 2937 LR: 0.0009999801231059845 Training loss: 0.0
2025-12-09 10:23:32.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 2938 LR: 0.0009999801090959323 Training loss: 0.0
2025-12-09 10:23:32.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 2939 LR: 0.0009999800950809446 Training loss: 0.0
2025-12-09 10:23:32.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 2940 LR: 0.000999980081061021 Training loss: 0.0
2025-12-09 10:23:32.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 2941 LR: 0.0009999800670361621 Training loss: 0.0
2025-12-09 10:23:32.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 2942 LR: 0.0009999800530063674 Training loss: 0.0
2025-12-09 10:23:32.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 2943 LR: 0.0009999800389716373 Training loss: 0.0
2025-12-09 10:23:32.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 2944 LR: 0.0009999800249319716 Training loss: 0.0
2025-12-09 10:23:32.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 2945 LR: 0.00099998001088737 Training loss: 0.0
2025-12-09 10:23:32.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 2946 LR: 0.0009999799968378332 Training loss: 0.0
2025-12-09 10:23:32.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 2947 LR: 0.0009999799827833606 Training loss: 0.0
2025-12-09 10:23:32.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 2948 LR: 0.0009999799687239524 Training loss: 0.0
2025-12-09 10:23:32.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 2949 LR: 0.0009999799546596088 Training loss: 0.0
2025-12-09 10:23:32.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 2950 LR: 0.0009999799405903294 Training loss: 0.0
2025-12-09 10:23:32.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 2951 LR: 0.0009999799265161143 Training loss: 0.0
2025-12-09 10:23:32.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 2952 LR: 0.0009999799124369639 Training loss: 0.0
2025-12-09 10:23:32.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 2953 LR: 0.0009999798983528778 Training loss: 0.0
2025-12-09 10:23:32.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 2954 LR: 0.000999979884263856 Training loss: 0.0
2025-12-09 10:23:32.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 2955 LR: 0.0009999798701698988 Training loss: 0.0
2025-12-09 10:23:32.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 2956 LR: 0.0009999798560710058 Training loss: 0.0
2025-12-09 10:23:32.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 2957 LR: 0.0009999798419671772 Training loss: 0.0
2025-12-09 10:23:32.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 2958 LR: 0.0009999798278584133 Training loss: 0.0
2025-12-09 10:23:32.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 2959 LR: 0.0009999798137447136 Training loss: 0.0
2025-12-09 10:23:32.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 2960 LR: 0.0009999797996260785 Training loss: 0.0
2025-12-09 10:23:32.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 2961 LR: 0.0009999797855025077 Training loss: 0.0
2025-12-09 10:23:32.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 2962 LR: 0.0009999797713740011 Training loss: 0.0
2025-12-09 10:23:32.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 2963 LR: 0.0009999797572405591 Training loss: 0.0
2025-12-09 10:23:32.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 2964 LR: 0.0009999797431021816 Training loss: 0.0
2025-12-09 10:23:32.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 2965 LR: 0.0009999797289588683 Training loss: 0.0
2025-12-09 10:23:32.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 2966 LR: 0.0009999797148106196 Training loss: 0.0
2025-12-09 10:23:32.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 2967 LR: 0.000999979700657435 Training loss: 0.0
2025-12-09 10:23:32.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 2968 LR: 0.000999979686499315 Training loss: 0.0
2025-12-09 10:23:32.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 2969 LR: 0.0009999796723362596 Training loss: 0.0
2025-12-09 10:23:32.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 2970 LR: 0.0009999796581682686 Training loss: 0.0
2025-12-09 10:23:32.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 2971 LR: 0.0009999796439953417 Training loss: 0.0
2025-12-09 10:23:32.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 2972 LR: 0.0009999796298174794 Training loss: 0.0
2025-12-09 10:23:32.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 2973 LR: 0.0009999796156346815 Training loss: 0.0
2025-12-09 10:23:32.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 2974 LR: 0.000999979601446948 Training loss: 0.0
2025-12-09 10:23:32.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 2975 LR: 0.0009999795872542789 Training loss: 0.0
2025-12-09 10:23:32.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 2976 LR: 0.0009999795730566744 Training loss: 0.0
2025-12-09 10:23:32.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 2977 LR: 0.000999979558854134 Training loss: 0.0
2025-12-09 10:23:32.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 2978 LR: 0.000999979544646658 Training loss: 0.0
2025-12-09 10:23:32.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 2979 LR: 0.0009999795304342467 Training loss: 0.0
2025-12-09 10:23:32.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 2980 LR: 0.0009999795162168998 Training loss: 0.0
2025-12-09 10:23:32.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 2981 LR: 0.0009999795019946171 Training loss: 0.0
2025-12-09 10:23:32.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 2982 LR: 0.000999979487767399 Training loss: 0.0
2025-12-09 10:23:32.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 2983 LR: 0.000999979473535245 Training loss: 0.0
2025-12-09 10:23:32.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 2984 LR: 0.0009999794592981557 Training loss: 0.0
2025-12-09 10:23:32.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 2985 LR: 0.0009999794450561309 Training loss: 0.0
2025-12-09 10:23:32.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 2986 LR: 0.0009999794308091703 Training loss: 0.0
2025-12-09 10:23:32.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 2987 LR: 0.0009999794165572741 Training loss: 0.0
2025-12-09 10:23:32.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 2988 LR: 0.0009999794023004425 Training loss: 0.0
2025-12-09 10:23:32.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 2989 LR: 0.0009999793880386752 Training loss: 0.0
2025-12-09 10:23:32.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 2990 LR: 0.0009999793737719722 Training loss: 0.0
2025-12-09 10:23:32.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 2991 LR: 0.0009999793595003338 Training loss: 0.0
2025-12-09 10:23:32.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 2992 LR: 0.0009999793452237598 Training loss: 0.0
2025-12-09 10:23:32.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 2993 LR: 0.0009999793309422502 Training loss: 0.0
2025-12-09 10:23:32.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 2994 LR: 0.0009999793166558049 Training loss: 0.0
2025-12-09 10:23:32.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 2995 LR: 0.000999979302364424 Training loss: 0.0
2025-12-09 10:23:32.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 2996 LR: 0.0009999792880681076 Training loss: 0.0
2025-12-09 10:23:32.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 2997 LR: 0.0009999792737668558 Training loss: 0.0
2025-12-09 10:23:32.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 2998 LR: 0.0009999792594606682 Training loss: 0.0
2025-12-09 10:23:32.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 2999 LR: 0.000999979245149545 Training loss: 0.0
2025-12-09 10:23:32.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 3000 LR: 0.0009999792308334862 Training loss: 0.0
2025-12-09 10:23:32.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 3001 LR: 0.000999979216512492 Training loss: 0.0
2025-12-09 10:23:32.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 3002 LR: 0.000999979202186562 Training loss: 0.0
2025-12-09 10:23:32.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 3003 LR: 0.0009999791878556965 Training loss: 0.0
2025-12-09 10:23:32.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 3004 LR: 0.0009999791735198955 Training loss: 0.0
2025-12-09 10:23:32.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 3005 LR: 0.0009999791591791588 Training loss: 0.0
2025-12-09 10:23:32.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 3006 LR: 0.0009999791448334866 Training loss: 0.0
2025-12-09 10:23:32.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 3007 LR: 0.0009999791304828786 Training loss: 0.0
2025-12-09 10:23:32.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 3008 LR: 0.0009999791161273354 Training loss: 0.0
2025-12-09 10:23:32.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 3009 LR: 0.0009999791017668565 Training loss: 0.0
2025-12-09 10:23:32.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 3010 LR: 0.0009999790874014418 Training loss: 0.0
2025-12-09 10:23:32.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 3011 LR: 0.0009999790730310916 Training loss: 0.0
2025-12-09 10:23:32.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 3012 LR: 0.000999979058655806 Training loss: 0.0
2025-12-09 10:23:32.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 3013 LR: 0.0009999790442755845 Training loss: 0.0
2025-12-09 10:23:32.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 3014 LR: 0.0009999790298904276 Training loss: 0.0
2025-12-09 10:23:32.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 3015 LR: 0.0009999790155003352 Training loss: 0.0
2025-12-09 10:23:32.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 3016 LR: 0.000999979001105307 Training loss: 0.0
2025-12-09 10:23:32.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 3017 LR: 0.0009999789867053434 Training loss: 0.0
2025-12-09 10:23:32.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 3018 LR: 0.0009999789723004443 Training loss: 0.0
2025-12-09 10:23:32.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 3019 LR: 0.0009999789578906094 Training loss: 0.0
2025-12-09 10:23:32.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 3020 LR: 0.000999978943475839 Training loss: 0.0
2025-12-09 10:23:32.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 3021 LR: 0.0009999789290561331 Training loss: 0.0
2025-12-09 10:23:32.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 3022 LR: 0.0009999789146314915 Training loss: 0.0
2025-12-09 10:23:32.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 3023 LR: 0.0009999789002019144 Training loss: 0.0
2025-12-09 10:23:32.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 3024 LR: 0.0009999788857674018 Training loss: 0.0
2025-12-09 10:23:32.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 3025 LR: 0.0009999788713279535 Training loss: 0.0
2025-12-09 10:23:32.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 3026 LR: 0.0009999788568835694 Training loss: 0.0
2025-12-09 10:23:32.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 3027 LR: 0.00099997884243425 Training loss: 0.0
2025-12-09 10:23:32.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 3028 LR: 0.000999978827979995 Training loss: 0.0
2025-12-09 10:23:32.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 3029 LR: 0.0009999788135208044 Training loss: 0.0
2025-12-09 10:23:32.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 3030 LR: 0.0009999787990566781 Training loss: 0.0
2025-12-09 10:23:32.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 3031 LR: 0.0009999787845876166 Training loss: 0.0
2025-12-09 10:23:32.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 3032 LR: 0.000999978770113619 Training loss: 0.0
2025-12-09 10:23:32.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 3033 LR: 0.000999978755634686 Training loss: 0.0
2025-12-09 10:23:32.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 3034 LR: 0.0009999787411508177 Training loss: 0.0
2025-12-09 10:23:32.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 3035 LR: 0.0009999787266620134 Training loss: 0.0
2025-12-09 10:23:32.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 3036 LR: 0.0009999787121682737 Training loss: 0.0
2025-12-09 10:23:32.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 3037 LR: 0.0009999786976695986 Training loss: 0.0
2025-12-09 10:23:32.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 3038 LR: 0.0009999786831659876 Training loss: 0.0
2025-12-09 10:23:32.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 3039 LR: 0.0009999786686574412 Training loss: 0.0
2025-12-09 10:23:32.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 3040 LR: 0.0009999786541439594 Training loss: 0.0
2025-12-09 10:23:32.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 3041 LR: 0.0009999786396255417 Training loss: 0.0
2025-12-09 10:23:32.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 3042 LR: 0.0009999786251021884 Training loss: 0.0
2025-12-09 10:23:32.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 3043 LR: 0.0009999786105739 Training loss: 0.0
2025-12-09 10:23:32.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 3044 LR: 0.0009999785960406755 Training loss: 0.0
2025-12-09 10:23:32.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 3045 LR: 0.0009999785815025157 Training loss: 0.0
2025-12-09 10:23:32.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 3046 LR: 0.00099997856695942 Training loss: 0.0
2025-12-09 10:23:32.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 3047 LR: 0.000999978552411389 Training loss: 0.0
2025-12-09 10:23:32.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 3048 LR: 0.0009999785378584226 Training loss: 0.0
2025-12-09 10:23:32.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 3049 LR: 0.0009999785233005202 Training loss: 0.0
2025-12-09 10:23:32.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 3050 LR: 0.0009999785087376825 Training loss: 0.0
2025-12-09 10:23:32.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 3051 LR: 0.0009999784941699093 Training loss: 0.0
2025-12-09 10:23:32.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 3052 LR: 0.0009999784795972002 Training loss: 0.0
2025-12-09 10:23:32.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 3053 LR: 0.0009999784650195557 Training loss: 0.0
2025-12-09 10:23:32.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 3054 LR: 0.0009999784504369756 Training loss: 0.0
2025-12-09 10:23:32.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 3055 LR: 0.00099997843584946 Training loss: 0.0
2025-12-09 10:23:32.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 3056 LR: 0.0009999784212570088 Training loss: 0.0
2025-12-09 10:23:32.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 3057 LR: 0.000999978406659622 Training loss: 0.0
2025-12-09 10:23:32.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 3058 LR: 0.0009999783920572995 Training loss: 0.0
2025-12-09 10:23:32.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 3059 LR: 0.0009999783774500416 Training loss: 0.0
2025-12-09 10:23:32.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 3060 LR: 0.000999978362837848 Training loss: 0.0
2025-12-09 10:23:32.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 3061 LR: 0.000999978348220719 Training loss: 0.0
2025-12-09 10:23:32.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 3062 LR: 0.0009999783335986542 Training loss: 0.0
2025-12-09 10:23:32.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 3063 LR: 0.000999978318971654 Training loss: 0.0
2025-12-09 10:23:32.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 3064 LR: 0.0009999783043397182 Training loss: 0.0
2025-12-09 10:23:32.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 3065 LR: 0.0009999782897028467 Training loss: 0.0
2025-12-09 10:23:32.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 3066 LR: 0.0009999782750610398 Training loss: 0.0
2025-12-09 10:23:32.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 3067 LR: 0.0009999782604142972 Training loss: 0.0
2025-12-09 10:23:32.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 3068 LR: 0.000999978245762619 Training loss: 0.0
2025-12-09 10:23:32.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 3069 LR: 0.0009999782311060053 Training loss: 0.0
2025-12-09 10:23:32.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 3070 LR: 0.000999978216444456 Training loss: 0.0
2025-12-09 10:23:32.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 3071 LR: 0.0009999782017779712 Training loss: 0.0
2025-12-09 10:23:32.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 3072 LR: 0.0009999781871065508 Training loss: 0.0
2025-12-09 10:23:32.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 3073 LR: 0.0009999781724301948 Training loss: 0.0
2025-12-09 10:23:32.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 3074 LR: 0.000999978157748903 Training loss: 0.0
2025-12-09 10:23:32.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 3075 LR: 0.000999978143062676 Training loss: 0.0
2025-12-09 10:23:32.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 3076 LR: 0.0009999781283715132 Training loss: 0.0
2025-12-09 10:23:32.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 3077 LR: 0.000999978113675415 Training loss: 0.0
2025-12-09 10:23:32.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 3078 LR: 0.000999978098974381 Training loss: 0.0
2025-12-09 10:23:32.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 3079 LR: 0.0009999780842684116 Training loss: 0.0
2025-12-09 10:23:32.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 3080 LR: 0.0009999780695575066 Training loss: 0.0
2025-12-09 10:23:32.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 3081 LR: 0.0009999780548416658 Training loss: 0.0
2025-12-09 10:23:32.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 3082 LR: 0.0009999780401208898 Training loss: 0.0
2025-12-09 10:23:32.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 3083 LR: 0.000999978025395178 Training loss: 0.0
2025-12-09 10:23:32.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 3084 LR: 0.0009999780106645308 Training loss: 0.0
2025-12-09 10:23:32.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 3085 LR: 0.0009999779959289478 Training loss: 0.0
2025-12-09 10:23:32.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 3086 LR: 0.0009999779811884293 Training loss: 0.0
2025-12-09 10:23:32.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 3087 LR: 0.0009999779664429753 Training loss: 0.0
2025-12-09 10:23:32.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 3088 LR: 0.0009999779516925858 Training loss: 0.0
2025-12-09 10:23:32.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 3089 LR: 0.0009999779369372606 Training loss: 0.0
2025-12-09 10:23:32.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 3090 LR: 0.000999977922177 Training loss: 0.0
2025-12-09 10:23:32.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 3091 LR: 0.0009999779074118037 Training loss: 0.0
2025-12-09 10:23:32.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 3092 LR: 0.0009999778926416715 Training loss: 0.0
2025-12-09 10:23:32.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 3093 LR: 0.0009999778778666043 Training loss: 0.0
2025-12-09 10:23:32.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 3094 LR: 0.0009999778630866013 Training loss: 0.0
2025-12-09 10:23:32.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 3095 LR: 0.0009999778483016626 Training loss: 0.0
2025-12-09 10:23:32.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 3096 LR: 0.0009999778335117884 Training loss: 0.0
2025-12-09 10:23:32.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 3097 LR: 0.0009999778187169785 Training loss: 0.0
2025-12-09 10:23:32.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 3098 LR: 0.0009999778039172333 Training loss: 0.0
2025-12-09 10:23:32.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 3099 LR: 0.0009999777891125524 Training loss: 0.0
2025-12-09 10:23:32.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 3100 LR: 0.000999977774302936 Training loss: 0.0
2025-12-09 10:23:32.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 3101 LR: 0.0009999777594883838 Training loss: 0.0
2025-12-09 10:23:32.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 3102 LR: 0.0009999777446688964 Training loss: 0.0
2025-12-09 10:23:32.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 3103 LR: 0.0009999777298444733 Training loss: 0.0
2025-12-09 10:23:32.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 3104 LR: 0.0009999777150151144 Training loss: 0.0
2025-12-09 10:23:32.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 3105 LR: 0.0009999777001808202 Training loss: 0.0
2025-12-09 10:23:32.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 3106 LR: 0.0009999776853415903 Training loss: 0.0
2025-12-09 10:23:32.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 3107 LR: 0.000999977670497425 Training loss: 0.0
2025-12-09 10:23:32.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 3108 LR: 0.0009999776556483238 Training loss: 0.0
2025-12-09 10:23:32.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 3109 LR: 0.0009999776407942874 Training loss: 0.0
2025-12-09 10:23:32.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 3110 LR: 0.000999977625935315 Training loss: 0.0
2025-12-09 10:23:32.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 3111 LR: 0.0009999776110714074 Training loss: 0.0
2025-12-09 10:23:32.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 3112 LR: 0.000999977596202564 Training loss: 0.0
2025-12-09 10:23:32.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 3113 LR: 0.0009999775813287852 Training loss: 0.0
2025-12-09 10:23:32.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 3114 LR: 0.0009999775664500709 Training loss: 0.0
2025-12-09 10:23:32.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 3115 LR: 0.000999977551566421 Training loss: 0.0
2025-12-09 10:23:32.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 3116 LR: 0.0009999775366778354 Training loss: 0.0
2025-12-09 10:23:32.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 3117 LR: 0.000999977521784314 Training loss: 0.0
2025-12-09 10:23:32.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 3118 LR: 0.0009999775068858575 Training loss: 0.0
2025-12-09 10:23:32.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 3119 LR: 0.0009999774919824652 Training loss: 0.0
2025-12-09 10:23:32.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 3120 LR: 0.0009999774770741373 Training loss: 0.0
2025-12-09 10:23:32.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 3121 LR: 0.000999977462160874 Training loss: 0.0
2025-12-09 10:23:32.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 3122 LR: 0.000999977447242675 Training loss: 0.0
2025-12-09 10:23:32.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 3123 LR: 0.0009999774323195406 Training loss: 0.0
2025-12-09 10:23:32.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 3124 LR: 0.0009999774173914703 Training loss: 0.0
2025-12-09 10:23:32.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 3125 LR: 0.0009999774024584648 Training loss: 0.0
2025-12-09 10:23:32.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 3126 LR: 0.0009999773875205237 Training loss: 0.0
2025-12-09 10:23:32.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 3127 LR: 0.0009999773725776467 Training loss: 0.0
2025-12-09 10:23:32.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 3128 LR: 0.0009999773576298344 Training loss: 0.0
2025-12-09 10:23:32.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 3129 LR: 0.0009999773426770863 Training loss: 0.0
2025-12-09 10:23:32.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 3130 LR: 0.000999977327719403 Training loss: 0.0
2025-12-09 10:23:32.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 3131 LR: 0.000999977312756784 Training loss: 0.0
2025-12-09 10:23:32.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 3132 LR: 0.0009999772977892292 Training loss: 0.0
2025-12-09 10:23:32.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 3133 LR: 0.000999977282816739 Training loss: 0.0
2025-12-09 10:23:32.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 3134 LR: 0.0009999772678393132 Training loss: 0.0
2025-12-09 10:23:32.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 3135 LR: 0.0009999772528569522 Training loss: 0.0
2025-12-09 10:23:32.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 3136 LR: 0.0009999772378696552 Training loss: 0.0
2025-12-09 10:23:32.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 3137 LR: 0.0009999772228774227 Training loss: 0.0
2025-12-09 10:23:32.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 3138 LR: 0.0009999772078802547 Training loss: 0.0
2025-12-09 10:23:32.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 3139 LR: 0.0009999771928781512 Training loss: 0.0
2025-12-09 10:23:32.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 3140 LR: 0.000999977177871112 Training loss: 0.0
2025-12-09 10:23:32.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 3141 LR: 0.0009999771628591374 Training loss: 0.0
2025-12-09 10:23:32.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 3142 LR: 0.000999977147842227 Training loss: 0.0
2025-12-09 10:23:32.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 3143 LR: 0.0009999771328203812 Training loss: 0.0
2025-12-09 10:23:32.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 3144 LR: 0.0009999771177936 Training loss: 0.0
2025-12-09 10:23:32.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 3145 LR: 0.000999977102761883 Training loss: 0.0
2025-12-09 10:23:32.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 3146 LR: 0.0009999770877252303 Training loss: 0.0
2025-12-09 10:23:32.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 3147 LR: 0.0009999770726836423 Training loss: 0.0
2025-12-09 10:23:32.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 3148 LR: 0.0009999770576371186 Training loss: 0.0
2025-12-09 10:23:32.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 3149 LR: 0.0009999770425856594 Training loss: 0.0
2025-12-09 10:23:32.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 3150 LR: 0.0009999770275292647 Training loss: 0.0
2025-12-09 10:23:32.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 3151 LR: 0.0009999770124679344 Training loss: 0.0
2025-12-09 10:23:32.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 3152 LR: 0.0009999769974016683 Training loss: 0.0
2025-12-09 10:23:32.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 3153 LR: 0.000999976982330467 Training loss: 0.0
2025-12-09 10:23:32.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 3154 LR: 0.0009999769672543299 Training loss: 0.0
2025-12-09 10:23:32.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 3155 LR: 0.0009999769521732574 Training loss: 0.0
2025-12-09 10:23:32.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 3156 LR: 0.0009999769370872492 Training loss: 0.0
2025-12-09 10:23:32.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 3157 LR: 0.0009999769219963056 Training loss: 0.0
2025-12-09 10:23:32.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 3158 LR: 0.0009999769069004264 Training loss: 0.0
2025-12-09 10:23:32.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 3159 LR: 0.0009999768917996114 Training loss: 0.0
2025-12-09 10:23:32.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 3160 LR: 0.000999976876693861 Training loss: 0.0
2025-12-09 10:23:32.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 3161 LR: 0.000999976861583175 Training loss: 0.0
2025-12-09 10:23:32.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 3162 LR: 0.0009999768464675537 Training loss: 0.0
2025-12-09 10:23:32.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 3163 LR: 0.0009999768313469965 Training loss: 0.0
2025-12-09 10:23:32.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 3164 LR: 0.0009999768162215039 Training loss: 0.0
2025-12-09 10:23:32.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 3165 LR: 0.0009999768010910757 Training loss: 0.0
2025-12-09 10:23:32.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 3166 LR: 0.0009999767859557118 Training loss: 0.0
2025-12-09 10:23:32.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 3167 LR: 0.0009999767708154127 Training loss: 0.0
2025-12-09 10:23:32.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 3168 LR: 0.0009999767556701778 Training loss: 0.0
2025-12-09 10:23:32.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 3169 LR: 0.0009999767405200074 Training loss: 0.0
2025-12-09 10:23:32.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 3170 LR: 0.0009999767253649013 Training loss: 0.0
2025-12-09 10:23:32.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 3171 LR: 0.0009999767102048598 Training loss: 0.0
2025-12-09 10:23:32.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 3172 LR: 0.0009999766950398827 Training loss: 0.0
2025-12-09 10:23:32.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 3173 LR: 0.00099997667986997 Training loss: 0.0
2025-12-09 10:23:32.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 3174 LR: 0.0009999766646951217 Training loss: 0.0
2025-12-09 10:23:32.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 3175 LR: 0.0009999766495153379 Training loss: 0.0
2025-12-09 10:23:32.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 3176 LR: 0.0009999766343306185 Training loss: 0.0
2025-12-09 10:23:32.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 3177 LR: 0.0009999766191409636 Training loss: 0.0
2025-12-09 10:23:32.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 3178 LR: 0.0009999766039463732 Training loss: 0.0
2025-12-09 10:23:32.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 3179 LR: 0.0009999765887468474 Training loss: 0.0
2025-12-09 10:23:32.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 3180 LR: 0.0009999765735423855 Training loss: 0.0
2025-12-09 10:23:32.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 3181 LR: 0.0009999765583329884 Training loss: 0.0
2025-12-09 10:23:32.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 3182 LR: 0.0009999765431186558 Training loss: 0.0
2025-12-09 10:23:32.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 3183 LR: 0.0009999765278993875 Training loss: 0.0
2025-12-09 10:23:32.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 3184 LR: 0.0009999765126751838 Training loss: 0.0
2025-12-09 10:23:32.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 3185 LR: 0.0009999764974460443 Training loss: 0.0
2025-12-09 10:23:32.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 3186 LR: 0.0009999764822119694 Training loss: 0.0
2025-12-09 10:23:32.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 3187 LR: 0.0009999764669729589 Training loss: 0.0
2025-12-09 10:23:32.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 3188 LR: 0.0009999764517290128 Training loss: 0.0
2025-12-09 10:23:32.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 3189 LR: 0.0009999764364801314 Training loss: 0.0
2025-12-09 10:23:32.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 3190 LR: 0.000999976421226314 Training loss: 0.0
2025-12-09 10:23:32.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 3191 LR: 0.0009999764059675615 Training loss: 0.0
2025-12-09 10:23:32.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 3192 LR: 0.0009999763907038732 Training loss: 0.0
2025-12-09 10:23:32.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 3193 LR: 0.0009999763754352494 Training loss: 0.0
2025-12-09 10:23:32.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 3194 LR: 0.00099997636016169 Training loss: 0.0
2025-12-09 10:23:32.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 3195 LR: 0.0009999763448831952 Training loss: 0.0
2025-12-09 10:23:32.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 3196 LR: 0.0009999763295997647 Training loss: 0.0
2025-12-09 10:23:32.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 3197 LR: 0.0009999763143113984 Training loss: 0.0
2025-12-09 10:23:32.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 3198 LR: 0.000999976299018097 Training loss: 0.0
2025-12-09 10:23:32.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 3199 LR: 0.0009999762837198597 Training loss: 0.0
2025-12-09 10:23:32.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 3200 LR: 0.0009999762684166872 Training loss: 0.0
2025-12-09 10:23:32.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 3201 LR: 0.0009999762531085787 Training loss: 0.0
2025-12-09 10:23:32.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 3202 LR: 0.0009999762377955349 Training loss: 0.0
2025-12-09 10:23:32.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 3203 LR: 0.0009999762224775556 Training loss: 0.0
2025-12-09 10:23:32.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 3204 LR: 0.0009999762071546405 Training loss: 0.0
2025-12-09 10:23:32.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 3205 LR: 0.0009999761918267902 Training loss: 0.0
2025-12-09 10:23:32.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 3206 LR: 0.0009999761764940042 Training loss: 0.0
2025-12-09 10:23:32.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 3207 LR: 0.0009999761611562826 Training loss: 0.0
2025-12-09 10:23:32.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 3208 LR: 0.0009999761458136254 Training loss: 0.0
2025-12-09 10:23:32.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 3209 LR: 0.0009999761304660326 Training loss: 0.0
2025-12-09 10:23:32.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 3210 LR: 0.0009999761151135043 Training loss: 0.0
2025-12-09 10:23:32.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 3211 LR: 0.0009999760997560405 Training loss: 0.0
2025-12-09 10:23:32.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 3212 LR: 0.0009999760843936412 Training loss: 0.0
2025-12-09 10:23:32.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 3213 LR: 0.0009999760690263062 Training loss: 0.0
2025-12-09 10:23:32.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 3214 LR: 0.000999976053654036 Training loss: 0.0
2025-12-09 10:23:32.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 3215 LR: 0.00099997603827683 Training loss: 0.0
2025-12-09 10:23:32.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 3216 LR: 0.0009999760228946882 Training loss: 0.0
2025-12-09 10:23:32.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 3217 LR: 0.0009999760075076111 Training loss: 0.0
2025-12-09 10:23:32.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 3218 LR: 0.0009999759921155984 Training loss: 0.0
2025-12-09 10:23:32.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 3219 LR: 0.0009999759767186501 Training loss: 0.0
2025-12-09 10:23:32.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 3220 LR: 0.0009999759613167664 Training loss: 0.0
2025-12-09 10:23:32.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 3221 LR: 0.0009999759459099471 Training loss: 0.0
2025-12-09 10:23:32.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 3222 LR: 0.0009999759304981921 Training loss: 0.0
2025-12-09 10:23:32.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 3223 LR: 0.0009999759150815018 Training loss: 0.0
2025-12-09 10:23:32.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 3224 LR: 0.0009999758996598758 Training loss: 0.0
2025-12-09 10:23:32.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 3225 LR: 0.0009999758842333141 Training loss: 0.0
2025-12-09 10:23:32.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 3226 LR: 0.0009999758688018171 Training loss: 0.0
2025-12-09 10:23:32.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 3227 LR: 0.0009999758533653844 Training loss: 0.0
2025-12-09 10:23:32.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 3228 LR: 0.0009999758379240161 Training loss: 0.0
2025-12-09 10:23:32.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 3229 LR: 0.0009999758224777124 Training loss: 0.0
2025-12-09 10:23:32.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 3230 LR: 0.0009999758070264732 Training loss: 0.0
2025-12-09 10:23:32.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 3231 LR: 0.0009999757915702982 Training loss: 0.0
2025-12-09 10:23:32.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 3232 LR: 0.000999975776109188 Training loss: 0.0
2025-12-09 10:23:32.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 3233 LR: 0.000999975760643142 Training loss: 0.0
2025-12-09 10:23:32.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 3234 LR: 0.0009999757451721605 Training loss: 0.0
2025-12-09 10:23:32.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 3235 LR: 0.0009999757296962435 Training loss: 0.0
2025-12-09 10:23:32.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 3236 LR: 0.000999975714215391 Training loss: 0.0
2025-12-09 10:23:32.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 3237 LR: 0.0009999756987296028 Training loss: 0.0
2025-12-09 10:23:32.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 3238 LR: 0.000999975683238879 Training loss: 0.0
2025-12-09 10:23:32.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 3239 LR: 0.0009999756677432196 Training loss: 0.0
2025-12-09 10:23:32.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 3240 LR: 0.0009999756522426249 Training loss: 0.0
2025-12-09 10:23:32.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 3241 LR: 0.0009999756367370946 Training loss: 0.0
2025-12-09 10:23:32.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 3242 LR: 0.0009999756212266287 Training loss: 0.0
2025-12-09 10:23:32.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 3243 LR: 0.0009999756057112272 Training loss: 0.0
2025-12-09 10:23:32.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 3244 LR: 0.0009999755901908903 Training loss: 0.0
2025-12-09 10:23:32.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 3245 LR: 0.0009999755746656178 Training loss: 0.0
2025-12-09 10:23:32.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 3246 LR: 0.0009999755591354096 Training loss: 0.0
2025-12-09 10:23:32.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 3247 LR: 0.000999975543600266 Training loss: 0.0
2025-12-09 10:23:32.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 3248 LR: 0.0009999755280601867 Training loss: 0.0
2025-12-09 10:23:32.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 3249 LR: 0.0009999755125151722 Training loss: 0.0
2025-12-09 10:23:32.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 3250 LR: 0.0009999754969652217 Training loss: 0.0
2025-12-09 10:23:32.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 3251 LR: 0.0009999754814103358 Training loss: 0.0
2025-12-09 10:23:32.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 3252 LR: 0.0009999754658505146 Training loss: 0.0
2025-12-09 10:23:32.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 3253 LR: 0.0009999754502857576 Training loss: 0.0
2025-12-09 10:23:32.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 3254 LR: 0.0009999754347160652 Training loss: 0.0
2025-12-09 10:23:32.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 3255 LR: 0.0009999754191414372 Training loss: 0.0
2025-12-09 10:23:32.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 3256 LR: 0.0009999754035618735 Training loss: 0.0
2025-12-09 10:23:32.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 3257 LR: 0.0009999753879773746 Training loss: 0.0
2025-12-09 10:23:32.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 3258 LR: 0.0009999753723879399 Training loss: 0.0
2025-12-09 10:23:32.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 3259 LR: 0.0009999753567935697 Training loss: 0.0
2025-12-09 10:23:32.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 3260 LR: 0.000999975341194264 Training loss: 0.0
2025-12-09 10:23:32.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 3261 LR: 0.0009999753255900226 Training loss: 0.0
2025-12-09 10:23:32.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 3262 LR: 0.0009999753099808456 Training loss: 0.0
2025-12-09 10:23:32.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 3263 LR: 0.0009999752943667334 Training loss: 0.0
2025-12-09 10:23:32.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 3264 LR: 0.0009999752787476855 Training loss: 0.0
2025-12-09 10:23:32.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 3265 LR: 0.000999975263123702 Training loss: 0.0
2025-12-09 10:23:32.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 3266 LR: 0.0009999752474947829 Training loss: 0.0
2025-12-09 10:23:32.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 3267 LR: 0.0009999752318609284 Training loss: 0.0
2025-12-09 10:23:32.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 3268 LR: 0.0009999752162221382 Training loss: 0.0
2025-12-09 10:23:32.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 3269 LR: 0.0009999752005784126 Training loss: 0.0
2025-12-09 10:23:32.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 3270 LR: 0.0009999751849297516 Training loss: 0.0
2025-12-09 10:23:32.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 3271 LR: 0.0009999751692761547 Training loss: 0.0
2025-12-09 10:23:32.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 3272 LR: 0.0009999751536176225 Training loss: 0.0
2025-12-09 10:23:32.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 3273 LR: 0.0009999751379541546 Training loss: 0.0
2025-12-09 10:23:32.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 3274 LR: 0.0009999751222857511 Training loss: 0.0
2025-12-09 10:23:32.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 3275 LR: 0.0009999751066124122 Training loss: 0.0
2025-12-09 10:23:32.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 3276 LR: 0.0009999750909341378 Training loss: 0.0
2025-12-09 10:23:32.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 3277 LR: 0.0009999750752509278 Training loss: 0.0
2025-12-09 10:23:32.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 3278 LR: 0.0009999750595627824 Training loss: 0.0
2025-12-09 10:23:32.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 3279 LR: 0.0009999750438697012 Training loss: 0.0
2025-12-09 10:23:32.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 3280 LR: 0.0009999750281716846 Training loss: 0.0
2025-12-09 10:23:32.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 3281 LR: 0.0009999750124687324 Training loss: 0.0
2025-12-09 10:23:32.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 3282 LR: 0.0009999749967608447 Training loss: 0.0
2025-12-09 10:23:32.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 3283 LR: 0.0009999749810480215 Training loss: 0.0
2025-12-09 10:23:32.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 3284 LR: 0.0009999749653302626 Training loss: 0.0
2025-12-09 10:23:32.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 3285 LR: 0.0009999749496075682 Training loss: 0.0
2025-12-09 10:23:32.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 3286 LR: 0.0009999749338799383 Training loss: 0.0
2025-12-09 10:23:32.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 3287 LR: 0.000999974918147373 Training loss: 0.0
2025-12-09 10:23:32.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 3288 LR: 0.000999974902409872 Training loss: 0.0
2025-12-09 10:23:32.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 3289 LR: 0.0009999748866674355 Training loss: 0.0
2025-12-09 10:23:32.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 3290 LR: 0.0009999748709200633 Training loss: 0.0
2025-12-09 10:23:32.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 3291 LR: 0.0009999748551677557 Training loss: 0.0
2025-12-09 10:23:32.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 3292 LR: 0.0009999748394105125 Training loss: 0.0
2025-12-09 10:23:32.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 3293 LR: 0.0009999748236483338 Training loss: 0.0
2025-12-09 10:23:32.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 3294 LR: 0.0009999748078812196 Training loss: 0.0
2025-12-09 10:23:32.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 3295 LR: 0.00099997479210917 Training loss: 0.0
2025-12-09 10:23:32.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 3296 LR: 0.0009999747763321848 Training loss: 0.0
2025-12-09 10:23:32.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 3297 LR: 0.0009999747605502639 Training loss: 0.0
2025-12-09 10:23:32.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 3298 LR: 0.0009999747447634075 Training loss: 0.0
2025-12-09 10:23:32.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 3299 LR: 0.0009999747289716155 Training loss: 0.0
2025-12-09 10:23:32.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 3300 LR: 0.0009999747131748881 Training loss: 0.0
2025-12-09 10:23:32.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 3301 LR: 0.0009999746973732252 Training loss: 0.0
2025-12-09 10:23:32.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 3302 LR: 0.0009999746815666265 Training loss: 0.0
2025-12-09 10:23:32.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 3303 LR: 0.0009999746657550924 Training loss: 0.0
2025-12-09 10:23:32.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 3304 LR: 0.000999974649938623 Training loss: 0.0
2025-12-09 10:23:32.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 3305 LR: 0.0009999746341172178 Training loss: 0.0
2025-12-09 10:23:32.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 3306 LR: 0.0009999746182908769 Training loss: 0.0
2025-12-09 10:23:32.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 3307 LR: 0.0009999746024596007 Training loss: 0.0
2025-12-09 10:23:32.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 3308 LR: 0.000999974586623389 Training loss: 0.0
2025-12-09 10:23:32.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 3309 LR: 0.0009999745707822416 Training loss: 0.0
2025-12-09 10:23:32.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 3310 LR: 0.0009999745549361587 Training loss: 0.0
2025-12-09 10:23:32.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 3311 LR: 0.0009999745390851405 Training loss: 0.0
2025-12-09 10:23:32.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 3312 LR: 0.0009999745232291864 Training loss: 0.0
2025-12-09 10:23:32.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 3313 LR: 0.000999974507368297 Training loss: 0.0
2025-12-09 10:23:32.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 3314 LR: 0.000999974491502472 Training loss: 0.0
2025-12-09 10:23:32.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 3315 LR: 0.0009999744756317116 Training loss: 0.0
2025-12-09 10:23:32.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 3316 LR: 0.0009999744597560154 Training loss: 0.0
2025-12-09 10:23:32.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 3317 LR: 0.0009999744438753838 Training loss: 0.0
2025-12-09 10:23:32.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 3318 LR: 0.0009999744279898166 Training loss: 0.0
2025-12-09 10:23:32.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 3319 LR: 0.000999974412099314 Training loss: 0.0
2025-12-09 10:23:32.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 3320 LR: 0.0009999743962038757 Training loss: 0.0
2025-12-09 10:23:32.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 3321 LR: 0.000999974380303502 Training loss: 0.0
2025-12-09 10:23:32.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 3322 LR: 0.0009999743643981927 Training loss: 0.0
2025-12-09 10:23:32.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 3323 LR: 0.0009999743484879477 Training loss: 0.0
2025-12-09 10:23:32.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 3324 LR: 0.0009999743325727675 Training loss: 0.0
2025-12-09 10:23:32.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 3325 LR: 0.0009999743166526516 Training loss: 0.0
2025-12-09 10:23:32.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 3326 LR: 0.0009999743007276002 Training loss: 0.0
2025-12-09 10:23:32.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 3327 LR: 0.000999974284797613 Training loss: 0.0
2025-12-09 10:23:32.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 3328 LR: 0.0009999742688626906 Training loss: 0.0
2025-12-09 10:23:32.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 3329 LR: 0.0009999742529228325 Training loss: 0.0
2025-12-09 10:23:32.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 3330 LR: 0.000999974236978039 Training loss: 0.0
2025-12-09 10:23:32.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 3331 LR: 0.0009999742210283098 Training loss: 0.0
2025-12-09 10:23:32.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 3332 LR: 0.0009999742050736452 Training loss: 0.0
2025-12-09 10:23:32.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 3333 LR: 0.000999974189114045 Training loss: 0.0
2025-12-09 10:23:32.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 3334 LR: 0.0009999741731495093 Training loss: 0.0
2025-12-09 10:23:32.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 3335 LR: 0.0009999741571800381 Training loss: 0.0
2025-12-09 10:23:32.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 3336 LR: 0.0009999741412056312 Training loss: 0.0
2025-12-09 10:23:32.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 3337 LR: 0.0009999741252262888 Training loss: 0.0
2025-12-09 10:23:32.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 3338 LR: 0.000999974109242011 Training loss: 0.0
2025-12-09 10:23:32.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 3339 LR: 0.0009999740932527977 Training loss: 0.0
2025-12-09 10:23:32.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 3340 LR: 0.0009999740772586487 Training loss: 0.0
2025-12-09 10:23:32.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 3341 LR: 0.0009999740612595643 Training loss: 0.0
2025-12-09 10:23:32.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 3342 LR: 0.0009999740452555441 Training loss: 0.0
2025-12-09 10:23:32.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 3343 LR: 0.0009999740292465887 Training loss: 0.0
2025-12-09 10:23:32.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 3344 LR: 0.0009999740132326978 Training loss: 0.0
2025-12-09 10:23:32.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 3345 LR: 0.000999973997213871 Training loss: 0.0
2025-12-09 10:23:32.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 3346 LR: 0.000999973981190109 Training loss: 0.0
2025-12-09 10:23:32.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 3347 LR: 0.0009999739651614112 Training loss: 0.0
2025-12-09 10:23:32.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 3348 LR: 0.0009999739491277782 Training loss: 0.0
2025-12-09 10:23:32.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 3349 LR: 0.0009999739330892093 Training loss: 0.0
2025-12-09 10:23:32.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 3350 LR: 0.0009999739170457051 Training loss: 0.0
2025-12-09 10:23:32.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 3351 LR: 0.0009999739009972652 Training loss: 0.0
2025-12-09 10:23:32.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 3352 LR: 0.00099997388494389 Training loss: 0.0
2025-12-09 10:23:32.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 3353 LR: 0.000999973868885579 Training loss: 0.0
2025-12-09 10:23:32.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 3354 LR: 0.0009999738528223329 Training loss: 0.0
2025-12-09 10:23:32.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 3355 LR: 0.000999973836754151 Training loss: 0.0
2025-12-09 10:23:32.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 3356 LR: 0.0009999738206810335 Training loss: 0.0
2025-12-09 10:23:32.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 3357 LR: 0.0009999738046029805 Training loss: 0.0
2025-12-09 10:23:32.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 3358 LR: 0.000999973788519992 Training loss: 0.0
2025-12-09 10:23:32.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 3359 LR: 0.0009999737724320679 Training loss: 0.0
2025-12-09 10:23:32.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 3360 LR: 0.0009999737563392084 Training loss: 0.0
2025-12-09 10:23:32.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 3361 LR: 0.0009999737402414132 Training loss: 0.0
2025-12-09 10:23:32.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 3362 LR: 0.0009999737241386825 Training loss: 0.0
2025-12-09 10:23:32.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 3363 LR: 0.0009999737080310165 Training loss: 0.0
2025-12-09 10:23:32.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 3364 LR: 0.0009999736919184148 Training loss: 0.0
2025-12-09 10:23:32.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 3365 LR: 0.0009999736758008774 Training loss: 0.0
2025-12-09 10:23:32.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 3366 LR: 0.0009999736596784047 Training loss: 0.0
2025-12-09 10:23:32.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 3367 LR: 0.0009999736435509965 Training loss: 0.0
2025-12-09 10:23:32.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 3368 LR: 0.0009999736274186528 Training loss: 0.0
2025-12-09 10:23:32.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 3369 LR: 0.0009999736112813735 Training loss: 0.0
2025-12-09 10:23:32.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 3370 LR: 0.0009999735951391586 Training loss: 0.0
2025-12-09 10:23:32.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 3371 LR: 0.0009999735789920081 Training loss: 0.0
2025-12-09 10:23:32.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 3372 LR: 0.0009999735628399222 Training loss: 0.0
2025-12-09 10:23:32.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 3373 LR: 0.0009999735466829007 Training loss: 0.0
2025-12-09 10:23:32.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 3374 LR: 0.000999973530520944 Training loss: 0.0
2025-12-09 10:23:32.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 3375 LR: 0.0009999735143540515 Training loss: 0.0
2025-12-09 10:23:32.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 3376 LR: 0.0009999734981822233 Training loss: 0.0
2025-12-09 10:23:32.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 3377 LR: 0.0009999734820054598 Training loss: 0.0
2025-12-09 10:23:32.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 3378 LR: 0.0009999734658237608 Training loss: 0.0
2025-12-09 10:23:32.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 3379 LR: 0.000999973449637126 Training loss: 0.0
2025-12-09 10:23:32.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 3380 LR: 0.0009999734334455558 Training loss: 0.0
2025-12-09 10:23:32.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 3381 LR: 0.0009999734172490501 Training loss: 0.0
2025-12-09 10:23:32.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 3382 LR: 0.000999973401047609 Training loss: 0.0
2025-12-09 10:23:32.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 3383 LR: 0.0009999733848412322 Training loss: 0.0
2025-12-09 10:23:32.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 3384 LR: 0.0009999733686299201 Training loss: 0.0
2025-12-09 10:23:32.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 3385 LR: 0.0009999733524136722 Training loss: 0.0
2025-12-09 10:23:32.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 3386 LR: 0.000999973336192489 Training loss: 0.0
2025-12-09 10:23:32.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 3387 LR: 0.0009999733199663702 Training loss: 0.0
2025-12-09 10:23:32.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 3388 LR: 0.000999973303735316 Training loss: 0.0
2025-12-09 10:23:32.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 3389 LR: 0.000999973287499326 Training loss: 0.0
2025-12-09 10:23:32.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 3390 LR: 0.0009999732712584006 Training loss: 0.0
2025-12-09 10:23:32.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 3391 LR: 0.0009999732550125397 Training loss: 0.0
2025-12-09 10:23:32.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 3392 LR: 0.0009999732387617432 Training loss: 0.0
2025-12-09 10:23:32.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 3393 LR: 0.0009999732225060111 Training loss: 0.0
2025-12-09 10:23:32.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 3394 LR: 0.0009999732062453436 Training loss: 0.0
2025-12-09 10:23:32.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 3395 LR: 0.0009999731899797406 Training loss: 0.0
2025-12-09 10:23:32.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 3396 LR: 0.000999973173709202 Training loss: 0.0
2025-12-09 10:23:32.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 3397 LR: 0.000999973157433728 Training loss: 0.0
2025-12-09 10:23:32.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 3398 LR: 0.0009999731411533183 Training loss: 0.0
2025-12-09 10:23:32.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 3399 LR: 0.0009999731248679733 Training loss: 0.0
2025-12-09 10:23:32.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 3400 LR: 0.0009999731085776925 Training loss: 0.0
2025-12-09 10:23:32.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 3401 LR: 0.0009999730922824765 Training loss: 0.0
2025-12-09 10:23:32.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 3402 LR: 0.0009999730759823247 Training loss: 0.0
2025-12-09 10:23:32.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 3403 LR: 0.0009999730596772375 Training loss: 0.0
2025-12-09 10:23:32.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 3404 LR: 0.0009999730433672147 Training loss: 0.0
2025-12-09 10:23:32.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 3405 LR: 0.0009999730270522564 Training loss: 0.0
2025-12-09 10:23:32.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 3406 LR: 0.0009999730107323628 Training loss: 0.0
2025-12-09 10:23:32.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 3407 LR: 0.0009999729944075333 Training loss: 0.0
2025-12-09 10:23:32.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 3408 LR: 0.0009999729780777685 Training loss: 0.0
2025-12-09 10:23:32.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 3409 LR: 0.0009999729617430682 Training loss: 0.0
2025-12-09 10:23:32.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 3410 LR: 0.0009999729454034322 Training loss: 0.0
2025-12-09 10:23:32.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 3411 LR: 0.0009999729290588609 Training loss: 0.0
2025-12-09 10:23:32.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 3412 LR: 0.000999972912709354 Training loss: 0.0
2025-12-09 10:23:32.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 3413 LR: 0.0009999728963549115 Training loss: 0.0
2025-12-09 10:23:32.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 3414 LR: 0.0009999728799955337 Training loss: 0.0
2025-12-09 10:23:32.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 3415 LR: 0.0009999728636312202 Training loss: 0.0
2025-12-09 10:23:32.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 3416 LR: 0.000999972847261971 Training loss: 0.0
2025-12-09 10:23:32.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 3417 LR: 0.0009999728308877865 Training loss: 0.0
2025-12-09 10:23:32.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 3418 LR: 0.0009999728145086665 Training loss: 0.0
2025-12-09 10:23:32.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 3419 LR: 0.000999972798124611 Training loss: 0.0
2025-12-09 10:23:32.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 3420 LR: 0.0009999727817356198 Training loss: 0.0
2025-12-09 10:23:32.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 3421 LR: 0.0009999727653416932 Training loss: 0.0
2025-12-09 10:23:32.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 3422 LR: 0.0009999727489428312 Training loss: 0.0
2025-12-09 10:23:32.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 3423 LR: 0.0009999727325390334 Training loss: 0.0
2025-12-09 10:23:32.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 3424 LR: 0.0009999727161303003 Training loss: 0.0
2025-12-09 10:23:32.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 3425 LR: 0.0009999726997166314 Training loss: 0.0
2025-12-09 10:23:32.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 3426 LR: 0.0009999726832980273 Training loss: 0.0
2025-12-09 10:23:32.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 3427 LR: 0.0009999726668744875 Training loss: 0.0
2025-12-09 10:23:32.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 3428 LR: 0.0009999726504460122 Training loss: 0.0
2025-12-09 10:23:32.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 3429 LR: 0.0009999726340126015 Training loss: 0.0
2025-12-09 10:23:32.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 3430 LR: 0.0009999726175742552 Training loss: 0.0
2025-12-09 10:23:32.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 3431 LR: 0.0009999726011309734 Training loss: 0.0
2025-12-09 10:23:32.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 3432 LR: 0.000999972584682756 Training loss: 0.0
2025-12-09 10:23:32.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 3433 LR: 0.0009999725682296034 Training loss: 0.0
2025-12-09 10:23:32.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 3434 LR: 0.0009999725517715148 Training loss: 0.0
2025-12-09 10:23:32.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 3435 LR: 0.000999972535308491 Training loss: 0.0
2025-12-09 10:23:32.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 3436 LR: 0.0009999725188405315 Training loss: 0.0
2025-12-09 10:23:32.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 3437 LR: 0.0009999725023676367 Training loss: 0.0
2025-12-09 10:23:32.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 3438 LR: 0.0009999724858898063 Training loss: 0.0
2025-12-09 10:23:32.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 3439 LR: 0.0009999724694070402 Training loss: 0.0
2025-12-09 10:23:32.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 3440 LR: 0.0009999724529193388 Training loss: 0.0
2025-12-09 10:23:32.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 3441 LR: 0.0009999724364267019 Training loss: 0.0
2025-12-09 10:23:32.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 3442 LR: 0.0009999724199291292 Training loss: 0.0
2025-12-09 10:23:32.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 3443 LR: 0.0009999724034266211 Training loss: 0.0
2025-12-09 10:23:32.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 3444 LR: 0.0009999723869191777 Training loss: 0.0
2025-12-09 10:23:32.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 3445 LR: 0.0009999723704067986 Training loss: 0.0
2025-12-09 10:23:32.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 3446 LR: 0.0009999723538894841 Training loss: 0.0
2025-12-09 10:23:32.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 3447 LR: 0.000999972337367234 Training loss: 0.0
2025-12-09 10:23:32.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 3448 LR: 0.0009999723208400483 Training loss: 0.0
2025-12-09 10:23:32.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 3449 LR: 0.0009999723043079272 Training loss: 0.0
2025-12-09 10:23:32.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 3450 LR: 0.0009999722877708705 Training loss: 0.0
2025-12-09 10:23:32.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 3451 LR: 0.0009999722712288783 Training loss: 0.0
2025-12-09 10:23:32.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 3452 LR: 0.0009999722546819507 Training loss: 0.0
2025-12-09 10:23:32.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 3453 LR: 0.0009999722381300875 Training loss: 0.0
2025-12-09 10:23:32.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 3454 LR: 0.0009999722215732888 Training loss: 0.0
2025-12-09 10:23:32.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 3455 LR: 0.0009999722050115544 Training loss: 0.0
2025-12-09 10:23:32.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 3456 LR: 0.000999972188444885 Training loss: 0.0
2025-12-09 10:23:32.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 3457 LR: 0.0009999721718732795 Training loss: 0.0
2025-12-09 10:23:32.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 3458 LR: 0.0009999721552967388 Training loss: 0.0
2025-12-09 10:23:32.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 3459 LR: 0.0009999721387152626 Training loss: 0.0
2025-12-09 10:23:32.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 3460 LR: 0.0009999721221288507 Training loss: 0.0
2025-12-09 10:23:32.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 3461 LR: 0.0009999721055375034 Training loss: 0.0
2025-12-09 10:23:32.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 3462 LR: 0.0009999720889412205 Training loss: 0.0
2025-12-09 10:23:32.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 3463 LR: 0.0009999720723400023 Training loss: 0.0
2025-12-09 10:23:32.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 3464 LR: 0.0009999720557338483 Training loss: 0.0
2025-12-09 10:23:32.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 3465 LR: 0.000999972039122759 Training loss: 0.0
2025-12-09 10:23:32.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 3466 LR: 0.0009999720225067341 Training loss: 0.0
2025-12-09 10:23:32.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 3467 LR: 0.0009999720058857737 Training loss: 0.0
2025-12-09 10:23:32.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 3468 LR: 0.000999971989259878 Training loss: 0.0
2025-12-09 10:23:32.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 3469 LR: 0.0009999719726290464 Training loss: 0.0
2025-12-09 10:23:32.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 3470 LR: 0.0009999719559932797 Training loss: 0.0
2025-12-09 10:23:32.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 3471 LR: 0.0009999719393525772 Training loss: 0.0
2025-12-09 10:23:32.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 3472 LR: 0.0009999719227069392 Training loss: 0.0
2025-12-09 10:23:32.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 3473 LR: 0.0009999719060563657 Training loss: 0.0
2025-12-09 10:23:32.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 3474 LR: 0.0009999718894008567 Training loss: 0.0
2025-12-09 10:23:32.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 3475 LR: 0.0009999718727404122 Training loss: 0.0
2025-12-09 10:23:32.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 3476 LR: 0.0009999718560750321 Training loss: 0.0
2025-12-09 10:23:32.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 3477 LR: 0.0009999718394047166 Training loss: 0.0
2025-12-09 10:23:32.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 3478 LR: 0.0009999718227294656 Training loss: 0.0
2025-12-09 10:23:32.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 3479 LR: 0.000999971806049279 Training loss: 0.0
2025-12-09 10:23:32.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 3480 LR: 0.000999971789364157 Training loss: 0.0
2025-12-09 10:23:32.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 3481 LR: 0.0009999717726740995 Training loss: 0.0
2025-12-09 10:23:32.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 3482 LR: 0.0009999717559791065 Training loss: 0.0
2025-12-09 10:23:32.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 3483 LR: 0.000999971739279178 Training loss: 0.0
2025-12-09 10:23:32.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 3484 LR: 0.0009999717225743139 Training loss: 0.0
2025-12-09 10:23:32.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 3485 LR: 0.000999971705864514 Training loss: 0.0
2025-12-09 10:23:32.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 3486 LR: 0.000999971689149779 Training loss: 0.0
2025-12-09 10:23:32.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 3487 LR: 0.0009999716724301084 Training loss: 0.0
2025-12-09 10:23:32.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 3488 LR: 0.0009999716557055024 Training loss: 0.0
2025-12-09 10:23:32.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 3489 LR: 0.0009999716389759608 Training loss: 0.0
2025-12-09 10:23:32.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 3490 LR: 0.0009999716222414837 Training loss: 0.0
2025-12-09 10:23:32.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 3491 LR: 0.000999971605502071 Training loss: 0.0
2025-12-09 10:23:32.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 3492 LR: 0.0009999715887577228 Training loss: 0.0
2025-12-09 10:23:32.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 3493 LR: 0.000999971572008439 Training loss: 0.0
2025-12-09 10:23:32.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 3494 LR: 0.0009999715552542199 Training loss: 0.0
2025-12-09 10:23:32.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 3495 LR: 0.0009999715384950653 Training loss: 0.0
2025-12-09 10:23:32.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 3496 LR: 0.0009999715217309752 Training loss: 0.0
2025-12-09 10:23:32.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 3497 LR: 0.0009999715049619493 Training loss: 0.0
2025-12-09 10:23:32.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 3498 LR: 0.000999971488187988 Training loss: 0.0
2025-12-09 10:23:32.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 3499 LR: 0.0009999714714090913 Training loss: 0.0
2025-12-09 10:23:32.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 3500 LR: 0.0009999714546252592 Training loss: 0.0
2025-12-09 10:23:32.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 3501 LR: 0.0009999714378364913 Training loss: 0.0
2025-12-09 10:23:32.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 3502 LR: 0.0009999714210427882 Training loss: 0.0
2025-12-09 10:23:32.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 3503 LR: 0.0009999714042441495 Training loss: 0.0
2025-12-09 10:23:32.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 3504 LR: 0.0009999713874405752 Training loss: 0.0
2025-12-09 10:23:32.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 3505 LR: 0.0009999713706320653 Training loss: 0.0
2025-12-09 10:23:32.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 3506 LR: 0.0009999713538186201 Training loss: 0.0
2025-12-09 10:23:32.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 3507 LR: 0.0009999713370002392 Training loss: 0.0
2025-12-09 10:23:32.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 3508 LR: 0.0009999713201769228 Training loss: 0.0
2025-12-09 10:23:32.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 3509 LR: 0.0009999713033486712 Training loss: 0.0
2025-12-09 10:23:32.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 3510 LR: 0.000999971286515484 Training loss: 0.0
2025-12-09 10:23:32.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 3511 LR: 0.000999971269677361 Training loss: 0.0
2025-12-09 10:23:32.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 3512 LR: 0.0009999712528343029 Training loss: 0.0
2025-12-09 10:23:32.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 3513 LR: 0.000999971235986309 Training loss: 0.0
2025-12-09 10:23:32.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 3514 LR: 0.0009999712191333797 Training loss: 0.0
2025-12-09 10:23:32.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 3515 LR: 0.0009999712022755148 Training loss: 0.0
2025-12-09 10:23:32.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 3516 LR: 0.0009999711854127146 Training loss: 0.0
2025-12-09 10:23:32.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 3517 LR: 0.0009999711685449786 Training loss: 0.0
2025-12-09 10:23:32.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 3518 LR: 0.0009999711516723074 Training loss: 0.0
2025-12-09 10:23:32.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 3519 LR: 0.0009999711347947005 Training loss: 0.0
2025-12-09 10:23:32.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 3520 LR: 0.000999971117912158 Training loss: 0.0
2025-12-09 10:23:32.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 3521 LR: 0.0009999711010246803 Training loss: 0.0
2025-12-09 10:23:32.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 3522 LR: 0.0009999710841322668 Training loss: 0.0
2025-12-09 10:23:32.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 3523 LR: 0.000999971067234918 Training loss: 0.0
2025-12-09 10:23:32.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 3524 LR: 0.0009999710503326338 Training loss: 0.0
2025-12-09 10:23:32.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 3525 LR: 0.0009999710334254138 Training loss: 0.0
2025-12-09 10:23:32.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 3526 LR: 0.0009999710165132585 Training loss: 0.0
2025-12-09 10:23:32.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 3527 LR: 0.0009999709995961675 Training loss: 0.0
2025-12-09 10:23:32.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 3528 LR: 0.0009999709826741413 Training loss: 0.0
2025-12-09 10:23:32.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 3529 LR: 0.0009999709657471795 Training loss: 0.0
2025-12-09 10:23:32.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 3530 LR: 0.000999970948815282 Training loss: 0.0
2025-12-09 10:23:32.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 3531 LR: 0.000999970931878449 Training loss: 0.0
2025-12-09 10:23:32.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 3532 LR: 0.0009999709149366807 Training loss: 0.0
2025-12-09 10:23:32.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 3533 LR: 0.0009999708979899768 Training loss: 0.0
2025-12-09 10:23:32.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 3534 LR: 0.0009999708810383373 Training loss: 0.0
2025-12-09 10:23:32.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 3535 LR: 0.0009999708640817625 Training loss: 0.0
2025-12-09 10:23:32.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 3536 LR: 0.000999970847120252 Training loss: 0.0
2025-12-09 10:23:32.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 3537 LR: 0.0009999708301538061 Training loss: 0.0
2025-12-09 10:23:32.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 3538 LR: 0.0009999708131824248 Training loss: 0.0
2025-12-09 10:23:32.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 3539 LR: 0.000999970796206108 Training loss: 0.0
2025-12-09 10:23:32.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 3540 LR: 0.0009999707792248554 Training loss: 0.0
2025-12-09 10:23:32.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 3541 LR: 0.0009999707622386676 Training loss: 0.0
2025-12-09 10:23:32.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 3542 LR: 0.0009999707452475442 Training loss: 0.0
2025-12-09 10:23:32.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 3543 LR: 0.0009999707282514854 Training loss: 0.0
2025-12-09 10:23:32.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 3544 LR: 0.0009999707112504908 Training loss: 0.0
2025-12-09 10:23:32.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 3545 LR: 0.000999970694244561 Training loss: 0.0
2025-12-09 10:23:32.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 3546 LR: 0.0009999706772336955 Training loss: 0.0
2025-12-09 10:23:32.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 3547 LR: 0.0009999706602178947 Training loss: 0.0
2025-12-09 10:23:32.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 3548 LR: 0.0009999706431971583 Training loss: 0.0
2025-12-09 10:23:32.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 3549 LR: 0.0009999706261714862 Training loss: 0.0
2025-12-09 10:23:32.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 3550 LR: 0.000999970609140879 Training loss: 0.0
2025-12-09 10:23:32.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 3551 LR: 0.000999970592105336 Training loss: 0.0
2025-12-09 10:23:32.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 3552 LR: 0.0009999705750648575 Training loss: 0.0
2025-12-09 10:23:32.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 3553 LR: 0.0009999705580194438 Training loss: 0.0
2025-12-09 10:23:32.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 3554 LR: 0.0009999705409690942 Training loss: 0.0
2025-12-09 10:23:32.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 3555 LR: 0.0009999705239138095 Training loss: 0.0
2025-12-09 10:23:32.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 3556 LR: 0.000999970506853589 Training loss: 0.0
2025-12-09 10:23:32.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 3557 LR: 0.000999970489788433 Training loss: 0.0
2025-12-09 10:23:32.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 3558 LR: 0.0009999704727183417 Training loss: 0.0
2025-12-09 10:23:32.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 3559 LR: 0.000999970455643315 Training loss: 0.0
2025-12-09 10:23:32.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 3560 LR: 0.0009999704385633525 Training loss: 0.0
2025-12-09 10:23:32.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 3561 LR: 0.0009999704214784546 Training loss: 0.0
2025-12-09 10:23:32.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 3562 LR: 0.000999970404388621 Training loss: 0.0
2025-12-09 10:23:32.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 3563 LR: 0.0009999703872938524 Training loss: 0.0
2025-12-09 10:23:32.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 3564 LR: 0.0009999703701941479 Training loss: 0.0
2025-12-09 10:23:32.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 3565 LR: 0.0009999703530895081 Training loss: 0.0
2025-12-09 10:23:32.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 3566 LR: 0.0009999703359799327 Training loss: 0.0
2025-12-09 10:23:32.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 3567 LR: 0.000999970318865422 Training loss: 0.0
2025-12-09 10:23:32.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 3568 LR: 0.0009999703017459754 Training loss: 0.0
2025-12-09 10:23:32.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 3569 LR: 0.0009999702846215936 Training loss: 0.0
2025-12-09 10:23:32.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 3570 LR: 0.0009999702674922764 Training loss: 0.0
2025-12-09 10:23:32.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 3571 LR: 0.0009999702503580236 Training loss: 0.0
2025-12-09 10:23:32.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 3572 LR: 0.000999970233218835 Training loss: 0.0
2025-12-09 10:23:32.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 3573 LR: 0.0009999702160747113 Training loss: 0.0
2025-12-09 10:23:32.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 3574 LR: 0.000999970198925652 Training loss: 0.0
2025-12-09 10:23:32.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 3575 LR: 0.0009999701817716572 Training loss: 0.0
2025-12-09 10:23:32.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 3576 LR: 0.0009999701646127266 Training loss: 0.0
2025-12-09 10:23:32.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 3577 LR: 0.000999970147448861 Training loss: 0.0
2025-12-09 10:23:32.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 3578 LR: 0.0009999701302800595 Training loss: 0.0
2025-12-09 10:23:32.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 3579 LR: 0.000999970113106323 Training loss: 0.0
2025-12-09 10:23:32.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 3580 LR: 0.0009999700959276504 Training loss: 0.0
2025-12-09 10:23:32.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 3581 LR: 0.0009999700787440427 Training loss: 0.0
2025-12-09 10:23:32.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 3582 LR: 0.0009999700615554994 Training loss: 0.0
2025-12-09 10:23:32.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 3583 LR: 0.0009999700443620205 Training loss: 0.0
2025-12-09 10:23:32.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 3584 LR: 0.0009999700271636062 Training loss: 0.0
2025-12-09 10:23:33.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 3585 LR: 0.0009999700099602563 Training loss: 0.0
2025-12-09 10:23:33.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 3586 LR: 0.0009999699927519712 Training loss: 0.0
2025-12-09 10:23:33.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 3587 LR: 0.0009999699755387505 Training loss: 0.0
2025-12-09 10:23:33.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 3588 LR: 0.0009999699583205942 Training loss: 0.0
2025-12-09 10:23:33.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 3589 LR: 0.0009999699410975025 Training loss: 0.0
2025-12-09 10:23:33.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 3590 LR: 0.0009999699238694754 Training loss: 0.0
2025-12-09 10:23:33.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 3591 LR: 0.0009999699066365125 Training loss: 0.0
2025-12-09 10:23:33.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 3592 LR: 0.0009999698893986143 Training loss: 0.0
2025-12-09 10:23:33.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 3593 LR: 0.0009999698721557806 Training loss: 0.0
2025-12-09 10:23:33.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 3594 LR: 0.0009999698549080114 Training loss: 0.0
2025-12-09 10:23:33.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 3595 LR: 0.0009999698376553067 Training loss: 0.0
2025-12-09 10:23:33.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 3596 LR: 0.0009999698203976665 Training loss: 0.0
2025-12-09 10:23:33.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 3597 LR: 0.0009999698031350908 Training loss: 0.0
2025-12-09 10:23:33.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 3598 LR: 0.0009999697858675796 Training loss: 0.0
2025-12-09 10:23:33.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 3599 LR: 0.000999969768595133 Training loss: 0.0
2025-12-09 10:23:33.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 3600 LR: 0.0009999697513177507 Training loss: 0.0
2025-12-09 10:23:33.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 3601 LR: 0.0009999697340354332 Training loss: 0.0
2025-12-09 10:23:33.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 3602 LR: 0.00099996971674818 Training loss: 0.0
2025-12-09 10:23:33.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 3603 LR: 0.0009999696994559915 Training loss: 0.0
2025-12-09 10:23:33.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 3604 LR: 0.0009999696821588672 Training loss: 0.0
2025-12-09 10:23:33.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 3605 LR: 0.0009999696648568077 Training loss: 0.0
2025-12-09 10:23:33.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 3606 LR: 0.0009999696475498127 Training loss: 0.0
2025-12-09 10:23:33.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 3607 LR: 0.000999969630237882 Training loss: 0.0
2025-12-09 10:23:33.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 3608 LR: 0.0009999696129210159 Training loss: 0.0
2025-12-09 10:23:33.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 3609 LR: 0.0009999695955992143 Training loss: 0.0
2025-12-09 10:23:33.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 3610 LR: 0.0009999695782724773 Training loss: 0.0
2025-12-09 10:23:33.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 3611 LR: 0.0009999695609408047 Training loss: 0.0
2025-12-09 10:23:33.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 3612 LR: 0.0009999695436041967 Training loss: 0.0
2025-12-09 10:23:33.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 3613 LR: 0.000999969526262653 Training loss: 0.0
2025-12-09 10:23:33.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 3614 LR: 0.0009999695089161743 Training loss: 0.0
2025-12-09 10:23:33.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 3615 LR: 0.0009999694915647597 Training loss: 0.0
2025-12-09 10:23:33.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 3616 LR: 0.0009999694742084096 Training loss: 0.0
2025-12-09 10:23:33.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 3617 LR: 0.0009999694568471242 Training loss: 0.0
2025-12-09 10:23:33.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 3618 LR: 0.0009999694394809033 Training loss: 0.0
2025-12-09 10:23:33.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 3619 LR: 0.0009999694221097468 Training loss: 0.0
2025-12-09 10:23:33.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 3620 LR: 0.0009999694047336549 Training loss: 0.0
2025-12-09 10:23:33.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 3621 LR: 0.0009999693873526275 Training loss: 0.0
2025-12-09 10:23:33.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 3622 LR: 0.0009999693699666646 Training loss: 0.0
2025-12-09 10:23:33.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 3623 LR: 0.0009999693525757662 Training loss: 0.0
2025-12-09 10:23:33.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 3624 LR: 0.0009999693351799323 Training loss: 0.0
2025-12-09 10:23:33.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 3625 LR: 0.0009999693177791629 Training loss: 0.0
2025-12-09 10:23:33.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 3626 LR: 0.000999969300373458 Training loss: 0.0
2025-12-09 10:23:33.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 3627 LR: 0.0009999692829628177 Training loss: 0.0
2025-12-09 10:23:33.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 3628 LR: 0.0009999692655472418 Training loss: 0.0
2025-12-09 10:23:33.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 3629 LR: 0.0009999692481267306 Training loss: 0.0
2025-12-09 10:23:33.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 3630 LR: 0.0009999692307012837 Training loss: 0.0
2025-12-09 10:23:33.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 3631 LR: 0.0009999692132709014 Training loss: 0.0
2025-12-09 10:23:33.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 3632 LR: 0.0009999691958355837 Training loss: 0.0
2025-12-09 10:23:33.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 3633 LR: 0.0009999691783953305 Training loss: 0.0
2025-12-09 10:23:33.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 3634 LR: 0.0009999691609501417 Training loss: 0.0
2025-12-09 10:23:33.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 3635 LR: 0.0009999691435000175 Training loss: 0.0
2025-12-09 10:23:33.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 3636 LR: 0.0009999691260449577 Training loss: 0.0
2025-12-09 10:23:33.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 3637 LR: 0.0009999691085849625 Training loss: 0.0
2025-12-09 10:23:33.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 3638 LR: 0.000999969091120032 Training loss: 0.0
2025-12-09 10:23:33.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 3639 LR: 0.0009999690736501657 Training loss: 0.0
2025-12-09 10:23:33.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 3640 LR: 0.0009999690561753641 Training loss: 0.0
2025-12-09 10:23:33.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 3641 LR: 0.0009999690386956269 Training loss: 0.0
2025-12-09 10:23:33.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 3642 LR: 0.0009999690212109543 Training loss: 0.0
2025-12-09 10:23:33.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 3643 LR: 0.0009999690037213462 Training loss: 0.0
2025-12-09 10:23:33.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 3644 LR: 0.0009999689862268026 Training loss: 0.0
2025-12-09 10:23:33.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 3645 LR: 0.0009999689687273234 Training loss: 0.0
2025-12-09 10:23:33.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 3646 LR: 0.000999968951222909 Training loss: 0.0
2025-12-09 10:23:33.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 3647 LR: 0.000999968933713559 Training loss: 0.0
2025-12-09 10:23:33.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 3648 LR: 0.0009999689161992735 Training loss: 0.0
2025-12-09 10:23:33.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 3649 LR: 0.0009999688986800524 Training loss: 0.0
2025-12-09 10:23:33.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 3650 LR: 0.000999968881155896 Training loss: 0.0
2025-12-09 10:23:33.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 3651 LR: 0.0009999688636268041 Training loss: 0.0
2025-12-09 10:23:33.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 3652 LR: 0.0009999688460927765 Training loss: 0.0
2025-12-09 10:23:33.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 3653 LR: 0.0009999688285538136 Training loss: 0.0
2025-12-09 10:23:33.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 3654 LR: 0.0009999688110099152 Training loss: 0.0
2025-12-09 10:23:33.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 3655 LR: 0.0009999687934610813 Training loss: 0.0
2025-12-09 10:23:33.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 3656 LR: 0.0009999687759073119 Training loss: 0.0
2025-12-09 10:23:33.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 3657 LR: 0.000999968758348607 Training loss: 0.0
2025-12-09 10:23:33.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 3658 LR: 0.0009999687407849667 Training loss: 0.0
2025-12-09 10:23:33.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 3659 LR: 0.000999968723216391 Training loss: 0.0
2025-12-09 10:23:33.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 3660 LR: 0.0009999687056428796 Training loss: 0.0
2025-12-09 10:23:33.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 3661 LR: 0.0009999686880644329 Training loss: 0.0
2025-12-09 10:23:33.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 3662 LR: 0.0009999686704810506 Training loss: 0.0
2025-12-09 10:23:33.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 3663 LR: 0.0009999686528927329 Training loss: 0.0
2025-12-09 10:23:33.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 3664 LR: 0.0009999686352994796 Training loss: 0.0
2025-12-09 10:23:33.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 3665 LR: 0.000999968617701291 Training loss: 0.0
2025-12-09 10:23:33.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 3666 LR: 0.0009999686000981669 Training loss: 0.0
2025-12-09 10:23:33.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 3667 LR: 0.000999968582490107 Training loss: 0.0
2025-12-09 10:23:33.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 3668 LR: 0.000999968564877112 Training loss: 0.0
2025-12-09 10:23:33.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 3669 LR: 0.0009999685472591815 Training loss: 0.0
2025-12-09 10:23:33.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 3670 LR: 0.0009999685296363152 Training loss: 0.0
2025-12-09 10:23:33.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 3671 LR: 0.0009999685120085139 Training loss: 0.0
2025-12-09 10:23:33.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 3672 LR: 0.0009999684943757768 Training loss: 0.0
2025-12-09 10:23:33.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 3673 LR: 0.000999968476738104 Training loss: 0.0
2025-12-09 10:23:33.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 3674 LR: 0.0009999684590954962 Training loss: 0.0
2025-12-09 10:23:33.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 3675 LR: 0.0009999684414479526 Training loss: 0.0
2025-12-09 10:23:33.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 3676 LR: 0.0009999684237954737 Training loss: 0.0
2025-12-09 10:23:33.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 3677 LR: 0.0009999684061380593 Training loss: 0.0
2025-12-09 10:23:33.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 3678 LR: 0.0009999683884757095 Training loss: 0.0
2025-12-09 10:23:33.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 3679 LR: 0.0009999683708084238 Training loss: 0.0
2025-12-09 10:23:33.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 3680 LR: 0.0009999683531362032 Training loss: 0.0
2025-12-09 10:23:33.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 3681 LR: 0.0009999683354590468 Training loss: 0.0
2025-12-09 10:23:33.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 3682 LR: 0.0009999683177769549 Training loss: 0.0
2025-12-09 10:23:33.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 3683 LR: 0.0009999683000899277 Training loss: 0.0
2025-12-09 10:23:33.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 3684 LR: 0.000999968282397965 Training loss: 0.0
2025-12-09 10:23:33.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 3685 LR: 0.0009999682647010666 Training loss: 0.0
2025-12-09 10:23:33.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 3686 LR: 0.0009999682469992329 Training loss: 0.0
2025-12-09 10:23:33.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 3687 LR: 0.0009999682292924637 Training loss: 0.0
2025-12-09 10:23:33.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 3688 LR: 0.000999968211580759 Training loss: 0.0
2025-12-09 10:23:33.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 3689 LR: 0.000999968193864119 Training loss: 0.0
2025-12-09 10:23:33.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 3690 LR: 0.0009999681761425432 Training loss: 0.0
2025-12-09 10:23:33.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 3691 LR: 0.000999968158416032 Training loss: 0.0
2025-12-09 10:23:33.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 3692 LR: 0.0009999681406845855 Training loss: 0.0
2025-12-09 10:23:33.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 3693 LR: 0.0009999681229482034 Training loss: 0.0
2025-12-09 10:23:33.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 3694 LR: 0.000999968105206886 Training loss: 0.0
2025-12-09 10:23:33.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 3695 LR: 0.0009999680874606329 Training loss: 0.0
2025-12-09 10:23:33.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 3696 LR: 0.0009999680697094443 Training loss: 0.0
2025-12-09 10:23:33.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 3697 LR: 0.0009999680519533205 Training loss: 0.0
2025-12-09 10:23:33.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 3698 LR: 0.0009999680341922612 Training loss: 0.0
2025-12-09 10:23:33.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 3699 LR: 0.0009999680164262663 Training loss: 0.0
2025-12-09 10:23:33.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 3700 LR: 0.0009999679986553358 Training loss: 0.0
2025-12-09 10:23:33.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 3701 LR: 0.00099996798087947 Training loss: 0.0
2025-12-09 10:23:33.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 3702 LR: 0.0009999679630986686 Training loss: 0.0
2025-12-09 10:23:33.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 3703 LR: 0.0009999679453129317 Training loss: 0.0
2025-12-09 10:23:33.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 3704 LR: 0.0009999679275222596 Training loss: 0.0
2025-12-09 10:23:33.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 3705 LR: 0.000999967909726652 Training loss: 0.0
2025-12-09 10:23:33.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 3706 LR: 0.0009999678919261085 Training loss: 0.0
2025-12-09 10:23:33.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 3707 LR: 0.0009999678741206299 Training loss: 0.0
2025-12-09 10:23:33.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 3708 LR: 0.0009999678563102157 Training loss: 0.0
2025-12-09 10:23:33.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 3709 LR: 0.0009999678384948662 Training loss: 0.0
2025-12-09 10:23:33.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 3710 LR: 0.000999967820674581 Training loss: 0.0
2025-12-09 10:23:33.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 3711 LR: 0.0009999678028493606 Training loss: 0.0
2025-12-09 10:23:33.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 3712 LR: 0.0009999677850192044 Training loss: 0.0
2025-12-09 10:23:33.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 3713 LR: 0.000999967767184113 Training loss: 0.0
2025-12-09 10:23:33.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 3714 LR: 0.000999967749344086 Training loss: 0.0
2025-12-09 10:23:33.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 3715 LR: 0.0009999677314991235 Training loss: 0.0
2025-12-09 10:23:33.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 3716 LR: 0.0009999677136492255 Training loss: 0.0
2025-12-09 10:23:33.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 3717 LR: 0.0009999676957943922 Training loss: 0.0
2025-12-09 10:23:33.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 3718 LR: 0.0009999676779346234 Training loss: 0.0
2025-12-09 10:23:33.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 3719 LR: 0.0009999676600699191 Training loss: 0.0
2025-12-09 10:23:33.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 3720 LR: 0.0009999676422002793 Training loss: 0.0
2025-12-09 10:23:33.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 3721 LR: 0.0009999676243257038 Training loss: 0.0
2025-12-09 10:23:33.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 3722 LR: 0.0009999676064461932 Training loss: 0.0
2025-12-09 10:23:33.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 3723 LR: 0.000999967588561747 Training loss: 0.0
2025-12-09 10:23:33.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 3724 LR: 0.0009999675706723653 Training loss: 0.0
2025-12-09 10:23:33.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 3725 LR: 0.000999967552778048 Training loss: 0.0
2025-12-09 10:23:33.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 3726 LR: 0.0009999675348787954 Training loss: 0.0
2025-12-09 10:23:33.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 3727 LR: 0.0009999675169746075 Training loss: 0.0
2025-12-09 10:23:33.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 3728 LR: 0.0009999674990654839 Training loss: 0.0
2025-12-09 10:23:33.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 3729 LR: 0.0009999674811514247 Training loss: 0.0
2025-12-09 10:23:33.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 3730 LR: 0.0009999674632324303 Training loss: 0.0
2025-12-09 10:23:33.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 3731 LR: 0.0009999674453085004 Training loss: 0.0
2025-12-09 10:23:33.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 3732 LR: 0.0009999674273796348 Training loss: 0.0
2025-12-09 10:23:33.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 3733 LR: 0.000999967409445834 Training loss: 0.0
2025-12-09 10:23:33.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 3734 LR: 0.0009999673915070976 Training loss: 0.0
2025-12-09 10:23:33.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 3735 LR: 0.000999967373563426 Training loss: 0.0
2025-12-09 10:23:33.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 3736 LR: 0.0009999673556148185 Training loss: 0.0
2025-12-09 10:23:33.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 3737 LR: 0.0009999673376612757 Training loss: 0.0
2025-12-09 10:23:33.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 3738 LR: 0.0009999673197027975 Training loss: 0.0
2025-12-09 10:23:33.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 3739 LR: 0.0009999673017393837 Training loss: 0.0
2025-12-09 10:23:33.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 3740 LR: 0.0009999672837710345 Training loss: 0.0
2025-12-09 10:23:33.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 3741 LR: 0.00099996726579775 Training loss: 0.0
2025-12-09 10:23:33.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 3742 LR: 0.00099996724781953 Training loss: 0.0
2025-12-09 10:23:33.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 3743 LR: 0.0009999672298363742 Training loss: 0.0
2025-12-09 10:23:33.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 3744 LR: 0.0009999672118482833 Training loss: 0.0
2025-12-09 10:23:33.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 3745 LR: 0.0009999671938552568 Training loss: 0.0
2025-12-09 10:23:33.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 3746 LR: 0.0009999671758572947 Training loss: 0.0
2025-12-09 10:23:33.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 3747 LR: 0.0009999671578543973 Training loss: 0.0
2025-12-09 10:23:33.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 3748 LR: 0.0009999671398465645 Training loss: 0.0
2025-12-09 10:23:33.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 3749 LR: 0.000999967121833796 Training loss: 0.0
2025-12-09 10:23:33.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 3750 LR: 0.0009999671038160923 Training loss: 0.0
2025-12-09 10:23:33.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 3751 LR: 0.000999967085793453 Training loss: 0.0
2025-12-09 10:23:33.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 3752 LR: 0.000999967067765878 Training loss: 0.0
2025-12-09 10:23:33.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 3753 LR: 0.0009999670497333679 Training loss: 0.0
2025-12-09 10:23:33.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 3754 LR: 0.0009999670316959222 Training loss: 0.0
2025-12-09 10:23:33.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 3755 LR: 0.000999967013653541 Training loss: 0.0
2025-12-09 10:23:33.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 3756 LR: 0.0009999669956062246 Training loss: 0.0
2025-12-09 10:23:33.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 3757 LR: 0.0009999669775539724 Training loss: 0.0
2025-12-09 10:23:33.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 3758 LR: 0.000999966959496785 Training loss: 0.0
2025-12-09 10:23:33.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 3759 LR: 0.000999966941434662 Training loss: 0.0
2025-12-09 10:23:33.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 3760 LR: 0.0009999669233676034 Training loss: 0.0
2025-12-09 10:23:33.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 3761 LR: 0.0009999669052956094 Training loss: 0.0
2025-12-09 10:23:33.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 3762 LR: 0.00099996688721868 Training loss: 0.0
2025-12-09 10:23:33.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 3763 LR: 0.0009999668691368152 Training loss: 0.0
2025-12-09 10:23:33.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 3764 LR: 0.0009999668510500149 Training loss: 0.0
2025-12-09 10:23:33.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 3765 LR: 0.000999966832958279 Training loss: 0.0
2025-12-09 10:23:33.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 3766 LR: 0.0009999668148616078 Training loss: 0.0
2025-12-09 10:23:33.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 3767 LR: 0.0009999667967600012 Training loss: 0.0
2025-12-09 10:23:33.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 3768 LR: 0.000999966778653459 Training loss: 0.0
2025-12-09 10:23:33.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 3769 LR: 0.0009999667605419815 Training loss: 0.0
2025-12-09 10:23:33.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 3770 LR: 0.0009999667424255682 Training loss: 0.0
2025-12-09 10:23:33.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 3771 LR: 0.0009999667243042198 Training loss: 0.0
2025-12-09 10:23:33.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 3772 LR: 0.000999966706177936 Training loss: 0.0
2025-12-09 10:23:33.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 3773 LR: 0.0009999666880467163 Training loss: 0.0
2025-12-09 10:23:33.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 3774 LR: 0.0009999666699105614 Training loss: 0.0
2025-12-09 10:23:33.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 3775 LR: 0.000999966651769471 Training loss: 0.0
2025-12-09 10:23:33.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 3776 LR: 0.0009999666336234453 Training loss: 0.0
2025-12-09 10:23:33.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 3777 LR: 0.0009999666154724839 Training loss: 0.0
2025-12-09 10:23:33.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 3778 LR: 0.000999966597316587 Training loss: 0.0
2025-12-09 10:23:33.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 3779 LR: 0.0009999665791557547 Training loss: 0.0
2025-12-09 10:23:33.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 3780 LR: 0.0009999665609899872 Training loss: 0.0
2025-12-09 10:23:33.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 3781 LR: 0.000999966542819284 Training loss: 0.0
2025-12-09 10:23:33.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 3782 LR: 0.0009999665246436453 Training loss: 0.0
2025-12-09 10:23:33.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 3783 LR: 0.0009999665064630715 Training loss: 0.0
2025-12-09 10:23:33.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 3784 LR: 0.000999966488277562 Training loss: 0.0
2025-12-09 10:23:33.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 3785 LR: 0.000999966470087117 Training loss: 0.0
2025-12-09 10:23:33.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 3786 LR: 0.0009999664518917364 Training loss: 0.0
2025-12-09 10:23:33.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 3787 LR: 0.0009999664336914206 Training loss: 0.0
2025-12-09 10:23:33.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 3788 LR: 0.0009999664154861693 Training loss: 0.0
2025-12-09 10:23:33.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 3789 LR: 0.0009999663972759822 Training loss: 0.0
2025-12-09 10:23:33.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 3790 LR: 0.0009999663790608599 Training loss: 0.0
2025-12-09 10:23:33.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 3791 LR: 0.0009999663608408023 Training loss: 0.0
2025-12-09 10:23:33.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 3792 LR: 0.0009999663426158091 Training loss: 0.0
2025-12-09 10:23:33.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 3793 LR: 0.0009999663243858805 Training loss: 0.0
2025-12-09 10:23:33.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 3794 LR: 0.0009999663061510166 Training loss: 0.0
2025-12-09 10:23:33.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 3795 LR: 0.0009999662879112167 Training loss: 0.0
2025-12-09 10:23:33.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 3796 LR: 0.0009999662696664818 Training loss: 0.0
2025-12-09 10:23:33.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 3797 LR: 0.0009999662514168113 Training loss: 0.0
2025-12-09 10:23:33.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 3798 LR: 0.0009999662331622054 Training loss: 0.0
2025-12-09 10:23:33.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 3799 LR: 0.000999966214902664 Training loss: 0.0
2025-12-09 10:23:33.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 3800 LR: 0.0009999661966381872 Training loss: 0.0
2025-12-09 10:23:33.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 3801 LR: 0.000999966178368775 Training loss: 0.0
2025-12-09 10:23:33.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 3802 LR: 0.0009999661600944272 Training loss: 0.0
2025-12-09 10:23:33.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 3803 LR: 0.000999966141815144 Training loss: 0.0
2025-12-09 10:23:33.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 3804 LR: 0.0009999661235309252 Training loss: 0.0
2025-12-09 10:23:33.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 3805 LR: 0.0009999661052417712 Training loss: 0.0
2025-12-09 10:23:33.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 3806 LR: 0.0009999660869476816 Training loss: 0.0
2025-12-09 10:23:33.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 3807 LR: 0.0009999660686486566 Training loss: 0.0
2025-12-09 10:23:33.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 3808 LR: 0.0009999660503446962 Training loss: 0.0
2025-12-09 10:23:33.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 3809 LR: 0.0009999660320358001 Training loss: 0.0
2025-12-09 10:23:33.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 3810 LR: 0.0009999660137219688 Training loss: 0.0
2025-12-09 10:23:33.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 3811 LR: 0.000999965995403202 Training loss: 0.0
2025-12-09 10:23:33.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 3812 LR: 0.0009999659770794996 Training loss: 0.0
2025-12-09 10:23:33.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 3813 LR: 0.000999965958750862 Training loss: 0.0
2025-12-09 10:23:33.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 3814 LR: 0.0009999659404172888 Training loss: 0.0
2025-12-09 10:23:33.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 3815 LR: 0.00099996592207878 Training loss: 0.0
2025-12-09 10:23:33.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 3816 LR: 0.000999965903735336 Training loss: 0.0
2025-12-09 10:23:33.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 3817 LR: 0.0009999658853869565 Training loss: 0.0
2025-12-09 10:23:33.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 3818 LR: 0.0009999658670336413 Training loss: 0.0
2025-12-09 10:23:33.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 3819 LR: 0.0009999658486753908 Training loss: 0.0
2025-12-09 10:23:33.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 3820 LR: 0.000999965830312205 Training loss: 0.0
2025-12-09 10:23:33.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 3821 LR: 0.0009999658119440836 Training loss: 0.0
2025-12-09 10:23:33.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 3822 LR: 0.0009999657935710268 Training loss: 0.0
2025-12-09 10:23:33.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 3823 LR: 0.0009999657751930346 Training loss: 0.0
2025-12-09 10:23:33.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 3824 LR: 0.0009999657568101068 Training loss: 0.0
2025-12-09 10:23:33.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 3825 LR: 0.0009999657384222435 Training loss: 0.0
2025-12-09 10:23:33.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 3826 LR: 0.000999965720029445 Training loss: 0.0
2025-12-09 10:23:33.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 3827 LR: 0.0009999657016317109 Training loss: 0.0
2025-12-09 10:23:33.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 3828 LR: 0.0009999656832290413 Training loss: 0.0
2025-12-09 10:23:33.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 3829 LR: 0.0009999656648214364 Training loss: 0.0
2025-12-09 10:23:33.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 3830 LR: 0.000999965646408896 Training loss: 0.0
2025-12-09 10:23:33.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 3831 LR: 0.0009999656279914202 Training loss: 0.0
2025-12-09 10:23:33.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 3832 LR: 0.0009999656095690088 Training loss: 0.0
2025-12-09 10:23:33.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 3833 LR: 0.000999965591141662 Training loss: 0.0
2025-12-09 10:23:33.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 3834 LR: 0.0009999655727093797 Training loss: 0.0
2025-12-09 10:23:33.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 3835 LR: 0.0009999655542721623 Training loss: 0.0
2025-12-09 10:23:33.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 3836 LR: 0.000999965535830009 Training loss: 0.0
2025-12-09 10:23:33.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 3837 LR: 0.0009999655173829204 Training loss: 0.0
2025-12-09 10:23:33.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 3838 LR: 0.0009999654989308964 Training loss: 0.0
2025-12-09 10:23:33.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 3839 LR: 0.000999965480473937 Training loss: 0.0
2025-12-09 10:23:33.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 3840 LR: 0.000999965462012042 Training loss: 0.0
2025-12-09 10:23:33.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 3841 LR: 0.0009999654435452116 Training loss: 0.0
2025-12-09 10:23:33.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 3842 LR: 0.0009999654250734459 Training loss: 0.0
2025-12-09 10:23:33.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 3843 LR: 0.0009999654065967446 Training loss: 0.0
2025-12-09 10:23:33.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 3844 LR: 0.0009999653881151078 Training loss: 0.0
2025-12-09 10:23:33.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 3845 LR: 0.0009999653696285357 Training loss: 0.0
2025-12-09 10:23:33.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 3846 LR: 0.000999965351137028 Training loss: 0.0
2025-12-09 10:23:33.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 3847 LR: 0.000999965332640585 Training loss: 0.0
2025-12-09 10:23:33.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 3848 LR: 0.0009999653141392064 Training loss: 0.0
2025-12-09 10:23:33.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 3849 LR: 0.0009999652956328925 Training loss: 0.0
2025-12-09 10:23:33.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 3850 LR: 0.0009999652771216431 Training loss: 0.0
2025-12-09 10:23:33.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 3851 LR: 0.0009999652586054585 Training loss: 0.0
2025-12-09 10:23:33.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 3852 LR: 0.000999965240084338 Training loss: 0.0
2025-12-09 10:23:33.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 3853 LR: 0.0009999652215582824 Training loss: 0.0
2025-12-09 10:23:33.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 3854 LR: 0.0009999652030272912 Training loss: 0.0
2025-12-09 10:23:33.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 3855 LR: 0.0009999651844913645 Training loss: 0.0
2025-12-09 10:23:33.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 3856 LR: 0.0009999651659505025 Training loss: 0.0
2025-12-09 10:23:33.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 3857 LR: 0.000999965147404705 Training loss: 0.0
2025-12-09 10:23:33.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 3858 LR: 0.000999965128853972 Training loss: 0.0
2025-12-09 10:23:33.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 3859 LR: 0.0009999651102983035 Training loss: 0.0
2025-12-09 10:23:33.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 3860 LR: 0.0009999650917376997 Training loss: 0.0
2025-12-09 10:23:33.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 3861 LR: 0.0009999650731721604 Training loss: 0.0
2025-12-09 10:23:33.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 3862 LR: 0.0009999650546016856 Training loss: 0.0
2025-12-09 10:23:33.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 3863 LR: 0.0009999650360262755 Training loss: 0.0
2025-12-09 10:23:33.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 3864 LR: 0.00099996501744593 Training loss: 0.0
2025-12-09 10:23:33.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 3865 LR: 0.0009999649988606488 Training loss: 0.0
2025-12-09 10:23:33.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 3866 LR: 0.0009999649802704322 Training loss: 0.0
2025-12-09 10:23:33.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 3867 LR: 0.0009999649616752803 Training loss: 0.0
2025-12-09 10:23:33.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 3868 LR: 0.000999964943075193 Training loss: 0.0
2025-12-09 10:23:33.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 3869 LR: 0.00099996492447017 Training loss: 0.0
2025-12-09 10:23:33.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 3870 LR: 0.0009999649058602118 Training loss: 0.0
2025-12-09 10:23:33.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 3871 LR: 0.000999964887245318 Training loss: 0.0
2025-12-09 10:23:33.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 3872 LR: 0.0009999648686254887 Training loss: 0.0
2025-12-09 10:23:33.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 3873 LR: 0.0009999648500007242 Training loss: 0.0
2025-12-09 10:23:33.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 3874 LR: 0.0009999648313710242 Training loss: 0.0
2025-12-09 10:23:33.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 3875 LR: 0.0009999648127363887 Training loss: 0.0
2025-12-09 10:23:33.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 3876 LR: 0.0009999647940968177 Training loss: 0.0
2025-12-09 10:23:33.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 3877 LR: 0.0009999647754523114 Training loss: 0.0
2025-12-09 10:23:33.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 3878 LR: 0.0009999647568028694 Training loss: 0.0
2025-12-09 10:23:33.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 3879 LR: 0.0009999647381484923 Training loss: 0.0
2025-12-09 10:23:33.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 3880 LR: 0.0009999647194891795 Training loss: 0.0
2025-12-09 10:23:33.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 3881 LR: 0.0009999647008249314 Training loss: 0.0
2025-12-09 10:23:33.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 3882 LR: 0.0009999646821557478 Training loss: 0.0
2025-12-09 10:23:33.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 3883 LR: 0.0009999646634816287 Training loss: 0.0
2025-12-09 10:23:33.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 3884 LR: 0.0009999646448025743 Training loss: 0.0
2025-12-09 10:23:33.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 3885 LR: 0.0009999646261185844 Training loss: 0.0
2025-12-09 10:23:33.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 3886 LR: 0.000999964607429659 Training loss: 0.0
2025-12-09 10:23:33.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 3887 LR: 0.000999964588735798 Training loss: 0.0
2025-12-09 10:23:33.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 3888 LR: 0.0009999645700370019 Training loss: 0.0
2025-12-09 10:23:33.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 3889 LR: 0.0009999645513332702 Training loss: 0.0
2025-12-09 10:23:33.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 3890 LR: 0.0009999645326246032 Training loss: 0.0
2025-12-09 10:23:33.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 3891 LR: 0.0009999645139110004 Training loss: 0.0
2025-12-09 10:23:33.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 3892 LR: 0.0009999644951924627 Training loss: 0.0
2025-12-09 10:23:33.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 3893 LR: 0.0009999644764689892 Training loss: 0.0
2025-12-09 10:23:33.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 3894 LR: 0.0009999644577405801 Training loss: 0.0
2025-12-09 10:23:33.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 3895 LR: 0.000999964439007236 Training loss: 0.0
2025-12-09 10:23:33.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 3896 LR: 0.0009999644202689562 Training loss: 0.0
2025-12-09 10:23:33.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 3897 LR: 0.000999964401525741 Training loss: 0.0
2025-12-09 10:23:33.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 3898 LR: 0.0009999643827775903 Training loss: 0.0
2025-12-09 10:23:33.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 3899 LR: 0.0009999643640245042 Training loss: 0.0
2025-12-09 10:23:33.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 3900 LR: 0.0009999643452664828 Training loss: 0.0
2025-12-09 10:23:33.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 3901 LR: 0.000999964326503526 Training loss: 0.0
2025-12-09 10:23:33.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 3902 LR: 0.0009999643077356335 Training loss: 0.0
2025-12-09 10:23:33.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 3903 LR: 0.0009999642889628058 Training loss: 0.0
2025-12-09 10:23:33.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 3904 LR: 0.0009999642701850424 Training loss: 0.0
2025-12-09 10:23:33.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 3905 LR: 0.0009999642514023437 Training loss: 0.0
2025-12-09 10:23:33.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 3906 LR: 0.0009999642326147095 Training loss: 0.0
2025-12-09 10:23:33.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 3907 LR: 0.00099996421382214 Training loss: 0.0
2025-12-09 10:23:33.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 3908 LR: 0.000999964195024635 Training loss: 0.0
2025-12-09 10:23:33.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 3909 LR: 0.0009999641762221947 Training loss: 0.0
2025-12-09 10:23:33.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 3910 LR: 0.000999964157414819 Training loss: 0.0
2025-12-09 10:23:33.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 3911 LR: 0.0009999641386025076 Training loss: 0.0
2025-12-09 10:23:33.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 3912 LR: 0.0009999641197852606 Training loss: 0.0
2025-12-09 10:23:33.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 3913 LR: 0.0009999641009630787 Training loss: 0.0
2025-12-09 10:23:33.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 3914 LR: 0.0009999640821359611 Training loss: 0.0
2025-12-09 10:23:33.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 3915 LR: 0.000999964063303908 Training loss: 0.0
2025-12-09 10:23:33.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 3916 LR: 0.0009999640444669194 Training loss: 0.0
2025-12-09 10:23:33.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 3917 LR: 0.0009999640256249955 Training loss: 0.0
2025-12-09 10:23:33.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 3918 LR: 0.0009999640067781363 Training loss: 0.0
2025-12-09 10:23:33.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 3919 LR: 0.0009999639879263414 Training loss: 0.0
2025-12-09 10:23:33.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 3920 LR: 0.0009999639690696112 Training loss: 0.0
2025-12-09 10:23:33.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 3921 LR: 0.0009999639502079455 Training loss: 0.0
2025-12-09 10:23:33.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 3922 LR: 0.0009999639313413445 Training loss: 0.0
2025-12-09 10:23:33.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 3923 LR: 0.000999963912469808 Training loss: 0.0
2025-12-09 10:23:33.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 3924 LR: 0.000999963893593336 Training loss: 0.0
2025-12-09 10:23:33.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 3925 LR: 0.0009999638747119285 Training loss: 0.0
2025-12-09 10:23:33.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 3926 LR: 0.000999963855825586 Training loss: 0.0
2025-12-09 10:23:33.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 3927 LR: 0.0009999638369343076 Training loss: 0.0
2025-12-09 10:23:33.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 3928 LR: 0.000999963818038094 Training loss: 0.0
2025-12-09 10:23:33.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 3929 LR: 0.0009999637991369447 Training loss: 0.0
2025-12-09 10:23:33.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 3930 LR: 0.0009999637802308604 Training loss: 0.0
2025-12-09 10:23:33.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 3931 LR: 0.0009999637613198403 Training loss: 0.0
2025-12-09 10:23:33.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 3932 LR: 0.000999963742403885 Training loss: 0.0
2025-12-09 10:23:33.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 3933 LR: 0.0009999637234829942 Training loss: 0.0
2025-12-09 10:23:33.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 3934 LR: 0.0009999637045571678 Training loss: 0.0
2025-12-09 10:23:33.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 3935 LR: 0.000999963685626406 Training loss: 0.0
2025-12-09 10:23:33.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 3936 LR: 0.0009999636666907091 Training loss: 0.0
2025-12-09 10:23:33.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 3937 LR: 0.0009999636477500764 Training loss: 0.0
2025-12-09 10:23:33.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 3938 LR: 0.0009999636288045084 Training loss: 0.0
2025-12-09 10:23:33.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 3939 LR: 0.000999963609854005 Training loss: 0.0
2025-12-09 10:23:33.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 3940 LR: 0.0009999635908985662 Training loss: 0.0
2025-12-09 10:23:33.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 3941 LR: 0.0009999635719381919 Training loss: 0.0
2025-12-09 10:23:33.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 3942 LR: 0.0009999635529728823 Training loss: 0.0
2025-12-09 10:23:33.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 3943 LR: 0.0009999635340026372 Training loss: 0.0
2025-12-09 10:23:33.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 3944 LR: 0.0009999635150274564 Training loss: 0.0
2025-12-09 10:23:33.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 3945 LR: 0.0009999634960473406 Training loss: 0.0
2025-12-09 10:23:33.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 3946 LR: 0.0009999634770622892 Training loss: 0.0
2025-12-09 10:23:33.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 3947 LR: 0.0009999634580723023 Training loss: 0.0
2025-12-09 10:23:33.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 3948 LR: 0.00099996343907738 Training loss: 0.0
2025-12-09 10:23:33.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 3949 LR: 0.0009999634200775222 Training loss: 0.0
2025-12-09 10:23:33.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 3950 LR: 0.0009999634010727293 Training loss: 0.0
2025-12-09 10:23:33.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 3951 LR: 0.0009999633820630006 Training loss: 0.0
2025-12-09 10:23:33.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 3952 LR: 0.0009999633630483366 Training loss: 0.0
2025-12-09 10:23:33.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 3953 LR: 0.0009999633440287373 Training loss: 0.0
2025-12-09 10:23:33.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 3954 LR: 0.0009999633250042024 Training loss: 0.0
2025-12-09 10:23:33.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 3955 LR: 0.000999963305974732 Training loss: 0.0
2025-12-09 10:23:33.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 3956 LR: 0.0009999632869403263 Training loss: 0.0
2025-12-09 10:23:33.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 3957 LR: 0.0009999632679009852 Training loss: 0.0
2025-12-09 10:23:33.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 3958 LR: 0.0009999632488567087 Training loss: 0.0
2025-12-09 10:23:33.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 3959 LR: 0.0009999632298074966 Training loss: 0.0
2025-12-09 10:23:33.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 3960 LR: 0.0009999632107533492 Training loss: 0.0
2025-12-09 10:23:33.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 3961 LR: 0.0009999631916942663 Training loss: 0.0
2025-12-09 10:23:33.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 3962 LR: 0.0009999631726302482 Training loss: 0.0
2025-12-09 10:23:33.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 3963 LR: 0.0009999631535612945 Training loss: 0.0
2025-12-09 10:23:33.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 3964 LR: 0.0009999631344874054 Training loss: 0.0
2025-12-09 10:23:33.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 3965 LR: 0.000999963115408581 Training loss: 0.0
2025-12-09 10:23:33.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 3966 LR: 0.000999963096324821 Training loss: 0.0
2025-12-09 10:23:33.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 3967 LR: 0.0009999630772361255 Training loss: 0.0
2025-12-09 10:23:33.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 3968 LR: 0.0009999630581424947 Training loss: 0.0
2025-12-09 10:23:33.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 3969 LR: 0.0009999630390439284 Training loss: 0.0
2025-12-09 10:23:33.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 3970 LR: 0.000999963019940427 Training loss: 0.0
2025-12-09 10:23:33.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 3971 LR: 0.0009999630008319896 Training loss: 0.0
2025-12-09 10:23:33.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 3972 LR: 0.000999962981718617 Training loss: 0.0
2025-12-09 10:23:33.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 3973 LR: 0.0009999629626003092 Training loss: 0.0
2025-12-09 10:23:33.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 3974 LR: 0.0009999629434770659 Training loss: 0.0
2025-12-09 10:23:33.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 3975 LR: 0.000999962924348887 Training loss: 0.0
2025-12-09 10:23:33.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 3976 LR: 0.0009999629052157729 Training loss: 0.0
2025-12-09 10:23:33.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 3977 LR: 0.0009999628860777232 Training loss: 0.0
2025-12-09 10:23:33.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 3978 LR: 0.0009999628669347383 Training loss: 0.0
2025-12-09 10:23:33.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 3979 LR: 0.0009999628477868176 Training loss: 0.0
2025-12-09 10:23:33.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 3980 LR: 0.0009999628286339619 Training loss: 0.0
2025-12-09 10:23:33.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 3981 LR: 0.0009999628094761706 Training loss: 0.0
2025-12-09 10:23:33.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 3982 LR: 0.0009999627903134439 Training loss: 0.0
2025-12-09 10:23:33.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 3983 LR: 0.0009999627711457816 Training loss: 0.0
2025-12-09 10:23:33.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 3984 LR: 0.0009999627519731839 Training loss: 0.0
2025-12-09 10:23:33.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 3985 LR: 0.000999962732795651 Training loss: 0.0
2025-12-09 10:23:33.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 3986 LR: 0.0009999627136131825 Training loss: 0.0
2025-12-09 10:23:33.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 3987 LR: 0.0009999626944257787 Training loss: 0.0
2025-12-09 10:23:33.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 3988 LR: 0.0009999626752334393 Training loss: 0.0
2025-12-09 10:23:33.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 3989 LR: 0.0009999626560361647 Training loss: 0.0
2025-12-09 10:23:33.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 3990 LR: 0.0009999626368339548 Training loss: 0.0
2025-12-09 10:23:33.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 3991 LR: 0.0009999626176268091 Training loss: 0.0
2025-12-09 10:23:33.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 3992 LR: 0.0009999625984147282 Training loss: 0.0
2025-12-09 10:23:33.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 3993 LR: 0.0009999625791977118 Training loss: 0.0
2025-12-09 10:23:33.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 3994 LR: 0.00099996255997576 Training loss: 0.0
2025-12-09 10:23:33.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 3995 LR: 0.0009999625407488728 Training loss: 0.0
2025-12-09 10:23:33.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 3996 LR: 0.00099996252151705 Training loss: 0.0
2025-12-09 10:23:33.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 3997 LR: 0.000999962502280292 Training loss: 0.0
2025-12-09 10:23:33.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 3998 LR: 0.0009999624830385988 Training loss: 0.0
2025-12-09 10:23:33.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 3999 LR: 0.0009999624637919697 Training loss: 0.0
2025-12-09 10:23:33.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 4000 LR: 0.0009999624445404054 Training loss: 0.0
2025-12-09 10:23:33.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 4001 LR: 0.0009999624252839056 Training loss: 0.0
2025-12-09 10:23:33.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 4002 LR: 0.0009999624060224705 Training loss: 0.0
2025-12-09 10:23:33.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 4003 LR: 0.0009999623867561 Training loss: 0.0
2025-12-09 10:23:33.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 4004 LR: 0.000999962367484794 Training loss: 0.0
2025-12-09 10:23:33.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 4005 LR: 0.0009999623482085528 Training loss: 0.0
2025-12-09 10:23:33.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 4006 LR: 0.0009999623289273759 Training loss: 0.0
2025-12-09 10:23:33.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 4007 LR: 0.0009999623096412637 Training loss: 0.0
2025-12-09 10:23:33.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 4008 LR: 0.000999962290350216 Training loss: 0.0
2025-12-09 10:23:33.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 4009 LR: 0.000999962271054233 Training loss: 0.0
2025-12-09 10:23:33.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 4010 LR: 0.0009999622517533144 Training loss: 0.0
2025-12-09 10:23:33.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 4011 LR: 0.0009999622324474604 Training loss: 0.0
2025-12-09 10:23:33.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 4012 LR: 0.0009999622131366711 Training loss: 0.0
2025-12-09 10:23:33.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 4013 LR: 0.0009999621938209463 Training loss: 0.0
2025-12-09 10:23:33.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 4014 LR: 0.0009999621745002863 Training loss: 0.0
2025-12-09 10:23:33.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 4015 LR: 0.0009999621551746907 Training loss: 0.0
2025-12-09 10:23:33.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 4016 LR: 0.0009999621358441598 Training loss: 0.0
2025-12-09 10:23:33.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 4017 LR: 0.0009999621165086934 Training loss: 0.0
2025-12-09 10:23:33.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 4018 LR: 0.0009999620971682915 Training loss: 0.0
2025-12-09 10:23:33.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 4019 LR: 0.0009999620778229543 Training loss: 0.0
2025-12-09 10:23:33.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 4020 LR: 0.0009999620584726816 Training loss: 0.0
2025-12-09 10:23:33.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 4021 LR: 0.0009999620391174734 Training loss: 0.0
2025-12-09 10:23:33.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 4022 LR: 0.00099996201975733 Training loss: 0.0
2025-12-09 10:23:33.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 4023 LR: 0.0009999620003922512 Training loss: 0.0
2025-12-09 10:23:33.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 4024 LR: 0.000999961981022237 Training loss: 0.0
2025-12-09 10:23:33.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 4025 LR: 0.0009999619616472874 Training loss: 0.0
2025-12-09 10:23:33.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 4026 LR: 0.000999961942267402 Training loss: 0.0
2025-12-09 10:23:33.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 4027 LR: 0.0009999619228825815 Training loss: 0.0
2025-12-09 10:23:33.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 4028 LR: 0.0009999619034928256 Training loss: 0.0
2025-12-09 10:23:33.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 4029 LR: 0.000999961884098134 Training loss: 0.0
2025-12-09 10:23:33.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 4030 LR: 0.0009999618646985074 Training loss: 0.0
2025-12-09 10:23:33.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 4031 LR: 0.0009999618452939452 Training loss: 0.0
2025-12-09 10:23:33.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 4032 LR: 0.0009999618258844476 Training loss: 0.0
2025-12-09 10:23:33.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 4033 LR: 0.0009999618064700146 Training loss: 0.0
2025-12-09 10:23:33.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 4034 LR: 0.0009999617870506462 Training loss: 0.0
2025-12-09 10:23:33.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 4035 LR: 0.0009999617676263424 Training loss: 0.0
2025-12-09 10:23:33.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 4036 LR: 0.000999961748197103 Training loss: 0.0
2025-12-09 10:23:33.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 4037 LR: 0.0009999617287629284 Training loss: 0.0
2025-12-09 10:23:33.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 4038 LR: 0.0009999617093238182 Training loss: 0.0
2025-12-09 10:23:33.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 4039 LR: 0.0009999616898797728 Training loss: 0.0
2025-12-09 10:23:33.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 4040 LR: 0.000999961670430792 Training loss: 0.0
2025-12-09 10:23:33.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 4041 LR: 0.0009999616509768757 Training loss: 0.0
2025-12-09 10:23:33.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 4042 LR: 0.0009999616315180238 Training loss: 0.0
2025-12-09 10:23:33.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 4043 LR: 0.0009999616120542367 Training loss: 0.0
2025-12-09 10:23:33.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 4044 LR: 0.000999961592585514 Training loss: 0.0
2025-12-09 10:23:33.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 4045 LR: 0.0009999615731118563 Training loss: 0.0
2025-12-09 10:23:33.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 4046 LR: 0.0009999615536332629 Training loss: 0.0
2025-12-09 10:23:33.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 4047 LR: 0.0009999615341497342 Training loss: 0.0
2025-12-09 10:23:33.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 4048 LR: 0.00099996151466127 Training loss: 0.0
2025-12-09 10:23:33.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 4049 LR: 0.0009999614951678704 Training loss: 0.0
2025-12-09 10:23:33.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 4050 LR: 0.0009999614756695354 Training loss: 0.0
2025-12-09 10:23:33.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 4051 LR: 0.0009999614561662649 Training loss: 0.0
2025-12-09 10:23:33.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 4052 LR: 0.0009999614366580593 Training loss: 0.0
2025-12-09 10:23:33.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 4053 LR: 0.0009999614171449177 Training loss: 0.0
2025-12-09 10:23:33.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 4054 LR: 0.0009999613976268413 Training loss: 0.0
2025-12-09 10:23:33.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 4055 LR: 0.0009999613781038292 Training loss: 0.0
2025-12-09 10:23:33.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 4056 LR: 0.0009999613585758818 Training loss: 0.0
2025-12-09 10:23:33.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 4057 LR: 0.000999961339042999 Training loss: 0.0
2025-12-09 10:23:33.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 4058 LR: 0.0009999613195051807 Training loss: 0.0
2025-12-09 10:23:33.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 4059 LR: 0.0009999612999624268 Training loss: 0.0
2025-12-09 10:23:33.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 4060 LR: 0.0009999612804147378 Training loss: 0.0
2025-12-09 10:23:33.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 4061 LR: 0.0009999612608621133 Training loss: 0.0
2025-12-09 10:23:33.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 4062 LR: 0.0009999612413045533 Training loss: 0.0
2025-12-09 10:23:33.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 4063 LR: 0.0009999612217420583 Training loss: 0.0
2025-12-09 10:23:33.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 4064 LR: 0.0009999612021746275 Training loss: 0.0
2025-12-09 10:23:33.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 4065 LR: 0.0009999611826022614 Training loss: 0.0
2025-12-09 10:23:33.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 4066 LR: 0.0009999611630249598 Training loss: 0.0
2025-12-09 10:23:33.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 4067 LR: 0.000999961143442723 Training loss: 0.0
2025-12-09 10:23:33.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 4068 LR: 0.0009999611238555505 Training loss: 0.0
2025-12-09 10:23:33.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 4069 LR: 0.0009999611042634429 Training loss: 0.0
2025-12-09 10:23:33.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 4070 LR: 0.0009999610846663995 Training loss: 0.0
2025-12-09 10:23:33.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 4071 LR: 0.000999961065064421 Training loss: 0.0
2025-12-09 10:23:33.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 4072 LR: 0.000999961045457507 Training loss: 0.0
2025-12-09 10:23:33.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 4073 LR: 0.0009999610258456578 Training loss: 0.0
2025-12-09 10:23:33.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 4074 LR: 0.000999961006228873 Training loss: 0.0
2025-12-09 10:23:33.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 4075 LR: 0.0009999609866071528 Training loss: 0.0
2025-12-09 10:23:33.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 4076 LR: 0.0009999609669804972 Training loss: 0.0
2025-12-09 10:23:33.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 4077 LR: 0.0009999609473489062 Training loss: 0.0
2025-12-09 10:23:33.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 4078 LR: 0.0009999609277123798 Training loss: 0.0
2025-12-09 10:23:33.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 4079 LR: 0.0009999609080709182 Training loss: 0.0
2025-12-09 10:23:33.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 4080 LR: 0.0009999608884245208 Training loss: 0.0
2025-12-09 10:23:33.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 4081 LR: 0.0009999608687731882 Training loss: 0.0
2025-12-09 10:23:33.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 4082 LR: 0.0009999608491169203 Training loss: 0.0
2025-12-09 10:23:33.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 4083 LR: 0.000999960829455717 Training loss: 0.0
2025-12-09 10:23:33.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 4084 LR: 0.000999960809789578 Training loss: 0.0
2025-12-09 10:23:33.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 4085 LR: 0.0009999607901185039 Training loss: 0.0
2025-12-09 10:23:33.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 4086 LR: 0.0009999607704424941 Training loss: 0.0
2025-12-09 10:23:33.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 4087 LR: 0.0009999607507615493 Training loss: 0.0
2025-12-09 10:23:33.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 4088 LR: 0.0009999607310756688 Training loss: 0.0
2025-12-09 10:23:33.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 4089 LR: 0.000999960711384853 Training loss: 0.0
2025-12-09 10:23:33.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 4090 LR: 0.0009999606916891019 Training loss: 0.0
2025-12-09 10:23:33.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 4091 LR: 0.0009999606719884153 Training loss: 0.0
2025-12-09 10:23:33.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 4092 LR: 0.0009999606522827931 Training loss: 0.0
2025-12-09 10:23:33.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 4093 LR: 0.0009999606325722357 Training loss: 0.0
2025-12-09 10:23:33.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 4094 LR: 0.000999960612856743 Training loss: 0.0
2025-12-09 10:23:33.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 4095 LR: 0.0009999605931363146 Training loss: 0.0
2025-12-09 10:23:33.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 4096 LR: 0.0009999605734109511 Training loss: 0.0
2025-12-09 10:23:33.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 4097 LR: 0.0009999605536806521 Training loss: 0.0
2025-12-09 10:23:33.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 4098 LR: 0.0009999605339454177 Training loss: 0.0
2025-12-09 10:23:33.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 4099 LR: 0.0009999605142052479 Training loss: 0.0
2025-12-09 10:23:33.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 4100 LR: 0.0009999604944601428 Training loss: 0.0
2025-12-09 10:23:33.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 4101 LR: 0.000999960474710102 Training loss: 0.0
2025-12-09 10:23:33.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 4102 LR: 0.000999960454955126 Training loss: 0.0
2025-12-09 10:23:33.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 4103 LR: 0.0009999604351952145 Training loss: 0.0
2025-12-09 10:23:33.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 4104 LR: 0.0009999604154303679 Training loss: 0.0
2025-12-09 10:23:33.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 4105 LR: 0.0009999603956605857 Training loss: 0.0
2025-12-09 10:23:33.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 4106 LR: 0.000999960375885868 Training loss: 0.0
2025-12-09 10:23:33.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 4107 LR: 0.0009999603561062149 Training loss: 0.0
2025-12-09 10:23:33.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 4108 LR: 0.0009999603363216266 Training loss: 0.0
2025-12-09 10:23:33.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 4109 LR: 0.0009999603165321027 Training loss: 0.0
2025-12-09 10:23:33.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 4110 LR: 0.0009999602967376436 Training loss: 0.0
2025-12-09 10:23:33.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 4111 LR: 0.000999960276938249 Training loss: 0.0
2025-12-09 10:23:33.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 4112 LR: 0.000999960257133919 Training loss: 0.0
2025-12-09 10:23:33.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 4113 LR: 0.0009999602373246537 Training loss: 0.0
2025-12-09 10:23:33.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 4114 LR: 0.0009999602175104528 Training loss: 0.0
2025-12-09 10:23:33.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 4115 LR: 0.0009999601976913167 Training loss: 0.0
2025-12-09 10:23:33.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 4116 LR: 0.000999960177867245 Training loss: 0.0
2025-12-09 10:23:33.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 4117 LR: 0.0009999601580382381 Training loss: 0.0
2025-12-09 10:23:33.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 4118 LR: 0.0009999601382042957 Training loss: 0.0
2025-12-09 10:23:33.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 4119 LR: 0.000999960118365418 Training loss: 0.0
2025-12-09 10:23:33.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 4120 LR: 0.0009999600985216048 Training loss: 0.0
2025-12-09 10:23:33.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 4121 LR: 0.0009999600786728562 Training loss: 0.0
2025-12-09 10:23:33.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 4122 LR: 0.0009999600588191722 Training loss: 0.0
2025-12-09 10:23:33.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 4123 LR: 0.000999960038960553 Training loss: 0.0
2025-12-09 10:23:33.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 4124 LR: 0.0009999600190969981 Training loss: 0.0
2025-12-09 10:23:33.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 4125 LR: 0.000999959999228508 Training loss: 0.0
2025-12-09 10:23:33.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 4126 LR: 0.0009999599793550824 Training loss: 0.0
2025-12-09 10:23:33.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 4127 LR: 0.0009999599594767215 Training loss: 0.0
2025-12-09 10:23:33.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 4128 LR: 0.0009999599395934251 Training loss: 0.0
2025-12-09 10:23:33.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 4129 LR: 0.0009999599197051934 Training loss: 0.0
2025-12-09 10:23:33.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 4130 LR: 0.0009999598998120265 Training loss: 0.0
2025-12-09 10:23:33.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 4131 LR: 0.0009999598799139238 Training loss: 0.0
2025-12-09 10:23:33.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 4132 LR: 0.000999959860010886 Training loss: 0.0
2025-12-09 10:23:33.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 4133 LR: 0.0009999598401029127 Training loss: 0.0
2025-12-09 10:23:33.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 4134 LR: 0.000999959820190004 Training loss: 0.0
2025-12-09 10:23:33.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 4135 LR: 0.0009999598002721599 Training loss: 0.0
2025-12-09 10:23:33.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 4136 LR: 0.0009999597803493805 Training loss: 0.0
2025-12-09 10:23:33.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 4137 LR: 0.0009999597604216657 Training loss: 0.0
2025-12-09 10:23:33.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 4138 LR: 0.0009999597404890153 Training loss: 0.0
2025-12-09 10:23:33.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 4139 LR: 0.0009999597205514296 Training loss: 0.0
2025-12-09 10:23:33.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 4140 LR: 0.0009999597006089087 Training loss: 0.0
2025-12-09 10:23:33.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 4141 LR: 0.0009999596806614522 Training loss: 0.0
2025-12-09 10:23:33.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 4142 LR: 0.0009999596607090605 Training loss: 0.0
2025-12-09 10:23:33.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 4143 LR: 0.0009999596407517333 Training loss: 0.0
2025-12-09 10:23:33.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 4144 LR: 0.0009999596207894705 Training loss: 0.0
2025-12-09 10:23:33.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 4145 LR: 0.0009999596008222727 Training loss: 0.0
2025-12-09 10:23:33.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 4146 LR: 0.0009999595808501392 Training loss: 0.0
2025-12-09 10:23:33.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 4147 LR: 0.0009999595608730706 Training loss: 0.0
2025-12-09 10:23:33.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 4148 LR: 0.0009999595408910662 Training loss: 0.0
2025-12-09 10:23:33.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 4149 LR: 0.0009999595209041268 Training loss: 0.0
2025-12-09 10:23:33.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 4150 LR: 0.0009999595009122517 Training loss: 0.0
2025-12-09 10:23:33.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 4151 LR: 0.0009999594809154415 Training loss: 0.0
2025-12-09 10:23:33.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 4152 LR: 0.0009999594609136958 Training loss: 0.0
2025-12-09 10:23:33.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 4153 LR: 0.0009999594409070146 Training loss: 0.0
2025-12-09 10:23:33.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 4154 LR: 0.000999959420895398 Training loss: 0.0
2025-12-09 10:23:33.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 4155 LR: 0.000999959400878846 Training loss: 0.0
2025-12-09 10:23:33.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 4156 LR: 0.000999959380857359 Training loss: 0.0
2025-12-09 10:23:33.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 4157 LR: 0.0009999593608309362 Training loss: 0.0
2025-12-09 10:23:33.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 4158 LR: 0.0009999593407995781 Training loss: 0.0
2025-12-09 10:23:33.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 4159 LR: 0.0009999593207632848 Training loss: 0.0
2025-12-09 10:23:33.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 4160 LR: 0.000999959300722056 Training loss: 0.0
2025-12-09 10:23:33.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 4161 LR: 0.0009999592806758917 Training loss: 0.0
2025-12-09 10:23:33.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 4162 LR: 0.000999959260624792 Training loss: 0.0
2025-12-09 10:23:33.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 4163 LR: 0.000999959240568757 Training loss: 0.0
2025-12-09 10:23:33.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 4164 LR: 0.0009999592205077869 Training loss: 0.0
2025-12-09 10:23:33.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 4165 LR: 0.000999959200441881 Training loss: 0.0
2025-12-09 10:23:33.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 4166 LR: 0.0009999591803710399 Training loss: 0.0
2025-12-09 10:23:33.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 4167 LR: 0.0009999591602952633 Training loss: 0.0
2025-12-09 10:23:33.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 4168 LR: 0.0009999591402145513 Training loss: 0.0
2025-12-09 10:23:33.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 4169 LR: 0.000999959120128904 Training loss: 0.0
2025-12-09 10:23:33.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 4170 LR: 0.0009999591000383213 Training loss: 0.0
2025-12-09 10:23:33.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 4171 LR: 0.0009999590799428034 Training loss: 0.0
2025-12-09 10:23:33.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 4172 LR: 0.0009999590598423497 Training loss: 0.0
2025-12-09 10:23:33.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 4173 LR: 0.0009999590397369608 Training loss: 0.0
2025-12-09 10:23:33.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 4174 LR: 0.0009999590196266366 Training loss: 0.0
2025-12-09 10:23:33.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 4175 LR: 0.000999958999511377 Training loss: 0.0
2025-12-09 10:23:33.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 4176 LR: 0.000999958979391182 Training loss: 0.0
2025-12-09 10:23:33.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 4177 LR: 0.0009999589592660516 Training loss: 0.0
2025-12-09 10:23:33.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 4178 LR: 0.000999958939135986 Training loss: 0.0
2025-12-09 10:23:33.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 4179 LR: 0.0009999589190009847 Training loss: 0.0
2025-12-09 10:23:33.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 4180 LR: 0.000999958898861048 Training loss: 0.0
2025-12-09 10:23:33.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 4181 LR: 0.0009999588787161762 Training loss: 0.0
2025-12-09 10:23:33.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 4182 LR: 0.000999958858566369 Training loss: 0.0
2025-12-09 10:23:33.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 4183 LR: 0.0009999588384116264 Training loss: 0.0
2025-12-09 10:23:33.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 4184 LR: 0.0009999588182519482 Training loss: 0.0
2025-12-09 10:23:33.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 4185 LR: 0.0009999587980873347 Training loss: 0.0
2025-12-09 10:23:33.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 4186 LR: 0.000999958777917786 Training loss: 0.0
2025-12-09 10:23:33.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 4187 LR: 0.0009999587577433017 Training loss: 0.0
2025-12-09 10:23:33.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 4188 LR: 0.0009999587375638822 Training loss: 0.0
2025-12-09 10:23:33.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 4189 LR: 0.000999958717379527 Training loss: 0.0
2025-12-09 10:23:33.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 4190 LR: 0.0009999586971902368 Training loss: 0.0
2025-12-09 10:23:33.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 4191 LR: 0.000999958676996011 Training loss: 0.0
2025-12-09 10:23:33.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 4192 LR: 0.0009999586567968498 Training loss: 0.0
2025-12-09 10:23:33.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 4193 LR: 0.0009999586365927533 Training loss: 0.0
2025-12-09 10:23:33.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 4194 LR: 0.0009999586163837214 Training loss: 0.0
2025-12-09 10:23:33.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 4195 LR: 0.0009999585961697542 Training loss: 0.0
2025-12-09 10:23:33.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 4196 LR: 0.0009999585759508515 Training loss: 0.0
2025-12-09 10:23:33.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 4197 LR: 0.0009999585557270135 Training loss: 0.0
2025-12-09 10:23:33.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 4198 LR: 0.0009999585354982402 Training loss: 0.0
2025-12-09 10:23:33.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 4199 LR: 0.0009999585152645311 Training loss: 0.0
2025-12-09 10:23:33.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 4200 LR: 0.000999958495025887 Training loss: 0.0
2025-12-09 10:23:33.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 4201 LR: 0.0009999584747823074 Training loss: 0.0
2025-12-09 10:23:33.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 4202 LR: 0.0009999584545337926 Training loss: 0.0
2025-12-09 10:23:33.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 4203 LR: 0.0009999584342803424 Training loss: 0.0
2025-12-09 10:23:33.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 4204 LR: 0.0009999584140219567 Training loss: 0.0
2025-12-09 10:23:33.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 4205 LR: 0.0009999583937586355 Training loss: 0.0
2025-12-09 10:23:33.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 4206 LR: 0.000999958373490379 Training loss: 0.0
2025-12-09 10:23:33.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 4207 LR: 0.0009999583532171873 Training loss: 0.0
2025-12-09 10:23:33.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 4208 LR: 0.00099995833293906 Training loss: 0.0
2025-12-09 10:23:33.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 4209 LR: 0.0009999583126559975 Training loss: 0.0
2025-12-09 10:23:33.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 4210 LR: 0.0009999582923679996 Training loss: 0.0
2025-12-09 10:23:33.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 4211 LR: 0.0009999582720750663 Training loss: 0.0
2025-12-09 10:23:33.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 4212 LR: 0.0009999582517771974 Training loss: 0.0
2025-12-09 10:23:33.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 4213 LR: 0.0009999582314743933 Training loss: 0.0
2025-12-09 10:23:33.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 4214 LR: 0.0009999582111666538 Training loss: 0.0
2025-12-09 10:23:33.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 4215 LR: 0.000999958190853979 Training loss: 0.0
2025-12-09 10:23:33.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 4216 LR: 0.0009999581705363687 Training loss: 0.0
2025-12-09 10:23:33.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 4217 LR: 0.0009999581502138232 Training loss: 0.0
2025-12-09 10:23:33.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 4218 LR: 0.0009999581298863421 Training loss: 0.0
2025-12-09 10:23:33.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 4219 LR: 0.0009999581095539258 Training loss: 0.0
2025-12-09 10:23:33.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 4220 LR: 0.000999958089216574 Training loss: 0.0
2025-12-09 10:23:33.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 4221 LR: 0.000999958068874287 Training loss: 0.0
2025-12-09 10:23:33.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 4222 LR: 0.0009999580485270645 Training loss: 0.0
2025-12-09 10:23:33.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 4223 LR: 0.0009999580281749066 Training loss: 0.0
2025-12-09 10:23:33.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 4224 LR: 0.0009999580078178135 Training loss: 0.0
2025-12-09 10:23:33.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 4225 LR: 0.0009999579874557848 Training loss: 0.0
2025-12-09 10:23:33.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 4226 LR: 0.0009999579670888208 Training loss: 0.0
2025-12-09 10:23:33.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 4227 LR: 0.0009999579467169215 Training loss: 0.0
2025-12-09 10:23:33.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 4228 LR: 0.0009999579263400868 Training loss: 0.0
2025-12-09 10:23:33.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 4229 LR: 0.0009999579059583165 Training loss: 0.0
2025-12-09 10:23:33.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 4230 LR: 0.0009999578855716112 Training loss: 0.0
2025-12-09 10:23:33.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 4231 LR: 0.0009999578651799703 Training loss: 0.0
2025-12-09 10:23:33.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 4232 LR: 0.0009999578447833942 Training loss: 0.0
2025-12-09 10:23:33.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 4233 LR: 0.0009999578243818825 Training loss: 0.0
2025-12-09 10:23:33.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 4234 LR: 0.0009999578039754356 Training loss: 0.0
2025-12-09 10:23:33.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 4235 LR: 0.0009999577835640532 Training loss: 0.0
2025-12-09 10:23:33.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 4236 LR: 0.0009999577631477354 Training loss: 0.0
2025-12-09 10:23:33.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 4237 LR: 0.0009999577427264824 Training loss: 0.0
2025-12-09 10:23:33.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 4238 LR: 0.000999957722300294 Training loss: 0.0
2025-12-09 10:23:33.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 4239 LR: 0.00099995770186917 Training loss: 0.0
2025-12-09 10:23:33.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 4240 LR: 0.0009999576814331108 Training loss: 0.0
2025-12-09 10:23:33.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 4241 LR: 0.0009999576609921164 Training loss: 0.0
2025-12-09 10:23:33.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 4242 LR: 0.0009999576405461863 Training loss: 0.0
2025-12-09 10:23:33.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 4243 LR: 0.0009999576200953211 Training loss: 0.0
2025-12-09 10:23:33.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 4244 LR: 0.0009999575996395202 Training loss: 0.0
2025-12-09 10:23:33.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 4245 LR: 0.0009999575791787842 Training loss: 0.0
2025-12-09 10:23:33.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 4246 LR: 0.000999957558713113 Training loss: 0.0
2025-12-09 10:23:33.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 4247 LR: 0.0009999575382425062 Training loss: 0.0
2025-12-09 10:23:33.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 4248 LR: 0.000999957517766964 Training loss: 0.0
2025-12-09 10:23:33.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 4249 LR: 0.0009999574972864864 Training loss: 0.0
2025-12-09 10:23:33.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 4250 LR: 0.0009999574768010733 Training loss: 0.0
2025-12-09 10:23:33.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 4251 LR: 0.0009999574563107252 Training loss: 0.0
2025-12-09 10:23:33.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 4252 LR: 0.0009999574358154416 Training loss: 0.0
2025-12-09 10:23:33.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 4253 LR: 0.0009999574153152224 Training loss: 0.0
2025-12-09 10:23:33.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 4254 LR: 0.000999957394810068 Training loss: 0.0
2025-12-09 10:23:33.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 4255 LR: 0.0009999573742999783 Training loss: 0.0
2025-12-09 10:23:33.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 4256 LR: 0.0009999573537849533 Training loss: 0.0
2025-12-09 10:23:33.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 4257 LR: 0.0009999573332649927 Training loss: 0.0
2025-12-09 10:23:33.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 4258 LR: 0.000999957312740097 Training loss: 0.0
2025-12-09 10:23:33.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 4259 LR: 0.0009999572922102656 Training loss: 0.0
2025-12-09 10:23:33.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 4260 LR: 0.000999957271675499 Training loss: 0.0
2025-12-09 10:23:33.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 4261 LR: 0.0009999572511357972 Training loss: 0.0
2025-12-09 10:23:33.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 4262 LR: 0.0009999572305911598 Training loss: 0.0
2025-12-09 10:23:33.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 4263 LR: 0.000999957210041587 Training loss: 0.0
2025-12-09 10:23:33.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 4264 LR: 0.000999957189487079 Training loss: 0.0
2025-12-09 10:23:33.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 4265 LR: 0.0009999571689276357 Training loss: 0.0
2025-12-09 10:23:33.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 4266 LR: 0.000999957148363257 Training loss: 0.0
2025-12-09 10:23:33.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 4267 LR: 0.0009999571277939426 Training loss: 0.0
2025-12-09 10:23:33.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 4268 LR: 0.000999957107219693 Training loss: 0.0
2025-12-09 10:23:33.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 4269 LR: 0.000999957086640508 Training loss: 0.0
2025-12-09 10:23:33.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 4270 LR: 0.000999957066056388 Training loss: 0.0
2025-12-09 10:23:33.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 4271 LR: 0.0009999570454673323 Training loss: 0.0
2025-12-09 10:23:33.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 4272 LR: 0.0009999570248733413 Training loss: 0.0
2025-12-09 10:23:33.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 4273 LR: 0.000999957004274415 Training loss: 0.0
2025-12-09 10:23:33.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 4274 LR: 0.0009999569836705532 Training loss: 0.0
2025-12-09 10:23:33.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 4275 LR: 0.0009999569630617562 Training loss: 0.0
2025-12-09 10:23:33.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 4276 LR: 0.0009999569424480237 Training loss: 0.0
2025-12-09 10:23:33.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 4277 LR: 0.0009999569218293559 Training loss: 0.0
2025-12-09 10:23:33.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 4278 LR: 0.0009999569012057526 Training loss: 0.0
2025-12-09 10:23:33.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 4279 LR: 0.0009999568805772142 Training loss: 0.0
2025-12-09 10:23:33.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 4280 LR: 0.0009999568599437401 Training loss: 0.0
2025-12-09 10:23:33.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 4281 LR: 0.000999956839305331 Training loss: 0.0
2025-12-09 10:23:33.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 4282 LR: 0.0009999568186619863 Training loss: 0.0
2025-12-09 10:23:33.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 4283 LR: 0.0009999567980137063 Training loss: 0.0
2025-12-09 10:23:33.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 4284 LR: 0.000999956777360491 Training loss: 0.0
2025-12-09 10:23:33.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 4285 LR: 0.0009999567567023403 Training loss: 0.0
2025-12-09 10:23:33.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 4286 LR: 0.000999956736039254 Training loss: 0.0
2025-12-09 10:23:33.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 4287 LR: 0.0009999567153712327 Training loss: 0.0
2025-12-09 10:23:33.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 4288 LR: 0.0009999566946982759 Training loss: 0.0
2025-12-09 10:23:33.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 4289 LR: 0.0009999566740203838 Training loss: 0.0
2025-12-09 10:23:33.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 4290 LR: 0.0009999566533375561 Training loss: 0.0
2025-12-09 10:23:33.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 4291 LR: 0.0009999566326497932 Training loss: 0.0
2025-12-09 10:23:33.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 4292 LR: 0.000999956611957095 Training loss: 0.0
2025-12-09 10:23:33.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 4293 LR: 0.0009999565912594613 Training loss: 0.0
2025-12-09 10:23:33.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 4294 LR: 0.0009999565705568925 Training loss: 0.0
2025-12-09 10:23:33.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 4295 LR: 0.000999956549849388 Training loss: 0.0
2025-12-09 10:23:33.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 4296 LR: 0.0009999565291369484 Training loss: 0.0
2025-12-09 10:23:33.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 4297 LR: 0.0009999565084195733 Training loss: 0.0
2025-12-09 10:23:33.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 4298 LR: 0.000999956487697263 Training loss: 0.0
2025-12-09 10:23:33.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 4299 LR: 0.000999956466970017 Training loss: 0.0
2025-12-09 10:23:33.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 4300 LR: 0.000999956446237836 Training loss: 0.0
2025-12-09 10:23:33.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 4301 LR: 0.0009999564255007195 Training loss: 0.0
2025-12-09 10:23:33.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 4302 LR: 0.0009999564047586675 Training loss: 0.0
2025-12-09 10:23:33.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 4303 LR: 0.0009999563840116803 Training loss: 0.0
2025-12-09 10:23:33.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 4304 LR: 0.0009999563632597578 Training loss: 0.0
2025-12-09 10:23:33.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 4305 LR: 0.0009999563425029 Training loss: 0.0
2025-12-09 10:23:33.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 4306 LR: 0.0009999563217411066 Training loss: 0.0
2025-12-09 10:23:33.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 4307 LR: 0.000999956300974378 Training loss: 0.0
2025-12-09 10:23:33.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 4308 LR: 0.000999956280202714 Training loss: 0.0
2025-12-09 10:23:33.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 4309 LR: 0.0009999562594261145 Training loss: 0.0
2025-12-09 10:23:33.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 4310 LR: 0.0009999562386445798 Training loss: 0.0
2025-12-09 10:23:33.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 4311 LR: 0.0009999562178581098 Training loss: 0.0
2025-12-09 10:23:33.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 4312 LR: 0.0009999561970667043 Training loss: 0.0
2025-12-09 10:23:33.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 4313 LR: 0.0009999561762703635 Training loss: 0.0
2025-12-09 10:23:33.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 4314 LR: 0.0009999561554690875 Training loss: 0.0
2025-12-09 10:23:33.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 4315 LR: 0.0009999561346628759 Training loss: 0.0
2025-12-09 10:23:33.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 4316 LR: 0.000999956113851729 Training loss: 0.0
2025-12-09 10:23:33.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 4317 LR: 0.0009999560930356469 Training loss: 0.0
2025-12-09 10:23:33.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 4318 LR: 0.0009999560722146292 Training loss: 0.0
2025-12-09 10:23:33.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 4319 LR: 0.0009999560513886763 Training loss: 0.0
2025-12-09 10:23:33.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 4320 LR: 0.000999956030557788 Training loss: 0.0
2025-12-09 10:23:33.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 4321 LR: 0.0009999560097219645 Training loss: 0.0
2025-12-09 10:23:33.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 4322 LR: 0.0009999559888812053 Training loss: 0.0
2025-12-09 10:23:33.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 4323 LR: 0.000999955968035511 Training loss: 0.0
2025-12-09 10:23:33.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 4324 LR: 0.0009999559471848814 Training loss: 0.0
2025-12-09 10:23:33.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 4325 LR: 0.0009999559263293163 Training loss: 0.0
2025-12-09 10:23:33.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 4326 LR: 0.0009999559054688159 Training loss: 0.0
2025-12-09 10:23:33.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 4327 LR: 0.00099995588460338 Training loss: 0.0
2025-12-09 10:23:33.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 4328 LR: 0.000999955863733009 Training loss: 0.0
2025-12-09 10:23:33.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 4329 LR: 0.0009999558428577025 Training loss: 0.0
2025-12-09 10:23:33.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 4330 LR: 0.0009999558219774608 Training loss: 0.0
2025-12-09 10:23:33.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 4331 LR: 0.0009999558010922835 Training loss: 0.0
2025-12-09 10:23:33.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 4332 LR: 0.000999955780202171 Training loss: 0.0
2025-12-09 10:23:33.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 4333 LR: 0.000999955759307123 Training loss: 0.0
2025-12-09 10:23:33.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 4334 LR: 0.0009999557384071398 Training loss: 0.0
2025-12-09 10:23:33.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 4335 LR: 0.0009999557175022211 Training loss: 0.0
2025-12-09 10:23:33.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 4336 LR: 0.0009999556965923672 Training loss: 0.0
2025-12-09 10:23:33.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 4337 LR: 0.000999955675677578 Training loss: 0.0
2025-12-09 10:23:33.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 4338 LR: 0.0009999556547578533 Training loss: 0.0
2025-12-09 10:23:33.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 4339 LR: 0.0009999556338331933 Training loss: 0.0
2025-12-09 10:23:33.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 4340 LR: 0.000999955612903598 Training loss: 0.0
2025-12-09 10:23:33.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 4341 LR: 0.0009999555919690674 Training loss: 0.0
2025-12-09 10:23:33.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 4342 LR: 0.000999955571029601 Training loss: 0.0
2025-12-09 10:23:33.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 4343 LR: 0.0009999555500851997 Training loss: 0.0
2025-12-09 10:23:33.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 4344 LR: 0.000999955529135863 Training loss: 0.0
2025-12-09 10:23:33.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 4345 LR: 0.000999955508181591 Training loss: 0.0
2025-12-09 10:23:33.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 4346 LR: 0.0009999554872223836 Training loss: 0.0
2025-12-09 10:23:33.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 4347 LR: 0.0009999554662582406 Training loss: 0.0
2025-12-09 10:23:33.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 4348 LR: 0.0009999554452891624 Training loss: 0.0
2025-12-09 10:23:33.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 4349 LR: 0.000999955424315149 Training loss: 0.0
2025-12-09 10:23:33.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 4350 LR: 0.0009999554033362002 Training loss: 0.0
2025-12-09 10:23:33.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 4351 LR: 0.000999955382352316 Training loss: 0.0
2025-12-09 10:23:33.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 4352 LR: 0.0009999553613634965 Training loss: 0.0
2025-12-09 10:23:33.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 4353 LR: 0.0009999553403697414 Training loss: 0.0
2025-12-09 10:23:33.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 4354 LR: 0.0009999553193710512 Training loss: 0.0
2025-12-09 10:23:33.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 4355 LR: 0.0009999552983674257 Training loss: 0.0
2025-12-09 10:23:33.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 4356 LR: 0.0009999552773588647 Training loss: 0.0
2025-12-09 10:23:33.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 4357 LR: 0.0009999552563453684 Training loss: 0.0
2025-12-09 10:23:33.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 4358 LR: 0.0009999552353269368 Training loss: 0.0
2025-12-09 10:23:33.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 4359 LR: 0.0009999552143035698 Training loss: 0.0
2025-12-09 10:23:33.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 4360 LR: 0.0009999551932752674 Training loss: 0.0
2025-12-09 10:23:33.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 4361 LR: 0.0009999551722420297 Training loss: 0.0
2025-12-09 10:23:33.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 4362 LR: 0.0009999551512038568 Training loss: 0.0
2025-12-09 10:23:33.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 4363 LR: 0.0009999551301607484 Training loss: 0.0
2025-12-09 10:23:33.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 4364 LR: 0.0009999551091127046 Training loss: 0.0
2025-12-09 10:23:33.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 4365 LR: 0.0009999550880597254 Training loss: 0.0
2025-12-09 10:23:33.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 4366 LR: 0.000999955067001811 Training loss: 0.0
2025-12-09 10:23:33.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 4367 LR: 0.0009999550459389613 Training loss: 0.0
2025-12-09 10:23:33.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 4368 LR: 0.0009999550248711762 Training loss: 0.0
2025-12-09 10:23:33.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 4369 LR: 0.0009999550037984558 Training loss: 0.0
2025-12-09 10:23:33.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 4370 LR: 0.0009999549827208 Training loss: 0.0
2025-12-09 10:23:33.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 4371 LR: 0.000999954961638209 Training loss: 0.0
2025-12-09 10:23:33.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 4372 LR: 0.0009999549405506824 Training loss: 0.0
2025-12-09 10:23:33.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 4373 LR: 0.0009999549194582204 Training loss: 0.0
2025-12-09 10:23:33.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 4374 LR: 0.0009999548983608234 Training loss: 0.0
2025-12-09 10:23:33.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 4375 LR: 0.0009999548772584908 Training loss: 0.0
2025-12-09 10:23:33.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 4376 LR: 0.000999954856151223 Training loss: 0.0
2025-12-09 10:23:33.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 4377 LR: 0.0009999548350390196 Training loss: 0.0
2025-12-09 10:23:33.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 4378 LR: 0.0009999548139218812 Training loss: 0.0
2025-12-09 10:23:33.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 4379 LR: 0.0009999547927998073 Training loss: 0.0
2025-12-09 10:23:33.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 4380 LR: 0.000999954771672798 Training loss: 0.0
2025-12-09 10:23:33.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 4381 LR: 0.0009999547505408536 Training loss: 0.0
2025-12-09 10:23:33.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 4382 LR: 0.0009999547294039736 Training loss: 0.0
2025-12-09 10:23:33.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 4383 LR: 0.0009999547082621583 Training loss: 0.0
2025-12-09 10:23:33.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 4384 LR: 0.0009999546871154077 Training loss: 0.0
2025-12-09 10:23:33.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 4385 LR: 0.0009999546659637218 Training loss: 0.0
2025-12-09 10:23:33.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 4386 LR: 0.0009999546448071005 Training loss: 0.0
2025-12-09 10:23:33.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 4387 LR: 0.000999954623645544 Training loss: 0.0
2025-12-09 10:23:33.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 4388 LR: 0.0009999546024790518 Training loss: 0.0
2025-12-09 10:23:33.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 4389 LR: 0.0009999545813076246 Training loss: 0.0
2025-12-09 10:23:33.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 4390 LR: 0.0009999545601312618 Training loss: 0.0
2025-12-09 10:23:33.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 4391 LR: 0.0009999545389499638 Training loss: 0.0
2025-12-09 10:23:33.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 4392 LR: 0.0009999545177637305 Training loss: 0.0
2025-12-09 10:23:33.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 4393 LR: 0.0009999544965725619 Training loss: 0.0
2025-12-09 10:23:33.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 4394 LR: 0.000999954475376458 Training loss: 0.0
2025-12-09 10:23:33.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 4395 LR: 0.0009999544541754186 Training loss: 0.0
2025-12-09 10:23:33.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 4396 LR: 0.0009999544329694439 Training loss: 0.0
2025-12-09 10:23:33.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 4397 LR: 0.0009999544117585337 Training loss: 0.0
2025-12-09 10:23:33.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 4398 LR: 0.0009999543905426884 Training loss: 0.0
2025-12-09 10:23:33.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 4399 LR: 0.0009999543693219079 Training loss: 0.0
2025-12-09 10:23:33.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 4400 LR: 0.0009999543480961916 Training loss: 0.0
2025-12-09 10:23:33.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 4401 LR: 0.0009999543268655402 Training loss: 0.0
2025-12-09 10:23:33.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 4402 LR: 0.0009999543056299536 Training loss: 0.0
2025-12-09 10:23:33.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 4403 LR: 0.0009999542843894314 Training loss: 0.0
2025-12-09 10:23:33.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 4404 LR: 0.000999954263143974 Training loss: 0.0
2025-12-09 10:23:33.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 4405 LR: 0.0009999542418935813 Training loss: 0.0
2025-12-09 10:23:33.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 4406 LR: 0.0009999542206382533 Training loss: 0.0
2025-12-09 10:23:33.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 4407 LR: 0.0009999541993779898 Training loss: 0.0
2025-12-09 10:23:33.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 4408 LR: 0.000999954178112791 Training loss: 0.0
2025-12-09 10:23:33.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 4409 LR: 0.0009999541568426569 Training loss: 0.0
2025-12-09 10:23:33.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 4410 LR: 0.0009999541355675875 Training loss: 0.0
2025-12-09 10:23:33.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 4411 LR: 0.0009999541142875828 Training loss: 0.0
2025-12-09 10:23:33.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 4412 LR: 0.0009999540930026426 Training loss: 0.0
2025-12-09 10:23:33.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 4413 LR: 0.0009999540717127672 Training loss: 0.0
2025-12-09 10:23:33.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 4414 LR: 0.0009999540504179564 Training loss: 0.0
2025-12-09 10:23:33.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 4415 LR: 0.0009999540291182104 Training loss: 0.0
2025-12-09 10:23:33.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 4416 LR: 0.0009999540078135289 Training loss: 0.0
2025-12-09 10:23:33.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 4417 LR: 0.000999953986503912 Training loss: 0.0
2025-12-09 10:23:33.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 4418 LR: 0.00099995396518936 Training loss: 0.0
2025-12-09 10:23:33.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 4419 LR: 0.0009999539438698725 Training loss: 0.0
2025-12-09 10:23:33.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 4420 LR: 0.0009999539225454498 Training loss: 0.0
2025-12-09 10:23:33.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 4421 LR: 0.0009999539012160916 Training loss: 0.0
2025-12-09 10:23:33.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 4422 LR: 0.000999953879881798 Training loss: 0.0
2025-12-09 10:23:33.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 4423 LR: 0.0009999538585425693 Training loss: 0.0
2025-12-09 10:23:33.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 4424 LR: 0.0009999538371984053 Training loss: 0.0
2025-12-09 10:23:33.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 4425 LR: 0.0009999538158493057 Training loss: 0.0
2025-12-09 10:23:33.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 4426 LR: 0.000999953794495271 Training loss: 0.0
2025-12-09 10:23:33.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 4427 LR: 0.000999953773136301 Training loss: 0.0
2025-12-09 10:23:33.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 4428 LR: 0.0009999537517723952 Training loss: 0.0
2025-12-09 10:23:33.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 4429 LR: 0.0009999537304035547 Training loss: 0.0
2025-12-09 10:23:33.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 4430 LR: 0.0009999537090297785 Training loss: 0.0
2025-12-09 10:23:33.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 4431 LR: 0.000999953687651067 Training loss: 0.0
2025-12-09 10:23:33.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 4432 LR: 0.0009999536662674202 Training loss: 0.0
2025-12-09 10:23:33.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 4433 LR: 0.000999953644878838 Training loss: 0.0
2025-12-09 10:23:33.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 4434 LR: 0.0009999536234853207 Training loss: 0.0
2025-12-09 10:23:33.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 4435 LR: 0.0009999536020868678 Training loss: 0.0
2025-12-09 10:23:33.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 4436 LR: 0.0009999535806834799 Training loss: 0.0
2025-12-09 10:23:33.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 4437 LR: 0.0009999535592751564 Training loss: 0.0
2025-12-09 10:23:33.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 4438 LR: 0.0009999535378618976 Training loss: 0.0
2025-12-09 10:23:33.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 4439 LR: 0.0009999535164437034 Training loss: 0.0
2025-12-09 10:23:33.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 4440 LR: 0.000999953495020574 Training loss: 0.0
2025-12-09 10:23:33.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 4441 LR: 0.0009999534735925092 Training loss: 0.0
2025-12-09 10:23:33.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 4442 LR: 0.000999953452159509 Training loss: 0.0
2025-12-09 10:23:33.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 4443 LR: 0.0009999534307215737 Training loss: 0.0
2025-12-09 10:23:33.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 4444 LR: 0.000999953409278703 Training loss: 0.0
2025-12-09 10:23:33.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 4445 LR: 0.0009999533878308968 Training loss: 0.0
2025-12-09 10:23:33.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 4446 LR: 0.0009999533663781555 Training loss: 0.0
2025-12-09 10:23:33.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 4447 LR: 0.0009999533449204787 Training loss: 0.0
2025-12-09 10:23:33.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 4448 LR: 0.0009999533234578667 Training loss: 0.0
2025-12-09 10:23:33.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 4449 LR: 0.0009999533019903193 Training loss: 0.0
2025-12-09 10:23:33.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 4450 LR: 0.0009999532805178364 Training loss: 0.0
2025-12-09 10:23:33.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 4451 LR: 0.0009999532590404185 Training loss: 0.0
2025-12-09 10:23:33.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 4452 LR: 0.000999953237558065 Training loss: 0.0
2025-12-09 10:23:33.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 4453 LR: 0.0009999532160707763 Training loss: 0.0
2025-12-09 10:23:33.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 4454 LR: 0.0009999531945785523 Training loss: 0.0
2025-12-09 10:23:33.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 4455 LR: 0.0009999531730813928 Training loss: 0.0
2025-12-09 10:23:33.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 4456 LR: 0.0009999531515792984 Training loss: 0.0
2025-12-09 10:23:33.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 4457 LR: 0.000999953130072268 Training loss: 0.0
2025-12-09 10:23:33.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 4458 LR: 0.000999953108560303 Training loss: 0.0
2025-12-09 10:23:33.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 4459 LR: 0.0009999530870434023 Training loss: 0.0
2025-12-09 10:23:33.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 4460 LR: 0.0009999530655215663 Training loss: 0.0
2025-12-09 10:23:33.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 4461 LR: 0.0009999530439947948 Training loss: 0.0
2025-12-09 10:23:33.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 4462 LR: 0.000999953022463088 Training loss: 0.0
2025-12-09 10:23:33.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 4463 LR: 0.0009999530009264462 Training loss: 0.0
2025-12-09 10:23:33.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 4464 LR: 0.000999952979384869 Training loss: 0.0
2025-12-09 10:23:33.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 4465 LR: 0.0009999529578383563 Training loss: 0.0
2025-12-09 10:23:33.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 4466 LR: 0.0009999529362869084 Training loss: 0.0
2025-12-09 10:23:33.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 4467 LR: 0.0009999529147305252 Training loss: 0.0
2025-12-09 10:23:33.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 4468 LR: 0.0009999528931692065 Training loss: 0.0
2025-12-09 10:23:33.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 4469 LR: 0.0009999528716029525 Training loss: 0.0
2025-12-09 10:23:33.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 4470 LR: 0.0009999528500317634 Training loss: 0.0
2025-12-09 10:23:33.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 4471 LR: 0.0009999528284556386 Training loss: 0.0
2025-12-09 10:23:33.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 4472 LR: 0.000999952806874579 Training loss: 0.0
2025-12-09 10:23:33.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 4473 LR: 0.0009999527852885836 Training loss: 0.0
2025-12-09 10:23:33.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 4474 LR: 0.000999952763697653 Training loss: 0.0
2025-12-09 10:23:33.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 4475 LR: 0.0009999527421017873 Training loss: 0.0
2025-12-09 10:23:33.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 4476 LR: 0.000999952720500986 Training loss: 0.0
2025-12-09 10:23:33.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 4477 LR: 0.0009999526988952495 Training loss: 0.0
2025-12-09 10:23:33.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 4478 LR: 0.0009999526772845777 Training loss: 0.0
2025-12-09 10:23:33.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 4479 LR: 0.0009999526556689706 Training loss: 0.0
2025-12-09 10:23:33.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 4480 LR: 0.000999952634048428 Training loss: 0.0
2025-12-09 10:23:33.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 4481 LR: 0.0009999526124229504 Training loss: 0.0
2025-12-09 10:23:33.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 4482 LR: 0.000999952590792537 Training loss: 0.0
2025-12-09 10:23:33.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 4483 LR: 0.0009999525691571887 Training loss: 0.0
2025-12-09 10:23:33.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 4484 LR: 0.000999952547516905 Training loss: 0.0
2025-12-09 10:23:33.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 4485 LR: 0.0009999525258716857 Training loss: 0.0
2025-12-09 10:23:33.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 4486 LR: 0.0009999525042215314 Training loss: 0.0
2025-12-09 10:23:33.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 4487 LR: 0.0009999524825664416 Training loss: 0.0
2025-12-09 10:23:33.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 4488 LR: 0.0009999524609064165 Training loss: 0.0
2025-12-09 10:23:33.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 4489 LR: 0.0009999524392414563 Training loss: 0.0
2025-12-09 10:23:33.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 4490 LR: 0.0009999524175715606 Training loss: 0.0
2025-12-09 10:23:33.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 4491 LR: 0.0009999523958967296 Training loss: 0.0
2025-12-09 10:23:33.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 4492 LR: 0.0009999523742169633 Training loss: 0.0
2025-12-09 10:23:33.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 4493 LR: 0.0009999523525322615 Training loss: 0.0
2025-12-09 10:23:33.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 4494 LR: 0.0009999523308426247 Training loss: 0.0
2025-12-09 10:23:33.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 4495 LR: 0.0009999523091480523 Training loss: 0.0
2025-12-09 10:23:33.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 4496 LR: 0.0009999522874485447 Training loss: 0.0
2025-12-09 10:23:33.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 4497 LR: 0.0009999522657441018 Training loss: 0.0
2025-12-09 10:23:33.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 4498 LR: 0.0009999522440347236 Training loss: 0.0
2025-12-09 10:23:33.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 4499 LR: 0.00099995222232041 Training loss: 0.0
2025-12-09 10:23:33.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 4500 LR: 0.0009999522006011612 Training loss: 0.0
2025-12-09 10:23:33.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 4501 LR: 0.000999952178876977 Training loss: 0.0
2025-12-09 10:23:33.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 4502 LR: 0.0009999521571478576 Training loss: 0.0
2025-12-09 10:23:33.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 4503 LR: 0.0009999521354138025 Training loss: 0.0
2025-12-09 10:23:33.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 4504 LR: 0.0009999521136748123 Training loss: 0.0
2025-12-09 10:23:33.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 4505 LR: 0.000999952091930887 Training loss: 0.0
2025-12-09 10:23:33.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 4506 LR: 0.0009999520701820263 Training loss: 0.0
2025-12-09 10:23:33.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 4507 LR: 0.00099995204842823 Training loss: 0.0
2025-12-09 10:23:33.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 4508 LR: 0.0009999520266694988 Training loss: 0.0
2025-12-09 10:23:33.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 4509 LR: 0.000999952004905832 Training loss: 0.0
2025-12-09 10:23:33.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 4510 LR: 0.00099995198313723 Training loss: 0.0
2025-12-09 10:23:33.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 4511 LR: 0.0009999519613636927 Training loss: 0.0
2025-12-09 10:23:33.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 4512 LR: 0.00099995193958522 Training loss: 0.0
2025-12-09 10:23:33.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 4513 LR: 0.000999951917801812 Training loss: 0.0
2025-12-09 10:23:33.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 4514 LR: 0.0009999518960134687 Training loss: 0.0
2025-12-09 10:23:33.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 4515 LR: 0.0009999518742201902 Training loss: 0.0
2025-12-09 10:23:33.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 4516 LR: 0.0009999518524219761 Training loss: 0.0
2025-12-09 10:23:33.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 4517 LR: 0.000999951830618827 Training loss: 0.0
2025-12-09 10:23:33.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 4518 LR: 0.0009999518088107423 Training loss: 0.0
2025-12-09 10:23:33.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 4519 LR: 0.0009999517869977224 Training loss: 0.0
2025-12-09 10:23:33.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 4520 LR: 0.0009999517651797674 Training loss: 0.0
2025-12-09 10:23:33.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 4521 LR: 0.0009999517433568767 Training loss: 0.0
2025-12-09 10:23:33.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 4522 LR: 0.000999951721529051 Training loss: 0.0
2025-12-09 10:23:33.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 4523 LR: 0.0009999516996962898 Training loss: 0.0
2025-12-09 10:23:33.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 4524 LR: 0.0009999516778585935 Training loss: 0.0
2025-12-09 10:23:33.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 4525 LR: 0.0009999516560159616 Training loss: 0.0
2025-12-09 10:23:33.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 4526 LR: 0.0009999516341683947 Training loss: 0.0
2025-12-09 10:23:33.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 4527 LR: 0.0009999516123158922 Training loss: 0.0
2025-12-09 10:23:33.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 4528 LR: 0.0009999515904584547 Training loss: 0.0
2025-12-09 10:23:33.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 4529 LR: 0.0009999515685960817 Training loss: 0.0
2025-12-09 10:23:33.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 4530 LR: 0.0009999515467287734 Training loss: 0.0
2025-12-09 10:23:33.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 4531 LR: 0.0009999515248565296 Training loss: 0.0
2025-12-09 10:23:33.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 4532 LR: 0.0009999515029793509 Training loss: 0.0
2025-12-09 10:23:33.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 4533 LR: 0.0009999514810972365 Training loss: 0.0
2025-12-09 10:23:33.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 4534 LR: 0.000999951459210187 Training loss: 0.0
2025-12-09 10:23:33.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 4535 LR: 0.000999951437318202 Training loss: 0.0
2025-12-09 10:23:33.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 4536 LR: 0.0009999514154212818 Training loss: 0.0
2025-12-09 10:23:33.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 4537 LR: 0.0009999513935194265 Training loss: 0.0
2025-12-09 10:23:33.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 4538 LR: 0.0009999513716126356 Training loss: 0.0
2025-12-09 10:23:33.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 4539 LR: 0.0009999513497009095 Training loss: 0.0
2025-12-09 10:23:33.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 4540 LR: 0.0009999513277842483 Training loss: 0.0
2025-12-09 10:23:33.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 4541 LR: 0.0009999513058626514 Training loss: 0.0
2025-12-09 10:23:33.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 4542 LR: 0.0009999512839361194 Training loss: 0.0
2025-12-09 10:23:33.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 4543 LR: 0.0009999512620046521 Training loss: 0.0
2025-12-09 10:23:33.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 4544 LR: 0.0009999512400682496 Training loss: 0.0
2025-12-09 10:23:33.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 4545 LR: 0.0009999512181269115 Training loss: 0.0
2025-12-09 10:23:33.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 4546 LR: 0.0009999511961806381 Training loss: 0.0
2025-12-09 10:23:33.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 4547 LR: 0.0009999511742294297 Training loss: 0.0
2025-12-09 10:23:33.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 4548 LR: 0.0009999511522732858 Training loss: 0.0
2025-12-09 10:23:33.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 4549 LR: 0.0009999511303122066 Training loss: 0.0
2025-12-09 10:23:33.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 4550 LR: 0.0009999511083461923 Training loss: 0.0
2025-12-09 10:23:33.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 4551 LR: 0.0009999510863752423 Training loss: 0.0
2025-12-09 10:23:33.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 4552 LR: 0.0009999510643993572 Training loss: 0.0
2025-12-09 10:23:33.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 4553 LR: 0.000999951042418537 Training loss: 0.0
2025-12-09 10:23:33.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 4554 LR: 0.0009999510204327811 Training loss: 0.0
2025-12-09 10:23:33.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 4555 LR: 0.0009999509984420902 Training loss: 0.0
2025-12-09 10:23:33.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 4556 LR: 0.0009999509764464637 Training loss: 0.0
2025-12-09 10:23:33.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 4557 LR: 0.0009999509544459022 Training loss: 0.0
2025-12-09 10:23:33.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 4558 LR: 0.0009999509324404052 Training loss: 0.0
2025-12-09 10:23:33.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 4559 LR: 0.000999950910429973 Training loss: 0.0
2025-12-09 10:23:33.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 4560 LR: 0.0009999508884146057 Training loss: 0.0
2025-12-09 10:23:33.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 4561 LR: 0.0009999508663943028 Training loss: 0.0
2025-12-09 10:23:33.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 4562 LR: 0.0009999508443690646 Training loss: 0.0
2025-12-09 10:23:33.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 4563 LR: 0.000999950822338891 Training loss: 0.0
2025-12-09 10:23:33.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 4564 LR: 0.0009999508003037823 Training loss: 0.0
2025-12-09 10:23:33.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 4565 LR: 0.0009999507782637383 Training loss: 0.0
2025-12-09 10:23:33.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 4566 LR: 0.000999950756218759 Training loss: 0.0
2025-12-09 10:23:33.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 4567 LR: 0.0009999507341688443 Training loss: 0.0
2025-12-09 10:23:33.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 4568 LR: 0.0009999507121139944 Training loss: 0.0
2025-12-09 10:23:33.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 4569 LR: 0.000999950690054209 Training loss: 0.0
2025-12-09 10:23:33.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 4570 LR: 0.0009999506679894885 Training loss: 0.0
2025-12-09 10:23:33.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 4571 LR: 0.0009999506459198325 Training loss: 0.0
2025-12-09 10:23:33.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 4572 LR: 0.0009999506238452414 Training loss: 0.0
2025-12-09 10:23:33.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 4573 LR: 0.000999950601765715 Training loss: 0.0
2025-12-09 10:23:33.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 4574 LR: 0.0009999505796812532 Training loss: 0.0
2025-12-09 10:23:33.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 4575 LR: 0.000999950557591856 Training loss: 0.0
2025-12-09 10:23:33.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 4576 LR: 0.0009999505354975236 Training loss: 0.0
2025-12-09 10:23:33.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 4577 LR: 0.0009999505133982559 Training loss: 0.0
2025-12-09 10:23:33.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 4578 LR: 0.0009999504912940529 Training loss: 0.0
2025-12-09 10:23:33.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 4579 LR: 0.0009999504691849145 Training loss: 0.0
2025-12-09 10:23:33.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 4580 LR: 0.0009999504470708412 Training loss: 0.0
2025-12-09 10:23:33.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 4581 LR: 0.0009999504249518323 Training loss: 0.0
2025-12-09 10:23:33.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 4582 LR: 0.0009999504028278881 Training loss: 0.0
2025-12-09 10:23:33.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 4583 LR: 0.0009999503806990084 Training loss: 0.0
2025-12-09 10:23:33.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 4584 LR: 0.0009999503585651937 Training loss: 0.0
2025-12-09 10:23:33.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 4585 LR: 0.0009999503364264437 Training loss: 0.0
2025-12-09 10:23:33.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 4586 LR: 0.0009999503142827581 Training loss: 0.0
2025-12-09 10:23:33.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 4587 LR: 0.0009999502921341375 Training loss: 0.0
2025-12-09 10:23:33.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 4588 LR: 0.0009999502699805816 Training loss: 0.0
2025-12-09 10:23:33.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 4589 LR: 0.0009999502478220904 Training loss: 0.0
2025-12-09 10:23:33.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 4590 LR: 0.0009999502256586637 Training loss: 0.0
2025-12-09 10:23:33.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 4591 LR: 0.0009999502034903017 Training loss: 0.0
2025-12-09 10:23:33.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 4592 LR: 0.0009999501813170047 Training loss: 0.0
2025-12-09 10:23:33.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 4593 LR: 0.0009999501591387721 Training loss: 0.0
2025-12-09 10:23:33.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 4594 LR: 0.0009999501369556045 Training loss: 0.0
2025-12-09 10:23:33.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 4595 LR: 0.0009999501147675014 Training loss: 0.0
2025-12-09 10:23:33.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 4596 LR: 0.000999950092574463 Training loss: 0.0
2025-12-09 10:23:33.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 4597 LR: 0.0009999500703764892 Training loss: 0.0
2025-12-09 10:23:33.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 4598 LR: 0.0009999500481735805 Training loss: 0.0
2025-12-09 10:23:33.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 4599 LR: 0.0009999500259657362 Training loss: 0.0
2025-12-09 10:23:33.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 4600 LR: 0.0009999500037529566 Training loss: 0.0
2025-12-09 10:23:33.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 4601 LR: 0.0009999499815352417 Training loss: 0.0
2025-12-09 10:23:33.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 4602 LR: 0.0009999499593125916 Training loss: 0.0
2025-12-09 10:23:33.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 4603 LR: 0.0009999499370850061 Training loss: 0.0
2025-12-09 10:23:33.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 4604 LR: 0.0009999499148524854 Training loss: 0.0
2025-12-09 10:23:33.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 4605 LR: 0.0009999498926150294 Training loss: 0.0
2025-12-09 10:23:33.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 4606 LR: 0.000999949870372638 Training loss: 0.0
2025-12-09 10:23:33.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 4607 LR: 0.0009999498481253115 Training loss: 0.0
2025-12-09 10:23:33.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 4608 LR: 0.0009999498258730494 Training loss: 0.0
2025-12-09 10:23:33.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 4609 LR: 0.0009999498036158522 Training loss: 0.0
2025-12-09 10:23:33.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 4610 LR: 0.0009999497813537198 Training loss: 0.0
2025-12-09 10:23:33.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 4611 LR: 0.000999949759086652 Training loss: 0.0
2025-12-09 10:23:33.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 4612 LR: 0.000999949736814649 Training loss: 0.0
2025-12-09 10:23:33.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 4613 LR: 0.0009999497145377107 Training loss: 0.0
2025-12-09 10:23:33.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 4614 LR: 0.0009999496922558368 Training loss: 0.0
2025-12-09 10:23:33.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 4615 LR: 0.000999949669969028 Training loss: 0.0
2025-12-09 10:23:33.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 4616 LR: 0.0009999496476772837 Training loss: 0.0
2025-12-09 10:23:33.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 4617 LR: 0.0009999496253806043 Training loss: 0.0
2025-12-09 10:23:33.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 4618 LR: 0.0009999496030789893 Training loss: 0.0
2025-12-09 10:23:33.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 4619 LR: 0.0009999495807724392 Training loss: 0.0
2025-12-09 10:23:33.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 4620 LR: 0.0009999495584609537 Training loss: 0.0
2025-12-09 10:23:33.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 4621 LR: 0.000999949536144533 Training loss: 0.0
2025-12-09 10:23:33.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 4622 LR: 0.0009999495138231771 Training loss: 0.0
2025-12-09 10:23:33.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 4623 LR: 0.0009999494914968857 Training loss: 0.0
2025-12-09 10:23:33.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 4624 LR: 0.0009999494691656592 Training loss: 0.0
2025-12-09 10:23:33.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 4625 LR: 0.0009999494468294972 Training loss: 0.0
2025-12-09 10:23:33.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 4626 LR: 0.0009999494244884001 Training loss: 0.0
2025-12-09 10:23:33.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 4627 LR: 0.0009999494021423676 Training loss: 0.0
2025-12-09 10:23:33.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 4628 LR: 0.0009999493797914 Training loss: 0.0
2025-12-09 10:23:33.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 4629 LR: 0.0009999493574354968 Training loss: 0.0
2025-12-09 10:23:33.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 4630 LR: 0.0009999493350746585 Training loss: 0.0
2025-12-09 10:23:33.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 4631 LR: 0.0009999493127088848 Training loss: 0.0
2025-12-09 10:23:33.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 4632 LR: 0.000999949290338176 Training loss: 0.0
2025-12-09 10:23:33.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 4633 LR: 0.000999949267962532 Training loss: 0.0
2025-12-09 10:23:33.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 4634 LR: 0.0009999492455819523 Training loss: 0.0
2025-12-09 10:23:33.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 4635 LR: 0.0009999492231964377 Training loss: 0.0
2025-12-09 10:23:33.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 4636 LR: 0.0009999492008059875 Training loss: 0.0
2025-12-09 10:23:33.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 4637 LR: 0.0009999491784106022 Training loss: 0.0
2025-12-09 10:23:33.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 4638 LR: 0.0009999491560102815 Training loss: 0.0
2025-12-09 10:23:33.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 4639 LR: 0.0009999491336050257 Training loss: 0.0
2025-12-09 10:23:33.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 4640 LR: 0.0009999491111948343 Training loss: 0.0
2025-12-09 10:23:33.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 4641 LR: 0.000999949088779708 Training loss: 0.0
2025-12-09 10:23:33.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 4642 LR: 0.000999949066359646 Training loss: 0.0
2025-12-09 10:23:33.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 4643 LR: 0.000999949043934649 Training loss: 0.0
2025-12-09 10:23:33.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 4644 LR: 0.0009999490215047166 Training loss: 0.0
2025-12-09 10:23:33.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 4645 LR: 0.000999948999069849 Training loss: 0.0
2025-12-09 10:23:33.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 4646 LR: 0.0009999489766300462 Training loss: 0.0
2025-12-09 10:23:33.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 4647 LR: 0.0009999489541853079 Training loss: 0.0
2025-12-09 10:23:33.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 4648 LR: 0.0009999489317356345 Training loss: 0.0
2025-12-09 10:23:33.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 4649 LR: 0.0009999489092810258 Training loss: 0.0
2025-12-09 10:23:33.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 4650 LR: 0.0009999488868214816 Training loss: 0.0
2025-12-09 10:23:33.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 4651 LR: 0.0009999488643570023 Training loss: 0.0
2025-12-09 10:23:33.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 4652 LR: 0.0009999488418875875 Training loss: 0.0
2025-12-09 10:23:33.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 4653 LR: 0.0009999488194132376 Training loss: 0.0
2025-12-09 10:23:33.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 4654 LR: 0.0009999487969339525 Training loss: 0.0
2025-12-09 10:23:33.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 4655 LR: 0.000999948774449732 Training loss: 0.0
2025-12-09 10:23:33.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 4656 LR: 0.0009999487519605761 Training loss: 0.0
2025-12-09 10:23:33.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 4657 LR: 0.0009999487294664851 Training loss: 0.0
2025-12-09 10:23:33.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 4658 LR: 0.0009999487069674588 Training loss: 0.0
2025-12-09 10:23:33.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 4659 LR: 0.0009999486844634972 Training loss: 0.0
2025-12-09 10:23:33.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 4660 LR: 0.0009999486619546004 Training loss: 0.0
2025-12-09 10:23:33.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 4661 LR: 0.000999948639440768 Training loss: 0.0
2025-12-09 10:23:33.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 4662 LR: 0.0009999486169220005 Training loss: 0.0
2025-12-09 10:23:33.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 4663 LR: 0.0009999485943982978 Training loss: 0.0
2025-12-09 10:23:33.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 4664 LR: 0.0009999485718696598 Training loss: 0.0
2025-12-09 10:23:33.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 4665 LR: 0.0009999485493360865 Training loss: 0.0
2025-12-09 10:23:33.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 4666 LR: 0.0009999485267975779 Training loss: 0.0
2025-12-09 10:23:33.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 4667 LR: 0.0009999485042541342 Training loss: 0.0
2025-12-09 10:23:33.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 4668 LR: 0.000999948481705755 Training loss: 0.0
2025-12-09 10:23:33.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 4669 LR: 0.0009999484591524403 Training loss: 0.0
2025-12-09 10:23:33.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 4670 LR: 0.0009999484365941906 Training loss: 0.0
2025-12-09 10:23:33.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 4671 LR: 0.0009999484140310057 Training loss: 0.0
2025-12-09 10:23:33.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 4672 LR: 0.0009999483914628854 Training loss: 0.0
2025-12-09 10:23:33.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 4673 LR: 0.0009999483688898298 Training loss: 0.0
2025-12-09 10:23:33.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 4674 LR: 0.000999948346311839 Training loss: 0.0
2025-12-09 10:23:33.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 4675 LR: 0.0009999483237289129 Training loss: 0.0
2025-12-09 10:23:33.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 4676 LR: 0.0009999483011410514 Training loss: 0.0
2025-12-09 10:23:33.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 4677 LR: 0.0009999482785482548 Training loss: 0.0
2025-12-09 10:23:33.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 4678 LR: 0.0009999482559505228 Training loss: 0.0
2025-12-09 10:23:33.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 4679 LR: 0.0009999482333478556 Training loss: 0.0
2025-12-09 10:23:33.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 4680 LR: 0.000999948210740253 Training loss: 0.0
2025-12-09 10:23:33.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 4681 LR: 0.0009999481881277153 Training loss: 0.0
2025-12-09 10:23:33.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 4682 LR: 0.0009999481655102423 Training loss: 0.0
2025-12-09 10:23:33.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 4683 LR: 0.0009999481428878338 Training loss: 0.0
2025-12-09 10:23:33.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 4684 LR: 0.0009999481202604902 Training loss: 0.0
2025-12-09 10:23:33.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 4685 LR: 0.0009999480976282114 Training loss: 0.0
2025-12-09 10:23:33.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 4686 LR: 0.0009999480749909972 Training loss: 0.0
2025-12-09 10:23:33.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 4687 LR: 0.0009999480523488478 Training loss: 0.0
2025-12-09 10:23:33.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 4688 LR: 0.000999948029701763 Training loss: 0.0
2025-12-09 10:23:33.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 4689 LR: 0.000999948007049743 Training loss: 0.0
2025-12-09 10:23:33.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 4690 LR: 0.0009999479843927877 Training loss: 0.0
2025-12-09 10:23:33.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 4691 LR: 0.0009999479617308971 Training loss: 0.0
2025-12-09 10:23:33.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 4692 LR: 0.0009999479390640712 Training loss: 0.0
2025-12-09 10:23:33.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 4693 LR: 0.0009999479163923103 Training loss: 0.0
2025-12-09 10:23:33.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 4694 LR: 0.0009999478937156138 Training loss: 0.0
2025-12-09 10:23:33.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 4695 LR: 0.0009999478710339823 Training loss: 0.0
2025-12-09 10:23:33.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 4696 LR: 0.000999947848347415 Training loss: 0.0
2025-12-09 10:23:33.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 4697 LR: 0.000999947825655913 Training loss: 0.0
2025-12-09 10:23:33.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 4698 LR: 0.0009999478029594755 Training loss: 0.0
2025-12-09 10:23:33.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 4699 LR: 0.0009999477802581026 Training loss: 0.0
2025-12-09 10:23:33.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 4700 LR: 0.000999947757551795 Training loss: 0.0
2025-12-09 10:23:33.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 4701 LR: 0.0009999477348405514 Training loss: 0.0
2025-12-09 10:23:33.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 4702 LR: 0.0009999477121243729 Training loss: 0.0
2025-12-09 10:23:33.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 4703 LR: 0.000999947689403259 Training loss: 0.0
2025-12-09 10:23:33.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 4704 LR: 0.00099994766667721 Training loss: 0.0
2025-12-09 10:23:33.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 4705 LR: 0.0009999476439462255 Training loss: 0.0
2025-12-09 10:23:33.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 4706 LR: 0.0009999476212103058 Training loss: 0.0
2025-12-09 10:23:33.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 4707 LR: 0.0009999475984694508 Training loss: 0.0
2025-12-09 10:23:34.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 4708 LR: 0.0009999475757236607 Training loss: 0.0
2025-12-09 10:23:34.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 4709 LR: 0.0009999475529729352 Training loss: 0.0
2025-12-09 10:23:34.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 4710 LR: 0.0009999475302172743 Training loss: 0.0
2025-12-09 10:23:34.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 4711 LR: 0.0009999475074566784 Training loss: 0.0
2025-12-09 10:23:34.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 4712 LR: 0.000999947484691147 Training loss: 0.0
2025-12-09 10:23:34.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 4713 LR: 0.0009999474619206805 Training loss: 0.0
2025-12-09 10:23:34.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 4714 LR: 0.0009999474391452787 Training loss: 0.0
2025-12-09 10:23:34.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 4715 LR: 0.0009999474163649416 Training loss: 0.0
2025-12-09 10:23:34.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 4716 LR: 0.0009999473935796692 Training loss: 0.0
2025-12-09 10:23:34.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 4717 LR: 0.0009999473707894616 Training loss: 0.0
2025-12-09 10:23:34.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 4718 LR: 0.0009999473479943186 Training loss: 0.0
2025-12-09 10:23:34.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 4719 LR: 0.0009999473251942404 Training loss: 0.0
2025-12-09 10:23:34.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 4720 LR: 0.0009999473023892269 Training loss: 0.0
2025-12-09 10:23:34.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 4721 LR: 0.000999947279579278 Training loss: 0.0
2025-12-09 10:23:34.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 4722 LR: 0.0009999472567643942 Training loss: 0.0
2025-12-09 10:23:34.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 4723 LR: 0.0009999472339445748 Training loss: 0.0
2025-12-09 10:23:34.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 4724 LR: 0.0009999472111198204 Training loss: 0.0
2025-12-09 10:23:34.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 4725 LR: 0.0009999471882901306 Training loss: 0.0
2025-12-09 10:23:34.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 4726 LR: 0.0009999471654555054 Training loss: 0.0
2025-12-09 10:23:34.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 4727 LR: 0.0009999471426159453 Training loss: 0.0
2025-12-09 10:23:34.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 4728 LR: 0.0009999471197714496 Training loss: 0.0
2025-12-09 10:23:34.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 4729 LR: 0.0009999470969220188 Training loss: 0.0
2025-12-09 10:23:34.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 4730 LR: 0.0009999470740676526 Training loss: 0.0
2025-12-09 10:23:34.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 4731 LR: 0.000999947051208351 Training loss: 0.0
2025-12-09 10:23:34.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 4732 LR: 0.0009999470283441145 Training loss: 0.0
2025-12-09 10:23:34.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 4733 LR: 0.0009999470054749425 Training loss: 0.0
2025-12-09 10:23:34.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 4734 LR: 0.0009999469826008354 Training loss: 0.0
2025-12-09 10:23:34.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 4735 LR: 0.0009999469597217927 Training loss: 0.0
2025-12-09 10:23:34.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 4736 LR: 0.000999946936837815 Training loss: 0.0
2025-12-09 10:23:34.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 4737 LR: 0.000999946913948902 Training loss: 0.0
2025-12-09 10:23:34.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 4738 LR: 0.0009999468910550538 Training loss: 0.0
2025-12-09 10:23:34.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 4739 LR: 0.0009999468681562702 Training loss: 0.0
2025-12-09 10:23:34.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 4740 LR: 0.0009999468452525514 Training loss: 0.0
2025-12-09 10:23:34.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 4741 LR: 0.0009999468223438974 Training loss: 0.0
2025-12-09 10:23:34.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 4742 LR: 0.000999946799430308 Training loss: 0.0
2025-12-09 10:23:34.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 4743 LR: 0.0009999467765117835 Training loss: 0.0
2025-12-09 10:23:34.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 4744 LR: 0.0009999467535883235 Training loss: 0.0
2025-12-09 10:23:34.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 4745 LR: 0.0009999467306599284 Training loss: 0.0
2025-12-09 10:23:34.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 4746 LR: 0.000999946707726598 Training loss: 0.0
2025-12-09 10:23:34.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 4747 LR: 0.0009999466847883324 Training loss: 0.0
2025-12-09 10:23:34.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 4748 LR: 0.0009999466618451315 Training loss: 0.0
2025-12-09 10:23:34.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 4749 LR: 0.0009999466388969952 Training loss: 0.0
2025-12-09 10:23:34.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 4750 LR: 0.000999946615943924 Training loss: 0.0
2025-12-09 10:23:34.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 4751 LR: 0.0009999465929859174 Training loss: 0.0
2025-12-09 10:23:34.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 4752 LR: 0.0009999465700229753 Training loss: 0.0
2025-12-09 10:23:34.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 4753 LR: 0.000999946547055098 Training loss: 0.0
2025-12-09 10:23:34.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 4754 LR: 0.0009999465240822856 Training loss: 0.0
2025-12-09 10:23:34.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 4755 LR: 0.0009999465011045377 Training loss: 0.0
2025-12-09 10:23:34.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 4756 LR: 0.0009999464781218549 Training loss: 0.0
2025-12-09 10:23:34.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 4757 LR: 0.0009999464551342365 Training loss: 0.0
2025-12-09 10:23:34.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 4758 LR: 0.000999946432141683 Training loss: 0.0
2025-12-09 10:23:34.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 4759 LR: 0.0009999464091441943 Training loss: 0.0
2025-12-09 10:23:34.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 4760 LR: 0.00099994638614177 Training loss: 0.0
2025-12-09 10:23:34.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 4761 LR: 0.0009999463631344108 Training loss: 0.0
2025-12-09 10:23:34.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 4762 LR: 0.0009999463401221163 Training loss: 0.0
2025-12-09 10:23:34.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 4763 LR: 0.0009999463171048864 Training loss: 0.0
2025-12-09 10:23:34.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 4764 LR: 0.0009999462940827213 Training loss: 0.0
2025-12-09 10:23:34.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 4765 LR: 0.0009999462710556211 Training loss: 0.0
2025-12-09 10:23:34.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 4766 LR: 0.0009999462480235854 Training loss: 0.0
2025-12-09 10:23:34.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 4767 LR: 0.0009999462249866144 Training loss: 0.0
2025-12-09 10:23:34.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 4768 LR: 0.0009999462019447084 Training loss: 0.0
2025-12-09 10:23:34.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 4769 LR: 0.000999946178897867 Training loss: 0.0
2025-12-09 10:23:34.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 4770 LR: 0.0009999461558460904 Training loss: 0.0
2025-12-09 10:23:34.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 4771 LR: 0.0009999461327893785 Training loss: 0.0
2025-12-09 10:23:34.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 4772 LR: 0.0009999461097277313 Training loss: 0.0
2025-12-09 10:23:34.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 4773 LR: 0.000999946086661149 Training loss: 0.0
2025-12-09 10:23:34.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 4774 LR: 0.0009999460635896312 Training loss: 0.0
2025-12-09 10:23:34.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 4775 LR: 0.0009999460405131784 Training loss: 0.0
2025-12-09 10:23:34.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 4776 LR: 0.0009999460174317902 Training loss: 0.0
2025-12-09 10:23:34.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 4777 LR: 0.0009999459943454668 Training loss: 0.0
2025-12-09 10:23:34.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 4778 LR: 0.000999945971254208 Training loss: 0.0
2025-12-09 10:23:34.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 4779 LR: 0.000999945948158014 Training loss: 0.0
2025-12-09 10:23:34.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 4780 LR: 0.000999945925056885 Training loss: 0.0
2025-12-09 10:23:34.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 4781 LR: 0.0009999459019508204 Training loss: 0.0
2025-12-09 10:23:34.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 4782 LR: 0.0009999458788398205 Training loss: 0.0
2025-12-09 10:23:34.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 4783 LR: 0.0009999458557238855 Training loss: 0.0
2025-12-09 10:23:34.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 4784 LR: 0.0009999458326030155 Training loss: 0.0
2025-12-09 10:23:34.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 4785 LR: 0.00099994580947721 Training loss: 0.0
2025-12-09 10:23:34.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 4786 LR: 0.0009999457863464692 Training loss: 0.0
2025-12-09 10:23:34.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 4787 LR: 0.0009999457632107933 Training loss: 0.0
2025-12-09 10:23:34.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 4788 LR: 0.000999945740070182 Training loss: 0.0
2025-12-09 10:23:34.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 4789 LR: 0.0009999457169246355 Training loss: 0.0
2025-12-09 10:23:34.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 4790 LR: 0.0009999456937741537 Training loss: 0.0
2025-12-09 10:23:34.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 4791 LR: 0.0009999456706187367 Training loss: 0.0
2025-12-09 10:23:34.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 4792 LR: 0.0009999456474583846 Training loss: 0.0
2025-12-09 10:23:34.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 4793 LR: 0.000999945624293097 Training loss: 0.0
2025-12-09 10:23:34.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 4794 LR: 0.0009999456011228743 Training loss: 0.0
2025-12-09 10:23:34.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 4795 LR: 0.0009999455779477163 Training loss: 0.0
2025-12-09 10:23:34.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 4796 LR: 0.000999945554767623 Training loss: 0.0
2025-12-09 10:23:34.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 4797 LR: 0.0009999455315825945 Training loss: 0.0
2025-12-09 10:23:34.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 4798 LR: 0.0009999455083926306 Training loss: 0.0
2025-12-09 10:23:34.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 4799 LR: 0.0009999454851977317 Training loss: 0.0
2025-12-09 10:23:34.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 4800 LR: 0.0009999454619978973 Training loss: 0.0
2025-12-09 10:23:34.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 4801 LR: 0.0009999454387931278 Training loss: 0.0
2025-12-09 10:23:34.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 4802 LR: 0.000999945415583423 Training loss: 0.0
2025-12-09 10:23:34.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 4803 LR: 0.000999945392368783 Training loss: 0.0
2025-12-09 10:23:34.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 4804 LR: 0.0009999453691492076 Training loss: 0.0
2025-12-09 10:23:34.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 4805 LR: 0.0009999453459246972 Training loss: 0.0
2025-12-09 10:23:34.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 4806 LR: 0.0009999453226952515 Training loss: 0.0
2025-12-09 10:23:34.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 4807 LR: 0.0009999452994608705 Training loss: 0.0
2025-12-09 10:23:34.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 4808 LR: 0.0009999452762215542 Training loss: 0.0
2025-12-09 10:23:34.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 4809 LR: 0.0009999452529773026 Training loss: 0.0
2025-12-09 10:23:34.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 4810 LR: 0.0009999452297281158 Training loss: 0.0
2025-12-09 10:23:34.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 4811 LR: 0.0009999452064739938 Training loss: 0.0
2025-12-09 10:23:34.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 4812 LR: 0.0009999451832149366 Training loss: 0.0
2025-12-09 10:23:34.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 4813 LR: 0.000999945159950944 Training loss: 0.0
2025-12-09 10:23:34.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 4814 LR: 0.0009999451366820163 Training loss: 0.0
2025-12-09 10:23:34.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 4815 LR: 0.0009999451134081532 Training loss: 0.0
2025-12-09 10:23:34.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 4816 LR: 0.000999945090129355 Training loss: 0.0
2025-12-09 10:23:34.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 4817 LR: 0.0009999450668456214 Training loss: 0.0
2025-12-09 10:23:34.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 4818 LR: 0.0009999450435569527 Training loss: 0.0
2025-12-09 10:23:34.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 4819 LR: 0.0009999450202633486 Training loss: 0.0
2025-12-09 10:23:34.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 4820 LR: 0.0009999449969648095 Training loss: 0.0
2025-12-09 10:23:34.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 4821 LR: 0.000999944973661335 Training loss: 0.0
2025-12-09 10:23:34.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 4822 LR: 0.0009999449503529253 Training loss: 0.0
2025-12-09 10:23:34.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 4823 LR: 0.00099994492703958 Training loss: 0.0
2025-12-09 10:23:34.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 4824 LR: 0.0009999449037213 Training loss: 0.0
2025-12-09 10:23:34.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 4825 LR: 0.0009999448803980845 Training loss: 0.0
2025-12-09 10:23:34.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 4826 LR: 0.0009999448570699337 Training loss: 0.0
2025-12-09 10:23:34.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 4827 LR: 0.0009999448337368478 Training loss: 0.0
2025-12-09 10:23:34.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 4828 LR: 0.0009999448103988266 Training loss: 0.0
2025-12-09 10:23:34.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 4829 LR: 0.0009999447870558701 Training loss: 0.0
2025-12-09 10:23:34.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 4830 LR: 0.0009999447637079784 Training loss: 0.0
2025-12-09 10:23:34.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 4831 LR: 0.0009999447403551515 Training loss: 0.0
2025-12-09 10:23:34.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 4832 LR: 0.0009999447169973894 Training loss: 0.0
2025-12-09 10:23:34.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 4833 LR: 0.0009999446936346918 Training loss: 0.0
2025-12-09 10:23:34.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 4834 LR: 0.000999944670267059 Training loss: 0.0
2025-12-09 10:23:34.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 4835 LR: 0.0009999446468944913 Training loss: 0.0
2025-12-09 10:23:34.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 4836 LR: 0.000999944623516988 Training loss: 0.0
2025-12-09 10:23:34.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 4837 LR: 0.0009999446001345497 Training loss: 0.0
2025-12-09 10:23:34.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 4838 LR: 0.000999944576747176 Training loss: 0.0
2025-12-09 10:23:34.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 4839 LR: 0.0009999445533548671 Training loss: 0.0
2025-12-09 10:23:34.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 4840 LR: 0.0009999445299576231 Training loss: 0.0
2025-12-09 10:23:34.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 4841 LR: 0.0009999445065554436 Training loss: 0.0
2025-12-09 10:23:34.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 4842 LR: 0.000999944483148329 Training loss: 0.0
2025-12-09 10:23:34.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 4843 LR: 0.0009999444597362792 Training loss: 0.0
2025-12-09 10:23:34.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 4844 LR: 0.000999944436319294 Training loss: 0.0
2025-12-09 10:23:34.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 4845 LR: 0.0009999444128973739 Training loss: 0.0
2025-12-09 10:23:34.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 4846 LR: 0.0009999443894705181 Training loss: 0.0
2025-12-09 10:23:34.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 4847 LR: 0.0009999443660387273 Training loss: 0.0
2025-12-09 10:23:34.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 4848 LR: 0.0009999443426020012 Training loss: 0.0
2025-12-09 10:23:34.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 4849 LR: 0.0009999443191603399 Training loss: 0.0
2025-12-09 10:23:34.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 4850 LR: 0.0009999442957137434 Training loss: 0.0
2025-12-09 10:23:34.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 4851 LR: 0.0009999442722622117 Training loss: 0.0
2025-12-09 10:23:34.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 4852 LR: 0.0009999442488057447 Training loss: 0.0
2025-12-09 10:23:34.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 4853 LR: 0.0009999442253443424 Training loss: 0.0
2025-12-09 10:23:34.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 4854 LR: 0.000999944201878005 Training loss: 0.0
2025-12-09 10:23:34.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 4855 LR: 0.000999944178406732 Training loss: 0.0
2025-12-09 10:23:34.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 4856 LR: 0.0009999441549305241 Training loss: 0.0
2025-12-09 10:23:34.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 4857 LR: 0.000999944131449381 Training loss: 0.0
2025-12-09 10:23:34.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 4858 LR: 0.0009999441079633026 Training loss: 0.0
2025-12-09 10:23:34.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 4859 LR: 0.000999944084472289 Training loss: 0.0
2025-12-09 10:23:34.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 4860 LR: 0.0009999440609763399 Training loss: 0.0
2025-12-09 10:23:34.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 4861 LR: 0.000999944037475456 Training loss: 0.0
2025-12-09 10:23:34.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 4862 LR: 0.0009999440139696362 Training loss: 0.0
2025-12-09 10:23:34.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 4863 LR: 0.0009999439904588817 Training loss: 0.0
2025-12-09 10:23:34.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 4864 LR: 0.0009999439669431918 Training loss: 0.0
2025-12-09 10:23:34.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 4865 LR: 0.0009999439434225667 Training loss: 0.0
2025-12-09 10:23:34.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 4866 LR: 0.0009999439198970063 Training loss: 0.0
2025-12-09 10:23:34.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 4867 LR: 0.0009999438963665108 Training loss: 0.0
2025-12-09 10:23:34.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 4868 LR: 0.00099994387283108 Training loss: 0.0
2025-12-09 10:23:34.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 4869 LR: 0.000999943849290714 Training loss: 0.0
2025-12-09 10:23:34.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 4870 LR: 0.0009999438257454127 Training loss: 0.0
2025-12-09 10:23:34.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 4871 LR: 0.000999943802195176 Training loss: 0.0
2025-12-09 10:23:34.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 4872 LR: 0.0009999437786400044 Training loss: 0.0
2025-12-09 10:23:34.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 4873 LR: 0.0009999437550798974 Training loss: 0.0
2025-12-09 10:23:34.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 4874 LR: 0.000999943731514855 Training loss: 0.0
2025-12-09 10:23:34.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 4875 LR: 0.0009999437079448777 Training loss: 0.0
2025-12-09 10:23:34.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 4876 LR: 0.0009999436843699649 Training loss: 0.0
2025-12-09 10:23:34.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 4877 LR: 0.0009999436607901172 Training loss: 0.0
2025-12-09 10:23:34.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 4878 LR: 0.000999943637205334 Training loss: 0.0
2025-12-09 10:23:34.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 4879 LR: 0.0009999436136156157 Training loss: 0.0
2025-12-09 10:23:34.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 4880 LR: 0.0009999435900209619 Training loss: 0.0
2025-12-09 10:23:34.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 4881 LR: 0.000999943566421373 Training loss: 0.0
2025-12-09 10:23:34.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 4882 LR: 0.000999943542816849 Training loss: 0.0
2025-12-09 10:23:34.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 4883 LR: 0.0009999435192073896 Training loss: 0.0
2025-12-09 10:23:34.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 4884 LR: 0.0009999434955929951 Training loss: 0.0
2025-12-09 10:23:34.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 4885 LR: 0.0009999434719736653 Training loss: 0.0
2025-12-09 10:23:34.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 4886 LR: 0.0009999434483494002 Training loss: 0.0
2025-12-09 10:23:34.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 4887 LR: 0.0009999434247202 Training loss: 0.0
2025-12-09 10:23:34.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 4888 LR: 0.0009999434010860646 Training loss: 0.0
2025-12-09 10:23:34.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 4889 LR: 0.000999943377446994 Training loss: 0.0
2025-12-09 10:23:34.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 4890 LR: 0.000999943353802988 Training loss: 0.0
2025-12-09 10:23:34.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 4891 LR: 0.0009999433301540468 Training loss: 0.0
2025-12-09 10:23:34.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 4892 LR: 0.0009999433065001704 Training loss: 0.0
2025-12-09 10:23:34.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 4893 LR: 0.0009999432828413587 Training loss: 0.0
2025-12-09 10:23:34.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 4894 LR: 0.000999943259177612 Training loss: 0.0
2025-12-09 10:23:34.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 4895 LR: 0.00099994323550893 Training loss: 0.0
2025-12-09 10:23:34.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 4896 LR: 0.0009999432118353126 Training loss: 0.0
2025-12-09 10:23:34.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 4897 LR: 0.00099994318815676 Training loss: 0.0
2025-12-09 10:23:34.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 4898 LR: 0.0009999431644732721 Training loss: 0.0
2025-12-09 10:23:34.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 4899 LR: 0.0009999431407848494 Training loss: 0.0
2025-12-09 10:23:34.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 4900 LR: 0.000999943117091491 Training loss: 0.0
2025-12-09 10:23:34.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 4901 LR: 0.0009999430933931976 Training loss: 0.0
2025-12-09 10:23:34.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 4902 LR: 0.000999943069689969 Training loss: 0.0
2025-12-09 10:23:34.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 4903 LR: 0.000999943045981805 Training loss: 0.0
2025-12-09 10:23:34.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 4904 LR: 0.0009999430222687059 Training loss: 0.0
2025-12-09 10:23:34.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 4905 LR: 0.0009999429985506716 Training loss: 0.0
2025-12-09 10:23:34.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 4906 LR: 0.0009999429748277018 Training loss: 0.0
2025-12-09 10:23:34.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 4907 LR: 0.000999942951099797 Training loss: 0.0
2025-12-09 10:23:34.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 4908 LR: 0.000999942927366957 Training loss: 0.0
2025-12-09 10:23:34.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 4909 LR: 0.0009999429036291819 Training loss: 0.0
2025-12-09 10:23:34.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 4910 LR: 0.0009999428798864712 Training loss: 0.0
2025-12-09 10:23:34.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 4911 LR: 0.0009999428561388256 Training loss: 0.0
2025-12-09 10:23:34.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 4912 LR: 0.0009999428323862445 Training loss: 0.0
2025-12-09 10:23:34.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 4913 LR: 0.0009999428086287284 Training loss: 0.0
2025-12-09 10:23:34.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 4914 LR: 0.000999942784866277 Training loss: 0.0
2025-12-09 10:23:34.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 4915 LR: 0.0009999427610988905 Training loss: 0.0
2025-12-09 10:23:34.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 4916 LR: 0.0009999427373265687 Training loss: 0.0
2025-12-09 10:23:34.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 4917 LR: 0.0009999427135493116 Training loss: 0.0
2025-12-09 10:23:34.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 4918 LR: 0.0009999426897671193 Training loss: 0.0
2025-12-09 10:23:34.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 4919 LR: 0.0009999426659799918 Training loss: 0.0
2025-12-09 10:23:34.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 4920 LR: 0.000999942642187929 Training loss: 0.0
2025-12-09 10:23:34.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 4921 LR: 0.000999942618390931 Training loss: 0.0
2025-12-09 10:23:34.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 4922 LR: 0.0009999425945889978 Training loss: 0.0
2025-12-09 10:23:34.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 4923 LR: 0.0009999425707821294 Training loss: 0.0
2025-12-09 10:23:34.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 4924 LR: 0.0009999425469703258 Training loss: 0.0
2025-12-09 10:23:34.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 4925 LR: 0.0009999425231535868 Training loss: 0.0
2025-12-09 10:23:34.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 4926 LR: 0.0009999424993319128 Training loss: 0.0
2025-12-09 10:23:34.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 4927 LR: 0.0009999424755053035 Training loss: 0.0
2025-12-09 10:23:34.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 4928 LR: 0.0009999424516737591 Training loss: 0.0
2025-12-09 10:23:34.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 4929 LR: 0.0009999424278372793 Training loss: 0.0
2025-12-09 10:23:34.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 4930 LR: 0.0009999424039958645 Training loss: 0.0
2025-12-09 10:23:34.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 4931 LR: 0.0009999423801495143 Training loss: 0.0
2025-12-09 10:23:34.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 4932 LR: 0.0009999423562982287 Training loss: 0.0
2025-12-09 10:23:34.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 4933 LR: 0.0009999423324420081 Training loss: 0.0
2025-12-09 10:23:34.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 4934 LR: 0.0009999423085808523 Training loss: 0.0
2025-12-09 10:23:34.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 4935 LR: 0.0009999422847147613 Training loss: 0.0
2025-12-09 10:23:34.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 4936 LR: 0.000999942260843735 Training loss: 0.0
2025-12-09 10:23:34.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 4937 LR: 0.0009999422369677735 Training loss: 0.0
2025-12-09 10:23:34.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 4938 LR: 0.0009999422130868767 Training loss: 0.0
2025-12-09 10:23:34.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 4939 LR: 0.0009999421892010448 Training loss: 0.0
2025-12-09 10:23:34.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 4940 LR: 0.0009999421653102778 Training loss: 0.0
2025-12-09 10:23:34.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 4941 LR: 0.0009999421414145753 Training loss: 0.0
2025-12-09 10:23:34.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 4942 LR: 0.0009999421175139378 Training loss: 0.0
2025-12-09 10:23:34.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 4943 LR: 0.000999942093608365 Training loss: 0.0
2025-12-09 10:23:34.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 4944 LR: 0.000999942069697857 Training loss: 0.0
2025-12-09 10:23:34.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 4945 LR: 0.0009999420457824136 Training loss: 0.0
2025-12-09 10:23:34.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 4946 LR: 0.0009999420218620352 Training loss: 0.0
2025-12-09 10:23:34.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 4947 LR: 0.0009999419979367214 Training loss: 0.0
2025-12-09 10:23:34.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 4948 LR: 0.0009999419740064725 Training loss: 0.0
2025-12-09 10:23:34.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 4949 LR: 0.0009999419500712884 Training loss: 0.0
2025-12-09 10:23:34.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 4950 LR: 0.0009999419261311692 Training loss: 0.0
2025-12-09 10:23:34.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 4951 LR: 0.0009999419021861147 Training loss: 0.0
2025-12-09 10:23:34.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 4952 LR: 0.000999941878236125 Training loss: 0.0
2025-12-09 10:23:34.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 4953 LR: 0.0009999418542811999 Training loss: 0.0
2025-12-09 10:23:34.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 4954 LR: 0.0009999418303213397 Training loss: 0.0
2025-12-09 10:23:34.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 4955 LR: 0.0009999418063565443 Training loss: 0.0
2025-12-09 10:23:34.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 4956 LR: 0.0009999417823868136 Training loss: 0.0
2025-12-09 10:23:34.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 4957 LR: 0.0009999417584121478 Training loss: 0.0
2025-12-09 10:23:34.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 4958 LR: 0.0009999417344325467 Training loss: 0.0
2025-12-09 10:23:34.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 4959 LR: 0.0009999417104480106 Training loss: 0.0
2025-12-09 10:23:34.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 4960 LR: 0.0009999416864585392 Training loss: 0.0
2025-12-09 10:23:34.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 4961 LR: 0.0009999416624641324 Training loss: 0.0
2025-12-09 10:23:34.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 4962 LR: 0.0009999416384647904 Training loss: 0.0
2025-12-09 10:23:34.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 4963 LR: 0.0009999416144605134 Training loss: 0.0
2025-12-09 10:23:34.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 4964 LR: 0.000999941590451301 Training loss: 0.0
2025-12-09 10:23:34.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 4965 LR: 0.0009999415664371533 Training loss: 0.0
2025-12-09 10:23:34.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 4966 LR: 0.0009999415424180706 Training loss: 0.0
2025-12-09 10:23:34.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 4967 LR: 0.0009999415183940528 Training loss: 0.0
2025-12-09 10:23:34.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 4968 LR: 0.0009999414943650995 Training loss: 0.0
2025-12-09 10:23:34.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 4969 LR: 0.0009999414703312111 Training loss: 0.0
2025-12-09 10:23:34.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 4970 LR: 0.0009999414462923874 Training loss: 0.0
2025-12-09 10:23:34.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 4971 LR: 0.0009999414222486287 Training loss: 0.0
2025-12-09 10:23:34.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 4972 LR: 0.000999941398199935 Training loss: 0.0
2025-12-09 10:23:34.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 4973 LR: 0.0009999413741463056 Training loss: 0.0
2025-12-09 10:23:34.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 4974 LR: 0.000999941350087741 Training loss: 0.0
2025-12-09 10:23:34.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 4975 LR: 0.0009999413260242413 Training loss: 0.0
2025-12-09 10:23:34.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 4976 LR: 0.0009999413019558066 Training loss: 0.0
2025-12-09 10:23:34.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 4977 LR: 0.0009999412778824363 Training loss: 0.0
2025-12-09 10:23:34.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 4978 LR: 0.0009999412538041312 Training loss: 0.0
2025-12-09 10:23:34.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 4979 LR: 0.0009999412297208906 Training loss: 0.0
2025-12-09 10:23:34.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 4980 LR: 0.000999941205632715 Training loss: 0.0
2025-12-09 10:23:34.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 4981 LR: 0.000999941181539604 Training loss: 0.0
2025-12-09 10:23:34.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 4982 LR: 0.000999941157441558 Training loss: 0.0
2025-12-09 10:23:34.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 4983 LR: 0.0009999411333385766 Training loss: 0.0
2025-12-09 10:23:34.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 4984 LR: 0.00099994110923066 Training loss: 0.0
2025-12-09 10:23:34.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 4985 LR: 0.0009999410851178083 Training loss: 0.0
2025-12-09 10:23:34.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 4986 LR: 0.0009999410610000213 Training loss: 0.0
2025-12-09 10:23:34.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 4987 LR: 0.0009999410368772992 Training loss: 0.0
2025-12-09 10:23:34.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 4988 LR: 0.0009999410127496417 Training loss: 0.0
2025-12-09 10:23:34.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 4989 LR: 0.0009999409886170493 Training loss: 0.0
2025-12-09 10:23:34.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 4990 LR: 0.0009999409644795214 Training loss: 0.0
2025-12-09 10:23:34.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 4991 LR: 0.0009999409403370586 Training loss: 0.0
2025-12-09 10:23:34.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 4992 LR: 0.00099994091618966 Training loss: 0.0
2025-12-09 10:23:34.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 4993 LR: 0.0009999408920373268 Training loss: 0.0
2025-12-09 10:23:34.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 4994 LR: 0.0009999408678800581 Training loss: 0.0
2025-12-09 10:23:34.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 4995 LR: 0.0009999408437178544 Training loss: 0.0
2025-12-09 10:23:34.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 4996 LR: 0.0009999408195507154 Training loss: 0.0
2025-12-09 10:23:34.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 4997 LR: 0.0009999407953786411 Training loss: 0.0
2025-12-09 10:23:34.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 4998 LR: 0.0009999407712016318 Training loss: 0.0
2025-12-09 10:23:34.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 4999 LR: 0.0009999407470196872 Training loss: 0.0
2025-12-09 10:23:34.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 5000 LR: 0.0009999407228328072 Training loss: 0.0
2025-12-09 10:23:34.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 5001 LR: 0.0009999406986409922 Training loss: 0.0
2025-12-09 10:23:34.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 5002 LR: 0.000999940674444242 Training loss: 0.0
2025-12-09 10:23:34.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 5003 LR: 0.0009999406502425566 Training loss: 0.0
2025-12-09 10:23:34.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 5004 LR: 0.000999940626035936 Training loss: 0.0
2025-12-09 10:23:34.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 5005 LR: 0.00099994060182438 Training loss: 0.0
2025-12-09 10:23:34.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 5006 LR: 0.000999940577607889 Training loss: 0.0
2025-12-09 10:23:34.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 5007 LR: 0.0009999405533864627 Training loss: 0.0
2025-12-09 10:23:34.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 5008 LR: 0.000999940529160101 Training loss: 0.0
2025-12-09 10:23:34.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 5009 LR: 0.0009999405049288047 Training loss: 0.0
2025-12-09 10:23:34.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 5010 LR: 0.0009999404806925727 Training loss: 0.0
2025-12-09 10:23:34.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 5011 LR: 0.0009999404564514057 Training loss: 0.0
2025-12-09 10:23:34.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 5012 LR: 0.0009999404322053034 Training loss: 0.0
2025-12-09 10:23:34.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 5013 LR: 0.0009999404079542658 Training loss: 0.0
2025-12-09 10:23:34.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 5014 LR: 0.0009999403836982931 Training loss: 0.0
2025-12-09 10:23:34.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 5015 LR: 0.0009999403594373852 Training loss: 0.0
2025-12-09 10:23:34.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 5016 LR: 0.0009999403351715422 Training loss: 0.0
2025-12-09 10:23:34.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 5017 LR: 0.000999940310900764 Training loss: 0.0
2025-12-09 10:23:34.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 5018 LR: 0.0009999402866250505 Training loss: 0.0
2025-12-09 10:23:34.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 5019 LR: 0.0009999402623444018 Training loss: 0.0
2025-12-09 10:23:34.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 5020 LR: 0.000999940238058818 Training loss: 0.0
2025-12-09 10:23:34.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 5021 LR: 0.000999940213768299 Training loss: 0.0
2025-12-09 10:23:34.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 5022 LR: 0.0009999401894728447 Training loss: 0.0
2025-12-09 10:23:34.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 5023 LR: 0.000999940165172455 Training loss: 0.0
2025-12-09 10:23:34.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 5024 LR: 0.0009999401408671304 Training loss: 0.0
2025-12-09 10:23:34.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 5025 LR: 0.0009999401165568707 Training loss: 0.0
2025-12-09 10:23:34.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 5026 LR: 0.0009999400922416754 Training loss: 0.0
2025-12-09 10:23:34.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 5027 LR: 0.0009999400679215453 Training loss: 0.0
2025-12-09 10:23:34.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 5028 LR: 0.0009999400435964799 Training loss: 0.0
2025-12-09 10:23:34.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 5029 LR: 0.0009999400192664792 Training loss: 0.0
2025-12-09 10:23:34.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 5030 LR: 0.0009999399949315432 Training loss: 0.0
2025-12-09 10:23:34.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 5031 LR: 0.0009999399705916722 Training loss: 0.0
2025-12-09 10:23:34.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 5032 LR: 0.0009999399462468658 Training loss: 0.0
2025-12-09 10:23:34.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 5033 LR: 0.0009999399218971244 Training loss: 0.0
2025-12-09 10:23:34.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 5034 LR: 0.000999939897542448 Training loss: 0.0
2025-12-09 10:23:34.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 5035 LR: 0.000999939873182836 Training loss: 0.0
2025-12-09 10:23:34.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 5036 LR: 0.000999939848818289 Training loss: 0.0
2025-12-09 10:23:34.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 5037 LR: 0.0009999398244488068 Training loss: 0.0
2025-12-09 10:23:34.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 5038 LR: 0.0009999398000743894 Training loss: 0.0
2025-12-09 10:23:34.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 5039 LR: 0.0009999397756950367 Training loss: 0.0
2025-12-09 10:23:34.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 5040 LR: 0.000999939751310749 Training loss: 0.0
2025-12-09 10:23:34.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 5041 LR: 0.0009999397269215258 Training loss: 0.0
2025-12-09 10:23:34.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 5042 LR: 0.0009999397025273677 Training loss: 0.0
2025-12-09 10:23:34.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 5043 LR: 0.0009999396781282743 Training loss: 0.0
2025-12-09 10:23:34.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 5044 LR: 0.0009999396537242456 Training loss: 0.0
2025-12-09 10:23:34.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 5045 LR: 0.0009999396293152818 Training loss: 0.0
2025-12-09 10:23:34.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 5046 LR: 0.000999939604901383 Training loss: 0.0
2025-12-09 10:23:34.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 5047 LR: 0.0009999395804825486 Training loss: 0.0
2025-12-09 10:23:34.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 5048 LR: 0.0009999395560587794 Training loss: 0.0
2025-12-09 10:23:34.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 5049 LR: 0.0009999395316300749 Training loss: 0.0
2025-12-09 10:23:34.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 5050 LR: 0.000999939507196435 Training loss: 0.0
2025-12-09 10:23:34.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 5051 LR: 0.00099993948275786 Training loss: 0.0
2025-12-09 10:23:34.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 5052 LR: 0.00099993945831435 Training loss: 0.0
2025-12-09 10:23:34.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 5053 LR: 0.0009999394338659046 Training loss: 0.0
2025-12-09 10:23:34.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 5054 LR: 0.000999939409412524 Training loss: 0.0
2025-12-09 10:23:34.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 5055 LR: 0.0009999393849542085 Training loss: 0.0
2025-12-09 10:23:34.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 5056 LR: 0.0009999393604909574 Training loss: 0.0
2025-12-09 10:23:34.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 5057 LR: 0.0009999393360227713 Training loss: 0.0
2025-12-09 10:23:34.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 5058 LR: 0.00099993931154965 Training loss: 0.0
2025-12-09 10:23:34.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 5059 LR: 0.0009999392870715935 Training loss: 0.0
2025-12-09 10:23:34.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 5060 LR: 0.000999939262588602 Training loss: 0.0
2025-12-09 10:23:34.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 5061 LR: 0.000999939238100675 Training loss: 0.0
2025-12-09 10:23:34.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 5062 LR: 0.0009999392136078131 Training loss: 0.0
2025-12-09 10:23:34.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 5063 LR: 0.0009999391891100159 Training loss: 0.0
2025-12-09 10:23:34.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 5064 LR: 0.0009999391646072834 Training loss: 0.0
2025-12-09 10:23:34.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 5065 LR: 0.0009999391400996158 Training loss: 0.0
2025-12-09 10:23:34.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 5066 LR: 0.000999939115587013 Training loss: 0.0
2025-12-09 10:23:34.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 5067 LR: 0.000999939091069475 Training loss: 0.0
2025-12-09 10:23:34.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 5068 LR: 0.0009999390665470019 Training loss: 0.0
2025-12-09 10:23:34.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 5069 LR: 0.0009999390420195936 Training loss: 0.0
2025-12-09 10:23:34.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 5070 LR: 0.00099993901748725 Training loss: 0.0
2025-12-09 10:23:34.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 5071 LR: 0.000999938992949971 Training loss: 0.0
2025-12-09 10:23:34.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 5072 LR: 0.0009999389684077573 Training loss: 0.0
2025-12-09 10:23:34.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 5073 LR: 0.000999938943860608 Training loss: 0.0
2025-12-09 10:23:34.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 5074 LR: 0.000999938919308524 Training loss: 0.0
2025-12-09 10:23:34.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 5075 LR: 0.0009999388947515044 Training loss: 0.0
2025-12-09 10:23:34.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 5076 LR: 0.0009999388701895497 Training loss: 0.0
2025-12-09 10:23:34.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 5077 LR: 0.00099993884562266 Training loss: 0.0
2025-12-09 10:23:34.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 5078 LR: 0.0009999388210508349 Training loss: 0.0
2025-12-09 10:23:34.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 5079 LR: 0.0009999387964740745 Training loss: 0.0
2025-12-09 10:23:34.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 5080 LR: 0.0009999387718923791 Training loss: 0.0
2025-12-09 10:23:34.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 5081 LR: 0.0009999387473057487 Training loss: 0.0
2025-12-09 10:23:34.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 5082 LR: 0.0009999387227141827 Training loss: 0.0
2025-12-09 10:23:34.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 5083 LR: 0.0009999386981176818 Training loss: 0.0
2025-12-09 10:23:34.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 5084 LR: 0.0009999386735162457 Training loss: 0.0
2025-12-09 10:23:34.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 5085 LR: 0.0009999386489098743 Training loss: 0.0
2025-12-09 10:23:34.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 5086 LR: 0.0009999386242985678 Training loss: 0.0
2025-12-09 10:23:34.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 5087 LR: 0.000999938599682326 Training loss: 0.0
2025-12-09 10:23:34.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 5088 LR: 0.0009999385750611492 Training loss: 0.0
2025-12-09 10:23:34.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 5089 LR: 0.000999938550435037 Training loss: 0.0
2025-12-09 10:23:34.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 5090 LR: 0.0009999385258039899 Training loss: 0.0
2025-12-09 10:23:34.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 5091 LR: 0.0009999385011680076 Training loss: 0.0
2025-12-09 10:23:34.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 5092 LR: 0.0009999384765270898 Training loss: 0.0
2025-12-09 10:23:34.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 5093 LR: 0.0009999384518812372 Training loss: 0.0
2025-12-09 10:23:34.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 5094 LR: 0.000999938427230449 Training loss: 0.0
2025-12-09 10:23:34.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 5095 LR: 0.000999938402574726 Training loss: 0.0
2025-12-09 10:23:34.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 5096 LR: 0.0009999383779140676 Training loss: 0.0
2025-12-09 10:23:34.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 5097 LR: 0.000999938353248474 Training loss: 0.0
2025-12-09 10:23:34.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 5098 LR: 0.0009999383285779454 Training loss: 0.0
2025-12-09 10:23:34.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 5099 LR: 0.0009999383039024814 Training loss: 0.0
2025-12-09 10:23:34.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 5100 LR: 0.0009999382792220824 Training loss: 0.0
2025-12-09 10:23:34.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 5101 LR: 0.0009999382545367481 Training loss: 0.0
2025-12-09 10:23:34.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 5102 LR: 0.0009999382298464788 Training loss: 0.0
2025-12-09 10:23:34.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 5103 LR: 0.0009999382051512741 Training loss: 0.0
2025-12-09 10:23:34.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 5104 LR: 0.0009999381804511344 Training loss: 0.0
2025-12-09 10:23:34.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 5105 LR: 0.0009999381557460594 Training loss: 0.0
2025-12-09 10:23:34.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 5106 LR: 0.0009999381310360493 Training loss: 0.0
2025-12-09 10:23:34.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 5107 LR: 0.000999938106321104 Training loss: 0.0
2025-12-09 10:23:34.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 5108 LR: 0.0009999380816012235 Training loss: 0.0
2025-12-09 10:23:34.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 5109 LR: 0.0009999380568764078 Training loss: 0.0
2025-12-09 10:23:34.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 5110 LR: 0.000999938032146657 Training loss: 0.0
2025-12-09 10:23:34.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 5111 LR: 0.000999938007411971 Training loss: 0.0
2025-12-09 10:23:34.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 5112 LR: 0.0009999379826723497 Training loss: 0.0
2025-12-09 10:23:34.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 5113 LR: 0.0009999379579277933 Training loss: 0.0
2025-12-09 10:23:34.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 5114 LR: 0.0009999379331783018 Training loss: 0.0
2025-12-09 10:23:34.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 5115 LR: 0.000999937908423875 Training loss: 0.0
2025-12-09 10:23:34.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 5116 LR: 0.000999937883664513 Training loss: 0.0
2025-12-09 10:23:34.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 5117 LR: 0.000999937858900216 Training loss: 0.0
2025-12-09 10:23:34.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 5118 LR: 0.0009999378341309837 Training loss: 0.0
2025-12-09 10:23:34.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 5119 LR: 0.0009999378093568164 Training loss: 0.0
2025-12-09 10:23:34.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 5120 LR: 0.0009999377845777136 Training loss: 0.0
2025-12-09 10:23:34.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 5121 LR: 0.000999937759793676 Training loss: 0.0
2025-12-09 10:23:34.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 5122 LR: 0.000999937735004703 Training loss: 0.0
2025-12-09 10:23:34.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 5123 LR: 0.0009999377102107947 Training loss: 0.0
2025-12-09 10:23:34.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 5124 LR: 0.0009999376854119516 Training loss: 0.0
2025-12-09 10:23:34.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 5125 LR: 0.000999937660608173 Training loss: 0.0
2025-12-09 10:23:34.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 5126 LR: 0.0009999376357994593 Training loss: 0.0
2025-12-09 10:23:34.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 5127 LR: 0.0009999376109858106 Training loss: 0.0
2025-12-09 10:23:34.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 5128 LR: 0.0009999375861672263 Training loss: 0.0
2025-12-09 10:23:34.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 5129 LR: 0.0009999375613437072 Training loss: 0.0
2025-12-09 10:23:34.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 5130 LR: 0.0009999375365152528 Training loss: 0.0
2025-12-09 10:23:34.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 5131 LR: 0.0009999375116818633 Training loss: 0.0
2025-12-09 10:23:34.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 5132 LR: 0.0009999374868435388 Training loss: 0.0
2025-12-09 10:23:34.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 5133 LR: 0.0009999374620002788 Training loss: 0.0
2025-12-09 10:23:34.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 5134 LR: 0.0009999374371520836 Training loss: 0.0
2025-12-09 10:23:34.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 5135 LR: 0.0009999374122989534 Training loss: 0.0
2025-12-09 10:23:34.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 5136 LR: 0.0009999373874408882 Training loss: 0.0
2025-12-09 10:23:34.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 5137 LR: 0.0009999373625778876 Training loss: 0.0
2025-12-09 10:23:34.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 5138 LR: 0.0009999373377099518 Training loss: 0.0
2025-12-09 10:23:34.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 5139 LR: 0.000999937312837081 Training loss: 0.0
2025-12-09 10:23:34.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 5140 LR: 0.000999937287959275 Training loss: 0.0
2025-12-09 10:23:34.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 5141 LR: 0.0009999372630765334 Training loss: 0.0
2025-12-09 10:23:34.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 5142 LR: 0.000999937238188857 Training loss: 0.0
2025-12-09 10:23:34.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 5143 LR: 0.0009999372132962457 Training loss: 0.0
2025-12-09 10:23:34.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 5144 LR: 0.0009999371883986988 Training loss: 0.0
2025-12-09 10:23:34.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 5145 LR: 0.0009999371634962168 Training loss: 0.0
2025-12-09 10:23:34.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 5146 LR: 0.0009999371385888 Training loss: 0.0
2025-12-09 10:23:34.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 5147 LR: 0.0009999371136764476 Training loss: 0.0
2025-12-09 10:23:34.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 5148 LR: 0.0009999370887591602 Training loss: 0.0
2025-12-09 10:23:34.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 5149 LR: 0.0009999370638369377 Training loss: 0.0
2025-12-09 10:23:34.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 5150 LR: 0.0009999370389097797 Training loss: 0.0
2025-12-09 10:23:34.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 5151 LR: 0.0009999370139776869 Training loss: 0.0
2025-12-09 10:23:34.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 5152 LR: 0.0009999369890406587 Training loss: 0.0
2025-12-09 10:23:34.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 5153 LR: 0.0009999369640986955 Training loss: 0.0
2025-12-09 10:23:34.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 5154 LR: 0.000999936939151797 Training loss: 0.0
2025-12-09 10:23:34.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 5155 LR: 0.0009999369141999634 Training loss: 0.0
2025-12-09 10:23:34.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 5156 LR: 0.0009999368892431946 Training loss: 0.0
2025-12-09 10:23:34.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 5157 LR: 0.0009999368642814909 Training loss: 0.0
2025-12-09 10:23:34.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 5158 LR: 0.0009999368393148517 Training loss: 0.0
2025-12-09 10:23:34.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 5159 LR: 0.0009999368143432774 Training loss: 0.0
2025-12-09 10:23:34.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 5160 LR: 0.000999936789366768 Training loss: 0.0
2025-12-09 10:23:34.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 5161 LR: 0.0009999367643853234 Training loss: 0.0
2025-12-09 10:23:34.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 5162 LR: 0.0009999367393989436 Training loss: 0.0
2025-12-09 10:23:34.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 5163 LR: 0.0009999367144076286 Training loss: 0.0
2025-12-09 10:23:34.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 5164 LR: 0.0009999366894113786 Training loss: 0.0
2025-12-09 10:23:34.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 5165 LR: 0.0009999366644101932 Training loss: 0.0
2025-12-09 10:23:34.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 5166 LR: 0.000999936639404073 Training loss: 0.0
2025-12-09 10:23:34.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 5167 LR: 0.0009999366143930172 Training loss: 0.0
2025-12-09 10:23:34.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 5168 LR: 0.0009999365893770264 Training loss: 0.0
2025-12-09 10:23:34.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 5169 LR: 0.0009999365643561008 Training loss: 0.0
2025-12-09 10:23:34.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 5170 LR: 0.0009999365393302396 Training loss: 0.0
2025-12-09 10:23:34.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 5171 LR: 0.0009999365142994434 Training loss: 0.0
2025-12-09 10:23:34.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 5172 LR: 0.0009999364892637119 Training loss: 0.0
2025-12-09 10:23:34.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 5173 LR: 0.0009999364642230453 Training loss: 0.0
2025-12-09 10:23:34.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 5174 LR: 0.0009999364391774436 Training loss: 0.0
2025-12-09 10:23:34.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 5175 LR: 0.0009999364141269067 Training loss: 0.0
2025-12-09 10:23:34.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 5176 LR: 0.0009999363890714347 Training loss: 0.0
2025-12-09 10:23:34.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 5177 LR: 0.0009999363640110276 Training loss: 0.0
2025-12-09 10:23:34.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 5178 LR: 0.0009999363389456852 Training loss: 0.0
2025-12-09 10:23:34.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 5179 LR: 0.0009999363138754075 Training loss: 0.0
2025-12-09 10:23:34.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 5180 LR: 0.0009999362888001948 Training loss: 0.0
2025-12-09 10:23:34.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 5181 LR: 0.000999936263720047 Training loss: 0.0
2025-12-09 10:23:34.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 5182 LR: 0.0009999362386349639 Training loss: 0.0
2025-12-09 10:23:34.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 5183 LR: 0.000999936213544946 Training loss: 0.0
2025-12-09 10:23:34.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 5184 LR: 0.0009999361884499925 Training loss: 0.0
2025-12-09 10:23:34.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 5185 LR: 0.0009999361633501042 Training loss: 0.0
2025-12-09 10:23:34.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 5186 LR: 0.0009999361382452803 Training loss: 0.0
2025-12-09 10:23:34.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 5187 LR: 0.0009999361131355217 Training loss: 0.0
2025-12-09 10:23:34.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 5188 LR: 0.0009999360880208275 Training loss: 0.0
2025-12-09 10:23:34.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 5189 LR: 0.0009999360629011985 Training loss: 0.0
2025-12-09 10:23:34.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 5190 LR: 0.0009999360377766341 Training loss: 0.0
2025-12-09 10:23:34.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 5191 LR: 0.0009999360126471347 Training loss: 0.0
2025-12-09 10:23:34.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 5192 LR: 0.0009999359875127 Training loss: 0.0
2025-12-09 10:23:34.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 5193 LR: 0.0009999359623733303 Training loss: 0.0
2025-12-09 10:23:34.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 5194 LR: 0.0009999359372290255 Training loss: 0.0
2025-12-09 10:23:34.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 5195 LR: 0.0009999359120797854 Training loss: 0.0
2025-12-09 10:23:34.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 5196 LR: 0.0009999358869256102 Training loss: 0.0
2025-12-09 10:23:34.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 5197 LR: 0.0009999358617664997 Training loss: 0.0
2025-12-09 10:23:34.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 5198 LR: 0.0009999358366024542 Training loss: 0.0
2025-12-09 10:23:34.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 5199 LR: 0.0009999358114334736 Training loss: 0.0
2025-12-09 10:23:34.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 5200 LR: 0.0009999357862595577 Training loss: 0.0
2025-12-09 10:23:34.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 5201 LR: 0.0009999357610807067 Training loss: 0.0
2025-12-09 10:23:34.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 5202 LR: 0.0009999357358969206 Training loss: 0.0
2025-12-09 10:23:34.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 5203 LR: 0.0009999357107081993 Training loss: 0.0
2025-12-09 10:23:34.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 5204 LR: 0.0009999356855145427 Training loss: 0.0
2025-12-09 10:23:34.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 5205 LR: 0.000999935660315951 Training loss: 0.0
2025-12-09 10:23:34.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 5206 LR: 0.0009999356351124244 Training loss: 0.0
2025-12-09 10:23:34.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 5207 LR: 0.0009999356099039624 Training loss: 0.0
2025-12-09 10:23:34.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 5208 LR: 0.0009999355846905653 Training loss: 0.0
2025-12-09 10:23:34.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 5209 LR: 0.000999935559472233 Training loss: 0.0
2025-12-09 10:23:34.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 5210 LR: 0.0009999355342489656 Training loss: 0.0
2025-12-09 10:23:34.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 5211 LR: 0.0009999355090207632 Training loss: 0.0
2025-12-09 10:23:34.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 5212 LR: 0.0009999354837876254 Training loss: 0.0
2025-12-09 10:23:34.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 5213 LR: 0.0009999354585495527 Training loss: 0.0
2025-12-09 10:23:34.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 5214 LR: 0.0009999354333065445 Training loss: 0.0
2025-12-09 10:23:34.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 5215 LR: 0.0009999354080586014 Training loss: 0.0
2025-12-09 10:23:34.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 5216 LR: 0.000999935382805723 Training loss: 0.0
2025-12-09 10:23:34.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 5217 LR: 0.0009999353575479097 Training loss: 0.0
2025-12-09 10:23:34.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 5218 LR: 0.000999935332285161 Training loss: 0.0
2025-12-09 10:23:34.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 5219 LR: 0.0009999353070174772 Training loss: 0.0
2025-12-09 10:23:34.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 5220 LR: 0.0009999352817448583 Training loss: 0.0
2025-12-09 10:23:34.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 5221 LR: 0.0009999352564673044 Training loss: 0.0
2025-12-09 10:23:34.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 5222 LR: 0.0009999352311848152 Training loss: 0.0
2025-12-09 10:23:34.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 5223 LR: 0.0009999352058973907 Training loss: 0.0
2025-12-09 10:23:34.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 5224 LR: 0.0009999351806050311 Training loss: 0.0
2025-12-09 10:23:34.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 5225 LR: 0.0009999351553077365 Training loss: 0.0
2025-12-09 10:23:34.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 5226 LR: 0.0009999351300055068 Training loss: 0.0
2025-12-09 10:23:34.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 5227 LR: 0.0009999351046983418 Training loss: 0.0
2025-12-09 10:23:34.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 5228 LR: 0.0009999350793862417 Training loss: 0.0
2025-12-09 10:23:34.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 5229 LR: 0.0009999350540692063 Training loss: 0.0
2025-12-09 10:23:34.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 5230 LR: 0.000999935028747236 Training loss: 0.0
2025-12-09 10:23:34.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 5231 LR: 0.0009999350034203304 Training loss: 0.0
2025-12-09 10:23:34.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 5232 LR: 0.0009999349780884896 Training loss: 0.0
2025-12-09 10:23:34.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 5233 LR: 0.000999934952751714 Training loss: 0.0
2025-12-09 10:23:34.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 5234 LR: 0.0009999349274100028 Training loss: 0.0
2025-12-09 10:23:34.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 5235 LR: 0.0009999349020633568 Training loss: 0.0
2025-12-09 10:23:34.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 5236 LR: 0.0009999348767117755 Training loss: 0.0
2025-12-09 10:23:34.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 5237 LR: 0.0009999348513552591 Training loss: 0.0
2025-12-09 10:23:34.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 5238 LR: 0.0009999348259938075 Training loss: 0.0
2025-12-09 10:23:34.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 5239 LR: 0.0009999348006274208 Training loss: 0.0
2025-12-09 10:23:34.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 5240 LR: 0.0009999347752560987 Training loss: 0.0
2025-12-09 10:23:34.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 5241 LR: 0.0009999347498798419 Training loss: 0.0
2025-12-09 10:23:34.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 5242 LR: 0.0009999347244986497 Training loss: 0.0
2025-12-09 10:23:34.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 5243 LR: 0.0009999346991125223 Training loss: 0.0
2025-12-09 10:23:34.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 5244 LR: 0.0009999346737214598 Training loss: 0.0
2025-12-09 10:23:34.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 5245 LR: 0.0009999346483254624 Training loss: 0.0
2025-12-09 10:23:34.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 5246 LR: 0.0009999346229245295 Training loss: 0.0
2025-12-09 10:23:34.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 5247 LR: 0.0009999345975186616 Training loss: 0.0
2025-12-09 10:23:34.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 5248 LR: 0.0009999345721078585 Training loss: 0.0
2025-12-09 10:23:34.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 5249 LR: 0.0009999345466921205 Training loss: 0.0
2025-12-09 10:23:34.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 5250 LR: 0.000999934521271447 Training loss: 0.0
2025-12-09 10:23:34.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 5251 LR: 0.0009999344958458386 Training loss: 0.0
2025-12-09 10:23:34.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 5252 LR: 0.000999934470415295 Training loss: 0.0
2025-12-09 10:23:34.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 5253 LR: 0.0009999344449798163 Training loss: 0.0
2025-12-09 10:23:34.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 5254 LR: 0.0009999344195394024 Training loss: 0.0
2025-12-09 10:23:34.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 5255 LR: 0.0009999343940940535 Training loss: 0.0
2025-12-09 10:23:34.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 5256 LR: 0.0009999343686437692 Training loss: 0.0
2025-12-09 10:23:34.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 5257 LR: 0.00099993434318855 Training loss: 0.0
2025-12-09 10:23:34.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 5258 LR: 0.0009999343177283955 Training loss: 0.0
2025-12-09 10:23:34.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 5259 LR: 0.0009999342922633059 Training loss: 0.0
2025-12-09 10:23:34.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 5260 LR: 0.0009999342667932811 Training loss: 0.0
2025-12-09 10:23:34.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 5261 LR: 0.0009999342413183213 Training loss: 0.0
2025-12-09 10:23:34.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 5262 LR: 0.0009999342158384262 Training loss: 0.0
2025-12-09 10:23:34.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 5263 LR: 0.000999934190353596 Training loss: 0.0
2025-12-09 10:23:34.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 5264 LR: 0.0009999341648638308 Training loss: 0.0
2025-12-09 10:23:34.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 5265 LR: 0.0009999341393691305 Training loss: 0.0
2025-12-09 10:23:34.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 5266 LR: 0.0009999341138694946 Training loss: 0.0
2025-12-09 10:23:34.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 5267 LR: 0.000999934088364924 Training loss: 0.0
2025-12-09 10:23:34.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 5268 LR: 0.0009999340628554182 Training loss: 0.0
2025-12-09 10:23:34.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 5269 LR: 0.0009999340373409772 Training loss: 0.0
2025-12-09 10:23:34.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 5270 LR: 0.000999934011821601 Training loss: 0.0
2025-12-09 10:23:34.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 5271 LR: 0.0009999339862972899 Training loss: 0.0
2025-12-09 10:23:34.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 5272 LR: 0.0009999339607680434 Training loss: 0.0
2025-12-09 10:23:34.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 5273 LR: 0.0009999339352338619 Training loss: 0.0
2025-12-09 10:23:34.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 5274 LR: 0.0009999339096947453 Training loss: 0.0
2025-12-09 10:23:34.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 5275 LR: 0.0009999338841506934 Training loss: 0.0
2025-12-09 10:23:34.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 5276 LR: 0.0009999338586017064 Training loss: 0.0
2025-12-09 10:23:34.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 5277 LR: 0.0009999338330477843 Training loss: 0.0
2025-12-09 10:23:34.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 5278 LR: 0.000999933807488927 Training loss: 0.0
2025-12-09 10:23:34.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 5279 LR: 0.0009999337819251348 Training loss: 0.0
2025-12-09 10:23:34.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 5280 LR: 0.0009999337563564074 Training loss: 0.0
2025-12-09 10:23:34.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 5281 LR: 0.0009999337307827446 Training loss: 0.0
2025-12-09 10:23:34.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 5282 LR: 0.0009999337052041468 Training loss: 0.0
2025-12-09 10:23:34.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 5283 LR: 0.000999933679620614 Training loss: 0.0
2025-12-09 10:23:34.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 5284 LR: 0.0009999336540321459 Training loss: 0.0
2025-12-09 10:23:34.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 5285 LR: 0.0009999336284387428 Training loss: 0.0
2025-12-09 10:23:34.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 5286 LR: 0.0009999336028404045 Training loss: 0.0
2025-12-09 10:23:34.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 5287 LR: 0.0009999335772371309 Training loss: 0.0
2025-12-09 10:23:34.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 5288 LR: 0.0009999335516289224 Training loss: 0.0
2025-12-09 10:23:34.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 5289 LR: 0.0009999335260157786 Training loss: 0.0
2025-12-09 10:23:34.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 5290 LR: 0.0009999335003977 Training loss: 0.0
2025-12-09 10:23:34.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 5291 LR: 0.0009999334747746859 Training loss: 0.0
2025-12-09 10:23:34.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 5292 LR: 0.0009999334491467369 Training loss: 0.0
2025-12-09 10:23:34.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 5293 LR: 0.0009999334235138526 Training loss: 0.0
2025-12-09 10:23:34.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 5294 LR: 0.0009999333978760333 Training loss: 0.0
2025-12-09 10:23:34.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 5295 LR: 0.0009999333722332786 Training loss: 0.0
2025-12-09 10:23:34.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 5296 LR: 0.0009999333465855892 Training loss: 0.0
2025-12-09 10:23:34.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 5297 LR: 0.0009999333209329644 Training loss: 0.0
2025-12-09 10:23:34.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 5298 LR: 0.0009999332952754043 Training loss: 0.0
2025-12-09 10:23:34.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 5299 LR: 0.0009999332696129094 Training loss: 0.0
2025-12-09 10:23:34.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 5300 LR: 0.0009999332439454792 Training loss: 0.0
2025-12-09 10:23:34.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 5301 LR: 0.000999933218273114 Training loss: 0.0
2025-12-09 10:23:34.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 5302 LR: 0.0009999331925958136 Training loss: 0.0
2025-12-09 10:23:34.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 5303 LR: 0.000999933166913578 Training loss: 0.0
2025-12-09 10:23:34.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 5304 LR: 0.0009999331412264072 Training loss: 0.0
2025-12-09 10:23:34.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 5305 LR: 0.0009999331155343015 Training loss: 0.0
2025-12-09 10:23:34.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 5306 LR: 0.0009999330898372604 Training loss: 0.0
2025-12-09 10:23:34.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 5307 LR: 0.0009999330641352845 Training loss: 0.0
2025-12-09 10:23:34.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 5308 LR: 0.0009999330384283733 Training loss: 0.0
2025-12-09 10:23:34.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 5309 LR: 0.000999933012716527 Training loss: 0.0
2025-12-09 10:23:34.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 5310 LR: 0.0009999329869997456 Training loss: 0.0
2025-12-09 10:23:34.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 5311 LR: 0.000999932961278029 Training loss: 0.0
2025-12-09 10:23:34.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 5312 LR: 0.0009999329355513773 Training loss: 0.0
2025-12-09 10:23:34.537 | INFO     | __main__:train:24 - Epoch: 0 Step: 5313 LR: 0.0009999329098197905 Training loss: 0.0
2025-12-09 10:23:34.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 5314 LR: 0.0009999328840832684 Training loss: 0.0
2025-12-09 10:23:34.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 5315 LR: 0.0009999328583418113 Training loss: 0.0
2025-12-09 10:23:34.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 5316 LR: 0.000999932832595419 Training loss: 0.0
2025-12-09 10:23:34.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 5317 LR: 0.0009999328068440918 Training loss: 0.0
2025-12-09 10:23:34.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 5318 LR: 0.0009999327810878294 Training loss: 0.0
2025-12-09 10:23:34.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 5319 LR: 0.0009999327553266318 Training loss: 0.0
2025-12-09 10:23:34.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 5320 LR: 0.000999932729560499 Training loss: 0.0
2025-12-09 10:23:34.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 5321 LR: 0.0009999327037894313 Training loss: 0.0
2025-12-09 10:23:34.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 5322 LR: 0.0009999326780134282 Training loss: 0.0
2025-12-09 10:23:34.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 5323 LR: 0.0009999326522324903 Training loss: 0.0
2025-12-09 10:23:34.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 5324 LR: 0.000999932626446617 Training loss: 0.0
2025-12-09 10:23:34.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 5325 LR: 0.0009999326006558085 Training loss: 0.0
2025-12-09 10:23:34.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 5326 LR: 0.0009999325748600652 Training loss: 0.0
2025-12-09 10:23:34.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 5327 LR: 0.0009999325490593865 Training loss: 0.0
2025-12-09 10:23:34.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 5328 LR: 0.0009999325232537728 Training loss: 0.0
2025-12-09 10:23:34.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 5329 LR: 0.000999932497443224 Training loss: 0.0
2025-12-09 10:23:34.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 5330 LR: 0.00099993247162774 Training loss: 0.0
2025-12-09 10:23:34.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 5331 LR: 0.000999932445807321 Training loss: 0.0
2025-12-09 10:23:34.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 5332 LR: 0.0009999324199819668 Training loss: 0.0
2025-12-09 10:23:34.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 5333 LR: 0.0009999323941516775 Training loss: 0.0
2025-12-09 10:23:34.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 5334 LR: 0.000999932368316453 Training loss: 0.0
2025-12-09 10:23:34.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 5335 LR: 0.0009999323424762935 Training loss: 0.0
2025-12-09 10:23:34.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 5336 LR: 0.0009999323166311987 Training loss: 0.0
2025-12-09 10:23:34.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 5337 LR: 0.000999932290781169 Training loss: 0.0
2025-12-09 10:23:34.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 5338 LR: 0.000999932264926204 Training loss: 0.0
2025-12-09 10:23:34.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 5339 LR: 0.000999932239066304 Training loss: 0.0
2025-12-09 10:23:34.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 5340 LR: 0.0009999322132014687 Training loss: 0.0
2025-12-09 10:23:34.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 5341 LR: 0.0009999321873316984 Training loss: 0.0
2025-12-09 10:23:34.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 5342 LR: 0.0009999321614569932 Training loss: 0.0
2025-12-09 10:23:34.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 5343 LR: 0.0009999321355773525 Training loss: 0.0
2025-12-09 10:23:34.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 5344 LR: 0.000999932109692777 Training loss: 0.0
2025-12-09 10:23:34.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 5345 LR: 0.0009999320838032662 Training loss: 0.0
2025-12-09 10:23:34.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 5346 LR: 0.0009999320579088204 Training loss: 0.0
2025-12-09 10:23:34.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 5347 LR: 0.0009999320320094392 Training loss: 0.0
2025-12-09 10:23:34.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 5348 LR: 0.0009999320061051232 Training loss: 0.0
2025-12-09 10:23:34.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 5349 LR: 0.0009999319801958719 Training loss: 0.0
2025-12-09 10:23:34.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 5350 LR: 0.0009999319542816857 Training loss: 0.0
2025-12-09 10:23:34.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 5351 LR: 0.000999931928362564 Training loss: 0.0
2025-12-09 10:23:34.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 5352 LR: 0.0009999319024385073 Training loss: 0.0
2025-12-09 10:23:34.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 5353 LR: 0.0009999318765095157 Training loss: 0.0
2025-12-09 10:23:34.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 5354 LR: 0.000999931850575589 Training loss: 0.0
2025-12-09 10:23:34.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 5355 LR: 0.000999931824636727 Training loss: 0.0
2025-12-09 10:23:34.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 5356 LR: 0.0009999317986929298 Training loss: 0.0
2025-12-09 10:23:34.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 5357 LR: 0.0009999317727441978 Training loss: 0.0
2025-12-09 10:23:34.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 5358 LR: 0.0009999317467905304 Training loss: 0.0
2025-12-09 10:23:34.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 5359 LR: 0.0009999317208319281 Training loss: 0.0
2025-12-09 10:23:34.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 5360 LR: 0.0009999316948683906 Training loss: 0.0
2025-12-09 10:23:34.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 5361 LR: 0.0009999316688999178 Training loss: 0.0
2025-12-09 10:23:34.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 5362 LR: 0.0009999316429265101 Training loss: 0.0
2025-12-09 10:23:34.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 5363 LR: 0.0009999316169481672 Training loss: 0.0
2025-12-09 10:23:34.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 5364 LR: 0.0009999315909648893 Training loss: 0.0
2025-12-09 10:23:34.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 5365 LR: 0.0009999315649766762 Training loss: 0.0
2025-12-09 10:23:34.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 5366 LR: 0.0009999315389835279 Training loss: 0.0
2025-12-09 10:23:34.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 5367 LR: 0.0009999315129854446 Training loss: 0.0
2025-12-09 10:23:34.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 5368 LR: 0.0009999314869824263 Training loss: 0.0
2025-12-09 10:23:34.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 5369 LR: 0.0009999314609744727 Training loss: 0.0
2025-12-09 10:23:34.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 5370 LR: 0.000999931434961584 Training loss: 0.0
2025-12-09 10:23:34.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 5371 LR: 0.00099993140894376 Training loss: 0.0
2025-12-09 10:23:34.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 5372 LR: 0.0009999313829210012 Training loss: 0.0
2025-12-09 10:23:34.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 5373 LR: 0.0009999313568933074 Training loss: 0.0
2025-12-09 10:23:34.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 5374 LR: 0.0009999313308606782 Training loss: 0.0
2025-12-09 10:23:34.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 5375 LR: 0.000999931304823114 Training loss: 0.0
2025-12-09 10:23:34.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 5376 LR: 0.0009999312787806146 Training loss: 0.0
2025-12-09 10:23:34.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 5377 LR: 0.0009999312527331802 Training loss: 0.0
2025-12-09 10:23:34.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 5378 LR: 0.0009999312266808105 Training loss: 0.0
2025-12-09 10:23:34.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 5379 LR: 0.000999931200623506 Training loss: 0.0
2025-12-09 10:23:34.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 5380 LR: 0.0009999311745612662 Training loss: 0.0
2025-12-09 10:23:34.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 5381 LR: 0.0009999311484940913 Training loss: 0.0
2025-12-09 10:23:34.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 5382 LR: 0.0009999311224219813 Training loss: 0.0
2025-12-09 10:23:34.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 5383 LR: 0.0009999310963449363 Training loss: 0.0
2025-12-09 10:23:34.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 5384 LR: 0.000999931070262956 Training loss: 0.0
2025-12-09 10:23:34.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 5385 LR: 0.0009999310441760406 Training loss: 0.0
2025-12-09 10:23:34.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 5386 LR: 0.0009999310180841903 Training loss: 0.0
2025-12-09 10:23:34.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 5387 LR: 0.0009999309919874048 Training loss: 0.0
2025-12-09 10:23:34.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 5388 LR: 0.0009999309658856842 Training loss: 0.0
2025-12-09 10:23:34.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 5389 LR: 0.0009999309397790283 Training loss: 0.0
2025-12-09 10:23:34.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 5390 LR: 0.0009999309136674375 Training loss: 0.0
2025-12-09 10:23:34.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 5391 LR: 0.0009999308875509115 Training loss: 0.0
2025-12-09 10:23:34.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 5392 LR: 0.0009999308614294503 Training loss: 0.0
2025-12-09 10:23:34.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 5393 LR: 0.0009999308353030542 Training loss: 0.0
2025-12-09 10:23:34.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 5394 LR: 0.000999930809171723 Training loss: 0.0
2025-12-09 10:23:34.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 5395 LR: 0.0009999307830354566 Training loss: 0.0
2025-12-09 10:23:34.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 5396 LR: 0.000999930756894255 Training loss: 0.0
2025-12-09 10:23:34.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 5397 LR: 0.0009999307307481183 Training loss: 0.0
2025-12-09 10:23:34.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 5398 LR: 0.0009999307045970467 Training loss: 0.0
2025-12-09 10:23:34.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 5399 LR: 0.00099993067844104 Training loss: 0.0
2025-12-09 10:23:34.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 5400 LR: 0.000999930652280098 Training loss: 0.0
2025-12-09 10:23:34.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 5401 LR: 0.000999930626114221 Training loss: 0.0
2025-12-09 10:23:34.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 5402 LR: 0.0009999305999434088 Training loss: 0.0
2025-12-09 10:23:34.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 5403 LR: 0.0009999305737676614 Training loss: 0.0
2025-12-09 10:23:34.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 5404 LR: 0.000999930547586979 Training loss: 0.0
2025-12-09 10:23:34.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 5405 LR: 0.0009999305214013615 Training loss: 0.0
2025-12-09 10:23:34.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 5406 LR: 0.0009999304952108092 Training loss: 0.0
2025-12-09 10:23:34.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 5407 LR: 0.0009999304690153214 Training loss: 0.0
2025-12-09 10:23:34.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 5408 LR: 0.0009999304428148987 Training loss: 0.0
2025-12-09 10:23:34.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 5409 LR: 0.000999930416609541 Training loss: 0.0
2025-12-09 10:23:34.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 5410 LR: 0.0009999303903992479 Training loss: 0.0
2025-12-09 10:23:34.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 5411 LR: 0.0009999303641840197 Training loss: 0.0
2025-12-09 10:23:34.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 5412 LR: 0.0009999303379638568 Training loss: 0.0
2025-12-09 10:23:34.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 5413 LR: 0.0009999303117387583 Training loss: 0.0
2025-12-09 10:23:34.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 5414 LR: 0.0009999302855087252 Training loss: 0.0
2025-12-09 10:23:34.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 5415 LR: 0.0009999302592737565 Training loss: 0.0
2025-12-09 10:23:34.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 5416 LR: 0.000999930233033853 Training loss: 0.0
2025-12-09 10:23:34.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 5417 LR: 0.0009999302067890143 Training loss: 0.0
2025-12-09 10:23:34.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 5418 LR: 0.0009999301805392405 Training loss: 0.0
2025-12-09 10:23:34.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 5419 LR: 0.0009999301542845318 Training loss: 0.0
2025-12-09 10:23:34.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 5420 LR: 0.0009999301280248878 Training loss: 0.0
2025-12-09 10:23:34.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 5421 LR: 0.0009999301017603087 Training loss: 0.0
2025-12-09 10:23:34.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 5422 LR: 0.0009999300754907946 Training loss: 0.0
2025-12-09 10:23:34.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 5423 LR: 0.0009999300492163452 Training loss: 0.0
2025-12-09 10:23:34.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 5424 LR: 0.0009999300229369607 Training loss: 0.0
2025-12-09 10:23:34.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 5425 LR: 0.0009999299966526414 Training loss: 0.0
2025-12-09 10:23:34.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 5426 LR: 0.0009999299703633867 Training loss: 0.0
2025-12-09 10:23:34.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 5427 LR: 0.000999929944069197 Training loss: 0.0
2025-12-09 10:23:34.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 5428 LR: 0.0009999299177700725 Training loss: 0.0
2025-12-09 10:23:34.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 5429 LR: 0.0009999298914660126 Training loss: 0.0
2025-12-09 10:23:34.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 5430 LR: 0.0009999298651570177 Training loss: 0.0
2025-12-09 10:23:34.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 5431 LR: 0.0009999298388430875 Training loss: 0.0
2025-12-09 10:23:34.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 5432 LR: 0.0009999298125242225 Training loss: 0.0
2025-12-09 10:23:34.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 5433 LR: 0.0009999297862004221 Training loss: 0.0
2025-12-09 10:23:34.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 5434 LR: 0.0009999297598716867 Training loss: 0.0
2025-12-09 10:23:34.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 5435 LR: 0.0009999297335380164 Training loss: 0.0
2025-12-09 10:23:34.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 5436 LR: 0.0009999297071994109 Training loss: 0.0
2025-12-09 10:23:34.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 5437 LR: 0.0009999296808558703 Training loss: 0.0
2025-12-09 10:23:34.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 5438 LR: 0.0009999296545073946 Training loss: 0.0
2025-12-09 10:23:34.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 5439 LR: 0.0009999296281539836 Training loss: 0.0
2025-12-09 10:23:34.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 5440 LR: 0.0009999296017956377 Training loss: 0.0
2025-12-09 10:23:34.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 5441 LR: 0.0009999295754323568 Training loss: 0.0
2025-12-09 10:23:34.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 5442 LR: 0.0009999295490641406 Training loss: 0.0
2025-12-09 10:23:34.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 5443 LR: 0.0009999295226909895 Training loss: 0.0
2025-12-09 10:23:34.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 5444 LR: 0.000999929496312903 Training loss: 0.0
2025-12-09 10:23:34.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 5445 LR: 0.0009999294699298818 Training loss: 0.0
2025-12-09 10:23:34.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 5446 LR: 0.0009999294435419253 Training loss: 0.0
2025-12-09 10:23:34.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 5447 LR: 0.0009999294171490337 Training loss: 0.0
2025-12-09 10:23:34.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 5448 LR: 0.000999929390751207 Training loss: 0.0
2025-12-09 10:23:34.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 5449 LR: 0.0009999293643484452 Training loss: 0.0
2025-12-09 10:23:34.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 5450 LR: 0.0009999293379407484 Training loss: 0.0
2025-12-09 10:23:34.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 5451 LR: 0.0009999293115281165 Training loss: 0.0
2025-12-09 10:23:34.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 5452 LR: 0.0009999292851105494 Training loss: 0.0
2025-12-09 10:23:34.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 5453 LR: 0.0009999292586880474 Training loss: 0.0
2025-12-09 10:23:34.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 5454 LR: 0.0009999292322606101 Training loss: 0.0
2025-12-09 10:23:34.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 5455 LR: 0.0009999292058282378 Training loss: 0.0
2025-12-09 10:23:34.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 5456 LR: 0.0009999291793909304 Training loss: 0.0
2025-12-09 10:23:34.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 5457 LR: 0.000999929152948688 Training loss: 0.0
2025-12-09 10:23:34.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 5458 LR: 0.0009999291265015105 Training loss: 0.0
2025-12-09 10:23:34.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 5459 LR: 0.0009999291000493977 Training loss: 0.0
2025-12-09 10:23:34.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 5460 LR: 0.00099992907359235 Training loss: 0.0
2025-12-09 10:23:34.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 5461 LR: 0.0009999290471303672 Training loss: 0.0
2025-12-09 10:23:34.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 5462 LR: 0.0009999290206634493 Training loss: 0.0
2025-12-09 10:23:34.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 5463 LR: 0.0009999289941915962 Training loss: 0.0
2025-12-09 10:23:34.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 5464 LR: 0.0009999289677148082 Training loss: 0.0
2025-12-09 10:23:34.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 5465 LR: 0.000999928941233085 Training loss: 0.0
2025-12-09 10:23:34.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 5466 LR: 0.0009999289147464266 Training loss: 0.0
2025-12-09 10:23:34.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 5467 LR: 0.0009999288882548332 Training loss: 0.0
2025-12-09 10:23:34.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 5468 LR: 0.0009999288617583049 Training loss: 0.0
2025-12-09 10:23:34.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 5469 LR: 0.000999928835256841 Training loss: 0.0
2025-12-09 10:23:34.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 5470 LR: 0.0009999288087504427 Training loss: 0.0
2025-12-09 10:23:34.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 5471 LR: 0.000999928782239109 Training loss: 0.0
2025-12-09 10:23:34.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 5472 LR: 0.00099992875572284 Training loss: 0.0
2025-12-09 10:23:34.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 5473 LR: 0.0009999287292016363 Training loss: 0.0
2025-12-09 10:23:34.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 5474 LR: 0.0009999287026754972 Training loss: 0.0
2025-12-09 10:23:34.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 5475 LR: 0.0009999286761444232 Training loss: 0.0
2025-12-09 10:23:34.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 5476 LR: 0.0009999286496084141 Training loss: 0.0
2025-12-09 10:23:34.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 5477 LR: 0.0009999286230674698 Training loss: 0.0
2025-12-09 10:23:34.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 5478 LR: 0.0009999285965215906 Training loss: 0.0
2025-12-09 10:23:34.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 5479 LR: 0.000999928569970776 Training loss: 0.0
2025-12-09 10:23:34.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 5480 LR: 0.0009999285434150265 Training loss: 0.0
2025-12-09 10:23:34.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 5481 LR: 0.000999928516854342 Training loss: 0.0
2025-12-09 10:23:34.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 5482 LR: 0.0009999284902887224 Training loss: 0.0
2025-12-09 10:23:34.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 5483 LR: 0.0009999284637181676 Training loss: 0.0
2025-12-09 10:23:34.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 5484 LR: 0.0009999284371426777 Training loss: 0.0
2025-12-09 10:23:34.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 5485 LR: 0.000999928410562253 Training loss: 0.0
2025-12-09 10:23:34.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 5486 LR: 0.000999928383976893 Training loss: 0.0
2025-12-09 10:23:34.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 5487 LR: 0.0009999283573865977 Training loss: 0.0
2025-12-09 10:23:34.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 5488 LR: 0.0009999283307913678 Training loss: 0.0
2025-12-09 10:23:34.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 5489 LR: 0.0009999283041912026 Training loss: 0.0
2025-12-09 10:23:34.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 5490 LR: 0.000999928277586102 Training loss: 0.0
2025-12-09 10:23:34.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 5491 LR: 0.0009999282509760667 Training loss: 0.0
2025-12-09 10:23:34.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 5492 LR: 0.0009999282243610963 Training loss: 0.0
2025-12-09 10:23:34.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 5493 LR: 0.0009999281977411908 Training loss: 0.0
2025-12-09 10:23:34.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 5494 LR: 0.0009999281711163502 Training loss: 0.0
2025-12-09 10:23:34.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 5495 LR: 0.0009999281444865744 Training loss: 0.0
2025-12-09 10:23:34.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 5496 LR: 0.0009999281178518637 Training loss: 0.0
2025-12-09 10:23:34.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 5497 LR: 0.0009999280912122177 Training loss: 0.0
2025-12-09 10:23:34.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 5498 LR: 0.0009999280645676368 Training loss: 0.0
2025-12-09 10:23:34.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 5499 LR: 0.0009999280379181209 Training loss: 0.0
2025-12-09 10:23:34.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 5500 LR: 0.0009999280112636697 Training loss: 0.0
2025-12-09 10:23:34.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 5501 LR: 0.0009999279846042834 Training loss: 0.0
2025-12-09 10:23:34.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 5502 LR: 0.0009999279579399622 Training loss: 0.0
2025-12-09 10:23:34.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 5503 LR: 0.0009999279312707058 Training loss: 0.0
2025-12-09 10:23:34.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 5504 LR: 0.0009999279045965143 Training loss: 0.0
2025-12-09 10:23:34.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 5505 LR: 0.000999927877917388 Training loss: 0.0
2025-12-09 10:23:34.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 5506 LR: 0.0009999278512333263 Training loss: 0.0
2025-12-09 10:23:34.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 5507 LR: 0.0009999278245443298 Training loss: 0.0
2025-12-09 10:23:34.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 5508 LR: 0.000999927797850398 Training loss: 0.0
2025-12-09 10:23:34.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 5509 LR: 0.0009999277711515312 Training loss: 0.0
2025-12-09 10:23:34.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 5510 LR: 0.0009999277444477292 Training loss: 0.0
2025-12-09 10:23:34.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 5511 LR: 0.0009999277177389922 Training loss: 0.0
2025-12-09 10:23:34.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 5512 LR: 0.0009999276910253201 Training loss: 0.0
2025-12-09 10:23:34.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 5513 LR: 0.0009999276643067132 Training loss: 0.0
2025-12-09 10:23:34.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 5514 LR: 0.000999927637583171 Training loss: 0.0
2025-12-09 10:23:34.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 5515 LR: 0.0009999276108546937 Training loss: 0.0
2025-12-09 10:23:34.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 5516 LR: 0.0009999275841212814 Training loss: 0.0
2025-12-09 10:23:34.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 5517 LR: 0.000999927557382934 Training loss: 0.0
2025-12-09 10:23:34.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 5518 LR: 0.0009999275306396514 Training loss: 0.0
2025-12-09 10:23:34.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 5519 LR: 0.0009999275038914339 Training loss: 0.0
2025-12-09 10:23:34.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 5520 LR: 0.0009999274771382812 Training loss: 0.0
2025-12-09 10:23:34.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 5521 LR: 0.0009999274503801935 Training loss: 0.0
2025-12-09 10:23:34.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 5522 LR: 0.0009999274236171707 Training loss: 0.0
2025-12-09 10:23:34.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 5523 LR: 0.0009999273968492128 Training loss: 0.0
2025-12-09 10:23:34.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 5524 LR: 0.00099992737007632 Training loss: 0.0
2025-12-09 10:23:34.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 5525 LR: 0.000999927343298492 Training loss: 0.0
2025-12-09 10:23:34.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 5526 LR: 0.0009999273165157288 Training loss: 0.0
2025-12-09 10:23:34.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 5527 LR: 0.0009999272897280307 Training loss: 0.0
2025-12-09 10:23:34.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 5528 LR: 0.0009999272629353975 Training loss: 0.0
2025-12-09 10:23:34.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 5529 LR: 0.0009999272361378292 Training loss: 0.0
2025-12-09 10:23:34.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 5530 LR: 0.0009999272093353258 Training loss: 0.0
2025-12-09 10:23:34.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 5531 LR: 0.0009999271825278874 Training loss: 0.0
2025-12-09 10:23:34.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 5532 LR: 0.000999927155715514 Training loss: 0.0
2025-12-09 10:23:34.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 5533 LR: 0.0009999271288982053 Training loss: 0.0
2025-12-09 10:23:34.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 5534 LR: 0.0009999271020759617 Training loss: 0.0
2025-12-09 10:23:34.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 5535 LR: 0.000999927075248783 Training loss: 0.0
2025-12-09 10:23:34.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 5536 LR: 0.0009999270484166692 Training loss: 0.0
2025-12-09 10:23:34.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 5537 LR: 0.0009999270215796203 Training loss: 0.0
2025-12-09 10:23:34.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 5538 LR: 0.0009999269947376364 Training loss: 0.0
2025-12-09 10:23:34.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 5539 LR: 0.0009999269678907174 Training loss: 0.0
2025-12-09 10:23:34.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 5540 LR: 0.0009999269410388633 Training loss: 0.0
2025-12-09 10:23:34.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 5541 LR: 0.0009999269141820744 Training loss: 0.0
2025-12-09 10:23:34.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 5542 LR: 0.0009999268873203502 Training loss: 0.0
2025-12-09 10:23:34.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 5543 LR: 0.0009999268604536909 Training loss: 0.0
2025-12-09 10:23:34.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 5544 LR: 0.0009999268335820965 Training loss: 0.0
2025-12-09 10:23:34.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 5545 LR: 0.000999926806705567 Training loss: 0.0
2025-12-09 10:23:34.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 5546 LR: 0.0009999267798241028 Training loss: 0.0
2025-12-09 10:23:34.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 5547 LR: 0.0009999267529377032 Training loss: 0.0
2025-12-09 10:23:34.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 5548 LR: 0.0009999267260463684 Training loss: 0.0
2025-12-09 10:23:34.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 5549 LR: 0.0009999266991500989 Training loss: 0.0
2025-12-09 10:23:34.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 5550 LR: 0.0009999266722488943 Training loss: 0.0
2025-12-09 10:23:34.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 5551 LR: 0.0009999266453427544 Training loss: 0.0
2025-12-09 10:23:34.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 5552 LR: 0.0009999266184316795 Training loss: 0.0
2025-12-09 10:23:34.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 5553 LR: 0.0009999265915156697 Training loss: 0.0
2025-12-09 10:23:34.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 5554 LR: 0.0009999265645947246 Training loss: 0.0
2025-12-09 10:23:34.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 5555 LR: 0.0009999265376688445 Training loss: 0.0
2025-12-09 10:23:34.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 5556 LR: 0.0009999265107380295 Training loss: 0.0
2025-12-09 10:23:34.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 5557 LR: 0.0009999264838022792 Training loss: 0.0
2025-12-09 10:23:34.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 5558 LR: 0.000999926456861594 Training loss: 0.0
2025-12-09 10:23:34.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 5559 LR: 0.0009999264299159739 Training loss: 0.0
2025-12-09 10:23:34.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 5560 LR: 0.0009999264029654184 Training loss: 0.0
2025-12-09 10:23:34.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 5561 LR: 0.000999926376009928 Training loss: 0.0
2025-12-09 10:23:34.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 5562 LR: 0.0009999263490495026 Training loss: 0.0
2025-12-09 10:23:34.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 5563 LR: 0.0009999263220841418 Training loss: 0.0
2025-12-09 10:23:34.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 5564 LR: 0.0009999262951138463 Training loss: 0.0
2025-12-09 10:23:34.758 | INFO     | __main__:train:24 - Epoch: 0 Step: 5565 LR: 0.0009999262681386156 Training loss: 0.0
2025-12-09 10:23:34.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 5566 LR: 0.00099992624115845 Training loss: 0.0
2025-12-09 10:23:34.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 5567 LR: 0.0009999262141733491 Training loss: 0.0
2025-12-09 10:23:34.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 5568 LR: 0.0009999261871833133 Training loss: 0.0
2025-12-09 10:23:34.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 5569 LR: 0.0009999261601883423 Training loss: 0.0
2025-12-09 10:23:34.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 5570 LR: 0.0009999261331884363 Training loss: 0.0
2025-12-09 10:23:34.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 5571 LR: 0.0009999261061835953 Training loss: 0.0
2025-12-09 10:23:34.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 5572 LR: 0.0009999260791738191 Training loss: 0.0
2025-12-09 10:23:34.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 5573 LR: 0.0009999260521591081 Training loss: 0.0
2025-12-09 10:23:34.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 5574 LR: 0.0009999260251394616 Training loss: 0.0
2025-12-09 10:23:34.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 5575 LR: 0.0009999259981148805 Training loss: 0.0
2025-12-09 10:23:34.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 5576 LR: 0.0009999259710853643 Training loss: 0.0
2025-12-09 10:23:34.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 5577 LR: 0.0009999259440509128 Training loss: 0.0
2025-12-09 10:23:34.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 5578 LR: 0.0009999259170115264 Training loss: 0.0
2025-12-09 10:23:34.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 5579 LR: 0.0009999258899672048 Training loss: 0.0
2025-12-09 10:23:34.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 5580 LR: 0.0009999258629179483 Training loss: 0.0
2025-12-09 10:23:34.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 5581 LR: 0.0009999258358637567 Training loss: 0.0
2025-12-09 10:23:34.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 5582 LR: 0.0009999258088046299 Training loss: 0.0
2025-12-09 10:23:34.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 5583 LR: 0.0009999257817405681 Training loss: 0.0
2025-12-09 10:23:34.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 5584 LR: 0.0009999257546715714 Training loss: 0.0
2025-12-09 10:23:34.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 5585 LR: 0.0009999257275976395 Training loss: 0.0
2025-12-09 10:23:34.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 5586 LR: 0.0009999257005187726 Training loss: 0.0
2025-12-09 10:23:34.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 5587 LR: 0.0009999256734349706 Training loss: 0.0
2025-12-09 10:23:34.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 5588 LR: 0.0009999256463462335 Training loss: 0.0
2025-12-09 10:23:34.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 5589 LR: 0.0009999256192525616 Training loss: 0.0
2025-12-09 10:23:34.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 5590 LR: 0.0009999255921539544 Training loss: 0.0
2025-12-09 10:23:34.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 5591 LR: 0.0009999255650504123 Training loss: 0.0
2025-12-09 10:23:34.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 5592 LR: 0.000999925537941935 Training loss: 0.0
2025-12-09 10:23:34.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 5593 LR: 0.0009999255108285227 Training loss: 0.0
2025-12-09 10:23:34.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 5594 LR: 0.0009999254837101752 Training loss: 0.0
2025-12-09 10:23:34.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 5595 LR: 0.000999925456586893 Training loss: 0.0
2025-12-09 10:23:34.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 5596 LR: 0.0009999254294586755 Training loss: 0.0
2025-12-09 10:23:34.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 5597 LR: 0.000999925402325523 Training loss: 0.0
2025-12-09 10:23:34.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 5598 LR: 0.0009999253751874354 Training loss: 0.0
2025-12-09 10:23:34.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 5599 LR: 0.0009999253480444128 Training loss: 0.0
2025-12-09 10:23:34.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 5600 LR: 0.000999925320896455 Training loss: 0.0
2025-12-09 10:23:34.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 5601 LR: 0.0009999252937435623 Training loss: 0.0
2025-12-09 10:23:34.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 5602 LR: 0.0009999252665857346 Training loss: 0.0
2025-12-09 10:23:34.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 5603 LR: 0.000999925239422972 Training loss: 0.0
2025-12-09 10:23:34.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 5604 LR: 0.000999925212255274 Training loss: 0.0
2025-12-09 10:23:34.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 5605 LR: 0.0009999251850826409 Training loss: 0.0
2025-12-09 10:23:34.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 5606 LR: 0.000999925157905073 Training loss: 0.0
2025-12-09 10:23:34.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 5607 LR: 0.00099992513072257 Training loss: 0.0
2025-12-09 10:23:34.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 5608 LR: 0.0009999251035351319 Training loss: 0.0
2025-12-09 10:23:34.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 5609 LR: 0.0009999250763427588 Training loss: 0.0
2025-12-09 10:23:34.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 5610 LR: 0.0009999250491454505 Training loss: 0.0
2025-12-09 10:23:34.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 5611 LR: 0.0009999250219432075 Training loss: 0.0
2025-12-09 10:23:34.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 5612 LR: 0.0009999249947360291 Training loss: 0.0
2025-12-09 10:23:34.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 5613 LR: 0.0009999249675239157 Training loss: 0.0
2025-12-09 10:23:34.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 5614 LR: 0.0009999249403068672 Training loss: 0.0
2025-12-09 10:23:34.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 5615 LR: 0.000999924913084884 Training loss: 0.0
2025-12-09 10:23:34.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 5616 LR: 0.0009999248858579654 Training loss: 0.0
2025-12-09 10:23:34.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 5617 LR: 0.000999924858626112 Training loss: 0.0
2025-12-09 10:23:34.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 5618 LR: 0.0009999248313893234 Training loss: 0.0
2025-12-09 10:23:34.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 5619 LR: 0.0009999248041475998 Training loss: 0.0
2025-12-09 10:23:34.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 5620 LR: 0.0009999247769009413 Training loss: 0.0
2025-12-09 10:23:34.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 5621 LR: 0.0009999247496493475 Training loss: 0.0
2025-12-09 10:23:34.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 5622 LR: 0.0009999247223928186 Training loss: 0.0
2025-12-09 10:23:34.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 5623 LR: 0.000999924695131355 Training loss: 0.0
2025-12-09 10:23:34.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 5624 LR: 0.000999924667864956 Training loss: 0.0
2025-12-09 10:23:34.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 5625 LR: 0.0009999246405936221 Training loss: 0.0
2025-12-09 10:23:34.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 5626 LR: 0.0009999246133173532 Training loss: 0.0
2025-12-09 10:23:34.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 5627 LR: 0.0009999245860361492 Training loss: 0.0
2025-12-09 10:23:34.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 5628 LR: 0.0009999245587500101 Training loss: 0.0
2025-12-09 10:23:34.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 5629 LR: 0.0009999245314589362 Training loss: 0.0
2025-12-09 10:23:34.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 5630 LR: 0.000999924504162927 Training loss: 0.0
2025-12-09 10:23:34.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 5631 LR: 0.0009999244768619828 Training loss: 0.0
2025-12-09 10:23:34.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 5632 LR: 0.0009999244495561036 Training loss: 0.0
2025-12-09 10:23:34.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 5633 LR: 0.0009999244222452894 Training loss: 0.0
2025-12-09 10:23:34.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 5634 LR: 0.0009999243949295402 Training loss: 0.0
2025-12-09 10:23:34.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 5635 LR: 0.0009999243676088558 Training loss: 0.0
2025-12-09 10:23:34.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 5636 LR: 0.0009999243402832364 Training loss: 0.0
2025-12-09 10:23:34.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 5637 LR: 0.0009999243129526821 Training loss: 0.0
2025-12-09 10:23:34.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 5638 LR: 0.0009999242856171926 Training loss: 0.0
2025-12-09 10:23:34.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 5639 LR: 0.000999924258276768 Training loss: 0.0
2025-12-09 10:23:34.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 5640 LR: 0.0009999242309314085 Training loss: 0.0
2025-12-09 10:23:34.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 5641 LR: 0.000999924203581114 Training loss: 0.0
2025-12-09 10:23:34.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 5642 LR: 0.0009999241762258843 Training loss: 0.0
2025-12-09 10:23:34.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 5643 LR: 0.0009999241488657196 Training loss: 0.0
2025-12-09 10:23:34.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 5644 LR: 0.0009999241215006198 Training loss: 0.0
2025-12-09 10:23:34.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 5645 LR: 0.0009999240941305852 Training loss: 0.0
2025-12-09 10:23:34.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 5646 LR: 0.0009999240667556153 Training loss: 0.0
2025-12-09 10:23:34.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 5647 LR: 0.0009999240393757105 Training loss: 0.0
2025-12-09 10:23:34.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 5648 LR: 0.0009999240119908707 Training loss: 0.0
2025-12-09 10:23:34.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 5649 LR: 0.0009999239846010958 Training loss: 0.0
2025-12-09 10:23:34.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 5650 LR: 0.0009999239572063858 Training loss: 0.0
2025-12-09 10:23:34.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 5651 LR: 0.000999923929806741 Training loss: 0.0
2025-12-09 10:23:34.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 5652 LR: 0.0009999239024021608 Training loss: 0.0
2025-12-09 10:23:34.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 5653 LR: 0.0009999238749926458 Training loss: 0.0
2025-12-09 10:23:34.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 5654 LR: 0.0009999238475781956 Training loss: 0.0
2025-12-09 10:23:34.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 5655 LR: 0.0009999238201588107 Training loss: 0.0
2025-12-09 10:23:34.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 5656 LR: 0.0009999237927344905 Training loss: 0.0
2025-12-09 10:23:34.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 5657 LR: 0.0009999237653052352 Training loss: 0.0
2025-12-09 10:23:34.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 5658 LR: 0.0009999237378710449 Training loss: 0.0
2025-12-09 10:23:34.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 5659 LR: 0.0009999237104319197 Training loss: 0.0
2025-12-09 10:23:34.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 5660 LR: 0.0009999236829878592 Training loss: 0.0
2025-12-09 10:23:34.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 5661 LR: 0.000999923655538864 Training loss: 0.0
2025-12-09 10:23:34.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 5662 LR: 0.0009999236280849335 Training loss: 0.0
2025-12-09 10:23:34.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 5663 LR: 0.0009999236006260682 Training loss: 0.0
2025-12-09 10:23:34.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 5664 LR: 0.0009999235731622676 Training loss: 0.0
2025-12-09 10:23:34.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 5665 LR: 0.0009999235456935322 Training loss: 0.0
2025-12-09 10:23:34.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 5666 LR: 0.0009999235182198616 Training loss: 0.0
2025-12-09 10:23:34.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 5667 LR: 0.000999923490741256 Training loss: 0.0
2025-12-09 10:23:34.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 5668 LR: 0.0009999234632577154 Training loss: 0.0
2025-12-09 10:23:34.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 5669 LR: 0.00099992343576924 Training loss: 0.0
2025-12-09 10:23:34.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 5670 LR: 0.0009999234082758292 Training loss: 0.0
2025-12-09 10:23:34.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 5671 LR: 0.0009999233807774835 Training loss: 0.0
2025-12-09 10:23:34.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 5672 LR: 0.0009999233532742026 Training loss: 0.0
2025-12-09 10:23:34.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 5673 LR: 0.0009999233257659869 Training loss: 0.0
2025-12-09 10:23:34.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 5674 LR: 0.000999923298252836 Training loss: 0.0
2025-12-09 10:23:34.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 5675 LR: 0.0009999232707347504 Training loss: 0.0
2025-12-09 10:23:34.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 5676 LR: 0.0009999232432117294 Training loss: 0.0
2025-12-09 10:23:34.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 5677 LR: 0.0009999232156837736 Training loss: 0.0
2025-12-09 10:23:34.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 5678 LR: 0.0009999231881508825 Training loss: 0.0
2025-12-09 10:23:34.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 5679 LR: 0.0009999231606130567 Training loss: 0.0
2025-12-09 10:23:34.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 5680 LR: 0.0009999231330702957 Training loss: 0.0
2025-12-09 10:23:34.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 5681 LR: 0.0009999231055225998 Training loss: 0.0
2025-12-09 10:23:34.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 5682 LR: 0.0009999230779699686 Training loss: 0.0
2025-12-09 10:23:34.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 5683 LR: 0.0009999230504124026 Training loss: 0.0
2025-12-09 10:23:34.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 5684 LR: 0.0009999230228499014 Training loss: 0.0
2025-12-09 10:23:34.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 5685 LR: 0.0009999229952824653 Training loss: 0.0
2025-12-09 10:23:34.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 5686 LR: 0.000999922967710094 Training loss: 0.0
2025-12-09 10:23:34.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 5687 LR: 0.000999922940132788 Training loss: 0.0
2025-12-09 10:23:34.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 5688 LR: 0.0009999229125505467 Training loss: 0.0
2025-12-09 10:23:34.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 5689 LR: 0.0009999228849633705 Training loss: 0.0
2025-12-09 10:23:34.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 5690 LR: 0.0009999228573712592 Training loss: 0.0
2025-12-09 10:23:34.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 5691 LR: 0.000999922829774213 Training loss: 0.0
2025-12-09 10:23:34.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 5692 LR: 0.0009999228021722315 Training loss: 0.0
2025-12-09 10:23:34.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 5693 LR: 0.0009999227745653152 Training loss: 0.0
2025-12-09 10:23:34.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 5694 LR: 0.0009999227469534638 Training loss: 0.0
2025-12-09 10:23:34.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 5695 LR: 0.0009999227193366773 Training loss: 0.0
2025-12-09 10:23:34.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 5696 LR: 0.000999922691714956 Training loss: 0.0
2025-12-09 10:23:34.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 5697 LR: 0.0009999226640882994 Training loss: 0.0
2025-12-09 10:23:34.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 5698 LR: 0.000999922636456708 Training loss: 0.0
2025-12-09 10:23:34.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 5699 LR: 0.0009999226088201814 Training loss: 0.0
2025-12-09 10:23:34.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 5700 LR: 0.0009999225811787198 Training loss: 0.0
2025-12-09 10:23:34.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 5701 LR: 0.0009999225535323234 Training loss: 0.0
2025-12-09 10:23:34.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 5702 LR: 0.0009999225258809918 Training loss: 0.0
2025-12-09 10:23:34.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 5703 LR: 0.0009999224982247252 Training loss: 0.0
2025-12-09 10:23:34.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 5704 LR: 0.0009999224705635236 Training loss: 0.0
2025-12-09 10:23:34.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 5705 LR: 0.0009999224428973868 Training loss: 0.0
2025-12-09 10:23:34.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 5706 LR: 0.000999922415226315 Training loss: 0.0
2025-12-09 10:23:34.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 5707 LR: 0.0009999223875503083 Training loss: 0.0
2025-12-09 10:23:34.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 5708 LR: 0.0009999223598693666 Training loss: 0.0
2025-12-09 10:23:34.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 5709 LR: 0.0009999223321834898 Training loss: 0.0
2025-12-09 10:23:34.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 5710 LR: 0.0009999223044926781 Training loss: 0.0
2025-12-09 10:23:34.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 5711 LR: 0.0009999222767969314 Training loss: 0.0
2025-12-09 10:23:34.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 5712 LR: 0.0009999222490962494 Training loss: 0.0
2025-12-09 10:23:34.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 5713 LR: 0.0009999222213906327 Training loss: 0.0
2025-12-09 10:23:34.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 5714 LR: 0.0009999221936800807 Training loss: 0.0
2025-12-09 10:23:34.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 5715 LR: 0.000999922165964594 Training loss: 0.0
2025-12-09 10:23:34.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 5716 LR: 0.0009999221382441718 Training loss: 0.0
2025-12-09 10:23:34.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 5717 LR: 0.000999922110518815 Training loss: 0.0
2025-12-09 10:23:34.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 5718 LR: 0.000999922082788523 Training loss: 0.0
2025-12-09 10:23:34.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 5719 LR: 0.0009999220550532962 Training loss: 0.0
2025-12-09 10:23:34.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 5720 LR: 0.000999922027313134 Training loss: 0.0
2025-12-09 10:23:34.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 5721 LR: 0.000999921999568037 Training loss: 0.0
2025-12-09 10:23:34.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 5722 LR: 0.000999921971818005 Training loss: 0.0
2025-12-09 10:23:34.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 5723 LR: 0.000999921944063038 Training loss: 0.0
2025-12-09 10:23:34.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 5724 LR: 0.000999921916303136 Training loss: 0.0
2025-12-09 10:23:34.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 5725 LR: 0.000999921888538299 Training loss: 0.0
2025-12-09 10:23:34.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 5726 LR: 0.0009999218607685267 Training loss: 0.0
2025-12-09 10:23:34.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 5727 LR: 0.0009999218329938195 Training loss: 0.0
2025-12-09 10:23:34.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 5728 LR: 0.0009999218052141774 Training loss: 0.0
2025-12-09 10:23:34.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 5729 LR: 0.0009999217774296003 Training loss: 0.0
2025-12-09 10:23:34.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 5730 LR: 0.000999921749640088 Training loss: 0.0
2025-12-09 10:23:34.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 5731 LR: 0.000999921721845641 Training loss: 0.0
2025-12-09 10:23:34.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 5732 LR: 0.0009999216940462588 Training loss: 0.0
2025-12-09 10:23:34.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 5733 LR: 0.0009999216662419416 Training loss: 0.0
2025-12-09 10:23:34.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 5734 LR: 0.0009999216384326893 Training loss: 0.0
2025-12-09 10:23:34.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 5735 LR: 0.000999921610618502 Training loss: 0.0
2025-12-09 10:23:34.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 5736 LR: 0.0009999215827993797 Training loss: 0.0
2025-12-09 10:23:34.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 5737 LR: 0.0009999215549753224 Training loss: 0.0
2025-12-09 10:23:34.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 5738 LR: 0.00099992152714633 Training loss: 0.0
2025-12-09 10:23:34.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 5739 LR: 0.0009999214993124028 Training loss: 0.0
2025-12-09 10:23:34.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 5740 LR: 0.0009999214714735405 Training loss: 0.0
2025-12-09 10:23:34.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 5741 LR: 0.000999921443629743 Training loss: 0.0
2025-12-09 10:23:34.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 5742 LR: 0.0009999214157810107 Training loss: 0.0
2025-12-09 10:23:34.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 5743 LR: 0.0009999213879273434 Training loss: 0.0
2025-12-09 10:23:34.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 5744 LR: 0.0009999213600687409 Training loss: 0.0
2025-12-09 10:23:34.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 5745 LR: 0.0009999213322052036 Training loss: 0.0
2025-12-09 10:23:34.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 5746 LR: 0.0009999213043367311 Training loss: 0.0
2025-12-09 10:23:34.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 5747 LR: 0.0009999212764633236 Training loss: 0.0
2025-12-09 10:23:34.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 5748 LR: 0.0009999212485849813 Training loss: 0.0
2025-12-09 10:23:34.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 5749 LR: 0.0009999212207017038 Training loss: 0.0
2025-12-09 10:23:34.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 5750 LR: 0.0009999211928134913 Training loss: 0.0
2025-12-09 10:23:34.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 5751 LR: 0.0009999211649203438 Training loss: 0.0
2025-12-09 10:23:34.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 5752 LR: 0.0009999211370222613 Training loss: 0.0
2025-12-09 10:23:34.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 5753 LR: 0.000999921109119244 Training loss: 0.0
2025-12-09 10:23:34.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 5754 LR: 0.0009999210812112914 Training loss: 0.0
2025-12-09 10:23:34.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 5755 LR: 0.0009999210532984039 Training loss: 0.0
2025-12-09 10:23:34.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 5756 LR: 0.0009999210253805813 Training loss: 0.0
2025-12-09 10:23:34.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 5757 LR: 0.0009999209974578239 Training loss: 0.0
2025-12-09 10:23:34.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 5758 LR: 0.0009999209695301312 Training loss: 0.0
2025-12-09 10:23:34.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 5759 LR: 0.0009999209415975036 Training loss: 0.0
2025-12-09 10:23:34.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 5760 LR: 0.0009999209136599412 Training loss: 0.0
2025-12-09 10:23:34.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 5761 LR: 0.0009999208857174435 Training loss: 0.0
2025-12-09 10:23:34.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 5762 LR: 0.000999920857770011 Training loss: 0.0
2025-12-09 10:23:34.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 5763 LR: 0.0009999208298176435 Training loss: 0.0
2025-12-09 10:23:34.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 5764 LR: 0.0009999208018603408 Training loss: 0.0
2025-12-09 10:23:34.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 5765 LR: 0.0009999207738981032 Training loss: 0.0
2025-12-09 10:23:34.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 5766 LR: 0.0009999207459309306 Training loss: 0.0
2025-12-09 10:23:34.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 5767 LR: 0.000999920717958823 Training loss: 0.0
2025-12-09 10:23:34.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 5768 LR: 0.0009999206899817803 Training loss: 0.0
2025-12-09 10:23:34.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 5769 LR: 0.0009999206619998027 Training loss: 0.0
2025-12-09 10:23:34.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 5770 LR: 0.0009999206340128902 Training loss: 0.0
2025-12-09 10:23:34.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 5771 LR: 0.0009999206060210424 Training loss: 0.0
2025-12-09 10:23:34.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 5772 LR: 0.0009999205780242598 Training loss: 0.0
2025-12-09 10:23:34.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 5773 LR: 0.0009999205500225421 Training loss: 0.0
2025-12-09 10:23:34.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 5774 LR: 0.0009999205220158896 Training loss: 0.0
2025-12-09 10:23:34.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 5775 LR: 0.000999920494004302 Training loss: 0.0
2025-12-09 10:23:34.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 5776 LR: 0.0009999204659877792 Training loss: 0.0
2025-12-09 10:23:34.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 5777 LR: 0.0009999204379663215 Training loss: 0.0
2025-12-09 10:23:34.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 5778 LR: 0.0009999204099399289 Training loss: 0.0
2025-12-09 10:23:34.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 5779 LR: 0.0009999203819086012 Training loss: 0.0
2025-12-09 10:23:34.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 5780 LR: 0.0009999203538723384 Training loss: 0.0
2025-12-09 10:23:34.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 5781 LR: 0.0009999203258311408 Training loss: 0.0
2025-12-09 10:23:34.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 5782 LR: 0.000999920297785008 Training loss: 0.0
2025-12-09 10:23:34.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 5783 LR: 0.0009999202697339403 Training loss: 0.0
2025-12-09 10:23:34.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 5784 LR: 0.0009999202416779377 Training loss: 0.0
2025-12-09 10:23:34.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 5785 LR: 0.000999920213617 Training loss: 0.0
2025-12-09 10:23:34.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 5786 LR: 0.0009999201855511273 Training loss: 0.0
2025-12-09 10:23:34.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 5787 LR: 0.0009999201574803196 Training loss: 0.0
2025-12-09 10:23:34.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 5788 LR: 0.000999920129404577 Training loss: 0.0
2025-12-09 10:23:34.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 5789 LR: 0.0009999201013238992 Training loss: 0.0
2025-12-09 10:23:34.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 5790 LR: 0.0009999200732382866 Training loss: 0.0
2025-12-09 10:23:34.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 5791 LR: 0.000999920045147739 Training loss: 0.0
2025-12-09 10:23:34.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 5792 LR: 0.000999920017052256 Training loss: 0.0
2025-12-09 10:23:34.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 5793 LR: 0.0009999199889518385 Training loss: 0.0
2025-12-09 10:23:34.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 5794 LR: 0.0009999199608464856 Training loss: 0.0
2025-12-09 10:23:34.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 5795 LR: 0.000999919932736198 Training loss: 0.0
2025-12-09 10:23:34.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 5796 LR: 0.0009999199046209753 Training loss: 0.0
2025-12-09 10:23:34.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 5797 LR: 0.0009999198765008176 Training loss: 0.0
2025-12-09 10:23:34.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 5798 LR: 0.0009999198483757249 Training loss: 0.0
2025-12-09 10:23:34.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 5799 LR: 0.0009999198202456973 Training loss: 0.0
2025-12-09 10:23:34.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 5800 LR: 0.0009999197921107344 Training loss: 0.0
2025-12-09 10:23:34.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 5801 LR: 0.0009999197639708368 Training loss: 0.0
2025-12-09 10:23:34.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 5802 LR: 0.0009999197358260042 Training loss: 0.0
2025-12-09 10:23:34.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 5803 LR: 0.0009999197076762363 Training loss: 0.0
2025-12-09 10:23:34.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 5804 LR: 0.0009999196795215338 Training loss: 0.0
2025-12-09 10:23:34.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 5805 LR: 0.000999919651361896 Training loss: 0.0
2025-12-09 10:23:34.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 5806 LR: 0.0009999196231973233 Training loss: 0.0
2025-12-09 10:23:34.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 5807 LR: 0.0009999195950278158 Training loss: 0.0
2025-12-09 10:23:34.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 5808 LR: 0.000999919566853373 Training loss: 0.0
2025-12-09 10:23:34.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 5809 LR: 0.0009999195386739955 Training loss: 0.0
2025-12-09 10:23:34.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 5810 LR: 0.0009999195104896828 Training loss: 0.0
2025-12-09 10:23:34.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 5811 LR: 0.000999919482300435 Training loss: 0.0
2025-12-09 10:23:34.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 5812 LR: 0.0009999194541062523 Training loss: 0.0
2025-12-09 10:23:34.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 5813 LR: 0.0009999194259071348 Training loss: 0.0
2025-12-09 10:23:34.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 5814 LR: 0.0009999193977030822 Training loss: 0.0
2025-12-09 10:23:34.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 5815 LR: 0.0009999193694940945 Training loss: 0.0
2025-12-09 10:23:34.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 5816 LR: 0.000999919341280172 Training loss: 0.0
2025-12-09 10:23:34.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 5817 LR: 0.0009999193130613142 Training loss: 0.0
2025-12-09 10:23:34.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 5818 LR: 0.0009999192848375218 Training loss: 0.0
2025-12-09 10:23:34.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 5819 LR: 0.000999919256608794 Training loss: 0.0
2025-12-09 10:23:34.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 5820 LR: 0.0009999192283751315 Training loss: 0.0
2025-12-09 10:23:34.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 5821 LR: 0.000999919200136534 Training loss: 0.0
2025-12-09 10:23:34.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 5822 LR: 0.0009999191718930015 Training loss: 0.0
2025-12-09 10:23:34.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 5823 LR: 0.000999919143644534 Training loss: 0.0
2025-12-09 10:23:34.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 5824 LR: 0.0009999191153911313 Training loss: 0.0
2025-12-09 10:23:34.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 5825 LR: 0.0009999190871327938 Training loss: 0.0
2025-12-09 10:23:34.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 5826 LR: 0.000999919058869521 Training loss: 0.0
2025-12-09 10:23:34.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 5827 LR: 0.0009999190306013135 Training loss: 0.0
2025-12-09 10:23:34.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 5828 LR: 0.000999919002328171 Training loss: 0.0
2025-12-09 10:23:34.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 5829 LR: 0.0009999189740500937 Training loss: 0.0
2025-12-09 10:23:34.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 5830 LR: 0.000999918945767081 Training loss: 0.0
2025-12-09 10:23:34.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 5831 LR: 0.0009999189174791337 Training loss: 0.0
2025-12-09 10:23:34.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 5832 LR: 0.0009999188891862511 Training loss: 0.0
2025-12-09 10:23:34.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 5833 LR: 0.0009999188608884337 Training loss: 0.0
2025-12-09 10:23:34.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 5834 LR: 0.0009999188325856812 Training loss: 0.0
2025-12-09 10:23:34.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 5835 LR: 0.0009999188042779938 Training loss: 0.0
2025-12-09 10:23:34.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 5836 LR: 0.0009999187759653714 Training loss: 0.0
2025-12-09 10:23:34.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 5837 LR: 0.000999918747647814 Training loss: 0.0
2025-12-09 10:23:34.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 5838 LR: 0.0009999187193253216 Training loss: 0.0
2025-12-09 10:23:34.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 5839 LR: 0.0009999186909978941 Training loss: 0.0
2025-12-09 10:23:34.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 5840 LR: 0.0009999186626655319 Training loss: 0.0
2025-12-09 10:23:35.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 5841 LR: 0.0009999186343282343 Training loss: 0.0
2025-12-09 10:23:35.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 5842 LR: 0.000999918605986002 Training loss: 0.0
2025-12-09 10:23:35.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 5843 LR: 0.0009999185776388346 Training loss: 0.0
2025-12-09 10:23:35.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 5844 LR: 0.0009999185492867324 Training loss: 0.0
2025-12-09 10:23:35.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 5845 LR: 0.000999918520929695 Training loss: 0.0
2025-12-09 10:23:35.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 5846 LR: 0.0009999184925677228 Training loss: 0.0
2025-12-09 10:23:35.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 5847 LR: 0.0009999184642008154 Training loss: 0.0
2025-12-09 10:23:35.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 5848 LR: 0.0009999184358289732 Training loss: 0.0
2025-12-09 10:23:35.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 5849 LR: 0.000999918407452196 Training loss: 0.0
2025-12-09 10:23:35.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 5850 LR: 0.0009999183790704838 Training loss: 0.0
2025-12-09 10:23:35.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 5851 LR: 0.0009999183506838366 Training loss: 0.0
2025-12-09 10:23:35.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 5852 LR: 0.0009999183222922543 Training loss: 0.0
2025-12-09 10:23:35.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 5853 LR: 0.0009999182938957372 Training loss: 0.0
2025-12-09 10:23:35.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 5854 LR: 0.000999918265494285 Training loss: 0.0
2025-12-09 10:23:35.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 5855 LR: 0.000999918237087898 Training loss: 0.0
2025-12-09 10:23:35.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 5856 LR: 0.0009999182086765756 Training loss: 0.0
2025-12-09 10:23:35.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 5857 LR: 0.0009999181802603186 Training loss: 0.0
2025-12-09 10:23:35.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 5858 LR: 0.0009999181518391266 Training loss: 0.0
2025-12-09 10:23:35.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 5859 LR: 0.0009999181234129995 Training loss: 0.0
2025-12-09 10:23:35.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 5860 LR: 0.0009999180949819375 Training loss: 0.0
2025-12-09 10:23:35.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 5861 LR: 0.0009999180665459404 Training loss: 0.0
2025-12-09 10:23:35.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 5862 LR: 0.0009999180381050083 Training loss: 0.0
2025-12-09 10:23:35.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 5863 LR: 0.0009999180096591414 Training loss: 0.0
2025-12-09 10:23:35.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 5864 LR: 0.0009999179812083395 Training loss: 0.0
2025-12-09 10:23:35.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 5865 LR: 0.0009999179527526026 Training loss: 0.0
2025-12-09 10:23:35.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 5866 LR: 0.0009999179242919304 Training loss: 0.0
2025-12-09 10:23:35.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 5867 LR: 0.0009999178958263236 Training loss: 0.0
2025-12-09 10:23:35.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 5868 LR: 0.0009999178673557817 Training loss: 0.0
2025-12-09 10:23:35.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 5869 LR: 0.0009999178388803048 Training loss: 0.0
2025-12-09 10:23:35.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 5870 LR: 0.0009999178103998931 Training loss: 0.0
2025-12-09 10:23:35.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 5871 LR: 0.0009999177819145463 Training loss: 0.0
2025-12-09 10:23:35.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 5872 LR: 0.0009999177534242643 Training loss: 0.0
2025-12-09 10:23:35.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 5873 LR: 0.0009999177249290477 Training loss: 0.0
2025-12-09 10:23:35.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 5874 LR: 0.0009999176964288958 Training loss: 0.0
2025-12-09 10:23:35.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 5875 LR: 0.000999917667923809 Training loss: 0.0
2025-12-09 10:23:35.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 5876 LR: 0.0009999176394137874 Training loss: 0.0
2025-12-09 10:23:35.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 5877 LR: 0.0009999176108988308 Training loss: 0.0
2025-12-09 10:23:35.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 5878 LR: 0.000999917582378939 Training loss: 0.0
2025-12-09 10:23:35.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 5879 LR: 0.0009999175538541124 Training loss: 0.0
2025-12-09 10:23:35.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 5880 LR: 0.0009999175253243508 Training loss: 0.0
2025-12-09 10:23:35.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 5881 LR: 0.0009999174967896542 Training loss: 0.0
2025-12-09 10:23:35.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 5882 LR: 0.0009999174682500226 Training loss: 0.0
2025-12-09 10:23:35.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 5883 LR: 0.0009999174397054562 Training loss: 0.0
2025-12-09 10:23:35.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 5884 LR: 0.0009999174111559547 Training loss: 0.0
2025-12-09 10:23:35.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 5885 LR: 0.0009999173826015183 Training loss: 0.0
2025-12-09 10:23:35.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 5886 LR: 0.0009999173540421466 Training loss: 0.0
2025-12-09 10:23:35.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 5887 LR: 0.0009999173254778401 Training loss: 0.0
2025-12-09 10:23:35.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 5888 LR: 0.0009999172969085987 Training loss: 0.0
2025-12-09 10:23:35.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 5889 LR: 0.0009999172683344225 Training loss: 0.0
2025-12-09 10:23:35.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 5890 LR: 0.0009999172397553112 Training loss: 0.0
2025-12-09 10:23:35.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 5891 LR: 0.0009999172111712648 Training loss: 0.0
2025-12-09 10:23:35.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 5892 LR: 0.0009999171825822834 Training loss: 0.0
2025-12-09 10:23:35.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 5893 LR: 0.000999917153988367 Training loss: 0.0
2025-12-09 10:23:35.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 5894 LR: 0.000999917125389516 Training loss: 0.0
2025-12-09 10:23:35.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 5895 LR: 0.00099991709678573 Training loss: 0.0
2025-12-09 10:23:35.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 5896 LR: 0.0009999170681770086 Training loss: 0.0
2025-12-09 10:23:35.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 5897 LR: 0.0009999170395633525 Training loss: 0.0
2025-12-09 10:23:35.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 5898 LR: 0.0009999170109447613 Training loss: 0.0
2025-12-09 10:23:35.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 5899 LR: 0.0009999169823212352 Training loss: 0.0
2025-12-09 10:23:35.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 5900 LR: 0.000999916953692774 Training loss: 0.0
2025-12-09 10:23:35.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 5901 LR: 0.000999916925059378 Training loss: 0.0
2025-12-09 10:23:35.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 5902 LR: 0.0009999168964210472 Training loss: 0.0
2025-12-09 10:23:35.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 5903 LR: 0.000999916867777781 Training loss: 0.0
2025-12-09 10:23:35.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 5904 LR: 0.0009999168391295803 Training loss: 0.0
2025-12-09 10:23:35.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 5905 LR: 0.0009999168104764442 Training loss: 0.0
2025-12-09 10:23:35.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 5906 LR: 0.0009999167818183735 Training loss: 0.0
2025-12-09 10:23:35.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 5907 LR: 0.0009999167531553675 Training loss: 0.0
2025-12-09 10:23:35.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 5908 LR: 0.0009999167244874269 Training loss: 0.0
2025-12-09 10:23:35.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 5909 LR: 0.000999916695814551 Training loss: 0.0
2025-12-09 10:23:35.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 5910 LR: 0.0009999166671367402 Training loss: 0.0
2025-12-09 10:23:35.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 5911 LR: 0.0009999166384539945 Training loss: 0.0
2025-12-09 10:23:35.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 5912 LR: 0.0009999166097663138 Training loss: 0.0
2025-12-09 10:23:35.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 5913 LR: 0.0009999165810736983 Training loss: 0.0
2025-12-09 10:23:35.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 5914 LR: 0.0009999165523761476 Training loss: 0.0
2025-12-09 10:23:35.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 5915 LR: 0.000999916523673662 Training loss: 0.0
2025-12-09 10:23:35.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 5916 LR: 0.0009999164949662414 Training loss: 0.0
2025-12-09 10:23:35.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 5917 LR: 0.000999916466253886 Training loss: 0.0
2025-12-09 10:23:35.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 5918 LR: 0.0009999164375365955 Training loss: 0.0
2025-12-09 10:23:35.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 5919 LR: 0.0009999164088143702 Training loss: 0.0
2025-12-09 10:23:35.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 5920 LR: 0.0009999163800872095 Training loss: 0.0
2025-12-09 10:23:35.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 5921 LR: 0.0009999163513551143 Training loss: 0.0
2025-12-09 10:23:35.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 5922 LR: 0.000999916322618084 Training loss: 0.0
2025-12-09 10:23:35.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 5923 LR: 0.0009999162938761185 Training loss: 0.0
2025-12-09 10:23:35.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 5924 LR: 0.0009999162651292185 Training loss: 0.0
2025-12-09 10:23:35.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 5925 LR: 0.0009999162363773834 Training loss: 0.0
2025-12-09 10:23:35.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 5926 LR: 0.000999916207620613 Training loss: 0.0
2025-12-09 10:23:35.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 5927 LR: 0.000999916178858908 Training loss: 0.0
2025-12-09 10:23:35.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 5928 LR: 0.0009999161500922678 Training loss: 0.0
2025-12-09 10:23:35.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 5929 LR: 0.0009999161213206926 Training loss: 0.0
2025-12-09 10:23:35.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 5930 LR: 0.0009999160925441826 Training loss: 0.0
2025-12-09 10:23:35.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 5931 LR: 0.0009999160637627377 Training loss: 0.0
2025-12-09 10:23:35.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 5932 LR: 0.0009999160349763577 Training loss: 0.0
2025-12-09 10:23:35.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 5933 LR: 0.000999916006185043 Training loss: 0.0
2025-12-09 10:23:35.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 5934 LR: 0.0009999159773887928 Training loss: 0.0
2025-12-09 10:23:35.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 5935 LR: 0.000999915948587608 Training loss: 0.0
2025-12-09 10:23:35.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 5936 LR: 0.0009999159197814885 Training loss: 0.0
2025-12-09 10:23:35.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 5937 LR: 0.0009999158909704336 Training loss: 0.0
2025-12-09 10:23:35.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 5938 LR: 0.000999915862154444 Training loss: 0.0
2025-12-09 10:23:35.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 5939 LR: 0.0009999158333335193 Training loss: 0.0
2025-12-09 10:23:35.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 5940 LR: 0.0009999158045076596 Training loss: 0.0
2025-12-09 10:23:35.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 5941 LR: 0.000999915775676865 Training loss: 0.0
2025-12-09 10:23:35.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 5942 LR: 0.0009999157468411355 Training loss: 0.0
2025-12-09 10:23:35.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 5943 LR: 0.000999915718000471 Training loss: 0.0
2025-12-09 10:23:35.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 5944 LR: 0.0009999156891548715 Training loss: 0.0
2025-12-09 10:23:35.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 5945 LR: 0.0009999156603043371 Training loss: 0.0
2025-12-09 10:23:35.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 5946 LR: 0.0009999156314488677 Training loss: 0.0
2025-12-09 10:23:35.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 5947 LR: 0.0009999156025884634 Training loss: 0.0
2025-12-09 10:23:35.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 5948 LR: 0.0009999155737231242 Training loss: 0.0
2025-12-09 10:23:35.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 5949 LR: 0.00099991554485285 Training loss: 0.0
2025-12-09 10:23:35.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 5950 LR: 0.0009999155159776407 Training loss: 0.0
2025-12-09 10:23:35.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 5951 LR: 0.0009999154870974968 Training loss: 0.0
2025-12-09 10:23:35.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 5952 LR: 0.0009999154582124175 Training loss: 0.0
2025-12-09 10:23:35.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 5953 LR: 0.0009999154293224035 Training loss: 0.0
2025-12-09 10:23:35.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 5954 LR: 0.0009999154004274545 Training loss: 0.0
2025-12-09 10:23:35.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 5955 LR: 0.0009999153715275705 Training loss: 0.0
2025-12-09 10:23:35.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 5956 LR: 0.0009999153426227517 Training loss: 0.0
2025-12-09 10:23:35.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 5957 LR: 0.0009999153137129977 Training loss: 0.0
2025-12-09 10:23:35.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 5958 LR: 0.000999915284798309 Training loss: 0.0
2025-12-09 10:23:35.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 5959 LR: 0.000999915255878685 Training loss: 0.0
2025-12-09 10:23:35.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 5960 LR: 0.0009999152269541264 Training loss: 0.0
2025-12-09 10:23:35.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 5961 LR: 0.0009999151980246326 Training loss: 0.0
2025-12-09 10:23:35.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 5962 LR: 0.000999915169090204 Training loss: 0.0
2025-12-09 10:23:35.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 5963 LR: 0.0009999151401508405 Training loss: 0.0
2025-12-09 10:23:35.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 5964 LR: 0.000999915111206542 Training loss: 0.0
2025-12-09 10:23:35.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 5965 LR: 0.0009999150822573085 Training loss: 0.0
2025-12-09 10:23:35.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 5966 LR: 0.00099991505330314 Training loss: 0.0
2025-12-09 10:23:35.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 5967 LR: 0.0009999150243440366 Training loss: 0.0
2025-12-09 10:23:35.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 5968 LR: 0.0009999149953799982 Training loss: 0.0
2025-12-09 10:23:35.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 5969 LR: 0.000999914966411025 Training loss: 0.0
2025-12-09 10:23:35.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 5970 LR: 0.0009999149374371166 Training loss: 0.0
2025-12-09 10:23:35.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 5971 LR: 0.0009999149084582734 Training loss: 0.0
2025-12-09 10:23:35.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 5972 LR: 0.0009999148794744954 Training loss: 0.0
2025-12-09 10:23:35.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 5973 LR: 0.0009999148504857822 Training loss: 0.0
2025-12-09 10:23:35.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 5974 LR: 0.0009999148214921343 Training loss: 0.0
2025-12-09 10:23:35.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 5975 LR: 0.0009999147924935512 Training loss: 0.0
2025-12-09 10:23:35.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 5976 LR: 0.0009999147634900333 Training loss: 0.0
2025-12-09 10:23:35.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 5977 LR: 0.0009999147344815803 Training loss: 0.0
2025-12-09 10:23:35.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 5978 LR: 0.0009999147054681925 Training loss: 0.0
2025-12-09 10:23:35.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 5979 LR: 0.0009999146764498698 Training loss: 0.0
2025-12-09 10:23:35.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 5980 LR: 0.000999914647426612 Training loss: 0.0
2025-12-09 10:23:35.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 5981 LR: 0.0009999146183984192 Training loss: 0.0
2025-12-09 10:23:35.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 5982 LR: 0.0009999145893652918 Training loss: 0.0
2025-12-09 10:23:35.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 5983 LR: 0.0009999145603272292 Training loss: 0.0
2025-12-09 10:23:35.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 5984 LR: 0.0009999145312842316 Training loss: 0.0
2025-12-09 10:23:35.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 5985 LR: 0.0009999145022362992 Training loss: 0.0
2025-12-09 10:23:35.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 5986 LR: 0.0009999144731834319 Training loss: 0.0
2025-12-09 10:23:35.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 5987 LR: 0.0009999144441256295 Training loss: 0.0
2025-12-09 10:23:35.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 5988 LR: 0.0009999144150628922 Training loss: 0.0
2025-12-09 10:23:35.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 5989 LR: 0.00099991438599522 Training loss: 0.0
2025-12-09 10:23:35.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 5990 LR: 0.0009999143569226127 Training loss: 0.0
2025-12-09 10:23:35.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 5991 LR: 0.0009999143278450707 Training loss: 0.0
2025-12-09 10:23:35.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 5992 LR: 0.0009999142987625936 Training loss: 0.0
2025-12-09 10:23:35.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 5993 LR: 0.0009999142696751815 Training loss: 0.0
2025-12-09 10:23:35.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 5994 LR: 0.0009999142405828347 Training loss: 0.0
2025-12-09 10:23:35.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 5995 LR: 0.0009999142114855528 Training loss: 0.0
2025-12-09 10:23:35.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 5996 LR: 0.0009999141823833358 Training loss: 0.0
2025-12-09 10:23:35.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 5997 LR: 0.0009999141532761842 Training loss: 0.0
2025-12-09 10:23:35.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 5998 LR: 0.0009999141241640974 Training loss: 0.0
2025-12-09 10:23:35.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 5999 LR: 0.0009999140950470759 Training loss: 0.0
2025-12-09 10:23:35.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 6000 LR: 0.000999914065925119 Training loss: 0.0
2025-12-09 10:23:35.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 6001 LR: 0.0009999140367982276 Training loss: 0.0
2025-12-09 10:23:35.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 6002 LR: 0.0009999140076664011 Training loss: 0.0
2025-12-09 10:23:35.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 6003 LR: 0.0009999139785296395 Training loss: 0.0
2025-12-09 10:23:35.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 6004 LR: 0.0009999139493879433 Training loss: 0.0
2025-12-09 10:23:35.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 6005 LR: 0.0009999139202413118 Training loss: 0.0
2025-12-09 10:23:35.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 6006 LR: 0.0009999138910897457 Training loss: 0.0
2025-12-09 10:23:35.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 6007 LR: 0.0009999138619332445 Training loss: 0.0
2025-12-09 10:23:35.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 6008 LR: 0.0009999138327718084 Training loss: 0.0
2025-12-09 10:23:35.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 6009 LR: 0.0009999138036054375 Training loss: 0.0
2025-12-09 10:23:35.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 6010 LR: 0.0009999137744341313 Training loss: 0.0
2025-12-09 10:23:35.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 6011 LR: 0.0009999137452578904 Training loss: 0.0
2025-12-09 10:23:35.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 6012 LR: 0.0009999137160767145 Training loss: 0.0
2025-12-09 10:23:35.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 6013 LR: 0.0009999136868906037 Training loss: 0.0
2025-12-09 10:23:35.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 6014 LR: 0.000999913657699558 Training loss: 0.0
2025-12-09 10:23:35.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 6015 LR: 0.0009999136285035772 Training loss: 0.0
2025-12-09 10:23:35.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 6016 LR: 0.0009999135993026616 Training loss: 0.0
2025-12-09 10:23:35.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 6017 LR: 0.000999913570096811 Training loss: 0.0
2025-12-09 10:23:35.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 6018 LR: 0.0009999135408860257 Training loss: 0.0
2025-12-09 10:23:35.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 6019 LR: 0.0009999135116703051 Training loss: 0.0
2025-12-09 10:23:35.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 6020 LR: 0.0009999134824496497 Training loss: 0.0
2025-12-09 10:23:35.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 6021 LR: 0.0009999134532240595 Training loss: 0.0
2025-12-09 10:23:35.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 6022 LR: 0.0009999134239935341 Training loss: 0.0
2025-12-09 10:23:35.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 6023 LR: 0.0009999133947580742 Training loss: 0.0
2025-12-09 10:23:35.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 6024 LR: 0.000999913365517679 Training loss: 0.0
2025-12-09 10:23:35.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 6025 LR: 0.000999913336272349 Training loss: 0.0
2025-12-09 10:23:35.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 6026 LR: 0.0009999133070220838 Training loss: 0.0
2025-12-09 10:23:35.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 6027 LR: 0.000999913277766884 Training loss: 0.0
2025-12-09 10:23:35.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 6028 LR: 0.000999913248506749 Training loss: 0.0
2025-12-09 10:23:35.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 6029 LR: 0.0009999132192416793 Training loss: 0.0
2025-12-09 10:23:35.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 6030 LR: 0.0009999131899716747 Training loss: 0.0
2025-12-09 10:23:35.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 6031 LR: 0.000999913160696735 Training loss: 0.0
2025-12-09 10:23:35.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 6032 LR: 0.0009999131314168603 Training loss: 0.0
2025-12-09 10:23:35.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 6033 LR: 0.000999913102132051 Training loss: 0.0
2025-12-09 10:23:35.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 6034 LR: 0.0009999130728423065 Training loss: 0.0
2025-12-09 10:23:35.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 6035 LR: 0.0009999130435476272 Training loss: 0.0
2025-12-09 10:23:35.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 6036 LR: 0.0009999130142480128 Training loss: 0.0
2025-12-09 10:23:35.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 6037 LR: 0.0009999129849434635 Training loss: 0.0
2025-12-09 10:23:35.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 6038 LR: 0.0009999129556339794 Training loss: 0.0
2025-12-09 10:23:35.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 6039 LR: 0.0009999129263195603 Training loss: 0.0
2025-12-09 10:23:35.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 6040 LR: 0.0009999128970002063 Training loss: 0.0
2025-12-09 10:23:35.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 6041 LR: 0.0009999128676759172 Training loss: 0.0
2025-12-09 10:23:35.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 6042 LR: 0.0009999128383466934 Training loss: 0.0
2025-12-09 10:23:35.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 6043 LR: 0.0009999128090125346 Training loss: 0.0
2025-12-09 10:23:35.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 6044 LR: 0.0009999127796734408 Training loss: 0.0
2025-12-09 10:23:35.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 6045 LR: 0.0009999127503294123 Training loss: 0.0
2025-12-09 10:23:35.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 6046 LR: 0.0009999127209804487 Training loss: 0.0
2025-12-09 10:23:35.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 6047 LR: 0.0009999126916265502 Training loss: 0.0
2025-12-09 10:23:35.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 6048 LR: 0.0009999126622677165 Training loss: 0.0
2025-12-09 10:23:35.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 6049 LR: 0.0009999126329039484 Training loss: 0.0
2025-12-09 10:23:35.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 6050 LR: 0.0009999126035352452 Training loss: 0.0
2025-12-09 10:23:35.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 6051 LR: 0.0009999125741616067 Training loss: 0.0
2025-12-09 10:23:35.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 6052 LR: 0.0009999125447830335 Training loss: 0.0
2025-12-09 10:23:35.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 6053 LR: 0.0009999125153995255 Training loss: 0.0
2025-12-09 10:23:35.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 6054 LR: 0.0009999124860110824 Training loss: 0.0
2025-12-09 10:23:35.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 6055 LR: 0.0009999124566177045 Training loss: 0.0
2025-12-09 10:23:35.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 6056 LR: 0.0009999124272193917 Training loss: 0.0
2025-12-09 10:23:35.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 6057 LR: 0.000999912397816144 Training loss: 0.0
2025-12-09 10:23:35.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 6058 LR: 0.0009999123684079612 Training loss: 0.0
2025-12-09 10:23:35.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 6059 LR: 0.0009999123389948436 Training loss: 0.0
2025-12-09 10:23:35.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 6060 LR: 0.000999912309576791 Training loss: 0.0
2025-12-09 10:23:35.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 6061 LR: 0.0009999122801538035 Training loss: 0.0
2025-12-09 10:23:35.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 6062 LR: 0.0009999122507258812 Training loss: 0.0
2025-12-09 10:23:35.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 6063 LR: 0.0009999122212930238 Training loss: 0.0
2025-12-09 10:23:35.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 6064 LR: 0.0009999121918552317 Training loss: 0.0
2025-12-09 10:23:35.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 6065 LR: 0.0009999121624125044 Training loss: 0.0
2025-12-09 10:23:35.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 6066 LR: 0.0009999121329648422 Training loss: 0.0
2025-12-09 10:23:35.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 6067 LR: 0.0009999121035122454 Training loss: 0.0
2025-12-09 10:23:35.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 6068 LR: 0.0009999120740547135 Training loss: 0.0
2025-12-09 10:23:35.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 6069 LR: 0.0009999120445922465 Training loss: 0.0
2025-12-09 10:23:35.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 6070 LR: 0.0009999120151248447 Training loss: 0.0
2025-12-09 10:23:35.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 6071 LR: 0.000999911985652508 Training loss: 0.0
2025-12-09 10:23:35.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 6072 LR: 0.0009999119561752362 Training loss: 0.0
2025-12-09 10:23:35.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 6073 LR: 0.0009999119266930299 Training loss: 0.0
2025-12-09 10:23:35.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 6074 LR: 0.0009999118972058884 Training loss: 0.0
2025-12-09 10:23:35.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 6075 LR: 0.0009999118677138119 Training loss: 0.0
2025-12-09 10:23:35.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 6076 LR: 0.0009999118382168007 Training loss: 0.0
2025-12-09 10:23:35.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 6077 LR: 0.0009999118087148544 Training loss: 0.0
2025-12-09 10:23:35.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 6078 LR: 0.0009999117792079733 Training loss: 0.0
2025-12-09 10:23:35.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 6079 LR: 0.0009999117496961572 Training loss: 0.0
2025-12-09 10:23:35.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 6080 LR: 0.0009999117201794064 Training loss: 0.0
2025-12-09 10:23:35.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 6081 LR: 0.0009999116906577203 Training loss: 0.0
2025-12-09 10:23:35.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 6082 LR: 0.0009999116611310998 Training loss: 0.0
2025-12-09 10:23:35.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 6083 LR: 0.0009999116315995437 Training loss: 0.0
2025-12-09 10:23:35.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 6084 LR: 0.0009999116020630533 Training loss: 0.0
2025-12-09 10:23:35.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 6085 LR: 0.0009999115725216276 Training loss: 0.0
2025-12-09 10:23:35.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 6086 LR: 0.0009999115429752672 Training loss: 0.0
2025-12-09 10:23:35.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 6087 LR: 0.0009999115134239718 Training loss: 0.0
2025-12-09 10:23:35.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 6088 LR: 0.0009999114838677415 Training loss: 0.0
2025-12-09 10:23:35.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 6089 LR: 0.0009999114543065763 Training loss: 0.0
2025-12-09 10:23:35.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 6090 LR: 0.0009999114247404761 Training loss: 0.0
2025-12-09 10:23:35.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 6091 LR: 0.000999911395169441 Training loss: 0.0
2025-12-09 10:23:35.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 6092 LR: 0.000999911365593471 Training loss: 0.0
2025-12-09 10:23:35.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 6093 LR: 0.0009999113360125663 Training loss: 0.0
2025-12-09 10:23:35.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 6094 LR: 0.0009999113064267265 Training loss: 0.0
2025-12-09 10:23:35.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 6095 LR: 0.0009999112768359518 Training loss: 0.0
2025-12-09 10:23:35.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 6096 LR: 0.000999911247240242 Training loss: 0.0
2025-12-09 10:23:35.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 6097 LR: 0.0009999112176395976 Training loss: 0.0
2025-12-09 10:23:35.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 6098 LR: 0.000999911188034018 Training loss: 0.0
2025-12-09 10:23:35.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 6099 LR: 0.0009999111584235037 Training loss: 0.0
2025-12-09 10:23:35.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 6100 LR: 0.0009999111288080545 Training loss: 0.0
2025-12-09 10:23:35.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 6101 LR: 0.0009999110991876703 Training loss: 0.0
2025-12-09 10:23:35.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 6102 LR: 0.0009999110695623511 Training loss: 0.0
2025-12-09 10:23:35.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 6103 LR: 0.0009999110399320972 Training loss: 0.0
2025-12-09 10:23:35.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 6104 LR: 0.0009999110102969083 Training loss: 0.0
2025-12-09 10:23:35.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 6105 LR: 0.0009999109806567844 Training loss: 0.0
2025-12-09 10:23:35.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 6106 LR: 0.0009999109510117257 Training loss: 0.0
2025-12-09 10:23:35.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 6107 LR: 0.000999910921361732 Training loss: 0.0
2025-12-09 10:23:35.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 6108 LR: 0.0009999108917068034 Training loss: 0.0
2025-12-09 10:23:35.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 6109 LR: 0.00099991086204694 Training loss: 0.0
2025-12-09 10:23:35.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 6110 LR: 0.0009999108323821416 Training loss: 0.0
2025-12-09 10:23:35.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 6111 LR: 0.0009999108027124082 Training loss: 0.0
2025-12-09 10:23:35.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 6112 LR: 0.00099991077303774 Training loss: 0.0
2025-12-09 10:23:35.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 6113 LR: 0.0009999107433581369 Training loss: 0.0
2025-12-09 10:23:35.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 6114 LR: 0.000999910713673599 Training loss: 0.0
2025-12-09 10:23:35.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 6115 LR: 0.000999910683984126 Training loss: 0.0
2025-12-09 10:23:35.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 6116 LR: 0.0009999106542897182 Training loss: 0.0
2025-12-09 10:23:35.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 6117 LR: 0.0009999106245903754 Training loss: 0.0
2025-12-09 10:23:35.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 6118 LR: 0.0009999105948860978 Training loss: 0.0
2025-12-09 10:23:35.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 6119 LR: 0.0009999105651768852 Training loss: 0.0
2025-12-09 10:23:35.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 6120 LR: 0.0009999105354627379 Training loss: 0.0
2025-12-09 10:23:35.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 6121 LR: 0.0009999105057436554 Training loss: 0.0
2025-12-09 10:23:35.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 6122 LR: 0.000999910476019638 Training loss: 0.0
2025-12-09 10:23:35.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 6123 LR: 0.000999910446290686 Training loss: 0.0
2025-12-09 10:23:35.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 6124 LR: 0.000999910416556799 Training loss: 0.0
2025-12-09 10:23:35.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 6125 LR: 0.0009999103868179769 Training loss: 0.0
2025-12-09 10:23:35.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 6126 LR: 0.0009999103570742201 Training loss: 0.0
2025-12-09 10:23:35.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 6127 LR: 0.0009999103273255281 Training loss: 0.0
2025-12-09 10:23:35.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 6128 LR: 0.0009999102975719015 Training loss: 0.0
2025-12-09 10:23:35.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 6129 LR: 0.0009999102678133398 Training loss: 0.0
2025-12-09 10:23:35.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 6130 LR: 0.0009999102380498434 Training loss: 0.0
2025-12-09 10:23:35.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 6131 LR: 0.000999910208281412 Training loss: 0.0
2025-12-09 10:23:35.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 6132 LR: 0.0009999101785080457 Training loss: 0.0
2025-12-09 10:23:35.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 6133 LR: 0.0009999101487297444 Training loss: 0.0
2025-12-09 10:23:35.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 6134 LR: 0.0009999101189465084 Training loss: 0.0
2025-12-09 10:23:35.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 6135 LR: 0.0009999100891583373 Training loss: 0.0
2025-12-09 10:23:35.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 6136 LR: 0.0009999100593652314 Training loss: 0.0
2025-12-09 10:23:35.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 6137 LR: 0.0009999100295671906 Training loss: 0.0
2025-12-09 10:23:35.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 6138 LR: 0.0009999099997642148 Training loss: 0.0
2025-12-09 10:23:35.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 6139 LR: 0.000999909969956304 Training loss: 0.0
2025-12-09 10:23:35.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 6140 LR: 0.0009999099401434585 Training loss: 0.0
2025-12-09 10:23:35.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 6141 LR: 0.0009999099103256783 Training loss: 0.0
2025-12-09 10:23:35.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 6142 LR: 0.0009999098805029629 Training loss: 0.0
2025-12-09 10:23:35.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 6143 LR: 0.0009999098506753125 Training loss: 0.0
2025-12-09 10:23:35.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 6144 LR: 0.0009999098208427276 Training loss: 0.0
2025-12-09 10:23:35.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 6145 LR: 0.0009999097910052075 Training loss: 0.0
2025-12-09 10:23:35.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 6146 LR: 0.0009999097611627526 Training loss: 0.0
2025-12-09 10:23:35.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 6147 LR: 0.0009999097313153629 Training loss: 0.0
2025-12-09 10:23:35.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 6148 LR: 0.000999909701463038 Training loss: 0.0
2025-12-09 10:23:35.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 6149 LR: 0.0009999096716057786 Training loss: 0.0
2025-12-09 10:23:35.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 6150 LR: 0.0009999096417435838 Training loss: 0.0
2025-12-09 10:23:35.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 6151 LR: 0.0009999096118764547 Training loss: 0.0
2025-12-09 10:23:35.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 6152 LR: 0.0009999095820043902 Training loss: 0.0
2025-12-09 10:23:35.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 6153 LR: 0.000999909552127391 Training loss: 0.0
2025-12-09 10:23:35.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 6154 LR: 0.0009999095222454567 Training loss: 0.0
2025-12-09 10:23:35.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 6155 LR: 0.000999909492358588 Training loss: 0.0
2025-12-09 10:23:35.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 6156 LR: 0.0009999094624667838 Training loss: 0.0
2025-12-09 10:23:35.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 6157 LR: 0.000999909432570045 Training loss: 0.0
2025-12-09 10:23:35.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 6158 LR: 0.0009999094026683715 Training loss: 0.0
2025-12-09 10:23:35.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 6159 LR: 0.000999909372761763 Training loss: 0.0
2025-12-09 10:23:35.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 6160 LR: 0.0009999093428502196 Training loss: 0.0
2025-12-09 10:23:35.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 6161 LR: 0.0009999093129337412 Training loss: 0.0
2025-12-09 10:23:35.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 6162 LR: 0.0009999092830123278 Training loss: 0.0
2025-12-09 10:23:35.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 6163 LR: 0.0009999092530859797 Training loss: 0.0
2025-12-09 10:23:35.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 6164 LR: 0.0009999092231546965 Training loss: 0.0
2025-12-09 10:23:35.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 6165 LR: 0.0009999091932184785 Training loss: 0.0
2025-12-09 10:23:35.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 6166 LR: 0.000999909163277326 Training loss: 0.0
2025-12-09 10:23:35.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 6167 LR: 0.000999909133331238 Training loss: 0.0
2025-12-09 10:23:35.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 6168 LR: 0.0009999091033802154 Training loss: 0.0
2025-12-09 10:23:35.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 6169 LR: 0.000999909073424258 Training loss: 0.0
2025-12-09 10:23:35.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 6170 LR: 0.0009999090434633655 Training loss: 0.0
2025-12-09 10:23:35.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 6171 LR: 0.0009999090134975382 Training loss: 0.0
2025-12-09 10:23:35.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 6172 LR: 0.000999908983526776 Training loss: 0.0
2025-12-09 10:23:35.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 6173 LR: 0.000999908953551079 Training loss: 0.0
2025-12-09 10:23:35.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 6174 LR: 0.000999908923570447 Training loss: 0.0
2025-12-09 10:23:35.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 6175 LR: 0.0009999088935848802 Training loss: 0.0
2025-12-09 10:23:35.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 6176 LR: 0.0009999088635943782 Training loss: 0.0
2025-12-09 10:23:35.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 6177 LR: 0.0009999088335989417 Training loss: 0.0
2025-12-09 10:23:35.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 6178 LR: 0.0009999088035985702 Training loss: 0.0
2025-12-09 10:23:35.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 6179 LR: 0.0009999087735932638 Training loss: 0.0
2025-12-09 10:23:35.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 6180 LR: 0.0009999087435830225 Training loss: 0.0
2025-12-09 10:23:35.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 6181 LR: 0.0009999087135678462 Training loss: 0.0
2025-12-09 10:23:35.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 6182 LR: 0.0009999086835477352 Training loss: 0.0
2025-12-09 10:23:35.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 6183 LR: 0.0009999086535226892 Training loss: 0.0
2025-12-09 10:23:35.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 6184 LR: 0.0009999086234927083 Training loss: 0.0
2025-12-09 10:23:35.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 6185 LR: 0.0009999085934577925 Training loss: 0.0
2025-12-09 10:23:35.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 6186 LR: 0.000999908563417942 Training loss: 0.0
2025-12-09 10:23:35.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 6187 LR: 0.0009999085333731563 Training loss: 0.0
2025-12-09 10:23:35.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 6188 LR: 0.0009999085033234362 Training loss: 0.0
2025-12-09 10:23:35.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 6189 LR: 0.0009999084732687806 Training loss: 0.0
2025-12-09 10:23:35.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 6190 LR: 0.0009999084432091906 Training loss: 0.0
2025-12-09 10:23:35.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 6191 LR: 0.0009999084131446655 Training loss: 0.0
2025-12-09 10:23:35.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 6192 LR: 0.0009999083830752055 Training loss: 0.0
2025-12-09 10:23:35.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 6193 LR: 0.0009999083530008105 Training loss: 0.0
2025-12-09 10:23:35.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 6194 LR: 0.0009999083229214809 Training loss: 0.0
2025-12-09 10:23:35.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 6195 LR: 0.0009999082928372164 Training loss: 0.0
2025-12-09 10:23:35.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 6196 LR: 0.000999908262748017 Training loss: 0.0
2025-12-09 10:23:35.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 6197 LR: 0.0009999082326538824 Training loss: 0.0
2025-12-09 10:23:35.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 6198 LR: 0.0009999082025548133 Training loss: 0.0
2025-12-09 10:23:35.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 6199 LR: 0.0009999081724508091 Training loss: 0.0
2025-12-09 10:23:35.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 6200 LR: 0.0009999081423418702 Training loss: 0.0
2025-12-09 10:23:35.316 | INFO     | __main__:train:24 - Epoch: 0 Step: 6201 LR: 0.000999908112227996 Training loss: 0.0
2025-12-09 10:23:35.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 6202 LR: 0.0009999080821091874 Training loss: 0.0
2025-12-09 10:23:35.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 6203 LR: 0.0009999080519854438 Training loss: 0.0
2025-12-09 10:23:35.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 6204 LR: 0.0009999080218567652 Training loss: 0.0
2025-12-09 10:23:35.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 6205 LR: 0.0009999079917231517 Training loss: 0.0
2025-12-09 10:23:35.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 6206 LR: 0.0009999079615846034 Training loss: 0.0
2025-12-09 10:23:35.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 6207 LR: 0.0009999079314411202 Training loss: 0.0
2025-12-09 10:23:35.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 6208 LR: 0.0009999079012927021 Training loss: 0.0
2025-12-09 10:23:35.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 6209 LR: 0.0009999078711393492 Training loss: 0.0
2025-12-09 10:23:35.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 6210 LR: 0.0009999078409810614 Training loss: 0.0
2025-12-09 10:23:35.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 6211 LR: 0.0009999078108178386 Training loss: 0.0
2025-12-09 10:23:35.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 6212 LR: 0.000999907780649681 Training loss: 0.0
2025-12-09 10:23:35.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 6213 LR: 0.0009999077504765886 Training loss: 0.0
2025-12-09 10:23:35.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 6214 LR: 0.0009999077202985612 Training loss: 0.0
2025-12-09 10:23:35.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 6215 LR: 0.000999907690115599 Training loss: 0.0
2025-12-09 10:23:35.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 6216 LR: 0.0009999076599277019 Training loss: 0.0
2025-12-09 10:23:35.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 6217 LR: 0.00099990762973487 Training loss: 0.0
2025-12-09 10:23:35.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 6218 LR: 0.0009999075995371029 Training loss: 0.0
2025-12-09 10:23:35.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 6219 LR: 0.0009999075693344012 Training loss: 0.0
2025-12-09 10:23:35.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 6220 LR: 0.0009999075391267647 Training loss: 0.0
2025-12-09 10:23:35.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 6221 LR: 0.000999907508914193 Training loss: 0.0
2025-12-09 10:23:35.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 6222 LR: 0.0009999074786966869 Training loss: 0.0
2025-12-09 10:23:35.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 6223 LR: 0.0009999074484742456 Training loss: 0.0
2025-12-09 10:23:35.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 6224 LR: 0.0009999074182468694 Training loss: 0.0
2025-12-09 10:23:35.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 6225 LR: 0.0009999073880145586 Training loss: 0.0
2025-12-09 10:23:35.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 6226 LR: 0.0009999073577773125 Training loss: 0.0
2025-12-09 10:23:35.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 6227 LR: 0.0009999073275351318 Training loss: 0.0
2025-12-09 10:23:35.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 6228 LR: 0.0009999072972880162 Training loss: 0.0
2025-12-09 10:23:35.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 6229 LR: 0.0009999072670359658 Training loss: 0.0
2025-12-09 10:23:35.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 6230 LR: 0.0009999072367789803 Training loss: 0.0
2025-12-09 10:23:35.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 6231 LR: 0.0009999072065170601 Training loss: 0.0
2025-12-09 10:23:35.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 6232 LR: 0.000999907176250205 Training loss: 0.0
2025-12-09 10:23:35.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 6233 LR: 0.000999907145978415 Training loss: 0.0
2025-12-09 10:23:35.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 6234 LR: 0.0009999071157016902 Training loss: 0.0
2025-12-09 10:23:35.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 6235 LR: 0.0009999070854200306 Training loss: 0.0
2025-12-09 10:23:35.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 6236 LR: 0.0009999070551334358 Training loss: 0.0
2025-12-09 10:23:35.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 6237 LR: 0.0009999070248419065 Training loss: 0.0
2025-12-09 10:23:35.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 6238 LR: 0.000999906994545442 Training loss: 0.0
2025-12-09 10:23:35.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 6239 LR: 0.0009999069642440427 Training loss: 0.0
2025-12-09 10:23:35.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 6240 LR: 0.0009999069339377087 Training loss: 0.0
2025-12-09 10:23:35.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 6241 LR: 0.0009999069036264396 Training loss: 0.0
2025-12-09 10:23:35.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 6242 LR: 0.0009999068733102358 Training loss: 0.0
2025-12-09 10:23:35.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 6243 LR: 0.0009999068429890972 Training loss: 0.0
2025-12-09 10:23:35.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 6244 LR: 0.0009999068126630237 Training loss: 0.0
2025-12-09 10:23:35.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 6245 LR: 0.0009999067823320152 Training loss: 0.0
2025-12-09 10:23:35.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 6246 LR: 0.0009999067519960718 Training loss: 0.0
2025-12-09 10:23:35.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 6247 LR: 0.0009999067216551938 Training loss: 0.0
2025-12-09 10:23:35.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 6248 LR: 0.0009999066913093807 Training loss: 0.0
2025-12-09 10:23:35.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 6249 LR: 0.0009999066609586327 Training loss: 0.0
2025-12-09 10:23:35.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 6250 LR: 0.00099990663060295 Training loss: 0.0
2025-12-09 10:23:35.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 6251 LR: 0.0009999066002423322 Training loss: 0.0
2025-12-09 10:23:35.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 6252 LR: 0.0009999065698767797 Training loss: 0.0
2025-12-09 10:23:35.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 6253 LR: 0.0009999065395062923 Training loss: 0.0
2025-12-09 10:23:35.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 6254 LR: 0.0009999065091308701 Training loss: 0.0
2025-12-09 10:23:35.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 6255 LR: 0.000999906478750513 Training loss: 0.0
2025-12-09 10:23:35.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 6256 LR: 0.000999906448365221 Training loss: 0.0
2025-12-09 10:23:35.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 6257 LR: 0.000999906417974994 Training loss: 0.0
2025-12-09 10:23:35.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 6258 LR: 0.0009999063875798324 Training loss: 0.0
2025-12-09 10:23:35.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 6259 LR: 0.000999906357179736 Training loss: 0.0
2025-12-09 10:23:35.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 6260 LR: 0.0009999063267747044 Training loss: 0.0
2025-12-09 10:23:35.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 6261 LR: 0.0009999062963647381 Training loss: 0.0
2025-12-09 10:23:35.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 6262 LR: 0.000999906265949837 Training loss: 0.0
2025-12-09 10:23:35.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 6263 LR: 0.000999906235530001 Training loss: 0.0
2025-12-09 10:23:35.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 6264 LR: 0.00099990620510523 Training loss: 0.0
2025-12-09 10:23:35.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 6265 LR: 0.0009999061746755243 Training loss: 0.0
2025-12-09 10:23:35.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 6266 LR: 0.0009999061442408836 Training loss: 0.0
2025-12-09 10:23:35.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 6267 LR: 0.000999906113801308 Training loss: 0.0
2025-12-09 10:23:35.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 6268 LR: 0.0009999060833567979 Training loss: 0.0
2025-12-09 10:23:35.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 6269 LR: 0.0009999060529073524 Training loss: 0.0
2025-12-09 10:23:35.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 6270 LR: 0.0009999060224529725 Training loss: 0.0
2025-12-09 10:23:35.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 6271 LR: 0.0009999059919936575 Training loss: 0.0
2025-12-09 10:23:35.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 6272 LR: 0.0009999059615294077 Training loss: 0.0
2025-12-09 10:23:35.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 6273 LR: 0.000999905931060223 Training loss: 0.0
2025-12-09 10:23:35.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 6274 LR: 0.0009999059005861035 Training loss: 0.0
2025-12-09 10:23:35.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 6275 LR: 0.000999905870107049 Training loss: 0.0
2025-12-09 10:23:35.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 6276 LR: 0.0009999058396230598 Training loss: 0.0
2025-12-09 10:23:35.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 6277 LR: 0.0009999058091341357 Training loss: 0.0
2025-12-09 10:23:35.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 6278 LR: 0.000999905778640277 Training loss: 0.0
2025-12-09 10:23:35.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 6279 LR: 0.000999905748141483 Training loss: 0.0
2025-12-09 10:23:35.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 6280 LR: 0.0009999057176377545 Training loss: 0.0
2025-12-09 10:23:35.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 6281 LR: 0.0009999056871290908 Training loss: 0.0
2025-12-09 10:23:35.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 6282 LR: 0.0009999056566154924 Training loss: 0.0
2025-12-09 10:23:35.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 6283 LR: 0.0009999056260969592 Training loss: 0.0
2025-12-09 10:23:35.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 6284 LR: 0.000999905595573491 Training loss: 0.0
2025-12-09 10:23:35.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 6285 LR: 0.0009999055650450881 Training loss: 0.0
2025-12-09 10:23:35.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 6286 LR: 0.0009999055345117503 Training loss: 0.0
2025-12-09 10:23:35.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 6287 LR: 0.0009999055039734775 Training loss: 0.0
2025-12-09 10:23:35.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 6288 LR: 0.00099990547343027 Training loss: 0.0
2025-12-09 10:23:35.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 6289 LR: 0.0009999054428821276 Training loss: 0.0
2025-12-09 10:23:35.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 6290 LR: 0.0009999054123290504 Training loss: 0.0
2025-12-09 10:23:35.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 6291 LR: 0.0009999053817710381 Training loss: 0.0
2025-12-09 10:23:35.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 6292 LR: 0.0009999053512080914 Training loss: 0.0
2025-12-09 10:23:35.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 6293 LR: 0.0009999053206402096 Training loss: 0.0
2025-12-09 10:23:35.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 6294 LR: 0.0009999052900673928 Training loss: 0.0
2025-12-09 10:23:35.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 6295 LR: 0.0009999052594896413 Training loss: 0.0
2025-12-09 10:23:35.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 6296 LR: 0.000999905228906955 Training loss: 0.0
2025-12-09 10:23:35.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 6297 LR: 0.0009999051983193338 Training loss: 0.0
2025-12-09 10:23:35.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 6298 LR: 0.0009999051677267777 Training loss: 0.0
2025-12-09 10:23:35.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 6299 LR: 0.0009999051371292866 Training loss: 0.0
2025-12-09 10:23:35.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 6300 LR: 0.0009999051065268608 Training loss: 0.0
2025-12-09 10:23:35.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 6301 LR: 0.0009999050759195002 Training loss: 0.0
2025-12-09 10:23:35.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 6302 LR: 0.0009999050453072048 Training loss: 0.0
2025-12-09 10:23:35.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 6303 LR: 0.0009999050146899742 Training loss: 0.0
2025-12-09 10:23:35.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 6304 LR: 0.0009999049840678093 Training loss: 0.0
2025-12-09 10:23:35.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 6305 LR: 0.000999904953440709 Training loss: 0.0
2025-12-09 10:23:35.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 6306 LR: 0.0009999049228086741 Training loss: 0.0
2025-12-09 10:23:35.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 6307 LR: 0.0009999048921717044 Training loss: 0.0
2025-12-09 10:23:35.408 | INFO     | __main__:train:24 - Epoch: 0 Step: 6308 LR: 0.0009999048615297998 Training loss: 0.0
2025-12-09 10:23:35.409 | INFO     | __main__:train:24 - Epoch: 0 Step: 6309 LR: 0.0009999048308829603 Training loss: 0.0
2025-12-09 10:23:35.410 | INFO     | __main__:train:24 - Epoch: 0 Step: 6310 LR: 0.000999904800231186 Training loss: 0.0
2025-12-09 10:23:35.411 | INFO     | __main__:train:24 - Epoch: 0 Step: 6311 LR: 0.0009999047695744769 Training loss: 0.0
2025-12-09 10:23:35.412 | INFO     | __main__:train:24 - Epoch: 0 Step: 6312 LR: 0.0009999047389128329 Training loss: 0.0
2025-12-09 10:23:35.413 | INFO     | __main__:train:24 - Epoch: 0 Step: 6313 LR: 0.000999904708246254 Training loss: 0.0
2025-12-09 10:23:35.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 6314 LR: 0.0009999046775747403 Training loss: 0.0
2025-12-09 10:23:35.414 | INFO     | __main__:train:24 - Epoch: 0 Step: 6315 LR: 0.0009999046468982917 Training loss: 0.0
2025-12-09 10:23:35.415 | INFO     | __main__:train:24 - Epoch: 0 Step: 6316 LR: 0.0009999046162169083 Training loss: 0.0
2025-12-09 10:23:35.416 | INFO     | __main__:train:24 - Epoch: 0 Step: 6317 LR: 0.0009999045855305902 Training loss: 0.0
2025-12-09 10:23:35.417 | INFO     | __main__:train:24 - Epoch: 0 Step: 6318 LR: 0.000999904554839337 Training loss: 0.0
2025-12-09 10:23:35.418 | INFO     | __main__:train:24 - Epoch: 0 Step: 6319 LR: 0.000999904524143149 Training loss: 0.0
2025-12-09 10:23:35.419 | INFO     | __main__:train:24 - Epoch: 0 Step: 6320 LR: 0.0009999044934420262 Training loss: 0.0
2025-12-09 10:23:35.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 6321 LR: 0.0009999044627359685 Training loss: 0.0
2025-12-09 10:23:35.420 | INFO     | __main__:train:24 - Epoch: 0 Step: 6322 LR: 0.0009999044320249762 Training loss: 0.0
2025-12-09 10:23:35.421 | INFO     | __main__:train:24 - Epoch: 0 Step: 6323 LR: 0.0009999044013090487 Training loss: 0.0
2025-12-09 10:23:35.422 | INFO     | __main__:train:24 - Epoch: 0 Step: 6324 LR: 0.0009999043705881867 Training loss: 0.0
2025-12-09 10:23:35.423 | INFO     | __main__:train:24 - Epoch: 0 Step: 6325 LR: 0.0009999043398623898 Training loss: 0.0
2025-12-09 10:23:35.424 | INFO     | __main__:train:24 - Epoch: 0 Step: 6326 LR: 0.0009999043091316578 Training loss: 0.0
2025-12-09 10:23:35.425 | INFO     | __main__:train:24 - Epoch: 0 Step: 6327 LR: 0.000999904278395991 Training loss: 0.0
2025-12-09 10:23:35.426 | INFO     | __main__:train:24 - Epoch: 0 Step: 6328 LR: 0.0009999042476553895 Training loss: 0.0
2025-12-09 10:23:35.427 | INFO     | __main__:train:24 - Epoch: 0 Step: 6329 LR: 0.0009999042169098532 Training loss: 0.0
2025-12-09 10:23:35.428 | INFO     | __main__:train:24 - Epoch: 0 Step: 6330 LR: 0.0009999041861593818 Training loss: 0.0
2025-12-09 10:23:35.429 | INFO     | __main__:train:24 - Epoch: 0 Step: 6331 LR: 0.0009999041554039757 Training loss: 0.0
2025-12-09 10:23:35.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 6332 LR: 0.0009999041246436349 Training loss: 0.0
2025-12-09 10:23:35.430 | INFO     | __main__:train:24 - Epoch: 0 Step: 6333 LR: 0.000999904093878359 Training loss: 0.0
2025-12-09 10:23:35.431 | INFO     | __main__:train:24 - Epoch: 0 Step: 6334 LR: 0.0009999040631081485 Training loss: 0.0
2025-12-09 10:23:35.432 | INFO     | __main__:train:24 - Epoch: 0 Step: 6335 LR: 0.000999904032333003 Training loss: 0.0
2025-12-09 10:23:35.433 | INFO     | __main__:train:24 - Epoch: 0 Step: 6336 LR: 0.0009999040015529227 Training loss: 0.0
2025-12-09 10:23:35.434 | INFO     | __main__:train:24 - Epoch: 0 Step: 6337 LR: 0.0009999039707679076 Training loss: 0.0
2025-12-09 10:23:35.435 | INFO     | __main__:train:24 - Epoch: 0 Step: 6338 LR: 0.0009999039399779576 Training loss: 0.0
2025-12-09 10:23:35.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 6339 LR: 0.000999903909183073 Training loss: 0.0
2025-12-09 10:23:35.436 | INFO     | __main__:train:24 - Epoch: 0 Step: 6340 LR: 0.0009999038783832532 Training loss: 0.0
2025-12-09 10:23:35.437 | INFO     | __main__:train:24 - Epoch: 0 Step: 6341 LR: 0.0009999038475784986 Training loss: 0.0
2025-12-09 10:23:35.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 6342 LR: 0.0009999038167688092 Training loss: 0.0
2025-12-09 10:23:35.439 | INFO     | __main__:train:24 - Epoch: 0 Step: 6343 LR: 0.000999903785954185 Training loss: 0.0
2025-12-09 10:23:35.440 | INFO     | __main__:train:24 - Epoch: 0 Step: 6344 LR: 0.000999903755134626 Training loss: 0.0
2025-12-09 10:23:35.441 | INFO     | __main__:train:24 - Epoch: 0 Step: 6345 LR: 0.0009999037243101322 Training loss: 0.0
2025-12-09 10:23:35.442 | INFO     | __main__:train:24 - Epoch: 0 Step: 6346 LR: 0.0009999036934807035 Training loss: 0.0
2025-12-09 10:23:35.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 6347 LR: 0.00099990366264634 Training loss: 0.0
2025-12-09 10:23:35.443 | INFO     | __main__:train:24 - Epoch: 0 Step: 6348 LR: 0.0009999036318070415 Training loss: 0.0
2025-12-09 10:23:35.444 | INFO     | __main__:train:24 - Epoch: 0 Step: 6349 LR: 0.0009999036009628085 Training loss: 0.0
2025-12-09 10:23:35.445 | INFO     | __main__:train:24 - Epoch: 0 Step: 6350 LR: 0.0009999035701136402 Training loss: 0.0
2025-12-09 10:23:35.446 | INFO     | __main__:train:24 - Epoch: 0 Step: 6351 LR: 0.0009999035392595375 Training loss: 0.0
2025-12-09 10:23:35.447 | INFO     | __main__:train:24 - Epoch: 0 Step: 6352 LR: 0.0009999035084004998 Training loss: 0.0
2025-12-09 10:23:35.448 | INFO     | __main__:train:24 - Epoch: 0 Step: 6353 LR: 0.0009999034775365272 Training loss: 0.0
2025-12-09 10:23:35.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 6354 LR: 0.00099990344666762 Training loss: 0.0
2025-12-09 10:23:35.449 | INFO     | __main__:train:24 - Epoch: 0 Step: 6355 LR: 0.0009999034157937776 Training loss: 0.0
2025-12-09 10:23:35.450 | INFO     | __main__:train:24 - Epoch: 0 Step: 6356 LR: 0.0009999033849150004 Training loss: 0.0
2025-12-09 10:23:35.451 | INFO     | __main__:train:24 - Epoch: 0 Step: 6357 LR: 0.0009999033540312886 Training loss: 0.0
2025-12-09 10:23:35.452 | INFO     | __main__:train:24 - Epoch: 0 Step: 6358 LR: 0.0009999033231426417 Training loss: 0.0
2025-12-09 10:23:35.453 | INFO     | __main__:train:24 - Epoch: 0 Step: 6359 LR: 0.0009999032922490604 Training loss: 0.0
2025-12-09 10:23:35.454 | INFO     | __main__:train:24 - Epoch: 0 Step: 6360 LR: 0.000999903261350544 Training loss: 0.0
2025-12-09 10:23:35.455 | INFO     | __main__:train:24 - Epoch: 0 Step: 6361 LR: 0.0009999032304470925 Training loss: 0.0
2025-12-09 10:23:35.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 6362 LR: 0.0009999031995387064 Training loss: 0.0
2025-12-09 10:23:35.456 | INFO     | __main__:train:24 - Epoch: 0 Step: 6363 LR: 0.0009999031686253855 Training loss: 0.0
2025-12-09 10:23:35.457 | INFO     | __main__:train:24 - Epoch: 0 Step: 6364 LR: 0.0009999031377071299 Training loss: 0.0
2025-12-09 10:23:35.458 | INFO     | __main__:train:24 - Epoch: 0 Step: 6365 LR: 0.0009999031067839392 Training loss: 0.0
2025-12-09 10:23:35.459 | INFO     | __main__:train:24 - Epoch: 0 Step: 6366 LR: 0.000999903075855814 Training loss: 0.0
2025-12-09 10:23:35.460 | INFO     | __main__:train:24 - Epoch: 0 Step: 6367 LR: 0.0009999030449227536 Training loss: 0.0
2025-12-09 10:23:35.461 | INFO     | __main__:train:24 - Epoch: 0 Step: 6368 LR: 0.0009999030139847586 Training loss: 0.0
2025-12-09 10:23:35.462 | INFO     | __main__:train:24 - Epoch: 0 Step: 6369 LR: 0.0009999029830418285 Training loss: 0.0
2025-12-09 10:23:35.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 6370 LR: 0.0009999029520939638 Training loss: 0.0
2025-12-09 10:23:35.463 | INFO     | __main__:train:24 - Epoch: 0 Step: 6371 LR: 0.0009999029211411644 Training loss: 0.0
2025-12-09 10:23:35.464 | INFO     | __main__:train:24 - Epoch: 0 Step: 6372 LR: 0.0009999028901834298 Training loss: 0.0
2025-12-09 10:23:35.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 6373 LR: 0.0009999028592207607 Training loss: 0.0
2025-12-09 10:23:35.466 | INFO     | __main__:train:24 - Epoch: 0 Step: 6374 LR: 0.0009999028282531566 Training loss: 0.0
2025-12-09 10:23:35.467 | INFO     | __main__:train:24 - Epoch: 0 Step: 6375 LR: 0.0009999027972806176 Training loss: 0.0
2025-12-09 10:23:35.468 | INFO     | __main__:train:24 - Epoch: 0 Step: 6376 LR: 0.000999902766303144 Training loss: 0.0
2025-12-09 10:23:35.469 | INFO     | __main__:train:24 - Epoch: 0 Step: 6377 LR: 0.0009999027353207353 Training loss: 0.0
2025-12-09 10:23:35.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 6378 LR: 0.000999902704333392 Training loss: 0.0
2025-12-09 10:23:35.470 | INFO     | __main__:train:24 - Epoch: 0 Step: 6379 LR: 0.0009999026733411138 Training loss: 0.0
2025-12-09 10:23:35.471 | INFO     | __main__:train:24 - Epoch: 0 Step: 6380 LR: 0.0009999026423439007 Training loss: 0.0
2025-12-09 10:23:35.472 | INFO     | __main__:train:24 - Epoch: 0 Step: 6381 LR: 0.0009999026113417528 Training loss: 0.0
2025-12-09 10:23:35.473 | INFO     | __main__:train:24 - Epoch: 0 Step: 6382 LR: 0.0009999025803346703 Training loss: 0.0
2025-12-09 10:23:35.474 | INFO     | __main__:train:24 - Epoch: 0 Step: 6383 LR: 0.0009999025493226525 Training loss: 0.0
2025-12-09 10:23:35.475 | INFO     | __main__:train:24 - Epoch: 0 Step: 6384 LR: 0.0009999025183057002 Training loss: 0.0
2025-12-09 10:23:35.476 | INFO     | __main__:train:24 - Epoch: 0 Step: 6385 LR: 0.0009999024872838131 Training loss: 0.0
2025-12-09 10:23:35.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 6386 LR: 0.0009999024562569912 Training loss: 0.0
2025-12-09 10:23:35.477 | INFO     | __main__:train:24 - Epoch: 0 Step: 6387 LR: 0.0009999024252252341 Training loss: 0.0
2025-12-09 10:23:35.478 | INFO     | __main__:train:24 - Epoch: 0 Step: 6388 LR: 0.0009999023941885425 Training loss: 0.0
2025-12-09 10:23:35.479 | INFO     | __main__:train:24 - Epoch: 0 Step: 6389 LR: 0.0009999023631469162 Training loss: 0.0
2025-12-09 10:23:35.480 | INFO     | __main__:train:24 - Epoch: 0 Step: 6390 LR: 0.0009999023321003548 Training loss: 0.0
2025-12-09 10:23:35.481 | INFO     | __main__:train:24 - Epoch: 0 Step: 6391 LR: 0.0009999023010488588 Training loss: 0.0
2025-12-09 10:23:35.482 | INFO     | __main__:train:24 - Epoch: 0 Step: 6392 LR: 0.0009999022699924277 Training loss: 0.0
2025-12-09 10:23:35.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 6393 LR: 0.000999902238931062 Training loss: 0.0
2025-12-09 10:23:35.483 | INFO     | __main__:train:24 - Epoch: 0 Step: 6394 LR: 0.0009999022078647612 Training loss: 0.0
2025-12-09 10:23:35.484 | INFO     | __main__:train:24 - Epoch: 0 Step: 6395 LR: 0.000999902176793526 Training loss: 0.0
2025-12-09 10:23:35.485 | INFO     | __main__:train:24 - Epoch: 0 Step: 6396 LR: 0.0009999021457173557 Training loss: 0.0
2025-12-09 10:23:35.486 | INFO     | __main__:train:24 - Epoch: 0 Step: 6397 LR: 0.0009999021146362506 Training loss: 0.0
2025-12-09 10:23:35.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 6398 LR: 0.0009999020835502106 Training loss: 0.0
2025-12-09 10:23:35.488 | INFO     | __main__:train:24 - Epoch: 0 Step: 6399 LR: 0.000999902052459236 Training loss: 0.0
2025-12-09 10:23:35.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 6400 LR: 0.0009999020213633263 Training loss: 0.0
2025-12-09 10:23:35.489 | INFO     | __main__:train:24 - Epoch: 0 Step: 6401 LR: 0.000999901990262482 Training loss: 0.0
2025-12-09 10:23:35.490 | INFO     | __main__:train:24 - Epoch: 0 Step: 6402 LR: 0.000999901959156703 Training loss: 0.0
2025-12-09 10:23:35.491 | INFO     | __main__:train:24 - Epoch: 0 Step: 6403 LR: 0.0009999019280459889 Training loss: 0.0
2025-12-09 10:23:35.492 | INFO     | __main__:train:24 - Epoch: 0 Step: 6404 LR: 0.00099990189693034 Training loss: 0.0
2025-12-09 10:23:35.493 | INFO     | __main__:train:24 - Epoch: 0 Step: 6405 LR: 0.0009999018658097562 Training loss: 0.0
2025-12-09 10:23:35.494 | INFO     | __main__:train:24 - Epoch: 0 Step: 6406 LR: 0.0009999018346842378 Training loss: 0.0
2025-12-09 10:23:35.495 | INFO     | __main__:train:24 - Epoch: 0 Step: 6407 LR: 0.0009999018035537846 Training loss: 0.0
2025-12-09 10:23:35.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 6408 LR: 0.0009999017724183965 Training loss: 0.0
2025-12-09 10:23:35.496 | INFO     | __main__:train:24 - Epoch: 0 Step: 6409 LR: 0.0009999017412780735 Training loss: 0.0
2025-12-09 10:23:35.497 | INFO     | __main__:train:24 - Epoch: 0 Step: 6410 LR: 0.0009999017101328157 Training loss: 0.0
2025-12-09 10:23:35.498 | INFO     | __main__:train:24 - Epoch: 0 Step: 6411 LR: 0.0009999016789826233 Training loss: 0.0
2025-12-09 10:23:35.499 | INFO     | __main__:train:24 - Epoch: 0 Step: 6412 LR: 0.0009999016478274957 Training loss: 0.0
2025-12-09 10:23:35.500 | INFO     | __main__:train:24 - Epoch: 0 Step: 6413 LR: 0.0009999016166674336 Training loss: 0.0
2025-12-09 10:23:35.501 | INFO     | __main__:train:24 - Epoch: 0 Step: 6414 LR: 0.0009999015855024366 Training loss: 0.0
2025-12-09 10:23:35.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 6415 LR: 0.0009999015543325047 Training loss: 0.0
2025-12-09 10:23:35.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 6416 LR: 0.000999901523157638 Training loss: 0.0
2025-12-09 10:23:35.503 | INFO     | __main__:train:24 - Epoch: 0 Step: 6417 LR: 0.0009999014919778366 Training loss: 0.0
2025-12-09 10:23:35.504 | INFO     | __main__:train:24 - Epoch: 0 Step: 6418 LR: 0.0009999014607931004 Training loss: 0.0
2025-12-09 10:23:35.505 | INFO     | __main__:train:24 - Epoch: 0 Step: 6419 LR: 0.000999901429603429 Training loss: 0.0
2025-12-09 10:23:35.506 | INFO     | __main__:train:24 - Epoch: 0 Step: 6420 LR: 0.0009999013984088232 Training loss: 0.0
2025-12-09 10:23:35.507 | INFO     | __main__:train:24 - Epoch: 0 Step: 6421 LR: 0.0009999013672092824 Training loss: 0.0
2025-12-09 10:23:35.508 | INFO     | __main__:train:24 - Epoch: 0 Step: 6422 LR: 0.0009999013360048067 Training loss: 0.0
2025-12-09 10:23:35.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 6423 LR: 0.0009999013047953965 Training loss: 0.0
2025-12-09 10:23:35.509 | INFO     | __main__:train:24 - Epoch: 0 Step: 6424 LR: 0.0009999012735810513 Training loss: 0.0
2025-12-09 10:23:35.510 | INFO     | __main__:train:24 - Epoch: 0 Step: 6425 LR: 0.0009999012423617714 Training loss: 0.0
2025-12-09 10:23:35.511 | INFO     | __main__:train:24 - Epoch: 0 Step: 6426 LR: 0.0009999012111375565 Training loss: 0.0
2025-12-09 10:23:35.512 | INFO     | __main__:train:24 - Epoch: 0 Step: 6427 LR: 0.0009999011799084068 Training loss: 0.0
2025-12-09 10:23:35.513 | INFO     | __main__:train:24 - Epoch: 0 Step: 6428 LR: 0.0009999011486743223 Training loss: 0.0
2025-12-09 10:23:35.514 | INFO     | __main__:train:24 - Epoch: 0 Step: 6429 LR: 0.000999901117435303 Training loss: 0.0
2025-12-09 10:23:35.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 6430 LR: 0.000999901086191349 Training loss: 0.0
2025-12-09 10:23:35.515 | INFO     | __main__:train:24 - Epoch: 0 Step: 6431 LR: 0.0009999010549424602 Training loss: 0.0
2025-12-09 10:23:35.516 | INFO     | __main__:train:24 - Epoch: 0 Step: 6432 LR: 0.0009999010236886364 Training loss: 0.0
2025-12-09 10:23:35.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 6433 LR: 0.0009999009924298778 Training loss: 0.0
2025-12-09 10:23:35.518 | INFO     | __main__:train:24 - Epoch: 0 Step: 6434 LR: 0.0009999009611661846 Training loss: 0.0
2025-12-09 10:23:35.519 | INFO     | __main__:train:24 - Epoch: 0 Step: 6435 LR: 0.0009999009298975565 Training loss: 0.0
2025-12-09 10:23:35.520 | INFO     | __main__:train:24 - Epoch: 0 Step: 6436 LR: 0.0009999008986239935 Training loss: 0.0
2025-12-09 10:23:35.521 | INFO     | __main__:train:24 - Epoch: 0 Step: 6437 LR: 0.0009999008673454957 Training loss: 0.0
2025-12-09 10:23:35.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 6438 LR: 0.000999900836062063 Training loss: 0.0
2025-12-09 10:23:35.522 | INFO     | __main__:train:24 - Epoch: 0 Step: 6439 LR: 0.0009999008047736958 Training loss: 0.0
2025-12-09 10:23:35.523 | INFO     | __main__:train:24 - Epoch: 0 Step: 6440 LR: 0.0009999007734803936 Training loss: 0.0
2025-12-09 10:23:35.524 | INFO     | __main__:train:24 - Epoch: 0 Step: 6441 LR: 0.0009999007421821566 Training loss: 0.0
2025-12-09 10:23:35.525 | INFO     | __main__:train:24 - Epoch: 0 Step: 6442 LR: 0.0009999007108789848 Training loss: 0.0
2025-12-09 10:23:35.526 | INFO     | __main__:train:24 - Epoch: 0 Step: 6443 LR: 0.000999900679570878 Training loss: 0.0
2025-12-09 10:23:35.527 | INFO     | __main__:train:24 - Epoch: 0 Step: 6444 LR: 0.0009999006482578367 Training loss: 0.0
2025-12-09 10:23:35.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 6445 LR: 0.0009999006169398605 Training loss: 0.0
2025-12-09 10:23:35.528 | INFO     | __main__:train:24 - Epoch: 0 Step: 6446 LR: 0.0009999005856169494 Training loss: 0.0
2025-12-09 10:23:35.529 | INFO     | __main__:train:24 - Epoch: 0 Step: 6447 LR: 0.0009999005542891035 Training loss: 0.0
2025-12-09 10:23:35.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 6448 LR: 0.000999900522956323 Training loss: 0.0
2025-12-09 10:23:35.531 | INFO     | __main__:train:24 - Epoch: 0 Step: 6449 LR: 0.0009999004916186073 Training loss: 0.0
2025-12-09 10:23:35.532 | INFO     | __main__:train:24 - Epoch: 0 Step: 6450 LR: 0.000999900460275957 Training loss: 0.0
2025-12-09 10:23:35.533 | INFO     | __main__:train:24 - Epoch: 0 Step: 6451 LR: 0.0009999004289283722 Training loss: 0.0
2025-12-09 10:23:35.534 | INFO     | __main__:train:24 - Epoch: 0 Step: 6452 LR: 0.0009999003975758522 Training loss: 0.0
2025-12-09 10:23:35.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 6453 LR: 0.0009999003662183976 Training loss: 0.0
2025-12-09 10:23:35.535 | INFO     | __main__:train:24 - Epoch: 0 Step: 6454 LR: 0.0009999003348560081 Training loss: 0.0
2025-12-09 10:23:35.536 | INFO     | __main__:train:24 - Epoch: 0 Step: 6455 LR: 0.0009999003034886838 Training loss: 0.0
2025-12-09 10:23:35.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 6456 LR: 0.0009999002721164246 Training loss: 0.0
2025-12-09 10:23:35.538 | INFO     | __main__:train:24 - Epoch: 0 Step: 6457 LR: 0.0009999002407392306 Training loss: 0.0
2025-12-09 10:23:35.539 | INFO     | __main__:train:24 - Epoch: 0 Step: 6458 LR: 0.000999900209357102 Training loss: 0.0
2025-12-09 10:23:35.540 | INFO     | __main__:train:24 - Epoch: 0 Step: 6459 LR: 0.0009999001779700384 Training loss: 0.0
2025-12-09 10:23:35.541 | INFO     | __main__:train:24 - Epoch: 0 Step: 6460 LR: 0.0009999001465780403 Training loss: 0.0
2025-12-09 10:23:35.542 | INFO     | __main__:train:24 - Epoch: 0 Step: 6461 LR: 0.0009999001151811068 Training loss: 0.0
2025-12-09 10:23:35.543 | INFO     | __main__:train:24 - Epoch: 0 Step: 6462 LR: 0.000999900083779239 Training loss: 0.0
2025-12-09 10:23:35.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 6463 LR: 0.0009999000523724362 Training loss: 0.0
2025-12-09 10:23:35.544 | INFO     | __main__:train:24 - Epoch: 0 Step: 6464 LR: 0.0009999000209606989 Training loss: 0.0
2025-12-09 10:23:35.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 6465 LR: 0.0009998999895440264 Training loss: 0.0
2025-12-09 10:23:35.546 | INFO     | __main__:train:24 - Epoch: 0 Step: 6466 LR: 0.0009998999581224194 Training loss: 0.0
2025-12-09 10:23:35.547 | INFO     | __main__:train:24 - Epoch: 0 Step: 6467 LR: 0.0009998999266958772 Training loss: 0.0
2025-12-09 10:23:35.548 | INFO     | __main__:train:24 - Epoch: 0 Step: 6468 LR: 0.0009998998952644004 Training loss: 0.0
2025-12-09 10:23:35.549 | INFO     | __main__:train:24 - Epoch: 0 Step: 6469 LR: 0.000999899863827989 Training loss: 0.0
2025-12-09 10:23:35.550 | INFO     | __main__:train:24 - Epoch: 0 Step: 6470 LR: 0.0009998998323866425 Training loss: 0.0
2025-12-09 10:23:35.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 6471 LR: 0.0009998998009403614 Training loss: 0.0
2025-12-09 10:23:35.551 | INFO     | __main__:train:24 - Epoch: 0 Step: 6472 LR: 0.0009998997694891456 Training loss: 0.0
2025-12-09 10:23:35.552 | INFO     | __main__:train:24 - Epoch: 0 Step: 6473 LR: 0.0009998997380329948 Training loss: 0.0
2025-12-09 10:23:35.553 | INFO     | __main__:train:24 - Epoch: 0 Step: 6474 LR: 0.0009998997065719093 Training loss: 0.0
2025-12-09 10:23:35.554 | INFO     | __main__:train:24 - Epoch: 0 Step: 6475 LR: 0.0009998996751058888 Training loss: 0.0
2025-12-09 10:23:35.555 | INFO     | __main__:train:24 - Epoch: 0 Step: 6476 LR: 0.0009998996436349336 Training loss: 0.0
2025-12-09 10:23:35.556 | INFO     | __main__:train:24 - Epoch: 0 Step: 6477 LR: 0.0009998996121590438 Training loss: 0.0
2025-12-09 10:23:35.557 | INFO     | __main__:train:24 - Epoch: 0 Step: 6478 LR: 0.000999899580678219 Training loss: 0.0
2025-12-09 10:23:35.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 6479 LR: 0.0009998995491924596 Training loss: 0.0
2025-12-09 10:23:35.558 | INFO     | __main__:train:24 - Epoch: 0 Step: 6480 LR: 0.0009998995177017652 Training loss: 0.0
2025-12-09 10:23:35.559 | INFO     | __main__:train:24 - Epoch: 0 Step: 6481 LR: 0.000999899486206136 Training loss: 0.0
2025-12-09 10:23:35.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 6482 LR: 0.000999899454705572 Training loss: 0.0
2025-12-09 10:23:35.561 | INFO     | __main__:train:24 - Epoch: 0 Step: 6483 LR: 0.0009998994232000733 Training loss: 0.0
2025-12-09 10:23:35.562 | INFO     | __main__:train:24 - Epoch: 0 Step: 6484 LR: 0.0009998993916896398 Training loss: 0.0
2025-12-09 10:23:35.563 | INFO     | __main__:train:24 - Epoch: 0 Step: 6485 LR: 0.0009998993601742715 Training loss: 0.0
2025-12-09 10:23:35.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 6486 LR: 0.0009998993286539685 Training loss: 0.0
2025-12-09 10:23:35.564 | INFO     | __main__:train:24 - Epoch: 0 Step: 6487 LR: 0.0009998992971287303 Training loss: 0.0
2025-12-09 10:23:35.565 | INFO     | __main__:train:24 - Epoch: 0 Step: 6488 LR: 0.0009998992655985577 Training loss: 0.0
2025-12-09 10:23:35.566 | INFO     | __main__:train:24 - Epoch: 0 Step: 6489 LR: 0.0009998992340634503 Training loss: 0.0
2025-12-09 10:23:35.567 | INFO     | __main__:train:24 - Epoch: 0 Step: 6490 LR: 0.000999899202523408 Training loss: 0.0
2025-12-09 10:23:35.568 | INFO     | __main__:train:24 - Epoch: 0 Step: 6491 LR: 0.000999899170978431 Training loss: 0.0
2025-12-09 10:23:35.569 | INFO     | __main__:train:24 - Epoch: 0 Step: 6492 LR: 0.000999899139428519 Training loss: 0.0
2025-12-09 10:23:35.570 | INFO     | __main__:train:24 - Epoch: 0 Step: 6493 LR: 0.0009998991078736723 Training loss: 0.0
2025-12-09 10:23:35.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 6494 LR: 0.0009998990763138908 Training loss: 0.0
2025-12-09 10:23:35.571 | INFO     | __main__:train:24 - Epoch: 0 Step: 6495 LR: 0.0009998990447491745 Training loss: 0.0
2025-12-09 10:23:35.572 | INFO     | __main__:train:24 - Epoch: 0 Step: 6496 LR: 0.0009998990131795235 Training loss: 0.0
2025-12-09 10:23:35.573 | INFO     | __main__:train:24 - Epoch: 0 Step: 6497 LR: 0.0009998989816049375 Training loss: 0.0
2025-12-09 10:23:35.574 | INFO     | __main__:train:24 - Epoch: 0 Step: 6498 LR: 0.000999898950025417 Training loss: 0.0
2025-12-09 10:23:35.575 | INFO     | __main__:train:24 - Epoch: 0 Step: 6499 LR: 0.0009998989184409615 Training loss: 0.0
2025-12-09 10:23:35.576 | INFO     | __main__:train:24 - Epoch: 0 Step: 6500 LR: 0.0009998988868515713 Training loss: 0.0
2025-12-09 10:23:35.577 | INFO     | __main__:train:24 - Epoch: 0 Step: 6501 LR: 0.0009998988552572462 Training loss: 0.0
2025-12-09 10:23:35.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 6502 LR: 0.0009998988236579864 Training loss: 0.0
2025-12-09 10:23:35.578 | INFO     | __main__:train:24 - Epoch: 0 Step: 6503 LR: 0.0009998987920537918 Training loss: 0.0
2025-12-09 10:23:35.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 6504 LR: 0.0009998987604446625 Training loss: 0.0
2025-12-09 10:23:35.580 | INFO     | __main__:train:24 - Epoch: 0 Step: 6505 LR: 0.0009998987288305982 Training loss: 0.0
2025-12-09 10:23:35.581 | INFO     | __main__:train:24 - Epoch: 0 Step: 6506 LR: 0.0009998986972115994 Training loss: 0.0
2025-12-09 10:23:35.582 | INFO     | __main__:train:24 - Epoch: 0 Step: 6507 LR: 0.0009998986655876654 Training loss: 0.0
2025-12-09 10:23:35.583 | INFO     | __main__:train:24 - Epoch: 0 Step: 6508 LR: 0.000999898633958797 Training loss: 0.0
2025-12-09 10:23:35.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 6509 LR: 0.0009998986023249936 Training loss: 0.0
2025-12-09 10:23:35.584 | INFO     | __main__:train:24 - Epoch: 0 Step: 6510 LR: 0.0009998985706862556 Training loss: 0.0
2025-12-09 10:23:35.585 | INFO     | __main__:train:24 - Epoch: 0 Step: 6511 LR: 0.0009998985390425826 Training loss: 0.0
2025-12-09 10:23:35.586 | INFO     | __main__:train:24 - Epoch: 0 Step: 6512 LR: 0.0009998985073939749 Training loss: 0.0
2025-12-09 10:23:35.587 | INFO     | __main__:train:24 - Epoch: 0 Step: 6513 LR: 0.0009998984757404324 Training loss: 0.0
2025-12-09 10:23:35.588 | INFO     | __main__:train:24 - Epoch: 0 Step: 6514 LR: 0.0009998984440819552 Training loss: 0.0
2025-12-09 10:23:35.589 | INFO     | __main__:train:24 - Epoch: 0 Step: 6515 LR: 0.000999898412418543 Training loss: 0.0
2025-12-09 10:23:35.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 6516 LR: 0.0009998983807501963 Training loss: 0.0
2025-12-09 10:23:35.590 | INFO     | __main__:train:24 - Epoch: 0 Step: 6517 LR: 0.0009998983490769147 Training loss: 0.0
2025-12-09 10:23:35.591 | INFO     | __main__:train:24 - Epoch: 0 Step: 6518 LR: 0.0009998983173986982 Training loss: 0.0
2025-12-09 10:23:35.592 | INFO     | __main__:train:24 - Epoch: 0 Step: 6519 LR: 0.000999898285715547 Training loss: 0.0
2025-12-09 10:23:35.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 6520 LR: 0.0009998982540274609 Training loss: 0.0
2025-12-09 10:23:35.594 | INFO     | __main__:train:24 - Epoch: 0 Step: 6521 LR: 0.00099989822233444 Training loss: 0.0
2025-12-09 10:23:35.595 | INFO     | __main__:train:24 - Epoch: 0 Step: 6522 LR: 0.0009998981906364846 Training loss: 0.0
2025-12-09 10:23:35.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 6523 LR: 0.0009998981589335943 Training loss: 0.0
2025-12-09 10:23:35.596 | INFO     | __main__:train:24 - Epoch: 0 Step: 6524 LR: 0.0009998981272257691 Training loss: 0.0
2025-12-09 10:23:35.597 | INFO     | __main__:train:24 - Epoch: 0 Step: 6525 LR: 0.0009998980955130093 Training loss: 0.0
2025-12-09 10:23:35.598 | INFO     | __main__:train:24 - Epoch: 0 Step: 6526 LR: 0.0009998980637953147 Training loss: 0.0
2025-12-09 10:23:35.599 | INFO     | __main__:train:24 - Epoch: 0 Step: 6527 LR: 0.000999898032072685 Training loss: 0.0
2025-12-09 10:23:35.600 | INFO     | __main__:train:24 - Epoch: 0 Step: 6528 LR: 0.0009998980003451208 Training loss: 0.0
2025-12-09 10:23:35.601 | INFO     | __main__:train:24 - Epoch: 0 Step: 6529 LR: 0.0009998979686126218 Training loss: 0.0
2025-12-09 10:23:35.602 | INFO     | __main__:train:24 - Epoch: 0 Step: 6530 LR: 0.000999897936875188 Training loss: 0.0
2025-12-09 10:23:35.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 6531 LR: 0.0009998979051328192 Training loss: 0.0
2025-12-09 10:23:35.603 | INFO     | __main__:train:24 - Epoch: 0 Step: 6532 LR: 0.0009998978733855158 Training loss: 0.0
2025-12-09 10:23:35.604 | INFO     | __main__:train:24 - Epoch: 0 Step: 6533 LR: 0.0009998978416332776 Training loss: 0.0
2025-12-09 10:23:35.605 | INFO     | __main__:train:24 - Epoch: 0 Step: 6534 LR: 0.0009998978098761046 Training loss: 0.0
2025-12-09 10:23:35.606 | INFO     | __main__:train:24 - Epoch: 0 Step: 6535 LR: 0.000999897778113997 Training loss: 0.0
2025-12-09 10:23:35.607 | INFO     | __main__:train:24 - Epoch: 0 Step: 6536 LR: 0.0009998977463469545 Training loss: 0.0
2025-12-09 10:23:35.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 6537 LR: 0.0009998977145749773 Training loss: 0.0
2025-12-09 10:23:35.609 | INFO     | __main__:train:24 - Epoch: 0 Step: 6538 LR: 0.000999897682798065 Training loss: 0.0
2025-12-09 10:23:35.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 6539 LR: 0.0009998976510162184 Training loss: 0.0
2025-12-09 10:23:35.610 | INFO     | __main__:train:24 - Epoch: 0 Step: 6540 LR: 0.0009998976192294366 Training loss: 0.0
2025-12-09 10:23:35.611 | INFO     | __main__:train:24 - Epoch: 0 Step: 6541 LR: 0.0009998975874377202 Training loss: 0.0
2025-12-09 10:23:35.612 | INFO     | __main__:train:24 - Epoch: 0 Step: 6542 LR: 0.000999897555641069 Training loss: 0.0
2025-12-09 10:23:35.613 | INFO     | __main__:train:24 - Epoch: 0 Step: 6543 LR: 0.000999897523839483 Training loss: 0.0
2025-12-09 10:23:35.614 | INFO     | __main__:train:24 - Epoch: 0 Step: 6544 LR: 0.0009998974920329624 Training loss: 0.0
2025-12-09 10:23:35.615 | INFO     | __main__:train:24 - Epoch: 0 Step: 6545 LR: 0.0009998974602215068 Training loss: 0.0
2025-12-09 10:23:35.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 6546 LR: 0.0009998974284051165 Training loss: 0.0
2025-12-09 10:23:35.616 | INFO     | __main__:train:24 - Epoch: 0 Step: 6547 LR: 0.0009998973965837914 Training loss: 0.0
2025-12-09 10:23:35.617 | INFO     | __main__:train:24 - Epoch: 0 Step: 6548 LR: 0.0009998973647575315 Training loss: 0.0
2025-12-09 10:23:35.618 | INFO     | __main__:train:24 - Epoch: 0 Step: 6549 LR: 0.000999897332926337 Training loss: 0.0
2025-12-09 10:23:35.619 | INFO     | __main__:train:24 - Epoch: 0 Step: 6550 LR: 0.0009998973010902075 Training loss: 0.0
2025-12-09 10:23:35.620 | INFO     | __main__:train:24 - Epoch: 0 Step: 6551 LR: 0.0009998972692491432 Training loss: 0.0
2025-12-09 10:23:35.621 | INFO     | __main__:train:24 - Epoch: 0 Step: 6552 LR: 0.0009998972374031443 Training loss: 0.0
2025-12-09 10:23:35.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 6553 LR: 0.0009998972055522107 Training loss: 0.0
2025-12-09 10:23:35.622 | INFO     | __main__:train:24 - Epoch: 0 Step: 6554 LR: 0.000999897173696342 Training loss: 0.0
2025-12-09 10:23:35.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 6555 LR: 0.000999897141835539 Training loss: 0.0
2025-12-09 10:23:35.624 | INFO     | __main__:train:24 - Epoch: 0 Step: 6556 LR: 0.0009998971099698009 Training loss: 0.0
2025-12-09 10:23:35.625 | INFO     | __main__:train:24 - Epoch: 0 Step: 6557 LR: 0.0009998970780991279 Training loss: 0.0
2025-12-09 10:23:35.626 | INFO     | __main__:train:24 - Epoch: 0 Step: 6558 LR: 0.0009998970462235205 Training loss: 0.0
2025-12-09 10:23:35.627 | INFO     | __main__:train:24 - Epoch: 0 Step: 6559 LR: 0.000999897014342978 Training loss: 0.0
2025-12-09 10:23:35.628 | INFO     | __main__:train:24 - Epoch: 0 Step: 6560 LR: 0.0009998969824575009 Training loss: 0.0
2025-12-09 10:23:35.629 | INFO     | __main__:train:24 - Epoch: 0 Step: 6561 LR: 0.000999896950567089 Training loss: 0.0
2025-12-09 10:23:35.630 | INFO     | __main__:train:24 - Epoch: 0 Step: 6562 LR: 0.000999896918671742 Training loss: 0.0
2025-12-09 10:23:35.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 6563 LR: 0.0009998968867714609 Training loss: 0.0
2025-12-09 10:23:35.631 | INFO     | __main__:train:24 - Epoch: 0 Step: 6564 LR: 0.0009998968548662445 Training loss: 0.0
2025-12-09 10:23:35.632 | INFO     | __main__:train:24 - Epoch: 0 Step: 6565 LR: 0.0009998968229560936 Training loss: 0.0
2025-12-09 10:23:35.633 | INFO     | __main__:train:24 - Epoch: 0 Step: 6566 LR: 0.0009998967910410078 Training loss: 0.0
2025-12-09 10:23:35.634 | INFO     | __main__:train:24 - Epoch: 0 Step: 6567 LR: 0.0009998967591209871 Training loss: 0.0
2025-12-09 10:23:35.635 | INFO     | __main__:train:24 - Epoch: 0 Step: 6568 LR: 0.0009998967271960318 Training loss: 0.0
2025-12-09 10:23:35.636 | INFO     | __main__:train:24 - Epoch: 0 Step: 6569 LR: 0.0009998966952661419 Training loss: 0.0
2025-12-09 10:23:35.637 | INFO     | __main__:train:24 - Epoch: 0 Step: 6570 LR: 0.0009998966633313169 Training loss: 0.0
2025-12-09 10:23:35.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 6571 LR: 0.0009998966313915572 Training loss: 0.0
2025-12-09 10:23:35.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 6572 LR: 0.000999896599446863 Training loss: 0.0
2025-12-09 10:23:35.639 | INFO     | __main__:train:24 - Epoch: 0 Step: 6573 LR: 0.0009998965674972338 Training loss: 0.0
2025-12-09 10:23:35.640 | INFO     | __main__:train:24 - Epoch: 0 Step: 6574 LR: 0.00099989653554267 Training loss: 0.0
2025-12-09 10:23:35.641 | INFO     | __main__:train:24 - Epoch: 0 Step: 6575 LR: 0.0009998965035831712 Training loss: 0.0
2025-12-09 10:23:35.642 | INFO     | __main__:train:24 - Epoch: 0 Step: 6576 LR: 0.0009998964716187377 Training loss: 0.0
2025-12-09 10:23:35.643 | INFO     | __main__:train:24 - Epoch: 0 Step: 6577 LR: 0.0009998964396493695 Training loss: 0.0
2025-12-09 10:23:35.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 6578 LR: 0.0009998964076750663 Training loss: 0.0
2025-12-09 10:23:35.644 | INFO     | __main__:train:24 - Epoch: 0 Step: 6579 LR: 0.0009998963756958285 Training loss: 0.0
2025-12-09 10:23:35.645 | INFO     | __main__:train:24 - Epoch: 0 Step: 6580 LR: 0.0009998963437116563 Training loss: 0.0
2025-12-09 10:23:35.646 | INFO     | __main__:train:24 - Epoch: 0 Step: 6581 LR: 0.0009998963117225487 Training loss: 0.0
2025-12-09 10:23:35.647 | INFO     | __main__:train:24 - Epoch: 0 Step: 6582 LR: 0.0009998962797285068 Training loss: 0.0
2025-12-09 10:23:35.648 | INFO     | __main__:train:24 - Epoch: 0 Step: 6583 LR: 0.00099989624772953 Training loss: 0.0
2025-12-09 10:23:35.649 | INFO     | __main__:train:24 - Epoch: 0 Step: 6584 LR: 0.0009998962157256185 Training loss: 0.0
2025-12-09 10:23:35.650 | INFO     | __main__:train:24 - Epoch: 0 Step: 6585 LR: 0.000999896183716772 Training loss: 0.0
2025-12-09 10:23:35.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 6586 LR: 0.0009998961517029908 Training loss: 0.0
2025-12-09 10:23:35.652 | INFO     | __main__:train:24 - Epoch: 0 Step: 6587 LR: 0.000999896119684275 Training loss: 0.0
2025-12-09 10:23:35.653 | INFO     | __main__:train:24 - Epoch: 0 Step: 6588 LR: 0.0009998960876606243 Training loss: 0.0
2025-12-09 10:23:35.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 6589 LR: 0.0009998960556320388 Training loss: 0.0
2025-12-09 10:23:35.654 | INFO     | __main__:train:24 - Epoch: 0 Step: 6590 LR: 0.0009998960235985187 Training loss: 0.0
2025-12-09 10:23:35.655 | INFO     | __main__:train:24 - Epoch: 0 Step: 6591 LR: 0.0009998959915600637 Training loss: 0.0
2025-12-09 10:23:35.656 | INFO     | __main__:train:24 - Epoch: 0 Step: 6592 LR: 0.000999895959516674 Training loss: 0.0
2025-12-09 10:23:35.657 | INFO     | __main__:train:24 - Epoch: 0 Step: 6593 LR: 0.0009998959274683495 Training loss: 0.0
2025-12-09 10:23:35.658 | INFO     | __main__:train:24 - Epoch: 0 Step: 6594 LR: 0.0009998958954150904 Training loss: 0.0
2025-12-09 10:23:35.659 | INFO     | __main__:train:24 - Epoch: 0 Step: 6595 LR: 0.0009998958633568964 Training loss: 0.0
2025-12-09 10:23:35.660 | INFO     | __main__:train:24 - Epoch: 0 Step: 6596 LR: 0.0009998958312937675 Training loss: 0.0
2025-12-09 10:23:35.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 6597 LR: 0.000999895799225704 Training loss: 0.0
2025-12-09 10:23:35.661 | INFO     | __main__:train:24 - Epoch: 0 Step: 6598 LR: 0.0009998957671527057 Training loss: 0.0
2025-12-09 10:23:35.662 | INFO     | __main__:train:24 - Epoch: 0 Step: 6599 LR: 0.0009998957350747727 Training loss: 0.0
2025-12-09 10:23:35.663 | INFO     | __main__:train:24 - Epoch: 0 Step: 6600 LR: 0.000999895702991905 Training loss: 0.0
2025-12-09 10:23:35.664 | INFO     | __main__:train:24 - Epoch: 0 Step: 6601 LR: 0.0009998956709041024 Training loss: 0.0
2025-12-09 10:23:35.665 | INFO     | __main__:train:24 - Epoch: 0 Step: 6602 LR: 0.0009998956388113651 Training loss: 0.0
2025-12-09 10:23:35.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 6603 LR: 0.0009998956067136932 Training loss: 0.0
2025-12-09 10:23:35.667 | INFO     | __main__:train:24 - Epoch: 0 Step: 6604 LR: 0.0009998955746110864 Training loss: 0.0
2025-12-09 10:23:35.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 6605 LR: 0.0009998955425035445 Training loss: 0.0
2025-12-09 10:23:35.668 | INFO     | __main__:train:24 - Epoch: 0 Step: 6606 LR: 0.0009998955103910684 Training loss: 0.0
2025-12-09 10:23:35.669 | INFO     | __main__:train:24 - Epoch: 0 Step: 6607 LR: 0.0009998954782736572 Training loss: 0.0
2025-12-09 10:23:35.670 | INFO     | __main__:train:24 - Epoch: 0 Step: 6608 LR: 0.0009998954461513112 Training loss: 0.0
2025-12-09 10:23:35.671 | INFO     | __main__:train:24 - Epoch: 0 Step: 6609 LR: 0.0009998954140240305 Training loss: 0.0
2025-12-09 10:23:35.672 | INFO     | __main__:train:24 - Epoch: 0 Step: 6610 LR: 0.0009998953818918153 Training loss: 0.0
2025-12-09 10:23:35.673 | INFO     | __main__:train:24 - Epoch: 0 Step: 6611 LR: 0.0009998953497546653 Training loss: 0.0
2025-12-09 10:23:35.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 6612 LR: 0.0009998953176125803 Training loss: 0.0
2025-12-09 10:23:35.674 | INFO     | __main__:train:24 - Epoch: 0 Step: 6613 LR: 0.0009998952854655607 Training loss: 0.0
2025-12-09 10:23:35.675 | INFO     | __main__:train:24 - Epoch: 0 Step: 6614 LR: 0.0009998952533136062 Training loss: 0.0
2025-12-09 10:23:35.676 | INFO     | __main__:train:24 - Epoch: 0 Step: 6615 LR: 0.000999895221156717 Training loss: 0.0
2025-12-09 10:23:35.677 | INFO     | __main__:train:24 - Epoch: 0 Step: 6616 LR: 0.000999895188994893 Training loss: 0.0
2025-12-09 10:23:35.678 | INFO     | __main__:train:24 - Epoch: 0 Step: 6617 LR: 0.0009998951568281345 Training loss: 0.0
2025-12-09 10:23:35.679 | INFO     | __main__:train:24 - Epoch: 0 Step: 6618 LR: 0.000999895124656441 Training loss: 0.0
2025-12-09 10:23:35.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 6619 LR: 0.0009998950924798129 Training loss: 0.0
2025-12-09 10:23:35.680 | INFO     | __main__:train:24 - Epoch: 0 Step: 6620 LR: 0.00099989506029825 Training loss: 0.0
2025-12-09 10:23:35.681 | INFO     | __main__:train:24 - Epoch: 0 Step: 6621 LR: 0.0009998950281117523 Training loss: 0.0
2025-12-09 10:23:35.682 | INFO     | __main__:train:24 - Epoch: 0 Step: 6622 LR: 0.0009998949959203198 Training loss: 0.0
2025-12-09 10:23:35.683 | INFO     | __main__:train:24 - Epoch: 0 Step: 6623 LR: 0.0009998949637239525 Training loss: 0.0
2025-12-09 10:23:35.684 | INFO     | __main__:train:24 - Epoch: 0 Step: 6624 LR: 0.0009998949315226506 Training loss: 0.0
2025-12-09 10:23:35.685 | INFO     | __main__:train:24 - Epoch: 0 Step: 6625 LR: 0.000999894899316414 Training loss: 0.0
2025-12-09 10:23:35.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 6626 LR: 0.0009998948671052425 Training loss: 0.0
2025-12-09 10:23:35.686 | INFO     | __main__:train:24 - Epoch: 0 Step: 6627 LR: 0.0009998948348891364 Training loss: 0.0
2025-12-09 10:23:35.687 | INFO     | __main__:train:24 - Epoch: 0 Step: 6628 LR: 0.0009998948026680955 Training loss: 0.0
2025-12-09 10:23:35.688 | INFO     | __main__:train:24 - Epoch: 0 Step: 6629 LR: 0.0009998947704421197 Training loss: 0.0
2025-12-09 10:23:35.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 6630 LR: 0.0009998947382112093 Training loss: 0.0
2025-12-09 10:23:35.690 | INFO     | __main__:train:24 - Epoch: 0 Step: 6631 LR: 0.000999894705975364 Training loss: 0.0
2025-12-09 10:23:35.691 | INFO     | __main__:train:24 - Epoch: 0 Step: 6632 LR: 0.000999894673734584 Training loss: 0.0
2025-12-09 10:23:35.692 | INFO     | __main__:train:24 - Epoch: 0 Step: 6633 LR: 0.0009998946414888695 Training loss: 0.0
2025-12-09 10:23:35.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 6634 LR: 0.0009998946092382199 Training loss: 0.0
2025-12-09 10:23:35.693 | INFO     | __main__:train:24 - Epoch: 0 Step: 6635 LR: 0.0009998945769826358 Training loss: 0.0
2025-12-09 10:23:35.694 | INFO     | __main__:train:24 - Epoch: 0 Step: 6636 LR: 0.000999894544722117 Training loss: 0.0
2025-12-09 10:23:35.695 | INFO     | __main__:train:24 - Epoch: 0 Step: 6637 LR: 0.0009998945124566631 Training loss: 0.0
2025-12-09 10:23:35.696 | INFO     | __main__:train:24 - Epoch: 0 Step: 6638 LR: 0.0009998944801862745 Training loss: 0.0
2025-12-09 10:23:35.697 | INFO     | __main__:train:24 - Epoch: 0 Step: 6639 LR: 0.0009998944479109515 Training loss: 0.0
2025-12-09 10:23:35.698 | INFO     | __main__:train:24 - Epoch: 0 Step: 6640 LR: 0.0009998944156306936 Training loss: 0.0
2025-12-09 10:23:35.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 6641 LR: 0.0009998943833455008 Training loss: 0.0
2025-12-09 10:23:35.699 | INFO     | __main__:train:24 - Epoch: 0 Step: 6642 LR: 0.0009998943510553734 Training loss: 0.0
2025-12-09 10:23:35.700 | INFO     | __main__:train:24 - Epoch: 0 Step: 6643 LR: 0.0009998943187603112 Training loss: 0.0
2025-12-09 10:23:35.701 | INFO     | __main__:train:24 - Epoch: 0 Step: 6644 LR: 0.0009998942864603143 Training loss: 0.0
2025-12-09 10:23:35.702 | INFO     | __main__:train:24 - Epoch: 0 Step: 6645 LR: 0.0009998942541553826 Training loss: 0.0
2025-12-09 10:23:35.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 6646 LR: 0.0009998942218455162 Training loss: 0.0
2025-12-09 10:23:35.704 | INFO     | __main__:train:24 - Epoch: 0 Step: 6647 LR: 0.000999894189530715 Training loss: 0.0
2025-12-09 10:23:35.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 6648 LR: 0.0009998941572109791 Training loss: 0.0
2025-12-09 10:23:35.705 | INFO     | __main__:train:24 - Epoch: 0 Step: 6649 LR: 0.0009998941248863084 Training loss: 0.0
2025-12-09 10:23:35.706 | INFO     | __main__:train:24 - Epoch: 0 Step: 6650 LR: 0.000999894092556703 Training loss: 0.0
2025-12-09 10:23:35.707 | INFO     | __main__:train:24 - Epoch: 0 Step: 6651 LR: 0.000999894060222163 Training loss: 0.0
2025-12-09 10:23:35.708 | INFO     | __main__:train:24 - Epoch: 0 Step: 6652 LR: 0.0009998940278826882 Training loss: 0.0
2025-12-09 10:23:35.709 | INFO     | __main__:train:24 - Epoch: 0 Step: 6653 LR: 0.0009998939955382785 Training loss: 0.0
2025-12-09 10:23:35.710 | INFO     | __main__:train:24 - Epoch: 0 Step: 6654 LR: 0.0009998939631889342 Training loss: 0.0
2025-12-09 10:23:35.711 | INFO     | __main__:train:24 - Epoch: 0 Step: 6655 LR: 0.000999893930834655 Training loss: 0.0
2025-12-09 10:23:35.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 6656 LR: 0.0009998938984754411 Training loss: 0.0
2025-12-09 10:23:35.712 | INFO     | __main__:train:24 - Epoch: 0 Step: 6657 LR: 0.0009998938661112927 Training loss: 0.0
2025-12-09 10:23:35.713 | INFO     | __main__:train:24 - Epoch: 0 Step: 6658 LR: 0.0009998938337422091 Training loss: 0.0
2025-12-09 10:23:35.714 | INFO     | __main__:train:24 - Epoch: 0 Step: 6659 LR: 0.0009998938013681912 Training loss: 0.0
2025-12-09 10:23:35.715 | INFO     | __main__:train:24 - Epoch: 0 Step: 6660 LR: 0.0009998937689892384 Training loss: 0.0
2025-12-09 10:23:35.716 | INFO     | __main__:train:24 - Epoch: 0 Step: 6661 LR: 0.0009998937366053507 Training loss: 0.0
2025-12-09 10:23:35.717 | INFO     | __main__:train:24 - Epoch: 0 Step: 6662 LR: 0.0009998937042165284 Training loss: 0.0
2025-12-09 10:23:35.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 6663 LR: 0.0009998936718227714 Training loss: 0.0
2025-12-09 10:23:35.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 6664 LR: 0.0009998936394240796 Training loss: 0.0
2025-12-09 10:23:35.719 | INFO     | __main__:train:24 - Epoch: 0 Step: 6665 LR: 0.0009998936070204532 Training loss: 0.0
2025-12-09 10:23:35.720 | INFO     | __main__:train:24 - Epoch: 0 Step: 6666 LR: 0.0009998935746118919 Training loss: 0.0
2025-12-09 10:23:35.721 | INFO     | __main__:train:24 - Epoch: 0 Step: 6667 LR: 0.000999893542198396 Training loss: 0.0
2025-12-09 10:23:35.722 | INFO     | __main__:train:24 - Epoch: 0 Step: 6668 LR: 0.0009998935097799652 Training loss: 0.0
2025-12-09 10:23:35.723 | INFO     | __main__:train:24 - Epoch: 0 Step: 6669 LR: 0.0009998934773565997 Training loss: 0.0
2025-12-09 10:23:35.724 | INFO     | __main__:train:24 - Epoch: 0 Step: 6670 LR: 0.0009998934449282995 Training loss: 0.0
2025-12-09 10:23:35.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 6671 LR: 0.0009998934124950645 Training loss: 0.0
2025-12-09 10:23:35.725 | INFO     | __main__:train:24 - Epoch: 0 Step: 6672 LR: 0.0009998933800568948 Training loss: 0.0
2025-12-09 10:23:35.726 | INFO     | __main__:train:24 - Epoch: 0 Step: 6673 LR: 0.0009998933476137904 Training loss: 0.0
2025-12-09 10:23:35.727 | INFO     | __main__:train:24 - Epoch: 0 Step: 6674 LR: 0.0009998933151657513 Training loss: 0.0
2025-12-09 10:23:35.728 | INFO     | __main__:train:24 - Epoch: 0 Step: 6675 LR: 0.0009998932827127774 Training loss: 0.0
2025-12-09 10:23:35.729 | INFO     | __main__:train:24 - Epoch: 0 Step: 6676 LR: 0.0009998932502548689 Training loss: 0.0
2025-12-09 10:23:35.730 | INFO     | __main__:train:24 - Epoch: 0 Step: 6677 LR: 0.0009998932177920255 Training loss: 0.0
2025-12-09 10:23:35.731 | INFO     | __main__:train:24 - Epoch: 0 Step: 6678 LR: 0.0009998931853242472 Training loss: 0.0
2025-12-09 10:23:35.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 6679 LR: 0.0009998931528515346 Training loss: 0.0
2025-12-09 10:23:35.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 6680 LR: 0.0009998931203738868 Training loss: 0.0
2025-12-09 10:23:35.733 | INFO     | __main__:train:24 - Epoch: 0 Step: 6681 LR: 0.0009998930878913047 Training loss: 0.0
2025-12-09 10:23:35.734 | INFO     | __main__:train:24 - Epoch: 0 Step: 6682 LR: 0.0009998930554037874 Training loss: 0.0
2025-12-09 10:23:35.735 | INFO     | __main__:train:24 - Epoch: 0 Step: 6683 LR: 0.0009998930229113358 Training loss: 0.0
2025-12-09 10:23:35.736 | INFO     | __main__:train:24 - Epoch: 0 Step: 6684 LR: 0.0009998929904139493 Training loss: 0.0
2025-12-09 10:23:35.737 | INFO     | __main__:train:24 - Epoch: 0 Step: 6685 LR: 0.0009998929579116281 Training loss: 0.0
2025-12-09 10:23:35.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 6686 LR: 0.0009998929254043721 Training loss: 0.0
2025-12-09 10:23:35.738 | INFO     | __main__:train:24 - Epoch: 0 Step: 6687 LR: 0.0009998928928921813 Training loss: 0.0
2025-12-09 10:23:35.739 | INFO     | __main__:train:24 - Epoch: 0 Step: 6688 LR: 0.000999892860375056 Training loss: 0.0
2025-12-09 10:23:35.740 | INFO     | __main__:train:24 - Epoch: 0 Step: 6689 LR: 0.0009998928278529956 Training loss: 0.0
2025-12-09 10:23:35.741 | INFO     | __main__:train:24 - Epoch: 0 Step: 6690 LR: 0.0009998927953260009 Training loss: 0.0
2025-12-09 10:23:35.742 | INFO     | __main__:train:24 - Epoch: 0 Step: 6691 LR: 0.0009998927627940712 Training loss: 0.0
2025-12-09 10:23:35.743 | INFO     | __main__:train:24 - Epoch: 0 Step: 6692 LR: 0.000999892730257207 Training loss: 0.0
2025-12-09 10:23:35.744 | INFO     | __main__:train:24 - Epoch: 0 Step: 6693 LR: 0.0009998926977154079 Training loss: 0.0
2025-12-09 10:23:35.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 6694 LR: 0.0009998926651686739 Training loss: 0.0
2025-12-09 10:23:35.745 | INFO     | __main__:train:24 - Epoch: 0 Step: 6695 LR: 0.0009998926326170055 Training loss: 0.0
2025-12-09 10:23:35.746 | INFO     | __main__:train:24 - Epoch: 0 Step: 6696 LR: 0.000999892600060402 Training loss: 0.0
2025-12-09 10:23:35.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 6697 LR: 0.0009998925674988641 Training loss: 0.0
2025-12-09 10:23:35.748 | INFO     | __main__:train:24 - Epoch: 0 Step: 6698 LR: 0.0009998925349323914 Training loss: 0.0
2025-12-09 10:23:35.749 | INFO     | __main__:train:24 - Epoch: 0 Step: 6699 LR: 0.000999892502360984 Training loss: 0.0
2025-12-09 10:23:35.750 | INFO     | __main__:train:24 - Epoch: 0 Step: 6700 LR: 0.0009998924697846416 Training loss: 0.0
2025-12-09 10:23:35.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 6701 LR: 0.000999892437203365 Training loss: 0.0
2025-12-09 10:23:35.751 | INFO     | __main__:train:24 - Epoch: 0 Step: 6702 LR: 0.0009998924046171532 Training loss: 0.0
2025-12-09 10:23:35.752 | INFO     | __main__:train:24 - Epoch: 0 Step: 6703 LR: 0.0009998923720260068 Training loss: 0.0
2025-12-09 10:23:35.753 | INFO     | __main__:train:24 - Epoch: 0 Step: 6704 LR: 0.0009998923394299258 Training loss: 0.0
2025-12-09 10:23:35.754 | INFO     | __main__:train:24 - Epoch: 0 Step: 6705 LR: 0.0009998923068289098 Training loss: 0.0
2025-12-09 10:23:35.755 | INFO     | __main__:train:24 - Epoch: 0 Step: 6706 LR: 0.0009998922742229593 Training loss: 0.0
2025-12-09 10:23:35.756 | INFO     | __main__:train:24 - Epoch: 0 Step: 6707 LR: 0.000999892241612074 Training loss: 0.0
2025-12-09 10:23:35.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 6708 LR: 0.000999892208996254 Training loss: 0.0
2025-12-09 10:23:35.757 | INFO     | __main__:train:24 - Epoch: 0 Step: 6709 LR: 0.0009998921763754993 Training loss: 0.0
2025-12-09 10:23:35.759 | INFO     | __main__:train:24 - Epoch: 0 Step: 6710 LR: 0.0009998921437498099 Training loss: 0.0
2025-12-09 10:23:35.760 | INFO     | __main__:train:24 - Epoch: 0 Step: 6711 LR: 0.0009998921111191857 Training loss: 0.0
2025-12-09 10:23:35.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 6712 LR: 0.0009998920784836268 Training loss: 0.0
2025-12-09 10:23:35.761 | INFO     | __main__:train:24 - Epoch: 0 Step: 6713 LR: 0.0009998920458431332 Training loss: 0.0
2025-12-09 10:23:35.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 6714 LR: 0.0009998920131977047 Training loss: 0.0
2025-12-09 10:23:35.763 | INFO     | __main__:train:24 - Epoch: 0 Step: 6715 LR: 0.0009998919805473416 Training loss: 0.0
2025-12-09 10:23:35.764 | INFO     | __main__:train:24 - Epoch: 0 Step: 6716 LR: 0.0009998919478920439 Training loss: 0.0
2025-12-09 10:23:35.765 | INFO     | __main__:train:24 - Epoch: 0 Step: 6717 LR: 0.0009998919152318113 Training loss: 0.0
2025-12-09 10:23:35.766 | INFO     | __main__:train:24 - Epoch: 0 Step: 6718 LR: 0.000999891882566644 Training loss: 0.0
2025-12-09 10:23:35.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 6719 LR: 0.0009998918498965422 Training loss: 0.0
2025-12-09 10:23:35.767 | INFO     | __main__:train:24 - Epoch: 0 Step: 6720 LR: 0.0009998918172215055 Training loss: 0.0
2025-12-09 10:23:35.768 | INFO     | __main__:train:24 - Epoch: 0 Step: 6721 LR: 0.000999891784541534 Training loss: 0.0
2025-12-09 10:23:35.769 | INFO     | __main__:train:24 - Epoch: 0 Step: 6722 LR: 0.0009998917518566279 Training loss: 0.0
2025-12-09 10:23:35.770 | INFO     | __main__:train:24 - Epoch: 0 Step: 6723 LR: 0.000999891719166787 Training loss: 0.0
2025-12-09 10:23:35.771 | INFO     | __main__:train:24 - Epoch: 0 Step: 6724 LR: 0.0009998916864720115 Training loss: 0.0
2025-12-09 10:23:35.772 | INFO     | __main__:train:24 - Epoch: 0 Step: 6725 LR: 0.0009998916537723012 Training loss: 0.0
2025-12-09 10:23:35.773 | INFO     | __main__:train:24 - Epoch: 0 Step: 6726 LR: 0.0009998916210676562 Training loss: 0.0
2025-12-09 10:23:35.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 6727 LR: 0.0009998915883580764 Training loss: 0.0
2025-12-09 10:23:35.774 | INFO     | __main__:train:24 - Epoch: 0 Step: 6728 LR: 0.000999891555643562 Training loss: 0.0
2025-12-09 10:23:35.775 | INFO     | __main__:train:24 - Epoch: 0 Step: 6729 LR: 0.0009998915229241128 Training loss: 0.0
2025-12-09 10:23:35.776 | INFO     | __main__:train:24 - Epoch: 0 Step: 6730 LR: 0.0009998914901997288 Training loss: 0.0
2025-12-09 10:23:35.777 | INFO     | __main__:train:24 - Epoch: 0 Step: 6731 LR: 0.0009998914574704102 Training loss: 0.0
2025-12-09 10:23:35.778 | INFO     | __main__:train:24 - Epoch: 0 Step: 6732 LR: 0.000999891424736157 Training loss: 0.0
2025-12-09 10:23:35.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 6733 LR: 0.0009998913919969689 Training loss: 0.0
2025-12-09 10:23:35.780 | INFO     | __main__:train:24 - Epoch: 0 Step: 6734 LR: 0.0009998913592528462 Training loss: 0.0
2025-12-09 10:23:35.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 6735 LR: 0.0009998913265037888 Training loss: 0.0
2025-12-09 10:23:35.781 | INFO     | __main__:train:24 - Epoch: 0 Step: 6736 LR: 0.0009998912937497966 Training loss: 0.0
2025-12-09 10:23:35.782 | INFO     | __main__:train:24 - Epoch: 0 Step: 6737 LR: 0.0009998912609908697 Training loss: 0.0
2025-12-09 10:23:35.783 | INFO     | __main__:train:24 - Epoch: 0 Step: 6738 LR: 0.000999891228227008 Training loss: 0.0
2025-12-09 10:23:35.784 | INFO     | __main__:train:24 - Epoch: 0 Step: 6739 LR: 0.0009998911954582118 Training loss: 0.0
2025-12-09 10:23:35.785 | INFO     | __main__:train:24 - Epoch: 0 Step: 6740 LR: 0.0009998911626844806 Training loss: 0.0
2025-12-09 10:23:35.786 | INFO     | __main__:train:24 - Epoch: 0 Step: 6741 LR: 0.000999891129905815 Training loss: 0.0
2025-12-09 10:23:35.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 6742 LR: 0.0009998910971222143 Training loss: 0.0
2025-12-09 10:23:35.787 | INFO     | __main__:train:24 - Epoch: 0 Step: 6743 LR: 0.0009998910643336792 Training loss: 0.0
2025-12-09 10:23:35.788 | INFO     | __main__:train:24 - Epoch: 0 Step: 6744 LR: 0.0009998910315402092 Training loss: 0.0
2025-12-09 10:23:35.789 | INFO     | __main__:train:24 - Epoch: 0 Step: 6745 LR: 0.0009998909987418046 Training loss: 0.0
2025-12-09 10:23:35.790 | INFO     | __main__:train:24 - Epoch: 0 Step: 6746 LR: 0.0009998909659384653 Training loss: 0.0
2025-12-09 10:23:35.791 | INFO     | __main__:train:24 - Epoch: 0 Step: 6747 LR: 0.0009998909331301914 Training loss: 0.0
2025-12-09 10:23:35.792 | INFO     | __main__:train:24 - Epoch: 0 Step: 6748 LR: 0.0009998909003169824 Training loss: 0.0
2025-12-09 10:23:35.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 6749 LR: 0.0009998908674988388 Training loss: 0.0
2025-12-09 10:23:35.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 6750 LR: 0.0009998908346757608 Training loss: 0.0
2025-12-09 10:23:35.794 | INFO     | __main__:train:24 - Epoch: 0 Step: 6751 LR: 0.000999890801847748 Training loss: 0.0
2025-12-09 10:23:35.795 | INFO     | __main__:train:24 - Epoch: 0 Step: 6752 LR: 0.0009998907690148002 Training loss: 0.0
2025-12-09 10:23:35.796 | INFO     | __main__:train:24 - Epoch: 0 Step: 6753 LR: 0.000999890736176918 Training loss: 0.0
2025-12-09 10:23:35.797 | INFO     | __main__:train:24 - Epoch: 0 Step: 6754 LR: 0.0009998907033341008 Training loss: 0.0
2025-12-09 10:23:35.798 | INFO     | __main__:train:24 - Epoch: 0 Step: 6755 LR: 0.0009998906704863492 Training loss: 0.0
2025-12-09 10:23:35.799 | INFO     | __main__:train:24 - Epoch: 0 Step: 6756 LR: 0.0009998906376336627 Training loss: 0.0
2025-12-09 10:23:35.800 | INFO     | __main__:train:24 - Epoch: 0 Step: 6757 LR: 0.0009998906047760416 Training loss: 0.0
2025-12-09 10:23:35.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 6758 LR: 0.0009998905719134856 Training loss: 0.0
2025-12-09 10:23:35.801 | INFO     | __main__:train:24 - Epoch: 0 Step: 6759 LR: 0.0009998905390459951 Training loss: 0.0
2025-12-09 10:23:35.802 | INFO     | __main__:train:24 - Epoch: 0 Step: 6760 LR: 0.0009998905061735699 Training loss: 0.0
2025-12-09 10:23:35.803 | INFO     | __main__:train:24 - Epoch: 0 Step: 6761 LR: 0.0009998904732962098 Training loss: 0.0
2025-12-09 10:23:35.804 | INFO     | __main__:train:24 - Epoch: 0 Step: 6762 LR: 0.000999890440413915 Training loss: 0.0
2025-12-09 10:23:35.805 | INFO     | __main__:train:24 - Epoch: 0 Step: 6763 LR: 0.0009998904075266856 Training loss: 0.0
2025-12-09 10:23:35.806 | INFO     | __main__:train:24 - Epoch: 0 Step: 6764 LR: 0.0009998903746345216 Training loss: 0.0
2025-12-09 10:23:35.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 6765 LR: 0.0009998903417374227 Training loss: 0.0
2025-12-09 10:23:35.807 | INFO     | __main__:train:24 - Epoch: 0 Step: 6766 LR: 0.0009998903088353891 Training loss: 0.0
2025-12-09 10:23:35.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 6767 LR: 0.000999890275928421 Training loss: 0.0
2025-12-09 10:23:35.809 | INFO     | __main__:train:24 - Epoch: 0 Step: 6768 LR: 0.000999890243016518 Training loss: 0.0
2025-12-09 10:23:35.810 | INFO     | __main__:train:24 - Epoch: 0 Step: 6769 LR: 0.0009998902100996803 Training loss: 0.0
2025-12-09 10:23:35.811 | INFO     | __main__:train:24 - Epoch: 0 Step: 6770 LR: 0.000999890177177908 Training loss: 0.0
2025-12-09 10:23:35.812 | INFO     | __main__:train:24 - Epoch: 0 Step: 6771 LR: 0.0009998901442512009 Training loss: 0.0
2025-12-09 10:23:35.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 6772 LR: 0.0009998901113195593 Training loss: 0.0
2025-12-09 10:23:35.813 | INFO     | __main__:train:24 - Epoch: 0 Step: 6773 LR: 0.0009998900783829826 Training loss: 0.0
2025-12-09 10:23:35.814 | INFO     | __main__:train:24 - Epoch: 0 Step: 6774 LR: 0.0009998900454414716 Training loss: 0.0
2025-12-09 10:23:35.815 | INFO     | __main__:train:24 - Epoch: 0 Step: 6775 LR: 0.0009998900124950257 Training loss: 0.0
2025-12-09 10:23:35.816 | INFO     | __main__:train:24 - Epoch: 0 Step: 6776 LR: 0.000999889979543645 Training loss: 0.0
2025-12-09 10:23:35.817 | INFO     | __main__:train:24 - Epoch: 0 Step: 6777 LR: 0.0009998899465873297 Training loss: 0.0
2025-12-09 10:23:35.818 | INFO     | __main__:train:24 - Epoch: 0 Step: 6778 LR: 0.0009998899136260796 Training loss: 0.0
2025-12-09 10:23:35.819 | INFO     | __main__:train:24 - Epoch: 0 Step: 6779 LR: 0.000999889880659895 Training loss: 0.0
2025-12-09 10:23:35.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 6780 LR: 0.0009998898476887756 Training loss: 0.0
2025-12-09 10:23:35.820 | INFO     | __main__:train:24 - Epoch: 0 Step: 6781 LR: 0.0009998898147127217 Training loss: 0.0
2025-12-09 10:23:35.821 | INFO     | __main__:train:24 - Epoch: 0 Step: 6782 LR: 0.0009998897817317326 Training loss: 0.0
2025-12-09 10:23:35.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 6783 LR: 0.0009998897487458094 Training loss: 0.0
2025-12-09 10:23:35.823 | INFO     | __main__:train:24 - Epoch: 0 Step: 6784 LR: 0.000999889715754951 Training loss: 0.0
2025-12-09 10:23:35.824 | INFO     | __main__:train:24 - Epoch: 0 Step: 6785 LR: 0.0009998896827591581 Training loss: 0.0
2025-12-09 10:23:35.825 | INFO     | __main__:train:24 - Epoch: 0 Step: 6786 LR: 0.0009998896497584306 Training loss: 0.0
2025-12-09 10:23:35.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 6787 LR: 0.0009998896167527683 Training loss: 0.0
2025-12-09 10:23:35.826 | INFO     | __main__:train:24 - Epoch: 0 Step: 6788 LR: 0.0009998895837421713 Training loss: 0.0
2025-12-09 10:23:35.827 | INFO     | __main__:train:24 - Epoch: 0 Step: 6789 LR: 0.0009998895507266395 Training loss: 0.0
2025-12-09 10:23:35.828 | INFO     | __main__:train:24 - Epoch: 0 Step: 6790 LR: 0.0009998895177061732 Training loss: 0.0
2025-12-09 10:23:35.829 | INFO     | __main__:train:24 - Epoch: 0 Step: 6791 LR: 0.000999889484680772 Training loss: 0.0
2025-12-09 10:23:35.830 | INFO     | __main__:train:24 - Epoch: 0 Step: 6792 LR: 0.0009998894516504361 Training loss: 0.0
2025-12-09 10:23:35.831 | INFO     | __main__:train:24 - Epoch: 0 Step: 6793 LR: 0.0009998894186151657 Training loss: 0.0
2025-12-09 10:23:35.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 6794 LR: 0.0009998893855749605 Training loss: 0.0
2025-12-09 10:23:35.832 | INFO     | __main__:train:24 - Epoch: 0 Step: 6795 LR: 0.0009998893525298208 Training loss: 0.0
2025-12-09 10:23:35.833 | INFO     | __main__:train:24 - Epoch: 0 Step: 6796 LR: 0.000999889319479746 Training loss: 0.0
2025-12-09 10:23:35.834 | INFO     | __main__:train:24 - Epoch: 0 Step: 6797 LR: 0.0009998892864247367 Training loss: 0.0
2025-12-09 10:23:35.835 | INFO     | __main__:train:24 - Epoch: 0 Step: 6798 LR: 0.0009998892533647928 Training loss: 0.0
2025-12-09 10:23:35.836 | INFO     | __main__:train:24 - Epoch: 0 Step: 6799 LR: 0.000999889220299914 Training loss: 0.0
2025-12-09 10:23:35.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 6800 LR: 0.000999889187230101 Training loss: 0.0
2025-12-09 10:23:35.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 6801 LR: 0.0009998891541553527 Training loss: 0.0
2025-12-09 10:23:35.838 | INFO     | __main__:train:24 - Epoch: 0 Step: 6802 LR: 0.00099988912107567 Training loss: 0.0
2025-12-09 10:23:35.839 | INFO     | __main__:train:24 - Epoch: 0 Step: 6803 LR: 0.0009998890879910525 Training loss: 0.0
2025-12-09 10:23:35.840 | INFO     | __main__:train:24 - Epoch: 0 Step: 6804 LR: 0.0009998890549015003 Training loss: 0.0
2025-12-09 10:23:35.841 | INFO     | __main__:train:24 - Epoch: 0 Step: 6805 LR: 0.0009998890218070136 Training loss: 0.0
2025-12-09 10:23:35.842 | INFO     | __main__:train:24 - Epoch: 0 Step: 6806 LR: 0.000999888988707592 Training loss: 0.0
2025-12-09 10:23:35.843 | INFO     | __main__:train:24 - Epoch: 0 Step: 6807 LR: 0.0009998889556032356 Training loss: 0.0
2025-12-09 10:23:35.844 | INFO     | __main__:train:24 - Epoch: 0 Step: 6808 LR: 0.0009998889224939447 Training loss: 0.0
2025-12-09 10:23:35.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 6809 LR: 0.0009998888893797192 Training loss: 0.0
2025-12-09 10:23:35.845 | INFO     | __main__:train:24 - Epoch: 0 Step: 6810 LR: 0.0009998888562605588 Training loss: 0.0
2025-12-09 10:23:35.846 | INFO     | __main__:train:24 - Epoch: 0 Step: 6811 LR: 0.0009998888231364637 Training loss: 0.0
2025-12-09 10:23:35.847 | INFO     | __main__:train:24 - Epoch: 0 Step: 6812 LR: 0.000999888790007434 Training loss: 0.0
2025-12-09 10:23:35.848 | INFO     | __main__:train:24 - Epoch: 0 Step: 6813 LR: 0.0009998887568734697 Training loss: 0.0
2025-12-09 10:23:35.849 | INFO     | __main__:train:24 - Epoch: 0 Step: 6814 LR: 0.0009998887237345705 Training loss: 0.0
2025-12-09 10:23:35.850 | INFO     | __main__:train:24 - Epoch: 0 Step: 6815 LR: 0.000999888690590737 Training loss: 0.0
2025-12-09 10:23:35.851 | INFO     | __main__:train:24 - Epoch: 0 Step: 6816 LR: 0.0009998886574419683 Training loss: 0.0
2025-12-09 10:23:35.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 6817 LR: 0.0009998886242882652 Training loss: 0.0
2025-12-09 10:23:35.852 | INFO     | __main__:train:24 - Epoch: 0 Step: 6818 LR: 0.0009998885911296274 Training loss: 0.0
2025-12-09 10:23:35.853 | INFO     | __main__:train:24 - Epoch: 0 Step: 6819 LR: 0.0009998885579660549 Training loss: 0.0
2025-12-09 10:23:35.854 | INFO     | __main__:train:24 - Epoch: 0 Step: 6820 LR: 0.0009998885247975476 Training loss: 0.0
2025-12-09 10:23:35.855 | INFO     | __main__:train:24 - Epoch: 0 Step: 6821 LR: 0.0009998884916241058 Training loss: 0.0
2025-12-09 10:23:35.856 | INFO     | __main__:train:24 - Epoch: 0 Step: 6822 LR: 0.000999888458445729 Training loss: 0.0
2025-12-09 10:23:35.857 | INFO     | __main__:train:24 - Epoch: 0 Step: 6823 LR: 0.000999888425262418 Training loss: 0.0
2025-12-09 10:23:35.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 6824 LR: 0.000999888392074172 Training loss: 0.0
2025-12-09 10:23:35.858 | INFO     | __main__:train:24 - Epoch: 0 Step: 6825 LR: 0.0009998883588809913 Training loss: 0.0
2025-12-09 10:23:35.859 | INFO     | __main__:train:24 - Epoch: 0 Step: 6826 LR: 0.0009998883256828758 Training loss: 0.0
2025-12-09 10:23:35.860 | INFO     | __main__:train:24 - Epoch: 0 Step: 6827 LR: 0.0009998882924798257 Training loss: 0.0
2025-12-09 10:23:35.861 | INFO     | __main__:train:24 - Epoch: 0 Step: 6828 LR: 0.0009998882592718412 Training loss: 0.0
2025-12-09 10:23:35.862 | INFO     | __main__:train:24 - Epoch: 0 Step: 6829 LR: 0.0009998882260589218 Training loss: 0.0
2025-12-09 10:23:35.863 | INFO     | __main__:train:24 - Epoch: 0 Step: 6830 LR: 0.0009998881928410675 Training loss: 0.0
2025-12-09 10:23:35.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 6831 LR: 0.0009998881596182789 Training loss: 0.0
2025-12-09 10:23:35.864 | INFO     | __main__:train:24 - Epoch: 0 Step: 6832 LR: 0.0009998881263905553 Training loss: 0.0
2025-12-09 10:23:35.865 | INFO     | __main__:train:24 - Epoch: 0 Step: 6833 LR: 0.0009998880931578972 Training loss: 0.0
2025-12-09 10:23:35.866 | INFO     | __main__:train:24 - Epoch: 0 Step: 6834 LR: 0.0009998880599203044 Training loss: 0.0
2025-12-09 10:23:35.867 | INFO     | __main__:train:24 - Epoch: 0 Step: 6835 LR: 0.0009998880266777767 Training loss: 0.0
2025-12-09 10:23:35.868 | INFO     | __main__:train:24 - Epoch: 0 Step: 6836 LR: 0.0009998879934303147 Training loss: 0.0
2025-12-09 10:23:35.869 | INFO     | __main__:train:24 - Epoch: 0 Step: 6837 LR: 0.0009998879601779177 Training loss: 0.0
2025-12-09 10:23:35.870 | INFO     | __main__:train:24 - Epoch: 0 Step: 6838 LR: 0.0009998879269205862 Training loss: 0.0
2025-12-09 10:23:35.871 | INFO     | __main__:train:24 - Epoch: 0 Step: 6839 LR: 0.00099988789365832 Training loss: 0.0
2025-12-09 10:23:35.872 | INFO     | __main__:train:24 - Epoch: 0 Step: 6840 LR: 0.0009998878603911191 Training loss: 0.0
2025-12-09 10:23:35.873 | INFO     | __main__:train:24 - Epoch: 0 Step: 6841 LR: 0.0009998878271189832 Training loss: 0.0
2025-12-09 10:23:35.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 6842 LR: 0.000999887793841913 Training loss: 0.0
2025-12-09 10:23:35.874 | INFO     | __main__:train:24 - Epoch: 0 Step: 6843 LR: 0.000999887760559908 Training loss: 0.0
2025-12-09 10:23:35.875 | INFO     | __main__:train:24 - Epoch: 0 Step: 6844 LR: 0.0009998877272729685 Training loss: 0.0
2025-12-09 10:23:35.876 | INFO     | __main__:train:24 - Epoch: 0 Step: 6845 LR: 0.000999887693981094 Training loss: 0.0
2025-12-09 10:23:35.877 | INFO     | __main__:train:24 - Epoch: 0 Step: 6846 LR: 0.0009998876606842851 Training loss: 0.0
2025-12-09 10:23:35.878 | INFO     | __main__:train:24 - Epoch: 0 Step: 6847 LR: 0.0009998876273825414 Training loss: 0.0
2025-12-09 10:23:35.879 | INFO     | __main__:train:24 - Epoch: 0 Step: 6848 LR: 0.000999887594075863 Training loss: 0.0
2025-12-09 10:23:35.880 | INFO     | __main__:train:24 - Epoch: 0 Step: 6849 LR: 0.00099988756076425 Training loss: 0.0
2025-12-09 10:23:35.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 6850 LR: 0.0009998875274477021 Training loss: 0.0
2025-12-09 10:23:35.881 | INFO     | __main__:train:24 - Epoch: 0 Step: 6851 LR: 0.0009998874941262196 Training loss: 0.0
2025-12-09 10:23:35.882 | INFO     | __main__:train:24 - Epoch: 0 Step: 6852 LR: 0.0009998874607998027 Training loss: 0.0
2025-12-09 10:23:35.883 | INFO     | __main__:train:24 - Epoch: 0 Step: 6853 LR: 0.000999887427468451 Training loss: 0.0
2025-12-09 10:23:35.884 | INFO     | __main__:train:24 - Epoch: 0 Step: 6854 LR: 0.0009998873941321645 Training loss: 0.0
2025-12-09 10:23:35.885 | INFO     | __main__:train:24 - Epoch: 0 Step: 6855 LR: 0.0009998873607909434 Training loss: 0.0
2025-12-09 10:23:35.886 | INFO     | __main__:train:24 - Epoch: 0 Step: 6856 LR: 0.0009998873274447875 Training loss: 0.0
2025-12-09 10:23:35.887 | INFO     | __main__:train:24 - Epoch: 0 Step: 6857 LR: 0.000999887294093697 Training loss: 0.0
2025-12-09 10:23:35.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 6858 LR: 0.0009998872607376718 Training loss: 0.0
2025-12-09 10:23:35.888 | INFO     | __main__:train:24 - Epoch: 0 Step: 6859 LR: 0.000999887227376712 Training loss: 0.0
2025-12-09 10:23:35.889 | INFO     | __main__:train:24 - Epoch: 0 Step: 6860 LR: 0.0009998871940108175 Training loss: 0.0
2025-12-09 10:23:35.890 | INFO     | __main__:train:24 - Epoch: 0 Step: 6861 LR: 0.0009998871606399882 Training loss: 0.0
2025-12-09 10:23:35.891 | INFO     | __main__:train:24 - Epoch: 0 Step: 6862 LR: 0.0009998871272642244 Training loss: 0.0
2025-12-09 10:23:35.892 | INFO     | __main__:train:24 - Epoch: 0 Step: 6863 LR: 0.0009998870938835258 Training loss: 0.0
2025-12-09 10:23:35.893 | INFO     | __main__:train:24 - Epoch: 0 Step: 6864 LR: 0.0009998870604978926 Training loss: 0.0
2025-12-09 10:23:35.894 | INFO     | __main__:train:24 - Epoch: 0 Step: 6865 LR: 0.0009998870271073247 Training loss: 0.0
2025-12-09 10:23:35.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 6866 LR: 0.0009998869937118222 Training loss: 0.0
2025-12-09 10:23:35.895 | INFO     | __main__:train:24 - Epoch: 0 Step: 6867 LR: 0.0009998869603113848 Training loss: 0.0
2025-12-09 10:23:35.896 | INFO     | __main__:train:24 - Epoch: 0 Step: 6868 LR: 0.0009998869269060128 Training loss: 0.0
2025-12-09 10:23:35.897 | INFO     | __main__:train:24 - Epoch: 0 Step: 6869 LR: 0.0009998868934957064 Training loss: 0.0
2025-12-09 10:23:35.898 | INFO     | __main__:train:24 - Epoch: 0 Step: 6870 LR: 0.0009998868600804651 Training loss: 0.0
2025-12-09 10:23:35.899 | INFO     | __main__:train:24 - Epoch: 0 Step: 6871 LR: 0.0009998868266602892 Training loss: 0.0
2025-12-09 10:23:35.900 | INFO     | __main__:train:24 - Epoch: 0 Step: 6872 LR: 0.0009998867932351785 Training loss: 0.0
2025-12-09 10:23:35.901 | INFO     | __main__:train:24 - Epoch: 0 Step: 6873 LR: 0.0009998867598051333 Training loss: 0.0
2025-12-09 10:23:35.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 6874 LR: 0.0009998867263701532 Training loss: 0.0
2025-12-09 10:23:35.902 | INFO     | __main__:train:24 - Epoch: 0 Step: 6875 LR: 0.0009998866929302388 Training loss: 0.0
2025-12-09 10:23:35.903 | INFO     | __main__:train:24 - Epoch: 0 Step: 6876 LR: 0.0009998866594853894 Training loss: 0.0
2025-12-09 10:23:35.904 | INFO     | __main__:train:24 - Epoch: 0 Step: 6877 LR: 0.0009998866260356055 Training loss: 0.0
2025-12-09 10:23:35.905 | INFO     | __main__:train:24 - Epoch: 0 Step: 6878 LR: 0.0009998865925808869 Training loss: 0.0
2025-12-09 10:23:35.906 | INFO     | __main__:train:24 - Epoch: 0 Step: 6879 LR: 0.0009998865591212336 Training loss: 0.0
2025-12-09 10:23:35.907 | INFO     | __main__:train:24 - Epoch: 0 Step: 6880 LR: 0.0009998865256566456 Training loss: 0.0
2025-12-09 10:23:35.908 | INFO     | __main__:train:24 - Epoch: 0 Step: 6881 LR: 0.0009998864921871228 Training loss: 0.0
2025-12-09 10:23:35.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 6882 LR: 0.0009998864587126657 Training loss: 0.0
2025-12-09 10:23:35.909 | INFO     | __main__:train:24 - Epoch: 0 Step: 6883 LR: 0.0009998864252332735 Training loss: 0.0
2025-12-09 10:23:35.910 | INFO     | __main__:train:24 - Epoch: 0 Step: 6884 LR: 0.0009998863917489468 Training loss: 0.0
2025-12-09 10:23:35.911 | INFO     | __main__:train:24 - Epoch: 0 Step: 6885 LR: 0.0009998863582596856 Training loss: 0.0
2025-12-09 10:23:35.912 | INFO     | __main__:train:24 - Epoch: 0 Step: 6886 LR: 0.0009998863247654896 Training loss: 0.0
2025-12-09 10:23:35.913 | INFO     | __main__:train:24 - Epoch: 0 Step: 6887 LR: 0.000999886291266359 Training loss: 0.0
2025-12-09 10:23:35.914 | INFO     | __main__:train:24 - Epoch: 0 Step: 6888 LR: 0.0009998862577622937 Training loss: 0.0
2025-12-09 10:23:35.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 6889 LR: 0.0009998862242532938 Training loss: 0.0
2025-12-09 10:23:35.915 | INFO     | __main__:train:24 - Epoch: 0 Step: 6890 LR: 0.000999886190739359 Training loss: 0.0
2025-12-09 10:23:35.916 | INFO     | __main__:train:24 - Epoch: 0 Step: 6891 LR: 0.0009998861572204898 Training loss: 0.0
2025-12-09 10:23:35.917 | INFO     | __main__:train:24 - Epoch: 0 Step: 6892 LR: 0.0009998861236966859 Training loss: 0.0
2025-12-09 10:23:35.918 | INFO     | __main__:train:24 - Epoch: 0 Step: 6893 LR: 0.0009998860901679473 Training loss: 0.0
2025-12-09 10:23:35.919 | INFO     | __main__:train:24 - Epoch: 0 Step: 6894 LR: 0.0009998860566342738 Training loss: 0.0
2025-12-09 10:23:35.920 | INFO     | __main__:train:24 - Epoch: 0 Step: 6895 LR: 0.000999886023095666 Training loss: 0.0
2025-12-09 10:23:35.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 6896 LR: 0.0009998859895521232 Training loss: 0.0
2025-12-09 10:23:35.921 | INFO     | __main__:train:24 - Epoch: 0 Step: 6897 LR: 0.0009998859560036459 Training loss: 0.0
2025-12-09 10:23:35.922 | INFO     | __main__:train:24 - Epoch: 0 Step: 6898 LR: 0.0009998859224502339 Training loss: 0.0
2025-12-09 10:23:35.923 | INFO     | __main__:train:24 - Epoch: 0 Step: 6899 LR: 0.0009998858888918874 Training loss: 0.0
2025-12-09 10:23:35.924 | INFO     | __main__:train:24 - Epoch: 0 Step: 6900 LR: 0.0009998858553286062 Training loss: 0.0
2025-12-09 10:23:35.925 | INFO     | __main__:train:24 - Epoch: 0 Step: 6901 LR: 0.00099988582176039 Training loss: 0.0
2025-12-09 10:23:35.926 | INFO     | __main__:train:24 - Epoch: 0 Step: 6902 LR: 0.0009998857881872395 Training loss: 0.0
2025-12-09 10:23:35.927 | INFO     | __main__:train:24 - Epoch: 0 Step: 6903 LR: 0.0009998857546091543 Training loss: 0.0
2025-12-09 10:23:35.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 6904 LR: 0.0009998857210261343 Training loss: 0.0
2025-12-09 10:23:35.928 | INFO     | __main__:train:24 - Epoch: 0 Step: 6905 LR: 0.0009998856874381796 Training loss: 0.0
2025-12-09 10:23:35.929 | INFO     | __main__:train:24 - Epoch: 0 Step: 6906 LR: 0.0009998856538452905 Training loss: 0.0
2025-12-09 10:23:35.930 | INFO     | __main__:train:24 - Epoch: 0 Step: 6907 LR: 0.0009998856202474665 Training loss: 0.0
2025-12-09 10:23:35.931 | INFO     | __main__:train:24 - Epoch: 0 Step: 6908 LR: 0.000999885586644708 Training loss: 0.0
2025-12-09 10:23:35.932 | INFO     | __main__:train:24 - Epoch: 0 Step: 6909 LR: 0.0009998855530370145 Training loss: 0.0
2025-12-09 10:23:35.933 | INFO     | __main__:train:24 - Epoch: 0 Step: 6910 LR: 0.0009998855194243868 Training loss: 0.0
2025-12-09 10:23:35.934 | INFO     | __main__:train:24 - Epoch: 0 Step: 6911 LR: 0.000999885485806824 Training loss: 0.0
2025-12-09 10:23:35.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 6912 LR: 0.000999885452184327 Training loss: 0.0
2025-12-09 10:23:35.935 | INFO     | __main__:train:24 - Epoch: 0 Step: 6913 LR: 0.0009998854185568951 Training loss: 0.0
2025-12-09 10:23:35.936 | INFO     | __main__:train:24 - Epoch: 0 Step: 6914 LR: 0.0009998853849245285 Training loss: 0.0
2025-12-09 10:23:35.937 | INFO     | __main__:train:24 - Epoch: 0 Step: 6915 LR: 0.0009998853512872274 Training loss: 0.0
2025-12-09 10:23:35.938 | INFO     | __main__:train:24 - Epoch: 0 Step: 6916 LR: 0.0009998853176449915 Training loss: 0.0
2025-12-09 10:23:35.939 | INFO     | __main__:train:24 - Epoch: 0 Step: 6917 LR: 0.000999885283997821 Training loss: 0.0
2025-12-09 10:23:35.940 | INFO     | __main__:train:24 - Epoch: 0 Step: 6918 LR: 0.0009998852503457158 Training loss: 0.0
2025-12-09 10:23:35.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 6919 LR: 0.000999885216688676 Training loss: 0.0
2025-12-09 10:23:35.941 | INFO     | __main__:train:24 - Epoch: 0 Step: 6920 LR: 0.0009998851830267015 Training loss: 0.0
2025-12-09 10:23:35.942 | INFO     | __main__:train:24 - Epoch: 0 Step: 6921 LR: 0.0009998851493597924 Training loss: 0.0
2025-12-09 10:23:35.943 | INFO     | __main__:train:24 - Epoch: 0 Step: 6922 LR: 0.0009998851156879486 Training loss: 0.0
2025-12-09 10:23:35.944 | INFO     | __main__:train:24 - Epoch: 0 Step: 6923 LR: 0.00099988508201117 Training loss: 0.0
2025-12-09 10:23:35.945 | INFO     | __main__:train:24 - Epoch: 0 Step: 6924 LR: 0.000999885048329457 Training loss: 0.0
2025-12-09 10:23:35.946 | INFO     | __main__:train:24 - Epoch: 0 Step: 6925 LR: 0.0009998850146428094 Training loss: 0.0
2025-12-09 10:23:35.947 | INFO     | __main__:train:24 - Epoch: 0 Step: 6926 LR: 0.0009998849809512269 Training loss: 0.0
2025-12-09 10:23:35.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 6927 LR: 0.0009998849472547097 Training loss: 0.0
2025-12-09 10:23:35.948 | INFO     | __main__:train:24 - Epoch: 0 Step: 6928 LR: 0.0009998849135532581 Training loss: 0.0
2025-12-09 10:23:35.949 | INFO     | __main__:train:24 - Epoch: 0 Step: 6929 LR: 0.0009998848798468717 Training loss: 0.0
2025-12-09 10:23:35.950 | INFO     | __main__:train:24 - Epoch: 0 Step: 6930 LR: 0.0009998848461355507 Training loss: 0.0
2025-12-09 10:23:35.951 | INFO     | __main__:train:24 - Epoch: 0 Step: 6931 LR: 0.000999884812419295 Training loss: 0.0
2025-12-09 10:23:35.952 | INFO     | __main__:train:24 - Epoch: 0 Step: 6932 LR: 0.0009998847786981046 Training loss: 0.0
2025-12-09 10:23:35.953 | INFO     | __main__:train:24 - Epoch: 0 Step: 6933 LR: 0.0009998847449719797 Training loss: 0.0
2025-12-09 10:23:35.954 | INFO     | __main__:train:24 - Epoch: 0 Step: 6934 LR: 0.00099988471124092 Training loss: 0.0
2025-12-09 10:23:35.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 6935 LR: 0.0009998846775049258 Training loss: 0.0
2025-12-09 10:23:35.955 | INFO     | __main__:train:24 - Epoch: 0 Step: 6936 LR: 0.000999884643763997 Training loss: 0.0
2025-12-09 10:23:35.956 | INFO     | __main__:train:24 - Epoch: 0 Step: 6937 LR: 0.0009998846100181334 Training loss: 0.0
2025-12-09 10:23:35.957 | INFO     | __main__:train:24 - Epoch: 0 Step: 6938 LR: 0.000999884576267335 Training loss: 0.0
2025-12-09 10:23:35.958 | INFO     | __main__:train:24 - Epoch: 0 Step: 6939 LR: 0.0009998845425116022 Training loss: 0.0
2025-12-09 10:23:35.959 | INFO     | __main__:train:24 - Epoch: 0 Step: 6940 LR: 0.0009998845087509345 Training loss: 0.0
2025-12-09 10:23:35.960 | INFO     | __main__:train:24 - Epoch: 0 Step: 6941 LR: 0.0009998844749853325 Training loss: 0.0
2025-12-09 10:23:35.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 6942 LR: 0.0009998844412147955 Training loss: 0.0
2025-12-09 10:23:35.961 | INFO     | __main__:train:24 - Epoch: 0 Step: 6943 LR: 0.0009998844074393242 Training loss: 0.0
2025-12-09 10:23:35.962 | INFO     | __main__:train:24 - Epoch: 0 Step: 6944 LR: 0.000999884373658918 Training loss: 0.0
2025-12-09 10:23:35.963 | INFO     | __main__:train:24 - Epoch: 0 Step: 6945 LR: 0.0009998843398735773 Training loss: 0.0
2025-12-09 10:23:35.964 | INFO     | __main__:train:24 - Epoch: 0 Step: 6946 LR: 0.0009998843060833019 Training loss: 0.0
2025-12-09 10:23:35.965 | INFO     | __main__:train:24 - Epoch: 0 Step: 6947 LR: 0.0009998842722880917 Training loss: 0.0
2025-12-09 10:23:35.966 | INFO     | __main__:train:24 - Epoch: 0 Step: 6948 LR: 0.000999884238487947 Training loss: 0.0
2025-12-09 10:23:35.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 6949 LR: 0.0009998842046828676 Training loss: 0.0
2025-12-09 10:23:35.967 | INFO     | __main__:train:24 - Epoch: 0 Step: 6950 LR: 0.0009998841708728536 Training loss: 0.0
2025-12-09 10:23:35.968 | INFO     | __main__:train:24 - Epoch: 0 Step: 6951 LR: 0.000999884137057905 Training loss: 0.0
2025-12-09 10:23:35.969 | INFO     | __main__:train:24 - Epoch: 0 Step: 6952 LR: 0.0009998841032380218 Training loss: 0.0
2025-12-09 10:23:35.970 | INFO     | __main__:train:24 - Epoch: 0 Step: 6953 LR: 0.0009998840694132036 Training loss: 0.0
2025-12-09 10:23:35.971 | INFO     | __main__:train:24 - Epoch: 0 Step: 6954 LR: 0.000999884035583451 Training loss: 0.0
2025-12-09 10:23:35.972 | INFO     | __main__:train:24 - Epoch: 0 Step: 6955 LR: 0.0009998840017487638 Training loss: 0.0
2025-12-09 10:23:35.973 | INFO     | __main__:train:24 - Epoch: 0 Step: 6956 LR: 0.000999883967909142 Training loss: 0.0
2025-12-09 10:23:35.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 6957 LR: 0.0009998839340645855 Training loss: 0.0
2025-12-09 10:23:35.974 | INFO     | __main__:train:24 - Epoch: 0 Step: 6958 LR: 0.0009998839002150943 Training loss: 0.0
2025-12-09 10:23:35.975 | INFO     | __main__:train:24 - Epoch: 0 Step: 6959 LR: 0.0009998838663606686 Training loss: 0.0
2025-12-09 10:23:35.976 | INFO     | __main__:train:24 - Epoch: 0 Step: 6960 LR: 0.000999883832501308 Training loss: 0.0
2025-12-09 10:23:35.977 | INFO     | __main__:train:24 - Epoch: 0 Step: 6961 LR: 0.0009998837986370129 Training loss: 0.0
2025-12-09 10:23:35.978 | INFO     | __main__:train:24 - Epoch: 0 Step: 6962 LR: 0.0009998837647677832 Training loss: 0.0
2025-12-09 10:23:35.979 | INFO     | __main__:train:24 - Epoch: 0 Step: 6963 LR: 0.0009998837308936189 Training loss: 0.0
2025-12-09 10:23:35.980 | INFO     | __main__:train:24 - Epoch: 0 Step: 6964 LR: 0.0009998836970145197 Training loss: 0.0
2025-12-09 10:23:35.981 | INFO     | __main__:train:24 - Epoch: 0 Step: 6965 LR: 0.000999883663130486 Training loss: 0.0
2025-12-09 10:23:35.982 | INFO     | __main__:train:24 - Epoch: 0 Step: 6966 LR: 0.0009998836292415179 Training loss: 0.0
2025-12-09 10:23:35.983 | INFO     | __main__:train:24 - Epoch: 0 Step: 6967 LR: 0.0009998835953476148 Training loss: 0.0
2025-12-09 10:23:35.984 | INFO     | __main__:train:24 - Epoch: 0 Step: 6968 LR: 0.0009998835614487772 Training loss: 0.0
2025-12-09 10:23:35.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 6969 LR: 0.000999883527545005 Training loss: 0.0
2025-12-09 10:23:35.985 | INFO     | __main__:train:24 - Epoch: 0 Step: 6970 LR: 0.000999883493636298 Training loss: 0.0
2025-12-09 10:23:35.986 | INFO     | __main__:train:24 - Epoch: 0 Step: 6971 LR: 0.0009998834597226567 Training loss: 0.0
2025-12-09 10:23:35.987 | INFO     | __main__:train:24 - Epoch: 0 Step: 6972 LR: 0.0009998834258040806 Training loss: 0.0
2025-12-09 10:23:35.988 | INFO     | __main__:train:24 - Epoch: 0 Step: 6973 LR: 0.0009998833918805697 Training loss: 0.0
2025-12-09 10:23:35.989 | INFO     | __main__:train:24 - Epoch: 0 Step: 6974 LR: 0.0009998833579521243 Training loss: 0.0
2025-12-09 10:23:35.990 | INFO     | __main__:train:24 - Epoch: 0 Step: 6975 LR: 0.0009998833240187444 Training loss: 0.0
2025-12-09 10:23:35.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 6976 LR: 0.0009998832900804295 Training loss: 0.0
2025-12-09 10:23:35.991 | INFO     | __main__:train:24 - Epoch: 0 Step: 6977 LR: 0.0009998832561371803 Training loss: 0.0
2025-12-09 10:23:35.992 | INFO     | __main__:train:24 - Epoch: 0 Step: 6978 LR: 0.0009998832221889964 Training loss: 0.0
2025-12-09 10:23:35.993 | INFO     | __main__:train:24 - Epoch: 0 Step: 6979 LR: 0.0009998831882358776 Training loss: 0.0
2025-12-09 10:23:35.994 | INFO     | __main__:train:24 - Epoch: 0 Step: 6980 LR: 0.0009998831542778245 Training loss: 0.0
2025-12-09 10:23:35.995 | INFO     | __main__:train:24 - Epoch: 0 Step: 6981 LR: 0.0009998831203148367 Training loss: 0.0
2025-12-09 10:23:35.996 | INFO     | __main__:train:24 - Epoch: 0 Step: 6982 LR: 0.000999883086346914 Training loss: 0.0
2025-12-09 10:23:35.997 | INFO     | __main__:train:24 - Epoch: 0 Step: 6983 LR: 0.000999883052374057 Training loss: 0.0
2025-12-09 10:23:35.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 6984 LR: 0.000999883018396265 Training loss: 0.0
2025-12-09 10:23:35.998 | INFO     | __main__:train:24 - Epoch: 0 Step: 6985 LR: 0.0009998829844135386 Training loss: 0.0
2025-12-09 10:23:35.999 | INFO     | __main__:train:24 - Epoch: 0 Step: 6986 LR: 0.0009998829504258777 Training loss: 0.0
2025-12-09 10:23:36.000 | INFO     | __main__:train:24 - Epoch: 0 Step: 6987 LR: 0.000999882916433282 Training loss: 0.0
2025-12-09 10:23:36.001 | INFO     | __main__:train:24 - Epoch: 0 Step: 6988 LR: 0.0009998828824357518 Training loss: 0.0
2025-12-09 10:23:36.002 | INFO     | __main__:train:24 - Epoch: 0 Step: 6989 LR: 0.0009998828484332866 Training loss: 0.0
2025-12-09 10:23:36.003 | INFO     | __main__:train:24 - Epoch: 0 Step: 6990 LR: 0.000999882814425887 Training loss: 0.0
2025-12-09 10:23:36.004 | INFO     | __main__:train:24 - Epoch: 0 Step: 6991 LR: 0.000999882780413553 Training loss: 0.0
2025-12-09 10:23:36.005 | INFO     | __main__:train:24 - Epoch: 0 Step: 6992 LR: 0.000999882746396284 Training loss: 0.0
2025-12-09 10:23:36.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 6993 LR: 0.0009998827123740806 Training loss: 0.0
2025-12-09 10:23:36.006 | INFO     | __main__:train:24 - Epoch: 0 Step: 6994 LR: 0.0009998826783469425 Training loss: 0.0
2025-12-09 10:23:36.007 | INFO     | __main__:train:24 - Epoch: 0 Step: 6995 LR: 0.0009998826443148696 Training loss: 0.0
2025-12-09 10:23:36.008 | INFO     | __main__:train:24 - Epoch: 0 Step: 6996 LR: 0.0009998826102778622 Training loss: 0.0
2025-12-09 10:23:36.009 | INFO     | __main__:train:24 - Epoch: 0 Step: 6997 LR: 0.0009998825762359202 Training loss: 0.0
2025-12-09 10:23:36.010 | INFO     | __main__:train:24 - Epoch: 0 Step: 6998 LR: 0.0009998825421890436 Training loss: 0.0
2025-12-09 10:23:36.011 | INFO     | __main__:train:24 - Epoch: 0 Step: 6999 LR: 0.0009998825081372325 Training loss: 0.0
2025-12-09 10:23:36.012 | INFO     | __main__:train:24 - Epoch: 0 Step: 7000 LR: 0.0009998824740804866 Training loss: 0.0
2025-12-09 10:23:36.013 | INFO     | __main__:train:24 - Epoch: 0 Step: 7001 LR: 0.000999882440018806 Training loss: 0.0
2025-12-09 10:23:36.014 | INFO     | __main__:train:24 - Epoch: 0 Step: 7002 LR: 0.0009998824059521908 Training loss: 0.0
2025-12-09 10:23:36.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 7003 LR: 0.0009998823718806412 Training loss: 0.0
2025-12-09 10:23:36.015 | INFO     | __main__:train:24 - Epoch: 0 Step: 7004 LR: 0.0009998823378041565 Training loss: 0.0
2025-12-09 10:23:36.016 | INFO     | __main__:train:24 - Epoch: 0 Step: 7005 LR: 0.0009998823037227376 Training loss: 0.0
2025-12-09 10:23:36.017 | INFO     | __main__:train:24 - Epoch: 0 Step: 7006 LR: 0.0009998822696363839 Training loss: 0.0
2025-12-09 10:23:36.018 | INFO     | __main__:train:24 - Epoch: 0 Step: 7007 LR: 0.0009998822355450957 Training loss: 0.0
2025-12-09 10:23:36.019 | INFO     | __main__:train:24 - Epoch: 0 Step: 7008 LR: 0.0009998822014488727 Training loss: 0.0
2025-12-09 10:23:36.020 | INFO     | __main__:train:24 - Epoch: 0 Step: 7009 LR: 0.0009998821673477152 Training loss: 0.0
2025-12-09 10:23:36.021 | INFO     | __main__:train:24 - Epoch: 0 Step: 7010 LR: 0.000999882133241623 Training loss: 0.0
2025-12-09 10:23:36.022 | INFO     | __main__:train:24 - Epoch: 0 Step: 7011 LR: 0.0009998820991305962 Training loss: 0.0
2025-12-09 10:23:36.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 7012 LR: 0.0009998820650146348 Training loss: 0.0
2025-12-09 10:23:36.023 | INFO     | __main__:train:24 - Epoch: 0 Step: 7013 LR: 0.0009998820308937389 Training loss: 0.0
2025-12-09 10:23:36.024 | INFO     | __main__:train:24 - Epoch: 0 Step: 7014 LR: 0.000999881996767908 Training loss: 0.0
2025-12-09 10:23:36.025 | INFO     | __main__:train:24 - Epoch: 0 Step: 7015 LR: 0.0009998819626371427 Training loss: 0.0
2025-12-09 10:23:36.026 | INFO     | __main__:train:24 - Epoch: 0 Step: 7016 LR: 0.0009998819285014428 Training loss: 0.0
2025-12-09 10:23:36.027 | INFO     | __main__:train:24 - Epoch: 0 Step: 7017 LR: 0.0009998818943608083 Training loss: 0.0
2025-12-09 10:23:36.028 | INFO     | __main__:train:24 - Epoch: 0 Step: 7018 LR: 0.000999881860215239 Training loss: 0.0
2025-12-09 10:23:36.029 | INFO     | __main__:train:24 - Epoch: 0 Step: 7019 LR: 0.0009998818260647353 Training loss: 0.0
2025-12-09 10:23:36.030 | INFO     | __main__:train:24 - Epoch: 0 Step: 7020 LR: 0.000999881791909297 Training loss: 0.0
2025-12-09 10:23:36.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 7021 LR: 0.000999881757748924 Training loss: 0.0
2025-12-09 10:23:36.031 | INFO     | __main__:train:24 - Epoch: 0 Step: 7022 LR: 0.0009998817235836162 Training loss: 0.0
2025-12-09 10:23:36.032 | INFO     | __main__:train:24 - Epoch: 0 Step: 7023 LR: 0.000999881689413374 Training loss: 0.0
2025-12-09 10:23:36.033 | INFO     | __main__:train:24 - Epoch: 0 Step: 7024 LR: 0.000999881655238197 Training loss: 0.0
2025-12-09 10:23:36.034 | INFO     | __main__:train:24 - Epoch: 0 Step: 7025 LR: 0.0009998816210580854 Training loss: 0.0
2025-12-09 10:23:36.035 | INFO     | __main__:train:24 - Epoch: 0 Step: 7026 LR: 0.0009998815868730393 Training loss: 0.0
2025-12-09 10:23:36.036 | INFO     | __main__:train:24 - Epoch: 0 Step: 7027 LR: 0.0009998815526830586 Training loss: 0.0
2025-12-09 10:23:36.037 | INFO     | __main__:train:24 - Epoch: 0 Step: 7028 LR: 0.0009998815184881433 Training loss: 0.0
2025-12-09 10:23:36.038 | INFO     | __main__:train:24 - Epoch: 0 Step: 7029 LR: 0.0009998814842882933 Training loss: 0.0
2025-12-09 10:23:36.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 7030 LR: 0.0009998814500835086 Training loss: 0.0
2025-12-09 10:23:36.039 | INFO     | __main__:train:24 - Epoch: 0 Step: 7031 LR: 0.0009998814158737894 Training loss: 0.0
2025-12-09 10:23:36.040 | INFO     | __main__:train:24 - Epoch: 0 Step: 7032 LR: 0.0009998813816591355 Training loss: 0.0
2025-12-09 10:23:36.041 | INFO     | __main__:train:24 - Epoch: 0 Step: 7033 LR: 0.000999881347439547 Training loss: 0.0
2025-12-09 10:23:36.042 | INFO     | __main__:train:24 - Epoch: 0 Step: 7034 LR: 0.000999881313215024 Training loss: 0.0
2025-12-09 10:23:36.043 | INFO     | __main__:train:24 - Epoch: 0 Step: 7035 LR: 0.0009998812789855662 Training loss: 0.0
2025-12-09 10:23:36.044 | INFO     | __main__:train:24 - Epoch: 0 Step: 7036 LR: 0.0009998812447511737 Training loss: 0.0
2025-12-09 10:23:36.045 | INFO     | __main__:train:24 - Epoch: 0 Step: 7037 LR: 0.0009998812105118469 Training loss: 0.0
2025-12-09 10:23:36.046 | INFO     | __main__:train:24 - Epoch: 0 Step: 7038 LR: 0.0009998811762675854 Training loss: 0.0
2025-12-09 10:23:36.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 7039 LR: 0.0009998811420183892 Training loss: 0.0
2025-12-09 10:23:36.047 | INFO     | __main__:train:24 - Epoch: 0 Step: 7040 LR: 0.0009998811077642584 Training loss: 0.0
2025-12-09 10:23:36.048 | INFO     | __main__:train:24 - Epoch: 0 Step: 7041 LR: 0.000999881073505193 Training loss: 0.0
2025-12-09 10:23:36.049 | INFO     | __main__:train:24 - Epoch: 0 Step: 7042 LR: 0.000999881039241193 Training loss: 0.0
2025-12-09 10:23:36.050 | INFO     | __main__:train:24 - Epoch: 0 Step: 7043 LR: 0.0009998810049722583 Training loss: 0.0
2025-12-09 10:23:36.051 | INFO     | __main__:train:24 - Epoch: 0 Step: 7044 LR: 0.000999880970698389 Training loss: 0.0
2025-12-09 10:23:36.052 | INFO     | __main__:train:24 - Epoch: 0 Step: 7045 LR: 0.0009998809364195852 Training loss: 0.0
2025-12-09 10:23:36.053 | INFO     | __main__:train:24 - Epoch: 0 Step: 7046 LR: 0.0009998809021358466 Training loss: 0.0
2025-12-09 10:23:36.054 | INFO     | __main__:train:24 - Epoch: 0 Step: 7047 LR: 0.0009998808678471735 Training loss: 0.0
2025-12-09 10:23:36.055 | INFO     | __main__:train:24 - Epoch: 0 Step: 7048 LR: 0.0009998808335535659 Training loss: 0.0
2025-12-09 10:23:36.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 7049 LR: 0.0009998807992550236 Training loss: 0.0
2025-12-09 10:23:36.056 | INFO     | __main__:train:24 - Epoch: 0 Step: 7050 LR: 0.0009998807649515466 Training loss: 0.0
2025-12-09 10:23:36.057 | INFO     | __main__:train:24 - Epoch: 0 Step: 7051 LR: 0.000999880730643135 Training loss: 0.0
2025-12-09 10:23:36.058 | INFO     | __main__:train:24 - Epoch: 0 Step: 7052 LR: 0.0009998806963297888 Training loss: 0.0
2025-12-09 10:23:36.059 | INFO     | __main__:train:24 - Epoch: 0 Step: 7053 LR: 0.000999880662011508 Training loss: 0.0
2025-12-09 10:23:36.060 | INFO     | __main__:train:24 - Epoch: 0 Step: 7054 LR: 0.0009998806276882927 Training loss: 0.0
2025-12-09 10:23:36.061 | INFO     | __main__:train:24 - Epoch: 0 Step: 7055 LR: 0.0009998805933601428 Training loss: 0.0
2025-12-09 10:23:36.062 | INFO     | __main__:train:24 - Epoch: 0 Step: 7056 LR: 0.000999880559027058 Training loss: 0.0
2025-12-09 10:23:36.063 | INFO     | __main__:train:24 - Epoch: 0 Step: 7057 LR: 0.0009998805246890388 Training loss: 0.0
2025-12-09 10:23:36.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 7058 LR: 0.000999880490346085 Training loss: 0.0
2025-12-09 10:23:36.064 | INFO     | __main__:train:24 - Epoch: 0 Step: 7059 LR: 0.0009998804559981968 Training loss: 0.0
2025-12-09 10:23:36.065 | INFO     | __main__:train:24 - Epoch: 0 Step: 7060 LR: 0.0009998804216453736 Training loss: 0.0
2025-12-09 10:23:36.066 | INFO     | __main__:train:24 - Epoch: 0 Step: 7061 LR: 0.000999880387287616 Training loss: 0.0
2025-12-09 10:23:36.067 | INFO     | __main__:train:24 - Epoch: 0 Step: 7062 LR: 0.0009998803529249235 Training loss: 0.0
2025-12-09 10:23:36.068 | INFO     | __main__:train:24 - Epoch: 0 Step: 7063 LR: 0.0009998803185572967 Training loss: 0.0
2025-12-09 10:23:36.069 | INFO     | __main__:train:24 - Epoch: 0 Step: 7064 LR: 0.0009998802841847353 Training loss: 0.0
2025-12-09 10:23:36.070 | INFO     | __main__:train:24 - Epoch: 0 Step: 7065 LR: 0.0009998802498072392 Training loss: 0.0
2025-12-09 10:23:36.071 | INFO     | __main__:train:24 - Epoch: 0 Step: 7066 LR: 0.0009998802154248085 Training loss: 0.0
2025-12-09 10:23:36.072 | INFO     | __main__:train:24 - Epoch: 0 Step: 7067 LR: 0.0009998801810374431 Training loss: 0.0
2025-12-09 10:23:36.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 7068 LR: 0.0009998801466451432 Training loss: 0.0
2025-12-09 10:23:36.073 | INFO     | __main__:train:24 - Epoch: 0 Step: 7069 LR: 0.0009998801122479088 Training loss: 0.0
2025-12-09 10:23:36.074 | INFO     | __main__:train:24 - Epoch: 0 Step: 7070 LR: 0.0009998800778457397 Training loss: 0.0
2025-12-09 10:23:36.075 | INFO     | __main__:train:24 - Epoch: 0 Step: 7071 LR: 0.000999880043438636 Training loss: 0.0
2025-12-09 10:23:36.076 | INFO     | __main__:train:24 - Epoch: 0 Step: 7072 LR: 0.0009998800090265977 Training loss: 0.0
2025-12-09 10:23:36.077 | INFO     | __main__:train:24 - Epoch: 0 Step: 7073 LR: 0.0009998799746096247 Training loss: 0.0
2025-12-09 10:23:36.078 | INFO     | __main__:train:24 - Epoch: 0 Step: 7074 LR: 0.0009998799401877171 Training loss: 0.0
2025-12-09 10:23:36.079 | INFO     | __main__:train:24 - Epoch: 0 Step: 7075 LR: 0.000999879905760875 Training loss: 0.0
2025-12-09 10:23:36.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 7076 LR: 0.0009998798713290982 Training loss: 0.0
2025-12-09 10:23:36.080 | INFO     | __main__:train:24 - Epoch: 0 Step: 7077 LR: 0.000999879836892387 Training loss: 0.0
2025-12-09 10:23:36.081 | INFO     | __main__:train:24 - Epoch: 0 Step: 7078 LR: 0.000999879802450741 Training loss: 0.0
2025-12-09 10:23:36.082 | INFO     | __main__:train:24 - Epoch: 0 Step: 7079 LR: 0.0009998797680041604 Training loss: 0.0
2025-12-09 10:23:36.083 | INFO     | __main__:train:24 - Epoch: 0 Step: 7080 LR: 0.0009998797335526452 Training loss: 0.0
2025-12-09 10:23:36.084 | INFO     | __main__:train:24 - Epoch: 0 Step: 7081 LR: 0.0009998796990961954 Training loss: 0.0
2025-12-09 10:23:36.085 | INFO     | __main__:train:24 - Epoch: 0 Step: 7082 LR: 0.0009998796646348111 Training loss: 0.0
2025-12-09 10:23:36.086 | INFO     | __main__:train:24 - Epoch: 0 Step: 7083 LR: 0.000999879630168492 Training loss: 0.0
2025-12-09 10:23:36.087 | INFO     | __main__:train:24 - Epoch: 0 Step: 7084 LR: 0.0009998795956972385 Training loss: 0.0
2025-12-09 10:23:36.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 7085 LR: 0.0009998795612210503 Training loss: 0.0
2025-12-09 10:23:36.088 | INFO     | __main__:train:24 - Epoch: 0 Step: 7086 LR: 0.0009998795267399277 Training loss: 0.0
2025-12-09 10:23:36.089 | INFO     | __main__:train:24 - Epoch: 0 Step: 7087 LR: 0.0009998794922538702 Training loss: 0.0
2025-12-09 10:23:36.090 | INFO     | __main__:train:24 - Epoch: 0 Step: 7088 LR: 0.0009998794577628783 Training loss: 0.0
2025-12-09 10:23:36.091 | INFO     | __main__:train:24 - Epoch: 0 Step: 7089 LR: 0.0009998794232669516 Training loss: 0.0
2025-12-09 10:23:36.092 | INFO     | __main__:train:24 - Epoch: 0 Step: 7090 LR: 0.0009998793887660905 Training loss: 0.0
2025-12-09 10:23:36.093 | INFO     | __main__:train:24 - Epoch: 0 Step: 7091 LR: 0.0009998793542602947 Training loss: 0.0
2025-12-09 10:23:36.094 | INFO     | __main__:train:24 - Epoch: 0 Step: 7092 LR: 0.0009998793197495645 Training loss: 0.0
2025-12-09 10:23:36.095 | INFO     | __main__:train:24 - Epoch: 0 Step: 7093 LR: 0.0009998792852338994 Training loss: 0.0
2025-12-09 10:23:36.096 | INFO     | __main__:train:24 - Epoch: 0 Step: 7094 LR: 0.0009998792507133 Training loss: 0.0
2025-12-09 10:23:36.097 | INFO     | __main__:train:24 - Epoch: 0 Step: 7095 LR: 0.0009998792161877656 Training loss: 0.0
2025-12-09 10:23:36.098 | INFO     | __main__:train:24 - Epoch: 0 Step: 7096 LR: 0.000999879181657297 Training loss: 0.0
2025-12-09 10:23:36.099 | INFO     | __main__:train:24 - Epoch: 0 Step: 7097 LR: 0.0009998791471218936 Training loss: 0.0
2025-12-09 10:23:36.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 7098 LR: 0.0009998791125815556 Training loss: 0.0
2025-12-09 10:23:36.100 | INFO     | __main__:train:24 - Epoch: 0 Step: 7099 LR: 0.0009998790780362831 Training loss: 0.0
2025-12-09 10:23:36.101 | INFO     | __main__:train:24 - Epoch: 0 Step: 7100 LR: 0.000999879043486076 Training loss: 0.0
2025-12-09 10:23:36.102 | INFO     | __main__:train:24 - Epoch: 0 Step: 7101 LR: 0.0009998790089309343 Training loss: 0.0
2025-12-09 10:23:36.103 | INFO     | __main__:train:24 - Epoch: 0 Step: 7102 LR: 0.000999878974370858 Training loss: 0.0
2025-12-09 10:23:36.104 | INFO     | __main__:train:24 - Epoch: 0 Step: 7103 LR: 0.000999878939805847 Training loss: 0.0
2025-12-09 10:23:36.105 | INFO     | __main__:train:24 - Epoch: 0 Step: 7104 LR: 0.0009998789052359015 Training loss: 0.0
2025-12-09 10:23:36.106 | INFO     | __main__:train:24 - Epoch: 0 Step: 7105 LR: 0.0009998788706610214 Training loss: 0.0
2025-12-09 10:23:36.107 | INFO     | __main__:train:24 - Epoch: 0 Step: 7106 LR: 0.0009998788360812067 Training loss: 0.0
2025-12-09 10:23:36.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 7107 LR: 0.0009998788014964574 Training loss: 0.0
2025-12-09 10:23:36.108 | INFO     | __main__:train:24 - Epoch: 0 Step: 7108 LR: 0.0009998787669067734 Training loss: 0.0
2025-12-09 10:23:36.109 | INFO     | __main__:train:24 - Epoch: 0 Step: 7109 LR: 0.000999878732312155 Training loss: 0.0
2025-12-09 10:23:36.110 | INFO     | __main__:train:24 - Epoch: 0 Step: 7110 LR: 0.000999878697712602 Training loss: 0.0
2025-12-09 10:23:36.111 | INFO     | __main__:train:24 - Epoch: 0 Step: 7111 LR: 0.0009998786631081143 Training loss: 0.0
2025-12-09 10:23:36.112 | INFO     | __main__:train:24 - Epoch: 0 Step: 7112 LR: 0.000999878628498692 Training loss: 0.0
2025-12-09 10:23:36.113 | INFO     | __main__:train:24 - Epoch: 0 Step: 7113 LR: 0.0009998785938843352 Training loss: 0.0
2025-12-09 10:23:36.114 | INFO     | __main__:train:24 - Epoch: 0 Step: 7114 LR: 0.0009998785592650436 Training loss: 0.0
2025-12-09 10:23:36.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 7115 LR: 0.0009998785246408178 Training loss: 0.0
2025-12-09 10:23:36.115 | INFO     | __main__:train:24 - Epoch: 0 Step: 7116 LR: 0.0009998784900116572 Training loss: 0.0
2025-12-09 10:23:36.116 | INFO     | __main__:train:24 - Epoch: 0 Step: 7117 LR: 0.0009998784553775619 Training loss: 0.0
2025-12-09 10:23:36.117 | INFO     | __main__:train:24 - Epoch: 0 Step: 7118 LR: 0.0009998784207385322 Training loss: 0.0
2025-12-09 10:23:36.118 | INFO     | __main__:train:24 - Epoch: 0 Step: 7119 LR: 0.0009998783860945676 Training loss: 0.0
2025-12-09 10:23:36.119 | INFO     | __main__:train:24 - Epoch: 0 Step: 7120 LR: 0.0009998783514456686 Training loss: 0.0
2025-12-09 10:23:36.120 | INFO     | __main__:train:24 - Epoch: 0 Step: 7121 LR: 0.000999878316791835 Training loss: 0.0
2025-12-09 10:23:36.121 | INFO     | __main__:train:24 - Epoch: 0 Step: 7122 LR: 0.000999878282133067 Training loss: 0.0
2025-12-09 10:23:36.122 | INFO     | __main__:train:24 - Epoch: 0 Step: 7123 LR: 0.0009998782474693643 Training loss: 0.0
2025-12-09 10:23:36.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 7124 LR: 0.000999878212800727 Training loss: 0.0
2025-12-09 10:23:36.123 | INFO     | __main__:train:24 - Epoch: 0 Step: 7125 LR: 0.000999878178127155 Training loss: 0.0
2025-12-09 10:23:36.124 | INFO     | __main__:train:24 - Epoch: 0 Step: 7126 LR: 0.0009998781434486484 Training loss: 0.0
2025-12-09 10:23:36.125 | INFO     | __main__:train:24 - Epoch: 0 Step: 7127 LR: 0.0009998781087652074 Training loss: 0.0
2025-12-09 10:23:36.126 | INFO     | __main__:train:24 - Epoch: 0 Step: 7128 LR: 0.0009998780740768315 Training loss: 0.0
2025-12-09 10:23:36.127 | INFO     | __main__:train:24 - Epoch: 0 Step: 7129 LR: 0.0009998780393835215 Training loss: 0.0
2025-12-09 10:23:36.128 | INFO     | __main__:train:24 - Epoch: 0 Step: 7130 LR: 0.0009998780046852765 Training loss: 0.0
2025-12-09 10:23:36.129 | INFO     | __main__:train:24 - Epoch: 0 Step: 7131 LR: 0.0009998779699820972 Training loss: 0.0
2025-12-09 10:23:36.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 7132 LR: 0.000999877935273983 Training loss: 0.0
2025-12-09 10:23:36.130 | INFO     | __main__:train:24 - Epoch: 0 Step: 7133 LR: 0.0009998779005609346 Training loss: 0.0
2025-12-09 10:23:36.131 | INFO     | __main__:train:24 - Epoch: 0 Step: 7134 LR: 0.0009998778658429513 Training loss: 0.0
2025-12-09 10:23:36.132 | INFO     | __main__:train:24 - Epoch: 0 Step: 7135 LR: 0.0009998778311200336 Training loss: 0.0
2025-12-09 10:23:36.133 | INFO     | __main__:train:24 - Epoch: 0 Step: 7136 LR: 0.0009998777963921813 Training loss: 0.0
2025-12-09 10:23:36.134 | INFO     | __main__:train:24 - Epoch: 0 Step: 7137 LR: 0.0009998777616593943 Training loss: 0.0
2025-12-09 10:23:36.135 | INFO     | __main__:train:24 - Epoch: 0 Step: 7138 LR: 0.0009998777269216727 Training loss: 0.0
2025-12-09 10:23:36.136 | INFO     | __main__:train:24 - Epoch: 0 Step: 7139 LR: 0.0009998776921790167 Training loss: 0.0
2025-12-09 10:23:36.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 7140 LR: 0.000999877657431426 Training loss: 0.0
2025-12-09 10:23:36.137 | INFO     | __main__:train:24 - Epoch: 0 Step: 7141 LR: 0.0009998776226789008 Training loss: 0.0
2025-12-09 10:23:36.138 | INFO     | __main__:train:24 - Epoch: 0 Step: 7142 LR: 0.0009998775879214408 Training loss: 0.0
2025-12-09 10:23:36.139 | INFO     | __main__:train:24 - Epoch: 0 Step: 7143 LR: 0.0009998775531590465 Training loss: 0.0
2025-12-09 10:23:36.140 | INFO     | __main__:train:24 - Epoch: 0 Step: 7144 LR: 0.0009998775183917175 Training loss: 0.0
2025-12-09 10:23:36.141 | INFO     | __main__:train:24 - Epoch: 0 Step: 7145 LR: 0.0009998774836194539 Training loss: 0.0
2025-12-09 10:23:36.142 | INFO     | __main__:train:24 - Epoch: 0 Step: 7146 LR: 0.0009998774488422558 Training loss: 0.0
2025-12-09 10:23:36.143 | INFO     | __main__:train:24 - Epoch: 0 Step: 7147 LR: 0.000999877414060123 Training loss: 0.0
2025-12-09 10:23:36.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 7148 LR: 0.0009998773792730556 Training loss: 0.0
2025-12-09 10:23:36.144 | INFO     | __main__:train:24 - Epoch: 0 Step: 7149 LR: 0.0009998773444810536 Training loss: 0.0
2025-12-09 10:23:36.145 | INFO     | __main__:train:24 - Epoch: 0 Step: 7150 LR: 0.0009998773096841173 Training loss: 0.0
2025-12-09 10:23:36.146 | INFO     | __main__:train:24 - Epoch: 0 Step: 7151 LR: 0.0009998772748822462 Training loss: 0.0
2025-12-09 10:23:36.147 | INFO     | __main__:train:24 - Epoch: 0 Step: 7152 LR: 0.0009998772400754406 Training loss: 0.0
2025-12-09 10:23:36.148 | INFO     | __main__:train:24 - Epoch: 0 Step: 7153 LR: 0.0009998772052637003 Training loss: 0.0
2025-12-09 10:23:36.149 | INFO     | __main__:train:24 - Epoch: 0 Step: 7154 LR: 0.0009998771704470256 Training loss: 0.0
2025-12-09 10:23:36.150 | INFO     | __main__:train:24 - Epoch: 0 Step: 7155 LR: 0.0009998771356254162 Training loss: 0.0
2025-12-09 10:23:36.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 7156 LR: 0.0009998771007988722 Training loss: 0.0
2025-12-09 10:23:36.151 | INFO     | __main__:train:24 - Epoch: 0 Step: 7157 LR: 0.0009998770659673938 Training loss: 0.0
2025-12-09 10:23:36.152 | INFO     | __main__:train:24 - Epoch: 0 Step: 7158 LR: 0.0009998770311309805 Training loss: 0.0
2025-12-09 10:23:36.153 | INFO     | __main__:train:24 - Epoch: 0 Step: 7159 LR: 0.0009998769962896328 Training loss: 0.0
2025-12-09 10:23:36.154 | INFO     | __main__:train:24 - Epoch: 0 Step: 7160 LR: 0.0009998769614433507 Training loss: 0.0
2025-12-09 10:23:36.155 | INFO     | __main__:train:24 - Epoch: 0 Step: 7161 LR: 0.0009998769265921338 Training loss: 0.0
2025-12-09 10:23:36.156 | INFO     | __main__:train:24 - Epoch: 0 Step: 7162 LR: 0.0009998768917359824 Training loss: 0.0
2025-12-09 10:23:36.157 | INFO     | __main__:train:24 - Epoch: 0 Step: 7163 LR: 0.0009998768568748964 Training loss: 0.0
2025-12-09 10:23:36.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 7164 LR: 0.000999876822008876 Training loss: 0.0
2025-12-09 10:23:36.158 | INFO     | __main__:train:24 - Epoch: 0 Step: 7165 LR: 0.0009998767871379208 Training loss: 0.0
2025-12-09 10:23:36.159 | INFO     | __main__:train:24 - Epoch: 0 Step: 7166 LR: 0.0009998767522620311 Training loss: 0.0
2025-12-09 10:23:36.160 | INFO     | __main__:train:24 - Epoch: 0 Step: 7167 LR: 0.000999876717381207 Training loss: 0.0
2025-12-09 10:23:36.161 | INFO     | __main__:train:24 - Epoch: 0 Step: 7168 LR: 0.000999876682495448 Training loss: 0.0
2025-12-09 10:23:36.162 | INFO     | __main__:train:24 - Epoch: 0 Step: 7169 LR: 0.0009998766476047546 Training loss: 0.0
2025-12-09 10:23:36.163 | INFO     | __main__:train:24 - Epoch: 0 Step: 7170 LR: 0.0009998766127091265 Training loss: 0.0
2025-12-09 10:23:36.164 | INFO     | __main__:train:24 - Epoch: 0 Step: 7171 LR: 0.000999876577808564 Training loss: 0.0
2025-12-09 10:23:36.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 7172 LR: 0.000999876542903067 Training loss: 0.0
2025-12-09 10:23:36.165 | INFO     | __main__:train:24 - Epoch: 0 Step: 7173 LR: 0.0009998765079926354 Training loss: 0.0
2025-12-09 10:23:36.166 | INFO     | __main__:train:24 - Epoch: 0 Step: 7174 LR: 0.000999876473077269 Training loss: 0.0
2025-12-09 10:23:36.167 | INFO     | __main__:train:24 - Epoch: 0 Step: 7175 LR: 0.0009998764381569682 Training loss: 0.0
2025-12-09 10:23:36.168 | INFO     | __main__:train:24 - Epoch: 0 Step: 7176 LR: 0.0009998764032317327 Training loss: 0.0
2025-12-09 10:23:36.169 | INFO     | __main__:train:24 - Epoch: 0 Step: 7177 LR: 0.0009998763683015629 Training loss: 0.0
2025-12-09 10:23:36.170 | INFO     | __main__:train:24 - Epoch: 0 Step: 7178 LR: 0.0009998763333664582 Training loss: 0.0
2025-12-09 10:23:36.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 7179 LR: 0.0009998762984264192 Training loss: 0.0
2025-12-09 10:23:36.171 | INFO     | __main__:train:24 - Epoch: 0 Step: 7180 LR: 0.0009998762634814454 Training loss: 0.0
2025-12-09 10:23:36.172 | INFO     | __main__:train:24 - Epoch: 0 Step: 7181 LR: 0.0009998762285315372 Training loss: 0.0
2025-12-09 10:23:36.173 | INFO     | __main__:train:24 - Epoch: 0 Step: 7182 LR: 0.0009998761935766944 Training loss: 0.0
2025-12-09 10:23:36.174 | INFO     | __main__:train:24 - Epoch: 0 Step: 7183 LR: 0.000999876158616917 Training loss: 0.0
2025-12-09 10:23:36.175 | INFO     | __main__:train:24 - Epoch: 0 Step: 7184 LR: 0.000999876123652205 Training loss: 0.0
2025-12-09 10:23:36.176 | INFO     | __main__:train:24 - Epoch: 0 Step: 7185 LR: 0.0009998760886825585 Training loss: 0.0
2025-12-09 10:23:36.177 | INFO     | __main__:train:24 - Epoch: 0 Step: 7186 LR: 0.0009998760537079773 Training loss: 0.0
2025-12-09 10:23:36.178 | INFO     | __main__:train:24 - Epoch: 0 Step: 7187 LR: 0.0009998760187284617 Training loss: 0.0
2025-12-09 10:23:36.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 7188 LR: 0.0009998759837440117 Training loss: 0.0
2025-12-09 10:23:36.179 | INFO     | __main__:train:24 - Epoch: 0 Step: 7189 LR: 0.0009998759487546268 Training loss: 0.0
2025-12-09 10:23:36.180 | INFO     | __main__:train:24 - Epoch: 0 Step: 7190 LR: 0.0009998759137603075 Training loss: 0.0
2025-12-09 10:23:36.181 | INFO     | __main__:train:24 - Epoch: 0 Step: 7191 LR: 0.0009998758787610536 Training loss: 0.0
2025-12-09 10:23:36.182 | INFO     | __main__:train:24 - Epoch: 0 Step: 7192 LR: 0.000999875843756865 Training loss: 0.0
2025-12-09 10:23:36.183 | INFO     | __main__:train:24 - Epoch: 0 Step: 7193 LR: 0.000999875808747742 Training loss: 0.0
2025-12-09 10:23:36.184 | INFO     | __main__:train:24 - Epoch: 0 Step: 7194 LR: 0.0009998757737336844 Training loss: 0.0
2025-12-09 10:23:36.185 | INFO     | __main__:train:24 - Epoch: 0 Step: 7195 LR: 0.0009998757387146924 Training loss: 0.0
2025-12-09 10:23:36.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 7196 LR: 0.0009998757036907655 Training loss: 0.0
2025-12-09 10:23:36.186 | INFO     | __main__:train:24 - Epoch: 0 Step: 7197 LR: 0.0009998756686619044 Training loss: 0.0
2025-12-09 10:23:36.187 | INFO     | __main__:train:24 - Epoch: 0 Step: 7198 LR: 0.0009998756336281084 Training loss: 0.0
2025-12-09 10:23:36.188 | INFO     | __main__:train:24 - Epoch: 0 Step: 7199 LR: 0.000999875598589378 Training loss: 0.0
2025-12-09 10:23:36.189 | INFO     | __main__:train:24 - Epoch: 0 Step: 7200 LR: 0.000999875563545713 Training loss: 0.0
2025-12-09 10:23:36.190 | INFO     | __main__:train:24 - Epoch: 0 Step: 7201 LR: 0.0009998755284971136 Training loss: 0.0
2025-12-09 10:23:36.191 | INFO     | __main__:train:24 - Epoch: 0 Step: 7202 LR: 0.0009998754934435795 Training loss: 0.0
2025-12-09 10:23:36.192 | INFO     | __main__:train:24 - Epoch: 0 Step: 7203 LR: 0.0009998754583851108 Training loss: 0.0
2025-12-09 10:23:36.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 7204 LR: 0.0009998754233217077 Training loss: 0.0
2025-12-09 10:23:36.193 | INFO     | __main__:train:24 - Epoch: 0 Step: 7205 LR: 0.0009998753882533697 Training loss: 0.0
2025-12-09 10:23:36.194 | INFO     | __main__:train:24 - Epoch: 0 Step: 7206 LR: 0.0009998753531800975 Training loss: 0.0
2025-12-09 10:23:36.195 | INFO     | __main__:train:24 - Epoch: 0 Step: 7207 LR: 0.0009998753181018906 Training loss: 0.0
2025-12-09 10:23:36.196 | INFO     | __main__:train:24 - Epoch: 0 Step: 7208 LR: 0.0009998752830187492 Training loss: 0.0
2025-12-09 10:23:36.197 | INFO     | __main__:train:24 - Epoch: 0 Step: 7209 LR: 0.0009998752479306733 Training loss: 0.0
2025-12-09 10:23:36.198 | INFO     | __main__:train:24 - Epoch: 0 Step: 7210 LR: 0.0009998752128376625 Training loss: 0.0
2025-12-09 10:23:36.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 7211 LR: 0.0009998751777397174 Training loss: 0.0
2025-12-09 10:23:36.199 | INFO     | __main__:train:24 - Epoch: 0 Step: 7212 LR: 0.0009998751426368378 Training loss: 0.0
2025-12-09 10:23:36.200 | INFO     | __main__:train:24 - Epoch: 0 Step: 7213 LR: 0.0009998751075290236 Training loss: 0.0
2025-12-09 10:23:36.201 | INFO     | __main__:train:24 - Epoch: 0 Step: 7214 LR: 0.000999875072416275 Training loss: 0.0
2025-12-09 10:23:36.202 | INFO     | __main__:train:24 - Epoch: 0 Step: 7215 LR: 0.0009998750372985914 Training loss: 0.0
2025-12-09 10:23:36.203 | INFO     | __main__:train:24 - Epoch: 0 Step: 7216 LR: 0.0009998750021759735 Training loss: 0.0
2025-12-09 10:23:36.204 | INFO     | __main__:train:24 - Epoch: 0 Step: 7217 LR: 0.0009998749670484211 Training loss: 0.0
2025-12-09 10:23:36.205 | INFO     | __main__:train:24 - Epoch: 0 Step: 7218 LR: 0.000999874931915934 Training loss: 0.0
2025-12-09 10:23:36.206 | INFO     | __main__:train:24 - Epoch: 0 Step: 7219 LR: 0.0009998748967785125 Training loss: 0.0
2025-12-09 10:23:36.207 | INFO     | __main__:train:24 - Epoch: 0 Step: 7220 LR: 0.0009998748616361563 Training loss: 0.0
2025-12-09 10:23:36.208 | INFO     | __main__:train:24 - Epoch: 0 Step: 7221 LR: 0.0009998748264888658 Training loss: 0.0
2025-12-09 10:23:36.209 | INFO     | __main__:train:24 - Epoch: 0 Step: 7222 LR: 0.0009998747913366403 Training loss: 0.0
2025-12-09 10:23:36.210 | INFO     | __main__:train:24 - Epoch: 0 Step: 7223 LR: 0.0009998747561794808 Training loss: 0.0
2025-12-09 10:23:36.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 7224 LR: 0.0009998747210173864 Training loss: 0.0
2025-12-09 10:23:36.211 | INFO     | __main__:train:24 - Epoch: 0 Step: 7225 LR: 0.0009998746858503574 Training loss: 0.0
2025-12-09 10:23:36.212 | INFO     | __main__:train:24 - Epoch: 0 Step: 7226 LR: 0.000999874650678394 Training loss: 0.0
2025-12-09 10:23:36.213 | INFO     | __main__:train:24 - Epoch: 0 Step: 7227 LR: 0.000999874615501496 Training loss: 0.0
2025-12-09 10:23:36.214 | INFO     | __main__:train:24 - Epoch: 0 Step: 7228 LR: 0.0009998745803196634 Training loss: 0.0
2025-12-09 10:23:36.215 | INFO     | __main__:train:24 - Epoch: 0 Step: 7229 LR: 0.0009998745451328963 Training loss: 0.0
2025-12-09 10:23:36.216 | INFO     | __main__:train:24 - Epoch: 0 Step: 7230 LR: 0.0009998745099411947 Training loss: 0.0
2025-12-09 10:23:36.217 | INFO     | __main__:train:24 - Epoch: 0 Step: 7231 LR: 0.0009998744747445585 Training loss: 0.0
2025-12-09 10:23:36.218 | INFO     | __main__:train:24 - Epoch: 0 Step: 7232 LR: 0.0009998744395429877 Training loss: 0.0
2025-12-09 10:23:36.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 7233 LR: 0.0009998744043364825 Training loss: 0.0
2025-12-09 10:23:36.219 | INFO     | __main__:train:24 - Epoch: 0 Step: 7234 LR: 0.0009998743691250428 Training loss: 0.0
2025-12-09 10:23:36.220 | INFO     | __main__:train:24 - Epoch: 0 Step: 7235 LR: 0.0009998743339086683 Training loss: 0.0
2025-12-09 10:23:36.221 | INFO     | __main__:train:24 - Epoch: 0 Step: 7236 LR: 0.0009998742986873593 Training loss: 0.0
2025-12-09 10:23:36.222 | INFO     | __main__:train:24 - Epoch: 0 Step: 7237 LR: 0.0009998742634611158 Training loss: 0.0
2025-12-09 10:23:36.223 | INFO     | __main__:train:24 - Epoch: 0 Step: 7238 LR: 0.0009998742282299378 Training loss: 0.0
2025-12-09 10:23:36.224 | INFO     | __main__:train:24 - Epoch: 0 Step: 7239 LR: 0.0009998741929938251 Training loss: 0.0
2025-12-09 10:23:36.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 7240 LR: 0.000999874157752778 Training loss: 0.0
2025-12-09 10:23:36.225 | INFO     | __main__:train:24 - Epoch: 0 Step: 7241 LR: 0.0009998741225067964 Training loss: 0.0
2025-12-09 10:23:36.226 | INFO     | __main__:train:24 - Epoch: 0 Step: 7242 LR: 0.0009998740872558802 Training loss: 0.0
2025-12-09 10:23:36.227 | INFO     | __main__:train:24 - Epoch: 0 Step: 7243 LR: 0.0009998740520000293 Training loss: 0.0
2025-12-09 10:23:36.228 | INFO     | __main__:train:24 - Epoch: 0 Step: 7244 LR: 0.000999874016739244 Training loss: 0.0
2025-12-09 10:23:36.229 | INFO     | __main__:train:24 - Epoch: 0 Step: 7245 LR: 0.000999873981473524 Training loss: 0.0
2025-12-09 10:23:36.230 | INFO     | __main__:train:24 - Epoch: 0 Step: 7246 LR: 0.0009998739462028698 Training loss: 0.0
2025-12-09 10:23:36.231 | INFO     | __main__:train:24 - Epoch: 0 Step: 7247 LR: 0.0009998739109272807 Training loss: 0.0
2025-12-09 10:23:36.232 | INFO     | __main__:train:24 - Epoch: 0 Step: 7248 LR: 0.0009998738756467574 Training loss: 0.0
2025-12-09 10:23:36.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 7249 LR: 0.0009998738403612993 Training loss: 0.0
2025-12-09 10:23:36.233 | INFO     | __main__:train:24 - Epoch: 0 Step: 7250 LR: 0.0009998738050709067 Training loss: 0.0
2025-12-09 10:23:36.234 | INFO     | __main__:train:24 - Epoch: 0 Step: 7251 LR: 0.0009998737697755795 Training loss: 0.0
2025-12-09 10:23:36.235 | INFO     | __main__:train:24 - Epoch: 0 Step: 7252 LR: 0.0009998737344753179 Training loss: 0.0
2025-12-09 10:23:36.236 | INFO     | __main__:train:24 - Epoch: 0 Step: 7253 LR: 0.0009998736991701216 Training loss: 0.0
2025-12-09 10:23:36.237 | INFO     | __main__:train:24 - Epoch: 0 Step: 7254 LR: 0.0009998736638599907 Training loss: 0.0
2025-12-09 10:23:36.238 | INFO     | __main__:train:24 - Epoch: 0 Step: 7255 LR: 0.0009998736285449256 Training loss: 0.0
2025-12-09 10:23:36.239 | INFO     | __main__:train:24 - Epoch: 0 Step: 7256 LR: 0.0009998735932249256 Training loss: 0.0
2025-12-09 10:23:36.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 7257 LR: 0.0009998735578999913 Training loss: 0.0
2025-12-09 10:23:36.240 | INFO     | __main__:train:24 - Epoch: 0 Step: 7258 LR: 0.0009998735225701222 Training loss: 0.0
2025-12-09 10:23:36.241 | INFO     | __main__:train:24 - Epoch: 0 Step: 7259 LR: 0.0009998734872353188 Training loss: 0.0
2025-12-09 10:23:36.242 | INFO     | __main__:train:24 - Epoch: 0 Step: 7260 LR: 0.000999873451895581 Training loss: 0.0
2025-12-09 10:23:36.243 | INFO     | __main__:train:24 - Epoch: 0 Step: 7261 LR: 0.0009998734165509084 Training loss: 0.0
2025-12-09 10:23:36.244 | INFO     | __main__:train:24 - Epoch: 0 Step: 7262 LR: 0.0009998733812013013 Training loss: 0.0
2025-12-09 10:23:36.245 | INFO     | __main__:train:24 - Epoch: 0 Step: 7263 LR: 0.0009998733458467597 Training loss: 0.0
2025-12-09 10:23:36.246 | INFO     | __main__:train:24 - Epoch: 0 Step: 7264 LR: 0.0009998733104872835 Training loss: 0.0
2025-12-09 10:23:36.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 7265 LR: 0.0009998732751228727 Training loss: 0.0
2025-12-09 10:23:36.247 | INFO     | __main__:train:24 - Epoch: 0 Step: 7266 LR: 0.0009998732397535274 Training loss: 0.0
2025-12-09 10:23:36.248 | INFO     | __main__:train:24 - Epoch: 0 Step: 7267 LR: 0.0009998732043792478 Training loss: 0.0
2025-12-09 10:23:36.249 | INFO     | __main__:train:24 - Epoch: 0 Step: 7268 LR: 0.0009998731690000332 Training loss: 0.0
2025-12-09 10:23:36.250 | INFO     | __main__:train:24 - Epoch: 0 Step: 7269 LR: 0.0009998731336158847 Training loss: 0.0
2025-12-09 10:23:36.251 | INFO     | __main__:train:24 - Epoch: 0 Step: 7270 LR: 0.0009998730982268011 Training loss: 0.0
2025-12-09 10:23:36.252 | INFO     | __main__:train:24 - Epoch: 0 Step: 7271 LR: 0.0009998730628327833 Training loss: 0.0
2025-12-09 10:23:36.253 | INFO     | __main__:train:24 - Epoch: 0 Step: 7272 LR: 0.000999873027433831 Training loss: 0.0
2025-12-09 10:23:36.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 7273 LR: 0.0009998729920299438 Training loss: 0.0
2025-12-09 10:23:36.254 | INFO     | __main__:train:24 - Epoch: 0 Step: 7274 LR: 0.0009998729566211221 Training loss: 0.0
2025-12-09 10:23:36.255 | INFO     | __main__:train:24 - Epoch: 0 Step: 7275 LR: 0.000999872921207366 Training loss: 0.0
2025-12-09 10:23:36.256 | INFO     | __main__:train:24 - Epoch: 0 Step: 7276 LR: 0.0009998728857886754 Training loss: 0.0
2025-12-09 10:23:36.257 | INFO     | __main__:train:24 - Epoch: 0 Step: 7277 LR: 0.0009998728503650505 Training loss: 0.0
2025-12-09 10:23:36.258 | INFO     | __main__:train:24 - Epoch: 0 Step: 7278 LR: 0.0009998728149364906 Training loss: 0.0
2025-12-09 10:23:36.259 | INFO     | __main__:train:24 - Epoch: 0 Step: 7279 LR: 0.0009998727795029964 Training loss: 0.0
2025-12-09 10:23:36.260 | INFO     | __main__:train:24 - Epoch: 0 Step: 7280 LR: 0.0009998727440645677 Training loss: 0.0
2025-12-09 10:23:36.261 | INFO     | __main__:train:24 - Epoch: 0 Step: 7281 LR: 0.0009998727086212044 Training loss: 0.0
2025-12-09 10:23:36.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 7282 LR: 0.0009998726731729067 Training loss: 0.0
2025-12-09 10:23:36.262 | INFO     | __main__:train:24 - Epoch: 0 Step: 7283 LR: 0.0009998726377196743 Training loss: 0.0
2025-12-09 10:23:36.263 | INFO     | __main__:train:24 - Epoch: 0 Step: 7284 LR: 0.0009998726022615075 Training loss: 0.0
2025-12-09 10:23:36.264 | INFO     | __main__:train:24 - Epoch: 0 Step: 7285 LR: 0.0009998725667984061 Training loss: 0.0
2025-12-09 10:23:36.265 | INFO     | __main__:train:24 - Epoch: 0 Step: 7286 LR: 0.00099987253133037 Training loss: 0.0
2025-12-09 10:23:36.266 | INFO     | __main__:train:24 - Epoch: 0 Step: 7287 LR: 0.0009998724958573998 Training loss: 0.0
2025-12-09 10:23:36.267 | INFO     | __main__:train:24 - Epoch: 0 Step: 7288 LR: 0.0009998724603794947 Training loss: 0.0
2025-12-09 10:23:36.268 | INFO     | __main__:train:24 - Epoch: 0 Step: 7289 LR: 0.0009998724248966551 Training loss: 0.0
2025-12-09 10:23:36.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 7290 LR: 0.000999872389408881 Training loss: 0.0
2025-12-09 10:23:36.269 | INFO     | __main__:train:24 - Epoch: 0 Step: 7291 LR: 0.0009998723539161726 Training loss: 0.0
2025-12-09 10:23:36.270 | INFO     | __main__:train:24 - Epoch: 0 Step: 7292 LR: 0.0009998723184185293 Training loss: 0.0
2025-12-09 10:23:36.271 | INFO     | __main__:train:24 - Epoch: 0 Step: 7293 LR: 0.0009998722829159517 Training loss: 0.0
2025-12-09 10:23:36.272 | INFO     | __main__:train:24 - Epoch: 0 Step: 7294 LR: 0.0009998722474084396 Training loss: 0.0
2025-12-09 10:23:36.273 | INFO     | __main__:train:24 - Epoch: 0 Step: 7295 LR: 0.000999872211895993 Training loss: 0.0
2025-12-09 10:23:36.274 | INFO     | __main__:train:24 - Epoch: 0 Step: 7296 LR: 0.0009998721763786115 Training loss: 0.0
2025-12-09 10:23:36.275 | INFO     | __main__:train:24 - Epoch: 0 Step: 7297 LR: 0.0009998721408562958 Training loss: 0.0
2025-12-09 10:23:36.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 7298 LR: 0.0009998721053290456 Training loss: 0.0
2025-12-09 10:23:36.276 | INFO     | __main__:train:24 - Epoch: 0 Step: 7299 LR: 0.0009998720697968605 Training loss: 0.0
2025-12-09 10:23:36.277 | INFO     | __main__:train:24 - Epoch: 0 Step: 7300 LR: 0.0009998720342597415 Training loss: 0.0
2025-12-09 10:23:36.278 | INFO     | __main__:train:24 - Epoch: 0 Step: 7301 LR: 0.0009998719987176874 Training loss: 0.0
2025-12-09 10:23:36.279 | INFO     | __main__:train:24 - Epoch: 0 Step: 7302 LR: 0.000999871963170699 Training loss: 0.0
2025-12-09 10:23:36.280 | INFO     | __main__:train:24 - Epoch: 0 Step: 7303 LR: 0.0009998719276187761 Training loss: 0.0
2025-12-09 10:23:36.281 | INFO     | __main__:train:24 - Epoch: 0 Step: 7304 LR: 0.0009998718920619187 Training loss: 0.0
2025-12-09 10:23:36.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 7305 LR: 0.0009998718565001267 Training loss: 0.0
2025-12-09 10:23:36.282 | INFO     | __main__:train:24 - Epoch: 0 Step: 7306 LR: 0.0009998718209334003 Training loss: 0.0
2025-12-09 10:23:36.283 | INFO     | __main__:train:24 - Epoch: 0 Step: 7307 LR: 0.0009998717853617392 Training loss: 0.0
2025-12-09 10:23:36.284 | INFO     | __main__:train:24 - Epoch: 0 Step: 7308 LR: 0.0009998717497851437 Training loss: 0.0
2025-12-09 10:23:36.285 | INFO     | __main__:train:24 - Epoch: 0 Step: 7309 LR: 0.0009998717142036136 Training loss: 0.0
2025-12-09 10:23:36.286 | INFO     | __main__:train:24 - Epoch: 0 Step: 7310 LR: 0.000999871678617149 Training loss: 0.0
2025-12-09 10:23:36.287 | INFO     | __main__:train:24 - Epoch: 0 Step: 7311 LR: 0.0009998716430257499 Training loss: 0.0
2025-12-09 10:23:36.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 7312 LR: 0.0009998716074294163 Training loss: 0.0
2025-12-09 10:23:36.288 | INFO     | __main__:train:24 - Epoch: 0 Step: 7313 LR: 0.000999871571828148 Training loss: 0.0
2025-12-09 10:23:36.289 | INFO     | __main__:train:24 - Epoch: 0 Step: 7314 LR: 0.0009998715362219456 Training loss: 0.0
2025-12-09 10:23:36.290 | INFO     | __main__:train:24 - Epoch: 0 Step: 7315 LR: 0.0009998715006108083 Training loss: 0.0
2025-12-09 10:23:36.291 | INFO     | __main__:train:24 - Epoch: 0 Step: 7316 LR: 0.0009998714649947366 Training loss: 0.0
2025-12-09 10:23:36.292 | INFO     | __main__:train:24 - Epoch: 0 Step: 7317 LR: 0.0009998714293737304 Training loss: 0.0
2025-12-09 10:23:36.293 | INFO     | __main__:train:24 - Epoch: 0 Step: 7318 LR: 0.0009998713937477896 Training loss: 0.0
2025-12-09 10:23:36.294 | INFO     | __main__:train:24 - Epoch: 0 Step: 7319 LR: 0.0009998713581169144 Training loss: 0.0
2025-12-09 10:23:36.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 7320 LR: 0.0009998713224811044 Training loss: 0.0
2025-12-09 10:23:36.295 | INFO     | __main__:train:24 - Epoch: 0 Step: 7321 LR: 0.0009998712868403603 Training loss: 0.0
2025-12-09 10:23:36.296 | INFO     | __main__:train:24 - Epoch: 0 Step: 7322 LR: 0.0009998712511946814 Training loss: 0.0
2025-12-09 10:23:36.297 | INFO     | __main__:train:24 - Epoch: 0 Step: 7323 LR: 0.000999871215544068 Training loss: 0.0
2025-12-09 10:23:36.298 | INFO     | __main__:train:24 - Epoch: 0 Step: 7324 LR: 0.0009998711798885201 Training loss: 0.0
2025-12-09 10:23:36.299 | INFO     | __main__:train:24 - Epoch: 0 Step: 7325 LR: 0.0009998711442280378 Training loss: 0.0
2025-12-09 10:23:36.300 | INFO     | __main__:train:24 - Epoch: 0 Step: 7326 LR: 0.000999871108562621 Training loss: 0.0
2025-12-09 10:23:36.301 | INFO     | __main__:train:24 - Epoch: 0 Step: 7327 LR: 0.0009998710728922693 Training loss: 0.0
2025-12-09 10:23:36.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 7328 LR: 0.0009998710372169835 Training loss: 0.0
2025-12-09 10:23:36.302 | INFO     | __main__:train:24 - Epoch: 0 Step: 7329 LR: 0.000999871001536763 Training loss: 0.0
2025-12-09 10:23:36.303 | INFO     | __main__:train:24 - Epoch: 0 Step: 7330 LR: 0.000999870965851608 Training loss: 0.0
2025-12-09 10:23:36.304 | INFO     | __main__:train:24 - Epoch: 0 Step: 7331 LR: 0.0009998709301615185 Training loss: 0.0
2025-12-09 10:23:36.305 | INFO     | __main__:train:24 - Epoch: 0 Step: 7332 LR: 0.0009998708944664945 Training loss: 0.0
2025-12-09 10:23:36.306 | INFO     | __main__:train:24 - Epoch: 0 Step: 7333 LR: 0.000999870858766536 Training loss: 0.0
2025-12-09 10:23:36.307 | INFO     | __main__:train:24 - Epoch: 0 Step: 7334 LR: 0.000999870823061643 Training loss: 0.0
2025-12-09 10:23:36.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 7335 LR: 0.0009998707873518154 Training loss: 0.0
2025-12-09 10:23:36.308 | INFO     | __main__:train:24 - Epoch: 0 Step: 7336 LR: 0.0009998707516370535 Training loss: 0.0
2025-12-09 10:23:36.309 | INFO     | __main__:train:24 - Epoch: 0 Step: 7337 LR: 0.0009998707159173568 Training loss: 0.0
2025-12-09 10:23:36.310 | INFO     | __main__:train:24 - Epoch: 0 Step: 7338 LR: 0.0009998706801927259 Training loss: 0.0
2025-12-09 10:23:36.311 | INFO     | __main__:train:24 - Epoch: 0 Step: 7339 LR: 0.0009998706444631603 Training loss: 0.0
2025-12-09 10:23:36.312 | INFO     | __main__:train:24 - Epoch: 0 Step: 7340 LR: 0.00099987060872866 Training loss: 0.0
2025-12-09 10:23:36.313 | INFO     | __main__:train:24 - Epoch: 0 Step: 7341 LR: 0.0009998705729892254 Training loss: 0.0
2025-12-09 10:23:36.314 | INFO     | __main__:train:24 - Epoch: 0 Step: 7342 LR: 0.0009998705372448562 Training loss: 0.0
2025-12-09 10:23:36.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 7343 LR: 0.0009998705014955527 Training loss: 0.0
2025-12-09 10:23:36.315 | INFO     | __main__:train:24 - Epoch: 0 Step: 7344 LR: 0.0009998704657413144 Training loss: 0.0
2025-12-09 10:23:36.317 | INFO     | __main__:train:24 - Epoch: 0 Step: 7345 LR: 0.0009998704299821418 Training loss: 0.0
2025-12-09 10:23:36.318 | INFO     | __main__:train:24 - Epoch: 0 Step: 7346 LR: 0.0009998703942180347 Training loss: 0.0
2025-12-09 10:23:36.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 7347 LR: 0.000999870358448993 Training loss: 0.0
2025-12-09 10:23:36.319 | INFO     | __main__:train:24 - Epoch: 0 Step: 7348 LR: 0.0009998703226750168 Training loss: 0.0
2025-12-09 10:23:36.320 | INFO     | __main__:train:24 - Epoch: 0 Step: 7349 LR: 0.000999870286896106 Training loss: 0.0
2025-12-09 10:23:36.321 | INFO     | __main__:train:24 - Epoch: 0 Step: 7350 LR: 0.000999870251112261 Training loss: 0.0
2025-12-09 10:23:36.322 | INFO     | __main__:train:24 - Epoch: 0 Step: 7351 LR: 0.0009998702153234812 Training loss: 0.0
2025-12-09 10:23:36.323 | INFO     | __main__:train:24 - Epoch: 0 Step: 7352 LR: 0.0009998701795297668 Training loss: 0.0
2025-12-09 10:23:36.324 | INFO     | __main__:train:24 - Epoch: 0 Step: 7353 LR: 0.000999870143731118 Training loss: 0.0
2025-12-09 10:23:36.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 7354 LR: 0.0009998701079275349 Training loss: 0.0
2025-12-09 10:23:36.325 | INFO     | __main__:train:24 - Epoch: 0 Step: 7355 LR: 0.000999870072119017 Training loss: 0.0
2025-12-09 10:23:36.326 | INFO     | __main__:train:24 - Epoch: 0 Step: 7356 LR: 0.0009998700363055648 Training loss: 0.0
2025-12-09 10:23:36.327 | INFO     | __main__:train:24 - Epoch: 0 Step: 7357 LR: 0.0009998700004871781 Training loss: 0.0
2025-12-09 10:23:36.328 | INFO     | __main__:train:24 - Epoch: 0 Step: 7358 LR: 0.0009998699646638568 Training loss: 0.0
2025-12-09 10:23:36.329 | INFO     | __main__:train:24 - Epoch: 0 Step: 7359 LR: 0.0009998699288356011 Training loss: 0.0
2025-12-09 10:23:36.330 | INFO     | __main__:train:24 - Epoch: 0 Step: 7360 LR: 0.0009998698930024108 Training loss: 0.0
2025-12-09 10:23:36.331 | INFO     | __main__:train:24 - Epoch: 0 Step: 7361 LR: 0.000999869857164286 Training loss: 0.0
2025-12-09 10:23:36.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 7362 LR: 0.0009998698213212268 Training loss: 0.0
2025-12-09 10:23:36.332 | INFO     | __main__:train:24 - Epoch: 0 Step: 7363 LR: 0.000999869785473233 Training loss: 0.0
2025-12-09 10:23:36.333 | INFO     | __main__:train:24 - Epoch: 0 Step: 7364 LR: 0.0009998697496203047 Training loss: 0.0
2025-12-09 10:23:36.334 | INFO     | __main__:train:24 - Epoch: 0 Step: 7365 LR: 0.0009998697137624417 Training loss: 0.0
2025-12-09 10:23:36.335 | INFO     | __main__:train:24 - Epoch: 0 Step: 7366 LR: 0.0009998696778996446 Training loss: 0.0
2025-12-09 10:23:36.336 | INFO     | __main__:train:24 - Epoch: 0 Step: 7367 LR: 0.0009998696420319127 Training loss: 0.0
2025-12-09 10:23:36.337 | INFO     | __main__:train:24 - Epoch: 0 Step: 7368 LR: 0.0009998696061592463 Training loss: 0.0
2025-12-09 10:23:36.338 | INFO     | __main__:train:24 - Epoch: 0 Step: 7369 LR: 0.0009998695702816457 Training loss: 0.0
2025-12-09 10:23:36.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 7370 LR: 0.0009998695343991103 Training loss: 0.0
2025-12-09 10:23:36.339 | INFO     | __main__:train:24 - Epoch: 0 Step: 7371 LR: 0.0009998694985116404 Training loss: 0.0
2025-12-09 10:23:36.340 | INFO     | __main__:train:24 - Epoch: 0 Step: 7372 LR: 0.0009998694626192361 Training loss: 0.0
2025-12-09 10:23:36.341 | INFO     | __main__:train:24 - Epoch: 0 Step: 7373 LR: 0.0009998694267218972 Training loss: 0.0
2025-12-09 10:23:36.342 | INFO     | __main__:train:24 - Epoch: 0 Step: 7374 LR: 0.0009998693908196239 Training loss: 0.0
2025-12-09 10:23:36.343 | INFO     | __main__:train:24 - Epoch: 0 Step: 7375 LR: 0.000999869354912416 Training loss: 0.0
2025-12-09 10:23:36.344 | INFO     | __main__:train:24 - Epoch: 0 Step: 7376 LR: 0.000999869319000274 Training loss: 0.0
2025-12-09 10:23:36.345 | INFO     | __main__:train:24 - Epoch: 0 Step: 7377 LR: 0.000999869283083197 Training loss: 0.0
2025-12-09 10:23:36.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 7378 LR: 0.0009998692471611856 Training loss: 0.0
2025-12-09 10:23:36.346 | INFO     | __main__:train:24 - Epoch: 0 Step: 7379 LR: 0.0009998692112342398 Training loss: 0.0
2025-12-09 10:23:36.347 | INFO     | __main__:train:24 - Epoch: 0 Step: 7380 LR: 0.0009998691753023595 Training loss: 0.0
2025-12-09 10:23:36.348 | INFO     | __main__:train:24 - Epoch: 0 Step: 7381 LR: 0.0009998691393655447 Training loss: 0.0
2025-12-09 10:23:36.349 | INFO     | __main__:train:24 - Epoch: 0 Step: 7382 LR: 0.0009998691034237954 Training loss: 0.0
2025-12-09 10:23:36.350 | INFO     | __main__:train:24 - Epoch: 0 Step: 7383 LR: 0.0009998690674771116 Training loss: 0.0
2025-12-09 10:23:36.351 | INFO     | __main__:train:24 - Epoch: 0 Step: 7384 LR: 0.0009998690315254932 Training loss: 0.0
2025-12-09 10:23:36.352 | INFO     | __main__:train:24 - Epoch: 0 Step: 7385 LR: 0.0009998689955689405 Training loss: 0.0
2025-12-09 10:23:36.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 7386 LR: 0.0009998689596074533 Training loss: 0.0
2025-12-09 10:23:36.353 | INFO     | __main__:train:24 - Epoch: 0 Step: 7387 LR: 0.0009998689236410314 Training loss: 0.0
2025-12-09 10:23:36.354 | INFO     | __main__:train:24 - Epoch: 0 Step: 7388 LR: 0.000999868887669675 Training loss: 0.0
2025-12-09 10:23:36.355 | INFO     | __main__:train:24 - Epoch: 0 Step: 7389 LR: 0.0009998688516933843 Training loss: 0.0
2025-12-09 10:23:36.356 | INFO     | __main__:train:24 - Epoch: 0 Step: 7390 LR: 0.000999868815712159 Training loss: 0.0
2025-12-09 10:23:36.357 | INFO     | __main__:train:24 - Epoch: 0 Step: 7391 LR: 0.0009998687797259994 Training loss: 0.0
2025-12-09 10:23:36.358 | INFO     | __main__:train:24 - Epoch: 0 Step: 7392 LR: 0.000999868743734905 Training loss: 0.0
2025-12-09 10:23:36.359 | INFO     | __main__:train:24 - Epoch: 0 Step: 7393 LR: 0.0009998687077388763 Training loss: 0.0
2025-12-09 10:23:36.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 7394 LR: 0.000999868671737913 Training loss: 0.0
2025-12-09 10:23:36.360 | INFO     | __main__:train:24 - Epoch: 0 Step: 7395 LR: 0.0009998686357320153 Training loss: 0.0
2025-12-09 10:23:36.361 | INFO     | __main__:train:24 - Epoch: 0 Step: 7396 LR: 0.000999868599721183 Training loss: 0.0
2025-12-09 10:23:36.362 | INFO     | __main__:train:24 - Epoch: 0 Step: 7397 LR: 0.0009998685637054164 Training loss: 0.0
2025-12-09 10:23:36.363 | INFO     | __main__:train:24 - Epoch: 0 Step: 7398 LR: 0.000999868527684715 Training loss: 0.0
2025-12-09 10:23:36.364 | INFO     | __main__:train:24 - Epoch: 0 Step: 7399 LR: 0.0009998684916590794 Training loss: 0.0
2025-12-09 10:23:36.365 | INFO     | __main__:train:24 - Epoch: 0 Step: 7400 LR: 0.0009998684556285092 Training loss: 0.0
2025-12-09 10:23:36.366 | INFO     | __main__:train:24 - Epoch: 0 Step: 7401 LR: 0.0009998684195930045 Training loss: 0.0
2025-12-09 10:23:36.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 7402 LR: 0.0009998683835525653 Training loss: 0.0
2025-12-09 10:23:36.367 | INFO     | __main__:train:24 - Epoch: 0 Step: 7403 LR: 0.0009998683475071915 Training loss: 0.0
2025-12-09 10:23:36.368 | INFO     | __main__:train:24 - Epoch: 0 Step: 7404 LR: 0.0009998683114568834 Training loss: 0.0
2025-12-09 10:23:36.369 | INFO     | __main__:train:24 - Epoch: 0 Step: 7405 LR: 0.0009998682754016408 Training loss: 0.0
2025-12-09 10:23:36.370 | INFO     | __main__:train:24 - Epoch: 0 Step: 7406 LR: 0.0009998682393414636 Training loss: 0.0
2025-12-09 10:23:36.371 | INFO     | __main__:train:24 - Epoch: 0 Step: 7407 LR: 0.000999868203276352 Training loss: 0.0
2025-12-09 10:23:36.372 | INFO     | __main__:train:24 - Epoch: 0 Step: 7408 LR: 0.000999868167206306 Training loss: 0.0
2025-12-09 10:23:36.373 | INFO     | __main__:train:24 - Epoch: 0 Step: 7409 LR: 0.0009998681311313253 Training loss: 0.0
2025-12-09 10:23:36.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 7410 LR: 0.0009998680950514102 Training loss: 0.0
2025-12-09 10:23:36.374 | INFO     | __main__:train:24 - Epoch: 0 Step: 7411 LR: 0.0009998680589665605 Training loss: 0.0
2025-12-09 10:23:36.375 | INFO     | __main__:train:24 - Epoch: 0 Step: 7412 LR: 0.0009998680228767765 Training loss: 0.0
2025-12-09 10:23:36.376 | INFO     | __main__:train:24 - Epoch: 0 Step: 7413 LR: 0.000999867986782058 Training loss: 0.0
2025-12-09 10:23:36.377 | INFO     | __main__:train:24 - Epoch: 0 Step: 7414 LR: 0.000999867950682405 Training loss: 0.0
2025-12-09 10:23:36.378 | INFO     | __main__:train:24 - Epoch: 0 Step: 7415 LR: 0.0009998679145778173 Training loss: 0.0
2025-12-09 10:23:36.379 | INFO     | __main__:train:24 - Epoch: 0 Step: 7416 LR: 0.0009998678784682953 Training loss: 0.0
2025-12-09 10:23:36.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 7417 LR: 0.0009998678423538388 Training loss: 0.0
2025-12-09 10:23:36.380 | INFO     | __main__:train:24 - Epoch: 0 Step: 7418 LR: 0.000999867806234448 Training loss: 0.0
2025-12-09 10:23:36.381 | INFO     | __main__:train:24 - Epoch: 0 Step: 7419 LR: 0.0009998677701101224 Training loss: 0.0
2025-12-09 10:23:36.382 | INFO     | __main__:train:24 - Epoch: 0 Step: 7420 LR: 0.0009998677339808624 Training loss: 0.0
2025-12-09 10:23:36.383 | INFO     | __main__:train:24 - Epoch: 0 Step: 7421 LR: 0.000999867697846668 Training loss: 0.0
2025-12-09 10:23:36.384 | INFO     | __main__:train:24 - Epoch: 0 Step: 7422 LR: 0.000999867661707539 Training loss: 0.0
2025-12-09 10:23:36.385 | INFO     | __main__:train:24 - Epoch: 0 Step: 7423 LR: 0.0009998676255634758 Training loss: 0.0
2025-12-09 10:23:36.386 | INFO     | __main__:train:24 - Epoch: 0 Step: 7424 LR: 0.0009998675894144777 Training loss: 0.0
2025-12-09 10:23:36.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 7425 LR: 0.0009998675532605454 Training loss: 0.0
2025-12-09 10:23:36.387 | INFO     | __main__:train:24 - Epoch: 0 Step: 7426 LR: 0.0009998675171016787 Training loss: 0.0
2025-12-09 10:23:36.388 | INFO     | __main__:train:24 - Epoch: 0 Step: 7427 LR: 0.0009998674809378772 Training loss: 0.0
2025-12-09 10:23:36.389 | INFO     | __main__:train:24 - Epoch: 0 Step: 7428 LR: 0.0009998674447691414 Training loss: 0.0
2025-12-09 10:23:36.390 | INFO     | __main__:train:24 - Epoch: 0 Step: 7429 LR: 0.000999867408595471 Training loss: 0.0
2025-12-09 10:23:36.391 | INFO     | __main__:train:24 - Epoch: 0 Step: 7430 LR: 0.0009998673724168664 Training loss: 0.0
2025-12-09 10:23:36.392 | INFO     | __main__:train:24 - Epoch: 0 Step: 7431 LR: 0.0009998673362333272 Training loss: 0.0
2025-12-09 10:23:36.393 | INFO     | __main__:train:24 - Epoch: 0 Step: 7432 LR: 0.0009998673000448535 Training loss: 0.0
2025-12-09 10:23:36.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 7433 LR: 0.0009998672638514452 Training loss: 0.0
2025-12-09 10:23:36.394 | INFO     | __main__:train:24 - Epoch: 0 Step: 7434 LR: 0.0009998672276531025 Training loss: 0.0
2025-12-09 10:23:36.395 | INFO     | __main__:train:24 - Epoch: 0 Step: 7435 LR: 0.0009998671914498254 Training loss: 0.0
2025-12-09 10:23:36.396 | INFO     | __main__:train:24 - Epoch: 0 Step: 7436 LR: 0.0009998671552416136 Training loss: 0.0
2025-12-09 10:23:36.397 | INFO     | __main__:train:24 - Epoch: 0 Step: 7437 LR: 0.0009998671190284676 Training loss: 0.0
2025-12-09 10:23:36.398 | INFO     | __main__:train:24 - Epoch: 0 Step: 7438 LR: 0.000999867082810387 Training loss: 0.0
2025-12-09 10:23:36.399 | INFO     | __main__:train:24 - Epoch: 0 Step: 7439 LR: 0.0009998670465873718 Training loss: 0.0
2025-12-09 10:23:36.400 | INFO     | __main__:train:24 - Epoch: 0 Step: 7440 LR: 0.0009998670103594223 Training loss: 0.0
2025-12-09 10:23:36.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 7441 LR: 0.0009998669741265382 Training loss: 0.0
2025-12-09 10:23:36.401 | INFO     | __main__:train:24 - Epoch: 0 Step: 7442 LR: 0.0009998669378887197 Training loss: 0.0
2025-12-09 10:23:36.402 | INFO     | __main__:train:24 - Epoch: 0 Step: 7443 LR: 0.0009998669016459667 Training loss: 0.0
2025-12-09 10:23:36.403 | INFO     | __main__:train:24 - Epoch: 0 Step: 7444 LR: 0.0009998668653982794 Training loss: 0.0
2025-12-09 10:23:36.404 | INFO     | __main__:train:24 - Epoch: 0 Step: 7445 LR: 0.0009998668291456574 Training loss: 0.0
2025-12-09 10:23:36.405 | INFO     | __main__:train:24 - Epoch: 0 Step: 7446 LR: 0.000999866792888101 Training loss: 0.0
2025-12-09 10:23:36.406 | INFO     | __main__:train:24 - Epoch: 0 Step: 7447 LR: 0.0009998667566256101 Training loss: 0.0
2025-12-09 10:23:36.407 | INFO     | __main__:train:24 - Epoch: 0 Step: 7448 LR: 0.0009998667203581849 Training loss: 0.0
