2025-12-09 12:09:11.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 4.867964267730713
2025-12-09 12:09:11.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 4.752755165100098
2025-12-09 12:09:11.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 4.8450493812561035
2025-12-09 12:09:11.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 4.874756336212158
2025-12-09 12:09:11.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 4.901021957397461
2025-12-09 12:09:11.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 4.947654724121094
2025-12-09 12:09:11.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 4.793710231781006
2025-12-09 12:09:11.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 4.876060485839844
2025-12-09 12:09:11.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 4.891377925872803
2025-12-09 12:09:11.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 4.8655314445495605
2025-12-09 12:09:11.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 4.778134346008301
2025-12-09 12:09:11.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 4.885640621185303
2025-12-09 12:09:11.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 4.768617630004883
2025-12-09 12:09:11.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 4.827330112457275
2025-12-09 12:09:11.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 4.791254043579102
2025-12-09 12:09:11.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 4.897307395935059
2025-12-09 12:09:11.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 4.930380821228027
2025-12-09 12:09:11.831 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 4.799029350280762
2025-12-09 12:09:11.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 4.868752479553223
2025-12-09 12:09:11.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 4.888643741607666
2025-12-09 12:09:11.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 4.837767124176025
2025-12-09 12:09:11.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 4.970856189727783
2025-12-09 12:09:11.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 4.678867816925049
2025-12-09 12:09:11.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 4.749395847320557
2025-12-09 12:09:12.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 4.803657054901123
2025-12-09 12:09:12.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 4.902401924133301
2025-12-09 12:09:12.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 4.652874946594238
2025-12-09 12:09:12.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 4.672297477722168
2025-12-09 12:09:12.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 4.850939750671387
2025-12-09 12:09:12.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 4.803436756134033
2025-12-09 12:09:12.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 4.736425399780273
2025-12-09 12:09:12.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 4.7653303146362305
2025-12-09 12:09:12.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 4.61149263381958
2025-12-09 12:09:12.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 4.818719387054443
2025-12-09 12:09:12.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 4.726781845092773
2025-12-09 12:09:12.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 4.800220966339111
2025-12-09 12:09:12.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 4.736105918884277
2025-12-09 12:09:12.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 4.626689434051514
2025-12-09 12:09:12.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 4.7491455078125
2025-12-09 12:09:12.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 4.700191020965576
2025-12-09 12:09:12.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 4.736059188842773
2025-12-09 12:09:12.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 4.604253768920898
2025-12-09 12:09:12.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 4.618766784667969
2025-12-09 12:09:12.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 4.60482120513916
2025-12-09 12:09:12.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 4.646894454956055
2025-12-09 12:09:12.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 4.609499931335449
2025-12-09 12:09:12.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 4.574423789978027
2025-12-09 12:09:12.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 4.675196170806885
2025-12-09 12:09:12.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 4.637381553649902
2025-12-09 12:09:12.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 4.676449298858643
2025-12-09 12:09:12.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 4.4951887130737305
2025-12-09 12:09:12.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 4.542452812194824
2025-12-09 12:09:12.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 4.47511100769043
2025-12-09 12:09:12.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 4.495915412902832
2025-12-09 12:09:12.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 4.439041614532471
2025-12-09 12:09:12.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 4.488807201385498
2025-12-09 12:09:12.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 4.340730667114258
2025-12-09 12:09:12.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 4.410270690917969
2025-12-09 12:09:12.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 4.5907368659973145
2025-12-09 12:09:12.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 4.334883213043213
2025-12-09 12:09:12.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 4.4854350090026855
2025-12-09 12:09:12.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 4.444277286529541
2025-12-09 12:09:13.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 4.547708511352539
2025-12-09 12:09:13.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 4.314401626586914
2025-12-09 12:09:13.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 4.402807235717773
2025-12-09 12:09:13.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 4.313190937042236
2025-12-09 12:09:13.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 4.360565662384033
2025-12-09 12:09:13.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 4.2713727951049805
2025-12-09 12:09:13.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 4.226003170013428
2025-12-09 12:09:13.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 4.333756923675537
2025-12-09 12:09:13.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 4.371339797973633
2025-12-09 12:09:13.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 4.237783908843994
2025-12-09 12:09:13.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 4.164427280426025
2025-12-09 12:09:13.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 4.237512588500977
2025-12-09 12:09:13.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 4.228678226470947
2025-12-09 12:09:13.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 4.1300435066223145
2025-12-09 12:09:13.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 4.305498123168945
2025-12-09 12:09:13.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 4.264948844909668
2025-12-09 12:09:13.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 4.150196075439453
2025-12-09 12:09:13.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 4.159801006317139
2025-12-09 12:09:13.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 4.180627346038818
2025-12-09 12:09:13.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 4.136504650115967
2025-12-09 12:09:13.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 4.22734260559082
2025-12-09 12:09:13.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 4.219476222991943
2025-12-09 12:09:13.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 4.114094257354736
2025-12-09 12:09:13.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 4.172778606414795
2025-12-09 12:09:13.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 4.149421691894531
2025-12-09 12:09:13.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 4.070248126983643
2025-12-09 12:09:13.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 4.124423027038574
2025-12-09 12:09:13.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 3.977649688720703
2025-12-09 12:09:13.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 4.269647121429443
2025-12-09 12:09:13.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 3.8925130367279053
2025-12-09 12:09:13.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 4.058652877807617
2025-12-09 12:09:13.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 3.8581485748291016
2025-12-09 12:09:13.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 4.010913848876953
2025-12-09 12:09:13.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 4.0856404304504395
2025-12-09 12:09:13.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 4.011567115783691
2025-12-09 12:09:13.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 3.9758317470550537
2025-12-09 12:09:13.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 3.775001049041748
2025-12-09 12:09:13.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 4.0273213386535645
2025-12-09 12:09:14.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0009999708626830617 Training loss: 4.180537223815918
2025-12-09 12:09:14.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.0009998834541281797 Training loss: 3.787970781326294
2025-12-09 12:09:14.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0009997377845227576 Training loss: 3.9033966064453125
2025-12-09 12:09:14.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0009995338708444802 Training loss: 3.89699387550354
2025-12-09 12:09:14.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0009992717368593384 Training loss: 4.115595817565918
2025-12-09 12:09:14.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0009989514131188558 Training loss: 3.9052822589874268
2025-12-09 12:09:14.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0009985729369565298 Training loss: 3.989516019821167
2025-12-09 12:09:14.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.00099813635248348 Training loss: 3.965050458908081
2025-12-09 12:09:14.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0009976417105833069 Training loss: 3.802431583404541
2025-12-09 12:09:14.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.000997089068906162 Training loss: 3.718979597091675
2025-12-09 12:09:14.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.0009964784918620282 Training loss: 3.885645627975464
2025-12-09 12:09:14.307 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0009958100506132126 Training loss: 3.8712961673736572
2025-12-09 12:09:14.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0009950838230660534 Training loss: 3.807142734527588
2025-12-09 12:09:14.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0009942998938618393 Training loss: 3.8443126678466797
2025-12-09 12:09:14.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.0009934583543669453 Training loss: 3.979933738708496
2025-12-09 12:09:14.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0009925593026621834 Training loss: 3.796443223953247
2025-12-09 12:09:14.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.000991602843531371 Training loss: 3.9282989501953125
2025-12-09 12:09:14.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.0009905890884491196 Training loss: 3.854079008102417
2025-12-09 12:09:14.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0009895181555678418 Training loss: 3.7231314182281494
2025-12-09 12:09:14.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.0009883901697039807 Training loss: 3.866689920425415
2025-12-09 12:09:14.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.000987205262323463 Training loss: 3.820570230484009
2025-12-09 12:09:14.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.000985963571526376 Training loss: 3.6439359188079834
2025-12-09 12:09:14.595 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.0009846652420308728 Training loss: 3.7129693031311035
2025-12-09 12:09:14.623 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.0009833104251563056 Training loss: 3.8171234130859375
2025-12-09 12:09:14.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.000981899278805589 Training loss: 3.6955373287200928
2025-12-09 12:09:14.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.0009804319674467969 Training loss: 3.8015472888946533
2025-12-09 12:09:14.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.0009789086620939935 Training loss: 3.6446597576141357
2025-12-09 12:09:14.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.0009773295402873026 Training loss: 3.5957608222961426
2025-12-09 12:09:14.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0009756947860722143 Training loss: 3.6731133460998535
2025-12-09 12:09:14.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.0009740045899781352 Training loss: 3.7929134368896484
2025-12-09 12:09:14.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.0009722591489961827 Training loss: 3.3809642791748047
2025-12-09 12:09:14.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.0009704586665562249 Training loss: 3.434152603149414
2025-12-09 12:09:14.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0009686033525031719 Training loss: 3.638435125350952
2025-12-09 12:09:14.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.0009666934230725179 Training loss: 3.8869941234588623
2025-12-09 12:09:14.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.0009647291008651398 Training loss: 3.6348414421081543
2025-12-09 12:09:14.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0009627106148213521 Training loss: 3.551774740219116
2025-12-09 12:09:14.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0009606382001942255 Training loss: 3.788710355758667
2025-12-09 12:09:14.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.0009585120985221671 Training loss: 3.8831491470336914
2025-12-09 12:09:15.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.0009563325576007701 Training loss: 3.709090232849121
2025-12-09 12:09:15.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0009540998314539327 Training loss: 3.726060152053833
2025-12-09 12:09:15.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0009518141803042527 Training loss: 3.840477466583252
2025-12-09 12:09:15.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.0009494758705426977 Training loss: 3.748037815093994
2025-12-09 12:09:15.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0009470851746975581 Training loss: 3.635279655456543
2025-12-09 12:09:15.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.0009446423714026846 Training loss: 3.6395668983459473
2025-12-09 12:09:15.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0009421477453650118 Training loss: 3.486353635787964
2025-12-09 12:09:15.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.0009396015873313782 Training loss: 3.6370363235473633
2025-12-09 12:09:15.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0009370041940546379 Training loss: 3.4205353260040283
2025-12-09 12:09:15.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0009343558682590756 Training loss: 3.5483145713806152
2025-12-09 12:09:15.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.0009316569186051234 Training loss: 3.594210147857666
2025-12-09 12:09:15.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0009289076596533872 Training loss: 3.7317681312561035
2025-12-09 12:09:15.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0009261084118279846 Training loss: 3.5786309242248535
2025-12-09 12:09:15.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.0009232595013792003 Training loss: 3.557804822921753
2025-12-09 12:09:15.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0009203612603454604 Training loss: 3.593764066696167
2025-12-09 12:09:15.408 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.0009174140265146356 Training loss: 3.6226603984832764
2025-12-09 12:09:15.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.0009144181433846706 Training loss: 3.421926498413086
2025-12-09 12:09:15.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0009113739601235507 Training loss: 3.4176859855651855
2025-12-09 12:09:15.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.0009082818315286055 Training loss: 3.6446049213409424
2025-12-09 12:09:15.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0009051421179851588 Training loss: 3.5387372970581055
2025-12-09 12:09:15.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.000901955185424525 Training loss: 3.349642515182495
2025-12-09 12:09:15.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0008987214052813603 Training loss: 3.368021011352539
2025-12-09 12:09:15.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.0008954411544503729 Training loss: 3.679715394973755
2025-12-09 12:09:15.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.0008921148152423946 Training loss: 3.561262607574463
2025-12-09 12:09:15.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.0008887427753398248 Training loss: 3.326637029647827
2025-12-09 12:09:15.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.0008853254277514447 Training loss: 3.587017059326172
2025-12-09 12:09:15.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0008818631707666135 Training loss: 3.5592801570892334
2025-12-09 12:09:15.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.0008783564079088476 Training loss: 3.488241672515869
2025-12-09 12:09:15.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.0008748055478887904 Training loss: 3.7126352787017822
2025-12-09 12:09:15.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0008712110045565768 Training loss: 3.352459192276001
2025-12-09 12:09:15.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.0008675731968536002 Training loss: 3.4612462520599365
2025-12-09 12:09:15.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.0008638925487636848 Training loss: 3.5426933765411377
2025-12-09 12:09:15.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.00086016948926367 Training loss: 3.6005120277404785
2025-12-09 12:09:15.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.0008564044522734146 Training loss: 3.3567726612091064
2025-12-09 12:09:15.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.000852597876605223 Training loss: 3.432292938232422
2025-12-09 12:09:15.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.0008487502059127015 Training loss: 3.327268362045288
2025-12-09 12:09:15.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.0008448618886390522 Training loss: 3.5398447513580322
2025-12-09 12:09:15.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.0008409333779648059 Training loss: 3.359544515609741
2025-12-09 12:09:16.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0008369651317550054 Training loss: 3.697922468185425
2025-12-09 12:09:16.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0008329576125058406 Training loss: 3.7162063121795654
2025-12-09 12:09:16.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.0008289112872907454 Training loss: 3.3821260929107666
2025-12-09 12:09:16.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.0008248266277059606 Training loss: 3.446566343307495
2025-12-09 12:09:16.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.00082070410981557 Training loss: 3.6524410247802734
2025-12-09 12:09:16.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.000816544214096015 Training loss: 3.364715814590454
2025-12-09 12:09:16.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.0008123474253800957 Training loss: 3.4935379028320312
2025-12-09 12:09:16.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.0008081142328004637 Training loss: 3.512636423110962
2025-12-09 12:09:16.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.0008038451297326145 Training loss: 3.313667058944702
2025-12-09 12:09:16.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0007995406137373846 Training loss: 3.563220977783203
2025-12-09 12:09:16.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.0007952011865029613 Training loss: 3.3646886348724365
2025-12-09 12:09:16.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.0007908273537864113 Training loss: 3.0694727897644043
2025-12-09 12:09:16.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0007864196253547349 Training loss: 3.779280424118042
2025-12-09 12:09:16.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.0007819785149254532 Training loss: 3.049384355545044
2025-12-09 12:09:16.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.000777504540106735 Training loss: 3.3079028129577637
2025-12-09 12:09:16.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0007729982223370691 Training loss: 3.210268259048462
2025-12-09 12:09:16.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.0007684600868244919 Training loss: 3.4543564319610596
2025-12-09 12:09:16.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.0007638906624853743 Training loss: 3.6774373054504395
2025-12-09 12:09:16.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.0007592904818827774 Training loss: 3.3189916610717773
2025-12-09 12:09:16.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0007546600811643815 Training loss: 3.3172881603240967
2025-12-09 12:09:16.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.00075 Training loss: 3.4331533908843994
2025-12-09 12:09:16.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.0007453107815186803 Training loss: 3.4237582683563232
2025-12-09 12:09:16.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0007405929722454026 Training loss: 3.3491461277008057
2025-12-09 12:09:16.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0007358471220373831 Training loss: 3.3383586406707764
2025-12-09 12:09:16.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0007310737840199885 Training loss: 3.5037946701049805
2025-12-09 12:09:16.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0007262735145222696 Training loss: 3.2202351093292236
2025-12-09 12:09:16.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0007214468730121209 Training loss: 3.2543163299560547
2025-12-09 12:09:16.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0007165944220310766 Training loss: 3.260937213897705
2025-12-09 12:09:16.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0007117167271287453 Training loss: 3.3913707733154297
2025-12-09 12:09:16.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0007068143567968958 Training loss: 3.774512767791748
2025-12-09 12:09:16.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.0007018878824032009 Training loss: 3.643768072128296
2025-12-09 12:09:16.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.0006969378781246436 Training loss: 3.0878400802612305
2025-12-09 12:09:16.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.0006919649208805981 Training loss: 3.3893356323242188
2025-12-09 12:09:16.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0006869695902655897 Training loss: 3.559068202972412
2025-12-09 12:09:16.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.0006819524684817438 Training loss: 3.668868064880371
2025-12-09 12:09:16.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.0006769141402709304 Training loss: 3.2111477851867676
2025-12-09 12:09:16.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0006718551928466132 Training loss: 3.589773178100586
2025-12-09 12:09:16.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.0006667762158254104 Training loss: 3.327845573425293
2025-12-09 12:09:17.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.0006616778011583743 Training loss: 3.1906793117523193
2025-12-09 12:09:17.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.0006565605430620013 Training loss: 3.4275479316711426
2025-12-09 12:09:17.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0006514250379489753 Training loss: 3.2560572624206543
2025-12-09 12:09:17.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.0006462718843586572 Training loss: 3.3565499782562256
2025-12-09 12:09:17.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.0006411016828873239 Training loss: 3.3947300910949707
2025-12-09 12:09:17.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0006359150361181715 Training loss: 3.4092400074005127
2025-12-09 12:09:17.181 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.0006307125485510829 Training loss: 3.3818376064300537
2025-12-09 12:09:17.207 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0006254948265321744 Training loss: 3.2490251064300537
2025-12-09 12:09:17.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0006202624781831269 Training loss: 3.2614152431488037
2025-12-09 12:09:17.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0006150161133303088 Training loss: 3.339339017868042
2025-12-09 12:09:17.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0006097563434337025 Training loss: 3.4167776107788086
2025-12-09 12:09:17.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.0006044837815156376 Training loss: 3.392859697341919
2025-12-09 12:09:17.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.0005991990420893449 Training loss: 3.251948356628418
2025-12-09 12:09:17.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.0005939027410873352 Training loss: 3.304143190383911
2025-12-09 12:09:17.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0005885954957896114 Training loss: 3.42814040184021
2025-12-09 12:09:17.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0005832779247517272 Training loss: 3.179335117340088
2025-12-09 12:09:17.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0005779506477326933 Training loss: 3.226577043533325
2025-12-09 12:09:17.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.0005726142856227452 Training loss: 3.1027841567993164
2025-12-09 12:09:17.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0005672694603709794 Training loss: 3.1106293201446533
2025-12-09 12:09:17.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0005619167949128652 Training loss: 3.312873363494873
2025-12-09 12:09:17.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.0005565569130976422 Training loss: 3.3613219261169434
2025-12-09 12:09:17.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0005511904396156113 Training loss: 3.112075090408325
2025-12-09 12:09:17.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.0005458179999253274 Training loss: 3.2250542640686035
2025-12-09 12:09:17.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0005404402201807021 Training loss: 3.215672731399536
2025-12-09 12:09:17.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.0005350577271580271 Training loss: 3.3876941204071045
2025-12-09 12:09:17.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0005296711481829226 Training loss: 3.1856329441070557
2025-12-09 12:09:17.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.0005242811110572242 Training loss: 3.3778741359710693
2025-12-09 12:09:17.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.0005188882439858117 Training loss: 3.3060076236724854
2025-12-09 12:09:17.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.0005134931755033936 Training loss: 3.210923671722412
2025-12-09 12:09:17.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.0005080965344012508 Training loss: 3.31127667427063
2025-12-09 12:09:17.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.0005026989496539523 Training loss: 3.325978994369507
2025-12-09 12:09:17.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0004973010503460479 Training loss: 3.1976287364959717
2025-12-09 12:09:17.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.0004919034655987492 Training loss: 3.406550645828247
2025-12-09 12:09:17.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0004865068244966066 Training loss: 3.2292537689208984
2025-12-09 12:09:17.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0004811117560141884 Training loss: 3.3332509994506836
2025-12-09 12:09:17.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.000475718888942776 Training loss: 3.4058451652526855
2025-12-09 12:09:17.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0004703288518170774 Training loss: 3.2924201488494873
2025-12-09 12:09:17.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.00046494227284197295 Training loss: 2.954603433609009
2025-12-09 12:09:18.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.00045955977981929796 Training loss: 3.3928146362304688
2025-12-09 12:09:18.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.0004541820000746727 Training loss: 3.3866190910339355
2025-12-09 12:09:18.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.00044880956038438873 Training loss: 3.2957961559295654
2025-12-09 12:09:18.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.0004434430869023579 Training loss: 3.234299898147583
2025-12-09 12:09:18.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.000438083205087135 Training loss: 3.335815906524658
2025-12-09 12:09:18.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.00043273053962902076 Training loss: 3.1053507328033447
2025-12-09 12:09:18.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.000427385714377255 Training loss: 3.3851606845855713
2025-12-09 12:09:18.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.0004220493522673067 Training loss: 2.9796383380889893
2025-12-09 12:09:18.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0004167220752482728 Training loss: 2.942444324493408
2025-12-09 12:09:18.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.00041140450421038864 Training loss: 3.5223910808563232
2025-12-09 12:09:18.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.000406097258912665 Training loss: 3.3376994132995605
2025-12-09 12:09:18.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0004008009579106551 Training loss: 3.1782853603363037
2025-12-09 12:09:18.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.0003955162184843625 Training loss: 3.122279405593872
2025-12-09 12:09:18.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.00039024365656629766 Training loss: 3.0369763374328613
2025-12-09 12:09:18.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0003849838866696913 Training loss: 3.155331611633301
2025-12-09 12:09:18.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.00037973752181687335 Training loss: 3.4066600799560547
2025-12-09 12:09:18.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.00037450517346782563 Training loss: 3.288241386413574
2025-12-09 12:09:18.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0003692874514489173 Training loss: 3.0149359703063965
2025-12-09 12:09:18.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.00036408496388182855 Training loss: 3.3236467838287354
2025-12-09 12:09:18.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0003588983171126762 Training loss: 3.1830170154571533
2025-12-09 12:09:18.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.000353728115641343 Training loss: 3.1620383262634277
2025-12-09 12:09:18.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.0003485749620510247 Training loss: 3.1074817180633545
2025-12-09 12:09:18.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.00034343945693799885 Training loss: 3.076838731765747
2025-12-09 12:09:18.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.00033832219884162584 Training loss: 3.3078041076660156
2025-12-09 12:09:18.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0003332237841745898 Training loss: 3.1956605911254883
2025-12-09 12:09:18.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.00032814480715338666 Training loss: 3.0986809730529785
2025-12-09 12:09:18.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0003230858597290697 Training loss: 3.1220059394836426
2025-12-09 12:09:18.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0003180475315182563 Training loss: 3.090812921524048
2025-12-09 12:09:18.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0003130304097344103 Training loss: 3.081214189529419
2025-12-09 12:09:18.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.0003080350791194019 Training loss: 2.9027063846588135
2025-12-09 12:09:18.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.00030306212187535653 Training loss: 2.985888957977295
2025-12-09 12:09:18.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0002981121175967992 Training loss: 3.2362136840820312
2025-12-09 12:09:18.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.00029318564320310444 Training loss: 3.2363686561584473
2025-12-09 12:09:18.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.0002882832728712551 Training loss: 3.2665421962738037
2025-12-09 12:09:18.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0002834055779689235 Training loss: 3.1541523933410645
2025-12-09 12:09:18.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.00027855312698787905 Training loss: 2.9155044555664062
2025-12-09 12:09:18.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0002737264854777306 Training loss: 3.240668296813965
2025-12-09 12:09:19.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.00026892621598001155 Training loss: 3.5081472396850586
2025-12-09 12:09:19.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0002641528779626171 Training loss: 3.1982667446136475
2025-12-09 12:09:19.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.00025940702775459747 Training loss: 2.840261220932007
2025-12-09 12:09:19.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.00025468921848131984 Training loss: 2.9993646144866943
2025-12-09 12:09:19.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0002500000000000001 Training loss: 3.1183297634124756
2025-12-09 12:09:19.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.00024533991883561866 Training loss: 3.2474708557128906
2025-12-09 12:09:19.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.00024070951811722268 Training loss: 3.288486957550049
2025-12-09 12:09:19.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.00023610933751462554 Training loss: 3.0099332332611084
2025-12-09 12:09:19.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.0002315399131755081 Training loss: 2.972219944000244
2025-12-09 12:09:19.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.00022700177766293096 Training loss: 3.353273391723633
2025-12-09 12:09:19.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.00022249545989326514 Training loss: 3.380249261856079
2025-12-09 12:09:19.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0002180214850745467 Training loss: 3.0167882442474365
2025-12-09 12:09:19.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.00021358037464526514 Training loss: 3.0888328552246094
2025-12-09 12:09:19.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.00020917264621358878 Training loss: 3.207172393798828
2025-12-09 12:09:19.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.00020479881349703882 Training loss: 3.397608518600464
2025-12-09 12:09:19.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.00020045938626261545 Training loss: 3.1436336040496826
2025-12-09 12:09:19.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.00019615487026738542 Training loss: 3.043191432952881
2025-12-09 12:09:19.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.00019188576719953633 Training loss: 2.864285945892334
2025-12-09 12:09:19.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.00018765257461990443 Training loss: 3.0910744667053223
2025-12-09 12:09:19.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0001834557859039851 Training loss: 2.942129135131836
2025-12-09 12:09:19.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.00017929589018443015 Training loss: 3.0002989768981934
2025-12-09 12:09:19.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.00017517337229403947 Training loss: 3.127915382385254
2025-12-09 12:09:19.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.0001710887127092548 Training loss: 3.4705264568328857
2025-12-09 12:09:19.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.00016704238749415957 Training loss: 3.08196759223938
2025-12-09 12:09:19.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0001630348682449946 Training loss: 3.0320169925689697
2025-12-09 12:09:19.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.00015906662203519413 Training loss: 3.2321743965148926
2025-12-09 12:09:19.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.00015513811136094787 Training loss: 3.196728467941284
2025-12-09 12:09:19.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.0001512497940872986 Training loss: 3.046377420425415
2025-12-09 12:09:19.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.0001474021233947772 Training loss: 3.0347023010253906
2025-12-09 12:09:19.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.00014359554772658552 Training loss: 3.114652633666992
2025-12-09 12:09:19.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.00013983051073632996 Training loss: 3.070955514907837
2025-12-09 12:09:19.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.00013610745123631535 Training loss: 3.055513381958008
2025-12-09 12:09:19.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.00013242680314639994 Training loss: 3.1437549591064453
2025-12-09 12:09:19.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.00012878899544342326 Training loss: 3.2042665481567383
2025-12-09 12:09:19.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.00012519445211120977 Training loss: 3.1323628425598145
2025-12-09 12:09:19.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.00012164359209115234 Training loss: 3.010483741760254
2025-12-09 12:09:19.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.00011813682923338653 Training loss: 3.22316837310791
2025-12-09 12:09:19.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.00011467457224855543 Training loss: 3.1557717323303223
2025-12-09 12:09:20.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.00011125722466017545 Training loss: 3.1257622241973877
2025-12-09 12:09:20.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.00010788518475760544 Training loss: 2.9180965423583984
2025-12-09 12:09:20.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.00010455884554962725 Training loss: 3.282376527786255
2025-12-09 12:09:20.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.0001012785947186397 Training loss: 3.137205123901367
2025-12-09 12:09:20.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 9.804481457547498e-05 Training loss: 3.153491258621216
2025-12-09 12:09:20.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 9.485788201484124e-05 Training loss: 3.3390543460845947
2025-12-09 12:09:20.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 9.171816847139447e-05 Training loss: 3.071697950363159
2025-12-09 12:09:20.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 8.862603987644941e-05 Training loss: 3.0913050174713135
2025-12-09 12:09:20.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 8.558185661532942e-05 Training loss: 3.1263949871063232
2025-12-09 12:09:20.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 8.258597348536451e-05 Training loss: 3.1573565006256104
2025-12-09 12:09:20.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 7.96387396545396e-05 Training loss: 3.186473846435547
2025-12-09 12:09:20.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 7.674049862079991e-05 Training loss: 3.0633368492126465
2025-12-09 12:09:20.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 7.38915881720154e-05 Training loss: 3.1564888954162598
2025-12-09 12:09:20.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 7.109234034661289e-05 Training loss: 3.165513515472412
2025-12-09 12:09:20.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 6.834308139487671e-05 Training loss: 3.0134124755859375
2025-12-09 12:09:20.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 6.564413174092443e-05 Training loss: 3.1487486362457275
2025-12-09 12:09:20.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 6.299580594536214e-05 Training loss: 3.1813035011291504
2025-12-09 12:09:20.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 6.0398412668621897e-05 Training loss: 3.18255877494812
2025-12-09 12:09:20.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 5.785225463498828e-05 Training loss: 3.085847854614258
2025-12-09 12:09:20.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 5.535762859731547e-05 Training loss: 2.901620626449585
2025-12-09 12:09:20.535 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 5.291482530244179e-05 Training loss: 3.255058765411377
2025-12-09 12:09:20.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 5.0524129457302394e-05 Training loss: 2.8630542755126953
2025-12-09 12:09:20.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 4.818581969574742e-05 Training loss: 2.9862208366394043
2025-12-09 12:09:20.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 4.5900168546067264e-05 Training loss: 3.1815543174743652
2025-12-09 12:09:20.639 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 4.366744239922998e-05 Training loss: 3.1705729961395264
2025-12-09 12:09:20.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 4.148790147783288e-05 Training loss: 3.065471887588501
2025-12-09 12:09:20.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 3.936179980577453e-05 Training loss: 2.9494898319244385
2025-12-09 12:09:20.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 3.728938517864794e-05 Training loss: 2.9353296756744385
2025-12-09 12:09:20.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 3.527089913486037e-05 Training loss: 3.0202202796936035
2025-12-09 12:09:20.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 3.330657692748212e-05 Training loss: 3.011760950088501
2025-12-09 12:09:20.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 3.1396647496828245e-05 Training loss: 2.9748878479003906
2025-12-09 12:09:20.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 2.9541333443775243e-05 Training loss: 3.024543046951294
2025-12-09 12:09:20.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 2.7740851003817347e-05 Training loss: 3.062976598739624
2025-12-09 12:09:20.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 2.5995410021864786e-05 Training loss: 3.212524652481079
2025-12-09 12:09:20.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 2.430521392778573e-05 Training loss: 2.9893665313720703
2025-12-09 12:09:20.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 2.2670459712697378e-05 Training loss: 3.1297597885131836
2025-12-09 12:09:20.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 2.109133790600648e-05 Training loss: 3.0053257942199707
2025-12-09 12:09:20.982 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 1.956803255320322e-05 Training loss: 2.936614513397217
2025-12-09 12:09:21.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 1.810072119441103e-05 Training loss: 3.2976956367492676
2025-12-09 12:09:21.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 1.6689574843694434e-05 Training loss: 2.990933418273926
2025-12-09 12:09:21.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 1.53347579691272e-05 Training loss: 3.1919407844543457
2025-12-09 12:09:21.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 1.4036428473624019e-05 Training loss: 2.8590407371520996
2025-12-09 12:09:21.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 1.2794737676536993e-05 Training loss: 2.9946448802948
2025-12-09 12:09:21.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 1.1609830296019142e-05 Training loss: 3.0953004360198975
2025-12-09 12:09:21.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 1.048184443215816e-05 Training loss: 3.100318431854248
2025-12-09 12:09:21.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.410911550880474e-06 Training loss: 3.006666898727417
2025-12-09 12:09:21.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 8.397156468629207e-06 Training loss: 3.1773955821990967
2025-12-09 12:09:21.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 7.440697337816771e-06 Training loss: 3.008298873901367
2025-12-09 12:09:21.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 6.541645633054649e-06 Training loss: 3.1008260250091553
2025-12-09 12:09:21.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 5.700106138160688e-06 Training loss: 3.2917561531066895
2025-12-09 12:09:21.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 4.916176933946692e-06 Training loss: 3.083470582962036
2025-12-09 12:09:21.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 4.189949386787462e-06 Training loss: 2.9920847415924072
2025-12-09 12:09:21.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 3.521508137971807e-06 Training loss: 2.914149284362793
2025-12-09 12:09:21.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 2.9109310938378875e-06 Training loss: 3.1162850856781006
2025-12-09 12:09:21.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 2.3582894166930268e-06 Training loss: 3.0260279178619385
2025-12-09 12:09:21.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 1.8636475165200173e-06 Training loss: 2.8754515647888184
2025-12-09 12:09:21.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 1.4270630434701782e-06 Training loss: 3.2164785861968994
2025-12-09 12:09:21.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 1.0485868811441758e-06 Training loss: 3.0323026180267334
2025-12-09 12:09:21.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 7.282631406615448e-07 Training loss: 2.944396495819092
2025-12-09 12:09:21.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 4.6612915551963455e-07 Training loss: 3.0973634719848633
2025-12-09 12:09:21.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 2.6221547724253336e-07 Training loss: 3.1554181575775146
2025-12-09 12:09:21.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 1.1654587182013953e-07 Training loss: 3.2025370597839355
2025-12-09 12:09:21.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 2.9137316938265823e-08 Training loss: 2.9282970428466797
2025-12-09 12:09:21.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0 Training loss: 2.993347644805908
