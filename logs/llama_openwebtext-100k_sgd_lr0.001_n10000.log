2025-12-09 12:59:06.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.137935638427734
2025-12-09 12:59:07.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.178789138793945
2025-12-09 12:59:07.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 12.173369407653809
2025-12-09 12:59:07.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 12.221269607543945
2025-12-09 12:59:08.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 12.188817024230957
2025-12-09 12:59:08.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 12.140146255493164
2025-12-09 12:59:08.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 12.264005661010742
2025-12-09 12:59:09.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 12.129694938659668
2025-12-09 12:59:09.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 12.141913414001465
2025-12-09 12:59:09.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 12.1560640335083
2025-12-09 12:59:10.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 12.198697090148926
2025-12-09 12:59:10.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 12.129362106323242
2025-12-09 12:59:11.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 12.184121131896973
2025-12-09 12:59:11.456 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 12.212296485900879
2025-12-09 12:59:11.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 12.201111793518066
2025-12-09 12:59:12.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 12.086747169494629
2025-12-09 12:59:12.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 12.147589683532715
2025-12-09 12:59:12.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 12.143519401550293
2025-12-09 12:59:13.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 12.134771347045898
2025-12-09 12:59:13.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 12.11362075805664
2025-12-09 12:59:14.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 12.102848052978516
2025-12-09 12:59:14.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 12.144946098327637
2025-12-09 12:59:14.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 12.062349319458008
2025-12-09 12:59:15.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 12.126548767089844
2025-12-09 12:59:15.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 12.119095802307129
2025-12-09 12:59:15.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 12.099289894104004
2025-12-09 12:59:16.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 12.072470664978027
2025-12-09 12:59:16.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 12.041607856750488
2025-12-09 12:59:17.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 12.024762153625488
2025-12-09 12:59:17.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 12.125921249389648
2025-12-09 12:59:17.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 11.980693817138672
2025-12-09 12:59:18.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 11.975509643554688
2025-12-09 12:59:18.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 11.896003723144531
2025-12-09 12:59:18.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 11.882841110229492
2025-12-09 12:59:19.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 11.93174934387207
2025-12-09 12:59:19.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 11.96211051940918
2025-12-09 12:59:20.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 11.8009033203125
2025-12-09 12:59:20.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 11.912639617919922
2025-12-09 12:59:20.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 11.76193618774414
2025-12-09 12:59:21.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 11.765238761901855
2025-12-09 12:59:21.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 11.7529878616333
2025-12-09 12:59:21.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 11.66698169708252
2025-12-09 12:59:22.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 11.677132606506348
2025-12-09 12:59:22.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 11.84012222290039
2025-12-09 12:59:22.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 11.457876205444336
2025-12-09 12:59:23.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 11.510994911193848
2025-12-09 12:59:23.739 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 11.328808784484863
2025-12-09 12:59:24.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 11.56597900390625
2025-12-09 12:59:24.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 11.345779418945312
2025-12-09 12:59:24.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 11.276752471923828
2025-12-09 12:59:25.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 11.047534942626953
2025-12-09 12:59:25.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 10.964014053344727
2025-12-09 12:59:25.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 10.786998748779297
2025-12-09 12:59:26.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 10.892854690551758
2025-12-09 12:59:26.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 10.733841896057129
2025-12-09 12:59:27.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 10.834040641784668
2025-12-09 12:59:27.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 10.73005485534668
2025-12-09 12:59:27.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 10.736184120178223
2025-12-09 12:59:28.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 10.494820594787598
2025-12-09 12:59:28.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 10.995670318603516
2025-12-09 12:59:28.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 10.652786254882812
2025-12-09 12:59:29.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 10.240823745727539
2025-12-09 12:59:29.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 10.492606163024902
2025-12-09 12:59:30.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 10.66700553894043
2025-12-09 12:59:30.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 10.230242729187012
2025-12-09 12:59:30.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 10.251350402832031
2025-12-09 12:59:31.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 10.24189567565918
2025-12-09 12:59:31.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 9.983833312988281
2025-12-09 12:59:31.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 10.078245162963867
2025-12-09 12:59:32.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 10.031977653503418
2025-12-09 12:59:32.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 10.262140274047852
2025-12-09 12:59:33.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 10.498931884765625
2025-12-09 12:59:33.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 10.02877140045166
2025-12-09 12:59:33.783 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 10.080604553222656
2025-12-09 12:59:34.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 10.002663612365723
2025-12-09 12:59:34.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 10.347408294677734
2025-12-09 12:59:34.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 9.941997528076172
2025-12-09 12:59:35.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 10.112570762634277
2025-12-09 12:59:35.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 9.862850189208984
2025-12-09 12:59:36.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 9.971816062927246
2025-12-09 12:59:36.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 9.785957336425781
2025-12-09 12:59:36.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 9.652910232543945
2025-12-09 12:59:37.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 9.953611373901367
2025-12-09 12:59:37.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 10.04456901550293
2025-12-09 12:59:37.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 9.905428886413574
2025-12-09 12:59:38.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 9.669769287109375
2025-12-09 12:59:38.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 10.500260353088379
2025-12-09 12:59:38.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 9.842129707336426
2025-12-09 12:59:39.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 10.151945114135742
2025-12-09 12:59:39.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 9.70368766784668
2025-12-09 12:59:40.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 9.912490844726562
2025-12-09 12:59:40.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 9.87569522857666
2025-12-09 12:59:40.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 9.754172325134277
2025-12-09 12:59:41.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 9.69719123840332
2025-12-09 12:59:41.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 9.67518424987793
2025-12-09 12:59:41.955 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 9.550548553466797
2025-12-09 12:59:42.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 9.582671165466309
2025-12-09 12:59:42.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 9.591779708862305
2025-12-09 12:59:43.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 9.760870933532715
2025-12-09 12:59:43.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 9.628135681152344
2025-12-09 12:59:43.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0009999999029798809 Training loss: 9.455211639404297
2025-12-09 12:59:44.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.000999999611919561 Training loss: 9.57008171081543
2025-12-09 12:59:44.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0009999991268191536 Training loss: 9.706546783447266
2025-12-09 12:59:44.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0009999984476788465 Training loss: 9.448872566223145
2025-12-09 12:59:45.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0009999975744989036 Training loss: 9.487771987915039
2025-12-09 12:59:45.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0009999965072796635 Training loss: 9.604016304016113
2025-12-09 12:59:46.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0009999952460215409 Training loss: 9.23054313659668
2025-12-09 12:59:46.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0009999937907250245 Training loss: 9.433575630187988
2025-12-09 12:59:46.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0009999921413906799 Training loss: 9.394303321838379
2025-12-09 12:59:47.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.0009999902980191463 Training loss: 9.884955406188965
2025-12-09 12:59:47.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.00099998826061114 Training loss: 9.599754333496094
2025-12-09 12:59:47.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0009999860291674508 Training loss: 9.514817237854004
2025-12-09 12:59:48.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0009999836036889453 Training loss: 9.976180076599121
2025-12-09 12:59:48.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0009999809841765644 Training loss: 9.454767227172852
2025-12-09 12:59:49.014 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.000999978170631325 Training loss: 9.42126178741455
2025-12-09 12:59:49.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0009999751630543187 Training loss: 9.5495023727417
2025-12-09 12:59:49.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.000999971961446713 Training loss: 9.427550315856934
2025-12-09 12:59:50.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.0009999685658097501 Training loss: 9.590789794921875
2025-12-09 12:59:50.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0009999649761447478 Training loss: 9.460347175598145
2025-12-09 12:59:50.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.0009999611924530994 Training loss: 9.474245071411133
2025-12-09 12:59:51.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.000999957214736273 Training loss: 9.262328147888184
2025-12-09 12:59:51.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.0009999530429958125 Training loss: 10.202817916870117
2025-12-09 12:59:51.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.0009999486772333365 Training loss: 9.374048233032227
2025-12-09 12:59:52.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.00099994411745054 Training loss: 9.228412628173828
2025-12-09 12:59:52.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0009999393636491917 Training loss: 9.781554222106934
2025-12-09 12:59:53.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.000999934415831137 Training loss: 9.422042846679688
2025-12-09 12:59:53.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.000999929273998296 Training loss: 9.244505882263184
2025-12-09 12:59:53.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.0009999239381526638 Training loss: 9.458905220031738
2025-12-09 12:59:54.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0009999184082963117 Training loss: 9.292396545410156
2025-12-09 12:59:54.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.0009999126844313852 Training loss: 9.42265796661377
2025-12-09 12:59:54.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.000999906766560106 Training loss: 9.383087158203125
2025-12-09 12:59:55.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.0009999006546847706 Training loss: 9.310324668884277
2025-12-09 12:59:55.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0009998943488077508 Training loss: 9.384669303894043
2025-12-09 12:59:56.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.0009998878489314938 Training loss: 9.277446746826172
2025-12-09 12:59:56.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.000999881155058522 Training loss: 9.268464088439941
2025-12-09 12:59:56.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0009998742671914335 Training loss: 9.32143783569336
2025-12-09 12:59:57.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.000999867185332901 Training loss: 9.104493141174316
2025-12-09 12:59:57.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.000999859909485673 Training loss: 9.63952922821045
2025-12-09 12:59:57.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.000999852439652573 Training loss: 9.468714714050293
2025-12-09 12:59:58.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0009998447758365 Training loss: 9.549199104309082
2025-12-09 12:59:58.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0009998369180404282 Training loss: 9.364264488220215
2025-12-09 12:59:59.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.000999828866267407 Training loss: 9.6237211227417
2025-12-09 12:59:59.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0009998206205205612 Training loss: 9.33860969543457
2025-12-09 12:59:59.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.0009998121808030905 Training loss: 9.466333389282227
2025-12-09 13:00:00.156 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0009998035471182707 Training loss: 9.413479804992676
2025-12-09 13:00:00.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.000999794719469452 Training loss: 9.695045471191406
2025-12-09 13:00:00.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0009997856978600603 Training loss: 9.495341300964355
2025-12-09 13:00:01.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0009997764822935967 Training loss: 9.147696495056152
2025-12-09 13:00:01.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.000999767072773638 Training loss: 9.531203269958496
2025-12-09 13:00:02.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0009997574693038351 Training loss: 9.387727737426758
2025-12-09 13:00:02.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0009997476718879154 Training loss: 8.981892585754395
2025-12-09 13:00:02.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.000999737680529681 Training loss: 9.438444137573242
2025-12-09 13:00:03.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0009997274952330093 Training loss: 9.0440092086792
2025-12-09 13:00:03.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.000999717116001853 Training loss: 9.308989524841309
2025-12-09 13:00:03.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.0009997065428402404 Training loss: 9.157726287841797
2025-12-09 13:00:04.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0009996957757522741 Training loss: 9.092020034790039
2025-12-09 13:00:04.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.0009996848147421334 Training loss: 9.2090482711792
2025-12-09 13:00:04.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0009996736598140714 Training loss: 9.128933906555176
2025-12-09 13:00:05.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.0009996623109724174 Training loss: 9.209988594055176
2025-12-09 13:00:05.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0009996507682215755 Training loss: 9.183797836303711
2025-12-09 13:00:06.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.0009996390315660253 Training loss: 9.141694068908691
2025-12-09 13:00:06.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.0009996271010103215 Training loss: 9.119421005249023
2025-12-09 13:00:06.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.0009996149765590945 Training loss: 9.262201309204102
2025-12-09 13:00:07.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.000999602658217049 Training loss: 9.182042121887207
2025-12-09 13:00:07.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0009995901459889658 Training loss: 9.5828857421875
2025-12-09 13:00:07.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.0009995774398797008 Training loss: 9.190921783447266
2025-12-09 13:00:08.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.0009995645398941846 Training loss: 9.06434440612793
2025-12-09 13:00:08.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0009995514460374238 Training loss: 9.050759315490723
2025-12-09 13:00:09.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.0009995381583144996 Training loss: 9.56811237335205
2025-12-09 13:00:09.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.0009995246767305688 Training loss: 9.009742736816406
2025-12-09 13:00:09.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0009995110012908633 Training loss: 9.071126937866211
2025-12-09 13:00:10.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.0009994971320006906 Training loss: 9.26402759552002
2025-12-09 13:00:10.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0009994830688654327 Training loss: 9.149270057678223
2025-12-09 13:00:10.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.000999468811890547 Training loss: 9.38447093963623
2025-12-09 13:00:11.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.000999454361081567 Training loss: 9.145365715026855
2025-12-09 13:00:11.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.0009994397164441006 Training loss: 9.4594087600708
2025-12-09 13:00:12.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.000999424877983831 Training loss: 9.119239807128906
2025-12-09 13:00:12.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0009994098457065167 Training loss: 9.080266952514648
2025-12-09 13:00:12.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.0009993946196179913 Training loss: 9.167706489562988
2025-12-09 13:00:13.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.000999379199724164 Training loss: 9.26475715637207
2025-12-09 13:00:13.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0009993635860310187 Training loss: 9.191400527954102
2025-12-09 13:00:13.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.000999347778544615 Training loss: 9.151095390319824
2025-12-09 13:00:14.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.0009993317772710873 Training loss: 9.002920150756836
2025-12-09 13:00:14.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.0009993155822166457 Training loss: 9.137007713317871
2025-12-09 13:00:15.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.0009992991933875748 Training loss: 8.96234130859375
2025-12-09 13:00:15.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0009992826107902348 Training loss: 9.338290214538574
2025-12-09 13:00:15.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.0009992658344310614 Training loss: 8.956343650817871
2025-12-09 13:00:16.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.000999248864316565 Training loss: 9.199254035949707
2025-12-09 13:00:16.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0009992317004533314 Training loss: 9.195355415344238
2025-12-09 13:00:16.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.0009992143428480215 Training loss: 9.153220176696777
2025-12-09 13:00:17.245 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0009991967915073715 Training loss: 8.87348461151123
2025-12-09 13:00:17.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0009991790464381925 Training loss: 9.144179344177246
2025-12-09 13:00:17.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.0009991611076473714 Training loss: 9.43064022064209
2025-12-09 13:00:18.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.0009991429751418698 Training loss: 8.9924955368042
2025-12-09 13:00:18.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.0009991246489287244 Training loss: 9.314881324768066
2025-12-09 13:00:19.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0009991061290150474 Training loss: 9.020210266113281
2025-12-09 13:00:19.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0009990874154080258 Training loss: 9.28157901763916
2025-12-09 13:00:19.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.0009990685081149222 Training loss: 9.131901741027832
2025-12-09 13:00:20.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0009990494071430741 Training loss: 9.299622535705566
2025-12-09 13:00:20.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0009990301124998943 Training loss: 9.137345314025879
2025-12-09 13:00:20.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0009990106241928704 Training loss: 9.228001594543457
2025-12-09 13:00:21.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0009989909422295658 Training loss: 8.982528686523438
2025-12-09 13:00:21.699 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0009989710666176185 Training loss: 8.974932670593262
2025-12-09 13:00:22.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0009989509973647418 Training loss: 9.214588165283203
2025-12-09 13:00:22.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0009989307344787242 Training loss: 8.97619342803955
2025-12-09 13:00:22.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0009989102779674292 Training loss: 8.985005378723145
2025-12-09 13:00:23.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.000998889627838796 Training loss: 9.286198616027832
2025-12-09 13:00:23.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.000998868784100838 Training loss: 9.199370384216309
2025-12-09 13:00:23.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.0009988477467616447 Training loss: 8.929740905761719
2025-12-09 13:00:24.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0009988265158293798 Training loss: 8.998412132263184
2025-12-09 13:00:24.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.000998805091312283 Training loss: 9.062339782714844
2025-12-09 13:00:25.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.0009987834732186687 Training loss: 9.31432056427002
2025-12-09 13:00:25.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0009987616615569263 Training loss: 9.271262168884277
2025-12-09 13:00:25.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.0009987396563355204 Training loss: 9.281968116760254
2025-12-09 13:00:26.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.000998717457562991 Training loss: 9.102042198181152
2025-12-09 13:00:26.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.0009986950652479533 Training loss: 9.003632545471191
2025-12-09 13:00:26.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0009986724793990967 Training loss: 9.013727188110352
2025-12-09 13:00:27.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.0009986497000251866 Training loss: 9.273077011108398
2025-12-09 13:00:27.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.0009986267271350634 Training loss: 8.901498794555664
2025-12-09 13:00:28.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0009986035607376421 Training loss: 9.047677040100098
2025-12-09 13:00:28.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.0009985802008419132 Training loss: 8.894655227661133
2025-12-09 13:00:28.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0009985566474569425 Training loss: 9.08566665649414
2025-12-09 13:00:29.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0009985329005918703 Training loss: 9.049214363098145
2025-12-09 13:00:29.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.0009985089602559125 Training loss: 8.84961986541748
2025-12-09 13:00:29.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0009984848264583597 Training loss: 9.065335273742676
2025-12-09 13:00:30.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.000998460499208578 Training loss: 9.127481460571289
2025-12-09 13:00:30.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.000998435978516008 Training loss: 8.890545845031738
2025-12-09 13:00:30.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.0009984112643901658 Training loss: 9.075743675231934
2025-12-09 13:00:31.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0009983863568406427 Training loss: 9.134389877319336
2025-12-09 13:00:31.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0009983612558771048 Training loss: 9.046087265014648
2025-12-09 13:00:32.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0009983359615092931 Training loss: 9.31141471862793
2025-12-09 13:00:32.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.000998310473747024 Training loss: 8.935006141662598
2025-12-09 13:00:32.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0009982847926001885 Training loss: 8.974495887756348
2025-12-09 13:00:33.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0009982589180787533 Training loss: 9.480904579162598
2025-12-09 13:00:33.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.0009982328501927599 Training loss: 8.948978424072266
2025-12-09 13:00:33.953 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0009982065889523242 Training loss: 8.758326530456543
2025-12-09 13:00:34.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.000998180134367638 Training loss: 9.322686195373535
2025-12-09 13:00:34.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0009981534864489678 Training loss: 8.984633445739746
2025-12-09 13:00:35.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.0009981266452066553 Training loss: 8.975831985473633
2025-12-09 13:00:35.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0009980996106511168 Training loss: 8.946418762207031
2025-12-09 13:00:35.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.000998072382792844 Training loss: 8.887574195861816
2025-12-09 13:00:36.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.0009980449616424037 Training loss: 9.019353866577148
2025-12-09 13:00:36.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.000998017347210437 Training loss: 8.968107223510742
2025-12-09 13:00:36.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.000997989539507661 Training loss: 9.328836441040039
2025-12-09 13:00:37.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.000997961538544867 Training loss: 8.959345817565918
2025-12-09 13:00:37.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0009979333443329217 Training loss: 8.935186386108398
2025-12-09 13:00:38.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.000997904956882767 Training loss: 9.46858024597168
2025-12-09 13:00:38.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0009978763762054192 Training loss: 9.758927345275879
2025-12-09 13:00:38.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.00099784760231197 Training loss: 8.943705558776855
2025-12-09 13:00:39.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.000997818635213586 Training loss: 9.093546867370605
2025-12-09 13:00:39.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0009977894749215088 Training loss: 9.067055702209473
2025-12-09 13:00:39.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.000997760121447055 Training loss: 9.072340965270996
2025-12-09 13:00:40.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0009977305748016159 Training loss: 8.979072570800781
2025-12-09 13:00:40.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.000997700834996658 Training loss: 9.488059043884277
2025-12-09 13:00:41.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.000997670902043723 Training loss: 8.852107048034668
2025-12-09 13:00:41.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.000997640775954427 Training loss: 8.896976470947266
2025-12-09 13:00:41.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.0009976104567404615 Training loss: 8.89536190032959
2025-12-09 13:00:42.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0009975799444135929 Training loss: 9.45689868927002
2025-12-09 13:00:42.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.0009975492389856621 Training loss: 9.463274002075195
2025-12-09 13:00:42.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.0009975183404685856 Training loss: 9.244111061096191
2025-12-09 13:00:43.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0009974872488743543 Training loss: 9.076839447021484
2025-12-09 13:00:43.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0009974559642150344 Training loss: 9.162982940673828
2025-12-09 13:00:43.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.000997424486502767 Training loss: 9.07947063446045
2025-12-09 13:00:44.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0009973928157497674 Training loss: 8.90294361114502
2025-12-09 13:00:44.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.000997360951968327 Training loss: 9.164362907409668
2025-12-09 13:00:45.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.0009973288951708112 Training loss: 9.161715507507324
2025-12-09 13:00:45.465 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0009972966453696609 Training loss: 9.076441764831543
2025-12-09 13:00:45.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.0009972642025773912 Training loss: 8.9668550491333
2025-12-09 13:00:46.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.0009972315668065929 Training loss: 8.811701774597168
2025-12-09 13:00:46.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.000997198738069931 Training loss: 8.956802368164062
2025-12-09 13:00:46.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.000997165716380146 Training loss: 8.984185218811035
2025-12-09 13:00:47.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0009971325017500525 Training loss: 8.864418029785156
2025-12-09 13:00:47.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.0009970990941925411 Training loss: 9.030268669128418
2025-12-09 13:00:48.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.0009970654937205762 Training loss: 8.942254066467285
2025-12-09 13:00:48.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0009970317003471976 Training loss: 9.342601776123047
2025-12-09 13:00:48.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.0009969977140855198 Training loss: 9.032618522644043
2025-12-09 13:00:49.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0009969635349487322 Training loss: 9.606302261352539
2025-12-09 13:00:49.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.000996929162950099 Training loss: 9.114492416381836
2025-12-09 13:00:49.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0009968945981029596 Training loss: 8.843073844909668
2025-12-09 13:00:50.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0009968598404207275 Training loss: 8.833215713500977
2025-12-09 13:00:50.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0009968248899168918 Training loss: 8.984464645385742
2025-12-09 13:00:51.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.000996789746605016 Training loss: 8.945331573486328
2025-12-09 13:00:51.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0009967544104987386 Training loss: 8.67014217376709
2025-12-09 13:00:51.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0009967188816117727 Training loss: 8.919093132019043
2025-12-09 13:00:52.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0009966831599579067 Training loss: 8.843318939208984
2025-12-09 13:00:52.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.000996647245551003 Training loss: 9.001173973083496
2025-12-09 13:00:52.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0009966111384049996 Training loss: 9.406563758850098
2025-12-09 13:00:53.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0009965748385339088 Training loss: 8.601317405700684
2025-12-09 13:00:53.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0009965383459518181 Training loss: 9.138169288635254
2025-12-09 13:00:54.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0009965016606728893 Training loss: 9.142014503479004
2025-12-09 13:00:54.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0009964647827113596 Training loss: 9.076656341552734
2025-12-09 13:00:54.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.0009964277120815403 Training loss: 9.18234920501709
2025-12-09 13:00:55.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.0009963904487978177 Training loss: 8.68591594696045
2025-12-09 13:00:55.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0009963529928746534 Training loss: 8.85468864440918
2025-12-09 13:00:55.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0009963153443265829 Training loss: 8.896795272827148
2025-12-09 13:00:56.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.0009962775031682168 Training loss: 8.891578674316406
2025-12-09 13:00:56.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.0009962394694142409 Training loss: 9.101744651794434
2025-12-09 13:00:56.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.0009962012430794153 Training loss: 9.061582565307617
2025-12-09 13:00:57.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.0009961628241785747 Training loss: 8.944170951843262
2025-12-09 13:00:57.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0009961242127266288 Training loss: 9.121068000793457
2025-12-09 13:00:58.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0009960854087385617 Training loss: 8.850955963134766
2025-12-09 13:00:58.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.000996046412229433 Training loss: 8.71349811553955
2025-12-09 13:00:58.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0009960072232143762 Training loss: 9.220148086547852
2025-12-09 13:00:59.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.0009959678417085997 Training loss: 8.849742889404297
2025-12-09 13:00:59.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0009959282677273868 Training loss: 8.831128120422363
2025-12-09 13:00:59.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0009958885012860954 Training loss: 8.813066482543945
2025-12-09 13:01:00.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.0009958485424001581 Training loss: 8.68796443939209
2025-12-09 13:01:00.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0009958083910850822 Training loss: 9.08593463897705
2025-12-09 13:01:01.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0009957680473564494 Training loss: 8.999424934387207
2025-12-09 13:01:01.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.0009957275112299165 Training loss: 8.867953300476074
2025-12-09 13:01:01.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0009956867827212148 Training loss: 8.992618560791016
2025-12-09 13:01:02.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.00099564586184615 Training loss: 8.729813575744629
2025-12-09 13:01:02.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0009956047486206032 Training loss: 9.299975395202637
2025-12-09 13:01:02.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0009955634430605291 Training loss: 8.918527603149414
2025-12-09 13:01:03.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.000995521945181958 Training loss: 8.654401779174805
2025-12-09 13:01:03.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0009954802550009943 Training loss: 9.100203514099121
2025-12-09 13:01:04.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.0009954383725338167 Training loss: 9.608113288879395
2025-12-09 13:01:04.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.0009953962977966794 Training loss: 8.724231719970703
2025-12-09 13:01:04.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.000995354030805911 Training loss: 8.931002616882324
2025-12-09 13:01:05.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0009953115715779141 Training loss: 9.228940963745117
2025-12-09 13:01:05.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.0009952689201291663 Training loss: 9.112866401672363
2025-12-09 13:01:05.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.00099522607647622 Training loss: 8.879677772521973
2025-12-09 13:01:06.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.0009951830406357018 Training loss: 9.07344913482666
2025-12-09 13:01:06.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.0009951398126243135 Training loss: 8.696102142333984
2025-12-09 13:01:07.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.0009950963924588304 Training loss: 9.086047172546387
2025-12-09 13:01:07.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.0009950527801561033 Training loss: 8.759856224060059
2025-12-09 13:01:07.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0009950089757330574 Training loss: 8.936968803405762
2025-12-09 13:01:08.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0009949649792066922 Training loss: 8.868927955627441
2025-12-09 13:01:08.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.000994920790594082 Training loss: 9.713040351867676
2025-12-09 13:01:08.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.0009948764099123755 Training loss: 8.864686012268066
2025-12-09 13:01:09.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.000994831837178796 Training loss: 8.806381225585938
2025-12-09 13:01:09.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.000994787072410641 Training loss: 8.93377685546875
2025-12-09 13:01:09.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0009947421156252835 Training loss: 8.82165813446045
2025-12-09 13:01:10.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.0009946969668401698 Training loss: 9.31235408782959
2025-12-09 13:01:10.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.0009946516260728212 Training loss: 8.821179389953613
2025-12-09 13:01:11.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.000994606093340834 Training loss: 9.060606002807617
2025-12-09 13:01:11.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.0009945603686618784 Training loss: 9.079970359802246
2025-12-09 13:01:11.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.000994514452053699 Training loss: 9.064461708068848
2025-12-09 13:01:12.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.0009944683435341155 Training loss: 8.941243171691895
2025-12-09 13:01:12.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.0009944220431210215 Training loss: 9.10112190246582
2025-12-09 13:01:12.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.0009943755508323854 Training loss: 9.187788963317871
2025-12-09 13:01:13.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.0009943288666862497 Training loss: 8.62945556640625
2025-12-09 13:01:13.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.000994281990700732 Training loss: 9.055447578430176
2025-12-09 13:01:14.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.0009942349228940237 Training loss: 8.73198413848877
2025-12-09 13:01:14.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.0009941876632843908 Training loss: 8.890374183654785
2025-12-09 13:01:14.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.0009941402118901744 Training loss: 9.064692497253418
2025-12-09 13:01:15.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0009940925687297885 Training loss: 8.843194961547852
2025-12-09 13:01:15.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0009940447338217234 Training loss: 8.787732124328613
2025-12-09 13:01:15.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0009939967071845423 Training loss: 8.814430236816406
2025-12-09 13:01:16.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.0009939484888368837 Training loss: 8.850788116455078
2025-12-09 13:01:16.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.0009939000787974601 Training loss: 9.003788948059082
2025-12-09 13:01:17.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.0009938514770850585 Training loss: 8.906756401062012
2025-12-09 13:01:17.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.0009938026837185403 Training loss: 9.048709869384766
2025-12-09 13:01:17.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.0009937536987168413 Training loss: 8.99294662475586
2025-12-09 13:01:18.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0009937045220989715 Training loss: 9.012145042419434
2025-12-09 13:01:18.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0009936551538840153 Training loss: 8.873952865600586
2025-12-09 13:01:18.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.000993605594091132 Training loss: 8.950578689575195
2025-12-09 13:01:19.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.000993555842739554 Training loss: 8.925192832946777
2025-12-09 13:01:19.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0009935058998485897 Training loss: 8.622367858886719
2025-12-09 13:01:20.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.0009934557654376205 Training loss: 8.761558532714844
2025-12-09 13:01:20.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.0009934054395261025 Training loss: 8.824812889099121
2025-12-09 13:01:20.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.0009933549221335664 Training loss: 9.044198989868164
2025-12-09 13:01:21.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.000993304213279617 Training loss: 9.050637245178223
2025-12-09 13:01:21.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0009932533129839334 Training loss: 8.929473876953125
2025-12-09 13:01:21.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.000993202221266269 Training loss: 8.864115715026855
2025-12-09 13:01:22.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.0009931509381464515 Training loss: 9.218267440795898
2025-12-09 13:01:22.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.0009930994636443828 Training loss: 8.925861358642578
2025-12-09 13:01:22.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.0009930477977800392 Training loss: 9.273713111877441
2025-12-09 13:01:23.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.000992995940573471 Training loss: 8.65691089630127
2025-12-09 13:01:23.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.0009929438920448037 Training loss: 9.23355484008789
2025-12-09 13:01:24.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.0009928916522142356 Training loss: 9.148368835449219
2025-12-09 13:01:24.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.00099283922110204 Training loss: 8.965410232543945
2025-12-09 13:01:24.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.0009927865987285648 Training loss: 8.808692932128906
2025-12-09 13:01:25.201 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.0009927337851142314 Training loss: 8.877184867858887
2025-12-09 13:01:25.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.000992680780279536 Training loss: 8.88927936553955
2025-12-09 13:01:25.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.0009926275842450482 Training loss: 8.947260856628418
2025-12-09 13:01:26.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.0009925741970314129 Training loss: 8.651219367980957
2025-12-09 13:01:26.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.0009925206186593484 Training loss: 8.713417053222656
2025-12-09 13:01:27.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.0009924668491496473 Training loss: 9.135381698608398
2025-12-09 13:01:27.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.000992412888523177 Training loss: 9.007896423339844
2025-12-09 13:01:27.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.000992358736800878 Training loss: 8.917159080505371
2025-12-09 13:01:28.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.0009923043940037657 Training loss: 8.931578636169434
2025-12-09 13:01:28.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.0009922498601529295 Training loss: 9.282635688781738
2025-12-09 13:01:28.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.000992195135269533 Training loss: 8.898107528686523
2025-12-09 13:01:29.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0009921402193748137 Training loss: 8.993722915649414
2025-12-09 13:01:29.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.0009920851124900836 Training loss: 8.785175323486328
2025-12-09 13:01:30.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.0009920298146367287 Training loss: 8.819146156311035
2025-12-09 13:01:30.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.0009919743258362086 Training loss: 8.893498420715332
2025-12-09 13:01:30.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0009919186461100577 Training loss: 8.785900115966797
2025-12-09 13:01:31.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.000991862775479884 Training loss: 9.634675979614258
2025-12-09 13:01:31.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.00099180671396737 Training loss: 8.854145050048828
2025-12-09 13:01:31.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.0009917504615942721 Training loss: 8.61108112335205
2025-12-09 13:01:32.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.0009916940183824206 Training loss: 8.588184356689453
2025-12-09 13:01:32.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.0009916373843537201 Training loss: 9.23566722869873
2025-12-09 13:01:33.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.0009915805595301491 Training loss: 8.901957511901855
2025-12-09 13:01:33.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.0009915235439337602 Training loss: 8.72083854675293
2025-12-09 13:01:33.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.0009914663375866803 Training loss: 9.04245662689209
2025-12-09 13:01:34.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.0009914089405111098 Training loss: 8.819945335388184
2025-12-09 13:01:34.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.0009913513527293235 Training loss: 8.947166442871094
2025-12-09 13:01:34.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0009912935742636697 Training loss: 8.850485801696777
2025-12-09 13:01:35.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.0009912356051365717 Training loss: 9.018757820129395
2025-12-09 13:01:35.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.0009911774453705258 Training loss: 8.903841972351074
2025-12-09 13:01:35.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.0009911190949881028 Training loss: 8.916704177856445
2025-12-09 13:01:36.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.0009910605540119474 Training loss: 8.675870895385742
2025-12-09 13:01:36.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.0009910018224647782 Training loss: 8.858406066894531
2025-12-09 13:01:37.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.0009909429003693876 Training loss: 9.060410499572754
2025-12-09 13:01:37.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.0009908837877486423 Training loss: 8.998579025268555
2025-12-09 13:01:37.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.0009908244846254825 Training loss: 8.785993576049805
2025-12-09 13:01:38.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.000990764991022923 Training loss: 8.819245338439941
2025-12-09 13:01:38.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.0009907053069640515 Training loss: 8.976187705993652
2025-12-09 13:01:38.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.000990645432472031 Training loss: 8.581945419311523
2025-12-09 13:01:39.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.000990585367570097 Training loss: 9.028501510620117
2025-12-09 13:01:39.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.0009905251122815596 Training loss: 9.215211868286133
2025-12-09 13:01:40.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.000990464666629803 Training loss: 8.952473640441895
2025-12-09 13:01:40.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.0009904040306382847 Training loss: 8.659180641174316
2025-12-09 13:01:40.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0009903432043305365 Training loss: 9.141386985778809
2025-12-09 13:01:41.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.0009902821877301638 Training loss: 8.647421836853027
2025-12-09 13:01:41.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.000990220980860846 Training loss: 8.69855785369873
2025-12-09 13:01:41.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.0009901595837463362 Training loss: 8.827096939086914
2025-12-09 13:01:42.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.0009900979964104616 Training loss: 8.985047340393066
2025-12-09 13:01:42.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.000990036218877123 Training loss: 9.076203346252441
2025-12-09 13:01:43.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.000989974251170295 Training loss: 8.866312026977539
2025-12-09 13:01:43.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.000989912093314026 Training loss: 8.769219398498535
2025-12-09 13:01:43.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.0009898497453324385 Training loss: 9.281238555908203
2025-12-09 13:01:44.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.000989787207249728 Training loss: 8.889594078063965
2025-12-09 13:01:44.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.0009897244790901649 Training loss: 8.806197166442871
2025-12-09 13:01:44.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.0009896615608780924 Training loss: 9.150951385498047
2025-12-09 13:01:45.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.000989598452637928 Training loss: 8.769433975219727
2025-12-09 13:01:45.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.0009895351543941628 Training loss: 8.732271194458008
2025-12-09 13:01:45.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0009894716661713616 Training loss: 8.910907745361328
2025-12-09 13:01:46.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0009894079879941627 Training loss: 8.937575340270996
2025-12-09 13:01:46.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.0009893441198872788 Training loss: 8.971851348876953
2025-12-09 13:01:47.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.0009892800618754953 Training loss: 9.016982078552246
2025-12-09 13:01:47.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.0009892158139836725 Training loss: 8.834563255310059
2025-12-09 13:01:47.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0009891513762367431 Training loss: 8.679845809936523
2025-12-09 13:01:48.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.0009890867486597146 Training loss: 8.740095138549805
2025-12-09 13:01:48.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.0009890219312776677 Training loss: 8.839377403259277
2025-12-09 13:01:48.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.0009889569241157564 Training loss: 8.65924072265625
2025-12-09 13:01:49.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.000988891727199209 Training loss: 8.941333770751953
2025-12-09 13:01:49.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.000988826340553327 Training loss: 8.638423919677734
2025-12-09 13:01:50.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.0009887607642034859 Training loss: 8.854255676269531
2025-12-09 13:01:50.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.0009886949981751346 Training loss: 9.050029754638672
2025-12-09 13:01:50.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.0009886290424937951 Training loss: 8.818638801574707
2025-12-09 13:01:51.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0009885628971850642 Training loss: 9.258345603942871
2025-12-09 13:01:51.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.0009884965622746112 Training loss: 9.464445114135742
2025-12-09 13:01:51.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.0009884300377881795 Training loss: 8.724587440490723
2025-12-09 13:01:52.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.0009883633237515858 Training loss: 8.841532707214355
2025-12-09 13:01:52.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.0009882964201907208 Training loss: 8.742706298828125
2025-12-09 13:01:53.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0009882293271315482 Training loss: 8.978780746459961
2025-12-09 13:01:53.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.0009881620446001056 Training loss: 8.746604919433594
2025-12-09 13:01:53.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.000988094572622504 Training loss: 9.059093475341797
2025-12-09 13:01:54.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.0009880269112249281 Training loss: 8.894478797912598
2025-12-09 13:01:54.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.000987959060433636 Training loss: 8.845333099365234
2025-12-09 13:01:54.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.0009878910202749589 Training loss: 8.835260391235352
2025-12-09 13:01:55.281 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.0009878227907753022 Training loss: 8.960169792175293
2025-12-09 13:01:55.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.0009877543719611444 Training loss: 8.951156616210938
2025-12-09 13:01:56.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.0009876857638590373 Training loss: 8.920156478881836
2025-12-09 13:01:56.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.0009876169664956068 Training loss: 9.175043106079102
2025-12-09 13:01:56.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.0009875479798975512 Training loss: 8.919565200805664
2025-12-09 13:01:57.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.0009874788040916433 Training loss: 8.946562767028809
2025-12-09 13:01:57.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.0009874094391047288 Training loss: 8.76046085357666
2025-12-09 13:01:57.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.0009873398849637267 Training loss: 8.721996307373047
2025-12-09 13:01:58.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.00098727014169563 Training loss: 8.756545066833496
2025-12-09 13:01:58.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.0009872002093275043 Training loss: 8.952746391296387
2025-12-09 13:01:58.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.000987130087886489 Training loss: 8.576114654541016
2025-12-09 13:01:59.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.000987059777399797 Training loss: 9.17602252960205
2025-12-09 13:01:59.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.0009869892778947148 Training loss: 9.229090690612793
2025-12-09 13:02:00.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.0009869185893986011 Training loss: 8.697415351867676
2025-12-09 13:02:00.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.0009868477119388895 Training loss: 8.76125717163086
2025-12-09 13:02:00.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.0009867766455430858 Training loss: 8.903395652770996
2025-12-09 13:02:01.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.0009867053902387693 Training loss: 8.831794738769531
2025-12-09 13:02:01.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.0009866339460535929 Training loss: 8.953293800354004
2025-12-09 13:02:01.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.0009865623130152828 Training loss: 8.81802749633789
2025-12-09 13:02:02.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.0009864904911516383 Training loss: 8.72712516784668
2025-12-09 13:02:02.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.0009864184804905323 Training loss: 8.996217727661133
2025-12-09 13:02:03.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.0009863462810599105 Training loss: 8.912375450134277
2025-12-09 13:02:03.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.000986273892887792 Training loss: 9.282248497009277
2025-12-09 13:02:03.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.0009862013160022696 Training loss: 8.873257637023926
2025-12-09 13:02:04.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.0009861285504315085 Training loss: 8.940634727478027
2025-12-09 13:02:04.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.0009860555962037478 Training loss: 8.802968978881836
2025-12-09 13:02:04.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.0009859824533472999 Training loss: 8.780756950378418
2025-12-09 13:02:05.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.0009859091218905498 Training loss: 9.138632774353027
2025-12-09 13:02:05.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.000985835601861956 Training loss: 9.087044715881348
2025-12-09 13:02:06.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.0009857618932900504 Training loss: 9.315680503845215
2025-12-09 13:02:06.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0009856879962034375 Training loss: 8.896748542785645
2025-12-09 13:02:06.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0009856139106307956 Training loss: 8.76923942565918
2025-12-09 13:02:07.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.0009855396366008756 Training loss: 9.007196426391602
2025-12-09 13:02:07.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.0009854651741425023 Training loss: 8.72045612335205
2025-12-09 13:02:07.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.0009853905232845728 Training loss: 8.75302505493164
2025-12-09 13:02:08.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0009853156840560575 Training loss: 9.15939712524414
2025-12-09 13:02:08.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.0009852406564860004 Training loss: 8.897002220153809
2025-12-09 13:02:09.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.000985165440603518 Training loss: 9.015929222106934
2025-12-09 13:02:09.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.0009850900364378 Training loss: 8.886028289794922
2025-12-09 13:02:09.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.0009850144440181096 Training loss: 9.135725975036621
2025-12-09 13:02:10.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.0009849386633737824 Training loss: 8.707448959350586
2025-12-09 13:02:10.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.0009848626945342278 Training loss: 8.934905052185059
2025-12-09 13:02:10.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.0009847865375289275 Training loss: 8.770895004272461
2025-12-09 13:02:11.257 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.0009847101923874367 Training loss: 8.786239624023438
2025-12-09 13:02:11.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.0009846336591393832 Training loss: 8.865350723266602
2025-12-09 13:02:12.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.0009845569378144686 Training loss: 8.904621124267578
2025-12-09 13:02:12.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.0009844800284424663 Training loss: 8.92142105102539
2025-12-09 13:02:12.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0009844029310532238 Training loss: 8.859911918640137
2025-12-09 13:02:13.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.0009843256456766609 Training loss: 9.043450355529785
2025-12-09 13:02:13.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.0009842481723427705 Training loss: 8.651044845581055
2025-12-09 13:02:13.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.0009841705110816186 Training loss: 8.837430953979492
2025-12-09 13:02:14.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.000984092661923344 Training loss: 9.486786842346191
2025-12-09 13:02:14.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.0009840146248981585 Training loss: 9.162250518798828
2025-12-09 13:02:14.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.0009839364000363466 Training loss: 8.941104888916016
2025-12-09 13:02:15.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.000983857987368266 Training loss: 8.758257865905762
2025-12-09 13:02:15.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.0009837793869243467 Training loss: 8.920615196228027
2025-12-09 13:02:16.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.0009837005987350927 Training loss: 8.710097312927246
2025-12-09 13:02:16.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.0009836216228310797 Training loss: 9.473055839538574
2025-12-09 13:02:16.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.0009835424592429566 Training loss: 8.777423858642578
2025-12-09 13:02:17.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.0009834631080014456 Training loss: 8.808911323547363
2025-12-09 13:02:17.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.0009833835691373412 Training loss: 8.708501815795898
2025-12-09 13:02:17.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.000983303842681511 Training loss: 8.942031860351562
2025-12-09 13:02:18.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.000983223928664895 Training loss: 8.885597229003906
2025-12-09 13:02:18.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.0009831438271185064 Training loss: 8.722382545471191
2025-12-09 13:02:19.053 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.0009830635380734312 Training loss: 8.735800743103027
2025-12-09 13:02:19.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.000982983061560828 Training loss: 8.885522842407227
2025-12-09 13:02:19.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0009829023976119279 Training loss: 9.104954719543457
2025-12-09 13:02:20.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0009828215462580352 Training loss: 8.862663269042969
2025-12-09 13:02:20.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.0009827405075305267 Training loss: 9.146924018859863
2025-12-09 13:02:20.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.000982659281460852 Training loss: 8.805074691772461
2025-12-09 13:02:21.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.0009825778680805331 Training loss: 9.192343711853027
2025-12-09 13:02:21.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.0009824962674211653 Training loss: 8.673962593078613
2025-12-09 13:02:22.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.0009824144795144158 Training loss: 8.837141990661621
2025-12-09 13:02:22.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.0009823325043920256 Training loss: 9.345657348632812
2025-12-09 13:02:22.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.0009822503420858068 Training loss: 8.951546669006348
2025-12-09 13:02:23.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.0009821679926276456 Training loss: 8.624842643737793
2025-12-09 13:02:23.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.0009820854560494998 Training loss: 8.916516304016113
2025-12-09 13:02:23.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.0009820027323834007 Training loss: 9.062616348266602
2025-12-09 13:02:24.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.0009819198216614513 Training loss: 8.683043479919434
2025-12-09 13:02:24.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.0009818367239158277 Training loss: 9.082542419433594
2025-12-09 13:02:24.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.0009817534391787788 Training loss: 8.911630630493164
2025-12-09 13:02:25.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0009816699674826256 Training loss: 8.74827766418457
2025-12-09 13:02:25.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.0009815863088597618 Training loss: 8.785943031311035
2025-12-09 13:02:26.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.0009815024633426537 Training loss: 9.114813804626465
2025-12-09 13:02:26.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.00098141843096384 Training loss: 8.998416900634766
2025-12-09 13:02:26.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.0009813342117559324 Training loss: 9.060345649719238
2025-12-09 13:02:27.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.0009812498057516143 Training loss: 8.722627639770508
2025-12-09 13:02:27.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.0009811652129836422 Training loss: 8.750787734985352
2025-12-09 13:02:27.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.0009810804334848449 Training loss: 8.98681354522705
2025-12-09 13:02:28.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.0009809954672881237 Training loss: 8.7793607711792
2025-12-09 13:02:28.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.0009809103144264523 Training loss: 8.746893882751465
2025-12-09 13:02:29.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.0009808249749328768 Training loss: 8.962031364440918
2025-12-09 13:02:29.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.000980739448840516 Training loss: 8.766244888305664
2025-12-09 13:02:29.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.0009806537361825606 Training loss: 8.828676223754883
2025-12-09 13:02:30.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.0009805678369922742 Training loss: 8.849570274353027
2025-12-09 13:02:30.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.0009804817513029928 Training loss: 9.438755989074707
2025-12-09 13:02:30.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.000980395479148124 Training loss: 8.790326118469238
2025-12-09 13:02:31.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.0009803090205611487 Training loss: 8.776994705200195
2025-12-09 13:02:31.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.0009802223755756199 Training loss: 8.999738693237305
2025-12-09 13:02:32.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0009801355442251626 Training loss: 8.95058822631836
2025-12-09 13:02:32.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.0009800485265434745 Training loss: 8.890241622924805
2025-12-09 13:02:32.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.0009799613225643252 Training loss: 8.843713760375977
2025-12-09 13:02:33.162 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.0009798739323215572 Training loss: 8.934069633483887
2025-12-09 13:02:33.539 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.0009797863558490849 Training loss: 8.775749206542969
2025-12-09 13:02:33.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.000979698593180895 Training loss: 8.881163597106934
2025-12-09 13:02:34.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.0009796106443510462 Training loss: 9.373701095581055
2025-12-09 13:02:34.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.00097952250939367 Training loss: 8.940766334533691
2025-12-09 13:02:35.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.0009794341883429699 Training loss: 8.731324195861816
2025-12-09 13:02:35.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.0009793456812332215 Training loss: 9.34367847442627
2025-12-09 13:02:35.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.0009792569880987725 Training loss: 9.04361629486084
2025-12-09 13:02:36.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.0009791681089740432 Training loss: 9.028301239013672
2025-12-09 13:02:36.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.0009790790438935256 Training loss: 9.16904354095459
2025-12-09 13:02:36.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.0009789897928917846 Training loss: 8.919853210449219
2025-12-09 13:02:37.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.000978900356003456 Training loss: 9.050774574279785
2025-12-09 13:02:37.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.0009788107332632495 Training loss: 8.99604606628418
2025-12-09 13:02:37.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.0009787209247059453 Training loss: 8.91409969329834
2025-12-09 13:02:38.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.0009786309303663962 Training loss: 8.890934944152832
2025-12-09 13:02:38.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.0009785407502795277 Training loss: 8.607489585876465
2025-12-09 13:02:39.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.0009784503844803367 Training loss: 9.105460166931152
2025-12-09 13:02:39.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.0009783598330038925 Training loss: 9.086908340454102
2025-12-09 13:02:39.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.0009782690958853363 Training loss: 8.980643272399902
2025-12-09 13:02:40.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.0009781781731598813 Training loss: 8.878005027770996
2025-12-09 13:02:40.593 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.000978087064862813 Training loss: 8.821627616882324
2025-12-09 13:02:40.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.0009779957710294885 Training loss: 8.785542488098145
2025-12-09 13:02:41.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.0009779042916953375 Training loss: 8.876693725585938
2025-12-09 13:02:41.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.0009778126268958612 Training loss: 8.798321723937988
2025-12-09 13:02:42.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.000977720776666633 Training loss: 8.894777297973633
2025-12-09 13:02:42.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.000977628741043298 Training loss: 8.927213668823242
2025-12-09 13:02:42.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.0009775365200615734 Training loss: 9.035512924194336
2025-12-09 13:02:43.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.0009774441137572487 Training loss: 9.327749252319336
2025-12-09 13:02:43.567 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.0009773515221661846 Training loss: 8.609233856201172
2025-12-09 13:02:43.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.0009772587453243141 Training loss: 8.86060619354248
2025-12-09 13:02:44.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.0009771657832676427 Training loss: 9.287379264831543
2025-12-09 13:02:44.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.0009770726360322465 Training loss: 8.839970588684082
2025-12-09 13:02:45.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.000976979303654274 Training loss: 8.781437873840332
2025-12-09 13:02:45.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.0009768857861699462 Training loss: 8.85851764678955
2025-12-09 13:02:45.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.0009767920836155552 Training loss: 9.171542167663574
2025-12-09 13:02:46.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.0009766981960274653 Training loss: 8.918597221374512
2025-12-09 13:02:46.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.000976604123442112 Training loss: 8.956527709960938
2025-12-09 13:02:46.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.0009765098658960035 Training loss: 8.887020111083984
2025-12-09 13:02:47.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.0009764154234257191 Training loss: 9.378649711608887
2025-12-09 13:02:47.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.00097632079606791 Training loss: 8.594223022460938
2025-12-09 13:02:48.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.0009762259838592994 Training loss: 8.73393726348877
2025-12-09 13:02:48.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.0009761309868366819 Training loss: 9.204139709472656
2025-12-09 13:02:48.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0009760358050369243 Training loss: 9.012548446655273
2025-12-09 13:02:49.134 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.0009759404384969643 Training loss: 8.790596961975098
2025-12-09 13:02:49.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.0009758448872538121 Training loss: 8.867982864379883
2025-12-09 13:02:49.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.0009757491513445493 Training loss: 8.666529655456543
2025-12-09 13:02:50.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.0009756532308063293 Training loss: 8.862868309020996
2025-12-09 13:02:50.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.0009755571256763765 Training loss: 8.765416145324707
2025-12-09 13:02:50.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.0009754608359919879 Training loss: 9.191608428955078
2025-12-09 13:02:51.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.0009753643617905312 Training loss: 8.890125274658203
2025-12-09 13:02:51.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.0009752677031094466 Training loss: 9.003271102905273
2025-12-09 13:02:52.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0009751708599862451 Training loss: 8.92955207824707
2025-12-09 13:02:52.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.0009750738324585098 Training loss: 8.904447555541992
2025-12-09 13:02:52.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.0009749766205638952 Training loss: 8.698989868164062
2025-12-09 13:02:53.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.0009748792243401273 Training loss: 8.963727951049805
2025-12-09 13:02:53.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.0009747816438250037 Training loss: 9.20563793182373
2025-12-09 13:02:53.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.0009746838790563935 Training loss: 8.95497989654541
2025-12-09 13:02:54.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.000974585930072237 Training loss: 8.934551239013672
2025-12-09 13:02:54.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.0009744877969105468 Training loss: 9.067296028137207
2025-12-09 13:02:55.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.0009743894796094062 Training loss: 8.776187896728516
2025-12-09 13:02:55.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.0009742909782069701 Training loss: 8.771040916442871
2025-12-09 13:02:55.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.0009741922927414651 Training loss: 8.939224243164062
2025-12-09 13:02:56.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.0009740934232511893 Training loss: 8.603645324707031
2025-12-09 13:02:56.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.0009739943697745117 Training loss: 8.849344253540039
2025-12-09 13:02:56.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0009738951323498732 Training loss: 8.893131256103516
2025-12-09 13:02:57.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0009737957110157858 Training loss: 9.097920417785645
2025-12-09 13:02:57.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.0009736961058108331 Training loss: 8.778083801269531
2025-12-09 13:02:58.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.0009735963167736698 Training loss: 8.817008972167969
2025-12-09 13:02:58.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.0009734963439430222 Training loss: 9.174715042114258
2025-12-09 13:02:58.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.0009733961873576877 Training loss: 9.001701354980469
2025-12-09 13:02:59.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0009732958470565352 Training loss: 8.62687873840332
2025-12-09 13:02:59.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.0009731953230785049 Training loss: 8.899345397949219
2025-12-09 13:02:59.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.0009730946154626079 Training loss: 8.78498649597168
2025-12-09 13:03:00.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.000972993724247927 Training loss: 8.85984992980957
2025-12-09 13:03:00.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.0009728926494736163 Training loss: 9.151200294494629
2025-12-09 13:03:01.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.0009727913911789008 Training loss: 9.027976989746094
2025-12-09 13:03:01.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.0009726899494030768 Training loss: 9.13295841217041
2025-12-09 13:03:01.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.0009725883241855118 Training loss: 9.150062561035156
2025-12-09 13:03:02.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.0009724865155656448 Training loss: 9.785155296325684
2025-12-09 13:03:02.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.0009723845235829856 Training loss: 9.047425270080566
2025-12-09 13:03:02.883 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.0009722823482771155 Training loss: 9.113332748413086
2025-12-09 13:03:03.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.0009721799896876864 Training loss: 8.992713928222656
2025-12-09 13:03:03.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.0009720774478544219 Training loss: 8.711901664733887
2025-12-09 13:03:03.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.0009719747228171163 Training loss: 8.630678176879883
2025-12-09 13:03:04.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.0009718718146156355 Training loss: 8.971692085266113
2025-12-09 13:03:04.745 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0009717687232899158 Training loss: 8.920167922973633
2025-12-09 13:03:05.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0009716654488799652 Training loss: 9.093037605285645
2025-12-09 13:03:05.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.0009715619914258623 Training loss: 9.12193775177002
2025-12-09 13:03:05.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.000971458350967757 Training loss: 8.75223159790039
2025-12-09 13:03:06.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.0009713545275458703 Training loss: 8.774348258972168
2025-12-09 13:03:06.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.0009712505212004937 Training loss: 9.122368812561035
2025-12-09 13:03:06.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.0009711463319719904 Training loss: 9.150091171264648
2025-12-09 13:03:07.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0009710419599007938 Training loss: 8.98502254486084
2025-12-09 13:03:07.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.0009709374050274089 Training loss: 8.976263999938965
2025-12-09 13:03:08.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.0009708326673924114 Training loss: 8.620312690734863
2025-12-09 13:03:08.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0009707277470364482 Training loss: 8.982985496520996
2025-12-09 13:03:08.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.0009706226440002363 Training loss: 8.883047103881836
2025-12-09 13:03:09.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.0009705173583245644 Training loss: 8.98604965209961
2025-12-09 13:03:09.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.0009704118900502918 Training loss: 8.998429298400879
2025-12-09 13:03:09.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.0009703062392183488 Training loss: 9.028036117553711
2025-12-09 13:03:10.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.0009702004058697362 Training loss: 9.316061973571777
2025-12-09 13:03:10.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0009700943900455262 Training loss: 8.81187915802002
2025-12-09 13:03:11.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.0009699881917868609 Training loss: 8.790072441101074
2025-12-09 13:03:11.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.0009698818111349544 Training loss: 8.891671180725098
2025-12-09 13:03:11.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.0009697752481310904 Training loss: 8.87205696105957
2025-12-09 13:03:12.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.0009696685028166244 Training loss: 8.730527877807617
2025-12-09 13:03:12.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.000969561575232982 Training loss: 8.945183753967285
2025-12-09 13:03:12.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0009694544654216595 Training loss: 8.842991828918457
2025-12-09 13:03:13.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.0009693471734242243 Training loss: 9.017873764038086
2025-12-09 13:03:13.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0009692396992823144 Training loss: 8.954875946044922
2025-12-09 13:03:14.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.0009691320430376385 Training loss: 8.870152473449707
2025-12-09 13:03:14.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.0009690242047319755 Training loss: 9.011482238769531
2025-12-09 13:03:14.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.0009689161844071756 Training loss: 9.076582908630371
2025-12-09 13:03:15.145 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.0009688079821051594 Training loss: 8.617546081542969
2025-12-09 13:03:15.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.0009686995978679181 Training loss: 8.840387344360352
2025-12-09 13:03:15.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.0009685910317375133 Training loss: 8.804596900939941
2025-12-09 13:03:16.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.0009684822837560776 Training loss: 8.793456077575684
2025-12-09 13:03:16.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.0009683733539658139 Training loss: 8.921491622924805
2025-12-09 13:03:16.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.0009682642424089958 Training loss: 9.14338493347168
2025-12-09 13:03:17.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.0009681549491279673 Training loss: 8.917916297912598
2025-12-09 13:03:17.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.000968045474165143 Training loss: 9.242270469665527
2025-12-09 13:03:18.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0009679358175630081 Training loss: 8.956360816955566
2025-12-09 13:03:18.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.000967825979364118 Training loss: 8.831049919128418
2025-12-09 13:03:18.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.0009677159596110987 Training loss: 9.341041564941406
2025-12-09 13:03:19.230 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.000967605758346647 Training loss: 8.903855323791504
2025-12-09 13:03:19.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.0009674953756135297 Training loss: 8.798447608947754
2025-12-09 13:03:19.971 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.0009673848114545843 Training loss: 8.75668716430664
2025-12-09 13:03:20.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.0009672740659127184 Training loss: 9.149629592895508
2025-12-09 13:03:20.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.0009671631390309102 Training loss: 9.043027877807617
2025-12-09 13:03:21.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.0009670520308522084 Training loss: 8.963472366333008
2025-12-09 13:03:21.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.0009669407414197318 Training loss: 8.733806610107422
2025-12-09 13:03:21.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.0009668292707766699 Training loss: 8.790458679199219
2025-12-09 13:03:22.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.0009667176189662818 Training loss: 8.905228614807129
2025-12-09 13:03:22.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.0009666057860318978 Training loss: 8.849903106689453
2025-12-09 13:03:22.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.000966493772016918 Training loss: 9.324928283691406
2025-12-09 13:03:23.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.0009663815769648127 Training loss: 9.030343055725098
2025-12-09 13:03:23.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.000966269200919123 Training loss: 8.846738815307617
2025-12-09 13:03:24.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.0009661566439234593 Training loss: 8.968799591064453
2025-12-09 13:03:24.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.000966043906021503 Training loss: 8.858352661132812
2025-12-09 13:03:24.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.0009659309872570057 Training loss: 9.740279197692871
2025-12-09 13:03:25.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.0009658178876737886 Training loss: 9.398697853088379
2025-12-09 13:03:25.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.0009657046073157437 Training loss: 8.737801551818848
2025-12-09 13:03:25.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.0009655911462268327 Training loss: 8.661553382873535
2025-12-09 13:03:26.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.000965477504451088 Training loss: 8.784241676330566
2025-12-09 13:03:26.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.0009653636820326113 Training loss: 8.94445514678955
2025-12-09 13:03:27.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.0009652496790155752 Training loss: 8.747698783874512
2025-12-09 13:03:27.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.0009651354954442218 Training loss: 8.756053924560547
2025-12-09 13:03:27.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.0009650211313628637 Training loss: 8.846616744995117
2025-12-09 13:03:28.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.0009649065868158832 Training loss: 8.881478309631348
2025-12-09 13:03:28.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.0009647918618477329 Training loss: 8.765130996704102
2025-12-09 13:03:28.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.0009646769565029354 Training loss: 8.874812126159668
2025-12-09 13:03:29.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.0009645618708260831 Training loss: 8.875649452209473
2025-12-09 13:03:29.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.0009644466048618386 Training loss: 8.741565704345703
2025-12-09 13:03:30.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.0009643311586549342 Training loss: 9.591398239135742
2025-12-09 13:03:30.373 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.0009642155322501725 Training loss: 9.06101131439209
2025-12-09 13:03:30.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.0009640997256924257 Training loss: 8.864084243774414
2025-12-09 13:03:31.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.0009639837390266362 Training loss: 8.868433952331543
2025-12-09 13:03:31.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.0009638675722978161 Training loss: 9.146724700927734
2025-12-09 13:03:31.862 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.0009637512255510475 Training loss: 8.98477840423584
2025-12-09 13:03:32.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.000963634698831482 Training loss: 9.378290176391602
2025-12-09 13:03:32.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.0009635179921843417 Training loss: 9.006269454956055
2025-12-09 13:03:32.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.0009634011056549182 Training loss: 8.94113540649414
2025-12-09 13:03:33.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.0009632840392885726 Training loss: 9.117043495178223
2025-12-09 13:03:33.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.0009631667931307364 Training loss: 9.207880020141602
2025-12-09 13:03:34.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.0009630493672269101 Training loss: 8.87587833404541
2025-12-09 13:03:34.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.0009629317616226649 Training loss: 9.084671020507812
2025-12-09 13:03:34.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.0009628139763636407 Training loss: 8.922636985778809
2025-12-09 13:03:35.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.0009626960114955483 Training loss: 8.959832191467285
2025-12-09 13:03:35.574 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.0009625778670641669 Training loss: 8.952259063720703
2025-12-09 13:03:35.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.0009624595431153467 Training loss: 9.090909957885742
2025-12-09 13:03:36.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 726 LR: 0.0009623410396950063 Training loss: 8.917102813720703
2025-12-09 13:03:36.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 727 LR: 0.000962222356849135 Training loss: 8.750676155090332
2025-12-09 13:03:37.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 728 LR: 0.000962103494623791 Training loss: 8.788788795471191
2025-12-09 13:03:37.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 729 LR: 0.0009619844530651026 Training loss: 8.832688331604004
2025-12-09 13:03:37.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 730 LR: 0.0009618652322192675 Training loss: 8.816078186035156
2025-12-09 13:03:38.179 | INFO     | __main__:train:25 - Epoch: 0 Step: 731 LR: 0.0009617458321325529 Training loss: 9.150752067565918
2025-12-09 13:03:38.549 | INFO     | __main__:train:25 - Epoch: 0 Step: 732 LR: 0.0009616262528512957 Training loss: 9.142777442932129
2025-12-09 13:03:38.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 733 LR: 0.0009615064944219022 Training loss: 9.32310676574707
2025-12-09 13:03:39.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 734 LR: 0.0009613865568908484 Training loss: 9.0405855178833
2025-12-09 13:03:39.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 735 LR: 0.0009612664403046797 Training loss: 8.94371509552002
