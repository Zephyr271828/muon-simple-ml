2025-12-09 12:14:04.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 12.026198387145996
2025-12-09 12:14:04.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 12.043404579162598
2025-12-09 12:14:04.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 11.992862701416016
2025-12-09 12:14:04.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 12.044525146484375
2025-12-09 12:14:04.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 12.03893756866455
2025-12-09 12:14:04.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 12.010963439941406
2025-12-09 12:14:04.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 12.014394760131836
2025-12-09 12:14:04.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 12.034148216247559
2025-12-09 12:14:04.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 12.071709632873535
2025-12-09 12:14:04.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 12.03562068939209
2025-12-09 12:14:04.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 11.976212501525879
2025-12-09 12:14:05.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 12.01708698272705
2025-12-09 12:14:05.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 12.033672332763672
2025-12-09 12:14:05.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 12.011858940124512
2025-12-09 12:14:05.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 12.009909629821777
2025-12-09 12:14:05.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 12.01820182800293
2025-12-09 12:14:05.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 12.001166343688965
2025-12-09 12:14:05.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 12.057205200195312
2025-12-09 12:14:05.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 12.019166946411133
2025-12-09 12:14:05.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 11.976936340332031
2025-12-09 12:14:05.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 11.994487762451172
2025-12-09 12:14:05.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 11.98105239868164
2025-12-09 12:14:05.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 12.00467586517334
2025-12-09 12:14:05.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 12.011951446533203
2025-12-09 12:14:06.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 11.999629020690918
2025-12-09 12:14:06.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 11.96753215789795
2025-12-09 12:14:06.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.00027 Training loss: 12.011751174926758
2025-12-09 12:14:06.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.00028000000000000003 Training loss: 11.954078674316406
2025-12-09 12:14:06.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00029 Training loss: 11.928852081298828
2025-12-09 12:14:06.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0003 Training loss: 11.919164657592773
2025-12-09 12:14:06.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00031 Training loss: 11.95722484588623
2025-12-09 12:14:06.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00032 Training loss: 11.956334114074707
2025-12-09 12:14:06.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00033 Training loss: 11.959586143493652
2025-12-09 12:14:06.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00034 Training loss: 11.899168014526367
2025-12-09 12:14:06.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00035 Training loss: 11.953441619873047
2025-12-09 12:14:06.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00035999999999999997 Training loss: 11.913326263427734
2025-12-09 12:14:07.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00037 Training loss: 11.903626441955566
2025-12-09 12:14:07.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00038 Training loss: 11.942782402038574
2025-12-09 12:14:07.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00039000000000000005 Training loss: 11.87434196472168
2025-12-09 12:14:07.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0004 Training loss: 11.906645774841309
2025-12-09 12:14:07.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00041 Training loss: 11.910993576049805
2025-12-09 12:14:07.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00042 Training loss: 11.839768409729004
2025-12-09 12:14:07.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00043 Training loss: 11.844996452331543
2025-12-09 12:14:07.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00044 Training loss: 11.772462844848633
2025-12-09 12:14:07.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00045000000000000004 Training loss: 11.87278938293457
2025-12-09 12:14:07.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.00046 Training loss: 11.740086555480957
2025-12-09 12:14:07.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00047 Training loss: 11.839200019836426
2025-12-09 12:14:07.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00048 Training loss: 11.755148887634277
2025-12-09 12:14:07.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00049 Training loss: 11.643583297729492
2025-12-09 12:14:08.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0005 Training loss: 11.656426429748535
2025-12-09 12:14:08.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00051 Training loss: 11.621028900146484
2025-12-09 12:14:08.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0005200000000000001 Training loss: 11.631108283996582
2025-12-09 12:14:08.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0005300000000000001 Training loss: 11.607160568237305
2025-12-09 12:14:08.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.00054 Training loss: 11.561397552490234
2025-12-09 12:14:08.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.00055 Training loss: 11.587746620178223
2025-12-09 12:14:08.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0005600000000000001 Training loss: 11.512386322021484
2025-12-09 12:14:08.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00057 Training loss: 11.75621223449707
2025-12-09 12:14:08.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00058 Training loss: 11.461410522460938
2025-12-09 12:14:08.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00059 Training loss: 11.485840797424316
2025-12-09 12:14:08.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0006 Training loss: 11.3569917678833
2025-12-09 12:14:08.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00061 Training loss: 11.383764266967773
2025-12-09 12:14:08.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00062 Training loss: 11.34099006652832
2025-12-09 12:14:09.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00063 Training loss: 11.37010383605957
2025-12-09 12:14:09.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00064 Training loss: 11.34264850616455
2025-12-09 12:14:09.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0006500000000000001 Training loss: 11.277132034301758
2025-12-09 12:14:09.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00066 Training loss: 11.429131507873535
2025-12-09 12:14:09.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00067 Training loss: 11.279635429382324
2025-12-09 12:14:09.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00068 Training loss: 11.282888412475586
2025-12-09 12:14:09.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00069 Training loss: 11.1802339553833
2025-12-09 12:14:09.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0007 Training loss: 11.268327713012695
2025-12-09 12:14:09.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00071 Training loss: 11.217259407043457
2025-12-09 12:14:09.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0007199999999999999 Training loss: 11.069029808044434
2025-12-09 12:14:09.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00073 Training loss: 11.105815887451172
2025-12-09 12:14:09.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00074 Training loss: 11.14590835571289
2025-12-09 12:14:09.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.00075 Training loss: 11.02363109588623
2025-12-09 12:14:10.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00076 Training loss: 11.002938270568848
2025-12-09 12:14:10.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0007700000000000001 Training loss: 11.015957832336426
2025-12-09 12:14:10.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0007800000000000001 Training loss: 10.91630744934082
2025-12-09 12:14:10.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00079 Training loss: 11.182198524475098
2025-12-09 12:14:10.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0008 Training loss: 10.91679859161377
2025-12-09 12:14:10.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0008100000000000001 Training loss: 10.906307220458984
2025-12-09 12:14:10.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00082 Training loss: 10.878861427307129
2025-12-09 12:14:10.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00083 Training loss: 10.723920822143555
2025-12-09 12:14:10.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00084 Training loss: 10.873257637023926
2025-12-09 12:14:10.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00085 Training loss: 10.767251014709473
2025-12-09 12:14:10.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00086 Training loss: 10.609009742736816
2025-12-09 12:14:10.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00087 Training loss: 10.724340438842773
2025-12-09 12:14:10.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00088 Training loss: 10.680809020996094
2025-12-09 12:14:10.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0008900000000000001 Training loss: 10.660667419433594
2025-12-09 12:14:11.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0009000000000000001 Training loss: 10.725526809692383
2025-12-09 12:14:11.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00091 Training loss: 10.702733993530273
2025-12-09 12:14:11.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.00092 Training loss: 10.798579216003418
2025-12-09 12:14:11.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.00093 Training loss: 10.666215896606445
2025-12-09 12:14:11.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00094 Training loss: 10.665013313293457
2025-12-09 12:14:11.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00095 Training loss: 10.640548706054688
2025-12-09 12:14:11.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00096 Training loss: 10.627167701721191
2025-12-09 12:14:11.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0009699999999999999 Training loss: 10.641465187072754
2025-12-09 12:14:11.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00098 Training loss: 10.386173248291016
2025-12-09 12:14:11.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00099 Training loss: 10.642126083374023
2025-12-09 12:14:11.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.001 Training loss: 10.565640449523926
2025-12-09 12:14:11.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.0009999999072578703 Training loss: 10.339362144470215
2025-12-09 12:14:11.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.0009999996290315154 Training loss: 10.400166511535645
2025-12-09 12:14:12.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0009999991653210384 Training loss: 10.58289623260498
2025-12-09 12:14:12.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0009999985161266117 Training loss: 10.401163101196289
2025-12-09 12:14:12.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0009999976814484759 Training loss: 10.467560768127441
2025-12-09 12:14:12.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0009999966612869405 Training loss: 10.343805313110352
2025-12-09 12:14:12.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0009999954556423843 Training loss: 10.406518936157227
2025-12-09 12:14:12.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0009999940645152542 Training loss: 10.70779800415039
2025-12-09 12:14:12.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0009999924879060664 Training loss: 10.424886703491211
2025-12-09 12:14:12.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.000999990725815406 Training loss: 10.362953186035156
2025-12-09 12:14:12.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.0009999887782439264 Training loss: 10.334183692932129
2025-12-09 12:14:12.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.00099998664519235 Training loss: 10.541529655456543
2025-12-09 12:14:12.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0009999843266614685 Training loss: 10.375160217285156
2025-12-09 12:14:12.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.0009999818226521416 Training loss: 10.379766464233398
2025-12-09 12:14:12.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.0009999791331652982 Training loss: 10.328569412231445
2025-12-09 12:14:13.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.0009999762582019365 Training loss: 10.302287101745605
2025-12-09 12:14:13.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.0009999731977631226 Training loss: 10.36513900756836
2025-12-09 12:14:13.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.0009999699518499921 Training loss: 10.571564674377441
2025-12-09 12:14:13.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0009999665204637486 Training loss: 10.166818618774414
2025-12-09 12:14:13.363 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.0009999629036056656 Training loss: 10.268672943115234
2025-12-09 12:14:13.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.0009999591012770847 Training loss: 10.088716506958008
2025-12-09 12:14:13.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.0009999551134794165 Training loss: 10.304351806640625
2025-12-09 12:14:13.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.00099995094021414 Training loss: 10.310420036315918
2025-12-09 12:14:13.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.0009999465814828036 Training loss: 10.3003511428833
2025-12-09 12:14:13.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0009999420372870244 Training loss: 10.277103424072266
2025-12-09 12:14:13.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.0009999373076284876 Training loss: 10.193211555480957
2025-12-09 12:14:13.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.0009999323925089486 Training loss: 9.87710189819336
2025-12-09 12:14:13.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.00099992729193023 Training loss: 10.264482498168945
2025-12-09 12:14:14.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0009999220058942244 Training loss: 10.264426231384277
2025-12-09 12:14:14.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.0009999165344028926 Training loss: 10.140997886657715
2025-12-09 12:14:14.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.0009999108774582644 Training loss: 10.808541297912598
2025-12-09 12:14:14.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.0009999050350624381 Training loss: 10.508787155151367
2025-12-09 12:14:14.354 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.0009998990072175814 Training loss: 9.758505821228027
2025-12-09 12:14:14.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.0009998927939259303 Training loss: 10.051041603088379
2025-12-09 12:14:14.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.0009998863951897897 Training loss: 10.105506896972656
2025-12-09 12:14:14.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.0009998798110115333 Training loss: 10.377866744995117
2025-12-09 12:14:14.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0009998730413936037 Training loss: 10.080635070800781
2025-12-09 12:14:14.734 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.0009998660863385124 Training loss: 9.708001136779785
2025-12-09 12:14:14.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.0009998589458488389 Training loss: 10.26118278503418
2025-12-09 12:14:14.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0009998516199272328 Training loss: 10.088712692260742
2025-12-09 12:14:14.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.0009998441085764113 Training loss: 10.018677711486816
2025-12-09 12:14:15.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.0009998364117991612 Training loss: 9.888498306274414
2025-12-09 12:14:15.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.0009998285295983375 Training loss: 10.163795471191406
2025-12-09 12:14:15.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.0009998204619768645 Training loss: 9.988375663757324
2025-12-09 12:14:15.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0009998122089377348 Training loss: 10.01899528503418
2025-12-09 12:14:15.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.0009998037704840102 Training loss: 10.094916343688965
2025-12-09 12:14:15.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.000999795146618821 Training loss: 10.238777160644531
2025-12-09 12:14:15.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0009997863373453664 Training loss: 9.97895622253418
2025-12-09 12:14:15.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.000999777342666914 Training loss: 10.012293815612793
2025-12-09 12:14:15.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0009997681625868013 Training loss: 10.028534889221191
2025-12-09 12:14:15.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.0009997587971084334 Training loss: 10.229820251464844
2025-12-09 12:14:15.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.0009997492462352846 Training loss: 10.135037422180176
2025-12-09 12:14:15.881 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0009997395099708981 Training loss: 9.89293384552002
2025-12-09 12:14:15.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.0009997295883188856 Training loss: 10.102710723876953
2025-12-09 12:14:16.034 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.0009997194812829276 Training loss: 9.998825073242188
2025-12-09 12:14:16.110 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0009997091888667737 Training loss: 10.076513290405273
2025-12-09 12:14:16.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.000999698711074242 Training loss: 9.974190711975098
2025-12-09 12:14:16.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0009996880479092197 Training loss: 9.987001419067383
2025-12-09 12:14:16.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.000999677199375662 Training loss: 9.893168449401855
2025-12-09 12:14:16.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0009996661654775938 Training loss: 10.303302764892578
2025-12-09 12:14:16.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.000999654946219108 Training loss: 9.927331924438477
2025-12-09 12:14:16.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.000999643541604367 Training loss: 9.980388641357422
2025-12-09 12:14:16.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.000999631951637601 Training loss: 10.239320755004883
2025-12-09 12:14:16.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.0009996201763231099 Training loss: 9.825177192687988
2025-12-09 12:14:16.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0009996082156652618 Training loss: 9.972468376159668
2025-12-09 12:14:16.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.000999596069668494 Training loss: 9.896614074707031
2025-12-09 12:14:16.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.000999583738337312 Training loss: 9.746320724487305
2025-12-09 12:14:17.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.0009995712216762903 Training loss: 9.926618576049805
2025-12-09 12:14:17.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.0009995585196900722 Training loss: 9.9508695602417
2025-12-09 12:14:17.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.00099954563238337 Training loss: 9.90578842163086
2025-12-09 12:14:17.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0009995325597609644 Training loss: 9.936841011047363
2025-12-09 12:14:17.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.000999519301827705 Training loss: 9.88404655456543
2025-12-09 12:14:17.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0009995058585885095 Training loss: 9.843181610107422
2025-12-09 12:14:17.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.0009994922300483656 Training loss: 9.752551078796387
2025-12-09 12:14:17.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.000999478416212329 Training loss: 10.246854782104492
2025-12-09 12:14:17.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.0009994644170855237 Training loss: 9.838154792785645
2025-12-09 12:14:17.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.0009994502326731434 Training loss: 9.958260536193848
2025-12-09 12:14:17.794 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.0009994358629804498 Training loss: 9.895411491394043
2025-12-09 12:14:17.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.0009994213080127738 Training loss: 9.929621696472168
2025-12-09 12:14:17.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.0009994065677755147 Training loss: 10.141862869262695
2025-12-09 12:14:18.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.0009993916422741409 Training loss: 9.915180206298828
2025-12-09 12:14:18.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.000999376531514189 Training loss: 9.816656112670898
2025-12-09 12:14:18.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.0009993612355012646 Training loss: 10.061928749084473
2025-12-09 12:14:18.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.0009993457542410422 Training loss: 9.87685775756836
2025-12-09 12:14:18.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.000999330087739265 Training loss: 9.831527709960938
2025-12-09 12:14:18.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0009993142360017445 Training loss: 9.835268020629883
2025-12-09 12:14:18.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.0009992981990343613 Training loss: 10.063946723937988
2025-12-09 12:14:18.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.0009992819768430649 Training loss: 9.782739639282227
2025-12-09 12:14:18.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.0009992655694338725 Training loss: 9.923466682434082
2025-12-09 12:14:18.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.0009992489768128714 Training loss: 9.936555862426758
2025-12-09 12:14:18.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0009992321989862165 Training loss: 9.859561920166016
2025-12-09 12:14:18.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0009992152359601322 Training loss: 9.896315574645996
2025-12-09 12:14:18.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.000999198087740911 Training loss: 9.934821128845215
2025-12-09 12:14:19.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.0009991807543349145 Training loss: 9.87403392791748
2025-12-09 12:14:19.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.000999163235748573 Training loss: 9.932236671447754
2025-12-09 12:14:19.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0009991455319883849 Training loss: 9.842342376708984
2025-12-09 12:14:19.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0009991276430609181 Training loss: 9.79159927368164
2025-12-09 12:14:19.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.0009991095689728087 Training loss: 9.861549377441406
2025-12-09 12:14:19.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0009990913097307613 Training loss: 9.819891929626465
2025-12-09 12:14:19.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0009990728653415503 Training loss: 9.739299774169922
2025-12-09 12:14:19.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.0009990542358120174 Training loss: 9.799897193908691
2025-12-09 12:14:19.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.0009990354211490736 Training loss: 9.800600051879883
2025-12-09 12:14:19.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.0009990164213596986 Training loss: 9.794225692749023
2025-12-09 12:14:19.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0009989972364509408 Training loss: 10.014196395874023
2025-12-09 12:14:19.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0009989778664299172 Training loss: 9.974810600280762
2025-12-09 12:14:19.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.0009989583113038133 Training loss: 9.96364974975586
2025-12-09 12:14:20.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.0009989385710798837 Training loss: 10.03183364868164
2025-12-09 12:14:20.083 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.0009989186457654514 Training loss: 9.775753021240234
2025-12-09 12:14:20.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.0009988985353679076 Training loss: 9.946028709411621
2025-12-09 12:14:20.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.0009988782398947132 Training loss: 9.71817684173584
2025-12-09 12:14:20.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.0009988577593533967 Training loss: 9.898778915405273
2025-12-09 12:14:20.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.000998837093751556 Training loss: 9.731721878051758
2025-12-09 12:14:20.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0009988162430968576 Training loss: 9.800786018371582
2025-12-09 12:14:20.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.000998795207397036 Training loss: 9.707310676574707
2025-12-09 12:14:20.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.000998773986659895 Training loss: 9.643139839172363
2025-12-09 12:14:20.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.0009987525808933069 Training loss: 9.806110382080078
2025-12-09 12:14:20.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0009987309901052122 Training loss: 9.960412979125977
2025-12-09 12:14:20.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.000998709214303621 Training loss: 9.757940292358398
2025-12-09 12:14:20.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.000998687253496611 Training loss: 9.620915412902832
2025-12-09 12:14:21.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0009986651076923287 Training loss: 9.617178916931152
2025-12-09 12:14:21.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.0009986427768989903 Training loss: 10.125335693359375
2025-12-09 12:14:21.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.0009986202611248793 Training loss: 9.873661994934082
2025-12-09 12:14:21.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0009985975603783483 Training loss: 9.713912963867188
2025-12-09 12:14:21.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.000998574674667819 Training loss: 9.957595825195312
2025-12-09 12:14:21.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0009985516040017807 Training loss: 9.9072847366333
2025-12-09 12:14:21.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.0009985283483887923 Training loss: 10.294549942016602
2025-12-09 12:14:21.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.0009985049078374806 Training loss: 9.845613479614258
2025-12-09 12:14:21.615 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.0009984812823565416 Training loss: 9.601187705993652
2025-12-09 12:14:21.691 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0009984574719547395 Training loss: 9.576029777526855
2025-12-09 12:14:21.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.000998433476640907 Training loss: 9.893952369689941
2025-12-09 12:14:21.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.0009984092964239462 Training loss: 9.809127807617188
2025-12-09 12:14:21.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.0009983849313128263 Training loss: 9.787736892700195
2025-12-09 12:14:21.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.0009983603813165868 Training loss: 9.661595344543457
2025-12-09 12:14:22.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0009983356464443346 Training loss: 9.937420845031738
2025-12-09 12:14:22.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.0009983107267052458 Training loss: 9.542031288146973
2025-12-09 12:14:22.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.0009982856221085643 Training loss: 9.646912574768066
2025-12-09 12:14:22.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.0009982603326636036 Training loss: 9.810104370117188
2025-12-09 12:14:22.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0009982348583797453 Training loss: 9.939801216125488
2025-12-09 12:14:22.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.0009982091992664392 Training loss: 9.707310676574707
2025-12-09 12:14:22.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0009981833553332044 Training loss: 10.234066009521484
2025-12-09 12:14:22.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.0009981573265896281 Training loss: 9.694148063659668
2025-12-09 12:14:22.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.000998131113045366 Training loss: 9.976901054382324
2025-12-09 12:14:22.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.0009981047147101425 Training loss: 9.816132545471191
2025-12-09 12:14:22.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.0009980781315937506 Training loss: 9.717423439025879
2025-12-09 12:14:22.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.000998051363706052 Training loss: 9.705645561218262
2025-12-09 12:14:22.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0009980244110569766 Training loss: 9.166106224060059
2025-12-09 12:14:23.066 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.0009979972736565226 Training loss: 9.765244483947754
2025-12-09 12:14:23.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0009979699515147579 Training loss: 9.6483736038208
2025-12-09 12:14:23.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.0009979424446418172 Training loss: 9.464617729187012
2025-12-09 12:14:23.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.0009979147530479056 Training loss: 9.750479698181152
2025-12-09 12:14:23.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0009978868767432953 Training loss: 9.93730354309082
2025-12-09 12:14:23.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.0009978588157383277 Training loss: 9.580856323242188
2025-12-09 12:14:23.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0009978305700434125 Training loss: 10.163007736206055
2025-12-09 12:14:23.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.000997802139669028 Training loss: 9.862813949584961
2025-12-09 12:14:23.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.0009977735246257209 Training loss: 9.610896110534668
2025-12-09 12:14:23.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.0009977447249241065 Training loss: 9.651891708374023
2025-12-09 12:14:23.832 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.0009977157405748687 Training loss: 9.812966346740723
2025-12-09 12:14:23.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0009976865715887596 Training loss: 9.620508193969727
2025-12-09 12:14:23.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.0009976572179766 Training loss: 9.861287117004395
2025-12-09 12:14:24.064 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.0009976276797492793 Training loss: 9.63589859008789
2025-12-09 12:14:24.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0009975979569177551 Training loss: 10.146946907043457
2025-12-09 12:14:24.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0009975680494930539 Training loss: 9.790369987487793
2025-12-09 12:14:24.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00099753795748627 Training loss: 9.492576599121094
2025-12-09 12:14:24.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.0009975076809085669 Training loss: 9.726304054260254
2025-12-09 12:14:24.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.0009974772197711762 Training loss: 9.619202613830566
2025-12-09 12:14:24.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.000997446574085398 Training loss: 9.48311710357666
2025-12-09 12:14:24.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0009974157438626008 Training loss: 9.964547157287598
2025-12-09 12:14:24.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.0009973847291142217 Training loss: 9.206533432006836
2025-12-09 12:14:24.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.0009973535298517663 Training loss: 9.740767478942871
2025-12-09 12:14:24.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0009973221460868086 Training loss: 9.716066360473633
2025-12-09 12:14:24.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.0009972905778309906 Training loss: 9.651981353759766
2025-12-09 12:14:24.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.0009972588250960234 Training loss: 9.057987213134766
2025-12-09 12:14:25.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.0009972268878936862 Training loss: 10.121420860290527
2025-12-09 12:14:25.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.000997194766235827 Training loss: 9.66585922241211
2025-12-09 12:14:25.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0009971624601343614 Training loss: 9.449387550354004
2025-12-09 12:14:25.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.0009971299696012743 Training loss: 9.704618453979492
2025-12-09 12:14:25.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.0009970972946486186 Training loss: 9.889945030212402
2025-12-09 12:14:25.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.0009970644352885157 Training loss: 9.907380104064941
2025-12-09 12:14:25.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.0009970313915331553 Training loss: 9.706388473510742
2025-12-09 12:14:25.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.0009969981633947955 Training loss: 9.65759563446045
2025-12-09 12:14:25.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0009969647508857632 Training loss: 9.709383010864258
2025-12-09 12:14:25.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.000996931154018453 Training loss: 9.668489456176758
2025-12-09 12:14:25.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0009968973728053288 Training loss: 9.799570083618164
2025-12-09 12:14:25.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0009968634072589219 Training loss: 9.630340576171875
2025-12-09 12:14:25.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0009968292573918325 Training loss: 9.872504234313965
2025-12-09 12:14:26.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.0009967949232167295 Training loss: 9.502740859985352
2025-12-09 12:14:26.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.0009967604047463492 Training loss: 9.598477363586426
2025-12-09 12:14:26.207 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0009967257019934974 Training loss: 9.748791694641113
2025-12-09 12:14:26.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.0009966908149710476 Training loss: 9.857009887695312
2025-12-09 12:14:26.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.0009966557436919415 Training loss: 9.795441627502441
2025-12-09 12:14:26.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.00099662048816919 Training loss: 9.62965202331543
2025-12-09 12:14:26.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.000996585048415871 Training loss: 9.609634399414062
2025-12-09 12:14:26.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.0009965494244451323 Training loss: 9.353875160217285
2025-12-09 12:14:26.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.0009965136162701888 Training loss: 9.839652061462402
2025-12-09 12:14:26.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0009964776239043244 Training loss: 9.725805282592773
2025-12-09 12:14:26.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.0009964414473608912 Training loss: 9.704694747924805
2025-12-09 12:14:26.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.0009964050866533092 Training loss: 9.639777183532715
2025-12-09 12:14:26.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.0009963685417950677 Training loss: 9.53536319732666
2025-12-09 12:14:27.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.000996331812799723 Training loss: 9.504867553710938
2025-12-09 12:14:27.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0009962948996809007 Training loss: 9.829997062683105
2025-12-09 12:14:27.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0009962578024522947 Training loss: 9.686617851257324
2025-12-09 12:14:27.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.0009962205211276665 Training loss: 9.638209342956543
2025-12-09 12:14:27.354 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0009961830557208464 Training loss: 9.59583854675293
2025-12-09 12:14:27.430 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.000996145406245733 Training loss: 9.723678588867188
2025-12-09 12:14:27.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0009961075727162928 Training loss: 9.677201271057129
2025-12-09 12:14:27.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0009960695551465611 Training loss: 9.55446720123291
2025-12-09 12:14:27.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.000996031353550641 Training loss: 9.566052436828613
2025-12-09 12:14:27.739 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0009959929679427047 Training loss: 9.683981895446777
2025-12-09 12:14:27.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.0009959543983369913 Training loss: 9.469609260559082
2025-12-09 12:14:27.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.000995915644747809 Training loss: 10.23240852355957
2025-12-09 12:14:27.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0009958767071895347 Training loss: 9.565679550170898
2025-12-09 12:14:28.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.0009958375856766127 Training loss: 9.379372596740723
2025-12-09 12:14:28.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0009957982802235555 Training loss: 9.521459579467773
2025-12-09 12:14:28.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0009957587908449449 Training loss: 9.61388874053955
2025-12-09 12:14:28.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.0009957191175554295 Training loss: 9.751590728759766
2025-12-09 12:14:28.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0009956792603697273 Training loss: 9.722394943237305
2025-12-09 12:14:28.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.000995639219302624 Training loss: 9.735336303710938
2025-12-09 12:14:28.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.0009955989943689733 Training loss: 9.730027198791504
2025-12-09 12:14:28.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.0009955585855836978 Training loss: 9.711788177490234
2025-12-09 12:14:28.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0009955179929617875 Training loss: 9.57736873626709
2025-12-09 12:14:28.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.0009954772165183012 Training loss: 9.701176643371582
2025-12-09 12:14:28.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.0009954362562683658 Training loss: 9.76754379272461
2025-12-09 12:14:28.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.000995395112227176 Training loss: 9.493337631225586
2025-12-09 12:14:28.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.000995353784409995 Training loss: 9.89025592803955
2025-12-09 12:14:29.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.0009953122728321542 Training loss: 9.573568344116211
2025-12-09 12:14:29.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.0009952705775090529 Training loss: 9.688319206237793
2025-12-09 12:14:29.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.0009952286984561591 Training loss: 9.693008422851562
2025-12-09 12:14:29.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0009951866356890083 Training loss: 9.684039115905762
2025-12-09 12:14:29.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.0009951443892232048 Training loss: 9.64135456085205
2025-12-09 12:14:29.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.0009951019590744203 Training loss: 9.639863967895508
2025-12-09 12:14:29.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.0009950593452583952 Training loss: 9.696945190429688
2025-12-09 12:14:29.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.0009950165477909379 Training loss: 9.478108406066895
2025-12-09 12:14:29.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0009949735666879252 Training loss: 9.555996894836426
2025-12-09 12:14:29.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.000994930401965301 Training loss: 9.293835639953613
2025-12-09 12:14:29.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.000994887053639079 Training loss: 9.834113121032715
2025-12-09 12:14:29.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.0009948435217253394 Training loss: 9.61922836303711
2025-12-09 12:14:29.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.0009947998062402312 Training loss: 9.6685791015625
2025-12-09 12:14:30.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.000994755907199972 Training loss: 9.92864990234375
2025-12-09 12:14:30.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.0009947118246208461 Training loss: 9.664045333862305
2025-12-09 12:14:30.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.0009946675585192075 Training loss: 9.79265308380127
2025-12-09 12:14:30.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.0009946231089114773 Training loss: 9.662537574768066
2025-12-09 12:14:30.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.000994578475814145 Training loss: 9.556462287902832
2025-12-09 12:14:30.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.0009945336592437678 Training loss: 9.4854154586792
2025-12-09 12:14:30.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.0009944886592169711 Training loss: 9.706950187683105
2025-12-09 12:14:30.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.000994443475750449 Training loss: 9.641226768493652
2025-12-09 12:14:30.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.000994398108860963 Training loss: 9.893388748168945
2025-12-09 12:14:30.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0009943525585653428 Training loss: 9.768280029296875
2025-12-09 12:14:30.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0009943068248804859 Training loss: 9.656693458557129
2025-12-09 12:14:30.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.000994260907823358 Training loss: 9.556772232055664
2025-12-09 12:14:30.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.0009942148074109933 Training loss: 9.819674491882324
2025-12-09 12:14:31.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.0009941685236604934 Training loss: 9.494086265563965
2025-12-09 12:14:31.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.0009941220565890278 Training loss: 9.510493278503418
2025-12-09 12:14:31.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.000994075406213835 Training loss: 9.753829002380371
2025-12-09 12:14:31.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.0009940285725522201 Training loss: 9.538898468017578
2025-12-09 12:14:31.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0009939815556215576 Training loss: 9.784527778625488
2025-12-09 12:14:31.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0009939343554392886 Training loss: 9.569034576416016
2025-12-09 12:14:31.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.0009938869720229233 Training loss: 9.601922988891602
2025-12-09 12:14:31.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.0009938394053900395 Training loss: 9.719890594482422
2025-12-09 12:14:31.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0009937916555582827 Training loss: 9.710355758666992
2025-12-09 12:14:31.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.000993743722545367 Training loss: 10.019452095031738
2025-12-09 12:14:31.794 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.0009936956063690734 Training loss: 9.6141939163208
2025-12-09 12:14:31.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.0009936473070472518 Training loss: 9.724645614624023
2025-12-09 12:14:31.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.0009935988245978198 Training loss: 9.513538360595703
2025-12-09 12:14:32.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0009935501590387628 Training loss: 9.490447044372559
2025-12-09 12:14:32.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.0009935013103881344 Training loss: 9.577765464782715
2025-12-09 12:14:32.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.0009934522786640555 Training loss: 9.521897315979004
2025-12-09 12:14:32.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.0009934030638847156 Training loss: 9.493483543395996
2025-12-09 12:14:32.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.0009933536660683717 Training loss: 9.714594841003418
2025-12-09 12:14:32.407 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.0009933040852333488 Training loss: 9.675437927246094
2025-12-09 12:14:32.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.00099325432139804 Training loss: 9.625822067260742
2025-12-09 12:14:32.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.0009932043745809064 Training loss: 9.19245433807373
2025-12-09 12:14:32.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.000993154244800476 Training loss: 9.626669883728027
2025-12-09 12:14:32.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.0009931039320753457 Training loss: 9.575508117675781
2025-12-09 12:14:32.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.00099305343642418 Training loss: 9.889020919799805
2025-12-09 12:14:32.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.0009930027578657114 Training loss: 9.570030212402344
2025-12-09 12:14:32.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.0009929518964187393 Training loss: 9.522686958312988
2025-12-09 12:14:33.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.0009929008521021325 Training loss: 8.960053443908691
2025-12-09 12:14:33.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.0009928496249348266 Training loss: 9.863341331481934
2025-12-09 12:14:33.170 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.000992798214935825 Training loss: 9.640645980834961
2025-12-09 12:14:33.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.0009927466221241995 Training loss: 9.764440536499023
2025-12-09 12:14:33.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.0009926948465190893 Training loss: 9.841599464416504
2025-12-09 12:14:33.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.0009926428881397015 Training loss: 9.801623344421387
2025-12-09 12:14:33.479 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.0009925907470053111 Training loss: 9.686901092529297
2025-12-09 12:14:33.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.0009925384231352606 Training loss: 9.932045936584473
2025-12-09 12:14:33.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0009924859165489608 Training loss: 9.44894790649414
2025-12-09 12:14:33.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.0009924332272658897 Training loss: 9.607897758483887
2025-12-09 12:14:33.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.0009923803553055937 Training loss: 9.593184471130371
2025-12-09 12:14:33.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.0009923273006876864 Training loss: 9.313167572021484
2025-12-09 12:14:33.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0009922740634318494 Training loss: 9.520581245422363
2025-12-09 12:14:34.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.0009922206435578323 Training loss: 9.582747459411621
2025-12-09 12:14:34.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0009921670410854518 Training loss: 9.21311092376709
2025-12-09 12:14:34.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.0009921132560345928 Training loss: 9.590195655822754
2025-12-09 12:14:34.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.0009920592884252082 Training loss: 9.464911460876465
2025-12-09 12:14:34.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.0009920051382773178 Training loss: 9.550729751586914
2025-12-09 12:14:34.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.00099195080561101 Training loss: 9.677017211914062
2025-12-09 12:14:34.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.0009918962904464407 Training loss: 9.351542472839355
2025-12-09 12:14:34.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.0009918415928038325 Training loss: 9.646343231201172
2025-12-09 12:14:34.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.000991786712703477 Training loss: 9.586238861083984
2025-12-09 12:14:34.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.0009917316501657334 Training loss: 9.50987434387207
2025-12-09 12:14:34.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0009916764052110274 Training loss: 9.681591987609863
2025-12-09 12:14:34.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.0009916209778598536 Training loss: 9.437589645385742
2025-12-09 12:14:34.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.0009915653681327736 Training loss: 9.288883209228516
2025-12-09 12:14:35.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.000991509576050417 Training loss: 9.872588157653809
2025-12-09 12:14:35.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.0009914536016334807 Training loss: 9.562880516052246
2025-12-09 12:14:35.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.0009913974449027297 Training loss: 9.723015785217285
2025-12-09 12:14:35.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.0009913411058789963 Training loss: 9.596343994140625
2025-12-09 12:14:35.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.0009912845845831805 Training loss: 9.477376937866211
2025-12-09 12:14:35.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.00099122788103625 Training loss: 9.552889823913574
2025-12-09 12:14:35.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.0009911709952592396 Training loss: 9.40401554107666
2025-12-09 12:14:35.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.0009911139272732526 Training loss: 9.37482738494873
2025-12-09 12:14:35.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.0009910566770994593 Training loss: 8.875777244567871
2025-12-09 12:14:35.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.0009909992447590978 Training loss: 9.522111892700195
2025-12-09 12:14:35.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.0009909416302734736 Training loss: 9.487106323242188
2025-12-09 12:14:35.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.0009908838336639598 Training loss: 9.627016067504883
2025-12-09 12:14:35.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.000990825854951997 Training loss: 9.296530723571777
2025-12-09 12:14:36.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0009907676941590937 Training loss: 9.430365562438965
2025-12-09 12:14:36.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.0009907093513068259 Training loss: 9.412697792053223
2025-12-09 12:14:36.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.0009906508264168365 Training loss: 9.466468811035156
2025-12-09 12:14:36.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.0009905921195108368 Training loss: 9.262206077575684
2025-12-09 12:14:36.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.0009905332306106049 Training loss: 9.83061695098877
2025-12-09 12:14:36.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.000990474159737987 Training loss: 9.444234848022461
2025-12-09 12:14:36.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.0009904149069148963 Training loss: 9.460968971252441
2025-12-09 12:14:36.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.000990355472163314 Training loss: 9.563316345214844
2025-12-09 12:14:36.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.0009902958555052881 Training loss: 9.545907020568848
2025-12-09 12:14:36.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.0009902360569629348 Training loss: 9.288515090942383
2025-12-09 12:14:36.770 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.0009901760765584375 Training loss: 9.915884971618652
2025-12-09 12:14:36.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.000990115914314047 Training loss: 9.524582862854004
2025-12-09 12:14:36.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.0009900555702520816 Training loss: 9.1097993850708
2025-12-09 12:14:37.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.000989995044394927 Training loss: 9.503280639648438
2025-12-09 12:14:37.080 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0009899343367650365 Training loss: 9.795097351074219
2025-12-09 12:14:37.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0009898734473849304 Training loss: 9.595098495483398
2025-12-09 12:14:37.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.0009898123762771972 Training loss: 9.654828071594238
2025-12-09 12:14:37.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.000989751123464492 Training loss: 9.011266708374023
2025-12-09 12:14:37.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.0009896896889695376 Training loss: 9.594165802001953
2025-12-09 12:14:37.461 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0009896280728151248 Training loss: 9.241744041442871
2025-12-09 12:14:37.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.0009895662750241108 Training loss: 9.620161056518555
2025-12-09 12:14:37.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.0009895042956194209 Training loss: 9.548480033874512
2025-12-09 12:14:37.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.0009894421346240473 Training loss: 9.54227352142334
2025-12-09 12:14:37.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.0009893797920610496 Training loss: 9.691231727600098
2025-12-09 12:14:37.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.0009893172679535552 Training loss: 9.609166145324707
2025-12-09 12:14:37.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.0009892545623247585 Training loss: 9.446932792663574
2025-12-09 12:14:37.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.0009891916751979218 Training loss: 9.406843185424805
2025-12-09 12:14:38.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.0009891286065963733 Training loss: 9.693370819091797
2025-12-09 12:14:38.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0009890653565435101 Training loss: 9.545675277709961
2025-12-09 12:14:38.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.0009890019250627959 Training loss: 9.466765403747559
2025-12-09 12:14:38.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.0009889383121777617 Training loss: 9.489747047424316
2025-12-09 12:14:38.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.000988874517912006 Training loss: 9.439937591552734
2025-12-09 12:14:38.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.0009888105422891941 Training loss: 9.799609184265137
2025-12-09 12:14:38.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0009887463853330593 Training loss: 9.970544815063477
2025-12-09 12:14:38.609 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.000988682047067402 Training loss: 9.26480484008789
2025-12-09 12:14:38.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.000988617527516089 Training loss: 9.483539581298828
2025-12-09 12:14:38.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.0009885528267030556 Training loss: 9.832549095153809
2025-12-09 12:14:38.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.0009884879446523036 Training loss: 9.622152328491211
2025-12-09 12:14:38.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.000988422881387902 Training loss: 9.422737121582031
2025-12-09 12:14:38.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.0009883576369339876 Training loss: 9.585110664367676
2025-12-09 12:14:39.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.0009882922113147636 Training loss: 8.968408584594727
2025-12-09 12:14:39.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.0009882266045545011 Training loss: 9.684853553771973
2025-12-09 12:14:39.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.0009881608166775384 Training loss: 9.384488105773926
2025-12-09 12:14:39.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.0009880948477082802 Training loss: 9.189764022827148
2025-12-09 12:14:39.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.0009880286976711992 Training loss: 9.707064628601074
2025-12-09 12:14:39.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.000987962366590835 Training loss: 9.538280487060547
2025-12-09 12:14:39.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.0009878958544917943 Training loss: 9.536511421203613
2025-12-09 12:14:39.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.0009878291613987509 Training loss: 9.743739128112793
2025-12-09 12:14:39.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.000987762287336446 Training loss: 9.47214412689209
2025-12-09 12:14:39.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.0009876952323296876 Training loss: 9.545012474060059
2025-12-09 12:14:39.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.0009876279964033511 Training loss: 9.511198997497559
2025-12-09 12:14:39.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.000987560579582379 Training loss: 9.744124412536621
2025-12-09 12:14:39.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.0009874929818917805 Training loss: 9.662240028381348
2025-12-09 12:14:40.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.0009874252033566326 Training loss: 9.529867172241211
2025-12-09 12:14:40.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.000987357244002079 Training loss: 9.817645072937012
2025-12-09 12:14:40.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.00098728910385333 Training loss: 9.791735649108887
2025-12-09 12:14:40.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.000987220782935664 Training loss: 9.394601821899414
2025-12-09 12:14:40.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.0009871522812744257 Training loss: 9.480975151062012
2025-12-09 12:14:40.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.0009870835988950268 Training loss: 9.593070030212402
2025-12-09 12:14:40.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.0009870147358229467 Training loss: 9.590020179748535
2025-12-09 12:14:40.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.0009869456920837312 Training loss: 9.550543785095215
2025-12-09 12:14:40.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.0009868764677029933 Training loss: 9.123157501220703
2025-12-09 12:14:40.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.0009868070627064133 Training loss: 9.786066055297852
2025-12-09 12:14:40.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.0009867374771197384 Training loss: 9.495807647705078
2025-12-09 12:14:40.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.0009866677109687822 Training loss: 9.526435852050781
2025-12-09 12:14:40.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.0009865977642794259 Training loss: 9.336725234985352
2025-12-09 12:14:41.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.0009865276370776177 Training loss: 9.563823699951172
2025-12-09 12:14:41.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.0009864573293893724 Training loss: 9.87905216217041
2025-12-09 12:14:41.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.000986386841240772 Training loss: 9.361503601074219
2025-12-09 12:14:41.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0009863161726579655 Training loss: 9.564611434936523
2025-12-09 12:14:41.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0009862453236671685 Training loss: 9.72788143157959
2025-12-09 12:14:41.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.000986174294294664 Training loss: 9.54112434387207
2025-12-09 12:14:41.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.0009861030845668014 Training loss: 9.455611228942871
2025-12-09 12:14:41.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.0009860316945099973 Training loss: 9.578819274902344
2025-12-09 12:14:41.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0009859601241507354 Training loss: 9.540850639343262
2025-12-09 12:14:41.754 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.0009858883735155658 Training loss: 9.338876724243164
2025-12-09 12:14:41.831 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.0009858164426311058 Training loss: 9.388510704040527
2025-12-09 12:14:41.907 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.0009857443315240395 Training loss: 9.627022743225098
2025-12-09 12:14:41.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.000985672040221118 Training loss: 9.403579711914062
2025-12-09 12:14:42.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.000985599568749159 Training loss: 9.399186134338379
2025-12-09 12:14:42.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.000985526917135047 Training loss: 9.547783851623535
2025-12-09 12:14:42.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.0009854540854057337 Training loss: 9.675711631774902
2025-12-09 12:14:42.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.000985381073588237 Training loss: 9.244953155517578
2025-12-09 12:14:42.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.0009853078817096423 Training loss: 9.598271369934082
2025-12-09 12:14:42.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.0009852345097971016 Training loss: 9.690232276916504
2025-12-09 12:14:42.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.0009851609578778332 Training loss: 9.46442985534668
2025-12-09 12:14:42.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0009850872259791227 Training loss: 9.651870727539062
2025-12-09 12:14:42.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.0009850133141283226 Training loss: 9.449543952941895
2025-12-09 12:14:42.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.0009849392223528514 Training loss: 9.40703010559082
2025-12-09 12:14:42.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.000984864950680195 Training loss: 9.723350524902344
2025-12-09 12:14:42.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.000984790499137906 Training loss: 9.472957611083984
2025-12-09 12:14:42.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.0009847158677536033 Training loss: 9.281075477600098
2025-12-09 12:14:43.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.000984641056554973 Training loss: 9.653611183166504
2025-12-09 12:14:43.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.0009845660655697678 Training loss: 9.348809242248535
2025-12-09 12:14:43.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.0009844908948258067 Training loss: 9.541969299316406
2025-12-09 12:14:43.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.000984415544350976 Training loss: 9.544339179992676
2025-12-09 12:14:43.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.000984340014173228 Training loss: 9.553791999816895
2025-12-09 12:14:43.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.0009842643043205823 Training loss: 9.382577896118164
2025-12-09 12:14:43.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.0009841884148211247 Training loss: 9.617494583129883
2025-12-09 12:14:43.594 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.000984112345703008 Training loss: 9.587732315063477
2025-12-09 12:14:43.671 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.000984036096994451 Training loss: 9.767134666442871
2025-12-09 12:14:43.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.0009839596687237402 Training loss: 9.517291069030762
2025-12-09 12:14:43.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.0009838830609192278 Training loss: 9.595922470092773
2025-12-09 12:14:43.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.0009838062736093327 Training loss: 9.433237075805664
2025-12-09 12:14:43.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.0009837293068225407 Training loss: 9.339583396911621
2025-12-09 12:14:44.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0009836521605874043 Training loss: 9.458809852600098
2025-12-09 12:14:44.128 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0009835748349325422 Training loss: 9.364314079284668
2025-12-09 12:14:44.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.0009834973298866393 Training loss: 9.41850757598877
2025-12-09 12:14:44.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.0009834196454784484 Training loss: 9.214896202087402
2025-12-09 12:14:44.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.0009833417817367873 Training loss: 9.715106010437012
2025-12-09 12:14:44.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.0009832637386905413 Training loss: 9.54790210723877
2025-12-09 12:14:44.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.0009831855163686617 Training loss: 9.501055717468262
2025-12-09 12:14:44.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.0009831071148001668 Training loss: 9.708953857421875
2025-12-09 12:14:44.667 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.0009830285340141408 Training loss: 9.485238075256348
2025-12-09 12:14:44.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.0009829497740397348 Training loss: 9.449358940124512
2025-12-09 12:14:44.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.0009828708349061664 Training loss: 9.495603561401367
2025-12-09 12:14:44.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.0009827917166427196 Training loss: 9.61135196685791
2025-12-09 12:14:44.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.0009827124192787445 Training loss: 9.715503692626953
2025-12-09 12:14:45.049 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.000982632942843658 Training loss: 9.490310668945312
2025-12-09 12:14:45.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.0009825532873669433 Training loss: 9.493711471557617
2025-12-09 12:14:45.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0009824734528781505 Training loss: 9.562206268310547
2025-12-09 12:14:45.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.0009823934394068952 Training loss: 9.577675819396973
2025-12-09 12:14:45.358 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.0009823132469828602 Training loss: 9.463102340698242
2025-12-09 12:14:45.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.000982232875635794 Training loss: 9.586915016174316
2025-12-09 12:14:45.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.0009821523253955122 Training loss: 9.638273239135742
2025-12-09 12:14:45.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.0009820715962918964 Training loss: 9.425559043884277
2025-12-09 12:14:45.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.0009819906883548942 Training loss: 9.47166633605957
2025-12-09 12:14:45.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.0009819096016145203 Training loss: 9.54011344909668
2025-12-09 12:14:45.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.000981828336100855 Training loss: 9.51074504852295
2025-12-09 12:14:45.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.0009817468918440454 Training loss: 9.33651351928711
2025-12-09 12:14:45.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.0009816652688743048 Training loss: 9.382554054260254
2025-12-09 12:14:46.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.0009815834672219127 Training loss: 9.64608097076416
2025-12-09 12:14:46.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.000981501486917215 Training loss: 9.173944473266602
2025-12-09 12:14:46.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.0009814193279906237 Training loss: 9.368086814880371
2025-12-09 12:14:46.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.000981336990472617 Training loss: 9.48245620727539
2025-12-09 12:14:46.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.00098125447439374 Training loss: 9.492286682128906
2025-12-09 12:14:46.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.0009811717797846033 Training loss: 9.583510398864746
2025-12-09 12:14:46.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.000981088906675884 Training loss: 10.027813911437988
2025-12-09 12:14:46.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0009810058550983253 Training loss: 9.43752384185791
2025-12-09 12:14:46.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.000980922625082737 Training loss: 9.47677993774414
2025-12-09 12:14:46.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.0009808392166599947 Training loss: 9.339994430541992
2025-12-09 12:14:46.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.0009807556298610403 Training loss: 9.55685806274414
2025-12-09 12:14:46.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.0009806718647168817 Training loss: 9.686355590820312
2025-12-09 12:14:46.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.0009805879212585933 Training loss: 9.529613494873047
2025-12-09 12:14:47.046 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.0009805037995173154 Training loss: 10.062671661376953
2025-12-09 12:14:47.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.0009804194995242548 Training loss: 9.506930351257324
2025-12-09 12:14:47.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.0009803350213106836 Training loss: 9.514068603515625
2025-12-09 12:14:47.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.000980250364907941 Training loss: 9.592607498168945
2025-12-09 12:14:47.352 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.0009801655303474318 Training loss: 9.10313606262207
2025-12-09 12:14:47.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.000980080517660627 Training loss: 9.748236656188965
2025-12-09 12:14:47.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.0009799953268790633 Training loss: 9.687057495117188
2025-12-09 12:14:47.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.000979909958034344 Training loss: 9.422239303588867
2025-12-09 12:14:47.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.0009798244111581382 Training loss: 9.262455940246582
2025-12-09 12:14:47.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.0009797386862821812 Training loss: 9.392571449279785
2025-12-09 12:14:47.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.0009796527834382745 Training loss: 9.428932189941406
2025-12-09 12:14:47.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.0009795667026582847 Training loss: 9.76506519317627
2025-12-09 12:14:47.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.0009794804439741454 Training loss: 9.397760391235352
2025-12-09 12:14:48.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.000979394007417856 Training loss: 9.399194717407227
2025-12-09 12:14:48.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.0009793073930214817 Training loss: 8.88891887664795
2025-12-09 12:14:48.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.0009792206008171535 Training loss: 9.597229957580566
2025-12-09 12:14:48.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.0009791336308370687 Training loss: 9.367192268371582
2025-12-09 12:14:48.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.0009790464831134903 Training loss: 10.407187461853027
2025-12-09 12:14:48.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.0009789591576787476 Training loss: 9.439911842346191
2025-12-09 12:14:48.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.0009788716545652352 Training loss: 9.56030559539795
2025-12-09 12:14:48.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.0009787839738054146 Training loss: 9.491113662719727
2025-12-09 12:14:48.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.0009786961154318121 Training loss: 9.206400871276855
2025-12-09 12:14:48.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.0009786080794770206 Training loss: 9.81218433380127
2025-12-09 12:14:48.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.0009785198659736987 Training loss: 9.460455894470215
2025-12-09 12:14:48.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.0009784314749545706 Training loss: 9.813854217529297
2025-12-09 12:14:48.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.0009783429064524269 Training loss: 9.44400691986084
2025-12-09 12:14:49.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.0009782541605001234 Training loss: 9.595867156982422
2025-12-09 12:14:49.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.0009781652371305826 Training loss: 9.54599666595459
2025-12-09 12:14:49.194 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.0009780761363767914 Training loss: 10.206159591674805
2025-12-09 12:14:49.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.000977986858271804 Training loss: 9.31332778930664
2025-12-09 12:14:49.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.0009778974028487398 Training loss: 9.574307441711426
2025-12-09 12:14:49.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.0009778077701407836 Training loss: 9.51952838897705
2025-12-09 12:14:49.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.0009777179601811866 Training loss: 9.648137092590332
2025-12-09 12:14:49.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.0009776279730032654 Training loss: 9.502686500549316
2025-12-09 12:14:49.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.0009775378086404024 Training loss: 9.609862327575684
2025-12-09 12:14:49.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.0009774474671260455 Training loss: 9.386524200439453
2025-12-09 12:14:49.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.000977356948493709 Training loss: 9.353564262390137
2025-12-09 12:14:49.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.000977266252776972 Training loss: 9.580150604248047
2025-12-09 12:14:49.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.0009771753800094803 Training loss: 9.474393844604492
2025-12-09 12:14:50.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0009770843302249442 Training loss: 9.669793128967285
2025-12-09 12:14:50.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.0009769931034571409 Training loss: 9.552034378051758
2025-12-09 12:14:50.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.0009769016997399121 Training loss: 9.708823204040527
2025-12-09 12:14:50.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.000976810119107166 Training loss: 9.632791519165039
2025-12-09 12:14:50.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.0009767183615928764 Training loss: 9.443768501281738
2025-12-09 12:14:50.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.000976626427231082 Training loss: 9.456665992736816
2025-12-09 12:14:50.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.0009765343160558879 Training loss: 9.441573143005371
2025-12-09 12:14:50.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.0009764420281014641 Training loss: 9.530023574829102
2025-12-09 12:14:50.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.0009763495634020466 Training loss: 9.529783248901367
2025-12-09 12:14:50.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0009762569219919371 Training loss: 9.725630760192871
2025-12-09 12:14:50.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.0009761641039055025 Training loss: 9.582408905029297
2025-12-09 12:14:50.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.0009760711091771755 Training loss: 9.493744850158691
2025-12-09 12:14:50.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.0009759779378414542 Training loss: 9.362317085266113
2025-12-09 12:14:51.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.0009758845899329021 Training loss: 9.591438293457031
2025-12-09 12:14:51.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.0009757910654861482 Training loss: 9.374161720275879
2025-12-09 12:14:51.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.0009756973645358876 Training loss: 9.646505355834961
2025-12-09 12:14:51.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.0009756034871168799 Training loss: 10.018973350524902
2025-12-09 12:14:51.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.0009755094332639511 Training loss: 9.41721248626709
2025-12-09 12:14:51.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.0009754152030119921 Training loss: 9.412041664123535
2025-12-09 12:14:51.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.0009753207963959591 Training loss: 9.689454078674316
2025-12-09 12:14:51.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.0009752262134508741 Training loss: 9.551933288574219
2025-12-09 12:14:51.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.0009751314542118246 Training loss: 9.456253051757812
2025-12-09 12:14:51.727 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0009750365187139631 Training loss: 9.432573318481445
2025-12-09 12:14:51.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0009749414069925077 Training loss: 9.50078296661377
2025-12-09 12:14:51.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.0009748461190827421 Training loss: 9.425780296325684
2025-12-09 12:14:51.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.0009747506550200146 Training loss: 9.639949798583984
2025-12-09 12:14:52.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.0009746550148397397 Training loss: 9.415623664855957
2025-12-09 12:14:52.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.0009745591985773971 Training loss: 9.380480766296387
2025-12-09 12:14:52.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0009744632062685312 Training loss: 9.262877464294434
2025-12-09 12:14:52.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.0009743670379487523 Training loss: 9.578110694885254
2025-12-09 12:14:52.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.0009742706936537357 Training loss: 9.497486114501953
2025-12-09 12:14:52.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.0009741741734192224 Training loss: 9.510083198547363
2025-12-09 12:14:52.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.0009740774772810182 Training loss: 9.520320892333984
2025-12-09 12:14:52.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.0009739806052749942 Training loss: 9.519530296325684
2025-12-09 12:14:52.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.0009738835574370871 Training loss: 9.409748077392578
2025-12-09 12:14:52.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.0009737863338032984 Training loss: 9.630501747131348
2025-12-09 12:14:52.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.0009736889344096951 Training loss: 9.535115242004395
2025-12-09 12:14:52.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.0009735913592924093 Training loss: 9.079265594482422
2025-12-09 12:14:52.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.0009734936084876383 Training loss: 9.795451164245605
2025-12-09 12:14:53.031 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.0009733956820316443 Training loss: 9.41381549835205
2025-12-09 12:14:53.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.0009732975799607554 Training loss: 9.671731948852539
2025-12-09 12:14:53.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.0009731993023113641 Training loss: 9.503564834594727
2025-12-09 12:14:53.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.0009731008491199284 Training loss: 9.381409645080566
2025-12-09 12:14:53.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0009730022204229714 Training loss: 9.399388313293457
2025-12-09 12:14:53.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0009729034162570811 Training loss: 9.472436904907227
2025-12-09 12:14:53.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.0009728044366589108 Training loss: 9.545736312866211
2025-12-09 12:14:53.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.0009727052816651788 Training loss: 9.830061912536621
2025-12-09 12:14:53.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.0009726059513126685 Training loss: 9.59287166595459
2025-12-09 12:14:53.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.0009725064456382282 Training loss: 9.480696678161621
2025-12-09 12:14:53.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.0009724067646787717 Training loss: 9.878253936767578
2025-12-09 12:14:53.875 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0009723069084712771 Training loss: 9.86694622039795
2025-12-09 12:14:53.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.0009722068770527882 Training loss: 9.405942916870117
2025-12-09 12:14:54.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.0009721066704604133 Training loss: 9.545364379882812
2025-12-09 12:14:54.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0009720062887313262 Training loss: 9.896819114685059
2025-12-09 12:14:54.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.000971905731902765 Training loss: 9.290905952453613
2025-12-09 12:14:54.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.0009718050000120333 Training loss: 9.595635414123535
2025-12-09 12:14:54.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.0009717040930964996 Training loss: 9.344304084777832
2025-12-09 12:14:54.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.0009716030111935968 Training loss: 9.476461410522461
2025-12-09 12:14:54.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.0009715017543408234 Training loss: 9.528063774108887
2025-12-09 12:14:54.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0009714003225757424 Training loss: 9.885488510131836
2025-12-09 12:14:54.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.0009712987159359818 Training loss: 9.434247016906738
2025-12-09 12:14:54.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.0009711969344592346 Training loss: 9.584949493408203
2025-12-09 12:14:54.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.0009710949781832585 Training loss: 9.497518539428711
2025-12-09 12:14:54.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.0009709928471458759 Training loss: 9.408126831054688
2025-12-09 12:14:54.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.0009708905413849743 Training loss: 9.467093467712402
2025-12-09 12:14:55.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0009707880609385058 Training loss: 9.433855056762695
2025-12-09 12:14:55.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.0009706854058444876 Training loss: 9.40279769897461
2025-12-09 12:14:55.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0009705825761410014 Training loss: 9.347097396850586
2025-12-09 12:14:55.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.0009704795718661938 Training loss: 9.361377716064453
2025-12-09 12:14:55.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.000970376393058276 Training loss: 9.457889556884766
2025-12-09 12:14:55.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.0009702730397555246 Training loss: 9.753263473510742
2025-12-09 12:14:55.487 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.0009701695119962799 Training loss: 9.45704174041748
2025-12-09 12:14:55.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.0009700658098189476 Training loss: 9.450897216796875
2025-12-09 12:14:55.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.0009699619332619979 Training loss: 9.740973472595215
2025-12-09 12:14:55.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.0009698578823639658 Training loss: 9.719575881958008
2025-12-09 12:14:55.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.0009697536571634509 Training loss: 9.573390007019043
2025-12-09 12:14:55.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.0009696492576991174 Training loss: 9.63094711303711
2025-12-09 12:14:55.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.0009695446840096944 Training loss: 9.35192584991455
2025-12-09 12:14:56.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.0009694399361339751 Training loss: 9.754584312438965
2025-12-09 12:14:56.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0009693350141108182 Training loss: 9.479320526123047
2025-12-09 12:14:56.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.000969229917979146 Training loss: 9.34048080444336
2025-12-09 12:14:56.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.000969124647777946 Training loss: 9.754171371459961
2025-12-09 12:14:56.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.0009690192035462701 Training loss: 9.540507316589355
2025-12-09 12:14:56.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.0009689135853232349 Training loss: 9.599075317382812
2025-12-09 12:14:56.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.0009688077931480212 Training loss: 9.136743545532227
2025-12-09 12:14:56.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.0009687018270598749 Training loss: 9.420498847961426
2025-12-09 12:14:56.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.0009685956870981059 Training loss: 9.887948989868164
2025-12-09 12:14:56.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.0009684893733020888 Training loss: 9.834908485412598
2025-12-09 12:14:56.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.0009683828857112626 Training loss: 9.605777740478516
2025-12-09 12:14:56.866 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.0009682762243651309 Training loss: 9.514575004577637
2025-12-09 12:14:56.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.0009681693893032617 Training loss: 9.35536003112793
2025-12-09 12:14:57.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.0009680623805652876 Training loss: 9.525830268859863
2025-12-09 12:14:57.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.0009679551981909053 Training loss: 9.618093490600586
2025-12-09 12:14:57.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.000967847842219876 Training loss: 9.63184928894043
2025-12-09 12:14:57.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.0009677403126920255 Training loss: 9.476103782653809
2025-12-09 12:14:57.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.0009676326096472441 Training loss: 9.539216995239258
2025-12-09 12:14:57.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.0009675247331254858 Training loss: 9.451558113098145
2025-12-09 12:14:57.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.0009674166831667697 Training loss: 9.445915222167969
2025-12-09 12:14:57.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.0009673084598111788 Training loss: 9.163688659667969
2025-12-09 12:14:57.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.0009672000630988605 Training loss: 9.721531867980957
2025-12-09 12:14:57.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.0009670914930700268 Training loss: 9.195724487304688
2025-12-09 12:14:57.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.0009669827497649536 Training loss: 9.613415718078613
2025-12-09 12:14:57.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.0009668738332239813 Training loss: 9.608210563659668
2025-12-09 12:14:57.940 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.0009667647434875144 Training loss: 9.533968925476074
2025-12-09 12:14:58.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.0009666554805960219 Training loss: 9.483887672424316
2025-12-09 12:14:58.098 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.0009665460445900368 Training loss: 9.720917701721191
2025-12-09 12:14:58.175 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.0009664364355101565 Training loss: 9.577486991882324
2025-12-09 12:14:58.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.0009663266533970423 Training loss: 9.527705192565918
2025-12-09 12:14:58.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.0009662166982914202 Training loss: 9.825296401977539
2025-12-09 12:14:58.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.00096610657023408 Training loss: 9.78754997253418
2025-12-09 12:14:58.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.0009659962692658757 Training loss: 9.385446548461914
2025-12-09 12:14:58.556 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.0009658857954277254 Training loss: 9.407288551330566
2025-12-09 12:14:58.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.0009657751487606115 Training loss: 9.475613594055176
2025-12-09 12:14:58.709 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.0009656643293055805 Training loss: 9.461284637451172
2025-12-09 12:14:58.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.0009655533371037426 Training loss: 9.654311180114746
2025-12-09 12:14:58.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.0009654421721962729 Training loss: 9.455816268920898
2025-12-09 12:14:58.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.0009653308346244099 Training loss: 9.18259048461914
2025-12-09 12:14:59.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.0009652193244294562 Training loss: 9.350995063781738
2025-12-09 12:14:59.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.0009651076416527786 Training loss: 9.566167831420898
2025-12-09 12:14:59.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.000964995786335808 Training loss: 9.7578763961792
2025-12-09 12:14:59.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.0009648837585200391 Training loss: 9.743718147277832
2025-12-09 12:14:59.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.0009647715582470309 Training loss: 9.75238037109375
2025-12-09 12:14:59.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.000964659185558406 Training loss: 9.546688079833984
2025-12-09 12:14:59.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.000964546640495851 Training loss: 9.420342445373535
2025-12-09 12:14:59.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.0009644339231011168 Training loss: 10.096919059753418
2025-12-09 12:14:59.631 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.0009643210334160178 Training loss: 9.32069206237793
2025-12-09 12:14:59.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.0009642079714824328 Training loss: 9.516759872436523
2025-12-09 12:14:59.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.0009640947373423039 Training loss: 9.69282341003418
