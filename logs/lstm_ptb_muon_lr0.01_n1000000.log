2025-12-09 12:05:25.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 0.0001 Training loss: 9.203239440917969
2025-12-09 12:05:25.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 0.0002 Training loss: 9.202942848205566
2025-12-09 12:05:25.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 0.0003 Training loss: 9.202733993530273
2025-12-09 12:05:25.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.0004 Training loss: 9.202313423156738
2025-12-09 12:05:25.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.0005 Training loss: 9.200252532958984
2025-12-09 12:05:25.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.0006 Training loss: 9.197815895080566
2025-12-09 12:05:26.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.0007000000000000001 Training loss: 9.195062637329102
2025-12-09 12:05:26.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.0008 Training loss: 9.192245483398438
2025-12-09 12:05:26.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.0009 Training loss: 9.189303398132324
2025-12-09 12:05:26.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.001 Training loss: 9.184635162353516
2025-12-09 12:05:26.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.0011 Training loss: 9.178248405456543
2025-12-09 12:05:26.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.0012 Training loss: 9.173714637756348
2025-12-09 12:05:26.114 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.0013000000000000002 Training loss: 9.168000221252441
2025-12-09 12:05:26.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.0014000000000000002 Training loss: 9.16197395324707
2025-12-09 12:05:26.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.0015 Training loss: 9.147485733032227
2025-12-09 12:05:26.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.0016 Training loss: 9.143495559692383
2025-12-09 12:05:26.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.0017000000000000001 Training loss: 9.131281852722168
2025-12-09 12:05:26.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.0018 Training loss: 9.125595092773438
2025-12-09 12:05:26.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.0019 Training loss: 9.11315631866455
2025-12-09 12:05:26.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.002 Training loss: 9.098722457885742
2025-12-09 12:05:26.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.0021 Training loss: 9.089285850524902
2025-12-09 12:05:26.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.0022 Training loss: 9.056537628173828
2025-12-09 12:05:26.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0023 Training loss: 9.046072959899902
2025-12-09 12:05:26.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0024 Training loss: 9.017667770385742
2025-12-09 12:05:26.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.0025 Training loss: 9.012964248657227
2025-12-09 12:05:26.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0026000000000000003 Training loss: 8.96566390991211
2025-12-09 12:05:26.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0027 Training loss: 8.935023307800293
2025-12-09 12:05:26.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0028000000000000004 Training loss: 8.894574165344238
2025-12-09 12:05:26.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.0029 Training loss: 8.861506462097168
2025-12-09 12:05:26.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.003 Training loss: 8.823013305664062
2025-12-09 12:05:26.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.0031 Training loss: 8.762772560119629
2025-12-09 12:05:26.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.0032 Training loss: 8.72768783569336
2025-12-09 12:05:26.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.0033000000000000004 Training loss: 8.68369197845459
2025-12-09 12:05:26.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.0034000000000000002 Training loss: 8.58271312713623
2025-12-09 12:05:26.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.0034999999999999996 Training loss: 8.56396484375
2025-12-09 12:05:26.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.0036 Training loss: 8.492445945739746
2025-12-09 12:05:26.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.0037 Training loss: 8.36238956451416
2025-12-09 12:05:26.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.0038 Training loss: 8.299790382385254
2025-12-09 12:05:26.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.0039000000000000003 Training loss: 8.157927513122559
2025-12-09 12:05:26.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.004 Training loss: 8.105157852172852
2025-12-09 12:05:26.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.0040999999999999995 Training loss: 8.014663696289062
2025-12-09 12:05:26.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.0042 Training loss: 7.975130558013916
2025-12-09 12:05:26.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.0043 Training loss: 7.9013166427612305
2025-12-09 12:05:26.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.0044 Training loss: 7.797182559967041
2025-12-09 12:05:26.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.0045000000000000005 Training loss: 7.75629186630249
2025-12-09 12:05:26.739 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0046 Training loss: 7.664514541625977
2025-12-09 12:05:26.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.0047 Training loss: 7.579594135284424
2025-12-09 12:05:26.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0048 Training loss: 7.485896110534668
2025-12-09 12:05:26.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.0049 Training loss: 7.404328346252441
2025-12-09 12:05:26.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.005 Training loss: 7.431312561035156
2025-12-09 12:05:26.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0051 Training loss: 7.20425271987915
2025-12-09 12:05:26.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.005200000000000001 Training loss: 7.214107513427734
2025-12-09 12:05:26.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0053 Training loss: 7.114408016204834
2025-12-09 12:05:26.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0054 Training loss: 7.181487083435059
2025-12-09 12:05:26.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0055000000000000005 Training loss: 6.978564262390137
2025-12-09 12:05:26.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.005600000000000001 Training loss: 6.990139007568359
2025-12-09 12:05:26.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.005699999999999999 Training loss: 6.84099817276001
2025-12-09 12:05:26.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.0058 Training loss: 6.88386344909668
2025-12-09 12:05:26.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0059 Training loss: 6.762944221496582
2025-12-09 12:05:26.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.006 Training loss: 6.7264227867126465
2025-12-09 12:05:27.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.0061 Training loss: 6.608733177185059
2025-12-09 12:05:27.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.0062 Training loss: 6.647653579711914
2025-12-09 12:05:27.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.0063 Training loss: 6.573606491088867
2025-12-09 12:05:27.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.0064 Training loss: 6.670754432678223
2025-12-09 12:05:27.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.006500000000000001 Training loss: 6.634359836578369
2025-12-09 12:05:27.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.006600000000000001 Training loss: 6.529048442840576
2025-12-09 12:05:27.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.0067 Training loss: 6.597766876220703
2025-12-09 12:05:27.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.0068000000000000005 Training loss: 6.375575065612793
2025-12-09 12:05:27.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.0069 Training loss: 6.332215309143066
2025-12-09 12:05:27.167 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.006999999999999999 Training loss: 6.380887031555176
2025-12-09 12:05:27.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.0070999999999999995 Training loss: 6.357466220855713
2025-12-09 12:05:27.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0072 Training loss: 6.295948028564453
2025-12-09 12:05:27.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.0073 Training loss: 6.24399995803833
2025-12-09 12:05:27.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.0074 Training loss: 6.300519943237305
2025-12-09 12:05:27.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0075 Training loss: 6.150449752807617
2025-12-09 12:05:27.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.0076 Training loss: 6.117475509643555
2025-12-09 12:05:27.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0077 Training loss: 6.244584083557129
2025-12-09 12:05:27.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0078000000000000005 Training loss: 6.1143622398376465
2025-12-09 12:05:27.329 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.0079 Training loss: 6.062627792358398
2025-12-09 12:05:27.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.008 Training loss: 5.990518093109131
2025-12-09 12:05:27.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.008100000000000001 Training loss: 6.050745964050293
2025-12-09 12:05:27.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.008199999999999999 Training loss: 6.070287704467773
2025-12-09 12:05:27.400 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.0083 Training loss: 5.904433727264404
2025-12-09 12:05:27.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.0084 Training loss: 5.928668975830078
2025-12-09 12:05:27.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.0085 Training loss: 6.081290245056152
2025-12-09 12:05:27.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.0086 Training loss: 5.952468395233154
2025-12-09 12:05:27.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.0087 Training loss: 5.886965274810791
2025-12-09 12:05:27.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.0088 Training loss: 5.917882919311523
2025-12-09 12:05:27.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0089 Training loss: 5.940845489501953
2025-12-09 12:05:27.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.009000000000000001 Training loss: 5.90283203125
2025-12-09 12:05:27.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0091 Training loss: 5.875065326690674
2025-12-09 12:05:27.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0092 Training loss: 5.82046365737915
2025-12-09 12:05:27.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.009300000000000001 Training loss: 5.676299571990967
2025-12-09 12:05:27.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.0094 Training loss: 5.7041707038879395
2025-12-09 12:05:27.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.0095 Training loss: 5.847036838531494
2025-12-09 12:05:27.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0096 Training loss: 5.523550987243652
2025-12-09 12:05:27.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0097 Training loss: 5.771084785461426
2025-12-09 12:05:27.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.0098 Training loss: 5.7648420333862305
2025-12-09 12:05:27.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.0099 Training loss: 5.766242027282715
2025-12-09 12:05:27.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.01 Training loss: 5.654702186584473
2025-12-09 12:05:27.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.009698463103929543 Training loss: 5.713146686553955
2025-12-09 12:05:27.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.00883022221559489 Training loss: 5.64657735824585
2025-12-09 12:05:27.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0075 Training loss: 5.768609046936035
2025-12-09 12:05:27.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.005868240888334653 Training loss: 5.782599449157715
2025-12-09 12:05:27.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0041317591116653484 Training loss: 5.634528636932373
2025-12-09 12:05:27.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0025000000000000014 Training loss: 5.448480606079102
2025-12-09 12:05:27.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0011697777844051104 Training loss: 5.61607027053833
2025-12-09 12:05:27.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.00030153689607045843 Training loss: 5.707545280456543
2025-12-09 12:05:27.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0 Training loss: 5.657616138458252
