2025-12-09 11:59:52.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 2.9999999999999997e-06 Training loss: 12.017276763916016
2025-12-09 11:59:52.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 5.999999999999999e-06 Training loss: 12.014233589172363
2025-12-09 11:59:52.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 8.999999999999999e-06 Training loss: 12.022150039672852
2025-12-09 11:59:53.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 1.1999999999999999e-05 Training loss: 12.003210067749023
2025-12-09 11:59:53.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 1.4999999999999999e-05 Training loss: 12.02867603302002
2025-12-09 11:59:53.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 1.7999999999999997e-05 Training loss: 11.990557670593262
2025-12-09 11:59:53.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 2.1e-05 Training loss: 12.018766403198242
2025-12-09 11:59:53.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 2.3999999999999997e-05 Training loss: 11.999632835388184
2025-12-09 11:59:53.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 2.6999999999999996e-05 Training loss: 12.01817512512207
2025-12-09 11:59:53.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 2.9999999999999997e-05 Training loss: 12.012396812438965
2025-12-09 11:59:54.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 3.2999999999999996e-05 Training loss: 11.997751235961914
2025-12-09 11:59:54.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 3.5999999999999994e-05 Training loss: 11.989872932434082
2025-12-09 11:59:54.279 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 3.9e-05 Training loss: 11.971329689025879
2025-12-09 11:59:54.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 4.2e-05 Training loss: 11.95942211151123
2025-12-09 11:59:54.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 4.4999999999999996e-05 Training loss: 11.987467765808105
2025-12-09 11:59:54.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 4.7999999999999994e-05 Training loss: 11.9531888961792
2025-12-09 11:59:54.801 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 5.1e-05 Training loss: 11.989813804626465
2025-12-09 11:59:54.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 5.399999999999999e-05 Training loss: 11.925163269042969
2025-12-09 11:59:55.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 5.6999999999999996e-05 Training loss: 11.953319549560547
2025-12-09 11:59:55.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 5.9999999999999995e-05 Training loss: 11.888598442077637
2025-12-09 11:59:55.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 6.299999999999999e-05 Training loss: 11.884206771850586
2025-12-09 11:59:55.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 6.599999999999999e-05 Training loss: 11.958853721618652
2025-12-09 11:59:55.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 6.9e-05 Training loss: 11.867239952087402
2025-12-09 11:59:55.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 7.199999999999999e-05 Training loss: 11.815393447875977
2025-12-09 11:59:55.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 7.5e-05 Training loss: 11.846590995788574
2025-12-09 11:59:55.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 7.8e-05 Training loss: 11.830863952636719
2025-12-09 11:59:56.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 8.1e-05 Training loss: 11.72628402709961
2025-12-09 11:59:56.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 8.4e-05 Training loss: 11.796181678771973
2025-12-09 11:59:56.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 8.699999999999999e-05 Training loss: 11.695066452026367
2025-12-09 11:59:56.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 8.999999999999999e-05 Training loss: 11.724515914916992
2025-12-09 11:59:56.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 9.3e-05 Training loss: 11.637164115905762
2025-12-09 11:59:56.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 9.599999999999999e-05 Training loss: 11.628205299377441
2025-12-09 11:59:56.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 9.9e-05 Training loss: 11.534814834594727
2025-12-09 11:59:57.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.000102 Training loss: 11.605683326721191
2025-12-09 11:59:57.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00010499999999999999 Training loss: 11.435103416442871
2025-12-09 11:59:57.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00010799999999999998 Training loss: 11.39958667755127
2025-12-09 11:59:57.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00011099999999999999 Training loss: 11.406482696533203
2025-12-09 11:59:57.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00011399999999999999 Training loss: 11.315913200378418
2025-12-09 11:59:57.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.000117 Training loss: 11.225587844848633
2025-12-09 11:59:57.828 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.00011999999999999999 Training loss: 11.308982849121094
2025-12-09 11:59:57.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00012299999999999998 Training loss: 11.156816482543945
2025-12-09 11:59:58.089 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00012599999999999997 Training loss: 11.023731231689453
2025-12-09 11:59:58.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.000129 Training loss: 10.980108261108398
2025-12-09 11:59:58.356 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00013199999999999998 Training loss: 10.802408218383789
2025-12-09 11:59:58.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.000135 Training loss: 10.823062896728516
2025-12-09 11:59:58.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.000138 Training loss: 10.800172805786133
2025-12-09 11:59:58.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00014099999999999998 Training loss: 10.717365264892578
2025-12-09 11:59:58.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.00014399999999999998 Training loss: 10.689472198486328
2025-12-09 11:59:59.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.000147 Training loss: 10.504203796386719
2025-12-09 11:59:59.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.00015 Training loss: 10.550110816955566
2025-12-09 11:59:59.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.00015299999999999998 Training loss: 10.492928504943848
2025-12-09 11:59:59.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.000156 Training loss: 10.329947471618652
2025-12-09 11:59:59.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.000159 Training loss: 10.44078540802002
2025-12-09 11:59:59.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.000162 Training loss: 10.120100021362305
2025-12-09 11:59:59.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.000165 Training loss: 10.238626480102539
2025-12-09 11:59:59.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.000168 Training loss: 10.031271934509277
2025-12-09 12:00:00.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00017099999999999998 Training loss: 9.937215805053711
2025-12-09 12:00:00.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00017399999999999997 Training loss: 10.180815696716309
2025-12-09 12:00:00.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.00017699999999999997 Training loss: 9.76114559173584
2025-12-09 12:00:00.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.00017999999999999998 Training loss: 9.801124572753906
2025-12-09 12:00:00.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00018299999999999998 Training loss: 9.698225021362305
2025-12-09 12:00:00.713 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.000186 Training loss: 9.512545585632324
2025-12-09 12:00:00.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00018899999999999999 Training loss: 9.389293670654297
2025-12-09 12:00:00.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00019199999999999998 Training loss: 9.380043983459473
2025-12-09 12:00:01.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.000195 Training loss: 9.32768440246582
2025-12-09 12:00:01.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.000198 Training loss: 9.210275650024414
2025-12-09 12:00:01.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.000201 Training loss: 9.08169937133789
2025-12-09 12:00:01.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.000204 Training loss: 9.50896167755127
2025-12-09 12:00:01.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00020699999999999996 Training loss: 9.305347442626953
2025-12-09 12:00:01.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.00020999999999999998 Training loss: 8.940635681152344
2025-12-09 12:00:01.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00021299999999999997 Training loss: 8.94219970703125
2025-12-09 12:00:02.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.00021599999999999996 Training loss: 8.775341033935547
2025-12-09 12:00:02.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00021899999999999998 Training loss: 8.892553329467773
2025-12-09 12:00:02.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00022199999999999998 Training loss: 8.82246208190918
2025-12-09 12:00:02.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.000225 Training loss: 8.661765098571777
2025-12-09 12:00:02.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00022799999999999999 Training loss: 8.507322311401367
2025-12-09 12:00:02.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.00023099999999999998 Training loss: 8.478124618530273
2025-12-09 12:00:02.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.000234 Training loss: 8.307353019714355
2025-12-09 12:00:03.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.000237 Training loss: 8.457712173461914
2025-12-09 12:00:03.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.00023999999999999998 Training loss: 8.137092590332031
2025-12-09 12:00:03.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.000243 Training loss: 8.336108207702637
2025-12-09 12:00:03.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00024599999999999996 Training loss: 8.147875785827637
2025-12-09 12:00:03.584 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.000249 Training loss: 8.210332870483398
2025-12-09 12:00:03.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00025199999999999995 Training loss: 7.9740424156188965
2025-12-09 12:00:03.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00025499999999999996 Training loss: 7.976816654205322
2025-12-09 12:00:03.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.000258 Training loss: 8.654913902282715
2025-12-09 12:00:04.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.000261 Training loss: 8.027856826782227
2025-12-09 12:00:04.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00026399999999999997 Training loss: 7.827661514282227
2025-12-09 12:00:04.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.000267 Training loss: 8.17063045501709
2025-12-09 12:00:04.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.00027 Training loss: 8.118560791015625
2025-12-09 12:00:04.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.00027299999999999997 Training loss: 8.113027572631836
2025-12-09 12:00:04.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.000276 Training loss: 7.664613246917725
2025-12-09 12:00:04.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.000279 Training loss: 7.601693630218506
2025-12-09 12:00:05.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00028199999999999997 Training loss: 7.814143180847168
2025-12-09 12:00:05.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.000285 Training loss: 7.749570846557617
2025-12-09 12:00:05.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.00028799999999999995 Training loss: 7.681154251098633
2025-12-09 12:00:05.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.00029099999999999997 Training loss: 7.375942707061768
2025-12-09 12:00:05.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.000294 Training loss: 7.896535873413086
2025-12-09 12:00:05.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00029699999999999996 Training loss: 8.019394874572754
2025-12-09 12:00:05.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0003 Training loss: 7.6782073974609375
2025-12-09 12:00:05.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.00029999997217736103 Training loss: 7.822945594787598
2025-12-09 12:00:06.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.00029999988870945456 Training loss: 7.564026355743408
2025-12-09 12:00:06.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0002999997495963115 Training loss: 7.921164512634277
2025-12-09 12:00:06.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.00029999955483798346 Training loss: 7.4398393630981445
2025-12-09 12:00:06.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0002999993044345427 Training loss: 7.5469231605529785
2025-12-09 12:00:06.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0002999989983860821 Training loss: 7.6619343757629395
2025-12-09 12:00:06.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.00029999863669271526 Training loss: 7.573153972625732
2025-12-09 12:00:06.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.0002999982193545762 Training loss: 7.601369380950928
2025-12-09 12:00:06.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0002999977463718199 Training loss: 7.776827812194824
2025-12-09 12:00:07.129 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.00029999721774462174 Training loss: 8.174052238464355
2025-12-09 12:00:07.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.00029999663347317785 Training loss: 7.613710403442383
2025-12-09 12:00:07.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.00029999599355770497 Training loss: 8.035562515258789
2025-12-09 12:00:07.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.0002999952979984405 Training loss: 7.46183443069458
2025-12-09 12:00:07.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.00029999454679564244 Training loss: 7.538503646850586
2025-12-09 12:00:07.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.0002999937399495895 Training loss: 7.684062480926514
2025-12-09 12:00:07.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.00029999287746058093 Training loss: 7.67542839050293
2025-12-09 12:00:08.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.00029999195932893676 Training loss: 7.487673282623291
2025-12-09 12:00:08.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.00029999098555499756 Training loss: 8.365485191345215
2025-12-09 12:00:08.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.0002999899561391246 Training loss: 7.410362243652344
2025-12-09 12:00:08.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.00029998887108169967 Training loss: 7.692431926727295
2025-12-09 12:00:08.572 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.0002999877303831254 Training loss: 7.746969223022461
2025-12-09 12:00:08.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.00029998653404382487 Training loss: 7.446236610412598
2025-12-09 12:00:08.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.000299985282064242 Training loss: 8.1162691116333
2025-12-09 12:00:08.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.00029998397444484104 Training loss: 8.049375534057617
2025-12-09 12:00:09.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.0002999826111861073 Training loss: 7.364995956420898
2025-12-09 12:00:09.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.00029998119228854625 Training loss: 7.422381401062012
2025-12-09 12:00:09.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.0002999797177526845 Training loss: 7.5230937004089355
2025-12-09 12:00:09.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.000299978187579069 Training loss: 7.672178745269775
2025-12-09 12:00:09.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.0002999766017682673 Training loss: 7.269942283630371
2025-12-09 12:00:09.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.00029997496032086775 Training loss: 7.003915786743164
2025-12-09 12:00:09.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.00029997326323747927 Training loss: 7.512111186981201
2025-12-09 12:00:10.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.0002999715105187314 Training loss: 7.581761837005615
2025-12-09 12:00:10.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.00029996970216527436 Training loss: 7.590974807739258
2025-12-09 12:00:10.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.000299967838177779 Training loss: 7.303343296051025
2025-12-09 12:00:10.415 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.00029996591855693686 Training loss: 8.074216842651367
2025-12-09 12:00:10.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.00029996394330345996 Training loss: 7.61617374420166
2025-12-09 12:00:10.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.0002999619124180811 Training loss: 7.564840793609619
2025-12-09 12:00:10.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.00029995982590155367 Training loss: 7.4469170570373535
2025-12-09 12:00:10.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.00029995768375465164 Training loss: 7.584579944610596
2025-12-09 12:00:11.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.0002999554859781698 Training loss: 7.121623516082764
2025-12-09 12:00:11.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.00029995323257292337 Training loss: 7.221843719482422
2025-12-09 12:00:11.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.0002999509235397483 Training loss: 7.283834457397461
2025-12-09 12:00:11.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.00029994855887950124 Training loss: 7.644946098327637
2025-12-09 12:00:11.597 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.00029994613859305933 Training loss: 7.821969985961914
2025-12-09 12:00:11.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.0002999436626813204 Training loss: 7.353585243225098
2025-12-09 12:00:11.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.000299941131145203 Training loss: 7.4362053871154785
2025-12-09 12:00:11.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.0002999385439856462 Training loss: 7.502919673919678
2025-12-09 12:00:12.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.0002999359012036099 Training loss: 7.132528305053711
2025-12-09 12:00:12.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.0002999332028000742 Training loss: 7.708968639373779
2025-12-09 12:00:12.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.0002999304487760404 Training loss: 7.287742614746094
2025-12-09 12:00:12.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.00029992763913253 Training loss: 7.491179943084717
2025-12-09 12:00:12.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.00029992477387058537 Training loss: 7.314788341522217
2025-12-09 12:00:12.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.0002999218529912694 Training loss: 7.25926399230957
2025-12-09 12:00:12.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.00029991887649566564 Training loss: 7.271883964538574
2025-12-09 12:00:13.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.00029991584438487825 Training loss: 7.258403301239014
2025-12-09 12:00:13.175 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.0002999127566600321 Training loss: 6.944456577301025
2025-12-09 12:00:13.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.00029990961332227264 Training loss: 7.257098197937012
2025-12-09 12:00:13.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.0002999064143727659 Training loss: 7.387748718261719
2025-12-09 12:00:13.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.00029990315981269863 Training loss: 7.1419291496276855
2025-12-09 12:00:13.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.0002998998496432781 Training loss: 7.343527317047119
2025-12-09 12:00:13.829 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.0002998964838657324 Training loss: 7.173925876617432
2025-12-09 12:00:13.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.0002998930624813101 Training loss: 7.1696696281433105
2025-12-09 12:00:14.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.00029988958549128026 Training loss: 6.954655647277832
2025-12-09 12:00:14.229 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.00029988605289693295 Training loss: 7.626846790313721
2025-12-09 12:00:14.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.0002998824646995785 Training loss: 7.048863410949707
2025-12-09 12:00:14.493 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.00029987882090054817 Training loss: 7.113448143005371
2025-12-09 12:00:14.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.0002998751215011935 Training loss: 7.375546455383301
2025-12-09 12:00:14.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.000299871366502887 Training loss: 7.182054042816162
2025-12-09 12:00:14.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.00029986755590702164 Training loss: 6.888533592224121
2025-12-09 12:00:15.017 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.000299863689715011 Training loss: 7.062204360961914
2025-12-09 12:00:15.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.0002998597679282893 Training loss: 6.34267520904541
2025-12-09 12:00:15.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.00029985579054831146 Training loss: 7.292207717895508
2025-12-09 12:00:15.412 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.0002998517575765528 Training loss: 7.690987586975098
2025-12-09 12:00:15.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.00029984766901450965 Training loss: 7.744146823883057
2025-12-09 12:00:15.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.00029984352486369867 Training loss: 7.155710220336914
2025-12-09 12:00:15.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.00029983932512565707 Training loss: 7.416845798492432
2025-12-09 12:00:15.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.00029983506980194296 Training loss: 7.458015441894531
2025-12-09 12:00:16.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.00029983075889413493 Training loss: 6.910699844360352
2025-12-09 12:00:16.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.00029982639240383214 Training loss: 6.702212810516357
2025-12-09 12:00:16.336 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.00029982197033265437 Training loss: 7.251434326171875
2025-12-09 12:00:16.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.00029981749268224225 Training loss: 7.214992046356201
2025-12-09 12:00:16.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.00029981295945425665 Training loss: 7.254419326782227
2025-12-09 12:00:16.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.00029980837065037935 Training loss: 7.155343055725098
2025-12-09 12:00:16.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.00029980372627231265 Training loss: 7.0749406814575195
2025-12-09 12:00:16.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.00029979902632177945 Training loss: 6.921314716339111
2025-12-09 12:00:17.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.0002997942708005233 Training loss: 7.144604206085205
2025-12-09 12:00:17.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.00029978945971030835 Training loss: 6.962082386016846
2025-12-09 12:00:17.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.0002997845930529194 Training loss: 6.878061294555664
2025-12-09 12:00:17.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.00029977967083016173 Training loss: 7.077265739440918
2025-12-09 12:00:17.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.00029977469304386133 Training loss: 7.145606994628906
2025-12-09 12:00:17.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.0002997696596958649 Training loss: 7.3023881912231445
2025-12-09 12:00:17.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.0002997645707880396 Training loss: 7.7349700927734375
2025-12-09 12:00:18.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.0002997594263222733 Training loss: 7.084598064422607
2025-12-09 12:00:18.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.00029975422630047435 Training loss: 7.221497535705566
2025-12-09 12:00:18.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.00029974897072457187 Training loss: 6.852949619293213
2025-12-09 12:00:18.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.0002997436595965154 Training loss: 6.9160590171813965
2025-12-09 12:00:18.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.0002997382929182754 Training loss: 7.702733039855957
2025-12-09 12:00:18.719 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.00029973287069184255 Training loss: 7.380812644958496
2025-12-09 12:00:18.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.0002997273929192284 Training loss: 6.937784194946289
2025-12-09 12:00:19.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.0002997218596024651 Training loss: 6.207913398742676
2025-12-09 12:00:19.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.00029971627074360516 Training loss: 7.223640441894531
2025-12-09 12:00:19.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.00029971062634472203 Training loss: 5.986891269683838
2025-12-09 12:00:19.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.00029970492640790956 Training loss: 7.947351932525635
2025-12-09 12:00:19.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.0002996991709352822 Training loss: 7.175192356109619
2025-12-09 12:00:19.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.0002996933599289751 Training loss: 7.190242290496826
2025-12-09 12:00:19.814 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.000299687493391144 Training loss: 7.3318190574646
2025-12-09 12:00:19.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.00029968157132396507 Training loss: 7.395473480224609
2025-12-09 12:00:20.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.00029967559372963534 Training loss: 6.940025806427002
2025-12-09 12:00:20.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.00029966956061037227 Training loss: 7.727866172790527
2025-12-09 12:00:20.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.00029966347196841393 Training loss: 6.684452533721924
2025-12-09 12:00:20.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.000299657327806019 Training loss: 6.898775100708008
2025-12-09 12:00:20.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.0002996511281254668 Training loss: 7.6024346351623535
2025-12-09 12:00:20.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.0002996448729290572 Training loss: 7.199158668518066
2025-12-09 12:00:20.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.00029963856221911075 Training loss: 7.090175151824951
2025-12-09 12:00:21.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.00029963219599796843 Training loss: 6.725348949432373
2025-12-09 12:00:21.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.000299625774267992 Training loss: 6.950185775756836
2025-12-09 12:00:21.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.0002996192970315636 Training loss: 6.9729437828063965
2025-12-09 12:00:21.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.00029961276429108625 Training loss: 7.124135494232178
2025-12-09 12:00:21.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.00029960617604898323 Training loss: 7.1713547706604
2025-12-09 12:00:21.676 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.0002995995323076986 Training loss: 6.559902667999268
2025-12-09 12:00:21.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.00029959283306969705 Training loss: 7.1608195304870605
2025-12-09 12:00:21.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.00029958607833746375 Training loss: 6.7136359214782715
2025-12-09 12:00:22.069 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.0002995792681135045 Training loss: 6.718952655792236
2025-12-09 12:00:22.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.00029957240240034564 Training loss: 6.798439979553223
2025-12-09 12:00:22.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.0002995654812005342 Training loss: 6.981288909912109
2025-12-09 12:00:22.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.0002995585045166376 Training loss: 7.012053489685059
2025-12-09 12:00:22.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.00029955147235124417 Training loss: 7.228607654571533
2025-12-09 12:00:22.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.00029954438470696247 Training loss: 6.548223495483398
2025-12-09 12:00:22.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.0002995372415864218 Training loss: 5.943597793579102
2025-12-09 12:00:23.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.0002995300429922721 Training loss: 7.049764633178711
2025-12-09 12:00:23.139 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.00029952278892718376 Training loss: 6.905707359313965
2025-12-09 12:00:23.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.0002995154793938479 Training loss: 6.76295804977417
2025-12-09 12:00:23.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.00029950811439497606 Training loss: 6.9565839767456055
2025-12-09 12:00:23.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.0002995006939333004 Training loss: 6.805382251739502
2025-12-09 12:00:23.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.00029949321801157365 Training loss: 7.950512409210205
2025-12-09 12:00:23.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.00029948568663256927 Training loss: 7.048497676849365
2025-12-09 12:00:23.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.0002994780997990811 Training loss: 7.039363384246826
2025-12-09 12:00:24.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.0002994704575139236 Training loss: 6.888115882873535
2025-12-09 12:00:24.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.00029946275977993175 Training loss: 7.001029014587402
2025-12-09 12:00:24.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.0002994550065999613 Training loss: 7.11806058883667
2025-12-09 12:00:24.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.0002994471979768884 Training loss: 7.161579608917236
2025-12-09 12:00:24.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.00029943933391360974 Training loss: 6.504371166229248
2025-12-09 12:00:24.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.00029943141441304274 Training loss: 6.617962837219238
2025-12-09 12:00:24.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.00029942343947812517 Training loss: 7.131515979766846
2025-12-09 12:00:24.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.0002994154091118156 Training loss: 6.107207775115967
2025-12-09 12:00:25.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.0002994073233170929 Training loss: 6.275119781494141
2025-12-09 12:00:25.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.00029939918209695676 Training loss: 6.597204685211182
2025-12-09 12:00:25.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.0002993909854544273 Training loss: 6.277313709259033
2025-12-09 12:00:25.526 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.00029938273339254515 Training loss: 6.763093948364258
2025-12-09 12:00:25.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.0002993744259143716 Training loss: 6.829300880432129
2025-12-09 12:00:25.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.0002993660630229886 Training loss: 7.109520435333252
2025-12-09 12:00:25.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.0002993576447214983 Training loss: 7.137240409851074
2025-12-09 12:00:26.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.0002993491710130237 Training loss: 6.714609622955322
2025-12-09 12:00:26.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.00029934064190070836 Training loss: 6.903271675109863
2025-12-09 12:00:26.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.00029933205738771624 Training loss: 7.076664924621582
2025-12-09 12:00:26.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.0002993234174772319 Training loss: 6.659549236297607
2025-12-09 12:00:26.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.00029931472217246057 Training loss: 7.0342607498168945
2025-12-09 12:00:26.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.0002993059714766278 Training loss: 6.066636085510254
2025-12-09 12:00:26.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.00029929716539297993 Training loss: 6.806735515594482
2025-12-09 12:00:26.985 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.00029928830392478376 Training loss: 7.439578533172607
2025-12-09 12:00:27.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.0002992793870753265 Training loss: 6.881400108337402
2025-12-09 12:00:27.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.0002992704148479161 Training loss: 7.194422245025635
2025-12-09 12:00:27.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.00029926138724588097 Training loss: 7.158584117889404
2025-12-09 12:00:27.511 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.00029925230427257004 Training loss: 7.2395853996276855
2025-12-09 12:00:27.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.0002992431659313528 Training loss: 6.77945613861084
2025-12-09 12:00:27.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.00029923397222561933 Training loss: 7.213230133056641
2025-12-09 12:00:27.904 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.0002992247231587802 Training loss: 6.953975677490234
2025-12-09 12:00:28.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.00029921541873426647 Training loss: 6.594226837158203
2025-12-09 12:00:28.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.00029920605895552985 Training loss: 6.635535717010498
2025-12-09 12:00:28.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.0002991966438260425 Training loss: 7.040811061859131
2025-12-09 12:00:28.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.0002991871733492971 Training loss: 6.753504276275635
2025-12-09 12:00:28.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.00029917764752880697 Training loss: 7.067911624908447
2025-12-09 12:00:28.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.0002991680663681059 Training loss: 7.362040042877197
2025-12-09 12:00:28.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.00029915842987074804 Training loss: 7.157418251037598
2025-12-09 12:00:28.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.0002991487380403084 Training loss: 7.118253231048584
2025-12-09 12:00:29.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.00029913899088038226 Training loss: 6.549434661865234
2025-12-09 12:00:29.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.00029912918839458555 Training loss: 6.925827980041504
2025-12-09 12:00:29.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.00029911933058655464 Training loss: 6.5985636711120605
2025-12-09 12:00:29.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.00029910941745994653 Training loss: 6.962003231048584
2025-12-09 12:00:29.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.00029909944901843863 Training loss: 7.894905090332031
2025-12-09 12:00:29.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.0002990894252657289 Training loss: 6.781303882598877
2025-12-09 12:00:29.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.0002990793462055359 Training loss: 7.158175945281982
2025-12-09 12:00:30.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.0002990692118415986 Training loss: 6.94621467590332
2025-12-09 12:00:30.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.0002990590221776765 Training loss: 6.757176876068115
2025-12-09 12:00:30.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.0002990487772175497 Training loss: 6.827723503112793
2025-12-09 12:00:30.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.00029903847696501876 Training loss: 7.409829139709473
2025-12-09 12:00:30.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.00029902812142390474 Training loss: 6.583880424499512
2025-12-09 12:00:30.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.0002990177105980492 Training loss: 6.771885871887207
2025-12-09 12:00:30.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.00029900724449131424 Training loss: 7.373349189758301
2025-12-09 12:00:30.957 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.00029899672310758243 Training loss: 6.428901672363281
2025-12-09 12:00:31.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.0002989861464507569 Training loss: 7.297654628753662
2025-12-09 12:00:31.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.0002989755145247613 Training loss: 6.713200569152832
2025-12-09 12:00:31.353 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.00029896482733353965 Training loss: 6.67735481262207
2025-12-09 12:00:31.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.00029895408488105665 Training loss: 6.996583938598633
2025-12-09 12:00:31.617 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.0002989432871712973 Training loss: 7.061568260192871
2025-12-09 12:00:31.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.0002989324342082673 Training loss: 7.690868377685547
2025-12-09 12:00:31.889 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.00029892152599599275 Training loss: 6.922292232513428
2025-12-09 12:00:32.021 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.00029891056253852026 Training loss: 6.728631496429443
2025-12-09 12:00:32.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.0002988995438399169 Training loss: 6.817065715789795
2025-12-09 12:00:32.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.0002988884699042702 Training loss: 6.712889671325684
2025-12-09 12:00:32.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.0002988773407356884 Training loss: 6.44709587097168
2025-12-09 12:00:32.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.0002988661563382999 Training loss: 7.103890895843506
2025-12-09 12:00:32.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.0002988549167162539 Training loss: 7.513609409332275
2025-12-09 12:00:32.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.00029884362187371986 Training loss: 7.006128787994385
2025-12-09 12:00:32.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.0002988322718148878 Training loss: 6.990085601806641
2025-12-09 12:00:33.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.0002988208665439683 Training loss: 7.175356864929199
2025-12-09 12:00:33.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.0002988094060651923 Training loss: 6.710684776306152
2025-12-09 12:00:33.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.0002987978903828114 Training loss: 7.093545913696289
2025-12-09 12:00:33.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.00029878631950109734 Training loss: 7.0405964851379395
2025-12-09 12:00:33.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.0002987746934243427 Training loss: 6.842047214508057
2025-12-09 12:00:33.750 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.0002987630121568604 Training loss: 6.953717231750488
2025-12-09 12:00:33.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.00029875127570298376 Training loss: 6.759392261505127
2025-12-09 12:00:34.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.0002987394840670666 Training loss: 6.142602443695068
2025-12-09 12:00:34.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.0002987276372534834 Training loss: 7.113316535949707
2025-12-09 12:00:34.274 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.0002987157352666288 Training loss: 6.678918838500977
2025-12-09 12:00:34.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.0002987037781109182 Training loss: 6.444745063781738
2025-12-09 12:00:34.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.00029869176579078714 Training loss: 6.755826473236084
2025-12-09 12:00:34.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.000298679698310692 Training loss: 7.067769527435303
2025-12-09 12:00:34.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.00029866757567510927 Training loss: 6.811863899230957
2025-12-09 12:00:34.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.0002986553978885362 Training loss: 6.969140529632568
2025-12-09 12:00:35.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.00029864316495549037 Training loss: 6.810227870941162
2025-12-09 12:00:35.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.0002986308768805097 Training loss: 5.967490196228027
2025-12-09 12:00:35.338 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.00029861853366815275 Training loss: 6.808614253997803
2025-12-09 12:00:35.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.00029860613532299845 Training loss: 6.7267165184021
2025-12-09 12:00:35.604 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.00029859368184964624 Training loss: 6.747554302215576
2025-12-09 12:00:35.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.00029858117325271585 Training loss: 7.392122745513916
2025-12-09 12:00:35.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.00029856860953684773 Training loss: 6.661529064178467
2025-12-09 12:00:35.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.0002985559907067025 Training loss: 6.95978307723999
2025-12-09 12:00:36.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.00029854331676696137 Training loss: 6.752152442932129
2025-12-09 12:00:36.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.000298530587722326 Training loss: 6.751728057861328
2025-12-09 12:00:36.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.00029851780357751853 Training loss: 6.682614326477051
2025-12-09 12:00:36.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.00029850496433728136 Training loss: 6.63006067276001
2025-12-09 12:00:36.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.0002984920700063775 Training loss: 6.877806663513184
2025-12-09 12:00:36.797 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.00029847912058959033 Training loss: 7.103487968444824
2025-12-09 12:00:36.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.00029846611609172363 Training loss: 6.630029201507568
2025-12-09 12:00:37.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.00029845305651760175 Training loss: 7.579110145568848
2025-12-09 12:00:37.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.00029843994187206933 Training loss: 6.6499247550964355
2025-12-09 12:00:37.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.0002984267721599915 Training loss: 6.5617852210998535
2025-12-09 12:00:37.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.0002984135473862538 Training loss: 6.881515979766846
2025-12-09 12:00:37.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.0002984002675557622 Training loss: 6.543944835662842
2025-12-09 12:00:37.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.0002983869326734432 Training loss: 6.714897155761719
2025-12-09 12:00:37.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.0002983735427442434 Training loss: 6.949604034423828
2025-12-09 12:00:37.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.00029836009777313026 Training loss: 7.588409423828125
2025-12-09 12:00:38.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.00029834659776509134 Training loss: 6.888827800750732
2025-12-09 12:00:38.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.0002983330427251347 Training loss: 6.862154483795166
2025-12-09 12:00:38.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.0002983194326582889 Training loss: 6.784917831420898
2025-12-09 12:00:38.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.0002983057675696028 Training loss: 6.580281734466553
2025-12-09 12:00:38.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.0002982920474641457 Training loss: 7.280778408050537
2025-12-09 12:00:38.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.0002982782723470074 Training loss: 7.199377059936523
2025-12-09 12:00:38.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.000298264442223298 Training loss: 6.732682704925537
2025-12-09 12:00:39.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.00029825055709814795 Training loss: 7.268727779388428
2025-12-09 12:00:39.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.00029823661697670834 Training loss: 6.57512903213501
2025-12-09 12:00:39.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.00029822262186415046 Training loss: 6.341458797454834
2025-12-09 12:00:39.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.00029820857176566606 Training loss: 6.5847673416137695
2025-12-09 12:00:39.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.0002981944666864672 Training loss: 6.8834052085876465
2025-12-09 12:00:39.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.0002981803066317865 Training loss: 7.025346755981445
2025-12-09 12:00:39.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.00029816609160687697 Training loss: 7.021263122558594
2025-12-09 12:00:39.987 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.0002981518216170118 Training loss: 7.221734523773193
2025-12-09 12:00:40.119 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.0002981374966674848 Training loss: 6.947574615478516
2025-12-09 12:00:40.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.00029812311676361003 Training loss: 5.895284175872803
2025-12-09 12:00:40.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.00029810868191072195 Training loss: 6.25653600692749
2025-12-09 12:00:40.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.00029809419211417553 Training loss: 7.446513652801514
2025-12-09 12:00:40.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.0002980796473793459 Training loss: 6.90146541595459
2025-12-09 12:00:40.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.0002980650477116288 Training loss: 6.996707916259766
2025-12-09 12:00:40.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.00029805039311644023 Training loss: 7.047536373138428
2025-12-09 12:00:41.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.0002980356835992166 Training loss: 7.055732250213623
2025-12-09 12:00:41.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.0002980209191654146 Training loss: 6.907588958740234
2025-12-09 12:00:41.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.00029800609982051147 Training loss: 6.754956245422363
2025-12-09 12:00:41.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.0002979912255700046 Training loss: 7.339073657989502
2025-12-09 12:00:41.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.000297976296419412 Training loss: 6.6379170417785645
2025-12-09 12:00:41.710 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.00029796131237427186 Training loss: 6.477149486541748
2025-12-09 12:00:41.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.00029794627344014276 Training loss: 6.932147026062012
2025-12-09 12:00:41.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.00029793117962260366 Training loss: 6.608974933624268
2025-12-09 12:00:42.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.000297916030927254 Training loss: 6.618497371673584
2025-12-09 12:00:42.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.0002979008273597133 Training loss: 7.411874771118164
2025-12-09 12:00:42.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.0002978855689256218 Training loss: 6.744926929473877
2025-12-09 12:00:42.500 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.00029787025563063975 Training loss: 6.44092321395874
2025-12-09 12:00:42.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.0002978548874804479 Training loss: 6.456856727600098
2025-12-09 12:00:42.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.0002978394644807475 Training loss: 7.120935916900635
2025-12-09 12:00:42.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.0002978239866372598 Training loss: 7.108285427093506
2025-12-09 12:00:43.037 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.00029780845395572673 Training loss: 7.113008499145508
2025-12-09 12:00:43.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.0002977928664419104 Training loss: 6.912765026092529
2025-12-09 12:00:43.304 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.0002977772241015933 Training loss: 6.974814414978027
2025-12-09 12:00:43.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.00029776152694057815 Training loss: 6.185475826263428
2025-12-09 12:00:43.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.0002977457749646882 Training loss: 6.958452224731445
2025-12-09 12:00:43.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.00029772996817976693 Training loss: 6.598051071166992
2025-12-09 12:00:43.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.00029771410659167806 Training loss: 6.62130880355835
2025-12-09 12:00:43.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.00029769819020630594 Training loss: 6.494078159332275
2025-12-09 12:00:44.097 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.0002976822190295548 Training loss: 6.744620323181152
2025-12-09 12:00:44.228 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.00029766619306734963 Training loss: 6.679957389831543
2025-12-09 12:00:44.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.0002976501123256355 Training loss: 6.6014909744262695
2025-12-09 12:00:44.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.00029763397681037787 Training loss: 6.906907558441162
2025-12-09 12:00:44.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.00029761778652756245 Training loss: 7.221487998962402
2025-12-09 12:00:44.769 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.00029760154148319534 Training loss: 7.039102077484131
2025-12-09 12:00:44.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.000297585241683303 Training loss: 6.538576602935791
2025-12-09 12:00:45.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.00029756888713393213 Training loss: 6.761519908905029
2025-12-09 12:00:45.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.00029755247784114976 Training loss: 6.651091575622559
2025-12-09 12:00:45.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.0002975360138110431 Training loss: 6.869318962097168
2025-12-09 12:00:45.429 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.00029751949504972 Training loss: 6.696396350860596
2025-12-09 12:00:45.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.0002975029215633082 Training loss: 7.248980522155762
2025-12-09 12:00:45.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.000297486293357956 Training loss: 6.517058372497559
2025-12-09 12:00:45.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.00029746961043983206 Training loss: 6.7073140144348145
2025-12-09 12:00:45.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.00029745287281512505 Training loss: 6.798377513885498
2025-12-09 12:00:46.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.0002974360804900442 Training loss: 6.943686485290527
2025-12-09 12:00:46.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.0002974192334708189 Training loss: 6.8597893714904785
2025-12-09 12:00:46.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.00029740233176369887 Training loss: 6.591212749481201
2025-12-09 12:00:46.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.0002973853753749541 Training loss: 6.628645896911621
2025-12-09 12:00:46.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.00029736836431087493 Training loss: 6.398437023162842
2025-12-09 12:00:46.768 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.00029735129857777183 Training loss: 6.707765102386475
2025-12-09 12:00:46.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.00029733417818197575 Training loss: 6.811399459838867
2025-12-09 12:00:47.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.00029731700312983776 Training loss: 6.555562973022461
2025-12-09 12:00:47.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.0002972997734277293 Training loss: 6.678510665893555
2025-12-09 12:00:47.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.000297282489082042 Training loss: 6.787700176239014
2025-12-09 12:00:47.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.00029726515009918786 Training loss: 6.5731096267700195
2025-12-09 12:00:47.558 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.0002972477564855991 Training loss: 6.974290370941162
2025-12-09 12:00:47.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.0002972303082477281 Training loss: 6.987683296203613
2025-12-09 12:00:47.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.00029721280539204774 Training loss: 6.633458614349365
2025-12-09 12:00:47.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.0002971952479250509 Training loss: 7.807102203369141
2025-12-09 12:00:48.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.000297177635853251 Training loss: 6.6467509269714355
2025-12-09 12:00:48.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.0002971599691831815 Training loss: 6.821258068084717
2025-12-09 12:00:48.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.00029714224792139605 Training loss: 6.8281569480896
2025-12-09 12:00:48.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.0002971244720744688 Training loss: 6.665641784667969
2025-12-09 12:00:48.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.00029710664164899413 Training loss: 6.440520763397217
2025-12-09 12:00:48.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.0002970887566515864 Training loss: 6.922285556793213
2025-12-09 12:00:48.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.0002970708170888804 Training loss: 6.9360270500183105
2025-12-09 12:00:49.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.0002970528229675312 Training loss: 6.502284526824951
2025-12-09 12:00:49.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.0002970347742942141 Training loss: 6.9281325340271
2025-12-09 12:00:49.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.0002970166710756244 Training loss: 6.749300479888916
2025-12-09 12:00:49.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.0002969985133184781 Training loss: 6.7211480140686035
2025-12-09 12:00:49.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.0002969803010295109 Training loss: 6.658637523651123
2025-12-09 12:00:49.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.0002969620342154791 Training loss: 7.637937545776367
2025-12-09 12:00:49.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.0002969437128831591 Training loss: 6.3284783363342285
2025-12-09 12:00:49.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.00029692533703934757 Training loss: 6.767683982849121
2025-12-09 12:00:50.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.00029690690669086127 Training loss: 6.610884189605713
2025-12-09 12:00:50.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.0002968884218445374 Training loss: 6.517043113708496
2025-12-09 12:00:50.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.0002968698825072332 Training loss: 6.566539764404297
2025-12-09 12:00:50.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.0002968512886858262 Training loss: 6.486649990081787
2025-12-09 12:00:50.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.00029683264038721414 Training loss: 6.8148064613342285
2025-12-09 12:00:50.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.00029681393761831485 Training loss: 6.758321285247803
2025-12-09 12:00:50.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.0002967951803860665 Training loss: 6.99622106552124
2025-12-09 12:00:51.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.0002967763686974276 Training loss: 6.537287712097168
2025-12-09 12:00:51.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.00029675750255937647 Training loss: 6.812067985534668
2025-12-09 12:00:51.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.000296738581978912 Training loss: 6.80968713760376
2025-12-09 12:00:51.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.00029671960696305304 Training loss: 6.3697075843811035
2025-12-09 12:00:51.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.00029670057751883874 Training loss: 7.253718376159668
2025-12-09 12:00:51.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.0002966814936533285 Training loss: 6.376917839050293
2025-12-09 12:00:51.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.00029666235537360175 Training loss: 6.779952049255371
2025-12-09 12:00:51.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.00029664316268675824 Training loss: 6.6794304847717285
2025-12-09 12:00:52.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.0002966239155999178 Training loss: 6.590425491333008
2025-12-09 12:00:52.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.0002966046141202205 Training loss: 6.6775007247924805
2025-12-09 12:00:52.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.0002965852582548267 Training loss: 6.99743127822876
2025-12-09 12:00:52.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.00029656584801091663 Training loss: 6.2806782722473145
2025-12-09 12:00:52.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.000296546383395691 Training loss: 6.46066427230835
2025-12-09 12:00:52.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.00029652686441637054 Training loss: 6.82151460647583
2025-12-09 12:00:52.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.00029650729108019624 Training loss: 6.659484386444092
2025-12-09 12:00:53.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.0002964876633944291 Training loss: 6.092236518859863
2025-12-09 12:00:53.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.00029646798136635034 Training loss: 7.143528938293457
2025-12-09 12:00:53.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.0002964482450032615 Training loss: 6.471934795379639
2025-12-09 12:00:53.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.00029642845431248406 Training loss: 6.759097099304199
2025-12-09 12:00:53.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.0002964086093013597 Training loss: 6.861564636230469
2025-12-09 12:00:53.718 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.00029638870997725046 Training loss: 6.656829833984375
2025-12-09 12:00:53.851 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.00029636875634753824 Training loss: 6.8517327308654785
2025-12-09 12:00:53.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.00029634874841962525 Training loss: 6.415431976318359
2025-12-09 12:00:54.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.00029632868620093375 Training loss: 6.452298641204834
2025-12-09 12:00:54.260 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.0002963085696989063 Training loss: 6.563694953918457
2025-12-09 12:00:54.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.00029628839892100535 Training loss: 6.6003499031066895
2025-12-09 12:00:54.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.00029626817387471365 Training loss: 6.354922771453857
2025-12-09 12:00:54.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.00029624789456753417 Training loss: 6.699944019317627
2025-12-09 12:00:54.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.00029622756100698976 Training loss: 6.899888038635254
2025-12-09 12:00:54.922 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.0002962071732006237 Training loss: 6.646925926208496
2025-12-09 12:00:55.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.00029618673115599896 Training loss: 6.423149585723877
2025-12-09 12:00:55.186 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.0002961662348806992 Training loss: 7.013546466827393
2025-12-09 12:00:55.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.00029614568438232766 Training loss: 6.659104824066162
2025-12-09 12:00:55.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.000296125079668508 Training loss: 6.39658260345459
2025-12-09 12:00:55.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.00029610442074688394 Training loss: 6.509881496429443
2025-12-09 12:00:55.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.00029608370762511935 Training loss: 6.559003829956055
2025-12-09 12:00:55.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.000296062940310898 Training loss: 6.078871250152588
2025-12-09 12:00:55.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.000296042118811924 Training loss: 6.983765602111816
2025-12-09 12:00:56.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.0002960212431359215 Training loss: 7.1297688484191895
2025-12-09 12:00:56.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.00029600031329063463 Training loss: 6.803799629211426
2025-12-09 12:00:56.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.0002959793292838277 Training loss: 7.153914451599121
2025-12-09 12:00:56.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.0002959582911232853 Training loss: 6.504130840301514
2025-12-09 12:00:56.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.00029593719881681167 Training loss: 6.674565315246582
2025-12-09 12:00:56.790 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.00029591605237223157 Training loss: 6.6391682624816895
2025-12-09 12:00:56.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.0002958948517973896 Training loss: 6.275681018829346
2025-12-09 12:00:57.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.0002958735971001505 Training loss: 6.545169353485107
2025-12-09 12:00:57.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.0002958522882883991 Training loss: 5.633846282958984
2025-12-09 12:00:57.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.0002958309253700404 Training loss: 6.947949409484863
2025-12-09 12:00:57.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.00029580950835299914 Training loss: 6.625441551208496
2025-12-09 12:00:57.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.0002957880372452206 Training loss: 6.708613872528076
2025-12-09 12:00:57.724 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.0002957665120546697 Training loss: 6.591789722442627
2025-12-09 12:00:57.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.0002957449327893317 Training loss: 7.192845821380615
2025-12-09 12:00:57.989 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.00029572329945721186 Training loss: 6.919058799743652
2025-12-09 12:00:58.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.0002957016120663354 Training loss: 6.879348278045654
2025-12-09 12:00:58.254 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.00029567987062474767 Training loss: 6.878209114074707
2025-12-09 12:00:58.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.00029565807514051406 Training loss: 6.1616034507751465
2025-12-09 12:00:58.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.0002956362256217201 Training loss: 6.729837894439697
2025-12-09 12:00:58.650 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.0002956143220764711 Training loss: 6.6906819343566895
2025-12-09 12:00:58.781 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.0002955923645128927 Training loss: 6.455505847930908
2025-12-09 12:00:58.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.00029557035293913044 Training loss: 6.91118049621582
2025-12-09 12:00:59.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.00029554828736334994 Training loss: 7.011110305786133
2025-12-09 12:00:59.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.0002955261677937368 Training loss: 6.810476303100586
2025-12-09 12:00:59.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.00029550399423849673 Training loss: 6.484557151794434
2025-12-09 12:00:59.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.0002954817667058554 Training loss: 6.714658737182617
2025-12-09 12:00:59.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.00029545948520405844 Training loss: 6.8229851722717285
2025-12-09 12:00:59.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.00029543714974137177 Training loss: 7.0380706787109375
2025-12-09 12:00:59.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.000295414760326081 Training loss: 6.656438827514648
2025-12-09 12:00:59.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.0002953923169664919 Training loss: 7.044652462005615
2025-12-09 12:01:00.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.00029536981967093033 Training loss: 6.90962028503418
2025-12-09 12:01:00.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.00029534726844774196 Training loss: 6.736878871917725
2025-12-09 12:01:00.383 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.00029532466330529277 Training loss: 6.888649940490723
2025-12-09 12:01:00.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.00029530200425196835 Training loss: 6.774148464202881
2025-12-09 12:01:00.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.00029527929129617464 Training loss: 6.553130149841309
2025-12-09 12:01:00.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.00029525652444633736 Training loss: 6.9994916915893555
2025-12-09 12:01:00.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.0002952337037109023 Training loss: 7.426202297210693
2025-12-09 12:01:01.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.0002952108290983353 Training loss: 6.5594868659973145
2025-12-09 12:01:01.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.00029518790061712204 Training loss: 6.241743564605713
2025-12-09 12:01:01.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.0002951649182757683 Training loss: 6.630245685577393
2025-12-09 12:01:01.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.00029514188208279977 Training loss: 6.535955905914307
2025-12-09 12:01:01.564 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.0002951187920467622 Training loss: 6.675178527832031
2025-12-09 12:01:01.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.0002950956481762213 Training loss: 6.392228603363037
2025-12-09 12:01:01.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.0002950724504797626 Training loss: 6.428028583526611
2025-12-09 12:01:01.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.0002950491989659918 Training loss: 6.644340515136719
2025-12-09 12:01:02.095 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.00029502589364353447 Training loss: 6.666628837585449
2025-12-09 12:01:02.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.00029500253452103615 Training loss: 6.48818302154541
2025-12-09 12:01:02.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.00029497912160716234 Training loss: 7.919956207275391
2025-12-09 12:01:02.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.0002949556549105985 Training loss: 6.822987079620361
2025-12-09 12:01:02.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.00029493213444005 Training loss: 6.4810991287231445
2025-12-09 12:01:02.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.0002949085602042422 Training loss: 6.540131568908691
2025-12-09 12:01:02.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.00029488493221192043 Training loss: 6.6362409591674805
2025-12-09 12:01:03.024 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.00029486125047184985 Training loss: 6.688593864440918
2025-12-09 12:01:03.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.0002948375149928158 Training loss: 5.852611541748047
2025-12-09 12:01:03.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.0002948137257836233 Training loss: 6.5392374992370605
2025-12-09 12:01:03.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.0002947898828530974 Training loss: 6.365372657775879
2025-12-09 12:01:03.547 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.000294765986210083 Training loss: 7.079968452453613
2025-12-09 12:01:03.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.0002947420358634451 Training loss: 6.70639181137085
2025-12-09 12:01:03.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.00029471803182206855 Training loss: 6.657026767730713
2025-12-09 12:01:03.953 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.000294693974094858 Training loss: 6.692840099334717
2025-12-09 12:01:04.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.0002946698626907382 Training loss: 6.8990912437438965
2025-12-09 12:01:04.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.00029464569761865366 Training loss: 6.507811546325684
2025-12-09 12:01:04.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.0002946214788875689 Training loss: 7.089452266693115
2025-12-09 12:01:04.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.00029459720650646824 Training loss: 6.292940139770508
2025-12-09 12:01:04.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.00029457288048435605 Training loss: 6.650278568267822
2025-12-09 12:01:04.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.00029454850083025644 Training loss: 7.036309242248535
2025-12-09 12:01:04.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.0002945240675532136 Training loss: 6.466826915740967
2025-12-09 12:01:05.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.0002944995806622914 Training loss: 6.294413089752197
2025-12-09 12:01:05.143 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.0002944750401665738 Training loss: 7.050683498382568
2025-12-09 12:01:05.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.00029445044607516447 Training loss: 6.929891586303711
2025-12-09 12:01:05.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.00029442579839718703 Training loss: 6.452652454376221
2025-12-09 12:01:05.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.0002944010971417851 Training loss: 6.59505558013916
2025-12-09 12:01:05.686 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.000294376342318122 Training loss: 6.840060234069824
2025-12-09 12:01:05.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.000294351533935381 Training loss: 6.942044258117676
2025-12-09 12:01:05.953 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.00029432667200276515 Training loss: 6.81189489364624
2025-12-09 12:01:06.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.0002943017565294976 Training loss: 6.930415153503418
2025-12-09 12:01:06.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.0002942767875248211 Training loss: 6.7939958572387695
2025-12-09 12:01:06.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.0002942517649979984 Training loss: 6.865792274475098
2025-12-09 12:01:06.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.00029422668895831203 Training loss: 6.40138053894043
2025-12-09 12:01:06.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.00029420155941506447 Training loss: 6.577569484710693
2025-12-09 12:01:06.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.00029417637637757797 Training loss: 6.156454563140869
2025-12-09 12:01:06.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.00029415113985519463 Training loss: 6.197803020477295
2025-12-09 12:01:07.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.0002941258498572764 Training loss: 7.021468639373779
2025-12-09 12:01:07.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.0002941005063932051 Training loss: 6.762009143829346
2025-12-09 12:01:07.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.0002940751094723823 Training loss: 6.613066673278809
2025-12-09 12:01:07.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.00029404965910422953 Training loss: 6.416049003601074
2025-12-09 12:01:07.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.00029402415529818804 Training loss: 6.506036281585693
2025-12-09 12:01:07.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.00029399859806371895 Training loss: 6.630853652954102
2025-12-09 12:01:07.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.0002939729874103032 Training loss: 7.615969181060791
2025-12-09 12:01:07.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.00029394732334744146 Training loss: 6.692241668701172
2025-12-09 12:01:08.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.00029392160588465434 Training loss: 6.455888748168945
2025-12-09 12:01:08.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.0002938958350314823 Training loss: 6.482207775115967
2025-12-09 12:01:08.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.00029387001079748536 Training loss: 6.586136341094971
2025-12-09 12:01:08.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.0002938441331922436 Training loss: 6.553709030151367
2025-12-09 12:01:08.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.0002938182022253568 Training loss: 5.880661964416504
2025-12-09 12:01:08.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.0002937922179064445 Training loss: 6.211407661437988
2025-12-09 12:01:08.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.000293766180245146 Training loss: 6.299215316772461
2025-12-09 12:01:09.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.00029374008925112056 Training loss: 6.504745006561279
2025-12-09 12:01:09.173 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.00029371394493404705 Training loss: 7.041599273681641
2025-12-09 12:01:09.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.00029368774730362425 Training loss: 6.443864345550537
2025-12-09 12:01:09.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.0002936614963695706 Training loss: 7.207455635070801
2025-12-09 12:01:09.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.0002936351921416244 Training loss: 5.95761775970459
2025-12-09 12:01:09.701 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.0002936088346295436 Training loss: 6.343687057495117
2025-12-09 12:01:09.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.0002935824238431062 Training loss: 6.546266078948975
2025-12-09 12:01:09.963 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.0002935559597921096 Training loss: 6.729245662689209
2025-12-09 12:01:10.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.00029352944248637117 Training loss: 6.764464855194092
2025-12-09 12:01:10.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.00029350287193572806 Training loss: 6.392004489898682
2025-12-09 12:01:10.378 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.000293476248150037 Training loss: 6.790611743927002
2025-12-09 12:01:10.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.00029344957113917473 Training loss: 7.3041863441467285
2025-12-09 12:01:10.643 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.0002934228409130374 Training loss: 6.534668445587158
2025-12-09 12:01:10.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.0002933960574815412 Training loss: 6.413110256195068
2025-12-09 12:01:10.909 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.0002933692208546219 Training loss: 6.887993812561035
2025-12-09 12:01:11.041 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.00029334233104223506 Training loss: 6.81685209274292
2025-12-09 12:01:11.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.00029331538805435595 Training loss: 6.687434196472168
2025-12-09 12:01:11.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.00029328839190097955 Training loss: 7.154909133911133
2025-12-09 12:01:11.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.00029326134259212064 Training loss: 6.669170379638672
2025-12-09 12:01:11.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.0002932342401378136 Training loss: 6.240015029907227
2025-12-09 12:01:11.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.0002932070845481126 Training loss: 6.975734710693359
2025-12-09 12:01:11.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.00029317987583309156 Training loss: 7.019876480102539
2025-12-09 12:01:11.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.00029315261400284404 Training loss: 6.4877214431762695
2025-12-09 12:01:12.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.0002931252990674832 Training loss: 6.861396312713623
2025-12-09 12:01:12.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.0002930979310371422 Training loss: 6.418371200561523
2025-12-09 12:01:12.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.0002930705099219736 Training loss: 6.357515811920166
2025-12-09 12:01:12.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.0002930430357321498 Training loss: 6.688861846923828
2025-12-09 12:01:12.645 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.0002930155084778629 Training loss: 7.235024929046631
2025-12-09 12:01:12.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.0002929879281693246 Training loss: 6.358208656311035
2025-12-09 12:01:12.908 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.0002929602948167663 Training loss: 6.311557769775391
2025-12-09 12:01:13.039 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.0002929326084304392 Training loss: 6.5353474617004395
2025-12-09 12:01:13.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.00029290486902061396 Training loss: 6.3556132316589355
2025-12-09 12:01:13.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.0002928770765975811 Training loss: 6.607030391693115
2025-12-09 12:01:13.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.00029284923117165075 Training loss: 5.5909857749938965
2025-12-09 12:01:13.579 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.0002928213327531526 Training loss: 6.5181050300598145
2025-12-09 12:01:13.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.00029279338135243624 Training loss: 6.742288112640381
2025-12-09 12:01:13.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.0002927653769798706 Training loss: 6.7202582359313965
2025-12-09 12:01:13.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.00029273731964584446 Training loss: 6.776366710662842
2025-12-09 12:01:14.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.00029270920936076624 Training loss: 6.625169277191162
2025-12-09 12:01:14.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.00029268104613506396 Training loss: 6.550739765167236
2025-12-09 12:01:14.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.00029265282997918533 Training loss: 6.306548595428467
2025-12-09 12:01:14.508 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.00029262456090359756 Training loss: 7.355528354644775
2025-12-09 12:01:14.640 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.0002925962389187877 Training loss: 6.676229476928711
2025-12-09 12:01:14.772 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.0002925678640352622 Training loss: 6.540258884429932
2025-12-09 12:01:14.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.00029253943626354734 Training loss: 7.206689834594727
2025-12-09 12:01:15.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.0002925109556141889 Training loss: 6.511402606964111
2025-12-09 12:01:15.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.0002924824220977523 Training loss: 6.303092956542969
2025-12-09 12:01:15.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.0002924538357248226 Training loss: 6.694511890411377
2025-12-09 12:01:15.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.00029242519650600436 Training loss: 6.763646125793457
2025-12-09 12:01:15.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.0002923965044519219 Training loss: 6.541094779968262
2025-12-09 12:01:15.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.0002923677595732191 Training loss: 6.488090515136719
2025-12-09 12:01:15.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.0002923389618805593 Training loss: 6.67152214050293
2025-12-09 12:01:15.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.00029231011138462564 Training loss: 6.443357944488525
2025-12-09 12:01:16.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.0002922812080961207 Training loss: 6.6047797203063965
2025-12-09 12:01:16.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.0002922522520257667 Training loss: 6.328556060791016
2025-12-09 12:01:16.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.0002922232431843054 Training loss: 6.736841201782227
2025-12-09 12:01:16.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.00029219418158249824 Training loss: 6.27064323425293
2025-12-09 12:01:16.652 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.0002921650672311261 Training loss: 6.51885986328125
2025-12-09 12:01:16.786 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.0002921359001409895 Training loss: 5.989752292633057
2025-12-09 12:01:16.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.0002921066803229085 Training loss: 6.7305827140808105
2025-12-09 12:01:17.055 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.00029207740778772277 Training loss: 6.618795871734619
2025-12-09 12:01:17.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.00029204808254629146 Training loss: 6.74566650390625
2025-12-09 12:01:17.322 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.00029201870460949326 Training loss: 7.412903785705566
2025-12-09 12:01:17.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.00029198927398822657 Training loss: 6.679183006286621
2025-12-09 12:01:17.587 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.0002919597906934092 Training loss: 6.704006195068359
2025-12-09 12:01:17.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.0002919302547359785 Training loss: 6.703843116760254
2025-12-09 12:01:17.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.0002919006661268914 Training loss: 6.841831207275391
2025-12-09 12:01:17.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.0002918710248771243 Training loss: 6.454733371734619
2025-12-09 12:01:18.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.0002918413309976732 Training loss: 6.605524063110352
2025-12-09 12:01:18.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.00029181158449955363 Training loss: 6.361297607421875
2025-12-09 12:01:18.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.0002917817853938005 Training loss: 6.784152507781982
2025-12-09 12:01:18.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.0002917519336914684 Training loss: 7.7667622566223145
2025-12-09 12:01:18.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.00029172202940363145 Training loss: 6.613851070404053
2025-12-09 12:01:18.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.0002916920725413831 Training loss: 6.148787021636963
2025-12-09 12:01:18.925 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.00029166206311583644 Training loss: 6.886045932769775
2025-12-09 12:01:19.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.000291632001138124 Training loss: 6.526935577392578
2025-12-09 12:01:19.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.0002916018866193978 Training loss: 6.916815757751465
2025-12-09 12:01:19.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.0002915717195708295 Training loss: 6.82345724105835
2025-12-09 12:01:19.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.00029154150000360995 Training loss: 6.552038669586182
2025-12-09 12:01:19.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.00029151122792894985 Training loss: 6.676163673400879
2025-12-09 12:01:19.729 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.000291480903358079 Training loss: 6.322205066680908
2025-12-09 12:01:19.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.00029145052630224696 Training loss: 6.571383953094482
2025-12-09 12:01:19.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.0002914200967727227 Training loss: 6.479857921600342
2025-12-09 12:01:20.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.00029138961478079455 Training loss: 6.495086193084717
2025-12-09 12:01:20.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.00029135908033777033 Training loss: 6.652370929718018
2025-12-09 12:01:20.397 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.00029132849345497755 Training loss: 6.543725967407227
2025-12-09 12:01:20.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.00029129785414376276 Training loss: 6.56861686706543
2025-12-09 12:01:20.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.00029126716241549224 Training loss: 6.753931999206543
2025-12-09 12:01:20.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.0002912364182815517 Training loss: 6.595376491546631
2025-12-09 12:01:20.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.00029120562175334624 Training loss: 6.505898475646973
2025-12-09 12:01:21.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.0002911747728423004 Training loss: 6.837916374206543
2025-12-09 12:01:21.190 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.00029114387155985814 Training loss: 6.638509273529053
2025-12-09 12:01:21.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.0002911129179174828 Training loss: 6.668562889099121
2025-12-09 12:01:21.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.00029108191192665734 Training loss: 6.300370216369629
2025-12-09 12:01:21.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.00029105085359888396 Training loss: 6.628427505493164
2025-12-09 12:01:21.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.00029101974294568425 Training loss: 6.7580766677856445
2025-12-09 12:01:21.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.0002909885799785993 Training loss: 6.897721290588379
2025-12-09 12:01:22.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.0002909573647091897 Training loss: 6.199451446533203
2025-12-09 12:01:22.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.00029092609714903523 Training loss: 5.520115852355957
2025-12-09 12:01:22.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.00029089477730973517 Training loss: 6.0059099197387695
2025-12-09 12:01:22.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.0002908634052029083 Training loss: 6.503190994262695
2025-12-09 12:01:22.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.0002908319808401925 Training loss: 6.72344446182251
2025-12-09 12:01:22.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.0002908005042332454 Training loss: 6.374513626098633
2025-12-09 12:01:22.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.00029076897539374375 Training loss: 6.233660697937012
2025-12-09 12:01:22.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.00029073739433338377 Training loss: 6.366774082183838
2025-12-09 12:01:23.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.000290705761063881 Training loss: 6.824740886688232
2025-12-09 12:01:23.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.00029067407559697046 Training loss: 6.360377788543701
2025-12-09 12:01:23.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.0002906423379444063 Training loss: 6.090755462646484
2025-12-09 12:01:23.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.00029061054811796243 Training loss: 5.938483715057373
2025-12-09 12:01:23.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.0002905787061294317 Training loss: 6.612460136413574
2025-12-09 12:01:23.739 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.00029054681199062657 Training loss: 6.465136528015137
2025-12-09 12:01:23.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.00029051486571337877 Training loss: 6.69902229309082
2025-12-09 12:01:24.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.00029048286730953924 Training loss: 6.477947235107422
2025-12-09 12:01:24.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.0002904508167909785 Training loss: 6.0830888748168945
2025-12-09 12:01:24.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.00029041871416958623 Training loss: 7.334750652313232
2025-12-09 12:01:24.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.00029038655945727153 Training loss: 6.911706924438477
2025-12-09 12:01:24.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.0002903543526659628 Training loss: 6.424605846405029
2025-12-09 12:01:24.683 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.00029032209380760765 Training loss: 6.860008239746094
2025-12-09 12:01:24.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.0002902897828941732 Training loss: 6.675594806671143
2025-12-09 12:01:24.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.0002902574199376457 Training loss: 6.521731376647949
2025-12-09 12:01:25.084 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.00029022500495003086 Training loss: 6.5252814292907715
2025-12-09 12:01:25.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.0002901925379433536 Training loss: 6.590757846832275
2025-12-09 12:01:25.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.0002901600189296581 Training loss: 6.5281805992126465
2025-12-09 12:01:25.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.000290127447921008 Training loss: 6.544780254364014
2025-12-09 12:01:25.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.00029009482492948607 Training loss: 6.504819869995117
2025-12-09 12:01:25.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.00029006214996719437 Training loss: 6.309567451477051
2025-12-09 12:01:25.879 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.0002900294230462543 Training loss: 7.658801078796387
2025-12-09 12:01:26.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.00028999664417880654 Training loss: 6.242201805114746
2025-12-09 12:01:26.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.000289963813377011 Training loss: 6.7849202156066895
2025-12-09 12:01:26.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.0002899309306530469 Training loss: 6.358148574829102
2025-12-09 12:01:26.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.0002898979960191127 Training loss: 6.5138325691223145
2025-12-09 12:01:26.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.000289865009487426 Training loss: 6.422249794006348
2025-12-09 12:01:26.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.00028983197107022396 Training loss: 6.185622215270996
2025-12-09 12:01:26.818 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.0002897988807797627 Training loss: 6.162075519561768
2025-12-09 12:01:26.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.00028976573862831757 Training loss: 6.689298152923584
2025-12-09 12:01:27.082 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.0002897325446281834 Training loss: 6.454525947570801
2025-12-09 12:01:27.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.0002896992987916741 Training loss: 6.3265700340271
2025-12-09 12:01:27.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.00028966600113112276 Training loss: 6.477938652038574
2025-12-09 12:01:27.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.00028963265165888187 Training loss: 6.591029167175293
2025-12-09 12:01:27.613 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 0.00028959925038732294 Training loss: 7.733788967132568
2025-12-09 12:01:27.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 0.00028956579732883684 Training loss: 6.176237106323242
2025-12-09 12:01:27.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 0.00028953229249583355 Training loss: 6.156928539276123
2025-12-09 12:01:28.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 0.0002894987359007424 Training loss: 6.974931716918945
2025-12-09 12:01:28.161 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 0.00028946512755601174 Training loss: 6.057158470153809
2025-12-09 12:01:28.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 0.0002894314674741092 Training loss: 6.154262065887451
2025-12-09 12:01:28.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 0.00028939775566752177 Training loss: 6.2636518478393555
2025-12-09 12:01:28.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 0.00028936399214875524 Training loss: 7.497303009033203
2025-12-09 12:01:28.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 0.000289330176930335 Training loss: 6.58074951171875
2025-12-09 12:01:28.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 0.0002892963100248053 Training loss: 6.721785068511963
2025-12-09 12:01:28.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 0.0002892623914447298 Training loss: 6.234133720397949
2025-12-09 12:01:29.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 0.00028922842120269115 Training loss: 6.179486274719238
