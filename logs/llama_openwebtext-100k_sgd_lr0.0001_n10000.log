2025-12-09 12:48:18.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 1.0000000000000002e-06 Training loss: 12.162163734436035
2025-12-09 12:48:18.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 2.0000000000000003e-06 Training loss: 12.169829368591309
2025-12-09 12:48:19.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 3e-06 Training loss: 12.117663383483887
2025-12-09 12:48:19.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 4.000000000000001e-06 Training loss: 12.185525894165039
2025-12-09 12:48:19.755 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 5e-06 Training loss: 12.1953763961792
2025-12-09 12:48:20.126 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 6e-06 Training loss: 12.197092056274414
2025-12-09 12:48:20.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 7.000000000000001e-06 Training loss: 12.210591316223145
2025-12-09 12:48:20.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 8.000000000000001e-06 Training loss: 12.167391777038574
2025-12-09 12:48:21.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 9e-06 Training loss: 12.128413200378418
2025-12-09 12:48:21.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 1e-05 Training loss: 12.162223815917969
2025-12-09 12:48:21.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 1.1000000000000001e-05 Training loss: 12.205605506896973
2025-12-09 12:48:22.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 1.2e-05 Training loss: 12.210490226745605
2025-12-09 12:48:22.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 1.3000000000000001e-05 Training loss: 12.200961112976074
2025-12-09 12:48:23.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 1.4000000000000001e-05 Training loss: 12.34389591217041
2025-12-09 12:48:23.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 1.5e-05 Training loss: 12.184263229370117
2025-12-09 12:48:23.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 1.6000000000000003e-05 Training loss: 12.220465660095215
2025-12-09 12:48:24.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 1.7000000000000003e-05 Training loss: 12.151910781860352
2025-12-09 12:48:24.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 1.8e-05 Training loss: 12.155423164367676
2025-12-09 12:48:24.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 1.9e-05 Training loss: 12.157703399658203
2025-12-09 12:48:25.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 2e-05 Training loss: 12.123184204101562
2025-12-09 12:48:25.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 2.1e-05 Training loss: 12.190208435058594
2025-12-09 12:48:26.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 2.2000000000000003e-05 Training loss: 12.191192626953125
2025-12-09 12:48:26.438 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 2.3000000000000003e-05 Training loss: 12.175613403320312
2025-12-09 12:48:26.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 2.4e-05 Training loss: 12.164671897888184
2025-12-09 12:48:27.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 2.5e-05 Training loss: 12.17802906036377
2025-12-09 12:48:27.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 2.6000000000000002e-05 Training loss: 12.211603164672852
2025-12-09 12:48:27.926 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 2.7000000000000002e-05 Training loss: 12.106077194213867
2025-12-09 12:48:28.297 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 2.8000000000000003e-05 Training loss: 12.187079429626465
2025-12-09 12:48:28.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 2.9e-05 Training loss: 12.170389175415039
2025-12-09 12:48:29.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 3e-05 Training loss: 12.175522804260254
2025-12-09 12:48:29.416 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 3.1e-05 Training loss: 12.136961936950684
2025-12-09 12:48:29.788 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 3.2000000000000005e-05 Training loss: 12.165750503540039
2025-12-09 12:48:30.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 3.3e-05 Training loss: 12.166057586669922
2025-12-09 12:48:30.532 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 3.4000000000000007e-05 Training loss: 12.176685333251953
2025-12-09 12:48:30.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 3.5e-05 Training loss: 12.136297225952148
2025-12-09 12:48:31.278 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 3.6e-05 Training loss: 12.123641014099121
2025-12-09 12:48:31.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 3.7e-05 Training loss: 12.153851509094238
2025-12-09 12:48:32.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 3.8e-05 Training loss: 12.186870574951172
2025-12-09 12:48:32.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 3.9000000000000006e-05 Training loss: 12.195305824279785
2025-12-09 12:48:32.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 4e-05 Training loss: 12.132088661193848
2025-12-09 12:48:33.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 4.1e-05 Training loss: 12.129196166992188
2025-12-09 12:48:33.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 4.2e-05 Training loss: 12.16373348236084
2025-12-09 12:48:33.884 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 4.3e-05 Training loss: 12.172629356384277
2025-12-09 12:48:34.256 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 4.4000000000000006e-05 Training loss: 12.117392539978027
2025-12-09 12:48:34.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 4.5e-05 Training loss: 12.110901832580566
2025-12-09 12:48:35.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 4.600000000000001e-05 Training loss: 12.122503280639648
2025-12-09 12:48:35.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 4.7e-05 Training loss: 12.200176239013672
2025-12-09 12:48:35.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 4.8e-05 Training loss: 12.120745658874512
2025-12-09 12:48:36.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 4.9e-05 Training loss: 12.109186172485352
2025-12-09 12:48:36.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 5e-05 Training loss: 12.117300033569336
2025-12-09 12:48:36.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 5.1000000000000006e-05 Training loss: 12.087366104125977
2025-12-09 12:48:37.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 5.2000000000000004e-05 Training loss: 12.124190330505371
2025-12-09 12:48:37.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 5.300000000000001e-05 Training loss: 12.117071151733398
2025-12-09 12:48:37.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 5.4000000000000005e-05 Training loss: 12.043821334838867
2025-12-09 12:48:38.355 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 5.500000000000001e-05 Training loss: 12.091883659362793
2025-12-09 12:48:38.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 5.6000000000000006e-05 Training loss: 12.135543823242188
2025-12-09 12:48:39.101 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 5.6999999999999996e-05 Training loss: 12.097591400146484
2025-12-09 12:48:39.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 5.8e-05 Training loss: 12.065223693847656
2025-12-09 12:48:39.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 5.9e-05 Training loss: 12.068614959716797
2025-12-09 12:48:40.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 6e-05 Training loss: 12.076142311096191
2025-12-09 12:48:40.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 6.1e-05 Training loss: 12.08559513092041
2025-12-09 12:48:40.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 6.2e-05 Training loss: 12.07158088684082
2025-12-09 12:48:41.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 6.3e-05 Training loss: 12.044792175292969
2025-12-09 12:48:41.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 6.400000000000001e-05 Training loss: 12.036609649658203
2025-12-09 12:48:42.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 6.500000000000001e-05 Training loss: 12.049824714660645
2025-12-09 12:48:42.457 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 6.6e-05 Training loss: 12.030176162719727
2025-12-09 12:48:42.830 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 6.7e-05 Training loss: 12.01749324798584
2025-12-09 12:48:43.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 6.800000000000001e-05 Training loss: 12.025797843933105
2025-12-09 12:48:43.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 6.9e-05 Training loss: 12.055620193481445
2025-12-09 12:48:43.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 7e-05 Training loss: 11.999513626098633
2025-12-09 12:48:44.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 7.1e-05 Training loss: 12.038586616516113
2025-12-09 12:48:44.693 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 7.2e-05 Training loss: 12.065753936767578
2025-12-09 12:48:45.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 7.3e-05 Training loss: 12.028143882751465
2025-12-09 12:48:45.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 7.4e-05 Training loss: 11.998446464538574
2025-12-09 12:48:45.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 7.500000000000001e-05 Training loss: 12.04477310180664
2025-12-09 12:48:46.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 7.6e-05 Training loss: 12.027569770812988
2025-12-09 12:48:46.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 7.7e-05 Training loss: 12.03686237335205
2025-12-09 12:48:46.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 7.800000000000001e-05 Training loss: 11.943374633789062
2025-12-09 12:48:47.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 7.900000000000001e-05 Training loss: 11.944486618041992
2025-12-09 12:48:47.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 8e-05 Training loss: 12.011140823364258
2025-12-09 12:48:48.051 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 8.1e-05 Training loss: 11.990104675292969
2025-12-09 12:48:48.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 8.2e-05 Training loss: 12.073492050170898
2025-12-09 12:48:48.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 8.3e-05 Training loss: 11.925308227539062
2025-12-09 12:48:49.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 8.4e-05 Training loss: 12.015758514404297
2025-12-09 12:48:49.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 8.5e-05 Training loss: 11.947731971740723
2025-12-09 12:48:49.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 8.6e-05 Training loss: 11.966586112976074
2025-12-09 12:48:50.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 8.7e-05 Training loss: 11.907608032226562
2025-12-09 12:48:50.661 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 8.800000000000001e-05 Training loss: 12.017390251159668
2025-12-09 12:48:51.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 8.900000000000001e-05 Training loss: 11.975567817687988
2025-12-09 12:48:51.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 9e-05 Training loss: 11.971487045288086
2025-12-09 12:48:51.785 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 9.1e-05 Training loss: 11.99289321899414
2025-12-09 12:48:52.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 9.200000000000001e-05 Training loss: 11.943201065063477
2025-12-09 12:48:52.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 9.300000000000001e-05 Training loss: 11.95628547668457
2025-12-09 12:48:52.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 9.4e-05 Training loss: 11.913899421691895
2025-12-09 12:48:53.275 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 9.5e-05 Training loss: 11.979228973388672
2025-12-09 12:48:53.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 9.6e-05 Training loss: 11.806804656982422
2025-12-09 12:48:54.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 9.7e-05 Training loss: 12.013786315917969
2025-12-09 12:48:54.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 9.8e-05 Training loss: 11.846590995788574
2025-12-09 12:48:54.765 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 9.900000000000001e-05 Training loss: 11.79616641998291
2025-12-09 12:48:55.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.0001 Training loss: 11.924983024597168
2025-12-09 12:48:55.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 9.999999029798809e-05 Training loss: 11.785237312316895
2025-12-09 12:48:55.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 9.999996119195611e-05 Training loss: 11.793326377868652
2025-12-09 12:48:56.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 9.999991268191536e-05 Training loss: 11.78632926940918
2025-12-09 12:48:56.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 9.999984476788465e-05 Training loss: 11.872175216674805
2025-12-09 12:48:57.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 9.999975744989037e-05 Training loss: 11.68947982788086
2025-12-09 12:48:57.375 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 9.999965072796636e-05 Training loss: 11.742691993713379
2025-12-09 12:48:57.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 9.999952460215408e-05 Training loss: 11.727685928344727
2025-12-09 12:48:58.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 9.999937907250246e-05 Training loss: 11.890458106994629
2025-12-09 12:48:58.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 9.999921413906798e-05 Training loss: 11.798478126525879
2025-12-09 12:48:58.867 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 9.999902980191464e-05 Training loss: 11.844319343566895
2025-12-09 12:48:59.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 9.999882606111399e-05 Training loss: 11.754762649536133
2025-12-09 12:48:59.612 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 9.999860291674508e-05 Training loss: 11.770105361938477
2025-12-09 12:48:59.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 9.999836036889453e-05 Training loss: 11.803543090820312
2025-12-09 12:49:00.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 9.999809841765644e-05 Training loss: 11.60687255859375
2025-12-09 12:49:00.736 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 9.999781706313251e-05 Training loss: 11.7212553024292
2025-12-09 12:49:01.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 9.999751630543188e-05 Training loss: 11.663324356079102
2025-12-09 12:49:01.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 9.99971961446713e-05 Training loss: 11.760815620422363
2025-12-09 12:49:01.855 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 9.999685658097502e-05 Training loss: 11.27832317352295
2025-12-09 12:49:02.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 9.999649761447478e-05 Training loss: 11.837480545043945
2025-12-09 12:49:02.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 9.999611924530994e-05 Training loss: 11.699317932128906
2025-12-09 12:49:02.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 9.999572147362731e-05 Training loss: 11.49933910369873
2025-12-09 12:49:03.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 9.999530429958124e-05 Training loss: 11.674701690673828
2025-12-09 12:49:03.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 9.999486772333366e-05 Training loss: 11.405783653259277
2025-12-09 12:49:04.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 9.999441174505399e-05 Training loss: 11.496513366699219
2025-12-09 12:49:04.466 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 9.999393636491918e-05 Training loss: 11.54464340209961
2025-12-09 12:49:04.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 9.99934415831137e-05 Training loss: 11.570005416870117
2025-12-09 12:49:05.216 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 9.99929273998296e-05 Training loss: 11.548973083496094
2025-12-09 12:49:05.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 9.99923938152664e-05 Training loss: 11.491233825683594
2025-12-09 12:49:05.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 9.999184082963118e-05 Training loss: 11.5483980178833
2025-12-09 12:49:06.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 9.999126844313853e-05 Training loss: 11.461623191833496
2025-12-09 12:49:06.706 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 9.999067665601061e-05 Training loss: 11.368895530700684
2025-12-09 12:49:07.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 9.999006546847707e-05 Training loss: 11.5049467086792
2025-12-09 12:49:07.453 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 9.998943488077508e-05 Training loss: 11.328349113464355
2025-12-09 12:49:07.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 9.998878489314938e-05 Training loss: 11.217138290405273
2025-12-09 12:49:08.197 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 9.99881155058522e-05 Training loss: 11.523008346557617
2025-12-09 12:49:08.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 9.998742671914335e-05 Training loss: 11.212780952453613
2025-12-09 12:49:08.942 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 9.99867185332901e-05 Training loss: 11.339944839477539
2025-12-09 12:49:09.318 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 9.998599094856732e-05 Training loss: 11.431185722351074
2025-12-09 12:49:09.690 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 9.99852439652573e-05 Training loss: 11.356016159057617
2025-12-09 12:49:10.065 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 9.998447758365002e-05 Training loss: 11.381332397460938
2025-12-09 12:49:10.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 9.998369180404283e-05 Training loss: 11.1334867477417
2025-12-09 12:49:10.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 9.99828866267407e-05 Training loss: 10.872836112976074
2025-12-09 12:49:11.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 9.998206205205611e-05 Training loss: 11.176006317138672
2025-12-09 12:49:11.555 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 9.998121808030906e-05 Training loss: 10.914996147155762
2025-12-09 12:49:11.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 9.998035471182708e-05 Training loss: 11.098191261291504
2025-12-09 12:49:12.302 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 9.997947194694519e-05 Training loss: 11.32523250579834
2025-12-09 12:49:12.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 9.997856978600604e-05 Training loss: 11.141162872314453
2025-12-09 12:49:13.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 9.997764822935967e-05 Training loss: 11.160271644592285
2025-12-09 12:49:13.420 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 9.997670727736378e-05 Training loss: 11.056584358215332
2025-12-09 12:49:13.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 9.99757469303835e-05 Training loss: 11.218456268310547
2025-12-09 12:49:14.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 9.997476718879153e-05 Training loss: 10.86037540435791
2025-12-09 12:49:14.542 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 9.99737680529681e-05 Training loss: 10.938823699951172
2025-12-09 12:49:14.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 9.997274952330094e-05 Training loss: 11.18699836730957
2025-12-09 12:49:15.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 9.997171160018531e-05 Training loss: 11.072670936584473
2025-12-09 12:49:15.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 9.997065428402403e-05 Training loss: 10.96828556060791
2025-12-09 12:49:16.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 9.996957757522742e-05 Training loss: 10.784357070922852
2025-12-09 12:49:16.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 9.996848147421334e-05 Training loss: 10.850643157958984
2025-12-09 12:49:16.777 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 9.996736598140714e-05 Training loss: 11.127063751220703
2025-12-09 12:49:17.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 9.996623109724174e-05 Training loss: 11.332084655761719
2025-12-09 12:49:17.523 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 9.996507682215754e-05 Training loss: 10.828466415405273
2025-12-09 12:49:17.894 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 9.996390315660253e-05 Training loss: 10.884355545043945
2025-12-09 12:49:18.271 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 9.996271010103216e-05 Training loss: 10.752790451049805
2025-12-09 12:49:18.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 9.996149765590946e-05 Training loss: 10.669111251831055
2025-12-09 12:49:19.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 9.99602658217049e-05 Training loss: 10.964224815368652
2025-12-09 12:49:19.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 9.995901459889658e-05 Training loss: 10.811060905456543
2025-12-09 12:49:19.762 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 9.995774398797007e-05 Training loss: 10.82894229888916
2025-12-09 12:49:20.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 9.995645398941846e-05 Training loss: 10.648233413696289
2025-12-09 12:49:20.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 9.995514460374238e-05 Training loss: 11.038290977478027
2025-12-09 12:49:20.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 9.995381583144996e-05 Training loss: 10.721672058105469
2025-12-09 12:49:21.251 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 9.995246767305688e-05 Training loss: 11.01842975616455
2025-12-09 12:49:21.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 9.995110012908634e-05 Training loss: 10.874443054199219
2025-12-09 12:49:21.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 9.994971320006905e-05 Training loss: 10.608304977416992
2025-12-09 12:49:22.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 9.994830688654326e-05 Training loss: 10.775552749633789
2025-12-09 12:49:22.745 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 9.994688118905472e-05 Training loss: 10.617237091064453
2025-12-09 12:49:23.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 9.994543610815671e-05 Training loss: 10.585933685302734
2025-12-09 12:49:23.489 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 9.994397164441007e-05 Training loss: 10.836801528930664
2025-12-09 12:49:23.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 9.994248779838311e-05 Training loss: 10.343914985656738
2025-12-09 12:49:24.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 9.994098457065166e-05 Training loss: 10.733258247375488
2025-12-09 12:49:24.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 9.993946196179913e-05 Training loss: 10.963654518127441
2025-12-09 12:49:24.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 9.993791997241639e-05 Training loss: 11.047673225402832
2025-12-09 12:49:25.350 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 9.993635860310187e-05 Training loss: 10.39225959777832
2025-12-09 12:49:25.722 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 9.99347778544615e-05 Training loss: 10.722264289855957
2025-12-09 12:49:26.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 9.993317772710874e-05 Training loss: 10.512035369873047
2025-12-09 12:49:26.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 9.993155822166457e-05 Training loss: 10.51222038269043
2025-12-09 12:49:26.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 9.992991933875748e-05 Training loss: 10.749431610107422
2025-12-09 12:49:27.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 9.99282610790235e-05 Training loss: 10.561431884765625
2025-12-09 12:49:27.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 9.992658344310614e-05 Training loss: 10.424931526184082
2025-12-09 12:49:27.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 9.992488643165651e-05 Training loss: 10.634074211120605
2025-12-09 12:49:28.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 9.992317004533313e-05 Training loss: 10.624419212341309
2025-12-09 12:49:28.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 9.992143428480214e-05 Training loss: 10.497724533081055
2025-12-09 12:49:29.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 9.991967915073714e-05 Training loss: 10.415751457214355
2025-12-09 12:49:29.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 9.991790464381926e-05 Training loss: 10.223017692565918
2025-12-09 12:49:29.823 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 9.991611076473714e-05 Training loss: 10.524879455566406
2025-12-09 12:49:30.195 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 9.991429751418697e-05 Training loss: 10.331722259521484
2025-12-09 12:49:30.565 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 9.991246489287245e-05 Training loss: 10.394624710083008
2025-12-09 12:49:30.939 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 9.991061290150475e-05 Training loss: 11.004168510437012
2025-12-09 12:49:31.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 9.990874154080259e-05 Training loss: 10.250880241394043
2025-12-09 12:49:31.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 9.990685081149222e-05 Training loss: 10.408140182495117
2025-12-09 12:49:32.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 9.990494071430742e-05 Training loss: 10.846076011657715
2025-12-09 12:49:32.432 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 9.990301124998945e-05 Training loss: 10.147920608520508
2025-12-09 12:49:32.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 9.990106241928706e-05 Training loss: 10.473099708557129
2025-12-09 12:49:33.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 9.989909422295659e-05 Training loss: 10.364727020263672
2025-12-09 12:49:33.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 9.989710666176186e-05 Training loss: 10.595335006713867
2025-12-09 12:49:33.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 9.989509973647417e-05 Training loss: 10.423338890075684
2025-12-09 12:49:34.293 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 9.989307344787242e-05 Training loss: 10.27683162689209
2025-12-09 12:49:34.666 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 9.989102779674293e-05 Training loss: 10.577385902404785
2025-12-09 12:49:35.040 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 9.98889627838796e-05 Training loss: 10.5608491897583
2025-12-09 12:49:35.410 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 9.98868784100838e-05 Training loss: 10.508788108825684
2025-12-09 12:49:35.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 9.988477467616447e-05 Training loss: 10.329981803894043
2025-12-09 12:49:36.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 9.988265158293799e-05 Training loss: 10.477877616882324
2025-12-09 12:49:36.530 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 9.98805091312283e-05 Training loss: 10.44042682647705
2025-12-09 12:49:36.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 9.987834732186687e-05 Training loss: 10.770843505859375
2025-12-09 12:49:37.277 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 9.987616615569263e-05 Training loss: 10.451589584350586
2025-12-09 12:49:37.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 9.987396563355205e-05 Training loss: 10.197437286376953
2025-12-09 12:49:38.023 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 9.987174575629911e-05 Training loss: 10.880026817321777
2025-12-09 12:49:38.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 9.986950652479532e-05 Training loss: 10.350839614868164
2025-12-09 12:49:38.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 9.986724793990966e-05 Training loss: 10.376651763916016
2025-12-09 12:49:39.140 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 9.986497000251866e-05 Training loss: 10.097819328308105
2025-12-09 12:49:39.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 9.986267271350633e-05 Training loss: 10.10232162475586
2025-12-09 12:49:39.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 9.98603560737642e-05 Training loss: 10.252894401550293
2025-12-09 12:49:40.258 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 9.985802008419131e-05 Training loss: 10.191271781921387
2025-12-09 12:49:40.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 9.985566474569424e-05 Training loss: 10.397116661071777
2025-12-09 12:49:41.006 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 9.985329005918702e-05 Training loss: 10.26093578338623
2025-12-09 12:49:41.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 9.985089602559125e-05 Training loss: 10.137243270874023
2025-12-09 12:49:41.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 9.984848264583597e-05 Training loss: 10.2694730758667
2025-12-09 12:49:42.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 9.98460499208578e-05 Training loss: 10.355692863464355
2025-12-09 12:49:42.495 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 9.98435978516008e-05 Training loss: 10.391196250915527
2025-12-09 12:49:42.869 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 9.98411264390166e-05 Training loss: 10.209521293640137
2025-12-09 12:49:43.241 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 9.983863568406428e-05 Training loss: 10.08398151397705
2025-12-09 12:49:43.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 9.983612558771049e-05 Training loss: 9.888911247253418
2025-12-09 12:49:43.986 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 9.983359615092931e-05 Training loss: 10.456385612487793
2025-12-09 12:49:44.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 9.983104737470239e-05 Training loss: 10.258344650268555
2025-12-09 12:49:44.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 9.982847926001886e-05 Training loss: 10.110895156860352
2025-12-09 12:49:45.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 9.982589180787534e-05 Training loss: 10.13536262512207
2025-12-09 12:49:45.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 9.982328501927599e-05 Training loss: 10.067292213439941
2025-12-09 12:49:45.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 9.982065889523242e-05 Training loss: 10.046698570251465
2025-12-09 12:49:46.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 9.98180134367638e-05 Training loss: 10.147855758666992
2025-12-09 12:49:46.597 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 9.981534864489679e-05 Training loss: 10.08233642578125
2025-12-09 12:49:46.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 9.981266452066553e-05 Training loss: 10.205440521240234
2025-12-09 12:49:47.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 9.98099610651117e-05 Training loss: 10.07536792755127
2025-12-09 12:49:47.716 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 9.980723827928441e-05 Training loss: 10.184678077697754
2025-12-09 12:49:48.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 9.980449616424037e-05 Training loss: 10.2174711227417
2025-12-09 12:49:48.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 9.98017347210437e-05 Training loss: 10.157844543457031
2025-12-09 12:49:48.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 9.979895395076609e-05 Training loss: 10.139946937561035
2025-12-09 12:49:49.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 9.979615385448669e-05 Training loss: 10.261917114257812
2025-12-09 12:49:49.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 9.979333443329217e-05 Training loss: 10.498883247375488
2025-12-09 12:49:49.953 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 9.97904956882767e-05 Training loss: 10.019021034240723
2025-12-09 12:49:50.325 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 9.978763762054194e-05 Training loss: 10.060608863830566
2025-12-09 12:49:50.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 9.978476023119701e-05 Training loss: 10.243354797363281
2025-12-09 12:49:51.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 9.978186352135861e-05 Training loss: 10.408341407775879
2025-12-09 12:49:51.444 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 9.977894749215089e-05 Training loss: 10.457671165466309
2025-12-09 12:49:51.816 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 9.97760121447055e-05 Training loss: 9.964212417602539
2025-12-09 12:49:52.188 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 9.977305748016159e-05 Training loss: 9.940801620483398
2025-12-09 12:49:52.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 9.977008349966582e-05 Training loss: 10.297362327575684
2025-12-09 12:49:52.934 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 9.976709020437229e-05 Training loss: 10.096936225891113
2025-12-09 12:49:53.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 9.97640775954427e-05 Training loss: 10.061444282531738
2025-12-09 12:49:53.677 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 9.976104567404617e-05 Training loss: 10.536656379699707
2025-12-09 12:49:54.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 9.97579944413593e-05 Training loss: 10.07320785522461
2025-12-09 12:49:54.426 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 9.975492389856622e-05 Training loss: 10.160550117492676
2025-12-09 12:49:54.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 9.975183404685856e-05 Training loss: 9.849785804748535
2025-12-09 12:49:55.172 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 9.974872488743543e-05 Training loss: 10.349806785583496
2025-12-09 12:49:55.544 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 9.974559642150345e-05 Training loss: 10.366107940673828
2025-12-09 12:49:55.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 9.974244865027669e-05 Training loss: 10.031368255615234
2025-12-09 12:49:56.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 9.973928157497674e-05 Training loss: 10.26887321472168
2025-12-09 12:49:56.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 9.973609519683268e-05 Training loss: 10.074053764343262
2025-12-09 12:49:57.033 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 9.973288951708111e-05 Training loss: 10.027859687805176
2025-12-09 12:49:57.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 9.972966453696608e-05 Training loss: 9.995098114013672
2025-12-09 12:49:57.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 9.972642025773912e-05 Training loss: 10.173632621765137
2025-12-09 12:49:58.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 9.972315668065929e-05 Training loss: 10.178361892700195
2025-12-09 12:49:58.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 9.97198738069931e-05 Training loss: 10.266975402832031
2025-12-09 12:49:58.902 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 9.971657163801458e-05 Training loss: 10.065520286560059
2025-12-09 12:49:59.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 9.971325017500526e-05 Training loss: 9.983501434326172
2025-12-09 12:49:59.646 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 9.970990941925411e-05 Training loss: 9.870549201965332
2025-12-09 12:50:00.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 9.970654937205762e-05 Training loss: 10.128117561340332
2025-12-09 12:50:00.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 9.970317003471976e-05 Training loss: 9.85637092590332
2025-12-09 12:50:00.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 9.969977140855198e-05 Training loss: 9.887116432189941
2025-12-09 12:50:01.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 9.969635349487321e-05 Training loss: 9.901044845581055
2025-12-09 12:50:01.509 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 9.969291629500991e-05 Training loss: 9.95906925201416
2025-12-09 12:50:01.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 9.968945981029596e-05 Training loss: 10.438660621643066
2025-12-09 12:50:02.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 9.968598404207275e-05 Training loss: 10.181575775146484
2025-12-09 12:50:02.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 9.96824889916892e-05 Training loss: 10.395589828491211
2025-12-09 12:50:03.004 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 9.96789746605016e-05 Training loss: 9.981450080871582
2025-12-09 12:50:03.376 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 9.967544104987387e-05 Training loss: 9.855002403259277
2025-12-09 12:50:03.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 9.967188816117727e-05 Training loss: 10.045783042907715
2025-12-09 12:50:04.120 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 9.966831599579066e-05 Training loss: 10.10616397857666
2025-12-09 12:50:04.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 9.96647245551003e-05 Training loss: 9.820018768310547
2025-12-09 12:50:04.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 9.966111384049997e-05 Training loss: 9.814043045043945
2025-12-09 12:50:05.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 9.965748385339089e-05 Training loss: 10.015721321105957
2025-12-09 12:50:05.608 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 9.96538345951818e-05 Training loss: 10.225654602050781
2025-12-09 12:50:05.981 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 9.965016606728894e-05 Training loss: 9.828672409057617
2025-12-09 12:50:06.354 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 9.964647827113595e-05 Training loss: 10.007301330566406
2025-12-09 12:50:06.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 9.964277120815401e-05 Training loss: 9.890606880187988
2025-12-09 12:50:07.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 9.963904487978177e-05 Training loss: 10.057378768920898
2025-12-09 12:50:07.476 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 9.963529928746534e-05 Training loss: 9.981829643249512
2025-12-09 12:50:07.847 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 9.963153443265828e-05 Training loss: 9.781253814697266
2025-12-09 12:50:08.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 9.96277503168217e-05 Training loss: 10.182222366333008
2025-12-09 12:50:08.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 9.96239469414241e-05 Training loss: 9.852587699890137
2025-12-09 12:50:08.964 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 9.962012430794153e-05 Training loss: 9.94367790222168
2025-12-09 12:50:09.337 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 9.961628241785747e-05 Training loss: 9.65950870513916
2025-12-09 12:50:09.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 9.961242127266288e-05 Training loss: 9.958202362060547
2025-12-09 12:50:10.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 9.960854087385619e-05 Training loss: 9.951903343200684
2025-12-09 12:50:10.454 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 9.96046412229433e-05 Training loss: 10.109512329101562
2025-12-09 12:50:10.825 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 9.960072232143762e-05 Training loss: 9.813610076904297
2025-12-09 12:50:11.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 9.959678417085997e-05 Training loss: 9.827508926391602
2025-12-09 12:50:11.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 9.95928267727387e-05 Training loss: 9.97535228729248
2025-12-09 12:50:11.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 9.958885012860954e-05 Training loss: 9.825493812561035
2025-12-09 12:50:12.320 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 9.958485424001583e-05 Training loss: 10.40023136138916
2025-12-09 12:50:12.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 9.958083910850821e-05 Training loss: 9.683938980102539
2025-12-09 12:50:13.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 9.957680473564495e-05 Training loss: 9.874008178710938
2025-12-09 12:50:13.435 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 9.957275112299165e-05 Training loss: 9.771635055541992
2025-12-09 12:50:13.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 9.956867827212148e-05 Training loss: 9.915602684020996
2025-12-09 12:50:14.180 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 9.956458618461502e-05 Training loss: 9.912557601928711
2025-12-09 12:50:14.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 9.956047486206032e-05 Training loss: 10.074220657348633
2025-12-09 12:50:14.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 9.955634430605291e-05 Training loss: 9.921175956726074
2025-12-09 12:50:15.299 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 9.955219451819579e-05 Training loss: 9.751479148864746
2025-12-09 12:50:15.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 9.954802550009942e-05 Training loss: 9.960739135742188
2025-12-09 12:50:16.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 9.954383725338167e-05 Training loss: 10.669637680053711
2025-12-09 12:50:16.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 9.953962977966795e-05 Training loss: 9.982176780700684
2025-12-09 12:50:16.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 9.953540308059111e-05 Training loss: 9.943882942199707
2025-12-09 12:50:17.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 9.953115715779141e-05 Training loss: 9.946135520935059
2025-12-09 12:50:17.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 9.952689201291664e-05 Training loss: 9.883417129516602
2025-12-09 12:50:17.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 9.9522607647622e-05 Training loss: 9.901617050170898
2025-12-09 12:50:18.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 9.951830406357019e-05 Training loss: 9.832561492919922
2025-12-09 12:50:18.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 9.951398126243134e-05 Training loss: 9.746139526367188
2025-12-09 12:50:19.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 9.950963924588303e-05 Training loss: 9.905734062194824
2025-12-09 12:50:19.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 9.950527801561033e-05 Training loss: 9.757115364074707
2025-12-09 12:50:19.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 9.950089757330574e-05 Training loss: 9.830517768859863
2025-12-09 12:50:20.146 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 9.949649792066922e-05 Training loss: 9.771347045898438
2025-12-09 12:50:20.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 9.94920790594082e-05 Training loss: 9.741057395935059
2025-12-09 12:50:20.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 9.948764099123755e-05 Training loss: 9.838644027709961
2025-12-09 12:50:21.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 9.94831837178796e-05 Training loss: 10.045063018798828
2025-12-09 12:50:21.641 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 9.947870724106412e-05 Training loss: 9.756109237670898
2025-12-09 12:50:22.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 9.947421156252836e-05 Training loss: 9.391104698181152
2025-12-09 12:50:22.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 9.946969668401697e-05 Training loss: 9.616451263427734
2025-12-09 12:50:22.756 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 9.946516260728214e-05 Training loss: 9.990531921386719
2025-12-09 12:50:23.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 9.946060933408341e-05 Training loss: 10.263059616088867
2025-12-09 12:50:23.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 9.945603686618785e-05 Training loss: 9.789401054382324
2025-12-09 12:50:23.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 9.945144520536992e-05 Training loss: 9.98781967163086
2025-12-09 12:50:24.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 9.944683435341155e-05 Training loss: 9.780316352844238
2025-12-09 12:50:24.619 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 9.944220431210216e-05 Training loss: 9.869556427001953
2025-12-09 12:50:24.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 9.943755508323855e-05 Training loss: 9.678277015686035
2025-12-09 12:50:25.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 9.943288666862498e-05 Training loss: 10.055224418640137
2025-12-09 12:50:25.740 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 9.942819907007321e-05 Training loss: 9.719404220581055
2025-12-09 12:50:26.112 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 9.942349228940237e-05 Training loss: 9.562967300415039
2025-12-09 12:50:26.483 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 9.941876632843909e-05 Training loss: 9.707161903381348
2025-12-09 12:50:26.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 9.941402118901744e-05 Training loss: 9.876967430114746
2025-12-09 12:50:27.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 9.940925687297886e-05 Training loss: 10.284820556640625
2025-12-09 12:50:27.599 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 9.940447338217234e-05 Training loss: 9.884064674377441
2025-12-09 12:50:27.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 9.939967071845423e-05 Training loss: 9.968877792358398
2025-12-09 12:50:28.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 9.939484888368838e-05 Training loss: 9.717201232910156
2025-12-09 12:50:28.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 9.939000787974602e-05 Training loss: 9.807687759399414
2025-12-09 12:50:29.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 9.938514770850587e-05 Training loss: 9.908910751342773
2025-12-09 12:50:29.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 9.938026837185404e-05 Training loss: 10.633213996887207
2025-12-09 12:50:29.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 9.937536987168413e-05 Training loss: 9.916866302490234
2025-12-09 12:50:30.209 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 9.937045220989715e-05 Training loss: 9.690810203552246
2025-12-09 12:50:30.582 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 9.936551538840155e-05 Training loss: 9.83810806274414
2025-12-09 12:50:30.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 9.93605594091132e-05 Training loss: 9.649495124816895
2025-12-09 12:50:31.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 9.935558427395542e-05 Training loss: 9.768267631530762
2025-12-09 12:50:31.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 9.935058998485897e-05 Training loss: 9.540467262268066
2025-12-09 12:50:32.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 9.934557654376205e-05 Training loss: 9.947766304016113
2025-12-09 12:50:32.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 9.934054395261026e-05 Training loss: 9.867445945739746
2025-12-09 12:50:32.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 9.933549221335664e-05 Training loss: 9.817309379577637
2025-12-09 12:50:33.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 9.933042132796171e-05 Training loss: 9.735108375549316
2025-12-09 12:50:33.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 9.932533129839334e-05 Training loss: 10.131185531616211
2025-12-09 12:50:33.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 9.932022212662691e-05 Training loss: 10.114134788513184
2025-12-09 12:50:34.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 9.931509381464515e-05 Training loss: 9.668691635131836
2025-12-09 12:50:34.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 9.930994636443829e-05 Training loss: 9.586180686950684
2025-12-09 12:50:35.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 9.930477977800392e-05 Training loss: 9.737403869628906
2025-12-09 12:50:35.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 9.929959405734712e-05 Training loss: 9.946925163269043
2025-12-09 12:50:35.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 9.929438920448037e-05 Training loss: 9.7499418258667
2025-12-09 12:50:36.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 9.928916522142357e-05 Training loss: 9.71851921081543
2025-12-09 12:50:36.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 9.928392211020401e-05 Training loss: 9.903003692626953
2025-12-09 12:50:36.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 9.927865987285649e-05 Training loss: 9.69002628326416
2025-12-09 12:50:37.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 9.927337851142314e-05 Training loss: 9.58450698852539
2025-12-09 12:50:37.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 9.926807802795359e-05 Training loss: 9.940970420837402
2025-12-09 12:50:38.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 9.926275842450483e-05 Training loss: 9.586408615112305
2025-12-09 12:50:38.403 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 9.925741970314129e-05 Training loss: 9.682319641113281
2025-12-09 12:50:38.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 9.925206186593484e-05 Training loss: 9.923629760742188
2025-12-09 12:50:39.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 9.924668491496474e-05 Training loss: 9.672581672668457
2025-12-09 12:50:39.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 9.92412888523177e-05 Training loss: 9.912446022033691
2025-12-09 12:50:39.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 9.923587368008778e-05 Training loss: 10.494706153869629
2025-12-09 12:50:40.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 9.923043940037657e-05 Training loss: 9.816356658935547
2025-12-09 12:50:40.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 9.922498601529296e-05 Training loss: 9.781228065490723
2025-12-09 12:50:41.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 9.92195135269533e-05 Training loss: 9.728202819824219
2025-12-09 12:50:41.386 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 9.921402193748139e-05 Training loss: 9.801891326904297
2025-12-09 12:50:41.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 9.920851124900837e-05 Training loss: 9.888652801513672
2025-12-09 12:50:42.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 9.920298146367286e-05 Training loss: 9.836540222167969
2025-12-09 12:50:42.505 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 9.919743258362085e-05 Training loss: 9.897258758544922
2025-12-09 12:50:42.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 9.919186461100576e-05 Training loss: 10.09568977355957
2025-12-09 12:50:43.255 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 9.91862775479884e-05 Training loss: 9.856160163879395
2025-12-09 12:50:43.626 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 9.9180671396737e-05 Training loss: 9.856157302856445
2025-12-09 12:50:44.000 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 9.91750461594272e-05 Training loss: 9.666570663452148
2025-12-09 12:50:44.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 9.916940183824206e-05 Training loss: 9.672353744506836
2025-12-09 12:50:44.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 9.916373843537201e-05 Training loss: 9.613789558410645
2025-12-09 12:50:45.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 9.915805595301491e-05 Training loss: 10.07406234741211
2025-12-09 12:50:45.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 9.915235439337603e-05 Training loss: 9.520806312561035
2025-12-09 12:50:45.860 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 9.914663375866804e-05 Training loss: 9.89579963684082
2025-12-09 12:50:46.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 9.914089405111098e-05 Training loss: 9.707418441772461
2025-12-09 12:50:46.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 9.913513527293235e-05 Training loss: 9.470094680786133
2025-12-09 12:50:46.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 9.912935742636698e-05 Training loss: 9.984273910522461
2025-12-09 12:50:47.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 9.912356051365718e-05 Training loss: 9.585844039916992
2025-12-09 12:50:47.726 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 9.911774453705258e-05 Training loss: 9.630552291870117
2025-12-09 12:50:48.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 9.91119094988103e-05 Training loss: 9.80911636352539
2025-12-09 12:50:48.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 9.910605540119475e-05 Training loss: 9.893495559692383
2025-12-09 12:50:48.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 9.91001822464778e-05 Training loss: 9.946226119995117
2025-12-09 12:50:49.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 9.909429003693876e-05 Training loss: 9.513421058654785
2025-12-09 12:50:49.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 9.908837877486423e-05 Training loss: 9.805570602416992
2025-12-09 12:50:49.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 9.908244846254826e-05 Training loss: 9.652641296386719
2025-12-09 12:50:50.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 9.907649910229229e-05 Training loss: 9.70641803741455
2025-12-09 12:50:50.704 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 9.907053069640517e-05 Training loss: 9.834307670593262
2025-12-09 12:50:51.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 9.90645432472031e-05 Training loss: 9.741867065429688
2025-12-09 12:50:51.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 9.905853675700969e-05 Training loss: 9.74886703491211
2025-12-09 12:50:51.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 9.905251122815596e-05 Training loss: 9.705796241760254
2025-12-09 12:50:52.198 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 9.90464666629803e-05 Training loss: 9.749080657958984
2025-12-09 12:50:52.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 9.904040306382846e-05 Training loss: 9.584628105163574
2025-12-09 12:50:52.944 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 9.903432043305365e-05 Training loss: 9.83012866973877
2025-12-09 12:50:53.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 9.902821877301637e-05 Training loss: 9.536869049072266
2025-12-09 12:50:53.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 9.90220980860846e-05 Training loss: 9.806961059570312
2025-12-09 12:50:54.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 9.901595837463363e-05 Training loss: 9.578662872314453
2025-12-09 12:50:54.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 9.900979964104617e-05 Training loss: 9.989110946655273
2025-12-09 12:50:54.806 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 9.900362188771231e-05 Training loss: 9.602302551269531
2025-12-09 12:50:55.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 9.899742511702951e-05 Training loss: 9.518097877502441
2025-12-09 12:50:55.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 9.89912093314026e-05 Training loss: 10.17345142364502
2025-12-09 12:50:55.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 9.898497453324384e-05 Training loss: 9.821386337280273
2025-12-09 12:50:56.296 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 9.897872072497281e-05 Training loss: 9.717072486877441
2025-12-09 12:50:56.673 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 9.897244790901649e-05 Training loss: 9.635443687438965
2025-12-09 12:50:57.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 9.896615608780925e-05 Training loss: 9.559080123901367
2025-12-09 12:50:57.417 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 9.895984526379281e-05 Training loss: 9.659337997436523
2025-12-09 12:50:57.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 9.895351543941629e-05 Training loss: 9.669271469116211
2025-12-09 12:50:58.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 9.894716661713617e-05 Training loss: 9.293913841247559
2025-12-09 12:50:58.533 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 9.894079879941627e-05 Training loss: 9.61565113067627
2025-12-09 12:50:58.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 9.893441198872787e-05 Training loss: 9.683829307556152
2025-12-09 12:50:59.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 9.892800618754954e-05 Training loss: 9.730870246887207
2025-12-09 12:50:59.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 9.892158139836725e-05 Training loss: 9.56859302520752
2025-12-09 12:51:00.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 9.891513762367431e-05 Training loss: 9.849347114562988
2025-12-09 12:51:00.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 9.890867486597146e-05 Training loss: 9.573612213134766
2025-12-09 12:51:00.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 9.890219312776676e-05 Training loss: 9.528392791748047
2025-12-09 12:51:01.144 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 9.889569241157563e-05 Training loss: 9.696592330932617
2025-12-09 12:51:01.518 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 9.888917271992091e-05 Training loss: 9.354167938232422
2025-12-09 12:51:01.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 9.888263405533271e-05 Training loss: 9.535327911376953
2025-12-09 12:51:02.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 9.88760764203486e-05 Training loss: 9.835514068603516
2025-12-09 12:51:02.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 9.886949981751346e-05 Training loss: 9.720569610595703
2025-12-09 12:51:03.005 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 9.886290424937952e-05 Training loss: 9.875960350036621
2025-12-09 12:51:03.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 9.885628971850642e-05 Training loss: 9.380355834960938
2025-12-09 12:51:03.751 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 9.884965622746111e-05 Training loss: 9.942689895629883
2025-12-09 12:51:04.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 9.884300377881795e-05 Training loss: 9.750895500183105
2025-12-09 12:51:04.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 9.883633237515858e-05 Training loss: 9.826451301574707
2025-12-09 12:51:04.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 9.882964201907207e-05 Training loss: 9.646209716796875
2025-12-09 12:51:05.240 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 9.882293271315481e-05 Training loss: 9.741631507873535
2025-12-09 12:51:05.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 9.881620446001056e-05 Training loss: 9.726459503173828
2025-12-09 12:51:05.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 9.88094572622504e-05 Training loss: 9.89570426940918
2025-12-09 12:51:06.362 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 9.88026911224928e-05 Training loss: 10.356729507446289
2025-12-09 12:51:06.735 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 9.879590604336359e-05 Training loss: 9.699478149414062
2025-12-09 12:51:07.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 9.87891020274959e-05 Training loss: 9.273527145385742
2025-12-09 12:51:07.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 9.878227907753021e-05 Training loss: 9.73816204071045
2025-12-09 12:51:07.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 9.877543719611444e-05 Training loss: 9.822915077209473
2025-12-09 12:51:08.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 9.876857638590373e-05 Training loss: 9.459753036499023
2025-12-09 12:51:08.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 9.876169664956067e-05 Training loss: 9.51450252532959
2025-12-09 12:51:08.967 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 9.875479798975512e-05 Training loss: 9.716841697692871
2025-12-09 12:51:09.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 9.874788040916432e-05 Training loss: 9.46215534210205
2025-12-09 12:51:09.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 9.874094391047289e-05 Training loss: 10.056185722351074
2025-12-09 12:51:10.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 9.873398849637268e-05 Training loss: 9.69058895111084
2025-12-09 12:51:10.462 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 9.872701416956299e-05 Training loss: 9.995893478393555
2025-12-09 12:51:10.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 9.872002093275042e-05 Training loss: 9.597497940063477
2025-12-09 12:51:11.207 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 9.871300878864891e-05 Training loss: 9.403817176818848
2025-12-09 12:51:11.580 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 9.870597773997972e-05 Training loss: 9.705315589904785
2025-12-09 12:51:11.953 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 9.869892778947148e-05 Training loss: 9.585073471069336
2025-12-09 12:51:12.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 9.869185893986012e-05 Training loss: 9.693126678466797
2025-12-09 12:51:12.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 9.868477119388896e-05 Training loss: 9.638091087341309
2025-12-09 12:51:13.067 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 9.867766455430857e-05 Training loss: 9.5562105178833
2025-12-09 12:51:13.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 9.867053902387693e-05 Training loss: 9.539185523986816
2025-12-09 12:51:13.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 9.86633946053593e-05 Training loss: 9.548482894897461
2025-12-09 12:51:14.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 9.865623130152828e-05 Training loss: 9.456801414489746
2025-12-09 12:51:14.561 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 9.864904911516384e-05 Training loss: 9.697822570800781
2025-12-09 12:51:14.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 9.864184804905323e-05 Training loss: 9.671807289123535
2025-12-09 12:51:15.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 9.863462810599105e-05 Training loss: 9.270270347595215
2025-12-09 12:51:15.678 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 9.862738928877922e-05 Training loss: 9.622878074645996
2025-12-09 12:51:16.050 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 9.862013160022696e-05 Training loss: 9.413186073303223
2025-12-09 12:51:16.422 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 9.861285504315085e-05 Training loss: 9.618906021118164
2025-12-09 12:51:16.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 9.860555962037479e-05 Training loss: 9.546331405639648
2025-12-09 12:51:17.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 9.859824533472998e-05 Training loss: 9.57211685180664
2025-12-09 12:51:17.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 9.859091218905498e-05 Training loss: 9.780566215515137
2025-12-09 12:51:17.911 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 9.85835601861956e-05 Training loss: 10.113210678100586
2025-12-09 12:51:18.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 9.857618932900503e-05 Training loss: 9.957412719726562
2025-12-09 12:51:18.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 9.856879962034374e-05 Training loss: 9.383747100830078
2025-12-09 12:51:19.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 9.856139106307955e-05 Training loss: 9.758645057678223
2025-12-09 12:51:19.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 9.855396366008758e-05 Training loss: 9.707764625549316
2025-12-09 12:51:19.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 9.854651741425023e-05 Training loss: 9.76783275604248
2025-12-09 12:51:20.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 9.853905232845728e-05 Training loss: 9.285840034484863
2025-12-09 12:51:20.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 9.853156840560575e-05 Training loss: 9.297219276428223
2025-12-09 12:51:20.892 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 9.852406564860003e-05 Training loss: 9.416653633117676
2025-12-09 12:51:21.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 9.851654406035179e-05 Training loss: 9.684832572937012
2025-12-09 12:51:21.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 9.850900364378e-05 Training loss: 9.366354942321777
2025-12-09 12:51:22.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 9.850144440181096e-05 Training loss: 9.712989807128906
2025-12-09 12:51:22.381 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 9.849386633737825e-05 Training loss: 10.221723556518555
2025-12-09 12:51:22.752 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 9.848626945342278e-05 Training loss: 9.814480781555176
2025-12-09 12:51:23.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 9.847865375289275e-05 Training loss: 9.987215995788574
2025-12-09 12:51:23.502 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 9.847101923874367e-05 Training loss: 9.729350090026855
2025-12-09 12:51:23.874 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 9.846336591393833e-05 Training loss: 9.680825233459473
2025-12-09 12:51:24.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 9.845569378144686e-05 Training loss: 9.792119026184082
2025-12-09 12:51:24.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 9.844800284424664e-05 Training loss: 9.564379692077637
2025-12-09 12:51:24.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 9.844029310532239e-05 Training loss: 9.725458145141602
2025-12-09 12:51:25.363 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 9.843256456766609e-05 Training loss: 9.554132461547852
2025-12-09 12:51:25.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 9.842481723427705e-05 Training loss: 9.799630165100098
2025-12-09 12:51:26.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 9.841705110816187e-05 Training loss: 9.751659393310547
2025-12-09 12:51:26.481 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 9.840926619233441e-05 Training loss: 9.560064315795898
2025-12-09 12:51:26.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 9.840146248981585e-05 Training loss: 9.792757034301758
2025-12-09 12:51:27.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 9.839364000363467e-05 Training loss: 9.694703102111816
2025-12-09 12:51:27.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 9.83857987368266e-05 Training loss: 9.674386024475098
2025-12-09 12:51:27.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 9.837793869243468e-05 Training loss: 9.668373107910156
2025-12-09 12:51:28.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 9.837005987350926e-05 Training loss: 9.964110374450684
2025-12-09 12:51:28.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 9.836216228310798e-05 Training loss: 9.514908790588379
2025-12-09 12:51:29.092 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 9.835424592429567e-05 Training loss: 9.436443328857422
2025-12-09 12:51:29.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 9.834631080014457e-05 Training loss: 9.625385284423828
2025-12-09 12:51:29.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 9.833835691373413e-05 Training loss: 9.554601669311523
2025-12-09 12:51:30.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 9.83303842681511e-05 Training loss: 9.509346008300781
2025-12-09 12:51:30.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 9.83223928664895e-05 Training loss: 9.742769241333008
2025-12-09 12:51:30.952 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 9.831438271185065e-05 Training loss: 9.539152145385742
2025-12-09 12:51:31.324 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 9.830635380734313e-05 Training loss: 9.614425659179688
2025-12-09 12:51:31.696 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 9.82983061560828e-05 Training loss: 9.376667976379395
2025-12-09 12:51:32.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 9.829023976119279e-05 Training loss: 9.300714492797852
2025-12-09 12:51:32.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 9.828215462580353e-05 Training loss: 9.604120254516602
2025-12-09 12:51:32.819 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 9.827405075305267e-05 Training loss: 9.361040115356445
2025-12-09 12:51:33.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 9.826592814608518e-05 Training loss: 9.596179008483887
2025-12-09 12:51:33.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 9.825778680805331e-05 Training loss: 9.85051155090332
2025-12-09 12:51:33.937 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 9.824962674211653e-05 Training loss: 9.592777252197266
2025-12-09 12:51:34.308 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 9.824144795144159e-05 Training loss: 9.65841293334961
2025-12-09 12:51:34.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 9.823325043920254e-05 Training loss: 9.888496398925781
2025-12-09 12:51:35.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 9.822503420858069e-05 Training loss: 9.607723236083984
2025-12-09 12:51:35.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 9.821679926276456e-05 Training loss: 9.409372329711914
2025-12-09 12:51:35.796 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 9.820854560494999e-05 Training loss: 9.536983489990234
2025-12-09 12:51:36.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 9.820027323834006e-05 Training loss: 9.46429443359375
2025-12-09 12:51:36.540 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 9.819198216614512e-05 Training loss: 9.478227615356445
2025-12-09 12:51:36.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 9.818367239158278e-05 Training loss: 9.713602066040039
2025-12-09 12:51:37.290 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 9.817534391787789e-05 Training loss: 9.826409339904785
2025-12-09 12:51:37.662 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 9.816699674826255e-05 Training loss: 9.529056549072266
2025-12-09 12:51:38.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 9.815863088597618e-05 Training loss: 9.591349601745605
2025-12-09 12:51:38.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 9.815024633426538e-05 Training loss: 9.435553550720215
2025-12-09 12:51:38.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 9.814184309638402e-05 Training loss: 9.590415000915527
2025-12-09 12:51:39.150 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 9.813342117559323e-05 Training loss: 9.3385591506958
2025-12-09 12:51:39.521 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 9.812498057516143e-05 Training loss: 9.66147232055664
2025-12-09 12:51:39.893 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 9.811652129836421e-05 Training loss: 9.697051048278809
2025-12-09 12:51:40.263 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 9.810804334848449e-05 Training loss: 9.391319274902344
2025-12-09 12:51:40.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 9.809954672881238e-05 Training loss: 9.645404815673828
2025-12-09 12:51:41.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 9.809103144264525e-05 Training loss: 9.61992359161377
2025-12-09 12:51:41.387 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 9.808249749328768e-05 Training loss: 9.40546989440918
2025-12-09 12:51:41.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 9.80739448840516e-05 Training loss: 9.890178680419922
2025-12-09 12:51:42.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 9.806537361825606e-05 Training loss: 9.635104179382324
2025-12-09 12:51:42.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 9.805678369922742e-05 Training loss: 9.676231384277344
2025-12-09 12:51:42.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 9.804817513029927e-05 Training loss: 9.620488166809082
2025-12-09 12:51:43.247 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 9.803954791481239e-05 Training loss: 9.630942344665527
2025-12-09 12:51:43.620 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 9.803090205611487e-05 Training loss: 9.535919189453125
2025-12-09 12:51:43.991 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 9.802223755756198e-05 Training loss: 9.353310585021973
2025-12-09 12:51:44.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 9.801355442251625e-05 Training loss: 9.56106948852539
2025-12-09 12:51:44.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 9.800485265434744e-05 Training loss: 9.725973129272461
2025-12-09 12:51:45.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 9.799613225643253e-05 Training loss: 9.60973072052002
2025-12-09 12:51:45.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 9.798739323215574e-05 Training loss: 9.5874605178833
2025-12-09 12:51:45.856 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 9.797863558490849e-05 Training loss: 9.528306007385254
2025-12-09 12:51:46.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 9.79698593180895e-05 Training loss: 9.43315601348877
2025-12-09 12:51:46.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 9.796106443510462e-05 Training loss: 9.499345779418945
2025-12-09 12:51:46.972 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 9.795225093936702e-05 Training loss: 9.479406356811523
2025-12-09 12:51:47.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 9.794341883429699e-05 Training loss: 9.256861686706543
2025-12-09 12:51:47.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 9.793456812332215e-05 Training loss: 9.671095848083496
2025-12-09 12:51:48.088 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 9.792569880987726e-05 Training loss: 9.451074600219727
2025-12-09 12:51:48.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 9.791681089740432e-05 Training loss: 10.172457695007324
2025-12-09 12:51:48.833 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 9.790790438935256e-05 Training loss: 9.545124053955078
2025-12-09 12:51:49.204 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 9.789897928917847e-05 Training loss: 9.291988372802734
2025-12-09 12:51:49.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 9.789003560034561e-05 Training loss: 9.604820251464844
2025-12-09 12:51:49.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 9.788107332632495e-05 Training loss: 9.666090965270996
2025-12-09 12:51:50.326 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 9.787209247059452e-05 Training loss: 9.355164527893066
2025-12-09 12:51:50.698 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 9.786309303663963e-05 Training loss: 9.389183044433594
2025-12-09 12:51:51.071 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 9.785407502795278e-05 Training loss: 9.539765357971191
2025-12-09 12:51:51.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 9.784503844803368e-05 Training loss: 9.453765869140625
2025-12-09 12:51:51.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 9.783598330038925e-05 Training loss: 9.541646957397461
2025-12-09 12:51:52.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 9.782690958853362e-05 Training loss: 9.402876853942871
2025-12-09 12:51:52.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 9.781781731598812e-05 Training loss: 9.527145385742188
2025-12-09 12:51:52.929 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 9.780870648628128e-05 Training loss: 9.412039756774902
2025-12-09 12:51:53.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 9.779957710294886e-05 Training loss: 9.85310173034668
2025-12-09 12:51:53.672 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 9.779042916953376e-05 Training loss: 9.626404762268066
2025-12-09 12:51:54.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 9.778126268958613e-05 Training loss: 9.555002212524414
2025-12-09 12:51:54.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 9.77720776666633e-05 Training loss: 9.385469436645508
2025-12-09 12:51:54.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 9.77628741043298e-05 Training loss: 9.410762786865234
2025-12-09 12:51:55.166 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 9.775365200615735e-05 Training loss: 9.45082950592041
2025-12-09 12:51:55.541 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 9.774441137572487e-05 Training loss: 9.546320915222168
2025-12-09 12:51:55.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 9.773515221661846e-05 Training loss: 10.040142059326172
2025-12-09 12:51:56.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 9.772587453243143e-05 Training loss: 9.79920768737793
2025-12-09 12:51:56.658 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 9.771657832676427e-05 Training loss: 9.546760559082031
2025-12-09 12:51:57.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 9.770726360322463e-05 Training loss: 9.572799682617188
2025-12-09 12:51:57.401 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 9.769793036542741e-05 Training loss: 9.462076187133789
2025-12-09 12:51:57.773 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 9.768857861699463e-05 Training loss: 9.401036262512207
2025-12-09 12:51:58.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 9.767920836155553e-05 Training loss: 9.586628913879395
2025-12-09 12:51:58.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 9.766981960274653e-05 Training loss: 9.321526527404785
2025-12-09 12:51:58.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 9.766041234421122e-05 Training loss: 9.292618751525879
2025-12-09 12:51:59.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 9.765098658960036e-05 Training loss: 9.464165687561035
2025-12-09 12:51:59.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 9.764154234257192e-05 Training loss: 9.3021879196167
2025-12-09 12:52:00.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 9.763207960679101e-05 Training loss: 9.445879936218262
2025-12-09 12:52:00.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 9.762259838592994e-05 Training loss: 9.54053020477295
2025-12-09 12:52:00.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 9.761309868366819e-05 Training loss: 9.416152954101562
2025-12-09 12:52:01.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 9.760358050369243e-05 Training loss: 9.487835884094238
2025-12-09 12:52:01.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 9.759404384969643e-05 Training loss: 9.311820030212402
2025-12-09 12:52:01.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 9.758448872538122e-05 Training loss: 9.55954647064209
2025-12-09 12:52:02.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 9.757491513445493e-05 Training loss: 9.71151065826416
2025-12-09 12:52:02.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 9.756532308063293e-05 Training loss: 9.623552322387695
2025-12-09 12:52:02.988 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 9.755571256763765e-05 Training loss: 9.418081283569336
2025-12-09 12:52:03.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 9.754608359919879e-05 Training loss: 9.285870552062988
2025-12-09 12:52:03.745 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 9.753643617905313e-05 Training loss: 9.477951049804688
2025-12-09 12:52:04.118 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 9.752677031094466e-05 Training loss: 9.704615592956543
2025-12-09 12:52:04.492 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 9.751708599862452e-05 Training loss: 9.31175422668457
2025-12-09 12:52:04.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 9.750738324585098e-05 Training loss: 10.118170738220215
2025-12-09 12:52:05.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 9.749766205638952e-05 Training loss: 9.418313980102539
2025-12-09 12:52:05.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 9.748792243401273e-05 Training loss: 9.388702392578125
2025-12-09 12:52:05.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 9.747816438250037e-05 Training loss: 9.446166038513184
2025-12-09 12:52:06.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 9.746838790563934e-05 Training loss: 9.469132423400879
2025-12-09 12:52:06.723 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 9.74585930072237e-05 Training loss: 9.538459777832031
2025-12-09 12:52:07.096 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 9.744877969105469e-05 Training loss: 9.544912338256836
2025-12-09 12:52:07.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 9.743894796094062e-05 Training loss: 9.499017715454102
2025-12-09 12:52:07.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 9.742909782069701e-05 Training loss: 9.500014305114746
2025-12-09 12:52:08.219 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 9.741922927414651e-05 Training loss: 9.698504447937012
2025-12-09 12:52:08.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 9.740934232511894e-05 Training loss: 9.798140525817871
2025-12-09 12:52:08.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 9.739943697745118e-05 Training loss: 9.554183006286621
2025-12-09 12:52:09.335 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 9.738951323498732e-05 Training loss: 9.387386322021484
2025-12-09 12:52:09.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 9.737957110157858e-05 Training loss: 9.46336841583252
2025-12-09 12:52:10.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 9.736961058108332e-05 Training loss: 9.723668098449707
2025-12-09 12:52:10.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 9.735963167736698e-05 Training loss: 9.448946952819824
2025-12-09 12:52:10.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 9.734963439430222e-05 Training loss: 9.99081802368164
2025-12-09 12:52:11.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 9.733961873576878e-05 Training loss: 9.478556632995605
2025-12-09 12:52:11.566 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 9.732958470565353e-05 Training loss: 9.571450233459473
2025-12-09 12:52:11.938 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 9.731953230785049e-05 Training loss: 9.59181022644043
2025-12-09 12:52:12.309 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 9.730946154626079e-05 Training loss: 9.342340469360352
2025-12-09 12:52:12.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 9.729937242479271e-05 Training loss: 9.569840431213379
2025-12-09 12:52:13.059 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 9.728926494736164e-05 Training loss: 9.532388687133789
2025-12-09 12:52:13.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 9.727913911789009e-05 Training loss: 9.555962562561035
2025-12-09 12:52:13.803 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 9.726899494030768e-05 Training loss: 9.515738487243652
2025-12-09 12:52:14.176 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 9.725883241855119e-05 Training loss: 9.637195587158203
2025-12-09 12:52:14.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 9.724865155656448e-05 Training loss: 9.566598892211914
2025-12-09 12:52:14.919 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 9.723845235829857e-05 Training loss: 9.366483688354492
2025-12-09 12:52:15.290 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 9.722823482771155e-05 Training loss: 9.461221694946289
2025-12-09 12:52:15.662 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 9.721799896876864e-05 Training loss: 9.448797225952148
2025-12-09 12:52:16.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 9.720774478544219e-05 Training loss: 9.460980415344238
2025-12-09 12:52:16.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 9.719747228171163e-05 Training loss: 9.353549003601074
2025-12-09 12:52:16.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 9.718718146156355e-05 Training loss: 9.807722091674805
2025-12-09 12:52:17.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 9.717687232899159e-05 Training loss: 9.59178352355957
2025-12-09 12:52:17.529 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 9.716654488799652e-05 Training loss: 9.345242500305176
2025-12-09 12:52:17.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 9.715619914258624e-05 Training loss: 9.622410774230957
2025-12-09 12:52:18.273 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 9.71458350967757e-05 Training loss: 9.337639808654785
2025-12-09 12:52:18.644 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 9.713545275458703e-05 Training loss: 9.290398597717285
2025-12-09 12:52:19.018 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 9.712505212004938e-05 Training loss: 9.363354682922363
2025-12-09 12:52:19.388 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 9.711463319719904e-05 Training loss: 9.449009895324707
2025-12-09 12:52:19.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 9.710419599007939e-05 Training loss: 9.42398738861084
2025-12-09 12:52:20.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 9.70937405027409e-05 Training loss: 9.206798553466797
2025-12-09 12:52:20.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 9.708326673924115e-05 Training loss: 9.418911933898926
2025-12-09 12:52:20.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 9.707277470364482e-05 Training loss: 9.452187538146973
2025-12-09 12:52:21.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 9.706226440002363e-05 Training loss: 9.235246658325195
2025-12-09 12:52:21.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 9.705173583245645e-05 Training loss: 9.613638877868652
2025-12-09 12:52:21.998 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 9.704118900502919e-05 Training loss: 9.483325958251953
2025-12-09 12:52:22.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 9.703062392183489e-05 Training loss: 9.776250839233398
2025-12-09 12:52:22.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 9.702004058697363e-05 Training loss: 9.343948364257812
2025-12-09 12:52:23.115 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 9.700943900455262e-05 Training loss: 9.254881858825684
2025-12-09 12:52:23.486 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 9.69988191786861e-05 Training loss: 9.639301300048828
2025-12-09 12:52:23.859 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 9.698818111349543e-05 Training loss: 9.404766082763672
2025-12-09 12:52:24.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 9.697752481310904e-05 Training loss: 9.669953346252441
2025-12-09 12:52:24.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 9.696685028166244e-05 Training loss: 9.657225608825684
2025-12-09 12:52:24.975 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 9.69561575232982e-05 Training loss: 9.179664611816406
2025-12-09 12:52:25.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 9.694544654216596e-05 Training loss: 9.502224922180176
2025-12-09 12:52:25.720 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 9.693471734242243e-05 Training loss: 9.734192848205566
2025-12-09 12:52:26.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 9.692396992823145e-05 Training loss: 9.488277435302734
2025-12-09 12:52:26.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 9.691320430376385e-05 Training loss: 9.568770408630371
2025-12-09 12:52:26.843 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 9.690242047319755e-05 Training loss: 9.273031234741211
2025-12-09 12:52:27.217 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 9.689161844071757e-05 Training loss: 9.349818229675293
2025-12-09 12:52:27.588 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 9.688079821051595e-05 Training loss: 9.309855461120605
2025-12-09 12:52:27.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 9.68699597867918e-05 Training loss: 9.510257720947266
2025-12-09 12:52:28.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 9.685910317375134e-05 Training loss: 9.417768478393555
2025-12-09 12:52:28.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 9.684822837560776e-05 Training loss: 9.564151763916016
2025-12-09 12:52:29.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 9.683733539658139e-05 Training loss: 9.44261360168457
2025-12-09 12:52:29.449 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 9.682642424089958e-05 Training loss: 9.703060150146484
2025-12-09 12:52:29.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 9.681549491279674e-05 Training loss: 9.19759464263916
2025-12-09 12:52:30.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 9.68045474165143e-05 Training loss: 9.43382453918457
2025-12-09 12:52:30.571 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 9.679358175630081e-05 Training loss: 9.276407241821289
2025-12-09 12:52:30.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 9.67825979364118e-05 Training loss: 9.416631698608398
2025-12-09 12:52:31.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 9.677159596110987e-05 Training loss: 9.441117286682129
2025-12-09 12:52:31.689 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 9.676057583466472e-05 Training loss: 9.333950996398926
2025-12-09 12:52:32.061 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 9.674953756135298e-05 Training loss: 9.461149215698242
2025-12-09 12:52:32.434 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 9.673848114545843e-05 Training loss: 9.280868530273438
2025-12-09 12:52:32.805 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 9.672740659127184e-05 Training loss: 9.284035682678223
2025-12-09 12:52:33.177 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 9.671631390309102e-05 Training loss: 9.296886444091797
2025-12-09 12:52:33.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 9.670520308522084e-05 Training loss: 9.246354103088379
2025-12-09 12:52:33.921 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 9.66940741419732e-05 Training loss: 9.30221176147461
2025-12-09 12:52:34.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 9.668292707766699e-05 Training loss: 9.582077026367188
2025-12-09 12:52:34.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 9.667176189662818e-05 Training loss: 9.000906944274902
2025-12-09 12:52:35.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 9.666057860318979e-05 Training loss: 9.589763641357422
2025-12-09 12:52:35.413 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 9.66493772016918e-05 Training loss: 9.45382308959961
2025-12-09 12:52:35.787 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 9.663815769648129e-05 Training loss: 9.583028793334961
2025-12-09 12:52:36.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 9.66269200919123e-05 Training loss: 9.477340698242188
2025-12-09 12:52:36.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 9.661566439234593e-05 Training loss: 9.460004806518555
2025-12-09 12:52:36.903 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 9.660439060215031e-05 Training loss: 9.517366409301758
2025-12-09 12:52:37.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 9.659309872570058e-05 Training loss: 9.312129974365234
2025-12-09 12:52:37.648 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 9.658178876737886e-05 Training loss: 9.376846313476562
2025-12-09 12:52:38.019 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 9.657046073157436e-05 Training loss: 9.346946716308594
2025-12-09 12:52:38.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 9.655911462268327e-05 Training loss: 9.739412307739258
2025-12-09 12:52:38.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 9.65477504451088e-05 Training loss: 9.76757526397705
2025-12-09 12:52:39.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 9.653636820326113e-05 Training loss: 9.679176330566406
2025-12-09 12:52:39.515 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 9.652496790155751e-05 Training loss: 9.076191902160645
2025-12-09 12:52:39.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 9.651354954442218e-05 Training loss: 9.369670867919922
2025-12-09 12:52:40.259 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 9.650211313628637e-05 Training loss: 9.569026947021484
2025-12-09 12:52:40.630 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 9.649065868158832e-05 Training loss: 9.42232608795166
2025-12-09 12:52:41.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 9.64791861847733e-05 Training loss: 9.325969696044922
2025-12-09 12:52:41.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 9.646769565029354e-05 Training loss: 9.343382835388184
2025-12-09 12:52:41.746 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 9.64561870826083e-05 Training loss: 9.340557098388672
2025-12-09 12:52:42.116 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 9.644466048618385e-05 Training loss: 9.411357879638672
2025-12-09 12:52:42.488 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 9.643311586549342e-05 Training loss: 9.268568992614746
2025-12-09 12:52:42.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 9.642155322501725e-05 Training loss: 9.469903945922852
2025-12-09 12:52:43.234 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 9.640997256924257e-05 Training loss: 9.289041519165039
2025-12-09 12:52:43.605 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 9.639837390266361e-05 Training loss: 9.573980331420898
2025-12-09 12:52:43.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 9.638675722978161e-05 Training loss: 9.424476623535156
2025-12-09 12:52:44.357 | INFO     | __main__:train:25 - Epoch: 0 Step: 714 LR: 9.637512255510475e-05 Training loss: 9.4098539352417
2025-12-09 12:52:44.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 715 LR: 9.63634698831482e-05 Training loss: 9.30477523803711
2025-12-09 12:52:45.099 | INFO     | __main__:train:25 - Epoch: 0 Step: 716 LR: 9.635179921843418e-05 Training loss: 9.441316604614258
2025-12-09 12:52:45.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 717 LR: 9.634011056549182e-05 Training loss: 9.237652778625488
2025-12-09 12:52:45.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 718 LR: 9.632840392885727e-05 Training loss: 9.588113784790039
2025-12-09 12:52:46.218 | INFO     | __main__:train:25 - Epoch: 0 Step: 719 LR: 9.631667931307364e-05 Training loss: 9.461227416992188
2025-12-09 12:52:46.590 | INFO     | __main__:train:25 - Epoch: 0 Step: 720 LR: 9.630493672269102e-05 Training loss: 9.44157886505127
2025-12-09 12:52:46.961 | INFO     | __main__:train:25 - Epoch: 0 Step: 721 LR: 9.629317616226649e-05 Training loss: 9.465545654296875
2025-12-09 12:52:47.333 | INFO     | __main__:train:25 - Epoch: 0 Step: 722 LR: 9.628139763636408e-05 Training loss: 9.480231285095215
2025-12-09 12:52:47.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 723 LR: 9.626960114955483e-05 Training loss: 9.46264934539795
2025-12-09 12:52:48.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 724 LR: 9.62577867064167e-05 Training loss: 9.514487266540527
2025-12-09 12:52:48.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 725 LR: 9.624595431153467e-05 Training loss: 9.590744018554688
2025-12-09 12:52:48.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 726 LR: 9.623410396950064e-05 Training loss: 9.65434455871582
2025-12-09 12:52:49.199 | INFO     | __main__:train:25 - Epoch: 0 Step: 727 LR: 9.62222356849135e-05 Training loss: 9.433405876159668
2025-12-09 12:52:49.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 728 LR: 9.621034946237911e-05 Training loss: 9.720502853393555
2025-12-09 12:52:49.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 729 LR: 9.619844530651027e-05 Training loss: 9.477336883544922
2025-12-09 12:52:50.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 730 LR: 9.618652322192675e-05 Training loss: 9.382425308227539
2025-12-09 12:52:50.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 731 LR: 9.61745832132553e-05 Training loss: 9.746809005737305
2025-12-09 12:52:51.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 732 LR: 9.616262528512957e-05 Training loss: 9.48220443725586
2025-12-09 12:52:51.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 733 LR: 9.615064944219022e-05 Training loss: 9.259673118591309
2025-12-09 12:52:51.802 | INFO     | __main__:train:25 - Epoch: 0 Step: 734 LR: 9.613865568908485e-05 Training loss: 9.361222267150879
2025-12-09 12:52:52.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 735 LR: 9.612664403046797e-05 Training loss: 9.193299293518066
