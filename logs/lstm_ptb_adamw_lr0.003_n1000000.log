2025-12-09 12:03:55.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 3e-05 Training loss: 9.209250450134277
2025-12-09 12:03:55.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 6e-05 Training loss: 9.20848274230957
2025-12-09 12:03:55.914 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 8.999999999999999e-05 Training loss: 9.207980155944824
2025-12-09 12:03:55.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.00012 Training loss: 9.20474624633789
2025-12-09 12:03:55.946 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.00015000000000000001 Training loss: 9.203522682189941
2025-12-09 12:03:55.962 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.00017999999999999998 Training loss: 9.1973237991333
2025-12-09 12:03:55.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.00021000000000000004 Training loss: 9.193097114562988
2025-12-09 12:03:55.994 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.00024 Training loss: 9.186467170715332
2025-12-09 12:03:56.013 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.00027 Training loss: 9.171623229980469
2025-12-09 12:03:56.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.00030000000000000003 Training loss: 9.165823936462402
2025-12-09 12:03:56.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.00033 Training loss: 9.147723197937012
2025-12-09 12:03:56.060 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.00035999999999999997 Training loss: 9.12002182006836
2025-12-09 12:03:56.076 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.00039000000000000005 Training loss: 9.07490348815918
2025-12-09 12:03:56.091 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.00042000000000000007 Training loss: 9.018562316894531
2025-12-09 12:03:56.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.00045 Training loss: 8.900736808776855
2025-12-09 12:03:56.122 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.00048 Training loss: 8.71423053741455
2025-12-09 12:03:56.138 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.00051 Training loss: 8.349832534790039
2025-12-09 12:03:56.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.00054 Training loss: 8.009297370910645
2025-12-09 12:03:56.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.00057 Training loss: 7.682666301727295
2025-12-09 12:03:56.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.0006000000000000001 Training loss: 7.441252708435059
2025-12-09 12:03:56.205 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.00063 Training loss: 7.2086310386657715
2025-12-09 12:03:56.221 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.00066 Training loss: 7.047186374664307
2025-12-09 12:03:56.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0006900000000000001 Training loss: 6.9445977210998535
2025-12-09 12:03:56.252 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0007199999999999999 Training loss: 6.835400581359863
2025-12-09 12:03:56.267 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.00075 Training loss: 6.8048481941223145
2025-12-09 12:03:56.283 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0007800000000000001 Training loss: 6.724974155426025
2025-12-09 12:03:56.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0008100000000000001 Training loss: 6.831225395202637
2025-12-09 12:03:56.313 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0008400000000000001 Training loss: 6.839715003967285
2025-12-09 12:03:56.328 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.00087 Training loss: 6.90850830078125
2025-12-09 12:03:56.343 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.0009 Training loss: 6.938464164733887
2025-12-09 12:03:56.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.00093 Training loss: 6.915770053863525
2025-12-09 12:03:56.374 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.00096 Training loss: 6.964052677154541
2025-12-09 12:03:56.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.00099 Training loss: 6.912509441375732
2025-12-09 12:03:56.409 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.00102 Training loss: 6.889625072479248
2025-12-09 12:03:56.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.00105 Training loss: 6.869534492492676
2025-12-09 12:03:56.440 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.00108 Training loss: 6.830481052398682
2025-12-09 12:03:56.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.00111 Training loss: 6.824329376220703
2025-12-09 12:03:56.470 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.00114 Training loss: 6.865135669708252
2025-12-09 12:03:56.485 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.00117 Training loss: 6.821558475494385
2025-12-09 12:03:56.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.0012000000000000001 Training loss: 6.868709564208984
2025-12-09 12:03:56.516 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.00123 Training loss: 6.758964538574219
2025-12-09 12:03:56.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.00126 Training loss: 6.848674774169922
2025-12-09 12:03:56.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.00129 Training loss: 6.837765693664551
2025-12-09 12:03:56.562 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.00132 Training loss: 6.7941575050354
2025-12-09 12:03:56.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.00135 Training loss: 6.781761646270752
2025-12-09 12:03:56.592 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0013800000000000002 Training loss: 6.87875509262085
2025-12-09 12:03:56.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.00141 Training loss: 6.84808349609375
2025-12-09 12:03:56.622 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0014399999999999999 Training loss: 6.725821495056152
2025-12-09 12:03:56.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.00147 Training loss: 6.849806308746338
2025-12-09 12:03:56.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.0015 Training loss: 6.812334060668945
2025-12-09 12:03:56.669 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0015300000000000001 Training loss: 6.855916976928711
2025-12-09 12:03:56.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.0015600000000000002 Training loss: 6.839410781860352
2025-12-09 12:03:56.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.00159 Training loss: 6.864078998565674
2025-12-09 12:03:56.717 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0016200000000000001 Training loss: 6.817417144775391
2025-12-09 12:03:56.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0016500000000000002 Training loss: 6.856346607208252
2025-12-09 12:03:56.748 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.0016800000000000003 Training loss: 6.741355895996094
2025-12-09 12:03:56.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.00171 Training loss: 6.775213718414307
2025-12-09 12:03:56.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.00174 Training loss: 6.804570198059082
2025-12-09 12:03:56.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0017699999999999999 Training loss: 6.855913162231445
2025-12-09 12:03:56.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.0018 Training loss: 6.832452297210693
2025-12-09 12:03:56.824 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.00183 Training loss: 6.7736711502075195
2025-12-09 12:03:56.839 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.00186 Training loss: 6.809383392333984
2025-12-09 12:03:56.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.00189 Training loss: 6.820450305938721
2025-12-09 12:03:56.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.00192 Training loss: 6.725386142730713
2025-12-09 12:03:56.885 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.0019500000000000001 Training loss: 6.781227111816406
2025-12-09 12:03:56.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.00198 Training loss: 6.833776473999023
2025-12-09 12:03:56.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.00201 Training loss: 6.7936601638793945
2025-12-09 12:03:56.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.00204 Training loss: 6.870271682739258
2025-12-09 12:03:56.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.00207 Training loss: 6.842087268829346
2025-12-09 12:03:56.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.0021 Training loss: 6.870007038116455
2025-12-09 12:03:56.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.00213 Training loss: 6.744718074798584
2025-12-09 12:03:56.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.00216 Training loss: 6.820641994476318
2025-12-09 12:03:57.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.00219 Training loss: 6.795774459838867
2025-12-09 12:03:57.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.00222 Training loss: 6.801806449890137
2025-12-09 12:03:57.042 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0022500000000000003 Training loss: 6.840578556060791
2025-12-09 12:03:57.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.00228 Training loss: 6.816405296325684
2025-12-09 12:03:57.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.00231 Training loss: 6.734302043914795
2025-12-09 12:03:57.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.00234 Training loss: 6.85374641418457
2025-12-09 12:03:57.102 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.00237 Training loss: 6.865849018096924
2025-12-09 12:03:57.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.0024000000000000002 Training loss: 6.731993198394775
2025-12-09 12:03:57.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.0024300000000000003 Training loss: 6.861001014709473
2025-12-09 12:03:57.148 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.00246 Training loss: 6.857686996459961
2025-12-09 12:03:57.163 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.00249 Training loss: 6.808369159698486
2025-12-09 12:03:57.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.00252 Training loss: 6.776035308837891
2025-12-09 12:03:57.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.00255 Training loss: 6.829299449920654
2025-12-09 12:03:57.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.00258 Training loss: 6.852065086364746
2025-12-09 12:03:57.223 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.00261 Training loss: 6.776773452758789
2025-12-09 12:03:57.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.00264 Training loss: 6.8312883377075195
2025-12-09 12:03:57.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.00267 Training loss: 6.8360795974731445
2025-12-09 12:03:57.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.0027 Training loss: 6.83233118057251
2025-12-09 12:03:57.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0027300000000000002 Training loss: 6.855138778686523
2025-12-09 12:03:57.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0027600000000000003 Training loss: 6.865377426147461
2025-12-09 12:03:57.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.0027900000000000004 Training loss: 6.857497692108154
2025-12-09 12:03:57.330 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.00282 Training loss: 6.861233234405518
2025-12-09 12:03:57.345 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.00285 Training loss: 6.8348612785339355
2025-12-09 12:03:57.361 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0028799999999999997 Training loss: 6.909553050994873
2025-12-09 12:03:57.376 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.00291 Training loss: 6.843113422393799
2025-12-09 12:03:57.391 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.00294 Training loss: 6.909501075744629
2025-12-09 12:03:57.406 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.00297 Training loss: 6.957088947296143
2025-12-09 12:03:57.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.003 Training loss: 6.965234756469727
2025-12-09 12:03:57.436 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.002909538931178863 Training loss: 6.870306968688965
2025-12-09 12:03:57.452 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.002649066664678467 Training loss: 6.826803684234619
2025-12-09 12:03:57.467 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.0022500000000000003 Training loss: 6.840785026550293
2025-12-09 12:03:57.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.0017604722665003959 Training loss: 6.921166896820068
2025-12-09 12:03:57.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.0012395277334996046 Training loss: 6.814672470092773
2025-12-09 12:03:57.513 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.0007500000000000003 Training loss: 6.756309986114502
2025-12-09 12:03:57.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.0003509333353215332 Training loss: 6.897526741027832
2025-12-09 12:03:57.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 9.046106882113752e-05 Training loss: 6.835457801818848
2025-12-09 12:03:57.553 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.0 Training loss: 6.666847229003906
