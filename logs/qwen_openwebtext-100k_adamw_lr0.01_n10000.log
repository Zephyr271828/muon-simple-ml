2025-12-09 11:55:17.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 0 LR: 0.0001 Training loss: 12.063255310058594
2025-12-09 11:55:17.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 1 LR: 0.0002 Training loss: 11.984463691711426
2025-12-09 11:55:17.624 | INFO     | __main__:train:25 - Epoch: 0 Step: 2 LR: 0.0003 Training loss: 11.958647727966309
2025-12-09 11:55:17.702 | INFO     | __main__:train:25 - Epoch: 0 Step: 3 LR: 0.0004 Training loss: 11.748620986938477
2025-12-09 11:55:17.780 | INFO     | __main__:train:25 - Epoch: 0 Step: 4 LR: 0.0005 Training loss: 11.376509666442871
2025-12-09 11:55:17.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 5 LR: 0.0006 Training loss: 11.247518539428711
2025-12-09 11:55:17.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 6 LR: 0.0007000000000000001 Training loss: 10.877285957336426
2025-12-09 11:55:18.016 | INFO     | __main__:train:25 - Epoch: 0 Step: 7 LR: 0.0008 Training loss: 10.8001070022583
2025-12-09 11:55:18.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 8 LR: 0.0009 Training loss: 10.534674644470215
2025-12-09 11:55:18.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 9 LR: 0.001 Training loss: 10.24853801727295
2025-12-09 11:55:18.249 | INFO     | __main__:train:25 - Epoch: 0 Step: 10 LR: 0.0011 Training loss: 9.917692184448242
2025-12-09 11:55:18.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 11 LR: 0.0012 Training loss: 9.327902793884277
2025-12-09 11:55:18.404 | INFO     | __main__:train:25 - Epoch: 0 Step: 12 LR: 0.0013000000000000002 Training loss: 9.123360633850098
2025-12-09 11:55:18.482 | INFO     | __main__:train:25 - Epoch: 0 Step: 13 LR: 0.0014000000000000002 Training loss: 8.69895076751709
2025-12-09 11:55:18.560 | INFO     | __main__:train:25 - Epoch: 0 Step: 14 LR: 0.0015 Training loss: 8.600857734680176
2025-12-09 11:55:18.638 | INFO     | __main__:train:25 - Epoch: 0 Step: 15 LR: 0.0016 Training loss: 8.295791625976562
2025-12-09 11:55:18.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 16 LR: 0.0017000000000000001 Training loss: 7.934670448303223
2025-12-09 11:55:18.795 | INFO     | __main__:train:25 - Epoch: 0 Step: 17 LR: 0.0018 Training loss: 8.213921546936035
2025-12-09 11:55:18.877 | INFO     | __main__:train:25 - Epoch: 0 Step: 18 LR: 0.0019 Training loss: 7.761539459228516
2025-12-09 11:55:18.958 | INFO     | __main__:train:25 - Epoch: 0 Step: 19 LR: 0.002 Training loss: 8.795857429504395
2025-12-09 11:55:19.036 | INFO     | __main__:train:25 - Epoch: 0 Step: 20 LR: 0.0021 Training loss: 8.233681678771973
2025-12-09 11:55:19.113 | INFO     | __main__:train:25 - Epoch: 0 Step: 21 LR: 0.0022 Training loss: 8.475003242492676
2025-12-09 11:55:19.191 | INFO     | __main__:train:25 - Epoch: 0 Step: 22 LR: 0.0023 Training loss: 8.806303024291992
2025-12-09 11:55:19.269 | INFO     | __main__:train:25 - Epoch: 0 Step: 23 LR: 0.0024 Training loss: 8.31022834777832
2025-12-09 11:55:19.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 24 LR: 0.0025 Training loss: 8.440410614013672
2025-12-09 11:55:19.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 25 LR: 0.0026000000000000003 Training loss: 8.32324504852295
2025-12-09 11:55:19.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 26 LR: 0.0027 Training loss: 7.915920734405518
2025-12-09 11:55:19.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 27 LR: 0.0028000000000000004 Training loss: 8.352940559387207
2025-12-09 11:55:19.659 | INFO     | __main__:train:25 - Epoch: 0 Step: 28 LR: 0.0029 Training loss: 8.296767234802246
2025-12-09 11:55:19.737 | INFO     | __main__:train:25 - Epoch: 0 Step: 29 LR: 0.003 Training loss: 8.073149681091309
2025-12-09 11:55:19.815 | INFO     | __main__:train:25 - Epoch: 0 Step: 30 LR: 0.0031 Training loss: 8.077943801879883
2025-12-09 11:55:19.896 | INFO     | __main__:train:25 - Epoch: 0 Step: 31 LR: 0.0032 Training loss: 7.8735504150390625
2025-12-09 11:55:19.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 32 LR: 0.0033000000000000004 Training loss: 8.561635971069336
2025-12-09 11:55:20.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 33 LR: 0.0034000000000000002 Training loss: 8.129870414733887
2025-12-09 11:55:20.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 34 LR: 0.0034999999999999996 Training loss: 8.21534252166748
2025-12-09 11:55:20.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 35 LR: 0.0036 Training loss: 8.371397972106934
2025-12-09 11:55:20.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 36 LR: 0.0037 Training loss: 8.288712501525879
2025-12-09 11:55:20.364 | INFO     | __main__:train:25 - Epoch: 0 Step: 37 LR: 0.0038 Training loss: 8.2721586227417
2025-12-09 11:55:20.442 | INFO     | __main__:train:25 - Epoch: 0 Step: 38 LR: 0.0039000000000000003 Training loss: 8.168195724487305
2025-12-09 11:55:20.520 | INFO     | __main__:train:25 - Epoch: 0 Step: 39 LR: 0.004 Training loss: 8.315217971801758
2025-12-09 11:55:20.598 | INFO     | __main__:train:25 - Epoch: 0 Step: 40 LR: 0.0040999999999999995 Training loss: 8.445841789245605
2025-12-09 11:55:20.675 | INFO     | __main__:train:25 - Epoch: 0 Step: 41 LR: 0.0042 Training loss: 8.319153785705566
2025-12-09 11:55:20.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 42 LR: 0.0043 Training loss: 8.377486228942871
2025-12-09 11:55:20.834 | INFO     | __main__:train:25 - Epoch: 0 Step: 43 LR: 0.0044 Training loss: 8.298627853393555
2025-12-09 11:55:20.912 | INFO     | __main__:train:25 - Epoch: 0 Step: 44 LR: 0.0045000000000000005 Training loss: 8.447206497192383
2025-12-09 11:55:20.990 | INFO     | __main__:train:25 - Epoch: 0 Step: 45 LR: 0.0046 Training loss: 8.34002685546875
2025-12-09 11:55:21.068 | INFO     | __main__:train:25 - Epoch: 0 Step: 46 LR: 0.0047 Training loss: 8.286623001098633
2025-12-09 11:55:21.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 47 LR: 0.0048 Training loss: 7.168179035186768
2025-12-09 11:55:21.225 | INFO     | __main__:train:25 - Epoch: 0 Step: 48 LR: 0.0049 Training loss: 8.062989234924316
2025-12-09 11:55:21.303 | INFO     | __main__:train:25 - Epoch: 0 Step: 49 LR: 0.005 Training loss: 8.379728317260742
2025-12-09 11:55:21.382 | INFO     | __main__:train:25 - Epoch: 0 Step: 50 LR: 0.0051 Training loss: 8.502148628234863
2025-12-09 11:55:21.460 | INFO     | __main__:train:25 - Epoch: 0 Step: 51 LR: 0.005200000000000001 Training loss: 8.302995681762695
2025-12-09 11:55:21.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 52 LR: 0.0053 Training loss: 8.154354095458984
2025-12-09 11:55:21.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 53 LR: 0.0054 Training loss: 8.138792037963867
2025-12-09 11:55:21.694 | INFO     | __main__:train:25 - Epoch: 0 Step: 54 LR: 0.0055000000000000005 Training loss: 8.232065200805664
2025-12-09 11:55:21.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 55 LR: 0.005600000000000001 Training loss: 9.041971206665039
2025-12-09 11:55:21.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 56 LR: 0.005699999999999999 Training loss: 8.484880447387695
2025-12-09 11:55:21.930 | INFO     | __main__:train:25 - Epoch: 0 Step: 57 LR: 0.0058 Training loss: 8.374231338500977
2025-12-09 11:55:22.008 | INFO     | __main__:train:25 - Epoch: 0 Step: 58 LR: 0.0059 Training loss: 8.291810035705566
2025-12-09 11:55:22.086 | INFO     | __main__:train:25 - Epoch: 0 Step: 59 LR: 0.006 Training loss: 8.031333923339844
2025-12-09 11:55:22.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 60 LR: 0.0061 Training loss: 8.304935455322266
2025-12-09 11:55:22.243 | INFO     | __main__:train:25 - Epoch: 0 Step: 61 LR: 0.0062 Training loss: 8.272747039794922
2025-12-09 11:55:22.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 62 LR: 0.0063 Training loss: 8.330089569091797
2025-12-09 11:55:22.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 63 LR: 0.0064 Training loss: 8.040046691894531
2025-12-09 11:55:22.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 64 LR: 0.006500000000000001 Training loss: 7.890986442565918
2025-12-09 11:55:22.556 | INFO     | __main__:train:25 - Epoch: 0 Step: 65 LR: 0.006600000000000001 Training loss: 7.9498162269592285
2025-12-09 11:55:22.634 | INFO     | __main__:train:25 - Epoch: 0 Step: 66 LR: 0.0067 Training loss: 8.037846565246582
2025-12-09 11:55:22.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 67 LR: 0.0068000000000000005 Training loss: 8.000903129577637
2025-12-09 11:55:22.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 68 LR: 0.0069 Training loss: 8.247431755065918
2025-12-09 11:55:22.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 69 LR: 0.006999999999999999 Training loss: 7.995804309844971
2025-12-09 11:55:22.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 70 LR: 0.0070999999999999995 Training loss: 8.29846477508545
2025-12-09 11:55:23.027 | INFO     | __main__:train:25 - Epoch: 0 Step: 71 LR: 0.0072 Training loss: 8.483443260192871
2025-12-09 11:55:23.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 72 LR: 0.0073 Training loss: 8.348827362060547
2025-12-09 11:55:23.183 | INFO     | __main__:train:25 - Epoch: 0 Step: 73 LR: 0.0074 Training loss: 7.922191619873047
2025-12-09 11:55:23.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 74 LR: 0.0075 Training loss: 8.266739845275879
2025-12-09 11:55:23.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 75 LR: 0.0076 Training loss: 7.98421049118042
2025-12-09 11:55:23.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 76 LR: 0.0077 Training loss: 8.139110565185547
2025-12-09 11:55:23.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 77 LR: 0.0078000000000000005 Training loss: 8.27150821685791
2025-12-09 11:55:23.574 | INFO     | __main__:train:25 - Epoch: 0 Step: 78 LR: 0.0079 Training loss: 8.009970664978027
2025-12-09 11:55:23.656 | INFO     | __main__:train:25 - Epoch: 0 Step: 79 LR: 0.008 Training loss: 8.098555564880371
2025-12-09 11:55:23.734 | INFO     | __main__:train:25 - Epoch: 0 Step: 80 LR: 0.008100000000000001 Training loss: 8.964803695678711
2025-12-09 11:55:23.813 | INFO     | __main__:train:25 - Epoch: 0 Step: 81 LR: 0.008199999999999999 Training loss: 8.432161331176758
2025-12-09 11:55:23.891 | INFO     | __main__:train:25 - Epoch: 0 Step: 82 LR: 0.0083 Training loss: 8.59907341003418
2025-12-09 11:55:23.970 | INFO     | __main__:train:25 - Epoch: 0 Step: 83 LR: 0.0084 Training loss: 7.838232517242432
2025-12-09 11:55:24.048 | INFO     | __main__:train:25 - Epoch: 0 Step: 84 LR: 0.0085 Training loss: 8.13435173034668
2025-12-09 11:55:24.127 | INFO     | __main__:train:25 - Epoch: 0 Step: 85 LR: 0.0086 Training loss: 8.322112083435059
2025-12-09 11:55:24.206 | INFO     | __main__:train:25 - Epoch: 0 Step: 86 LR: 0.0087 Training loss: 8.416458129882812
2025-12-09 11:55:24.284 | INFO     | __main__:train:25 - Epoch: 0 Step: 87 LR: 0.0088 Training loss: 8.426653861999512
2025-12-09 11:55:24.363 | INFO     | __main__:train:25 - Epoch: 0 Step: 88 LR: 0.0089 Training loss: 8.385293006896973
2025-12-09 11:55:24.441 | INFO     | __main__:train:25 - Epoch: 0 Step: 89 LR: 0.009000000000000001 Training loss: 8.705780982971191
2025-12-09 11:55:24.519 | INFO     | __main__:train:25 - Epoch: 0 Step: 90 LR: 0.0091 Training loss: 8.011357307434082
2025-12-09 11:55:24.600 | INFO     | __main__:train:25 - Epoch: 0 Step: 91 LR: 0.0092 Training loss: 8.354504585266113
2025-12-09 11:55:24.679 | INFO     | __main__:train:25 - Epoch: 0 Step: 92 LR: 0.009300000000000001 Training loss: 8.102559089660645
2025-12-09 11:55:24.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 93 LR: 0.0094 Training loss: 7.839563369750977
2025-12-09 11:55:24.835 | INFO     | __main__:train:25 - Epoch: 0 Step: 94 LR: 0.0095 Training loss: 7.943742275238037
2025-12-09 11:55:24.913 | INFO     | __main__:train:25 - Epoch: 0 Step: 95 LR: 0.0096 Training loss: 8.120260238647461
2025-12-09 11:55:24.992 | INFO     | __main__:train:25 - Epoch: 0 Step: 96 LR: 0.0097 Training loss: 7.992364406585693
2025-12-09 11:55:25.070 | INFO     | __main__:train:25 - Epoch: 0 Step: 97 LR: 0.0098 Training loss: 7.949121475219727
2025-12-09 11:55:25.149 | INFO     | __main__:train:25 - Epoch: 0 Step: 98 LR: 0.0099 Training loss: 8.070487022399902
2025-12-09 11:55:25.227 | INFO     | __main__:train:25 - Epoch: 0 Step: 99 LR: 0.01 Training loss: 7.975766658782959
2025-12-09 11:55:25.305 | INFO     | __main__:train:25 - Epoch: 0 Step: 100 LR: 0.009999999072578702 Training loss: 8.261590957641602
2025-12-09 11:55:25.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 101 LR: 0.009999996290315153 Training loss: 8.06386947631836
2025-12-09 11:55:25.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 102 LR: 0.009999991653210385 Training loss: 7.864890098571777
2025-12-09 11:55:25.545 | INFO     | __main__:train:25 - Epoch: 0 Step: 103 LR: 0.009999985161266116 Training loss: 8.286579132080078
2025-12-09 11:55:25.623 | INFO     | __main__:train:25 - Epoch: 0 Step: 104 LR: 0.009999976814484758 Training loss: 7.955945014953613
2025-12-09 11:55:25.798 | INFO     | __main__:train:25 - Epoch: 0 Step: 105 LR: 0.009999966612869405 Training loss: 8.195731163024902
2025-12-09 11:55:25.876 | INFO     | __main__:train:25 - Epoch: 0 Step: 106 LR: 0.009999954556423843 Training loss: 7.40069055557251
2025-12-09 11:55:25.954 | INFO     | __main__:train:25 - Epoch: 0 Step: 107 LR: 0.009999940645152541 Training loss: 7.764433860778809
2025-12-09 11:55:26.032 | INFO     | __main__:train:25 - Epoch: 0 Step: 108 LR: 0.009999924879060665 Training loss: 8.193150520324707
2025-12-09 11:55:26.111 | INFO     | __main__:train:25 - Epoch: 0 Step: 109 LR: 0.00999990725815406 Training loss: 8.528305053710938
2025-12-09 11:55:26.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 110 LR: 0.009999887782439263 Training loss: 8.32723617553711
2025-12-09 11:55:26.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 111 LR: 0.0099998664519235 Training loss: 8.124420166015625
2025-12-09 11:55:26.346 | INFO     | __main__:train:25 - Epoch: 0 Step: 112 LR: 0.009999843266614685 Training loss: 7.911625862121582
2025-12-09 11:55:26.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 113 LR: 0.009999818226521415 Training loss: 8.024813652038574
2025-12-09 11:55:26.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 114 LR: 0.009999791331652984 Training loss: 7.943151473999023
2025-12-09 11:55:26.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 115 LR: 0.009999762582019366 Training loss: 8.324020385742188
2025-12-09 11:55:26.663 | INFO     | __main__:train:25 - Epoch: 0 Step: 116 LR: 0.009999731977631227 Training loss: 8.122705459594727
2025-12-09 11:55:26.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 117 LR: 0.00999969951849992 Training loss: 7.937477111816406
2025-12-09 11:55:26.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 118 LR: 0.009999665204637487 Training loss: 8.036410331726074
2025-12-09 11:55:26.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 119 LR: 0.009999629036056657 Training loss: 8.261991500854492
2025-12-09 11:55:26.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 120 LR: 0.009999591012770847 Training loss: 7.872769355773926
2025-12-09 11:55:27.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 121 LR: 0.009999551134794164 Training loss: 7.931832313537598
2025-12-09 11:55:27.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 122 LR: 0.0099995094021414 Training loss: 7.909985065460205
2025-12-09 11:55:27.213 | INFO     | __main__:train:25 - Epoch: 0 Step: 123 LR: 0.009999465814828036 Training loss: 7.893203258514404
2025-12-09 11:55:27.291 | INFO     | __main__:train:25 - Epoch: 0 Step: 124 LR: 0.009999420372870242 Training loss: 7.598515033721924
2025-12-09 11:55:27.370 | INFO     | __main__:train:25 - Epoch: 0 Step: 125 LR: 0.009999373076284877 Training loss: 8.647554397583008
2025-12-09 11:55:27.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 126 LR: 0.009999323925089485 Training loss: 7.917816162109375
2025-12-09 11:55:27.531 | INFO     | __main__:train:25 - Epoch: 0 Step: 127 LR: 0.009999272919302301 Training loss: 8.258798599243164
2025-12-09 11:55:27.610 | INFO     | __main__:train:25 - Epoch: 0 Step: 128 LR: 0.009999220058942245 Training loss: 8.160890579223633
2025-12-09 11:55:27.688 | INFO     | __main__:train:25 - Epoch: 0 Step: 129 LR: 0.009999165344028926 Training loss: 8.216623306274414
2025-12-09 11:55:27.767 | INFO     | __main__:train:25 - Epoch: 0 Step: 130 LR: 0.009999108774582644 Training loss: 8.291814804077148
2025-12-09 11:55:27.846 | INFO     | __main__:train:25 - Epoch: 0 Step: 131 LR: 0.009999050350624381 Training loss: 8.099577903747559
2025-12-09 11:55:27.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 132 LR: 0.009998990072175813 Training loss: 7.747289657592773
2025-12-09 11:55:28.003 | INFO     | __main__:train:25 - Epoch: 0 Step: 133 LR: 0.009998927939259302 Training loss: 7.784843444824219
2025-12-09 11:55:28.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 134 LR: 0.009998863951897896 Training loss: 7.8815789222717285
2025-12-09 11:55:28.160 | INFO     | __main__:train:25 - Epoch: 0 Step: 135 LR: 0.009998798110115333 Training loss: 7.906425952911377
2025-12-09 11:55:28.238 | INFO     | __main__:train:25 - Epoch: 0 Step: 136 LR: 0.009998730413936037 Training loss: 7.728353023529053
2025-12-09 11:55:28.317 | INFO     | __main__:train:25 - Epoch: 0 Step: 137 LR: 0.009998660863385123 Training loss: 7.761204719543457
2025-12-09 11:55:28.396 | INFO     | __main__:train:25 - Epoch: 0 Step: 138 LR: 0.00999858945848839 Training loss: 7.645893096923828
2025-12-09 11:55:28.478 | INFO     | __main__:train:25 - Epoch: 0 Step: 139 LR: 0.009998516199272327 Training loss: 7.629789352416992
2025-12-09 11:55:28.557 | INFO     | __main__:train:25 - Epoch: 0 Step: 140 LR: 0.009998441085764113 Training loss: 8.078169822692871
2025-12-09 11:55:28.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 141 LR: 0.009998364117991612 Training loss: 7.550654888153076
2025-12-09 11:55:28.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 142 LR: 0.009998285295983376 Training loss: 7.7021894454956055
2025-12-09 11:55:28.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 143 LR: 0.009998204619768645 Training loss: 7.587409973144531
2025-12-09 11:55:28.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 144 LR: 0.00999812208937735 Training loss: 7.677079200744629
2025-12-09 11:55:28.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 145 LR: 0.009998037704840102 Training loss: 7.808053970336914
2025-12-09 11:55:29.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 146 LR: 0.00999795146618821 Training loss: 7.7483673095703125
2025-12-09 11:55:29.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 147 LR: 0.009997863373453663 Training loss: 8.357640266418457
2025-12-09 11:55:29.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 148 LR: 0.00999777342666914 Training loss: 7.653663158416748
2025-12-09 11:55:29.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 149 LR: 0.009997681625868013 Training loss: 8.430500984191895
2025-12-09 11:55:29.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 150 LR: 0.009997587971084335 Training loss: 8.395631790161133
2025-12-09 11:55:29.424 | INFO     | __main__:train:25 - Epoch: 0 Step: 151 LR: 0.009997492462352845 Training loss: 7.618196964263916
2025-12-09 11:55:29.503 | INFO     | __main__:train:25 - Epoch: 0 Step: 152 LR: 0.009997395099708982 Training loss: 8.309478759765625
2025-12-09 11:55:29.581 | INFO     | __main__:train:25 - Epoch: 0 Step: 153 LR: 0.009997295883188855 Training loss: 7.910280227661133
2025-12-09 11:55:29.660 | INFO     | __main__:train:25 - Epoch: 0 Step: 154 LR: 0.009997194812829277 Training loss: 7.923718452453613
2025-12-09 11:55:29.738 | INFO     | __main__:train:25 - Epoch: 0 Step: 155 LR: 0.009997091888667738 Training loss: 7.7104811668396
2025-12-09 11:55:29.817 | INFO     | __main__:train:25 - Epoch: 0 Step: 156 LR: 0.009996987110742421 Training loss: 8.001173973083496
2025-12-09 11:55:29.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 157 LR: 0.009996880479092198 Training loss: 7.736845970153809
2025-12-09 11:55:29.973 | INFO     | __main__:train:25 - Epoch: 0 Step: 158 LR: 0.009996771993756622 Training loss: 7.69703483581543
2025-12-09 11:55:30.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 159 LR: 0.009996661654775939 Training loss: 7.741270542144775
2025-12-09 11:55:30.130 | INFO     | __main__:train:25 - Epoch: 0 Step: 160 LR: 0.009996549462191081 Training loss: 7.505443572998047
2025-12-09 11:55:30.208 | INFO     | __main__:train:25 - Epoch: 0 Step: 161 LR: 0.00999643541604367 Training loss: 7.662580490112305
2025-12-09 11:55:30.287 | INFO     | __main__:train:25 - Epoch: 0 Step: 162 LR: 0.00999631951637601 Training loss: 7.5269012451171875
2025-12-09 11:55:30.369 | INFO     | __main__:train:25 - Epoch: 0 Step: 163 LR: 0.009996201763231098 Training loss: 7.623422622680664
2025-12-09 11:55:30.448 | INFO     | __main__:train:25 - Epoch: 0 Step: 164 LR: 0.009996082156652618 Training loss: 7.7637481689453125
2025-12-09 11:55:30.527 | INFO     | __main__:train:25 - Epoch: 0 Step: 165 LR: 0.009995960696684939 Training loss: 7.781864643096924
2025-12-09 11:55:30.606 | INFO     | __main__:train:25 - Epoch: 0 Step: 166 LR: 0.009995837383373118 Training loss: 8.13175106048584
2025-12-09 11:55:30.684 | INFO     | __main__:train:25 - Epoch: 0 Step: 167 LR: 0.009995712216762901 Training loss: 7.754611015319824
2025-12-09 11:55:30.763 | INFO     | __main__:train:25 - Epoch: 0 Step: 168 LR: 0.009995585196900723 Training loss: 7.734020233154297
2025-12-09 11:55:30.842 | INFO     | __main__:train:25 - Epoch: 0 Step: 169 LR: 0.009995456323833701 Training loss: 7.283416748046875
2025-12-09 11:55:30.920 | INFO     | __main__:train:25 - Epoch: 0 Step: 170 LR: 0.009995325597609645 Training loss: 7.622228145599365
2025-12-09 11:55:30.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 171 LR: 0.00999519301827705 Training loss: 8.358405113220215
2025-12-09 11:55:31.077 | INFO     | __main__:train:25 - Epoch: 0 Step: 172 LR: 0.009995058585885095 Training loss: 7.877101421356201
2025-12-09 11:55:31.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 173 LR: 0.009994922300483657 Training loss: 7.5470967292785645
2025-12-09 11:55:31.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 174 LR: 0.00999478416212329 Training loss: 7.768487453460693
2025-12-09 11:55:31.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 175 LR: 0.009994644170855237 Training loss: 7.337655067443848
2025-12-09 11:55:31.394 | INFO     | __main__:train:25 - Epoch: 0 Step: 176 LR: 0.009994502326731434 Training loss: 7.546895503997803
2025-12-09 11:55:31.472 | INFO     | __main__:train:25 - Epoch: 0 Step: 177 LR: 0.009994358629804499 Training loss: 7.534764766693115
2025-12-09 11:55:31.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 178 LR: 0.009994213080127738 Training loss: 7.847391605377197
2025-12-09 11:55:31.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 179 LR: 0.009994065677755147 Training loss: 8.390033721923828
2025-12-09 11:55:31.708 | INFO     | __main__:train:25 - Epoch: 0 Step: 180 LR: 0.00999391642274141 Training loss: 7.531929016113281
2025-12-09 11:55:31.786 | INFO     | __main__:train:25 - Epoch: 0 Step: 181 LR: 0.00999376531514189 Training loss: 7.76187801361084
2025-12-09 11:55:31.865 | INFO     | __main__:train:25 - Epoch: 0 Step: 182 LR: 0.009993612355012647 Training loss: 7.599546432495117
2025-12-09 11:55:31.943 | INFO     | __main__:train:25 - Epoch: 0 Step: 183 LR: 0.009993457542410423 Training loss: 7.383874416351318
2025-12-09 11:55:32.022 | INFO     | __main__:train:25 - Epoch: 0 Step: 184 LR: 0.00999330087739265 Training loss: 7.452495574951172
2025-12-09 11:55:32.100 | INFO     | __main__:train:25 - Epoch: 0 Step: 185 LR: 0.009993142360017445 Training loss: 7.498838901519775
2025-12-09 11:55:32.178 | INFO     | __main__:train:25 - Epoch: 0 Step: 186 LR: 0.009992981990343614 Training loss: 7.474030494689941
2025-12-09 11:55:32.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 187 LR: 0.009992819768430647 Training loss: 8.18108081817627
2025-12-09 11:55:32.340 | INFO     | __main__:train:25 - Epoch: 0 Step: 188 LR: 0.009992655694338725 Training loss: 7.547801494598389
2025-12-09 11:55:32.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 189 LR: 0.009992489768128714 Training loss: 7.43247652053833
2025-12-09 11:55:32.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 190 LR: 0.009992321989862165 Training loss: 7.8740386962890625
2025-12-09 11:55:32.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 191 LR: 0.009992152359601322 Training loss: 7.70432710647583
2025-12-09 11:55:32.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 192 LR: 0.00999198087740911 Training loss: 7.5174031257629395
2025-12-09 11:55:32.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 193 LR: 0.009991807543349147 Training loss: 7.1944804191589355
2025-12-09 11:55:32.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 194 LR: 0.009991632357485729 Training loss: 7.3987579345703125
2025-12-09 11:55:32.890 | INFO     | __main__:train:25 - Epoch: 0 Step: 195 LR: 0.009991455319883848 Training loss: 7.473138809204102
2025-12-09 11:55:32.968 | INFO     | __main__:train:25 - Epoch: 0 Step: 196 LR: 0.00999127643060918 Training loss: 7.763890266418457
2025-12-09 11:55:33.047 | INFO     | __main__:train:25 - Epoch: 0 Step: 197 LR: 0.009991095689728087 Training loss: 7.2437591552734375
2025-12-09 11:55:33.125 | INFO     | __main__:train:25 - Epoch: 0 Step: 198 LR: 0.009990913097307614 Training loss: 7.473475933074951
2025-12-09 11:55:33.207 | INFO     | __main__:train:25 - Epoch: 0 Step: 199 LR: 0.009990728653415505 Training loss: 7.578348159790039
2025-12-09 11:55:33.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 200 LR: 0.009990542358120174 Training loss: 8.058544158935547
2025-12-09 11:55:33.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 201 LR: 0.009990354211490735 Training loss: 7.463674068450928
2025-12-09 11:55:33.443 | INFO     | __main__:train:25 - Epoch: 0 Step: 202 LR: 0.009990164213596987 Training loss: 7.5904669761657715
2025-12-09 11:55:33.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 203 LR: 0.009989972364509407 Training loss: 6.4049201011657715
2025-12-09 11:55:33.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 204 LR: 0.009989778664299172 Training loss: 7.041526794433594
2025-12-09 11:55:33.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 205 LR: 0.009989583113038134 Training loss: 7.602558135986328
2025-12-09 11:55:33.758 | INFO     | __main__:train:25 - Epoch: 0 Step: 206 LR: 0.009989385710798838 Training loss: 8.005163192749023
2025-12-09 11:55:33.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 207 LR: 0.009989186457654514 Training loss: 6.6269330978393555
2025-12-09 11:55:33.915 | INFO     | __main__:train:25 - Epoch: 0 Step: 208 LR: 0.009988985353679076 Training loss: 7.5526909828186035
2025-12-09 11:55:33.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 209 LR: 0.009988782398947132 Training loss: 7.555957317352295
2025-12-09 11:55:34.072 | INFO     | __main__:train:25 - Epoch: 0 Step: 210 LR: 0.009988577593533967 Training loss: 7.5728631019592285
2025-12-09 11:55:34.155 | INFO     | __main__:train:25 - Epoch: 0 Step: 211 LR: 0.00998837093751556 Training loss: 7.457029819488525
2025-12-09 11:55:34.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 212 LR: 0.009988162430968575 Training loss: 8.746326446533203
2025-12-09 11:55:34.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 213 LR: 0.009987952073970359 Training loss: 7.4252610206604
2025-12-09 11:55:34.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 214 LR: 0.00998773986659895 Training loss: 7.692333221435547
2025-12-09 11:55:34.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 215 LR: 0.009987525808933069 Training loss: 7.2847981452941895
2025-12-09 11:55:34.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 216 LR: 0.009987309901052122 Training loss: 7.64419412612915
2025-12-09 11:55:34.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 217 LR: 0.009987092143036209 Training loss: 7.579955101013184
2025-12-09 11:55:34.705 | INFO     | __main__:train:25 - Epoch: 0 Step: 218 LR: 0.009986872534966109 Training loss: 7.636409759521484
2025-12-09 11:55:34.784 | INFO     | __main__:train:25 - Epoch: 0 Step: 219 LR: 0.009986651076923288 Training loss: 7.427708625793457
2025-12-09 11:55:34.863 | INFO     | __main__:train:25 - Epoch: 0 Step: 220 LR: 0.009986427768989904 Training loss: 7.420014381408691
2025-12-09 11:55:34.941 | INFO     | __main__:train:25 - Epoch: 0 Step: 221 LR: 0.009986202611248794 Training loss: 7.456103801727295
2025-12-09 11:55:35.020 | INFO     | __main__:train:25 - Epoch: 0 Step: 222 LR: 0.009985975603783484 Training loss: 7.568571090698242
2025-12-09 11:55:35.103 | INFO     | __main__:train:25 - Epoch: 0 Step: 223 LR: 0.00998574674667819 Training loss: 7.833445072174072
2025-12-09 11:55:35.182 | INFO     | __main__:train:25 - Epoch: 0 Step: 224 LR: 0.009985516040017807 Training loss: 7.556896686553955
2025-12-09 11:55:35.261 | INFO     | __main__:train:25 - Epoch: 0 Step: 225 LR: 0.009985283483887922 Training loss: 7.389524459838867
2025-12-09 11:55:35.339 | INFO     | __main__:train:25 - Epoch: 0 Step: 226 LR: 0.009985049078374806 Training loss: 7.6837897300720215
2025-12-09 11:55:35.418 | INFO     | __main__:train:25 - Epoch: 0 Step: 227 LR: 0.009984812823565416 Training loss: 7.83908224105835
2025-12-09 11:55:35.496 | INFO     | __main__:train:25 - Epoch: 0 Step: 228 LR: 0.009984574719547395 Training loss: 7.602456092834473
2025-12-09 11:55:35.575 | INFO     | __main__:train:25 - Epoch: 0 Step: 229 LR: 0.00998433476640907 Training loss: 7.46757173538208
2025-12-09 11:55:35.653 | INFO     | __main__:train:25 - Epoch: 0 Step: 230 LR: 0.00998409296423946 Training loss: 7.463108539581299
2025-12-09 11:55:35.732 | INFO     | __main__:train:25 - Epoch: 0 Step: 231 LR: 0.009983849313128264 Training loss: 7.595710754394531
2025-12-09 11:55:35.810 | INFO     | __main__:train:25 - Epoch: 0 Step: 232 LR: 0.009983603813165869 Training loss: 7.496494293212891
2025-12-09 11:55:35.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 233 LR: 0.009983356464443347 Training loss: 7.394896984100342
2025-12-09 11:55:35.969 | INFO     | __main__:train:25 - Epoch: 0 Step: 234 LR: 0.009983107267052456 Training loss: 7.492064952850342
2025-12-09 11:55:36.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 235 LR: 0.009982856221085643 Training loss: 6.689952373504639
2025-12-09 11:55:36.131 | INFO     | __main__:train:25 - Epoch: 0 Step: 236 LR: 0.009982603326636037 Training loss: 7.652336597442627
2025-12-09 11:55:36.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 237 LR: 0.009982348583797453 Training loss: 7.557606220245361
2025-12-09 11:55:36.288 | INFO     | __main__:train:25 - Epoch: 0 Step: 238 LR: 0.009982091992664392 Training loss: 7.495641708374023
2025-12-09 11:55:36.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 239 LR: 0.009981833553332044 Training loss: 7.396645545959473
2025-12-09 11:55:36.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 240 LR: 0.009981573265896281 Training loss: 7.479889392852783
2025-12-09 11:55:36.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 241 LR: 0.00998131113045366 Training loss: 7.270506858825684
2025-12-09 11:55:36.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 242 LR: 0.009981047147101425 Training loss: 7.421928882598877
2025-12-09 11:55:36.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 243 LR: 0.009980781315937506 Training loss: 7.201287269592285
2025-12-09 11:55:36.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 244 LR: 0.00998051363706052 Training loss: 7.344010829925537
2025-12-09 11:55:36.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 245 LR: 0.009980244110569764 Training loss: 7.33998966217041
2025-12-09 11:55:36.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 246 LR: 0.009979972736565226 Training loss: 7.1696367263793945
2025-12-09 11:55:36.999 | INFO     | __main__:train:25 - Epoch: 0 Step: 247 LR: 0.009979699515147577 Training loss: 7.779980659484863
2025-12-09 11:55:37.078 | INFO     | __main__:train:25 - Epoch: 0 Step: 248 LR: 0.009979424446418172 Training loss: 7.475347518920898
2025-12-09 11:55:37.157 | INFO     | __main__:train:25 - Epoch: 0 Step: 249 LR: 0.009979147530479055 Training loss: 7.407486915588379
2025-12-09 11:55:37.235 | INFO     | __main__:train:25 - Epoch: 0 Step: 250 LR: 0.009978868767432954 Training loss: 7.72120475769043
2025-12-09 11:55:37.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 251 LR: 0.009978588157383277 Training loss: 7.444549083709717
2025-12-09 11:55:37.392 | INFO     | __main__:train:25 - Epoch: 0 Step: 252 LR: 0.009978305700434125 Training loss: 7.338507175445557
2025-12-09 11:55:37.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 253 LR: 0.00997802139669028 Training loss: 7.762402534484863
2025-12-09 11:55:37.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 254 LR: 0.009977735246257209 Training loss: 7.154247283935547
2025-12-09 11:55:37.628 | INFO     | __main__:train:25 - Epoch: 0 Step: 255 LR: 0.009977447249241066 Training loss: 7.3433613777160645
2025-12-09 11:55:37.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 256 LR: 0.009977157405748687 Training loss: 7.297767162322998
2025-12-09 11:55:37.786 | INFO     | __main__:train:25 - Epoch: 0 Step: 257 LR: 0.009976865715887595 Training loss: 7.127902507781982
2025-12-09 11:55:37.864 | INFO     | __main__:train:25 - Epoch: 0 Step: 258 LR: 0.009976572179765998 Training loss: 7.209758758544922
2025-12-09 11:55:37.948 | INFO     | __main__:train:25 - Epoch: 0 Step: 259 LR: 0.009976276797492793 Training loss: 7.616316318511963
2025-12-09 11:55:38.026 | INFO     | __main__:train:25 - Epoch: 0 Step: 260 LR: 0.009975979569177552 Training loss: 7.505348205566406
2025-12-09 11:55:38.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 261 LR: 0.009975680494930538 Training loss: 7.475014686584473
2025-12-09 11:55:38.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 262 LR: 0.0099753795748627 Training loss: 7.4884138107299805
2025-12-09 11:55:38.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 263 LR: 0.00997507680908567 Training loss: 7.407138824462891
2025-12-09 11:55:38.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 264 LR: 0.009974772197711762 Training loss: 7.440126895904541
2025-12-09 11:55:38.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 265 LR: 0.009974465740853979 Training loss: 7.482104301452637
2025-12-09 11:55:38.497 | INFO     | __main__:train:25 - Epoch: 0 Step: 266 LR: 0.009974157438626008 Training loss: 7.358704090118408
2025-12-09 11:55:38.576 | INFO     | __main__:train:25 - Epoch: 0 Step: 267 LR: 0.009973847291142217 Training loss: 7.1426849365234375
2025-12-09 11:55:38.654 | INFO     | __main__:train:25 - Epoch: 0 Step: 268 LR: 0.009973535298517662 Training loss: 7.327328681945801
2025-12-09 11:55:38.733 | INFO     | __main__:train:25 - Epoch: 0 Step: 269 LR: 0.009973221460868084 Training loss: 6.639787673950195
2025-12-09 11:55:38.811 | INFO     | __main__:train:25 - Epoch: 0 Step: 270 LR: 0.009972905778309905 Training loss: 7.272516250610352
2025-12-09 11:55:38.895 | INFO     | __main__:train:25 - Epoch: 0 Step: 271 LR: 0.009972588250960234 Training loss: 7.707494735717773
2025-12-09 11:55:38.974 | INFO     | __main__:train:25 - Epoch: 0 Step: 272 LR: 0.009972268878936864 Training loss: 7.511810302734375
2025-12-09 11:55:39.052 | INFO     | __main__:train:25 - Epoch: 0 Step: 273 LR: 0.009971947662358269 Training loss: 7.838357448577881
2025-12-09 11:55:39.132 | INFO     | __main__:train:25 - Epoch: 0 Step: 274 LR: 0.009971624601343614 Training loss: 7.54288387298584
2025-12-09 11:55:39.210 | INFO     | __main__:train:25 - Epoch: 0 Step: 275 LR: 0.009971299696012743 Training loss: 7.72575044631958
2025-12-09 11:55:39.289 | INFO     | __main__:train:25 - Epoch: 0 Step: 276 LR: 0.009970972946486186 Training loss: 7.87484884262085
2025-12-09 11:55:39.367 | INFO     | __main__:train:25 - Epoch: 0 Step: 277 LR: 0.009970644352885156 Training loss: 6.880894184112549
2025-12-09 11:55:39.446 | INFO     | __main__:train:25 - Epoch: 0 Step: 278 LR: 0.009970313915331553 Training loss: 7.528165340423584
2025-12-09 11:55:39.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 279 LR: 0.009969981633947956 Training loss: 7.3944315910339355
2025-12-09 11:55:39.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 280 LR: 0.009969647508857631 Training loss: 7.36381196975708
2025-12-09 11:55:39.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 281 LR: 0.00996931154018453 Training loss: 7.966464996337891
2025-12-09 11:55:39.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 282 LR: 0.009968973728053289 Training loss: 7.6080756187438965
2025-12-09 11:55:39.844 | INFO     | __main__:train:25 - Epoch: 0 Step: 283 LR: 0.009968634072589218 Training loss: 7.584969520568848
2025-12-09 11:55:39.923 | INFO     | __main__:train:25 - Epoch: 0 Step: 284 LR: 0.009968292573918324 Training loss: 7.221831321716309
2025-12-09 11:55:40.001 | INFO     | __main__:train:25 - Epoch: 0 Step: 285 LR: 0.009967949232167294 Training loss: 7.490912914276123
2025-12-09 11:55:40.079 | INFO     | __main__:train:25 - Epoch: 0 Step: 286 LR: 0.009967604047463493 Training loss: 7.351847171783447
2025-12-09 11:55:40.158 | INFO     | __main__:train:25 - Epoch: 0 Step: 287 LR: 0.009967257019934974 Training loss: 7.525744438171387
2025-12-09 11:55:40.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 288 LR: 0.009966908149710475 Training loss: 7.181379318237305
2025-12-09 11:55:40.314 | INFO     | __main__:train:25 - Epoch: 0 Step: 289 LR: 0.009966557436919416 Training loss: 7.568030834197998
2025-12-09 11:55:40.393 | INFO     | __main__:train:25 - Epoch: 0 Step: 290 LR: 0.009966204881691898 Training loss: 7.513513088226318
2025-12-09 11:55:40.471 | INFO     | __main__:train:25 - Epoch: 0 Step: 291 LR: 0.00996585048415871 Training loss: 7.493380069732666
2025-12-09 11:55:40.550 | INFO     | __main__:train:25 - Epoch: 0 Step: 292 LR: 0.009965494244451324 Training loss: 7.323841571807861
2025-12-09 11:55:40.629 | INFO     | __main__:train:25 - Epoch: 0 Step: 293 LR: 0.00996513616270189 Training loss: 7.934737205505371
2025-12-09 11:55:40.707 | INFO     | __main__:train:25 - Epoch: 0 Step: 294 LR: 0.009964776239043245 Training loss: 8.333213806152344
2025-12-09 11:55:40.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 295 LR: 0.009964414473608912 Training loss: 7.0594682693481445
2025-12-09 11:55:40.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 296 LR: 0.009964050866533094 Training loss: 7.439661026000977
2025-12-09 11:55:40.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 297 LR: 0.009963685417950676 Training loss: 7.395275592803955
2025-12-09 11:55:41.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 298 LR: 0.00996331812799723 Training loss: 6.863248348236084
2025-12-09 11:55:41.106 | INFO     | __main__:train:25 - Epoch: 0 Step: 299 LR: 0.009962948996809008 Training loss: 7.290817737579346
2025-12-09 11:55:41.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 300 LR: 0.009962578024522948 Training loss: 7.259187698364258
2025-12-09 11:55:41.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 301 LR: 0.009962205211276665 Training loss: 7.681544780731201
2025-12-09 11:55:41.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 302 LR: 0.009961830557208463 Training loss: 7.005021572113037
2025-12-09 11:55:41.421 | INFO     | __main__:train:25 - Epoch: 0 Step: 303 LR: 0.009961454062457329 Training loss: 7.414706707000732
2025-12-09 11:55:41.499 | INFO     | __main__:train:25 - Epoch: 0 Step: 304 LR: 0.009961075727162927 Training loss: 7.098309516906738
2025-12-09 11:55:41.578 | INFO     | __main__:train:25 - Epoch: 0 Step: 305 LR: 0.009960695551465611 Training loss: 7.2688469886779785
2025-12-09 11:55:41.657 | INFO     | __main__:train:25 - Epoch: 0 Step: 306 LR: 0.009960313535506412 Training loss: 7.196478366851807
2025-12-09 11:55:41.741 | INFO     | __main__:train:25 - Epoch: 0 Step: 307 LR: 0.009959929679427047 Training loss: 7.855969429016113
2025-12-09 11:55:41.820 | INFO     | __main__:train:25 - Epoch: 0 Step: 308 LR: 0.009959543983369913 Training loss: 7.147617340087891
2025-12-09 11:55:41.898 | INFO     | __main__:train:25 - Epoch: 0 Step: 309 LR: 0.009959156447478091 Training loss: 7.260180950164795
2025-12-09 11:55:41.976 | INFO     | __main__:train:25 - Epoch: 0 Step: 310 LR: 0.009958767071895348 Training loss: 7.454639434814453
2025-12-09 11:55:42.054 | INFO     | __main__:train:25 - Epoch: 0 Step: 311 LR: 0.009958375856766127 Training loss: 7.353964805603027
2025-12-09 11:55:42.133 | INFO     | __main__:train:25 - Epoch: 0 Step: 312 LR: 0.009957982802235556 Training loss: 7.338326930999756
2025-12-09 11:55:42.211 | INFO     | __main__:train:25 - Epoch: 0 Step: 313 LR: 0.009957587908449448 Training loss: 7.053083896636963
2025-12-09 11:55:42.290 | INFO     | __main__:train:25 - Epoch: 0 Step: 314 LR: 0.009957191175554294 Training loss: 6.90659236907959
2025-12-09 11:55:42.368 | INFO     | __main__:train:25 - Epoch: 0 Step: 315 LR: 0.009956792603697273 Training loss: 6.929520606994629
2025-12-09 11:55:42.447 | INFO     | __main__:train:25 - Epoch: 0 Step: 316 LR: 0.009956392193026239 Training loss: 6.517426013946533
2025-12-09 11:55:42.525 | INFO     | __main__:train:25 - Epoch: 0 Step: 317 LR: 0.009955989943689734 Training loss: 7.51852560043335
2025-12-09 11:55:42.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 318 LR: 0.009955585855836977 Training loss: 6.852766990661621
2025-12-09 11:55:42.687 | INFO     | __main__:train:25 - Epoch: 0 Step: 319 LR: 0.009955179929617875 Training loss: 7.041172027587891
2025-12-09 11:55:42.766 | INFO     | __main__:train:25 - Epoch: 0 Step: 320 LR: 0.009954772165183012 Training loss: 7.907735824584961
2025-12-09 11:55:42.845 | INFO     | __main__:train:25 - Epoch: 0 Step: 321 LR: 0.009954362562683658 Training loss: 7.437585830688477
2025-12-09 11:55:42.924 | INFO     | __main__:train:25 - Epoch: 0 Step: 322 LR: 0.00995395112227176 Training loss: 7.336905002593994
2025-12-09 11:55:43.002 | INFO     | __main__:train:25 - Epoch: 0 Step: 323 LR: 0.00995353784409995 Training loss: 7.372098922729492
2025-12-09 11:55:43.081 | INFO     | __main__:train:25 - Epoch: 0 Step: 324 LR: 0.009953122728321542 Training loss: 7.261094570159912
2025-12-09 11:55:43.159 | INFO     | __main__:train:25 - Epoch: 0 Step: 325 LR: 0.00995270577509053 Training loss: 7.616641998291016
2025-12-09 11:55:43.237 | INFO     | __main__:train:25 - Epoch: 0 Step: 326 LR: 0.009952286984561591 Training loss: 7.307137489318848
2025-12-09 11:55:43.316 | INFO     | __main__:train:25 - Epoch: 0 Step: 327 LR: 0.009951866356890084 Training loss: 7.526341438293457
2025-12-09 11:55:43.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 328 LR: 0.009951443892232048 Training loss: 7.2258124351501465
2025-12-09 11:55:43.473 | INFO     | __main__:train:25 - Epoch: 0 Step: 329 LR: 0.009951019590744202 Training loss: 6.971292972564697
2025-12-09 11:55:43.551 | INFO     | __main__:train:25 - Epoch: 0 Step: 330 LR: 0.009950593452583952 Training loss: 7.100450038909912
2025-12-09 11:55:43.636 | INFO     | __main__:train:25 - Epoch: 0 Step: 331 LR: 0.00995016547790938 Training loss: 7.082421779632568
2025-12-09 11:55:43.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 332 LR: 0.009949735666879251 Training loss: 7.009369373321533
2025-12-09 11:55:43.794 | INFO     | __main__:train:25 - Epoch: 0 Step: 333 LR: 0.009949304019653011 Training loss: 6.999507904052734
2025-12-09 11:55:43.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 334 LR: 0.00994887053639079 Training loss: 7.076481342315674
2025-12-09 11:55:43.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 335 LR: 0.009948435217253393 Training loss: 7.522009372711182
2025-12-09 11:55:44.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 336 LR: 0.009947998062402312 Training loss: 7.2952799797058105
2025-12-09 11:55:44.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 337 LR: 0.009947559071999719 Training loss: 7.22723913192749
2025-12-09 11:55:44.187 | INFO     | __main__:train:25 - Epoch: 0 Step: 338 LR: 0.009947118246208461 Training loss: 7.1438984870910645
2025-12-09 11:55:44.266 | INFO     | __main__:train:25 - Epoch: 0 Step: 339 LR: 0.009946675585192076 Training loss: 7.187896251678467
2025-12-09 11:55:44.344 | INFO     | __main__:train:25 - Epoch: 0 Step: 340 LR: 0.009946231089114773 Training loss: 7.4475297927856445
2025-12-09 11:55:44.423 | INFO     | __main__:train:25 - Epoch: 0 Step: 341 LR: 0.009945784758141448 Training loss: 8.069966316223145
2025-12-09 11:55:44.501 | INFO     | __main__:train:25 - Epoch: 0 Step: 342 LR: 0.009945336592437678 Training loss: 7.634110450744629
2025-12-09 11:55:44.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 343 LR: 0.009944886592169713 Training loss: 7.4019060134887695
2025-12-09 11:55:44.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 344 LR: 0.009944434757504492 Training loss: 7.382606506347656
2025-12-09 11:55:44.744 | INFO     | __main__:train:25 - Epoch: 0 Step: 345 LR: 0.009943981088609631 Training loss: 7.223486423492432
2025-12-09 11:55:44.822 | INFO     | __main__:train:25 - Epoch: 0 Step: 346 LR: 0.009943525585653428 Training loss: 7.427748203277588
2025-12-09 11:55:44.901 | INFO     | __main__:train:25 - Epoch: 0 Step: 347 LR: 0.009943068248804858 Training loss: 7.817005634307861
2025-12-09 11:55:44.980 | INFO     | __main__:train:25 - Epoch: 0 Step: 348 LR: 0.009942609078233581 Training loss: 6.706047058105469
2025-12-09 11:55:45.058 | INFO     | __main__:train:25 - Epoch: 0 Step: 349 LR: 0.009942148074109933 Training loss: 7.218790054321289
2025-12-09 11:55:45.137 | INFO     | __main__:train:25 - Epoch: 0 Step: 350 LR: 0.009941685236604934 Training loss: 7.005025863647461
2025-12-09 11:55:45.215 | INFO     | __main__:train:25 - Epoch: 0 Step: 351 LR: 0.009941220565890278 Training loss: 7.603968620300293
2025-12-09 11:55:45.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 352 LR: 0.00994075406213835 Training loss: 7.257932186126709
2025-12-09 11:55:45.372 | INFO     | __main__:train:25 - Epoch: 0 Step: 353 LR: 0.009940285725522203 Training loss: 7.105490207672119
2025-12-09 11:55:45.451 | INFO     | __main__:train:25 - Epoch: 0 Step: 354 LR: 0.009939815556215575 Training loss: 7.388701915740967
2025-12-09 11:55:45.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 355 LR: 0.009939343554392886 Training loss: 7.561097621917725
2025-12-09 11:55:45.614 | INFO     | __main__:train:25 - Epoch: 0 Step: 356 LR: 0.009938869720229233 Training loss: 7.284152030944824
2025-12-09 11:55:45.692 | INFO     | __main__:train:25 - Epoch: 0 Step: 357 LR: 0.009938394053900394 Training loss: 7.435295104980469
2025-12-09 11:55:45.771 | INFO     | __main__:train:25 - Epoch: 0 Step: 358 LR: 0.009937916555582828 Training loss: 7.398191452026367
2025-12-09 11:55:45.850 | INFO     | __main__:train:25 - Epoch: 0 Step: 359 LR: 0.009937437225453668 Training loss: 7.412835597991943
2025-12-09 11:55:45.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 360 LR: 0.009936956063690734 Training loss: 7.280543327331543
2025-12-09 11:55:46.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 361 LR: 0.009936473070472518 Training loss: 6.316446781158447
2025-12-09 11:55:46.085 | INFO     | __main__:train:25 - Epoch: 0 Step: 362 LR: 0.009935988245978198 Training loss: 5.538674354553223
2025-12-09 11:55:46.164 | INFO     | __main__:train:25 - Epoch: 0 Step: 363 LR: 0.009935501590387627 Training loss: 7.224228858947754
2025-12-09 11:55:46.242 | INFO     | __main__:train:25 - Epoch: 0 Step: 364 LR: 0.009935013103881342 Training loss: 7.023738384246826
2025-12-09 11:55:46.321 | INFO     | __main__:train:25 - Epoch: 0 Step: 365 LR: 0.009934522786640554 Training loss: 7.04462194442749
2025-12-09 11:55:46.399 | INFO     | __main__:train:25 - Epoch: 0 Step: 366 LR: 0.009934030638847154 Training loss: 7.432401657104492
2025-12-09 11:55:46.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 367 LR: 0.009933536660683716 Training loss: 7.1573896408081055
2025-12-09 11:55:46.563 | INFO     | __main__:train:25 - Epoch: 0 Step: 368 LR: 0.009933040852333487 Training loss: 7.376941204071045
2025-12-09 11:55:46.642 | INFO     | __main__:train:25 - Epoch: 0 Step: 369 LR: 0.009932543213980401 Training loss: 7.257607936859131
2025-12-09 11:55:46.721 | INFO     | __main__:train:25 - Epoch: 0 Step: 370 LR: 0.009932043745809064 Training loss: 7.248316287994385
2025-12-09 11:55:46.799 | INFO     | __main__:train:25 - Epoch: 0 Step: 371 LR: 0.009931542448004758 Training loss: 7.130856513977051
2025-12-09 11:55:46.878 | INFO     | __main__:train:25 - Epoch: 0 Step: 372 LR: 0.009931039320753456 Training loss: 7.425638675689697
2025-12-09 11:55:46.956 | INFO     | __main__:train:25 - Epoch: 0 Step: 373 LR: 0.0099305343642418 Training loss: 7.321896553039551
2025-12-09 11:55:47.035 | INFO     | __main__:train:25 - Epoch: 0 Step: 374 LR: 0.009930027578657113 Training loss: 6.742832660675049
2025-12-09 11:55:47.113 | INFO     | __main__:train:25 - Epoch: 0 Step: 375 LR: 0.009929518964187393 Training loss: 7.097373008728027
2025-12-09 11:55:47.192 | INFO     | __main__:train:25 - Epoch: 0 Step: 376 LR: 0.009929008521021325 Training loss: 7.064377784729004
2025-12-09 11:55:47.270 | INFO     | __main__:train:25 - Epoch: 0 Step: 377 LR: 0.009928496249348266 Training loss: 7.32477331161499
2025-12-09 11:55:47.349 | INFO     | __main__:train:25 - Epoch: 0 Step: 378 LR: 0.00992798214935825 Training loss: 7.29099178314209
2025-12-09 11:55:47.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 379 LR: 0.009927466221241995 Training loss: 7.404202938079834
2025-12-09 11:55:47.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 380 LR: 0.009926948465190892 Training loss: 7.490055561065674
2025-12-09 11:55:47.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 381 LR: 0.009926428881397015 Training loss: 7.692793369293213
2025-12-09 11:55:47.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 382 LR: 0.00992590747005311 Training loss: 6.8855061531066895
2025-12-09 11:55:47.749 | INFO     | __main__:train:25 - Epoch: 0 Step: 383 LR: 0.009925384231352606 Training loss: 7.142307281494141
2025-12-09 11:55:47.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 384 LR: 0.009924859165489608 Training loss: 7.484642505645752
2025-12-09 11:55:47.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 385 LR: 0.009924332272658898 Training loss: 7.309149265289307
2025-12-09 11:55:47.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 386 LR: 0.009923803553055936 Training loss: 7.039489269256592
2025-12-09 11:55:48.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 387 LR: 0.009923273006876865 Training loss: 6.8761749267578125
2025-12-09 11:55:48.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 388 LR: 0.009922740634318495 Training loss: 7.318877220153809
2025-12-09 11:55:48.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 389 LR: 0.009922206435578323 Training loss: 7.196369171142578
2025-12-09 11:55:48.300 | INFO     | __main__:train:25 - Epoch: 0 Step: 390 LR: 0.009921670410854518 Training loss: 7.1927971839904785
2025-12-09 11:55:48.384 | INFO     | __main__:train:25 - Epoch: 0 Step: 391 LR: 0.009921132560345929 Training loss: 8.093311309814453
2025-12-09 11:55:48.463 | INFO     | __main__:train:25 - Epoch: 0 Step: 392 LR: 0.009920592884252082 Training loss: 6.079619884490967
2025-12-09 11:55:48.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 393 LR: 0.009920051382773179 Training loss: 7.387023448944092
2025-12-09 11:55:48.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 394 LR: 0.009919508056110101 Training loss: 7.181493282318115
2025-12-09 11:55:48.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 395 LR: 0.009918962904464406 Training loss: 6.584753513336182
2025-12-09 11:55:48.779 | INFO     | __main__:train:25 - Epoch: 0 Step: 396 LR: 0.009918415928038325 Training loss: 7.621324062347412
2025-12-09 11:55:48.858 | INFO     | __main__:train:25 - Epoch: 0 Step: 397 LR: 0.009917867127034772 Training loss: 6.448436260223389
2025-12-09 11:55:48.936 | INFO     | __main__:train:25 - Epoch: 0 Step: 398 LR: 0.009917316501657334 Training loss: 7.422311305999756
2025-12-09 11:55:49.015 | INFO     | __main__:train:25 - Epoch: 0 Step: 399 LR: 0.009916764052110274 Training loss: 6.740147113800049
2025-12-09 11:55:49.093 | INFO     | __main__:train:25 - Epoch: 0 Step: 400 LR: 0.009916209778598535 Training loss: 7.16002082824707
2025-12-09 11:55:49.171 | INFO     | __main__:train:25 - Epoch: 0 Step: 401 LR: 0.009915653681327737 Training loss: 7.076687812805176
2025-12-09 11:55:49.250 | INFO     | __main__:train:25 - Epoch: 0 Step: 402 LR: 0.009915095760504169 Training loss: 7.56663703918457
2025-12-09 11:55:49.334 | INFO     | __main__:train:25 - Epoch: 0 Step: 403 LR: 0.009914536016334808 Training loss: 7.300405502319336
2025-12-09 11:55:49.414 | INFO     | __main__:train:25 - Epoch: 0 Step: 404 LR: 0.009913974449027297 Training loss: 7.07456111907959
2025-12-09 11:55:49.494 | INFO     | __main__:train:25 - Epoch: 0 Step: 405 LR: 0.009913411058789963 Training loss: 7.459012031555176
2025-12-09 11:55:49.573 | INFO     | __main__:train:25 - Epoch: 0 Step: 406 LR: 0.009912845845831806 Training loss: 7.433396339416504
2025-12-09 11:55:49.651 | INFO     | __main__:train:25 - Epoch: 0 Step: 407 LR: 0.009912278810362498 Training loss: 7.391078472137451
2025-12-09 11:55:49.730 | INFO     | __main__:train:25 - Epoch: 0 Step: 408 LR: 0.009911709952592397 Training loss: 7.301466464996338
2025-12-09 11:55:49.809 | INFO     | __main__:train:25 - Epoch: 0 Step: 409 LR: 0.009911139272732527 Training loss: 7.140738010406494
2025-12-09 11:55:49.888 | INFO     | __main__:train:25 - Epoch: 0 Step: 410 LR: 0.009910566770994594 Training loss: 7.147168159484863
2025-12-09 11:55:49.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 411 LR: 0.00990999244759098 Training loss: 7.102423191070557
2025-12-09 11:55:50.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 412 LR: 0.009909416302734736 Training loss: 7.446854114532471
2025-12-09 11:55:50.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 413 LR: 0.009908838336639598 Training loss: 7.176449775695801
2025-12-09 11:55:50.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 414 LR: 0.00990825854951997 Training loss: 7.2059855461120605
2025-12-09 11:55:50.286 | INFO     | __main__:train:25 - Epoch: 0 Step: 415 LR: 0.009907676941590938 Training loss: 7.129060745239258
2025-12-09 11:55:50.366 | INFO     | __main__:train:25 - Epoch: 0 Step: 416 LR: 0.009907093513068259 Training loss: 7.3673553466796875
2025-12-09 11:55:50.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 417 LR: 0.009906508264168366 Training loss: 6.877706050872803
2025-12-09 11:55:50.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 418 LR: 0.009905921195108367 Training loss: 7.19063663482666
2025-12-09 11:55:50.602 | INFO     | __main__:train:25 - Epoch: 0 Step: 419 LR: 0.00990533230610605 Training loss: 7.128118991851807
2025-12-09 11:55:50.681 | INFO     | __main__:train:25 - Epoch: 0 Step: 420 LR: 0.00990474159737987 Training loss: 7.211218357086182
2025-12-09 11:55:50.759 | INFO     | __main__:train:25 - Epoch: 0 Step: 421 LR: 0.009904149069148962 Training loss: 7.742252826690674
2025-12-09 11:55:50.837 | INFO     | __main__:train:25 - Epoch: 0 Step: 422 LR: 0.009903554721633139 Training loss: 7.25877571105957
2025-12-09 11:55:50.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 423 LR: 0.00990295855505288 Training loss: 7.667971611022949
2025-12-09 11:55:50.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 424 LR: 0.009902360569629348 Training loss: 7.386274337768555
2025-12-09 11:55:51.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 425 LR: 0.009901760765584376 Training loss: 7.091309070587158
2025-12-09 11:55:51.151 | INFO     | __main__:train:25 - Epoch: 0 Step: 426 LR: 0.00990115914314047 Training loss: 7.73568868637085
2025-12-09 11:55:51.236 | INFO     | __main__:train:25 - Epoch: 0 Step: 427 LR: 0.009900555702520816 Training loss: 7.9177632331848145
2025-12-09 11:55:51.315 | INFO     | __main__:train:25 - Epoch: 0 Step: 428 LR: 0.00989995044394927 Training loss: 7.547481060028076
2025-12-09 11:55:51.395 | INFO     | __main__:train:25 - Epoch: 0 Step: 429 LR: 0.009899343367650365 Training loss: 7.212563514709473
2025-12-09 11:55:51.474 | INFO     | __main__:train:25 - Epoch: 0 Step: 430 LR: 0.009898734473849305 Training loss: 6.888923168182373
2025-12-09 11:55:51.552 | INFO     | __main__:train:25 - Epoch: 0 Step: 431 LR: 0.00989812376277197 Training loss: 7.3718791007995605
2025-12-09 11:55:51.632 | INFO     | __main__:train:25 - Epoch: 0 Step: 432 LR: 0.00989751123464492 Training loss: 7.229673862457275
2025-12-09 11:55:51.711 | INFO     | __main__:train:25 - Epoch: 0 Step: 433 LR: 0.009896896889695377 Training loss: 7.275705337524414
2025-12-09 11:55:51.789 | INFO     | __main__:train:25 - Epoch: 0 Step: 434 LR: 0.009896280728151248 Training loss: 6.89022159576416
2025-12-09 11:55:51.868 | INFO     | __main__:train:25 - Epoch: 0 Step: 435 LR: 0.009895662750241108 Training loss: 7.184666156768799
2025-12-09 11:55:51.947 | INFO     | __main__:train:25 - Epoch: 0 Step: 436 LR: 0.009895042956194209 Training loss: 7.316910266876221
2025-12-09 11:55:52.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 437 LR: 0.009894421346240473 Training loss: 7.122453689575195
2025-12-09 11:55:52.104 | INFO     | __main__:train:25 - Epoch: 0 Step: 438 LR: 0.009893797920610495 Training loss: 7.1011857986450195
2025-12-09 11:55:52.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 439 LR: 0.009893172679535553 Training loss: 7.576826572418213
2025-12-09 11:55:52.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 440 LR: 0.009892545623247586 Training loss: 7.201186180114746
2025-12-09 11:55:52.348 | INFO     | __main__:train:25 - Epoch: 0 Step: 441 LR: 0.009891916751979217 Training loss: 6.924297332763672
2025-12-09 11:55:52.427 | INFO     | __main__:train:25 - Epoch: 0 Step: 442 LR: 0.009891286065963734 Training loss: 7.502424240112305
2025-12-09 11:55:52.506 | INFO     | __main__:train:25 - Epoch: 0 Step: 443 LR: 0.0098906535654351 Training loss: 7.415647983551025
2025-12-09 11:55:52.585 | INFO     | __main__:train:25 - Epoch: 0 Step: 444 LR: 0.00989001925062796 Training loss: 7.095068454742432
2025-12-09 11:55:52.664 | INFO     | __main__:train:25 - Epoch: 0 Step: 445 LR: 0.009889383121777617 Training loss: 7.349898338317871
2025-12-09 11:55:52.742 | INFO     | __main__:train:25 - Epoch: 0 Step: 446 LR: 0.00988874517912006 Training loss: 6.860998153686523
2025-12-09 11:55:52.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 447 LR: 0.009888105422891941 Training loss: 7.2267279624938965
2025-12-09 11:55:52.899 | INFO     | __main__:train:25 - Epoch: 0 Step: 448 LR: 0.009887463853330595 Training loss: 7.5100603103637695
2025-12-09 11:55:52.978 | INFO     | __main__:train:25 - Epoch: 0 Step: 449 LR: 0.009886820470674018 Training loss: 7.483155727386475
2025-12-09 11:55:53.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 450 LR: 0.00988617527516089 Training loss: 7.121877670288086
2025-12-09 11:55:53.142 | INFO     | __main__:train:25 - Epoch: 0 Step: 451 LR: 0.009885528267030555 Training loss: 7.0699543952941895
2025-12-09 11:55:53.222 | INFO     | __main__:train:25 - Epoch: 0 Step: 452 LR: 0.009884879446523035 Training loss: 7.506855010986328
2025-12-09 11:55:53.301 | INFO     | __main__:train:25 - Epoch: 0 Step: 453 LR: 0.00988422881387902 Training loss: 7.444037914276123
2025-12-09 11:55:53.380 | INFO     | __main__:train:25 - Epoch: 0 Step: 454 LR: 0.009883576369339874 Training loss: 7.08614444732666
2025-12-09 11:55:53.459 | INFO     | __main__:train:25 - Epoch: 0 Step: 455 LR: 0.009882922113147636 Training loss: 6.958566665649414
2025-12-09 11:55:53.538 | INFO     | __main__:train:25 - Epoch: 0 Step: 456 LR: 0.009882266045545011 Training loss: 7.310863971710205
2025-12-09 11:55:53.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 457 LR: 0.009881608166775383 Training loss: 6.895522117614746
2025-12-09 11:55:53.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 458 LR: 0.009880948477082803 Training loss: 7.957093715667725
2025-12-09 11:55:53.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 459 LR: 0.009880286976711991 Training loss: 6.952081680297852
2025-12-09 11:55:53.852 | INFO     | __main__:train:25 - Epoch: 0 Step: 460 LR: 0.00987962366590835 Training loss: 7.425051212310791
2025-12-09 11:55:53.931 | INFO     | __main__:train:25 - Epoch: 0 Step: 461 LR: 0.009878958544917943 Training loss: 7.330679416656494
2025-12-09 11:55:54.010 | INFO     | __main__:train:25 - Epoch: 0 Step: 462 LR: 0.00987829161398751 Training loss: 6.972446918487549
2025-12-09 11:55:54.094 | INFO     | __main__:train:25 - Epoch: 0 Step: 463 LR: 0.00987762287336446 Training loss: 6.77932596206665
2025-12-09 11:55:54.174 | INFO     | __main__:train:25 - Epoch: 0 Step: 464 LR: 0.009876952323296877 Training loss: 7.257870197296143
2025-12-09 11:55:54.253 | INFO     | __main__:train:25 - Epoch: 0 Step: 465 LR: 0.009876279964033513 Training loss: 7.450436592102051
2025-12-09 11:55:54.332 | INFO     | __main__:train:25 - Epoch: 0 Step: 466 LR: 0.00987560579582379 Training loss: 6.995098114013672
2025-12-09 11:55:54.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 467 LR: 0.009874929818917806 Training loss: 7.075699806213379
2025-12-09 11:55:54.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 468 LR: 0.009874252033566327 Training loss: 7.014240741729736
2025-12-09 11:55:54.568 | INFO     | __main__:train:25 - Epoch: 0 Step: 469 LR: 0.009873572440020791 Training loss: 7.252887725830078
2025-12-09 11:55:54.647 | INFO     | __main__:train:25 - Epoch: 0 Step: 470 LR: 0.0098728910385333 Training loss: 7.462603569030762
2025-12-09 11:55:54.725 | INFO     | __main__:train:25 - Epoch: 0 Step: 471 LR: 0.009872207829356642 Training loss: 7.457915782928467
2025-12-09 11:55:54.804 | INFO     | __main__:train:25 - Epoch: 0 Step: 472 LR: 0.009871522812744256 Training loss: 6.9056267738342285
2025-12-09 11:55:54.882 | INFO     | __main__:train:25 - Epoch: 0 Step: 473 LR: 0.009870835988950269 Training loss: 7.073171615600586
2025-12-09 11:55:54.960 | INFO     | __main__:train:25 - Epoch: 0 Step: 474 LR: 0.009870147358229466 Training loss: 6.784204006195068
2025-12-09 11:55:55.045 | INFO     | __main__:train:25 - Epoch: 0 Step: 475 LR: 0.009869456920837311 Training loss: 6.880091190338135
2025-12-09 11:55:55.124 | INFO     | __main__:train:25 - Epoch: 0 Step: 476 LR: 0.009868764677029934 Training loss: 6.696523666381836
2025-12-09 11:55:55.203 | INFO     | __main__:train:25 - Epoch: 0 Step: 477 LR: 0.009868070627064135 Training loss: 6.655722141265869
2025-12-09 11:55:55.282 | INFO     | __main__:train:25 - Epoch: 0 Step: 478 LR: 0.009867374771197384 Training loss: 6.71453332901001
2025-12-09 11:55:55.360 | INFO     | __main__:train:25 - Epoch: 0 Step: 479 LR: 0.009866677109687822 Training loss: 7.243475437164307
2025-12-09 11:55:55.439 | INFO     | __main__:train:25 - Epoch: 0 Step: 480 LR: 0.009865977642794259 Training loss: 7.150756359100342
2025-12-09 11:55:55.517 | INFO     | __main__:train:25 - Epoch: 0 Step: 481 LR: 0.009865276370776178 Training loss: 7.403965950012207
2025-12-09 11:55:55.596 | INFO     | __main__:train:25 - Epoch: 0 Step: 482 LR: 0.009864573293893723 Training loss: 7.384838104248047
2025-12-09 11:55:55.674 | INFO     | __main__:train:25 - Epoch: 0 Step: 483 LR: 0.00986386841240772 Training loss: 7.1348958015441895
2025-12-09 11:55:55.753 | INFO     | __main__:train:25 - Epoch: 0 Step: 484 LR: 0.009863161726579655 Training loss: 6.932092666625977
2025-12-09 11:55:55.831 | INFO     | __main__:train:25 - Epoch: 0 Step: 485 LR: 0.009862453236671684 Training loss: 7.008739948272705
2025-12-09 11:55:55.910 | INFO     | __main__:train:25 - Epoch: 0 Step: 486 LR: 0.009861742942946639 Training loss: 6.948450088500977
2025-12-09 11:55:55.993 | INFO     | __main__:train:25 - Epoch: 0 Step: 487 LR: 0.009861030845668013 Training loss: 7.526383399963379
2025-12-09 11:55:56.073 | INFO     | __main__:train:25 - Epoch: 0 Step: 488 LR: 0.009860316945099973 Training loss: 6.847995281219482
2025-12-09 11:55:56.152 | INFO     | __main__:train:25 - Epoch: 0 Step: 489 LR: 0.009859601241507353 Training loss: 7.278702735900879
2025-12-09 11:55:56.231 | INFO     | __main__:train:25 - Epoch: 0 Step: 490 LR: 0.009858883735155657 Training loss: 7.1369147300720215
2025-12-09 11:55:56.310 | INFO     | __main__:train:25 - Epoch: 0 Step: 491 LR: 0.009858164426311058 Training loss: 6.309526443481445
2025-12-09 11:55:56.389 | INFO     | __main__:train:25 - Epoch: 0 Step: 492 LR: 0.009857443315240397 Training loss: 6.9638566970825195
2025-12-09 11:55:56.468 | INFO     | __main__:train:25 - Epoch: 0 Step: 493 LR: 0.00985672040221118 Training loss: 6.970827102661133
2025-12-09 11:55:56.546 | INFO     | __main__:train:25 - Epoch: 0 Step: 494 LR: 0.00985599568749159 Training loss: 6.989009380340576
2025-12-09 11:55:56.625 | INFO     | __main__:train:25 - Epoch: 0 Step: 495 LR: 0.00985526917135047 Training loss: 7.352584362030029
2025-12-09 11:55:56.703 | INFO     | __main__:train:25 - Epoch: 0 Step: 496 LR: 0.009854540854057337 Training loss: 6.9328227043151855
2025-12-09 11:55:56.782 | INFO     | __main__:train:25 - Epoch: 0 Step: 497 LR: 0.00985381073588237 Training loss: 7.270742893218994
2025-12-09 11:55:56.861 | INFO     | __main__:train:25 - Epoch: 0 Step: 498 LR: 0.009853078817096423 Training loss: 7.246467113494873
2025-12-09 11:55:56.945 | INFO     | __main__:train:25 - Epoch: 0 Step: 499 LR: 0.009852345097971017 Training loss: 6.669419288635254
2025-12-09 11:55:57.025 | INFO     | __main__:train:25 - Epoch: 0 Step: 500 LR: 0.009851609578778332 Training loss: 6.909061908721924
2025-12-09 11:55:57.105 | INFO     | __main__:train:25 - Epoch: 0 Step: 501 LR: 0.009850872259791229 Training loss: 6.624825477600098
2025-12-09 11:55:57.184 | INFO     | __main__:train:25 - Epoch: 0 Step: 502 LR: 0.009850133141283225 Training loss: 7.049295425415039
2025-12-09 11:55:57.262 | INFO     | __main__:train:25 - Epoch: 0 Step: 503 LR: 0.009849392223528514 Training loss: 6.941177845001221
2025-12-09 11:55:57.341 | INFO     | __main__:train:25 - Epoch: 0 Step: 504 LR: 0.00984864950680195 Training loss: 6.993532180786133
2025-12-09 11:55:57.419 | INFO     | __main__:train:25 - Epoch: 0 Step: 505 LR: 0.00984790499137906 Training loss: 7.293515205383301
2025-12-09 11:55:57.498 | INFO     | __main__:train:25 - Epoch: 0 Step: 506 LR: 0.009847158677536034 Training loss: 7.214664936065674
2025-12-09 11:55:57.577 | INFO     | __main__:train:25 - Epoch: 0 Step: 507 LR: 0.00984641056554973 Training loss: 7.866571426391602
2025-12-09 11:55:57.655 | INFO     | __main__:train:25 - Epoch: 0 Step: 508 LR: 0.009845660655697678 Training loss: 7.327062129974365
2025-12-09 11:55:57.734 | INFO     | __main__:train:25 - Epoch: 0 Step: 509 LR: 0.009844908948258067 Training loss: 7.328981876373291
2025-12-09 11:55:57.812 | INFO     | __main__:train:25 - Epoch: 0 Step: 510 LR: 0.009844155443509759 Training loss: 7.042409896850586
2025-12-09 11:55:57.897 | INFO     | __main__:train:25 - Epoch: 0 Step: 511 LR: 0.009843400141732279 Training loss: 7.015265941619873
2025-12-09 11:55:57.977 | INFO     | __main__:train:25 - Epoch: 0 Step: 512 LR: 0.009842643043205822 Training loss: 6.898802757263184
2025-12-09 11:55:58.056 | INFO     | __main__:train:25 - Epoch: 0 Step: 513 LR: 0.009841884148211246 Training loss: 7.464487552642822
2025-12-09 11:55:58.135 | INFO     | __main__:train:25 - Epoch: 0 Step: 514 LR: 0.009841123457030079 Training loss: 7.231400966644287
2025-12-09 11:55:58.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 515 LR: 0.009840360969944511 Training loss: 7.3331780433654785
2025-12-09 11:55:58.292 | INFO     | __main__:train:25 - Epoch: 0 Step: 516 LR: 0.009839596687237401 Training loss: 7.020747661590576
2025-12-09 11:55:58.371 | INFO     | __main__:train:25 - Epoch: 0 Step: 517 LR: 0.009838830609192278 Training loss: 6.348623275756836
2025-12-09 11:55:58.450 | INFO     | __main__:train:25 - Epoch: 0 Step: 518 LR: 0.009838062736093327 Training loss: 7.226046562194824
2025-12-09 11:55:58.528 | INFO     | __main__:train:25 - Epoch: 0 Step: 519 LR: 0.009837293068225408 Training loss: 7.493988037109375
2025-12-09 11:55:58.607 | INFO     | __main__:train:25 - Epoch: 0 Step: 520 LR: 0.009836521605874044 Training loss: 7.294822692871094
2025-12-09 11:55:58.685 | INFO     | __main__:train:25 - Epoch: 0 Step: 521 LR: 0.009835748349325421 Training loss: 6.863480567932129
2025-12-09 11:55:58.764 | INFO     | __main__:train:25 - Epoch: 0 Step: 522 LR: 0.009834973298866394 Training loss: 7.248147010803223
2025-12-09 11:55:58.849 | INFO     | __main__:train:25 - Epoch: 0 Step: 523 LR: 0.009834196454784484 Training loss: 7.423813343048096
2025-12-09 11:55:58.928 | INFO     | __main__:train:25 - Epoch: 0 Step: 524 LR: 0.009833417817367874 Training loss: 7.108026027679443
2025-12-09 11:55:59.007 | INFO     | __main__:train:25 - Epoch: 0 Step: 525 LR: 0.009832637386905412 Training loss: 7.03368616104126
2025-12-09 11:55:59.087 | INFO     | __main__:train:25 - Epoch: 0 Step: 526 LR: 0.009831855163686617 Training loss: 6.968229293823242
2025-12-09 11:55:59.165 | INFO     | __main__:train:25 - Epoch: 0 Step: 527 LR: 0.009831071148001667 Training loss: 6.509942531585693
2025-12-09 11:55:59.244 | INFO     | __main__:train:25 - Epoch: 0 Step: 528 LR: 0.009830285340141407 Training loss: 7.395468711853027
2025-12-09 11:55:59.323 | INFO     | __main__:train:25 - Epoch: 0 Step: 529 LR: 0.009829497740397349 Training loss: 6.174252510070801
2025-12-09 11:55:59.402 | INFO     | __main__:train:25 - Epoch: 0 Step: 530 LR: 0.009828708349061663 Training loss: 7.301041126251221
2025-12-09 11:55:59.480 | INFO     | __main__:train:25 - Epoch: 0 Step: 531 LR: 0.009827917166427195 Training loss: 8.660079956054688
2025-12-09 11:55:59.559 | INFO     | __main__:train:25 - Epoch: 0 Step: 532 LR: 0.009827124192787444 Training loss: 7.381092548370361
2025-12-09 11:55:59.637 | INFO     | __main__:train:25 - Epoch: 0 Step: 533 LR: 0.00982632942843658 Training loss: 7.53005838394165
2025-12-09 11:55:59.715 | INFO     | __main__:train:25 - Epoch: 0 Step: 534 LR: 0.009825532873669433 Training loss: 7.217495918273926
2025-12-09 11:55:59.800 | INFO     | __main__:train:25 - Epoch: 0 Step: 535 LR: 0.009824734528781505 Training loss: 7.232083320617676
2025-12-09 11:55:59.880 | INFO     | __main__:train:25 - Epoch: 0 Step: 536 LR: 0.009823934394068952 Training loss: 7.371476650238037
2025-12-09 11:55:59.959 | INFO     | __main__:train:25 - Epoch: 0 Step: 537 LR: 0.009823132469828601 Training loss: 7.252811908721924
2025-12-09 11:56:00.038 | INFO     | __main__:train:25 - Epoch: 0 Step: 538 LR: 0.009822328756357942 Training loss: 7.0067009925842285
2025-12-09 11:56:00.117 | INFO     | __main__:train:25 - Epoch: 0 Step: 539 LR: 0.009821523253955123 Training loss: 7.005199909210205
2025-12-09 11:56:00.196 | INFO     | __main__:train:25 - Epoch: 0 Step: 540 LR: 0.009820715962918964 Training loss: 7.170434474945068
2025-12-09 11:56:00.276 | INFO     | __main__:train:25 - Epoch: 0 Step: 541 LR: 0.009819906883548942 Training loss: 7.268289566040039
2025-12-09 11:56:00.354 | INFO     | __main__:train:25 - Epoch: 0 Step: 542 LR: 0.009819096016145203 Training loss: 6.920798301696777
2025-12-09 11:56:00.433 | INFO     | __main__:train:25 - Epoch: 0 Step: 543 LR: 0.00981828336100855 Training loss: 7.285030364990234
2025-12-09 11:56:00.512 | INFO     | __main__:train:25 - Epoch: 0 Step: 544 LR: 0.009817468918440455 Training loss: 7.267150402069092
2025-12-09 11:56:00.591 | INFO     | __main__:train:25 - Epoch: 0 Step: 545 LR: 0.009816652688743049 Training loss: 7.128125190734863
2025-12-09 11:56:00.670 | INFO     | __main__:train:25 - Epoch: 0 Step: 546 LR: 0.009815834672219127 Training loss: 7.1963725090026855
2025-12-09 11:56:00.757 | INFO     | __main__:train:25 - Epoch: 0 Step: 547 LR: 0.00981501486917215 Training loss: 6.773182392120361
2025-12-09 11:56:00.836 | INFO     | __main__:train:25 - Epoch: 0 Step: 548 LR: 0.009814193279906236 Training loss: 6.871586799621582
2025-12-09 11:56:00.916 | INFO     | __main__:train:25 - Epoch: 0 Step: 549 LR: 0.00981336990472617 Training loss: 7.332981586456299
2025-12-09 11:56:00.995 | INFO     | __main__:train:25 - Epoch: 0 Step: 550 LR: 0.0098125447439374 Training loss: 7.150868892669678
2025-12-09 11:56:01.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 551 LR: 0.009811717797846033 Training loss: 6.496454238891602
2025-12-09 11:56:01.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 552 LR: 0.00981088906675884 Training loss: 6.987274169921875
2025-12-09 11:56:01.233 | INFO     | __main__:train:25 - Epoch: 0 Step: 553 LR: 0.009810058550983254 Training loss: 7.063376426696777
2025-12-09 11:56:01.312 | INFO     | __main__:train:25 - Epoch: 0 Step: 554 LR: 0.009809226250827372 Training loss: 6.942118167877197
2025-12-09 11:56:01.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 555 LR: 0.009808392166599948 Training loss: 7.026293754577637
2025-12-09 11:56:01.469 | INFO     | __main__:train:25 - Epoch: 0 Step: 556 LR: 0.009807556298610402 Training loss: 7.121580123901367
2025-12-09 11:56:01.548 | INFO     | __main__:train:25 - Epoch: 0 Step: 557 LR: 0.009806718647168818 Training loss: 7.34888219833374
2025-12-09 11:56:01.627 | INFO     | __main__:train:25 - Epoch: 0 Step: 558 LR: 0.009805879212585933 Training loss: 7.229014873504639
2025-12-09 11:56:01.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 559 LR: 0.009805037995173155 Training loss: 7.0859150886535645
2025-12-09 11:56:01.792 | INFO     | __main__:train:25 - Epoch: 0 Step: 560 LR: 0.009804194995242549 Training loss: 6.713641166687012
2025-12-09 11:56:01.871 | INFO     | __main__:train:25 - Epoch: 0 Step: 561 LR: 0.009803350213106837 Training loss: 6.762513160705566
2025-12-09 11:56:01.951 | INFO     | __main__:train:25 - Epoch: 0 Step: 562 LR: 0.00980250364907941 Training loss: 7.578720569610596
2025-12-09 11:56:02.030 | INFO     | __main__:train:25 - Epoch: 0 Step: 563 LR: 0.009801655303474318 Training loss: 7.411484718322754
2025-12-09 11:56:02.109 | INFO     | __main__:train:25 - Epoch: 0 Step: 564 LR: 0.009800805176606269 Training loss: 7.395954132080078
2025-12-09 11:56:02.189 | INFO     | __main__:train:25 - Epoch: 0 Step: 565 LR: 0.009799953268790632 Training loss: 7.332022190093994
2025-12-09 11:56:02.268 | INFO     | __main__:train:25 - Epoch: 0 Step: 566 LR: 0.00979909958034344 Training loss: 6.975959777832031
2025-12-09 11:56:02.347 | INFO     | __main__:train:25 - Epoch: 0 Step: 567 LR: 0.009798244111581382 Training loss: 6.813775539398193
2025-12-09 11:56:02.425 | INFO     | __main__:train:25 - Epoch: 0 Step: 568 LR: 0.009797386862821814 Training loss: 7.016226291656494
2025-12-09 11:56:02.504 | INFO     | __main__:train:25 - Epoch: 0 Step: 569 LR: 0.009796527834382745 Training loss: 7.335012435913086
2025-12-09 11:56:02.583 | INFO     | __main__:train:25 - Epoch: 0 Step: 570 LR: 0.009795667026582846 Training loss: 6.909502983093262
2025-12-09 11:56:02.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 571 LR: 0.009794804439741454 Training loss: 7.027585029602051
2025-12-09 11:56:02.748 | INFO     | __main__:train:25 - Epoch: 0 Step: 572 LR: 0.00979394007417856 Training loss: 7.693682670593262
2025-12-09 11:56:02.827 | INFO     | __main__:train:25 - Epoch: 0 Step: 573 LR: 0.009793073930214816 Training loss: 6.9458699226379395
2025-12-09 11:56:02.906 | INFO     | __main__:train:25 - Epoch: 0 Step: 574 LR: 0.009792206008171534 Training loss: 7.137169361114502
2025-12-09 11:56:02.984 | INFO     | __main__:train:25 - Epoch: 0 Step: 575 LR: 0.009791336308370686 Training loss: 7.245114326477051
2025-12-09 11:56:03.063 | INFO     | __main__:train:25 - Epoch: 0 Step: 576 LR: 0.009790464831134903 Training loss: 7.050073146820068
2025-12-09 11:56:03.141 | INFO     | __main__:train:25 - Epoch: 0 Step: 577 LR: 0.009789591576787476 Training loss: 7.081058979034424
2025-12-09 11:56:03.220 | INFO     | __main__:train:25 - Epoch: 0 Step: 578 LR: 0.009788716545652353 Training loss: 7.2676005363464355
2025-12-09 11:56:03.298 | INFO     | __main__:train:25 - Epoch: 0 Step: 579 LR: 0.009787839738054147 Training loss: 7.00048828125
2025-12-09 11:56:03.377 | INFO     | __main__:train:25 - Epoch: 0 Step: 580 LR: 0.009786961154318121 Training loss: 6.978905200958252
2025-12-09 11:56:03.455 | INFO     | __main__:train:25 - Epoch: 0 Step: 581 LR: 0.009786080794770207 Training loss: 7.14905309677124
2025-12-09 11:56:03.534 | INFO     | __main__:train:25 - Epoch: 0 Step: 582 LR: 0.009785198659736987 Training loss: 7.4001264572143555
2025-12-09 11:56:03.618 | INFO     | __main__:train:25 - Epoch: 0 Step: 583 LR: 0.009784314749545706 Training loss: 6.86639928817749
2025-12-09 11:56:03.697 | INFO     | __main__:train:25 - Epoch: 0 Step: 584 LR: 0.00978342906452427 Training loss: 7.276663780212402
2025-12-09 11:56:03.776 | INFO     | __main__:train:25 - Epoch: 0 Step: 585 LR: 0.009782541605001235 Training loss: 7.112419128417969
2025-12-09 11:56:03.854 | INFO     | __main__:train:25 - Epoch: 0 Step: 586 LR: 0.009781652371305825 Training loss: 7.208958148956299
2025-12-09 11:56:03.933 | INFO     | __main__:train:25 - Epoch: 0 Step: 587 LR: 0.009780761363767914 Training loss: 8.22702693939209
2025-12-09 11:56:04.012 | INFO     | __main__:train:25 - Epoch: 0 Step: 588 LR: 0.009779868582718041 Training loss: 6.9339375495910645
2025-12-09 11:56:04.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 589 LR: 0.009778974028487398 Training loss: 7.501800060272217
2025-12-09 11:56:04.169 | INFO     | __main__:train:25 - Epoch: 0 Step: 590 LR: 0.009778077701407838 Training loss: 7.175399303436279
2025-12-09 11:56:04.248 | INFO     | __main__:train:25 - Epoch: 0 Step: 591 LR: 0.009777179601811866 Training loss: 7.14601993560791
2025-12-09 11:56:04.327 | INFO     | __main__:train:25 - Epoch: 0 Step: 592 LR: 0.009776279730032653 Training loss: 7.3351545333862305
2025-12-09 11:56:04.405 | INFO     | __main__:train:25 - Epoch: 0 Step: 593 LR: 0.009775378086404022 Training loss: 7.196518898010254
2025-12-09 11:56:04.484 | INFO     | __main__:train:25 - Epoch: 0 Step: 594 LR: 0.009774474671260455 Training loss: 7.312355995178223
2025-12-09 11:56:04.569 | INFO     | __main__:train:25 - Epoch: 0 Step: 595 LR: 0.00977356948493709 Training loss: 7.091278553009033
2025-12-09 11:56:04.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 596 LR: 0.00977266252776972 Training loss: 7.043217182159424
2025-12-09 11:56:04.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 597 LR: 0.009771753800094802 Training loss: 7.328257083892822
2025-12-09 11:56:04.808 | INFO     | __main__:train:25 - Epoch: 0 Step: 598 LR: 0.009770843302249442 Training loss: 6.895500659942627
2025-12-09 11:56:04.887 | INFO     | __main__:train:25 - Epoch: 0 Step: 599 LR: 0.009769931034571407 Training loss: 7.333732604980469
2025-12-09 11:56:04.966 | INFO     | __main__:train:25 - Epoch: 0 Step: 600 LR: 0.00976901699739912 Training loss: 7.285698890686035
2025-12-09 11:56:05.044 | INFO     | __main__:train:25 - Epoch: 0 Step: 601 LR: 0.009768101191071661 Training loss: 7.211524486541748
2025-12-09 11:56:05.123 | INFO     | __main__:train:25 - Epoch: 0 Step: 602 LR: 0.009767183615928763 Training loss: 7.861427307128906
2025-12-09 11:56:05.202 | INFO     | __main__:train:25 - Epoch: 0 Step: 603 LR: 0.009766264272310822 Training loss: 6.999772548675537
2025-12-09 11:56:05.280 | INFO     | __main__:train:25 - Epoch: 0 Step: 604 LR: 0.009765343160558878 Training loss: 7.924746036529541
2025-12-09 11:56:05.359 | INFO     | __main__:train:25 - Epoch: 0 Step: 605 LR: 0.009764420281014641 Training loss: 7.123581886291504
2025-12-09 11:56:05.437 | INFO     | __main__:train:25 - Epoch: 0 Step: 606 LR: 0.009763495634020467 Training loss: 7.027801036834717
2025-12-09 11:56:05.522 | INFO     | __main__:train:25 - Epoch: 0 Step: 607 LR: 0.009762569219919371 Training loss: 6.964165210723877
2025-12-09 11:56:05.601 | INFO     | __main__:train:25 - Epoch: 0 Step: 608 LR: 0.009761641039055026 Training loss: 7.700946807861328
2025-12-09 11:56:05.680 | INFO     | __main__:train:25 - Epoch: 0 Step: 609 LR: 0.009760711091771755 Training loss: 7.197073459625244
2025-12-09 11:56:05.760 | INFO     | __main__:train:25 - Epoch: 0 Step: 610 LR: 0.009759779378414542 Training loss: 6.9793877601623535
2025-12-09 11:56:05.838 | INFO     | __main__:train:25 - Epoch: 0 Step: 611 LR: 0.009758845899329021 Training loss: 7.17614221572876
2025-12-09 11:56:05.917 | INFO     | __main__:train:25 - Epoch: 0 Step: 612 LR: 0.009757910654861483 Training loss: 7.229683876037598
2025-12-09 11:56:05.996 | INFO     | __main__:train:25 - Epoch: 0 Step: 613 LR: 0.009756973645358876 Training loss: 7.1698317527771
2025-12-09 11:56:06.074 | INFO     | __main__:train:25 - Epoch: 0 Step: 614 LR: 0.009756034871168799 Training loss: 6.969210147857666
2025-12-09 11:56:06.153 | INFO     | __main__:train:25 - Epoch: 0 Step: 615 LR: 0.009755094332639512 Training loss: 7.2860589027404785
2025-12-09 11:56:06.232 | INFO     | __main__:train:25 - Epoch: 0 Step: 616 LR: 0.00975415203011992 Training loss: 7.205755233764648
2025-12-09 11:56:06.311 | INFO     | __main__:train:25 - Epoch: 0 Step: 617 LR: 0.00975320796395959 Training loss: 7.3187360763549805
2025-12-09 11:56:06.390 | INFO     | __main__:train:25 - Epoch: 0 Step: 618 LR: 0.009752262134508742 Training loss: 7.116626262664795
2025-12-09 11:56:06.475 | INFO     | __main__:train:25 - Epoch: 0 Step: 619 LR: 0.009751314542118247 Training loss: 7.409585952758789
2025-12-09 11:56:06.554 | INFO     | __main__:train:25 - Epoch: 0 Step: 620 LR: 0.009750365187139632 Training loss: 7.205497741699219
2025-12-09 11:56:06.633 | INFO     | __main__:train:25 - Epoch: 0 Step: 621 LR: 0.009749414069925078 Training loss: 6.966934680938721
2025-12-09 11:56:06.712 | INFO     | __main__:train:25 - Epoch: 0 Step: 622 LR: 0.00974846119082742 Training loss: 7.120182991027832
2025-12-09 11:56:06.791 | INFO     | __main__:train:25 - Epoch: 0 Step: 623 LR: 0.009747506550200145 Training loss: 6.7997283935546875
2025-12-09 11:56:06.870 | INFO     | __main__:train:25 - Epoch: 0 Step: 624 LR: 0.009746550148397396 Training loss: 7.234615802764893
2025-12-09 11:56:06.949 | INFO     | __main__:train:25 - Epoch: 0 Step: 625 LR: 0.00974559198577397 Training loss: 6.952595233917236
2025-12-09 11:56:07.028 | INFO     | __main__:train:25 - Epoch: 0 Step: 626 LR: 0.009744632062685311 Training loss: 6.686868667602539
2025-12-09 11:56:07.107 | INFO     | __main__:train:25 - Epoch: 0 Step: 627 LR: 0.009743670379487522 Training loss: 6.975579261779785
2025-12-09 11:56:07.185 | INFO     | __main__:train:25 - Epoch: 0 Step: 628 LR: 0.009742706936537358 Training loss: 6.965710163116455
2025-12-09 11:56:07.264 | INFO     | __main__:train:25 - Epoch: 0 Step: 629 LR: 0.009741741734192224 Training loss: 7.891019821166992
2025-12-09 11:56:07.342 | INFO     | __main__:train:25 - Epoch: 0 Step: 630 LR: 0.009740774772810181 Training loss: 7.502557277679443
2025-12-09 11:56:07.428 | INFO     | __main__:train:25 - Epoch: 0 Step: 631 LR: 0.009739806052749942 Training loss: 7.120981693267822
2025-12-09 11:56:07.507 | INFO     | __main__:train:25 - Epoch: 0 Step: 632 LR: 0.009738835574370872 Training loss: 7.251792907714844
2025-12-09 11:56:07.586 | INFO     | __main__:train:25 - Epoch: 0 Step: 633 LR: 0.009737863338032985 Training loss: 7.112079620361328
2025-12-09 11:56:07.665 | INFO     | __main__:train:25 - Epoch: 0 Step: 634 LR: 0.009736889344096951 Training loss: 6.772538185119629
2025-12-09 11:56:07.743 | INFO     | __main__:train:25 - Epoch: 0 Step: 635 LR: 0.009735913592924092 Training loss: 6.816474437713623
2025-12-09 11:56:07.821 | INFO     | __main__:train:25 - Epoch: 0 Step: 636 LR: 0.009734936084876382 Training loss: 7.0142130851745605
2025-12-09 11:56:07.900 | INFO     | __main__:train:25 - Epoch: 0 Step: 637 LR: 0.009733956820316443 Training loss: 7.03582239151001
2025-12-09 11:56:07.979 | INFO     | __main__:train:25 - Epoch: 0 Step: 638 LR: 0.009732975799607553 Training loss: 7.946193695068359
2025-12-09 11:56:08.057 | INFO     | __main__:train:25 - Epoch: 0 Step: 639 LR: 0.00973199302311364 Training loss: 6.737399578094482
2025-12-09 11:56:08.136 | INFO     | __main__:train:25 - Epoch: 0 Step: 640 LR: 0.009731008491199285 Training loss: 7.00885009765625
2025-12-09 11:56:08.214 | INFO     | __main__:train:25 - Epoch: 0 Step: 641 LR: 0.009730022204229714 Training loss: 7.170485973358154
2025-12-09 11:56:08.294 | INFO     | __main__:train:25 - Epoch: 0 Step: 642 LR: 0.009729034162570812 Training loss: 7.247425556182861
2025-12-09 11:56:08.379 | INFO     | __main__:train:25 - Epoch: 0 Step: 643 LR: 0.009728044366589108 Training loss: 7.153532981872559
2025-12-09 11:56:08.458 | INFO     | __main__:train:25 - Epoch: 0 Step: 644 LR: 0.009727052816651788 Training loss: 7.150241374969482
2025-12-09 11:56:08.537 | INFO     | __main__:train:25 - Epoch: 0 Step: 645 LR: 0.009726059513126686 Training loss: 7.003635883331299
2025-12-09 11:56:08.616 | INFO     | __main__:train:25 - Epoch: 0 Step: 646 LR: 0.009725064456382283 Training loss: 7.458043098449707
2025-12-09 11:56:08.695 | INFO     | __main__:train:25 - Epoch: 0 Step: 647 LR: 0.009724067646787717 Training loss: 7.35405969619751
2025-12-09 11:56:08.774 | INFO     | __main__:train:25 - Epoch: 0 Step: 648 LR: 0.00972306908471277 Training loss: 7.0142340660095215
2025-12-09 11:56:08.853 | INFO     | __main__:train:25 - Epoch: 0 Step: 649 LR: 0.009722068770527881 Training loss: 7.168453693389893
2025-12-09 11:56:08.932 | INFO     | __main__:train:25 - Epoch: 0 Step: 650 LR: 0.009721066704604134 Training loss: 7.077658176422119
2025-12-09 11:56:09.011 | INFO     | __main__:train:25 - Epoch: 0 Step: 651 LR: 0.00972006288731326 Training loss: 7.24127197265625
2025-12-09 11:56:09.090 | INFO     | __main__:train:25 - Epoch: 0 Step: 652 LR: 0.00971905731902765 Training loss: 6.82778787612915
2025-12-09 11:56:09.168 | INFO     | __main__:train:25 - Epoch: 0 Step: 653 LR: 0.009718050000120333 Training loss: 7.277169227600098
2025-12-09 11:56:09.246 | INFO     | __main__:train:25 - Epoch: 0 Step: 654 LR: 0.009717040930964996 Training loss: 7.243133068084717
2025-12-09 11:56:09.331 | INFO     | __main__:train:25 - Epoch: 0 Step: 655 LR: 0.009716030111935968 Training loss: 6.971852779388428
2025-12-09 11:56:09.411 | INFO     | __main__:train:25 - Epoch: 0 Step: 656 LR: 0.009715017543408233 Training loss: 7.422744274139404
2025-12-09 11:56:09.490 | INFO     | __main__:train:25 - Epoch: 0 Step: 657 LR: 0.009714003225757424 Training loss: 7.000168323516846
2025-12-09 11:56:09.570 | INFO     | __main__:train:25 - Epoch: 0 Step: 658 LR: 0.009712987159359818 Training loss: 6.811604976654053
2025-12-09 11:56:09.649 | INFO     | __main__:train:25 - Epoch: 0 Step: 659 LR: 0.009711969344592347 Training loss: 7.1781415939331055
2025-12-09 11:56:09.728 | INFO     | __main__:train:25 - Epoch: 0 Step: 660 LR: 0.009710949781832585 Training loss: 7.062676906585693
2025-12-09 11:56:09.807 | INFO     | __main__:train:25 - Epoch: 0 Step: 661 LR: 0.009709928471458759 Training loss: 7.143895149230957
2025-12-09 11:56:09.886 | INFO     | __main__:train:25 - Epoch: 0 Step: 662 LR: 0.009708905413849743 Training loss: 5.833603858947754
2025-12-09 11:56:09.965 | INFO     | __main__:train:25 - Epoch: 0 Step: 663 LR: 0.009707880609385058 Training loss: 6.667603015899658
2025-12-09 11:56:10.043 | INFO     | __main__:train:25 - Epoch: 0 Step: 664 LR: 0.009706854058444877 Training loss: 7.0289740562438965
2025-12-09 11:56:10.121 | INFO     | __main__:train:25 - Epoch: 0 Step: 665 LR: 0.009705825761410014 Training loss: 7.244795799255371
2025-12-09 11:56:10.200 | INFO     | __main__:train:25 - Epoch: 0 Step: 666 LR: 0.009704795718661938 Training loss: 7.071484088897705
2025-12-09 11:56:10.285 | INFO     | __main__:train:25 - Epoch: 0 Step: 667 LR: 0.00970376393058276 Training loss: 7.338198661804199
2025-12-09 11:56:10.365 | INFO     | __main__:train:25 - Epoch: 0 Step: 668 LR: 0.009702730397555245 Training loss: 7.124305248260498
2025-12-09 11:56:10.445 | INFO     | __main__:train:25 - Epoch: 0 Step: 669 LR: 0.009701695119962798 Training loss: 7.349289417266846
2025-12-09 11:56:10.524 | INFO     | __main__:train:25 - Epoch: 0 Step: 670 LR: 0.009700658098189475 Training loss: 7.263746738433838
2025-12-09 11:56:10.603 | INFO     | __main__:train:25 - Epoch: 0 Step: 671 LR: 0.009699619332619978 Training loss: 7.195834636688232
2025-12-09 11:56:10.682 | INFO     | __main__:train:25 - Epoch: 0 Step: 672 LR: 0.009698578823639658 Training loss: 7.1403703689575195
2025-12-09 11:56:10.761 | INFO     | __main__:train:25 - Epoch: 0 Step: 673 LR: 0.009697536571634508 Training loss: 6.811283111572266
2025-12-09 11:56:10.840 | INFO     | __main__:train:25 - Epoch: 0 Step: 674 LR: 0.009696492576991175 Training loss: 6.589407444000244
2025-12-09 11:56:10.918 | INFO     | __main__:train:25 - Epoch: 0 Step: 675 LR: 0.009695446840096945 Training loss: 7.294337749481201
2025-12-09 11:56:10.997 | INFO     | __main__:train:25 - Epoch: 0 Step: 676 LR: 0.009694399361339753 Training loss: 7.225009441375732
2025-12-09 11:56:11.075 | INFO     | __main__:train:25 - Epoch: 0 Step: 677 LR: 0.009693350141108182 Training loss: 7.108267307281494
2025-12-09 11:56:11.154 | INFO     | __main__:train:25 - Epoch: 0 Step: 678 LR: 0.00969229917979146 Training loss: 7.345263481140137
2025-12-09 11:56:11.239 | INFO     | __main__:train:25 - Epoch: 0 Step: 679 LR: 0.009691246477779459 Training loss: 7.612823009490967
2025-12-09 11:56:11.319 | INFO     | __main__:train:25 - Epoch: 0 Step: 680 LR: 0.0096901920354627 Training loss: 7.088704586029053
2025-12-09 11:56:11.398 | INFO     | __main__:train:25 - Epoch: 0 Step: 681 LR: 0.009689135853232349 Training loss: 7.222228527069092
2025-12-09 11:56:11.477 | INFO     | __main__:train:25 - Epoch: 0 Step: 682 LR: 0.009688077931480212 Training loss: 7.167717933654785
2025-12-09 11:56:11.556 | INFO     | __main__:train:25 - Epoch: 0 Step: 683 LR: 0.009687018270598749 Training loss: 6.818683624267578
2025-12-09 11:56:11.635 | INFO     | __main__:train:25 - Epoch: 0 Step: 684 LR: 0.009685956870981059 Training loss: 7.232278823852539
2025-12-09 11:56:11.714 | INFO     | __main__:train:25 - Epoch: 0 Step: 685 LR: 0.009684893733020887 Training loss: 7.154414176940918
2025-12-09 11:56:11.793 | INFO     | __main__:train:25 - Epoch: 0 Step: 686 LR: 0.009683828857112626 Training loss: 6.596502780914307
2025-12-09 11:56:11.872 | INFO     | __main__:train:25 - Epoch: 0 Step: 687 LR: 0.009682762243651308 Training loss: 6.161585330963135
2025-12-09 11:56:11.950 | INFO     | __main__:train:25 - Epoch: 0 Step: 688 LR: 0.009681693893032617 Training loss: 6.727372646331787
2025-12-09 11:56:12.029 | INFO     | __main__:train:25 - Epoch: 0 Step: 689 LR: 0.009680623805652875 Training loss: 7.043707370758057
2025-12-09 11:56:12.108 | INFO     | __main__:train:25 - Epoch: 0 Step: 690 LR: 0.009679551981909052 Training loss: 7.054770469665527
2025-12-09 11:56:12.193 | INFO     | __main__:train:25 - Epoch: 0 Step: 691 LR: 0.00967847842219876 Training loss: 7.484165668487549
2025-12-09 11:56:12.272 | INFO     | __main__:train:25 - Epoch: 0 Step: 692 LR: 0.009677403126920255 Training loss: 7.03688907623291
2025-12-09 11:56:12.351 | INFO     | __main__:train:25 - Epoch: 0 Step: 693 LR: 0.00967632609647244 Training loss: 7.07042932510376
2025-12-09 11:56:12.431 | INFO     | __main__:train:25 - Epoch: 0 Step: 694 LR: 0.009675247331254857 Training loss: 7.258984088897705
2025-12-09 11:56:12.510 | INFO     | __main__:train:25 - Epoch: 0 Step: 695 LR: 0.009674166831667696 Training loss: 7.2662506103515625
2025-12-09 11:56:12.589 | INFO     | __main__:train:25 - Epoch: 0 Step: 696 LR: 0.009673084598111788 Training loss: 6.933848857879639
2025-12-09 11:56:12.668 | INFO     | __main__:train:25 - Epoch: 0 Step: 697 LR: 0.009672000630988605 Training loss: 6.736988544464111
2025-12-09 11:56:12.747 | INFO     | __main__:train:25 - Epoch: 0 Step: 698 LR: 0.009670914930700268 Training loss: 6.871099472045898
2025-12-09 11:56:12.826 | INFO     | __main__:train:25 - Epoch: 0 Step: 699 LR: 0.009669827497649537 Training loss: 7.255423545837402
2025-12-09 11:56:12.905 | INFO     | __main__:train:25 - Epoch: 0 Step: 700 LR: 0.009668738332239813 Training loss: 7.132386684417725
2025-12-09 11:56:12.983 | INFO     | __main__:train:25 - Epoch: 0 Step: 701 LR: 0.009667647434875144 Training loss: 7.45217227935791
2025-12-09 11:56:13.062 | INFO     | __main__:train:25 - Epoch: 0 Step: 702 LR: 0.00966655480596022 Training loss: 6.95609188079834
2025-12-09 11:56:13.147 | INFO     | __main__:train:25 - Epoch: 0 Step: 703 LR: 0.009665460445900368 Training loss: 6.481606483459473
2025-12-09 11:56:13.226 | INFO     | __main__:train:25 - Epoch: 0 Step: 704 LR: 0.009664364355101564 Training loss: 7.234328269958496
2025-12-09 11:56:13.306 | INFO     | __main__:train:25 - Epoch: 0 Step: 705 LR: 0.009663266533970424 Training loss: 7.062373638153076
2025-12-09 11:56:13.385 | INFO     | __main__:train:25 - Epoch: 0 Step: 706 LR: 0.009662166982914203 Training loss: 7.104862689971924
2025-12-09 11:56:13.464 | INFO     | __main__:train:25 - Epoch: 0 Step: 707 LR: 0.0096610657023408 Training loss: 7.610682010650635
2025-12-09 11:56:13.543 | INFO     | __main__:train:25 - Epoch: 0 Step: 708 LR: 0.009659962692658756 Training loss: 7.147070407867432
2025-12-09 11:56:13.621 | INFO     | __main__:train:25 - Epoch: 0 Step: 709 LR: 0.009658857954277254 Training loss: 7.078472137451172
2025-12-09 11:56:13.700 | INFO     | __main__:train:25 - Epoch: 0 Step: 710 LR: 0.009657751487606114 Training loss: 6.751798629760742
2025-12-09 11:56:13.778 | INFO     | __main__:train:25 - Epoch: 0 Step: 711 LR: 0.009656643293055805 Training loss: 8.017505645751953
2025-12-09 11:56:13.857 | INFO     | __main__:train:25 - Epoch: 0 Step: 712 LR: 0.009655533371037426 Training loss: 6.932236671447754
2025-12-09 11:56:13.935 | INFO     | __main__:train:25 - Epoch: 0 Step: 713 LR: 0.009654421721962729 Training loss: 7.140132427215576
