2025-12-09 09:57:16.438 | INFO     | __main__:train:24 - Epoch: 0 Step: 0 LR: 1e-05 Training loss: 9.076559066772461
2025-12-09 09:57:16.465 | INFO     | __main__:train:24 - Epoch: 0 Step: 1 LR: 2e-05 Training loss: 9.076799392700195
2025-12-09 09:57:16.487 | INFO     | __main__:train:24 - Epoch: 0 Step: 2 LR: 3e-05 Training loss: 9.075735092163086
2025-12-09 09:57:16.502 | INFO     | __main__:train:24 - Epoch: 0 Step: 3 LR: 4e-05 Training loss: 9.076749801635742
2025-12-09 09:57:16.517 | INFO     | __main__:train:24 - Epoch: 0 Step: 4 LR: 5e-05 Training loss: 9.075913429260254
2025-12-09 09:57:16.530 | INFO     | __main__:train:24 - Epoch: 0 Step: 5 LR: 6e-05 Training loss: 9.076167106628418
2025-12-09 09:57:16.545 | INFO     | __main__:train:24 - Epoch: 0 Step: 6 LR: 7.000000000000001e-05 Training loss: 9.075984001159668
2025-12-09 09:57:16.560 | INFO     | __main__:train:24 - Epoch: 0 Step: 7 LR: 8e-05 Training loss: 9.076897621154785
2025-12-09 09:57:16.579 | INFO     | __main__:train:24 - Epoch: 0 Step: 8 LR: 8.999999999999999e-05 Training loss: 9.075640678405762
2025-12-09 09:57:16.593 | INFO     | __main__:train:24 - Epoch: 0 Step: 9 LR: 0.0001 Training loss: 9.076639175415039
2025-12-09 09:57:16.608 | INFO     | __main__:train:24 - Epoch: 0 Step: 10 LR: 0.00011 Training loss: 9.076066970825195
2025-12-09 09:57:16.623 | INFO     | __main__:train:24 - Epoch: 0 Step: 11 LR: 0.00012 Training loss: 9.075692176818848
2025-12-09 09:57:16.638 | INFO     | __main__:train:24 - Epoch: 0 Step: 12 LR: 0.00013000000000000002 Training loss: 9.076338768005371
2025-12-09 09:57:16.651 | INFO     | __main__:train:24 - Epoch: 0 Step: 13 LR: 0.00014000000000000001 Training loss: 9.076200485229492
2025-12-09 09:57:16.666 | INFO     | __main__:train:24 - Epoch: 0 Step: 14 LR: 0.00015 Training loss: 9.075607299804688
2025-12-09 09:57:16.689 | INFO     | __main__:train:24 - Epoch: 0 Step: 15 LR: 0.00016 Training loss: 9.075562477111816
2025-12-09 09:57:16.703 | INFO     | __main__:train:24 - Epoch: 0 Step: 16 LR: 0.00017 Training loss: 9.075687408447266
2025-12-09 09:57:16.718 | INFO     | __main__:train:24 - Epoch: 0 Step: 17 LR: 0.00017999999999999998 Training loss: 9.076262474060059
2025-12-09 09:57:16.732 | INFO     | __main__:train:24 - Epoch: 0 Step: 18 LR: 0.00019 Training loss: 9.076482772827148
2025-12-09 09:57:16.747 | INFO     | __main__:train:24 - Epoch: 0 Step: 19 LR: 0.0002 Training loss: 9.077095985412598
2025-12-09 09:57:16.762 | INFO     | __main__:train:24 - Epoch: 0 Step: 20 LR: 0.00021 Training loss: 9.075060844421387
2025-12-09 09:57:16.779 | INFO     | __main__:train:24 - Epoch: 0 Step: 21 LR: 0.00022 Training loss: 9.075896263122559
2025-12-09 09:57:16.793 | INFO     | __main__:train:24 - Epoch: 0 Step: 22 LR: 0.00023 Training loss: 9.076498985290527
2025-12-09 09:57:16.808 | INFO     | __main__:train:24 - Epoch: 0 Step: 23 LR: 0.00024 Training loss: 9.075234413146973
2025-12-09 09:57:16.822 | INFO     | __main__:train:24 - Epoch: 0 Step: 24 LR: 0.00025 Training loss: 9.075255393981934
2025-12-09 09:57:16.837 | INFO     | __main__:train:24 - Epoch: 0 Step: 25 LR: 0.00026000000000000003 Training loss: 9.076590538024902
